[{"snippet_id": 89003, "code": " \"\"\"Selects targets in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during", "label": 0}, {"snippet_id": 9019, "code": " if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1]", "label": 0}, {"snippet_id": 37845, "code": ".snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params", "label": 0}, {"snippet_id": 13248, "code": ".github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data[\"target_repo_branch\"]) request_json={ \"ref\": \"refs/heads/{}\".format(data[\"new_branch\"", "label": 0}, {"snippet_id": 79843, "code": "\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs", "label": 0}, {"snippet_id": 16996, "code": " headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession", "label": 0}, {"snippet_id": 57903, "code": " '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun found.') add_comment(runs, comment", "label": 0}, {"snippet_id": 61048, "code": ".append(np.outer(temp.conj(), temp)) return d, P I=np.eye(2) X=np.array([[0, 1],[1, 0]]) Y=np.array([[0, -1j],[1j, 0]]) Z=np.array([[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1", "label": 0}, {"snippet_id": 13380, "code": " auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file.encode()).decode(\"utf-8\") request_json={ \"path\": file, \"message\": \"Fix pep8 errors in{}\".format(file),", "label": 0}, {"snippet_id": 94010, "code": "=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node", "label": 0}, {"snippet_id": 16126, "code": "\n import os import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from", "label": 0}, {"snippet_id": 29773, "code": " \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp", "label": 0}, {"snippet_id": 42802, "code": " item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput", "label": 0}, {"snippet_id": 34668, "code": ".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) >", "label": 0}, {"snippet_id": 58457, "code": " needed'}) def test_refuse_if_missing_no_case_run_pk(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment',", "label": 0}, {"snippet_id": 79517, "code": "\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes)", "label": 0}, {"snippet_id": 75534, "code": " make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None): if not reqid: reqid", "label": 0}, {"snippet_id": 49495, "code": " filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list()", "label": 0}, {"snippet_id": 71044, "code": "[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append", "label": 0}, {"snippet_id": 79151, "code": ",fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"", "label": 0}, {"snippet_id": 58300, "code": " import EnvGroupPropertyMapFactory from tcms.tests.factories import EnvPropertyFactory class TestNavigation(test.TestCase): @classmethod def setUpTestData(cls): super(TestNavigation, cls).setUpTestData()", "label": 0}, {"snippet_id": 86816, "code": "-Dzinc.analysis.cache.limit=1000', '-Djava.awt.headless=true', '-Xmx2g') @classmethod def get_args_default(cls, bootstrap_option_values): return('-C-encoding', '-CUTF-8', '-S-encoding', '-SUTF-8', '-S-g", "label": 0}, {"snippet_id": 59479, "code": ", and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=[x.val", "label": 0}, {"snippet_id": 52219, "code": " snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(", "label": 0}, {"snippet_id": 46196, "code": " filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: *", "label": 0}, {"snippet_id": 15794, "code": "=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data)", "label": 0}, {"snippet_id": 61988, "code": "(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY'", "label": 0}, {"snippet_id": 93822, "code": " in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name", "label": 0}, {"snippet_id": 34304, "code": " return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs,", "label": 0}, {"snippet_id": 37127, "code": ": try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))", "label": 1}, {"snippet_id": 59543, "code": "[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is", "label": 0}, {"snippet_id": 33836, "code": " overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack", "label": 0}, {"snippet_id": 42098, "code": ".params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\":", "label": 0}, {"snippet_id": 57531, "code": " say_no('Not know what to update.') def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids=map(int, self.request.POST.getlist('case')) self._update_objects=TestCase.objects", "label": 0}, {"snippet_id": 50326, "code": ": raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority", "label": 0}, {"snippet_id": 49606, "code": "=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata", "label": 0}, {"snippet_id": 55042, "code": ".check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you", "label": 0}, {"snippet_id": 19643, "code": "--nodebug', action='store_true') host=parser.add_mutually_exclusive_group() host.add_argument('--host') host.add_argument('--server-host') parser.add_argument('--port', type=int, required=True) target=parser", "label": 0}, {"snippet_id": 88850, "code": " for the root directory associated with this context. When a goal requires serialization, it will call this to acquire the lock. :API: public \"\"\" if self.options.for_global_scope().lock: if not self._lock", "label": 0}, {"snippet_id": 72356, "code": "%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname) remoteirc.reply=old_reply remoteirc.pseudoclient.account='' @utils.add_cmd def reloadproto(irc, source, args): \"\"\"<protocol module", "label": 1}, {"snippet_id": 18237, "code": " class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp", "label": 0}, {"snippet_id": 43193, "code": " concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize", "label": 0}, {"snippet_id": 92321, "code": " new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as(HORK=None): subprocess.Popen([sys.executable", "label": 0}, {"snippet_id": 80586, "code": "=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies", "label": 0}, {"snippet_id": 72087, "code": "): \"\"\"<network> <seconds> Sets the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"\"\" permissions.checkPermissions(irc, source", "label": 0}, {"snippet_id": 75813, "code": "=None): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=timeout if timeout else self.wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface, method, data, rs", "label": 1}, {"snippet_id": 10481, "code": " of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is", "label": 0}, {"snippet_id": 51264, "code": " occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint", "label": 0}, {"snippet_id": 9842, "code": " dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically", "label": 0}, {"snippet_id": 5476, "code": " return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,", "label": 0}, {"snippet_id": 5026, "code": " objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\"", "label": 0}, {"snippet_id": 71166, "code": "(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif", "label": 0}, {"snippet_id": 63619, "code": " download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(", "label": 0}, {"snippet_id": 21027, "code": " @contextlib.contextmanager def _wait_for_message(self, match, handlername, timeout=None): if timeout is None: timeout=self.TIMEOUT lock, wait=get_locked_and_waiter() def handler(msg): if not match(msg)", "label": 0}, {"snippet_id": 35033, "code": "(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:", "label": 0}, {"snippet_id": 2932, "code": ".debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(", "label": 0}, {"snippet_id": 5746, "code": "]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0", "label": 0}, {"snippet_id": 51611, "code": " filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the", "label": 0}, {"snippet_id": 87506, "code": ", relative_to_exec_root(v) ) for k, v in upstream_analysis.items())]) zinc_args.extend(self._zinc.rebase_map_args) zinc_args.extend(args) zinc_args.extend(self._get_zinc_arguments(settings)) zinc_args.append", "label": 0}, {"snippet_id": 14064, "code": " query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json", "label": 0}, {"snippet_id": 11921, "code": " \"header\": \"\", \"footer\": \"\" }, \"updated\":{ \"header\": \"\", \"footer\": \"\" } }, \"scanner\":{\"diff_only\": False}, \"pycodestyle\":{ \"ignore\":[], \"max-line-length\": 79, \"count\": False, \"first\": False, \"show-pep8", "label": 0}, {"snippet_id": 77269, "code": "%s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self, wclass, count, args=(), kvargs={}): wname", "label": 0}, {"snippet_id": 65888, "code": " if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len", "label": 0}, {"snippet_id": 74439, "code": " not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation", "label": 0}, {"snippet_id": 74128, "code": " vcf_to_zarr_blosc_shuffle_types: self.blosc_shuffle_mode=blosc_shuffle_mode_int else: raise ValueError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode must be a valid integer", "label": 0}, {"snippet_id": 14421, "code": " : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self", "label": 0}, {"snippet_id": 83297, "code": " job_state=self.__find_watched_job( job_id) if not job_state: log.warn( \"Failed to find job corresponding to final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status", "label": 1}, {"snippet_id": 66400, "code": ".Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self", "label": 0}, {"snippet_id": 24148, "code": ".util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES", "label": 1}, {"snippet_id": 26282, "code": ", 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv", "label": 1}, {"snippet_id": 57837, "code": " flat=True) if not reviewers: err_msg='Reviewer %s is not found' % self.new_value raise ObjectDoesNotExist(err_msg) self.get_update_targets().update(**{str(self.target_field): reviewers[0]}) @require_POST", "label": 0}, {"snippet_id": 75924, "code": "): flag=0 for rs in rslist: if rs.finished: if not rs.retry: del msgdict[rs] continue s.send_multipart(msgdict[rs]) rs.finished=False rs.retry=False flag=1 if not flag: return t.tick() p(timeout*1000) if", "label": 0}, {"snippet_id": 74465, "code": " Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\" password=\"\" use_tls=False directory=\"\" files=[] def __init__(self, runtime_config=None): \"\"", "label": 0}, {"snippet_id": 80594, "code": "+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning", "label": 0}, {"snippet_id": 543, "code": "'logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\"", "label": 0}, {"snippet_id": 36268, "code": "{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self", "label": 0}, {"snippet_id": 20682, "code": "'command': command, 'arguments': args, } def send_request(self, command, **args): if self.closed: raise RuntimeError('session closed') wait=args.pop('wait', False) req=self._create_request(command, **args", "label": 0}, {"snippet_id": 62929, "code": " string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep import os from.lwr_client import build_client_manager from.lwr_client import url_to_destination_params from", "label": 0}, {"snippet_id": 47843, "code": " self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output)", "label": 0}, {"snippet_id": 72775, "code": " the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS,", "label": 0}, {"snippet_id": 81452, "code": " \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext", "label": 0}, {"snippet_id": 61777, "code": " ValueError('Bad target subsystems.') a=np.min(wires) b=np.max(wires) n_between=b-a-1 before =2**a after =2**(self.wires-b-1) between=2**n_between U=np.kron(U, np.eye(between)) if wires[0] < wires[1]: p=", "label": 0}, {"snippet_id": 3097, "code": " is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug", "label": 0}, {"snippet_id": 55644, "code": "]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile", "label": 0}, {"snippet_id": 52118, "code": " load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file", "label": 0}, {"snippet_id": 95957, "code": "(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path,", "label": 0}, {"snippet_id": 38727, "code": " rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return", "label": 0}, {"snippet_id": 9000, "code": " output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache:", "label": 0}, {"snippet_id": 90629, "code": ", name, stricter): version_a=_parse_java_version(name, a) version_b=_parse_java_version(name, b) if version_a is None: return version_b if version_b is None: return version_a return stricter(version_a,", "label": 0}, {"snippet_id": 30454, "code": " JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that", "label": 0}, {"snippet_id": 31640, "code": ") self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names", "label": 0}, {"snippet_id": 31575, "code": " self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow", "label": 0}, {"snippet_id": 86986, "code": " cache ' 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies() +(Zinc.Factory, JvmPlatform,) @classmethod def prepare(cls,", "label": 0}, {"snippet_id": 70362, "code": " target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support", "label": 0}, {"snippet_id": 70152, "code": "(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror", "label": 0}, {"snippet_id": 23175, "code": " struct_size, we can't get the information we need. I believe this may be caused by only python i686 being shipped with BIG-IP instead of python x86_64?? \"\"\" iface='' expected=16 python_arc=platform.architecture", "label": 0}, {"snippet_id": 29447, "code": " or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self):", "label": 0}, {"snippet_id": 60820, "code": "=shots self._out=None self._queue=[] self._observe=None def __repr__(self): \"\"\"String representation.\"\"\" return self.__module__ +'.' +self.__class__.__name__ +'\\nInstance: ' +self.name def __str__(self)", "label": 0}, {"snippet_id": 44531, "code": "=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster", "label": 0}, {"snippet_id": 18273, "code": "._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file", "label": 0}, {"snippet_id": 15449, "code": "( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False)", "label": 0}, {"snippet_id": 57108, "code": ".get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field", "label": 0}, {"snippet_id": 35560, "code": "._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items():", "label": 0}, {"snippet_id": 34595, "code": ".rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly", "label": 0}, {"snippet_id": 4163, "code": "\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False,", "label": 0}, {"snippet_id": 41021, "code": " \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone", "label": 0}, {"snippet_id": 58410, "code": "\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls).setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs') def test_refuse_if_missing_comment(self): self.client.login", "label": 0}, {"snippet_id": 18616, "code": "( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self", "label": 0}, {"snippet_id": 84857, "code": " cls._create_jardep('scala-library', version) @classmethod def _create_compiler_jardep(cls, version): return cls._create_jardep('scala-compiler', version) @classmethod def _key_for_tool_version(cls, tool,", "label": 1}, {"snippet_id": 82956, "code": " executor: \tfutures=[] \ttry: \t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a[\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName", "label": 0}, {"snippet_id": 66747, "code": "\"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" %", "label": 1}, {"snippet_id": 75686, "code": "=[] self.wz_bind_methods=[] self.wz_poll_timeout=30 def __sinit__(self): '''Initializes thread-local interface on startup''' self.log=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker", "label": 1}, {"snippet_id": 59592, "code": " \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits", "label": 0}, {"snippet_id": 74709, "code": " value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"chunk_width\" in runtime_config.vcf_to_zarr: chunk_width_str=runtime_config.vcf_to_zarr[\"chunk_width\"]", "label": 0}, {"snippet_id": 30579, "code": " logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self", "label": 0}, {"snippet_id": 95141, "code": " temp_dir=temp_directory, output_dir=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service.setup_vcf_to_zarr(input_vcf_dir", "label": 1}, {"snippet_id": 11163, "code": ".mtime: lines.append(\"%s%d\" %(Header.MTIME_COMMMENT, self.mtime)) return lines @staticmethod def parse(file_name): etag, mtime=None, 0 def extract(comment, current_value): value=None if line.startswith", "label": 0}, {"snippet_id": 69633, "code": "=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf", "label": 1}, {"snippet_id": 76512, "code": ".unbind_methods() self.running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx, sig_addr, *args, ", "label": 0}, {"snippet_id": 95655, "code": " Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The", "label": 0}, {"snippet_id": 75001, "code": " if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified", "label": 0}, {"snippet_id": 61598, "code": "\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem Returns: float: expectation value", "label": 0}, {"snippet_id": 46978, "code": " self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf", "label": 0}, {"snippet_id": 28187, "code": "', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy',", "label": 0}, {"snippet_id": 33126, "code": " return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets", "label": 0}, {"snippet_id": 60594, "code": " self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self", "label": 1}, {"snippet_id": 40751, "code": " flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern", "label": 0}, {"snippet_id": 928, "code": "(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 55312, "code": ")) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler", "label": 0}, {"snippet_id": 95229, "code": " the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib", "label": 0}, {"snippet_id": 1019, "code": ") elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess", "label": 0}, {"snippet_id": 19833, "code": " def adapter(self): return self._adapter @property def session(self): return self._session def start_debugging(self, launchcfg): if self.closed: raise RuntimeError('debug client closed') if self._adapter", "label": 0}, {"snippet_id": 90503, "code": " maximum_version: maximum jvm version to look for(eg, 1.7.9999). :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None if no matching distribution", "label": 0}, {"snippet_id": 60827, "code": "\"\"\"String representation.\"\"\" return self.__module__ +'.' +self.__class__.__name__ +'\\nInstance: ' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self", "label": 0}, {"snippet_id": 67539, "code": " class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on", "label": 0}, {"snippet_id": 71557, "code": " print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file", "label": 0}, {"snippet_id": 64576, "code": " fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes:", "label": 0}, {"snippet_id": 35018, "code": "\" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append", "label": 0}, {"snippet_id": 11246, "code": " -h Options: -h Show this message. --debug Print additional information. --targetdir=DIR The generated Icinga monitoring configuration is written into this directory. If no target directory is given its", "label": 0}, {"snippet_id": 15253, "code": " self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request", "label": 0}, {"snippet_id": 95600, "code": "}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file", "label": 0}, {"snippet_id": 92154, "code": "-setup-requires-pex' @classmethod def register_options(cls, register): super(BuildSetupRequiresPex, cls).register_options(register) register('--setuptools-version', advanced=True, fingerprint=True, default", "label": 0}, {"snippet_id": 1421, "code": ") print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{", "label": 0}, {"snippet_id": 76314, "code": "(reqid, seqnum, status, data)) def send_success_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.success, data) def send_error_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.error", "label": 0}, {"snippet_id": 40942, "code": " hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict -", "label": 0}, {"snippet_id": 31425, "code": ".incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files", "label": 0}, {"snippet_id": 42673, "code": "(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in", "label": 0}, {"snippet_id": 33646, "code": " if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes", "label": 0}, {"snippet_id": 32637, "code": " return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values()))", "label": 0}, {"snippet_id": 28199, "code": ":['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi", "label": 0}, {"snippet_id": 18927, "code": "\"\"\" if isinstance(source, collections.Mapping): return source elif hasattr(source, 'read') and callable(source.read): raw_source=source.read() elif os.path.exists(os.path.expanduser(str(source))): with", "label": 0}, {"snippet_id": 22131, "code": ".loader, options=self.options, passwords={}) def run(self, job_id): \"\"\"Run the playbook and returns the playbook's stats.\"\"\" self.variable_manager.extra_vars={'job_id': job_id} self.pbex.run() return self", "label": 0}, {"snippet_id": 23909, "code": "\".format(iface)) for line in output.split('\\n'): if line.find('inet ') !=-1: inet=line.split()[1] elif line.find('ether ') !=-1: mac=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface", "label": 0}, {"snippet_id": 10375, "code": "(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml)", "label": 0}, {"snippet_id": 68351, "code": "().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet()", "label": 0}, {"snippet_id": 80125, "code": "\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(", "label": 0}, {"snippet_id": 62790, "code": " if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs", "label": 0}, {"snippet_id": 90865, "code": " locations on the file system such as `/usr/lib/jvm` on Linux machines. :API: public \"\"\" class Error(Distribution.Error): \"\"\"Error locating a java distribution. :API: public \"\"\" @classmethod def cached", "label": 0}, {"snippet_id": 51341, "code": " WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__", "label": 0}, {"snippet_id": 79186, "code": "\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()", "label": 0}, {"snippet_id": 86791, "code": " settings.args) zinc_args.extend(settings_args) return zinc_args @classmethod def implementation_version(cls): return super(BaseZincCompile, cls).implementation_version() +[('BaseZincCompile', 7)] @classmethod", "label": 0}, {"snippet_id": 5698, "code": " kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords", "label": 0}, {"snippet_id": 94980, "code": "\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration", "label": 0}, {"snippet_id": 84259, "code": " job_wrapper, remote_metadata, remote_job_config): metadata_kwds={} if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(", "label": 0}, {"snippet_id": 68299, "code": " layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 88265, "code": " WorkUnit, WorkUnitLabel from pants.build_graph.target import Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products import Products from pants.goal.workspace", "label": 1}, {"snippet_id": 3667, "code": " logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else:", "label": 0}, {"snippet_id": 79868, "code": " named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index", "label": 0}, {"snippet_id": 78581, "code": ": with cstate(self, WipeState.waiting_for_targets): while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self", "label": 0}, {"snippet_id": 65879, "code": ".state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d", "label": 0}, {"snippet_id": 85788, "code": " compile_classpath_entries(self, classpath_product_key, target, extra_cp_entries=None): classpath_product=self._products.get_data(classpath_product_key) if DependencyContext.global_instance().defaulted_property", "label": 0}, {"snippet_id": 79098, "code": ".warning(\"Code execution detection will not be possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile", "label": 0}, {"snippet_id": 91504, "code": ".engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch) from pants.engine.isolated_process import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult", "label": 0}, {"snippet_id": 20657, "code": "._listenerthread.start() @property def is_client(self): return self._conn.is_client @property def received(self): return list(self._received) def _create_request(self, command, **args): seq=self._seq self", "label": 0}, {"snippet_id": 21462, "code": " with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) else: print(\"Reddytt: Working directory found. Loading variables.\") with open(seen_file, 'rb') as f: seen_links=pickle.load(f) with open", "label": 0}, {"snippet_id": 89770, "code": "=jdk_dir self._home=home return self._home @property def real_home(self): \"\"\"Real path to the distribution java.home(resolving links).\"\"\" return os.path.realpath(self.home) @property def java(self): \"\"", "label": 1}, {"snippet_id": 37453, "code": " files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if", "label": 0}, {"snippet_id": 53301, "code": ".priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile", "label": 0}, {"snippet_id": 55518, "code": " self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self", "label": 0}, {"snippet_id": 20976, "code": "=handle_message(msg) try: msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True", "label": 0}, {"snippet_id": 42541, "code": " try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))]", "label": 1}, {"snippet_id": 82612, "code": ".legitExtensions: \targs.legitExtensions=[x.lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging", "label": 0}, {"snippet_id": 35522, "code": " to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone -", "label": 0}, {"snippet_id": 95450, "code": "(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"\" Recursive function that automatically downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type", "label": 0}, {"snippet_id": 10017, "code": "[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} ", "label": 0}, {"snippet_id": 73431, "code": " path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str))", "label": 0}, {"snippet_id": 20418, "code": ".sleep(0.1) else: break else: raise RuntimeError('could not connect') return sock return cls._create(connect, addr, **kwargs) @classmethod def create_server(cls, addr, **kwargs): def connect(addr, timeout)", "label": 0}, {"snippet_id": 47852, "code": "._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self", "label": 0}, {"snippet_id": 10601, "code": "\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if", "label": 1}, {"snippet_id": 25087, "code": "(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self", "label": 1}, {"snippet_id": 51032, "code": "=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic", "label": 1}, {"snippet_id": 82484, "code": " method must be provided, either with --not-regex or with --true-regex.\") if args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON", "label": 0}, {"snippet_id": 6355, "code": " one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately", "label": 0}, {"snippet_id": 32887, "code": "=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self", "label": 0}, {"snippet_id": 14957, "code": ".post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5,", "label": 1}, {"snippet_id": 18688, "code": "(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format(", "label": 0}, {"snippet_id": 17979, "code": " requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return", "label": 0}, {"snippet_id": 32481, "code": ".dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self", "label": 0}, {"snippet_id": 18363, "code": "._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port", "label": 0}, {"snippet_id": 92295, "code": " output.seek(0) self.assertEqual('BORK\\n', output.read()) with temporary_file(binary_mode=False) as new_output: subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\" in os.environ)'], stdout", "label": 0}, {"snippet_id": 31293, "code": " \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return", "label": 0}, {"snippet_id": 79510, "code": "+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern", "label": 1}, {"snippet_id": 66254, "code": ", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\"", "label": 0}, {"snippet_id": 81065, "code": ".logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit(", "label": 0}, {"snippet_id": 85241, "code": " repl(self): \"\"\"Return the repl tool key.\"\"\" return self._key_for_tool_version('scala-repl', self.version) def injectables(self, build_graph): if self.version=='custom': return specs_to_create=[ ('scalac", "label": 1}, {"snippet_id": 18107, "code": " try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data", "label": 0}, {"snippet_id": 81895, "code": ".add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\"", "label": 0}, {"snippet_id": 20808, "code": " and condition(msg) handlername='event{!r}'.format(event) evt=self._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result[\"msg\"], evt) def _get_awaiter_for_request(self, req, ", "label": 0}, {"snippet_id": 66934, "code": " self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd", "label": 0}, {"snippet_id": 17875, "code": " BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 6257, "code": "\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file", "label": 1}, {"snippet_id": 25359, "code": " _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(", "label": 1}, {"snippet_id": 26007, "code": "=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 26380, "code": " data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s", "label": 0}, {"snippet_id": 44505, "code": " scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit", "label": 0}, {"snippet_id": 17612, "code": " SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest", "label": 0}, {"snippet_id": 57826, "code": "**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list('pk', flat=True) if not reviewers: err_msg='Reviewer %s is not found' % self.new_value", "label": 0}, {"snippet_id": 78272, "code": ".Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment,(t, msg)) except(exc.Closed, exc.UserDeny) as e: try: self.targets.remove(t) except ValueError: pass self.w.sleep", "label": 0}, {"snippet_id": 67120, "code": " event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print ", "label": 0}, {"snippet_id": 27108, "code": "-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import", "label": 1}, {"snippet_id": 23162, "code": " here because, curiously, our 64bit platform is identified by python in Azure(Stack) as 32 bit and without adjusting the struct_size, we can't get the information we need. I believe this may be caused by", "label": 0}, {"snippet_id": 17767, "code": ", extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options", "label": 0}, {"snippet_id": 38113, "code": " def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2", "label": 0}, {"snippet_id": 93636, "code": " start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if", "label": 0}, {"snippet_id": 60218, "code": " Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'Kerr': Kgate", "label": 0}, {"snippet_id": 72641, "code": ") elif command==\"setup\": print(\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration", "label": 1}, {"snippet_id": 27191, "code": ", 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery'", "label": 0}, {"snippet_id": 67529, "code": ".Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self", "label": 0}, {"snippet_id": 14301, "code": "( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript", "label": 1}, {"snippet_id": 83009, "code": "\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints", "label": 0}, {"snippet_id": 72936, "code": " in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary(", "label": 0}, {"snippet_id": 90186, "code": " home): \"\"\"Creates a location given the JAVA_HOME directory. :param string home: The path of the JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None)", "label": 0}, {"snippet_id": 43202, "code": "[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if", "label": 0}, {"snippet_id": 78535, "code": "', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c==0:", "label": 0}, {"snippet_id": 58670, "code": "=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission Dinied.'}) def test_update_plan_is_active(self): self.client.login( username=self.tester.username, password='password') post_data={ 'content_type", "label": 0}, {"snippet_id": 43305, "code": " rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile)", "label": 0}, {"snippet_id": 84233, "code": " datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def __rewrite_parameters", "label": 0}, {"snippet_id": 62646, "code": " in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset", "label": 0}, {"snippet_id": 38258, "code": " def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False):", "label": 0}, {"snippet_id": 26937, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0:", "label": 0}, {"snippet_id": 79721, "code": "-proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at", "label": 0}, {"snippet_id": 57579, "code": "._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context)", "label": 0}, {"snippet_id": 76297, "code": ".wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep(self, reqid", "label": 0}, {"snippet_id": 22409, "code": " rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh", "label": 0}, {"snippet_id": 13367, "code": " params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file.encode()).decode(", "label": 0}, {"snippet_id": 83956, "code": ", e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID ", "label": 0}, {"snippet_id": 8152, "code": ") filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"", "label": 0}, {"snippet_id": 91074, "code": "\"{}\"; combining results.'.format(rename)) normalized[rename].extend(paths) else: normalized[rename]=paths return normalized def _get_explicit_jdk_paths(self): if not self._normalized_jdk_paths: return(", "label": 0}, {"snippet_id": 28503, "code": " update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found", "label": 0}, {"snippet_id": 1445, "code": ", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method", "label": 0}, {"snippet_id": 32010, "code": ".dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, ", "label": 0}, {"snippet_id": 70026, "code": ".Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand", "label": 0}, {"snippet_id": 21537, "code": " link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt: That was: %s\" % link) if x==0: seen_links.append(link", "label": 1}, {"snippet_id": 86999, "code": " JvmPlatform,) @classmethod def prepare(cls, options, round_manager): super(BaseZincCompile, cls).prepare(options, round_manager) ScalaPlatform.prepare_tools(round_manager) @property def incremental(self): \"\"", "label": 0}, {"snippet_id": 26008, "code": " elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data", "label": 0}, {"snippet_id": 37777, "code": "\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item:", "label": 0}, {"snippet_id": 52228, "code": " UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag", "label": 0}, {"snippet_id": 92071, "code": " not self._any_targets_have_native_sources(targets): return False platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys()", "label": 0}, {"snippet_id": 2080, "code": " safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(", "label": 0}, {"snippet_id": 92368, "code": "'USER', os.environ) def test_hermetic_environment_subprocesses(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**dict(AAA='333')): output=subprocess.check_output('env', shell=True)", "label": 1}, {"snippet_id": 22738, "code": ".format(username, retcode, out) ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id=6, salt_len=10): \"\"\"Change a user's password with tmsh Since we are creating the user", "label": 0}, {"snippet_id": 88179, "code": " plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile): \"\"\"Compile Scala and Java code to classfiles using", "label": 0}, {"snippet_id": 6408, "code": " from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as", "label": 0}, {"snippet_id": 27998, "code": "'rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status", "label": 0}, {"snippet_id": 36058, "code": " name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(),", "label": 0}, {"snippet_id": 94453, "code": " was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED elif check_available and run_component_check", "label": 0}, {"snippet_id": 93592, "code": ": self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self, comp_name, host", "label": 0}, {"snippet_id": 23579, "code": "=self._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper() return None def get_first_if(self): return self._get_net_info()[:2] def route_add(self, net, mask, gateway): cmd='route", "label": 0}, {"snippet_id": 45774, "code": ") def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove", "label": 0}, {"snippet_id": 12273, "code": "[WE]\\d+\\s.*\", error): data[\"results\"][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error in list(data[\"results\"][filename]): if config", "label": 0}, {"snippet_id": 21592, "code": "=pd.read_csv('Social_Network_Ads.csv') X=dataset.iloc[:,[2, 3]].values y=dataset.iloc[:, 4].values from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X", "label": 1}, {"snippet_id": 59505, "code": " in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name, wires,", "label": 0}, {"snippet_id": 12325, "code": "\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request.json[\"action\"]==\"opened\"", "label": 0}, {"snippet_id": 77771, "code": ", 'pr_sock'): self.pr_sock.send_multipart(msg) def join_threads(self): for t in self.threads: t.join() def send_passthrough(self, interface, method, frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg", "label": 0}, {"snippet_id": 71241, "code": ".dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target", "label": 0}, {"snippet_id": 23863, "code": "'' mac='' err, output=shellutil.run_get_output('ifconfig -l ether', chk_err=False) if err: raise OSUtilError(\"Can't find ether interface:{0}\".format(output)) ifaces=output.split() if not ifaces: raise OSUtilError", "label": 0}, {"snippet_id": 60768, "code": ", along with any additional parameters.\"\"\" return cls(name, *args, **kwargs) return new_object class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an illegal operation", "label": 0}, {"snippet_id": 83167, "code": "): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the job runner \"\"\" super( LwrJobRunner", "label": 0}, {"snippet_id": 52398, "code": " priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): ", "label": 0}, {"snippet_id": 2074, "code": ":userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout", "label": 0}, {"snippet_id": 48110, "code": ".items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark", "label": 0}, {"snippet_id": 3860, "code": ".makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help", "label": 0}, {"snippet_id": 77014, "code": "]=fset net=make_net(proxy, proxytype) net.cookiefname=(proxy if proxy else 'noproxy')+'_'+domain w=UniWipe(fset, tlist, sbjfun, message, pc, net, domain, Mailinator, uq(domain) if uq else None) w.stoponclose", "label": 0}, {"snippet_id": 74646, "code": " \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config", "label": 0}, {"snippet_id": 91508, "code": " DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch) from pants.engine.isolated_process import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult) from pants.engine", "label": 0}, {"snippet_id": 68624, "code": "=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status", "label": 0}, {"snippet_id": 59460, "code": "'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation", "label": 1}, {"snippet_id": 4767, "code": " keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name", "label": 0}, {"snippet_id": 18398, "code": "._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ :", "label": 0}, {"snippet_id": 96040, "code": "==\"Blosc\": compressor=Blosc(cname=conversion_config.blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected", "label": 0}, {"snippet_id": 48388, "code": " return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item", "label": 0}, {"snippet_id": 41875, "code": ")\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list", "label": 0}, {"snippet_id": 83557, "code": ", compute_environment def __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if", "label": 0}, {"snippet_id": 81603, "code": "\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t", "label": 0}, {"snippet_id": 17022, "code": " BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport", "label": 0}, {"snippet_id": 12775, "code": " headers=headers, auth=auth) def autopep8(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(data", "label": 0}, {"snippet_id": 26786, "code": " data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" %", "label": 0}, {"snippet_id": 73755, "code": ".items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username", "label": 0}, {"snippet_id": 24793, "code": "\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 22809, "code": " unencrypted password to set for the user :param crypt_id: If encrypting the password, the crypt_id that was used :param salt_len: If encrypting the password, the length of the salt value used to do it. \"\"", "label": 0}, {"snippet_id": 87445, "code": ", '-analysis-cache', analysis_cache, '-classpath', ':'.join(relative_classpath), '-d', classes_dir, ]) if not self.get_options().colors: zinc_args.append('-no-color') zinc_args.extend(['-compiler-interface", "label": 1}, {"snippet_id": 68230, "code": "\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR", "label": 0}, {"snippet_id": 79540, "code": "\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t", "label": 0}, {"snippet_id": 74974, "code": " a dictionary of the form <dict>.<section>[<option>] and the corresponding values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite", "label": 0}, {"snippet_id": 41608, "code": "._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise", "label": 0}, {"snippet_id": 8005, "code": " labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]", "label": 0}, {"snippet_id": 42132, "code": " return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other", "label": 0}, {"snippet_id": 72546, "code": " benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser", "label": 0}, {"snippet_id": 71123, "code": " AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View", "label": 0}, {"snippet_id": 36767, "code": "\"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self", "label": 0}, {"snippet_id": 82524, "code": " ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking", "label": 0}, {"snippet_id": 91938, "code": "--native-source-extensions', type=list, default=cls.default_native_source_extensions, fingerprint=True, advanced=True, help='The extensions recognized for native source files in `python_dist()` sources", "label": 0}, {"snippet_id": 81965, "code": ",dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r", "label": 0}, {"snippet_id": 60832, "code": ".__module__ +'.' +self.__class__.__name__ +'\\nInstance: ' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version", "label": 0}, {"snippet_id": 59478, "code": " device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=", "label": 0}, {"snippet_id": 7430, "code": "] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results", "label": 0}, {"snippet_id": 61899, "code": ".ClassicalSimulator()\t A simple introspective simulator that only permits classical operations. -projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class, which stores the circuit, transforms it", "label": 0}, {"snippet_id": 10999, "code": ", error: %s\" %(url, e) raise HostUnreachableException(msg) except RequestException as e: msg=\"Could not get monitoring yaml from '%s', error: %s\" %(url, e) raise MonitoringConfigGeneratorException(msg)", "label": 0}, {"snippet_id": 7544, "code": " the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author", "label": 0}, {"snippet_id": 28422, "code": "[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self", "label": 0}, {"snippet_id": 29595, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f", "label": 0}, {"snippet_id": 78393, "code": "=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min exc caught, topic_successtimeout +0.1, cur: %f', self", "label": 0}, {"snippet_id": 89868, "code": "\"\"Validates this distribution against its configured constraints. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" if self._validated_binaries: return", "label": 0}, {"snippet_id": 62647, "code": " operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"", "label": 0}, {"snippet_id": 20992, "code": " def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[] for handle_msg, name, required in", "label": 0}, {"snippet_id": 79055, "code": "\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex", "label": 0}, {"snippet_id": 43534, "code": " Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause", "label": 0}, {"snippet_id": 82908, "code": "=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime", "label": 1}, {"snippet_id": 90566, "code": " meets the given constraints and returns it. First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg, 1.7). The", "label": 0}, {"snippet_id": 23679, "code": ".format(ifname), chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self", "label": 0}, {"snippet_id": 36404, "code": " input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set()", "label": 0}, {"snippet_id": 28552, "code": "=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data[", "label": 0}, {"snippet_id": 58007, "code": " else: data['action']=request.GET.get('a') data['bz_external_track']=True if request.GET.get('bz_external_track', False) else False return(data, '') def update_bugs_to_caseruns(request): \"\"\" Add one or", "label": 0}, {"snippet_id": 37269, "code": " lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property", "label": 0}, {"snippet_id": 46778, "code": " import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile,", "label": 1}, {"snippet_id": 93359, "code": " group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)", "label": 0}, {"snippet_id": 45199, "code": " self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self", "label": 0}, {"snippet_id": 25304, "code": " vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, })", "label": 0}, {"snippet_id": 29474, "code": "?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing", "label": 0}, {"snippet_id": 62828, "code": "(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure", "label": 0}, {"snippet_id": 44445, "code": "\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes", "label": 0}, {"snippet_id": 1786, "code": " data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\"", "label": 0}, {"snippet_id": 56648, "code": ".values('tag').annotate(num_runs=Count('tag')).order_by('tag') plan_counter=_TagCounter('num_plans', test_plan_tags) case_counter=_TagCounter('num_cases', test_case_tags) run_counter=_TagCounter('num_runs", "label": 0}, {"snippet_id": 49956, "code": " if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores", "label": 0}, {"snippet_id": 68534, "code": " if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout", "label": 0}, {"snippet_id": 69283, "code": "\"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"", "label": 1}, {"snippet_id": 23401, "code": "\"\\n\".join(conf_file)) shellutil.run(\"hostname{0}\".format(hostname), chk_err=False) def restart_ssh_service(self): return shellutil.run('service sshd restart', chk_err=False) def useradd(self, username,", "label": 1}, {"snippet_id": 76037, "code": ".request[i, m])) def bind_route(self, i, m, f): self.log.debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m,", "label": 0}, {"snippet_id": 20864, "code": "{})'.format(command, seq) evt=self._get_message_handle(match, handlername) return AwaitableResponse(req, lambda: result[\"msg\"], evt) @contextlib.contextmanager def wait_for_response(self, req, **kwargs", "label": 0}, {"snippet_id": 3501, "code": ".config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self", "label": 0}, {"snippet_id": 53480, "code": "(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, *", "label": 0}, {"snippet_id": 34795, "code": " fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill", "label": 1}, {"snippet_id": 87335, "code": "=sha1() for cp_entry in[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12", "label": 1}, {"snippet_id": 33118, "code": ".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets", "label": 0}, {"snippet_id": 21542, "code": ") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt: That was: %s\" % link) if x==0: seen_links.append(link) save_links.remove(link) elif x==1024: print(\"Reddytt: Forced", "label": 1}, {"snippet_id": 9539, "code": " of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should", "label": 0}, {"snippet_id": 54527, "code": " self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname", "label": 0}, {"snippet_id": 44648, "code": " if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include", "label": 0}, {"snippet_id": 3824, "code": ".cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path):", "label": 0}, {"snippet_id": 90033, "code": "=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self.Error('Failed to determine java system properties for{} with{}", "label": 0}, {"snippet_id": 67461, "code": " command aims to start Lustre filesystem servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os", "label": 0}, {"snippet_id": 46937, "code": " if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self", "label": 0}, {"snippet_id": 12164, "code": "\".py\": del files[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 29941, "code": "(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(", "label": 0}, {"snippet_id": 50550, "code": "=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 17908, "code": " BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler", "label": 0}, {"snippet_id": 89342, "code": " from pants.subsystem.subsystem import Subsystem from pants.util.contextutil import temporary_dir from pants.util.memo import memoized_method, memoized_property from pants.util.meta import AbstractClass", "label": 0}, {"snippet_id": 88108, "code": "\"\"If classpath_element is a scalac plugin, returns its name. Returns None otherwise. \"\"\" def process_info_file(cp_elem, info_file): plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag", "label": 0}, {"snippet_id": 94189, "code": " Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion", "label": 0}, {"snippet_id": 77275, "code": " except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self, wclass, count, args=(), kvargs={}): wname=str(wclass.__name__) self.log.info('Starting %s(s)", "label": 0}, {"snippet_id": 58462, "code": " self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run':[]}) self.assertJSONEqual( str(response.content,", "label": 0}, {"snippet_id": 90843, "code": " java Distribution. Distributions are searched for in the following order by default: 1. Paths listed for this operating system in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely", "label": 0}, {"snippet_id": 77235, "code": "', line, e) return newproxies.difference(self.proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try: proxypair=proxypairs.pop() except Exception: return self.proxylist.add(proxypair", "label": 0}, {"snippet_id": 43595, "code": " import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources", "label": 0}, {"snippet_id": 85335, "code": " pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.shader import Shader from pants.backend.jvm.targets.scala_jar_dependency import ScalaJarDependency from", "label": 0}, {"snippet_id": 54914, "code": ".first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets", "label": 0}, {"snippet_id": 52367, "code": " f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self", "label": 0}, {"snippet_id": 18517, "code": " NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled", "label": 0}, {"snippet_id": 12415, "code": "]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link\"])) for issue in issues", "label": 0}, {"snippet_id": 55052, "code": ".\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error(", "label": 0}, {"snippet_id": 56647, "code": ").values('tag').annotate(num_runs=Count('tag')).order_by('tag') plan_counter=_TagCounter('num_plans', test_plan_tags) case_counter=_TagCounter('num_cases', test_case_tags) run_counter=_TagCounter('num_runs", "label": 0}, {"snippet_id": 26918, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self", "label": 0}, {"snippet_id": 63288, "code": "=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and LWR client for this job. \"\"\" command_line", "label": 0}, {"snippet_id": 54447, "code": ", CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler", "label": 0}, {"snippet_id": 88866, "code": ".for_global_scope().lock: if not self._lock.acquired: self._lock.acquire() def release_lock(self): \"\"\"Release the global lock if it's held. Returns True if the lock was held before this call. :API: public", "label": 0}, {"snippet_id": 56369, "code": ">' +obj_value.get(field, None) +'</li>' response_str +='</ul>' return HttpResponse(response_str) return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value'))) class _InfoObjects", "label": 0}, {"snippet_id": 85731, "code": " @memoized_method def _compiler_plugins_cp_entries(self): \"\"\"Any additional global compiletime classpath entries for compiler plugins.\"\"\" java_options_src=Java.global_instance() scala_options_src=ScalaPlatform", "label": 0}, {"snippet_id": 28289, "code": "'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol", "label": 1}, {"snippet_id": 17500, "code": ", completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest(", "label": 0}, {"snippet_id": 88779, "code": ") work function. :param items: A iterable of pickleable arguments to f. \"\"\" try: res=SubprocPool.foreground().map_async(f, items) while not res.ready(): res.wait(60) if not res.ready(): self.log.debug(", "label": 0}, {"snippet_id": 52463, "code": " KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self", "label": 0}, {"snippet_id": 4929, "code": " :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output", "label": 0}, {"snippet_id": 11159, "code": ".ETAG_COMMENT, self.etag)) if self.mtime: lines.append(\"%s%d\" %(Header.MTIME_COMMMENT, self.mtime)) return lines @staticmethod def parse(file_name): etag, mtime=None, 0 def extract(comment, current_value)", "label": 0}, {"snippet_id": 44425, "code": "(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed", "label": 0}, {"snippet_id": 29833, "code": " rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches", "label": 1}, {"snippet_id": 632, "code": ".append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW", "label": 0}, {"snippet_id": 1911, "code": "(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row", "label": 0}, {"snippet_id": 39246, "code": " print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path", "label": 0}, {"snippet_id": 90393, "code": ", path) if os.path.isdir(home): yield self.Location.from_home(home) class _ExplicitEnvironment(_DistributionEnvironment): def __init__(self, *homes): self._homes=homes @property def jvm_locations(self)", "label": 0}, {"snippet_id": 61999, "code": "'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits", "label": 0}, {"snippet_id": 80990, "code": "=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests", "label": 0}, {"snippet_id": 94851, "code": " args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init", "label": 0}, {"snippet_id": 85519, "code": " custom_rules=shader_rules) cls.register_jvm_tool(register, Zinc.ZINC_EXTRACTOR_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-extractor_2.11', '0.0.4') ]) @classmethod def _zinc(cls, products):", "label": 1}, {"snippet_id": 62777, "code": " ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the ", "label": 0}, {"snippet_id": 75434, "code": "(reqid, seqnum, status, answer)) return msg def get_iden(self, reqid): return self.iden_reqid_map.get_key(reqid) def get_reqids(self, iden): return self.iden_reqid_map.get_values(iden) def make_reqid(self", "label": 0}, {"snippet_id": 79975, "code": "=False,dest=\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"", "label": 0}, {"snippet_id": 22874, "code": "/tmsh modify auth user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin'", "label": 0}, {"snippet_id": 17160, "code": ".ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import", "label": 0}, {"snippet_id": 19155, "code": " raw_request, raw_response): \"\"\" Validate the request/response cycle of an api call against a swagger schema. Request/Response objects from the `requests` and `urllib` library are supported. \"\"\" request", "label": 0}, {"snippet_id": 54717, "code": " --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules", "label": 0}, {"snippet_id": 75005, "code": " is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with", "label": 0}, {"snippet_id": 66678, "code": "): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print", "label": 0}, {"snippet_id": 4908, "code": " of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary", "label": 0}, {"snippet_id": 24998, "code": "'rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'", "label": 0}, {"snippet_id": 54284, "code": ".groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len", "label": 0}, {"snippet_id": 67756, "code": "-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK,", "label": 0}, {"snippet_id": 22674, "code": " the admin account that is, or should be, built in to the system. :param username: The username that you want to add to the system :param expiration: The expiration date to use. We do not use this value. ", "label": 0}, {"snippet_id": 7044, "code": " keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords", "label": 0}, {"snippet_id": 75084, "code": " send_keepalive(self): msg=self.p.wz.make_req_msg(b'Router', b'bind-keepalive',[], self.handle_keepalive_reply) msg.insert(0, b'') self.p.wz_sock.send_multipart(msg) def handle_keepalive_reply(self, reqid,", "label": 0}, {"snippet_id": 61336, "code": "(Device): \"\"\"Default qubit device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float)", "label": 0}, {"snippet_id": 38534, "code": "(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall", "label": 0}, {"snippet_id": 59170, "code": "------ .. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device", "label": 0}, {"snippet_id": 6428, "code": " import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text", "label": 1}, {"snippet_id": 85958, "code": "(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod def get_args_default(cls, bootstrap_option_values): return('-encoding", "label": 0}, {"snippet_id": 68394, "code": ".state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append", "label": 0}, {"snippet_id": 38454, "code": ".first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"", "label": 0}, {"snippet_id": 57525, "code": " else: if resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids=map(int, self.request", "label": 0}, {"snippet_id": 43035, "code": " specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item", "label": 0}, {"snippet_id": 71469, "code": " import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose", "label": 0}, {"snippet_id": 36878, "code": "=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected", "label": 0}, {"snippet_id": 57465, "code": "('target_field') self.new_value=request.POST.get('new_value') def get_update_action(self): return getattr(self, '_update_%s' % self.target_field, None) def update(self): has_perms=check_permission(self", "label": 0}, {"snippet_id": 23415, "code": " sshd restart', chk_err=False) def useradd(self, username, expiration=None): \"\"\" Create user account with 'username' \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User", "label": 1}, {"snippet_id": 46409, "code": "): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None", "label": 0}, {"snippet_id": 24217, "code": "'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, ", "label": 0}, {"snippet_id": 78178, "code": " beon import exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type", "label": 0}, {"snippet_id": 73628, "code": ".vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length, chunk_width=chunk_width) print(\"[VCF-Zarr] Done.\"", "label": 1}, {"snippet_id": 33612, "code": ")) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 5114, "code": " tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw])", "label": 0}, {"snippet_id": 41395, "code": " import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type", "label": 0}, {"snippet_id": 76170, "code": ") that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers", "label": 0}, {"snippet_id": 62742, "code": " SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose", "label": 0}, {"snippet_id": 39637, "code": ": def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate", "label": 0}, {"snippet_id": 61853, "code": " openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends", "label": 0}, {"snippet_id": 62098, "code": " user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve", "label": 0}, {"snippet_id": 17218, "code": "(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ", "label": 0}, {"snippet_id": 46982, "code": "._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8", "label": 0}, {"snippet_id": 53179, "code": "=2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self", "label": 0}, {"snippet_id": 15071, "code": "): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None", "label": 0}, {"snippet_id": 32478, "code": " rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile", "label": 0}, {"snippet_id": 66541, "code": " nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException", "label": 0}, {"snippet_id": 44954, "code": "(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring", "label": 0}, {"snippet_id": 49681, "code": "}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the -", "label": 0}, {"snippet_id": 7562, "code": " of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output ", "label": 0}, {"snippet_id": 27475, "code": " @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def", "label": 0}, {"snippet_id": 3359, "code": ": self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit", "label": 0}, {"snippet_id": 85397, "code": "\"\"\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main' ZINC_EXTRACT_MAIN='org.pantsbuild.zinc.extractor.Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor", "label": 0}, {"snippet_id": 80700, "code": ".now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[", "label": 0}, {"snippet_id": 27925, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30:", "label": 0}, {"snippet_id": 62813, "code": " constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list", "label": 0}, {"snippet_id": 18406, "code": ".join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR", "label": 0}, {"snippet_id": 1636, "code": " to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '", "label": 0}, {"snippet_id": 40924, "code": ".append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def", "label": 0}, {"snippet_id": 23549, "code": " raise OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format(username, output)) def del_root_password(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed to delete root", "label": 0}, {"snippet_id": 16067, "code": " future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return", "label": 0}, {"snippet_id": 11671, "code": ") exit_code=EXIT_CODE_NOT_WRITTEN except ConfigurationContainsUndefinedVariables: LOG.error(\"Configuration contained undefined variables!\") exit_code=EXIT_CODE_ERROR except SystemExit as e: exit_code=e", "label": 0}, {"snippet_id": 37444, "code": ".temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise", "label": 0}, {"snippet_id": 37355, "code": " output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule", "label": 0}, {"snippet_id": 66329, "code": " layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 57786, "code": ") if plan is None: return say_no('No plan record found.') update_targets=self.get_update_targets() offset=0 step_length=500 queryset_filter=TestCasePlan.objects.filter data={self.target_field: sortkey}", "label": 0}, {"snippet_id": 21917, "code": "=None, ask_vault_pass=None, vault_password_files=None, new_vault_password_file=None, output_file=None, tags=None, skip_tags=None, one_line=None, tree=None, ask_sudo_pass=None, ask_su_pass=None, sudo=None", "label": 0}, {"snippet_id": 1586, "code": ")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name", "label": 0}, {"snippet_id": 43514, "code": ": return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules", "label": 0}, {"snippet_id": 68274, "code": "\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])", "label": 0}, {"snippet_id": 26424, "code": ", SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self", "label": 0}, {"snippet_id": 33241, "code": " items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self", "label": 0}, {"snippet_id": 169, "code": " docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname", "label": 1}, {"snippet_id": 82316, "code": "=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent", "label": 0}, {"snippet_id": 13379, "code": ", auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file.encode()).decode(\"utf-8\") request_json={ \"path\": file, \"message\": \"Fix pep8 errors in{}\".format(file", "label": 0}, {"snippet_id": 72832, "code": " :param path: The path to create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and", "label": 0}, {"snippet_id": 57709, "code": " except Http404: return say_no(\"No plan record found.\") else: if plan is None: return say_no('No plan record found.') confirm_status_name='CONFIRMED' plan.run_case=plan.case.filter(case_status__name=confirm_status_name", "label": 0}, {"snippet_id": 73430, "code": " for path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str", "label": 0}, {"snippet_id": 9218, "code": "]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the", "label": 0}, {"snippet_id": 69275, "code": ".message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e", "label": 1}, {"snippet_id": 86346, "code": " for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin", "label": 0}, {"snippet_id": 53321, "code": ".lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input,", "label": 0}, {"snippet_id": 22546, "code": " the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1", "label": 0}, {"snippet_id": 87550, "code": " compiler_option_sets: if option_set=='fatal_warnings': disabled_args=self.get_options().fatal_warnings_disabled_args zinc_args.extend(disabled_args) if not self._clear_invalid_analysis: zinc_args.append('", "label": 0}, {"snippet_id": 14127, "code": " _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'", "label": 0}, {"snippet_id": 45044, "code": " decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message", "label": 0}, {"snippet_id": 25743, "code": "=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value", "label": 0}, {"snippet_id": 25341, "code": " config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names():", "label": 1}, {"snippet_id": 253, "code": ".PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802", "label": 0}, {"snippet_id": 23332, "code": "\n import azurelinuxagent.common.utils.fileutil as fileutil import azurelinuxagent.common.utils.shellutil as shellutil import azurelinuxagent.common.utils.textutil as textutil import azurelinuxagent.common", "label": 0}, {"snippet_id": 75881, "code": " wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0]) rslist", "label": 0}, {"snippet_id": 47774, "code": ".docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set()", "label": 0}, {"snippet_id": 70088, "code": " > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self", "label": 0}, {"snippet_id": 39053, "code": "*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(", "label": 0}, {"snippet_id": 78328, "code": ") except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self", "label": 1}, {"snippet_id": 12399, "code": "[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8 issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])", "label": 0}, {"snippet_id": 71996, "code": " configured networks.\"\"\" import importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc.coremods import control, permissions @utils.add_cmd", "label": 0}, {"snippet_id": 50306, "code": " rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int", "label": 0}, {"snippet_id": 73997, "code": " chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration", "label": 0}, {"snippet_id": 59467, "code": "\"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map", "label": 1}, {"snippet_id": 47489, "code": " properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items(", "label": 0}, {"snippet_id": 20477, "code": "=True) self._addr=addr return self def __init__(self, sock, ownsock=False): super(DebugSessionConnection, self).__init__() self._sock=sock self._ownsock=ownsock @property def is_client(self): try: return", "label": 0}, {"snippet_id": 34470, "code": " self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for", "label": 0}, {"snippet_id": 37340, "code": "._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" ", "label": 0}, {"snippet_id": 3525, "code": ".config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state", "label": 0}, {"snippet_id": 77596, "code": "(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues[domain] except KeyError: self.log.info('Created userqueue for %s', domain) uq=Queue(", "label": 0}, {"snippet_id": 62896, "code": "'0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend", "label": 0}, {"snippet_id": 80900, "code": "._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using", "label": 0}, {"snippet_id": 27915, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60:", "label": 0}, {"snippet_id": 30295, "code": " if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index", "label": 0}, {"snippet_id": 12575, "code": " repository=data[\"repository\"] headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/issues/", "label": 0}, {"snippet_id": 73398, "code": ":param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config", "label": 0}, {"snippet_id": 4326, "code": "**kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines", "label": 1}, {"snippet_id": 28207, "code": ":weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':", "label": 0}, {"snippet_id": 37714, "code": ".apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None", "label": 0}, {"snippet_id": 41470, "code": " for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input", "label": 0}, {"snippet_id": 27111, "code": "/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY", "label": 1}, {"snippet_id": 70023, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand", "label": 0}, {"snippet_id": 4983, "code": " list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate", "label": 0}, {"snippet_id": 55454, "code": " logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks:", "label": 0}, {"snippet_id": 92579, "code": " file should exist outside of context if cleanup=False.') os.unlink(fp.name) def test_temporary_file_within_other_dir(self): with temporary_dir() as path: with temporary_file(root_dir=path) as f: self.assertTrue", "label": 0}, {"snippet_id": 68195, "code": ".status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs", "label": 1}, {"snippet_id": 2423, "code": " self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open", "label": 0}, {"snippet_id": 41753, "code": ")) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input", "label": 0}, {"snippet_id": 51154, "code": " files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return", "label": 0}, {"snippet_id": 63809, "code": " %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name", "label": 0}, {"snippet_id": 94722, "code": "--config argument\") subparser_val=subparsers.add_parser('validate', help=\"Validate the setup specified by the --config argument\") subparser_remote=subparsers.add_parser('slave', help=\"Run a component locally", "label": 0}, {"snippet_id": 24171, "code": " TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':", "label": 0}, {"snippet_id": 3104, "code": "='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys", "label": 0}, {"snippet_id": 87782, "code": " entries provided to zinc should be absolute. ' '{} is not.'.format(path)) if is_outside(path, self.get_options().pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath", "label": 0}, {"snippet_id": 29929, "code": " in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map", "label": 0}, {"snippet_id": 61856, "code": ".projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the", "label": 0}, {"snippet_id": 5415, "code": "\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords", "label": 0}, {"snippet_id": 16655, "code": "._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler(", "label": 0}, {"snippet_id": 48809, "code": " snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"", "label": 0}, {"snippet_id": 53163, "code": " InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name", "label": 0}, {"snippet_id": 5299, "code": " boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify<", "label": 0}, {"snippet_id": 88442, "code": "(run_tracker) self._target_base=target_base or Target self._products=Products() self._buildroot=get_buildroot() self._source_roots=SourceRootConfig.global_instance().get_source_roots() self._lock=OwnerPrintingInterProcessFileLock", "label": 0}, {"snippet_id": 91539, "code": ".engine.rules import UnionRule, optionable_rule, rule from pants.engine.selectors import Get from pants.rules.core.core_test_model import Status, TestResult, TestTarget from pants.source.source_root import", "label": 0}, {"snippet_id": 77945, "code": " id_) logger.info('Removing %s from targets[%s]', repr(t), domain) tlist.remove(t) def add_target_exc(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str", "label": 0}, {"snippet_id": 93497, "code": "(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, ", "label": 0}, {"snippet_id": 66139, "code": "(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=", "label": 0}, {"snippet_id": 44706, "code": " self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code)", "label": 0}, {"snippet_id": 44367, "code": "=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected", "label": 0}, {"snippet_id": 94893, "code": " import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a", "label": 1}, {"snippet_id": 58154, "code": " r in results] return results def get_prod_related_obj_json(request): \"\"\" View for updating product drop-down\\n in a Ajax way. \"\"\" data=request.GET.copy() target=data.get('target', None) p_pks=data.get", "label": 0}, {"snippet_id": 57757, "code": "'review_case_count': review_case_count, }) def _update_sortkey(self): try: sortkey=int(self.new_value) if sortkey < 0 or sortkey > 32300: return say_no('New sortkey is out of range[0, 32300].') except ValueError", "label": 0}, {"snippet_id": 73521, "code": " by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr]", "label": 0}, {"snippet_id": 30460, "code": " file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance", "label": 0}, {"snippet_id": 52275, "code": "(self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources", "label": 0}, {"snippet_id": 78892, "code": "+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t", "label": 0}, {"snippet_id": 41643, "code": "}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError", "label": 0}, {"snippet_id": 18283, "code": " server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file)", "label": 1}, {"snippet_id": 64093, "code": " string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration(self, client, job_wrapper, remote_metadata, remote_job_config): metadata_kwds", "label": 0}, {"snippet_id": 34335, "code": " return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator", "label": 0}, {"snippet_id": 23030, "code": ": if dvd is not None: return \"/dev/{0}\".format(dvd.group(0)) raise OSUtilError(\"Failed to get dvd device\") def mount_dvd(self, **kwargs): \"\"\"Mount the DVD containing the provisioningiso.iso file This is", "label": 0}, {"snippet_id": 51970, "code": "(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len", "label": 0}, {"snippet_id": 36381, "code": " f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self", "label": 0}, {"snippet_id": 35107, "code": "(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict", "label": 0}, {"snippet_id": 72052, "code": ".networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1: network name(case sensitive)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return", "label": 0}, {"snippet_id": 41449, "code": "(self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources", "label": 0}, {"snippet_id": 10935, "code": "(uri_parsed): return read_config_from_host(uri) else: raise ValueError('Given url was not acceptable %s' % uri) def read_config_from_file(path): yaml_config=merge_yaml_files(path) etag=None mtime=os.path", "label": 0}, {"snippet_id": 24149, "code": " Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta", "label": 1}, {"snippet_id": 89444, "code": " forward. :API: public TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class", "label": 0}, {"snippet_id": 83616, "code": ".job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model", "label": 0}, {"snippet_id": 93043, "code": " with mock.patch('signal.signal', **PATCH_OPTS) as mock_signal: mock_signal.return_value=mock_initial_handler try: with signal_handler_as(signal.SIGUSR2, mock_new_handler): raise NotImplementedError('blah", "label": 0}, {"snippet_id": 37371, "code": " SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item", "label": 0}, {"snippet_id": 44657, "code": "(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile", "label": 0}, {"snippet_id": 64487, "code": " next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command", "label": 0}, {"snippet_id": 68888, "code": "\n \"\"\" Shine `umount' command classes. The umount command aims to stop Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals", "label": 0}, {"snippet_id": 51234, "code": "(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name ", "label": 0}, {"snippet_id": 80647, "code": ",args.trueRegex,s,args.size,postData,args.uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not args.skipRecon: ", "label": 0}, {"snippet_id": 45906, "code": "\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing", "label": 0}, {"snippet_id": 14419, "code": " server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR", "label": 0}, {"snippet_id": 17279, "code": "() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file", "label": 1}, {"snippet_id": 91613, "code": "=yield Get(Snapshot, UrlToFetch(url, digest)) transitive_hydrated_targets=yield Get( TransitiveHydratedTargets, BuildFileAddresses((test_target.address,)) ) all_targets=[t.adaptor for t in transitive_hydrated_targets", "label": 0}, {"snippet_id": 66921, "code": " CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.", "label": 0}, {"snippet_id": 81776, "code": "\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote", "label": 0}, {"snippet_id": 20593, "code": "(cls, addr=None, **kwargs): if addr is None: addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_server(addr, **kwargs) return cls(conn, owned=True, **kwargs) def __init__(self, conn, seq=1000", "label": 0}, {"snippet_id": 57919, "code": "(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun found.') add_comment(runs, comment, request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n ", "label": 0}, {"snippet_id": 91756, "code": " inits_digest=yield Get(InjectedInitDigest, Digest, sources_digest) all_input_digests=[ sources_digest, inits_digest.directory_digest, requirements_pex_response.output_directory_digest, ] merged_input_files=yield", "label": 0}, {"snippet_id": 65506, "code": " Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self", "label": 0}, {"snippet_id": 28811, "code": " elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" ", "label": 0}, {"snippet_id": 94115, "code": "(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check", "label": 0}, {"snippet_id": 62337, "code": ": \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and", "label": 0}, {"snippet_id": 39665, "code": " def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources", "label": 0}, {"snippet_id": 2076, "code": ":configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 6676, "code": " taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode:", "label": 0}, {"snippet_id": 5835, "code": "(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir", "label": 0}, {"snippet_id": 60470, "code": " Gaussian) from strawberryfields.ops import(GaussianTransform, Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate", "label": 0}, {"snippet_id": 24437, "code": ".type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\", "label": 0}, {"snippet_id": 25906, "code": " >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 78181, "code": " class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)", "label": 0}, {"snippet_id": 95632, "code": ".copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir. Additionally moves", "label": 0}, {"snippet_id": 52143, "code": " or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"", "label": 0}, {"snippet_id": 88281, "code": ".workspace import ScmWorkspace from pants.process.lock import OwnerPrintingInterProcessFileLock from pants.reporting.report import Report from pants.source.source_root import SourceRootConfig class Context", "label": 0}, {"snippet_id": 6621, "code": " get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache", "label": 0}, {"snippet_id": 12556, "code": " comment_footer=''.join(comment_footer) return comment_header, comment_body, comment_footer, ERROR def comment_permission_check(data, comment): \"\"\"Check for quite and resume status or duplicate comments", "label": 0}, {"snippet_id": 3099, "code": " hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not", "label": 0}, {"snippet_id": 13840, "code": ", key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals, self.locals) if __name__=='__main__': for k, v in _safe_locals", "label": 0}, {"snippet_id": 3202, "code": "=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node", "label": 0}, {"snippet_id": 14339, "code": ".path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std", "label": 0}, {"snippet_id": 91095, "code": " os_name=normalize_os_name(os.uname()[0].lower()) if os_name not in self._normalized_jdk_paths: logger.warning('--jvm-distributions-paths was specified, but has no entry for \"{}\".' .format(os_name)) return", "label": 0}, {"snippet_id": 81523, "code": " detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t\t\t\tself.logger.debug(\"Requesting %s...\",url) \t\t \t\tr=self.session.get(url) \t\tif self.shouldLog: \t\t\tif r.status_code", "label": 0}, {"snippet_id": 65652, "code": " elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks", "label": 1}, {"snippet_id": 65282, "code": "=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type)", "label": 0}, {"snippet_id": 55511, "code": ".path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile", "label": 0}, {"snippet_id": 63336, "code": ".__prepare_input_files_locally(job_wrapper) remote_metadata=LwrJobRunner.__remote_metadata( client) remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution", "label": 0}, {"snippet_id": 68476, "code": "%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients:", "label": 0}, {"snippet_id": 37486, "code": ".add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append", "label": 0}, {"snippet_id": 22067, "code": "=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self, playbook, options=None, verbosity=0): if options is None: self.options=Options() self.options.verbosity", "label": 0}, {"snippet_id": 48354, "code": " inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 73544, "code": " provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length", "label": 0}, {"snippet_id": 43966, "code": " local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None,", "label": 0}, {"snippet_id": 15303, "code": "._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port)", "label": 1}, {"snippet_id": 90330, "code": "(plist) for distribution in plist_results: home=distribution['JVMHomePath'] yield self.Location.from_home(home) except subprocess.CalledProcessError: pass class _LinuxEnvironment(_DistributionEnvironment", "label": 0}, {"snippet_id": 84352, "code": ".extra_filenames.append(integrates_datatypes_config) metadata_kwds['datatypes_config']=os.path.join(configs_directory, os.path.basename(integrates_datatypes_config)) return metadata_kwds class LwrComputeEnvironment", "label": 0}, {"snippet_id": 52456, "code": " AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property", "label": 0}, {"snippet_id": 44579, "code": "+provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info(", "label": 0}, {"snippet_id": 73098, "code": "\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory,", "label": 0}, {"snippet_id": 73706, "code": " ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): \"\"\" Initializes the", "label": 0}, {"snippet_id": 80920, "code": ".parse import urljoin,urlparse from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t", "label": 0}, {"snippet_id": 72806, "code": " allel import sys import functools import numpy as np import zarr import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree", "label": 1}, {"snippet_id": 60927, "code": "\"Get the predefined circuit templates. .. todo:: rename to circuits? Returns: dict[str->Circuit]: circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns", "label": 0}, {"snippet_id": 44522, "code": " immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats,", "label": 0}, {"snippet_id": 86763, "code": ", strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format", "label": 0}, {"snippet_id": 34138, "code": ".message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd", "label": 0}, {"snippet_id": 34997, "code": "(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a", "label": 0}, {"snippet_id": 42123, "code": " return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and(", "label": 0}, {"snippet_id": 67254, "code": " print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message", "label": 1}, {"snippet_id": 26679, "code": " self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 46336, "code": " name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\"", "label": 0}, {"snippet_id": 23577, "code": " def get_if_mac(self, ifname): data=self._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper() return None def get_first_if(self): return self._get_net_info()[:2] def route_add(self", "label": 0}, {"snippet_id": 6836, "code": ":var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return", "label": 0}, {"snippet_id": 22783, "code": " level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param username: The username whose password to change ", "label": 0}, {"snippet_id": 78577, "code": "(self.comment_loop) return if len(self.forums)==0: with cstate(self, WipeState.waiting_for_targets): while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def", "label": 0}, {"snippet_id": 55938, "code": " return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 56616, "code": "'pk') test_plan_tags=TestPlanTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_plans=Count('tag')).order_by('tag') test_case_tags=TestCaseTag.objects.filter( tag__in=all_tags).values('tag", "label": 0}, {"snippet_id": 94249, "code": " self.session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s", "label": 0}, {"snippet_id": 23045, "code": "*kwargs): \"\"\"Mount the DVD containing the provisioningiso.iso file This is the _first_ hook that WAAgent provides for us, so this is the point where we should wait for mcpd to load. I am just overloading", "label": 0}, {"snippet_id": 45450, "code": " def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os", "label": 1}, {"snippet_id": 63826, "code": " TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id)) client=self.get_client", "label": 0}, {"snippet_id": 42703, "code": " @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output", "label": 0}, {"snippet_id": 91279, "code": " pants.backend.python.tasks.python_repl import PythonRepl from pants.backend.python.tasks.python_run import PythonRun from pants.backend.python.tasks.resolve_requirements import ResolveRequirements from", "label": 0}, {"snippet_id": 79724, "code": "\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds", "label": 0}, {"snippet_id": 5251, "code": " element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output", "label": 0}, {"snippet_id": 84361, "code": " os.path.basename(integrates_datatypes_config)) return metadata_kwds class LwrComputeEnvironment( ComputeEnvironment): def __init__( self, lwr_client, job_wrapper, remote_job_config): self.lwr_client=lwr_client", "label": 0}, {"snippet_id": 5534, "code": "(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*',", "label": 0}, {"snippet_id": 706, "code": "(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU", "label": 0}, {"snippet_id": 21858, "code": " metrics=['accuracy']) classifier.fit(X_train, y_train, batch_size=10, epochs=100) y_pred=classifier.predict(X_test) y_pred=(y_pred > 0.5) from sklearn.metrics import confusion_matrix cm=confusion_matrix", "label": 1}, {"snippet_id": 91143, "code": ".python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements from pants.backend.python.rules", "label": 0}, {"snippet_id": 84383, "code": "{} self._wrapper_input_paths=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config", "label": 0}, {"snippet_id": 12898, "code": ".communicate() data[\"diff\"][filename]=stdout.decode(r.encoding) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\", "label": 0}, {"snippet_id": 26932, "code": " data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 21069, "code": " handlername): event=threading.Event() def handler(msg): if not match(msg): return msg, False event.set() return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object", "label": 0}, {"snippet_id": 55131, "code": " subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake", "label": 0}, {"snippet_id": 8222, "code": " a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen", "label": 1}, {"snippet_id": 82813, "code": ": \t\tn=up.detectValidExtensions(extensions,args.n,args.legitExtensions) \telse: \t\tn=up.detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions", "label": 0}, {"snippet_id": 3490, "code": ".window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running", "label": 0}, {"snippet_id": 33155, "code": " printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None", "label": 0}, {"snippet_id": 65777, "code": "\"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER)", "label": 0}, {"snippet_id": 71220, "code": " dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\"", "label": 0}, {"snippet_id": 34736, "code": ".join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( ", "label": 1}, {"snippet_id": 39128, "code": "=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores", "label": 0}, {"snippet_id": 38828, "code": " permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the", "label": 0}, {"snippet_id": 72505, "code": "'Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path", "label": 0}, {"snippet_id": 92194, "code": ".py` scripts.') @property def base_requirements(self): return[ PythonRequirement('setuptools=={}'.format(self.get_options().setuptools_version)), PythonRequirement('wheel=={}'.format(self.get_options()", "label": 0}, {"snippet_id": 32970, "code": ".output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename", "label": 0}, {"snippet_id": 31664, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True):", "label": 0}, {"snippet_id": 93106, "code": ") with self.assertRaises(AssertionError): with exception_logging(fake_logger, 'error!'): assert True is False fake_logger.exception.assert_called_once_with('error!') def test_maybe_profiled(self): with", "label": 0}, {"snippet_id": 16501, "code": " SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def", "label": 0}, {"snippet_id": 90075, "code": "]=val self._system_properties=props return self._system_properties def _validate_executable(self, name): def bin_paths(): yield self._bin_path if self._is_jdk: yield os.path.join(self.home, 'jre', 'bin", "label": 0}, {"snippet_id": 92972, "code": ".strip()) def test_stdio_as(self): self.assertTrue(sys.stderr.fileno() > 2, \"Expected a pseudofile as stderr, got:{}\".format(sys.stderr)) old_stdout, old_stderr, old_stdin=sys.stdout, sys.stderr, sys.stdin", "label": 0}, {"snippet_id": 15354, "code": "._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[", "label": 0}, {"snippet_id": 44610, "code": "\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats(", "label": 0}, {"snippet_id": 64796, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None,", "label": 0}, {"snippet_id": 69035, "code": " return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR:", "label": 0}, {"snippet_id": 73645, "code": " numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', ", "label": 0}, {"snippet_id": 12197, "code": "\"after_commit_hash\"] author=data[\"author\"] py_files=get_python_files_involved_in_pr(data) for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format(repository,", "label": 0}, {"snippet_id": 42641, "code": " Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile", "label": 0}, {"snippet_id": 77861, "code": " continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except WorkerInterrupt: pass except Exception as e: self.log.exception(e) self", "label": 0}, {"snippet_id": 87144, "code": "): compile_contexts=[self.select_runtime_context(compile_contexts[t]) for t in targets] zinc_analysis=self.context.products.get_data('zinc_analysis') zinc_args=self.context.products.get_data('zinc_args", "label": 0}, {"snippet_id": 78953, "code": " test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) ", "label": 0}, {"snippet_id": 35932, "code": "},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if", "label": 0}, {"snippet_id": 38483, "code": " not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets:", "label": 0}, {"snippet_id": 62873, "code": "-expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for", "label": 0}, {"snippet_id": 46743, "code": ": \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat", "label": 0}, {"snippet_id": 43061, "code": " _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try", "label": 0}, {"snippet_id": 48853, "code": " bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict()", "label": 0}, {"snippet_id": 37951, "code": "=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True", "label": 0}, {"snippet_id": 17779, "code": " in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData(", "label": 0}, {"snippet_id": 24583, "code": " self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'", "label": 0}, {"snippet_id": 37533, "code": " start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have", "label": 0}, {"snippet_id": 80035, "code": " parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser.add_argument(\"-T\",", "label": 0}, {"snippet_id": 88110, "code": " classpath_element is a scalac plugin, returns its name. Returns None otherwise. \"\"\" def process_info_file(cp_elem, info_file): plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag !='plugin", "label": 0}, {"snippet_id": 74805, "code": " for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str=runtime_config", "label": 0}, {"snippet_id": 24982, "code": "'rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self", "label": 0}, {"snippet_id": 52408, "code": ".output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size", "label": 0}, {"snippet_id": 24088, "code": "}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*(//'| sed", "label": 0}, {"snippet_id": 71940, "code": ".append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack", "label": 0}, {"snippet_id": 11818, "code": ".Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key,{}), value) else: base[key]=head[key] else: base={key: head[key]} return base def match_webhook_secret(request):", "label": 1}, {"snippet_id": 19343, "code": ".NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_url(httpbin): native={ 'origin': '127.0.0.1', 'args", "label": 0}, {"snippet_id": 64374, "code": " Base.Command import Command from Shine.Commands import commandList from Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self", "label": 0}, {"snippet_id": 12322, "code": " file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request", "label": 0}, {"snippet_id": 83422, "code": ".exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state", "label": 0}, {"snippet_id": 65520, "code": "-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target", "label": 0}, {"snippet_id": 8360, "code": " lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re", "label": 0}, {"snippet_id": 68125, "code": ".nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view", "label": 0}, {"snippet_id": 55013, "code": " or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes", "label": 0}, {"snippet_id": 21222, "code": " import re import sys import argparse as ap flatten=lambda l:[item for sublist in l for item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())", "label": 0}, {"snippet_id": 73953, "code": ".enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr[\"alt_number\"] if str(alt_number_str).lower()==\"auto", "label": 0}, {"snippet_id": 49990, "code": " resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources:", "label": 0}, {"snippet_id": 34652, "code": " WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self", "label": 1}, {"snippet_id": 38823, "code": " Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process", "label": 0}, {"snippet_id": 88358, "code": " reporting framework.\"\"\" def __init__(self, run_tracker): self._run_tracker=run_tracker def debug(self, *msg_elements): self._run_tracker.log(Report.DEBUG, *msg_elements) def info(self, *msg_elements): self", "label": 0}, {"snippet_id": 5585, "code": ",...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort", "label": 0}, {"snippet_id": 56467, "code": "]).property.all() return EnvProperty.objects.all() def env_values(self): return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id')) def users(self): query=strip_parameters(self", "label": 0}, {"snippet_id": 81672, "code": "\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode=self", "label": 0}, {"snippet_id": 75761, "code": "'Termination signal %s recieved', repr((interface, method, data))) self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method,", "label": 1}, {"snippet_id": 5857, "code": " os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory):", "label": 0}, {"snippet_id": 57510, "code": " ObjectDoesNotExist as err: return say_no(str(err)) except Exception: return say_no('Update failed. Please try again or request ' 'support from your organization.') else: if resp is None: resp=say_yes() return", "label": 0}, {"snippet_id": 31520, "code": "-the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params", "label": 0}, {"snippet_id": 59270, "code": " backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0", "label": 0}, {"snippet_id": 89992, "code": " _parse_java_version('java.version', self._get_system_properties(java)['java.version']) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open", "label": 0}, {"snippet_id": 33694, "code": ", jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats", "label": 0}, {"snippet_id": 67264, "code": ": FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s", "label": 0}, {"snippet_id": 21456, "code": ", f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) else: print(\"Reddytt: Working directory found. Loading variables.\") with open(seen_file, 'rb') as", "label": 0}, {"snippet_id": 85678, "code": " PathGlobsAndRoot( PathGlobs( tuple( fast_relpath(a, buildroot) for a in(self.zinc, self.compiler_bridge, self.compiler_interface) ) ), buildroot, ), ))[0] @memoized_property def rebase_map_args(self): \"\"\"We rebase", "label": 1}, {"snippet_id": 60629, "code": "\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation", "label": 0}, {"snippet_id": 61115, "code": "(theta): r\"\"\"One-qubit rotation about the y axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm(-1j * theta/2 * Y) def frz", "label": 0}, {"snippet_id": 4292, "code": "(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file", "label": 1}, {"snippet_id": 81785, "code": "] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of", "label": 0}, {"snippet_id": 77414, "code": " self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: if type_==0", "label": 0}, {"snippet_id": 27748, "code": " elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle", "label": 0}, {"snippet_id": 75666, "code": "**pkvargs) self.name=name if name else type(self).__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self", "label": 0}, {"snippet_id": 84043, "code": " in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model", "label": 0}, {"snippet_id": 19401, "code": "-DEBUG_RECORD_SOCKET_READS', '--cmd-line', '--module', '--multiproc', '--multiprocess', '--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}", "label": 0}, {"snippet_id": 36928, "code": ", snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input", "label": 0}, {"snippet_id": 90022, "code": "')) cmd=[java, '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self", "label": 0}, {"snippet_id": 61555, "code": " or openqml.Expectation): operation/observable. Returns: array: matrix representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)", "label": 0}, {"snippet_id": 20774, "code": "}'.format(event) with self._wait_for_message(match, handlername, **kwargs): yield result def get_awaiter_for_event(self, event, condition=lambda msg: True, **kwargs): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 6627, "code": " with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name, output_mode", "label": 0}, {"snippet_id": 13658, "code": ".wav\")\r return myText\r \r mouthThread=Thread(target=updateMouth)\r mouthThread.start()\r eyesThread=Thread(target=updateEyes)\r eyesThread.start() \r audio=AudioPlayer()\r \r if( consumerKey.find( 'TWITTER') ", "label": 0}, {"snippet_id": 79630, "code": "\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote", "label": 0}, {"snippet_id": 75340, "code": " def _parse_sig(self, iden, msg, interface, method): try: handler=self.sig_handlers[(interface, method)] except KeyError: raise WZENoHandler(iden, 'No handler for sig %s,%s'%(interface, method)) handler", "label": 0}, {"snippet_id": 12980, "code": "\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth", "label": 0}, {"snippet_id": 71836, "code": "(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except KeyError: print \"Error ", "label": 1}, {"snippet_id": 31421, "code": "{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run", "label": 0}, {"snippet_id": 4000, "code": "=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug", "label": 0}, {"snippet_id": 21606, "code": " train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=0) from sklearn.preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train)", "label": 0}, {"snippet_id": 16333, "code": ".path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std", "label": 0}, {"snippet_id": 64118, "code": " Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory=remote_job_config['outputs_directory'] configs_directory=remote_job_config['configs_directory", "label": 0}, {"snippet_id": 12025, "code": ".append(\"--{}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments.append(\"--{}={}\".format(key, ','.join(value))) config[\"pycodestyle_cmd_config\"]=", "label": 0}, {"snippet_id": 49803, "code": "\"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input)", "label": 0}, {"snippet_id": 37276, "code": " for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self", "label": 0}, {"snippet_id": 50357, "code": " to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule", "label": 0}, {"snippet_id": 51647, "code": ")) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values", "label": 0}, {"snippet_id": 90084, "code": ": def bin_paths(): yield self._bin_path if self._is_jdk: yield os.path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe", "label": 0}, {"snippet_id": 14194, "code": ".event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError:", "label": 0}, {"snippet_id": 93274, "code": ".has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self", "label": 0}, {"snippet_id": 22439, "code": "\"WARNING: Cannot save sys config on 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err=False) def stop_agent_service(self): return shellutil", "label": 0}, {"snippet_id": 94469, "code": ".STOPPED elif check_available and run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient", "label": 0}, {"snippet_id": 14688, "code": " vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info", "label": 0}, {"snippet_id": 92157, "code": " @classmethod def register_options(cls, register): super(BuildSetupRequiresPex, cls).register_options(register) register('--setuptools-version', advanced=True, fingerprint=True, default='40.6.3', help='The", "label": 0}, {"snippet_id": 91686, "code": "=ExecuteProcessRequest( argv=tuple(requirements_pex_argv), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=pex_snapshot.directory_digest, description='Resolve requirements:{}", "label": 1}, {"snippet_id": 84690, "code": "=ClocBinary.global_instance().hackily_snapshot(self.context) directory_digest=self.context._scheduler.merge_directories(tuple(s.directory_digest for s in input_snapshots +( cloc_snapshot, list_file_snapshot", "label": 0}, {"snippet_id": 14049, "code": "'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if", "label": 0}, {"snippet_id": 39401, "code": " workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self", "label": 0}, {"snippet_id": 29282, "code": "(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file):", "label": 0}, {"snippet_id": 51624, "code": "(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}", "label": 0}, {"snippet_id": 21999, "code": "=vault_password_files self.new_vault_password_file=new_vault_password_file self.output_file=output_file self.tags=tags self.skip_tags=skip_tags self.one_line=one_line self.tree=tree self.ask_sudo_pass=ask_sudo_pass", "label": 0}, {"snippet_id": 86276, "code": ")) as batched_sources: javac_cmd.extend(batched_sources) if self.execution_strategy==self.HERMETIC: self._execute_hermetic_compile(javac_cmd, ctx) else: with self.context.new_workunit(name='javac', cmd", "label": 0}, {"snippet_id": 57506, "code": " self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception: return say_no('Update failed. Please try again or request ' 'support from your organization.') else: if resp", "label": 0}, {"snippet_id": 15395, "code": ": returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash", "label": 0}, {"snippet_id": 32848, "code": "=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. ", "label": 0}, {"snippet_id": 71371, "code": ".RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT,", "label": 0}, {"snippet_id": 12244, "code": "=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"extra_results\"][filename]=stdout.decode(r.encoding).splitlines() data[\"results\"][filename]=[] for error in list", "label": 0}, {"snippet_id": 6075, "code": " file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\")", "label": 0}, {"snippet_id": 7369, "code": "]))) for field, keywords in((auth_field, output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field", "label": 0}, {"snippet_id": 69493, "code": ".cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance", "label": 0}, {"snippet_id": 51253, "code": " multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard))", "label": 0}, {"snippet_id": 64782, "code": ", OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute", "label": 0}, {"snippet_id": 27782, "code": "] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0", "label": 0}, {"snippet_id": 19471, "code": "] supported, pydevd, script=_group_args(argv) args=_parse_args(prog, supported) extra=pydevd +['--'] if script: extra +=script return args, extra def _group_args(argv): supported=[] pydevd=[] script=[]", "label": 0}, {"snippet_id": 19716, "code": ": if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')) else: args.address=Address.as_client(clienthost, ns.pop('port", "label": 0}, {"snippet_id": 67626, "code": " target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" %", "label": 0}, {"snippet_id": 11859, "code": "=header_signature.split('=') if sha_name !='sha1': abort(501) mac=hmac.new(os.environ[\"GITHUB_PAYLOAD_SECRET\"].encode(), msg=request.data, digestmod=\"sha1\") if not hmac.compare_digest(str(mac.hexdigest(", "label": 0}, {"snippet_id": 93706, "code": " comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component(node", "label": 0}, {"snippet_id": 79226, "code": "\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload", "label": 0}, {"snippet_id": 39205, "code": " be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks", "label": 0}, {"snippet_id": 57850, "code": " reviewers[0]}) @require_POST def update_cases_default_tester(request): \"\"\"Update default tester upon selected TestCases\"\"\" proxy=TestCaseUpdateActions(request) return proxy.update() update_cases_priority", "label": 0}, {"snippet_id": 20932, "code": "=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still running') self._check_handlers() def _listen(self): try: for msg in self._conn.iter_messages(): if self.VERBOSE: print(' -", "label": 0}, {"snippet_id": 52471, "code": ", rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise", "label": 0}, {"snippet_id": 69690, "code": " install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs", "label": 0}, {"snippet_id": 5665, "code": ".items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a", "label": 0}, {"snippet_id": 56110, "code": "(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs", "label": 0}, {"snippet_id": 67992, "code": "=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed", "label": 0}, {"snippet_id": 16221, "code": "(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ", "label": 0}, {"snippet_id": 22614, "code": " on setting it here too. :param hostname: The hostname to set on the device \"\"\" return None def set_dhcp_hostname(self, hostname): \"\"\"Sets the DHCP hostname See `set_hostname` for an explanation of why", "label": 0}, {"snippet_id": 27577, "code": " self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'", "label": 0}, {"snippet_id": 10931, "code": " return read_config_from_file(uri_parsed.path) elif is_host(uri_parsed): return read_config_from_host(uri) else: raise ValueError('Given url was not acceptable %s' % uri) def read_config_from_file(path", "label": 0}, {"snippet_id": 22992, "code": " device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists on all platforms that are supported on Azure(Stack) :param dev_dir: The root directory from which to", "label": 0}, {"snippet_id": 22420, "code": " raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys config\" rc=shellutil.run(cmd) if rc !=0: logger.error(\"WARNING: Cannot", "label": 0}, {"snippet_id": 39161, "code": ".resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources", "label": 0}, {"snippet_id": 88459, "code": "(os.path.join(self._buildroot, '.pants.workdir.file_lock')) self._java_sysprops=None self.requested_goals=requested_goals or[] self._console_outstream=console_outstream or sys.stdout self._scm=scm or get_scm", "label": 0}, {"snippet_id": 94840, "code": "() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui", "label": 0}, {"snippet_id": 57125, "code": " fields are required -content_type, ' 'object_pk, field and value.') field=str(field) value, error=get_value_by_type(value, vtype) if error: return say_no(error) has_perms=check_permission(request, ctype)", "label": 0}, {"snippet_id": 51256, "code": " name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f", "label": 0}, {"snippet_id": 63243, "code": ") log.info(\"lwr job submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( ", "label": 0}, {"snippet_id": 68998, "code": ", rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount", "label": 0}, {"snippet_id": 29205, "code": " def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property", "label": 1}, {"snippet_id": 65343, "code": " The status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global", "label": 0}, {"snippet_id": 38474, "code": "\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules", "label": 0}, {"snippet_id": 90324, "code": "', '--xml']) plist_results=plistlib.loads(plist) if PY3 else plistlib.readPlistFromString(plist) for distribution in plist_results: home=distribution['JVMHomePath'] yield self.Location.from_home(home) except", "label": 0}, {"snippet_id": 87659, "code": " snapshots.append( self.context._scheduler.capture_snapshots((PathGlobsAndRoot( PathGlobs(scala_path), get_buildroot(), ),))[0] ) merged_input_digest=self.context._scheduler.merge_directories( tuple(s.directory_digest", "label": 0}, {"snippet_id": 94774, "code": "=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch to kill mode\", action=\"store_true\") remote_mutex.add_argument('-c', '--check', help", "label": 0}, {"snippet_id": 5045, "code": " kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' ", "label": 0}, {"snippet_id": 73995, "code": ".vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for", "label": 0}, {"snippet_id": 12929, "code": ".format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON[\"public\"]=True REQUEST_JSON[\"files", "label": 0}, {"snippet_id": 25998, "code": " self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type==", "label": 0}, {"snippet_id": 4535, "code": " else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags", "label": 0}, {"snippet_id": 92638, "code": ".path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False) as path: self.assertTrue(os.path.exists(path", "label": 0}, {"snippet_id": 37811, "code": " name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards", "label": 0}, {"snippet_id": 68961, "code": "%s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else", "label": 1}, {"snippet_id": 37068, "code": "=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd", "label": 0}, {"snippet_id": 1072, "code": " wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers", "label": 0}, {"snippet_id": 76120, "code": " t): self.log.debug('Setting %s,%s type to %d', i, m, t) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Succesfully set route type for(%s, %s) to %s', i", "label": 0}, {"snippet_id": 51050, "code": "=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self", "label": 1}, {"snippet_id": 33048, "code": "\"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self", "label": 0}, {"snippet_id": 43868, "code": " self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule", "label": 0}, {"snippet_id": 46165, "code": "): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format", "label": 0}, {"snippet_id": 74536, "code": "\"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in", "label": 0}, {"snippet_id": 85230, "code": " will be added automatically.'.format(name, self.version)) return '{0}_{1}'.format(name, self.version) @property def repl(self): \"\"\"Return the repl tool key.\"\"\" return self._key_for_tool_version('scala", "label": 1}, {"snippet_id": 13308, "code": " file_to_fix.py{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"results\"][filename]=stdout.decode(r", "label": 0}, {"snippet_id": 1126, "code": " configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False", "label": 0}, {"snippet_id": 45581, "code": "==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise", "label": 0}, {"snippet_id": 60216, "code": " Ket, 'SqueezedState': Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement':", "label": 0}, {"snippet_id": 46365, "code": "=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self)", "label": 0}, {"snippet_id": 87404, "code": ".scalac_classpath() compiler_interface=self._zinc.compiler_interface compiler_bridge=self._zinc.compiler_bridge classes_dir=ctx.classes_dir analysis_cache=ctx.analysis_file scala_path=tuple(relative_to_exec_root(c)", "label": 1}, {"snippet_id": 84648, "code": ".context._scheduler) for target in targets ) input_files={f.path for snapshot in input_snapshots for f in snapshot.files} with temporary_dir() as tmpdir: list_file=os.path.join(tmpdir, 'input_files_list')", "label": 0}, {"snippet_id": 95227, "code": " benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import logging import os.path", "label": 0}, {"snippet_id": 11310, "code": " monitoring_config_generator.yaml_tools.config import YamlConfig from monitoring_config_generator.settings import CONFIG EXIT_CODE_CONFIG_WRITTEN=0 EXIT_CODE_ERROR=1 EXIT_CODE_NOT_WRITTEN=2 LOG=logging", "label": 0}, {"snippet_id": 72003, "code": " import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc.coremods import control, permissions @utils.add_cmd def disconnect(irc, source, args): \"\"\"<network", "label": 0}, {"snippet_id": 58390, "code": "=self.client.get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-recent', args=[self.tester.username]), target_status_code=HTTPStatus.OK) class TestCommentCaseRuns(BaseCaseRun)", "label": 0}, {"snippet_id": 78804, "code": "\t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself", "label": 0}, {"snippet_id": 88028, "code": "} if not plugin_names: return{} active_plugins={} buildroot=get_buildroot() cp_product=self.context.products.get_data('runtime_classpath') for classpath_element in classpath: name=self._maybe_get_plugin_name", "label": 0}, {"snippet_id": 13346, "code": ".environ[\"BOT_PASSWORD\"]) fullname=data.get(\"fork_fullname\") for file, new_file in data[\"results\"].items(): url=\"https://api.github.com/repos/{}/contents/{}\" url=url.format(fullname, file) params={\"ref\": data", "label": 0}, {"snippet_id": 74648, "code": " if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr", "label": 0}, {"snippet_id": 69136, "code": " from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import ", "label": 0}, {"snippet_id": 16196, "code": ".server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal", "label": 0}, {"snippet_id": 12071, "code": "\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} diff_headers=headers.copy() diff_headers[\"Accept\"]=\"application/vnd.github.VERSION.diff\" auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD", "label": 0}, {"snippet_id": 92631, "code": "(path), 'Temporary dir should be a dir and not a file.') self.assertFalse(os.path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with", "label": 0}, {"snippet_id": 9323, "code": " composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted", "label": 0}, {"snippet_id": 86338, "code": " @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces '", "label": 0}, {"snippet_id": 83836, "code": " use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self", "label": 0}, {"snippet_id": 83705, "code": " finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state(job_state) run_results=client.full_status() stdout=run_results.get('stdout', '')", "label": 0}, {"snippet_id": 40937, "code": " Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist", "label": 0}, {"snippet_id": 32283, "code": "=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f", "label": 0}, {"snippet_id": 50837, "code": "=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists", "label": 0}, {"snippet_id": 56529, "code": ".GET.get('format') if not q_format: q_format='p' if not q_app_form: return HttpResponse('Unrecognizable app_form') q_app, q_form=q_app_form.split('.')[0], q_app_form.split('.')[1] exec('from tcms.%s.forms", "label": 1}, {"snippet_id": 59593, "code": " if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to", "label": 0}, {"snippet_id": 81166, "code": " not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self", "label": 0}, {"snippet_id": 45968, "code": "=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged", "label": 0}, {"snippet_id": 83137, "code": " configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this", "label": 0}, {"snippet_id": 88997, "code": " def targets(self, predicate=None, **kwargs): \"\"\"Selects targets in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target", "label": 0}, {"snippet_id": 41952, "code": " chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare(", "label": 0}, {"snippet_id": 29136, "code": ".utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule", "label": 0}, {"snippet_id": 47057, "code": ".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError", "label": 0}, {"snippet_id": 19262, "code": "=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.file.seek(0) with open(tmp_file.name) as json_file: result=load_source(json_file) assert result==native def test_json_file_path(): native", "label": 0}, {"snippet_id": 72295, "code": " loop\" log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name, text, placeholder_self.name) if 'source' in kwargs: del kwargs['source'] irc.reply(text, source=irc.pseudoclient.uid", "label": 0}, {"snippet_id": 56496, "code": ".objects.filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters", "label": 1}, {"snippet_id": 89929, "code": " older than' '{} and got{}'.format(java, self._maximum_version, version)) self._bin_path=os.path.join(self.home, 'bin') try: self._validated_executable('javac') self._is_jdk=True except self.Error as e: if", "label": 0}, {"snippet_id": 79570, "code": " \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file", "label": 0}, {"snippet_id": 52761, "code": " output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self", "label": 0}, {"snippet_id": 88495, "code": "=scheduler @property def options(self): \"\"\"Returns the new-style options. :API: public \"\"\" return self._options @property def log(self): \"\"\"Returns the preferred logger for goals to use. :API: public \"\"", "label": 0}, {"snippet_id": 77852, "code": ": self.spawn_evaluators() try: while self.running.is_set(): if self.c.tcount==0: self.inter_sleep(5) continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep(5) continue", "label": 0}, {"snippet_id": 16545, "code": " if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data)", "label": 0}, {"snippet_id": 44101, "code": "=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards,", "label": 0}, {"snippet_id": 51255, "code": " same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard", "label": 0}, {"snippet_id": 10765, "code": " text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W", "label": 1}, {"snippet_id": 33036, "code": "._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name ", "label": 0}, {"snippet_id": 42072, "code": "+str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value", "label": 0}, {"snippet_id": 46310, "code": " in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards", "label": 0}, {"snippet_id": 40220, "code": " wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard", "label": 1}, {"snippet_id": 67402, "code": " from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS", "label": 0}, {"snippet_id": 27511, "code": " updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN", "label": 0}, {"snippet_id": 50369, "code": ".log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func", "label": 0}, {"snippet_id": 56969, "code": "'5', None) 4. get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type", "label": 0}, {"snippet_id": 14174, "code": " import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import", "label": 0}, {"snippet_id": 95910, "code": "=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a Zarr format. Only converts a single VCF file.", "label": 1}, {"snippet_id": 11267, "code": " no target directory is given its value is read from /etc/monitoring_config_generator/config.yaml --skip-checks Do not run checks on the yaml file received from the URL. \"\"\" from datetime import datetime", "label": 0}, {"snippet_id": 82358, "code": " in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t", "label": 0}, {"snippet_id": 63046, "code": " 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy", "label": 0}, {"snippet_id": 52375, "code": ": self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self", "label": 0}, {"snippet_id": 12001, "code": " config=update_dict(config, new_config) except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key, value in confs.items(): if value: if isinstance(value, int): if isinstance(value, bool):", "label": 0}, {"snippet_id": 38878, "code": "\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow", "label": 0}, {"snippet_id": 44037, "code": " updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores", "label": 0}, {"snippet_id": 46217, "code": " wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values))", "label": 0}, {"snippet_id": 36056, "code": "), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input", "label": 0}, {"snippet_id": 35386, "code": " **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format", "label": 0}, {"snippet_id": 78339, "code": "(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t, msg)) self.w.sleep(self.errortimeout) except exc.PermanentError as e:", "label": 0}, {"snippet_id": 22509, "code": " None def set_hostname(self, hostname): \"\"\"Set the static hostname of the device Normally, tmsh is used to set the hostname for the system. For our purposes at this time though, I would hesitate to trust", "label": 0}, {"snippet_id": 11769, "code": " } auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/user/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict(base", "label": 0}, {"snippet_id": 42712, "code": " products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists", "label": 0}, {"snippet_id": 94000, "code": " send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on", "label": 0}, {"snippet_id": 77584, "code": "(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues", "label": 0}, {"snippet_id": 78536, "code": " user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c==0: self", "label": 0}, {"snippet_id": 24291, "code": "'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), ", "label": 1}, {"snippet_id": 79027, "code": ".warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can", "label": 0}, {"snippet_id": 31709, "code": ", f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i", "label": 1}, {"snippet_id": 72854, "code": " Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors", "label": 0}, {"snippet_id": 63360, "code": "], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy", "label": 1}, {"snippet_id": 19922, "code": " NotImplementedError def attach_socket(self, addr=None, adapter=None, **kwargs): if self.closed: raise RuntimeError('debug client closed') if adapter is None: adapter=self._adapter elif self._adapter is", "label": 0}, {"snippet_id": 81807, "code": " is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following(name -description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t[\"templateName", "label": 0}, {"snippet_id": 41381, "code": " snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import", "label": 1}, {"snippet_id": 85189, "code": " 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not specified, then the version specified in ' '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would", "label": 0}, {"snippet_id": 58056, "code": "] bug_ids=data['bugs'] try: validate_bug_id(bug_ids, bug_system_id) except ValidationError as e: return say_no(str(e)) bz_external_track=data['bz_external_track'] action=data['action'] try: if action==", "label": 0}, {"snippet_id": 90460, "code": "\"Error locating a java distribution.\"\"\" def __init__(self, distribution_environment, minimum_version=None, maximum_version=None): self._cache={} self._distribution_environment=distribution_environment self", "label": 0}, {"snippet_id": 70248, "code": " %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to", "label": 0}, {"snippet_id": 82389, "code": "\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args", "label": 0}, {"snippet_id": 58771, "code": "'object_pk': self.case_run_1.pk, 'field': 'case_run_status', 'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings", "label": 0}, {"snippet_id": 44443, "code": ": print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif", "label": 0}, {"snippet_id": 59585, "code": "/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure", "label": 0}, {"snippet_id": 36285, "code": ".rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f", "label": 1}, {"snippet_id": 69797, "code": " client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc", "label": 1}, {"snippet_id": 87590, "code": " jvm_options.extend(self._jvm_options) zinc_args.extend(ctx.sources) self.log_zinc_file(ctx.analysis_file) with open(ctx.zinc_args_file, 'wb') as fp: for arg in zinc_args: fp.write(arg) fp.write(b'\\n')", "label": 0}, {"snippet_id": 28007, "code": "<=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self", "label": 0}, {"snippet_id": 40183, "code": ".file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f:", "label": 0}, {"snippet_id": 92515, "code": ".path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_temporary_file_no_args(self): with temporary_file() as fp: self.assertTrue(os", "label": 0}, {"snippet_id": 67151, "code": ") if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count", "label": 0}, {"snippet_id": 25653, "code": " if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\"", "label": 0}, {"snippet_id": 8999, "code": " output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache", "label": 0}, {"snippet_id": 20085, "code": "(self, addr, **kwargs): if addr is None: addr=self._addr assert addr.host=='localhost' self._session=self.SESSION.create_client(addr, **kwargs) def _detach(self): session=self._session if session is None:", "label": 0}, {"snippet_id": 17961, "code": ".session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri(", "label": 1}, {"snippet_id": 9441, "code": " composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword", "label": 0}, {"snippet_id": 41554, "code": "[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id", "label": 0}, {"snippet_id": 77576, "code": ": uqsize=uq.qsize() uds=[] for i in range(uqsize): uds.append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved", "label": 0}, {"snippet_id": 22805, "code": " change :param password: The unencrypted password to set for the user :param crypt_id: If encrypting the password, the crypt_id that was used :param salt_len: If encrypting the password, the length of the", "label": 0}, {"snippet_id": 37893, "code": " self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark", "label": 0}, {"snippet_id": 59811, "code": ".QubitOperator(str(observable)[-1]+'0'), self.reg) variance=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'", "label": 0}, {"snippet_id": 66101, "code": " status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state", "label": 0}, {"snippet_id": 67749, "code": ">][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map", "label": 0}, {"snippet_id": 80033, "code": " switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser.add_argument(\"", "label": 0}, {"snippet_id": 93473, "code": " tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit", "label": 0}, {"snippet_id": 37431, "code": " is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 29777, "code": "\"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): ", "label": 0}, {"snippet_id": 22183, "code": " template=templateEnv.get_template( template_file) outputText=template.render( data) return outputText def run(self, state, data=None, context=None): \"\"\"Run ansible-playbook on the specified playbook. \"", "label": 0}, {"snippet_id": 49579, "code": " targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity,", "label": 0}, {"snippet_id": 92835, "code": ") as tempdir: file_symlink=os.path.join(tempdir, 'foo') os.symlink(not_zip.name, file_symlink) self.assertEqual(os.path.realpath(file_symlink), os.path.realpath(not_zip.name)) with self.assertRaisesRegexp", "label": 0}, {"snippet_id": 42966, "code": " files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for", "label": 0}, {"snippet_id": 38458, "code": "(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule", "label": 0}, {"snippet_id": 19320, "code": ".write(source) tmp_file.flush() with open(tmp_file.name) as yaml_file: result=load_source(yaml_file) assert result==native def test_yaml_file_path(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file", "label": 0}, {"snippet_id": 91683, "code": " all_requirements ] requirements_pex_request=ExecuteProcessRequest( argv=tuple(requirements_pex_argv), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=pex_snapshot", "label": 1}, {"snippet_id": 44279, "code": ", \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and", "label": 0}, {"snippet_id": 19969, "code": "=adapter.address self._attach(addr, **kwargs) return self._session def detach(self, adapter=None): if self.closed: raise RuntimeError('debug client closed') if self._session is None: raise RuntimeError('not", "label": 0}, {"snippet_id": 63154, "code": " full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str", "label": 1}, {"snippet_id": 13030, "code": ".environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(url, headers=headers, auth=auth) for repo in r.json(): if repo[\"description\"]: if data[\"target_repo_fullname\"] in repo[\"description\"", "label": 0}, {"snippet_id": 83689, "code": ".galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds)", "label": 0}, {"snippet_id": 2230, "code": " action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0", "label": 0}, {"snippet_id": 1149, "code": "(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets", "label": 0}, {"snippet_id": 30972, "code": ".exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file", "label": 0}, {"snippet_id": 83315, "code": ".__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state", "label": 0}, {"snippet_id": 62506, "code": ") _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and", "label": 0}, {"snippet_id": 37796, "code": "[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len", "label": 0}, {"snippet_id": 57737, "code": "(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case.count() review_case_count=plan.review_case.count() return http.JsonResponse({ 'rc': 0, 'response': 'ok', 'run_case_count", "label": 0}, {"snippet_id": 58758, "code": ".login( username=self.tester.username, password='password') response=self.client.post(self.update_url,{ 'content_type': 'testruns.testcaserun', 'object_pk': self.case_run_1.pk, 'field': 'case_run_status", "label": 0}, {"snippet_id": 14400, "code": ".poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr:", "label": 0}, {"snippet_id": 95656, "code": " searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory", "label": 0}, {"snippet_id": 90842, "code": " a java Distribution. Distributions are searched for in the following order by default: 1. Paths listed for this operating system in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4", "label": 0}, {"snippet_id": 25425, "code": ".format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon", "label": 0}, {"snippet_id": 77657, "code": " data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data['domains']) if 'sets' in data: self.log.debug", "label": 0}, {"snippet_id": 1097, "code": " 'endpoint': wifi_name}], safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass)", "label": 0}, {"snippet_id": 1794, "code": " return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows", "label": 0}, {"snippet_id": 22200, "code": "-playbook on the specified playbook. \"\"\" playbook=None log_file=None template=None if state in self.conf: if 'playbook' in self.conf[state]: playbook=self.conf[state]['playbook'] if 'log_file' in self.conf", "label": 0}, {"snippet_id": 95396, "code": " with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)", "label": 0}, {"snippet_id": 10099, "code": " fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches,", "label": 0}, {"snippet_id": 68806, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER)", "label": 0}, {"snippet_id": 62614, "code": " return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq", "label": 0}, {"snippet_id": 81871, "code": " type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds", "label": 0}, {"snippet_id": 28348, "code": "(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable", "label": 0}, {"snippet_id": 21161, "code": ".0): if self._event is None: return if not self._event.wait(timeout): message='Timeout waiting for ' if isinstance(self, AwaitableEvent): message +='Event{}'.format(self.name) else: message +='Response{", "label": 0}, {"snippet_id": 72067, "code": "%s\"(case sensitive).' % netname) return irc.reply(\"Done. If you want to reconnect this network, use the 'rehash' command.\") control.remove_network(network) @utils.add_cmd def autoconnect(irc, source, args", "label": 0}, {"snippet_id": 65935, "code": " > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join", "label": 0}, {"snippet_id": 52038, "code": " pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries", "label": 0}, {"snippet_id": 6394, "code": " code are left in this module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import", "label": 0}, {"snippet_id": 173, "code": " \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi", "label": 1}, {"snippet_id": 55701, "code": "*ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo", "label": 0}, {"snippet_id": 32932, "code": "._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values", "label": 0}, {"snippet_id": 14002, "code": " requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method,", "label": 0}, {"snippet_id": 41055, "code": " names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index)", "label": 0}, {"snippet_id": 85581, "code": " classpaths from. :type products::class:`pants.goal.products.Products` :returns: A Zinc instance with access to relevant Zinc compiler wrapper jars and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self,", "label": 0}, {"snippet_id": 89651, "code": " distribution is not valid according to the configured constraints. \"\"\" return self._get_version(self.java) def find_libs(self, names): \"\"\"Looks for jars in the distribution lib folder(s). If the distribution", "label": 0}, {"snippet_id": 58175, "code": ", None) sep=data.get('sep', None) if target and p_pks and sep: p_pks=[k for k in p_pks.split(sep) if k] res=get_prod_related_objs(p_pks, target) else: res=[] return HttpResponse(json.dumps(res)) def objects_update", "label": 0}, {"snippet_id": 46703, "code": ".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise", "label": 0}, {"snippet_id": 39991, "code": " a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return", "label": 0}, {"snippet_id": 71831, "code": " return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"", "label": 1}, {"snippet_id": 89896, "code": ") if version < self._minimum_version: raise self.Error('The java distribution at{} is too old; expecting at least{} and' ' got{}'.format(java, self._minimum_version, version)) if self._maximum_version:", "label": 0}, {"snippet_id": 39492, "code": ".\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if", "label": 0}, {"snippet_id": 21585, "code": "(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove(link) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links, f)", "label": 0}, {"snippet_id": 5104, "code": "]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1,", "label": 0}, {"snippet_id": 37420, "code": ": if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output", "label": 0}, {"snippet_id": 51950, "code": " for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len", "label": 0}, {"snippet_id": 21825, "code": " keras from keras.models import Sequential from keras.layers import Dense classifier=Sequential() classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11)) classifier", "label": 1}, {"snippet_id": 9389, "code": " composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for", "label": 0}, {"snippet_id": 27379, "code": ".station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable", "label": 0}, {"snippet_id": 33725, "code": ": logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down", "label": 0}, {"snippet_id": 77332, "code": "'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: w=wclass(*args, name='.'.join( (wname,('pr{0}' if type_", "label": 0}, {"snippet_id": 78498, "code": "(t in self.pc.sets['closed'] or t in self.pc.sets['bumplimit'] or t in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in forum", "label": 1}, {"snippet_id": 64783, "code": " RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self)", "label": 0}, {"snippet_id": 16832, "code": " _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description': x.description ", "label": 0}, {"snippet_id": 10401, "code": ".path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir", "label": 0}, {"snippet_id": 811, "code": " processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor", "label": 0}, {"snippet_id": 84324, "code": "'galaxy_dataset_files_path', None) if LwrJobRunner.__use_remote_datatypes_conf( client): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file', None) if not remote_datatypes_config", "label": 0}, {"snippet_id": 528, "code": "(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username", "label": 0}, {"snippet_id": 2036, "code": "'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e','docker'],", "label": 0}, {"snippet_id": 49523, "code": " forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets)", "label": 0}, {"snippet_id": 52435, "code": " def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex", "label": 0}, {"snippet_id": 61049, "code": ".outer(temp.conj(), temp)) return d, P I=np.eye(2) X=np.array([[0, 1],[1, 0]]) Y=np.array([[0, -1j],[1j, 0]]) Z=np.array([[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1,", "label": 0}, {"snippet_id": 42461, "code": ") self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log", "label": 0}, {"snippet_id": 83070, "code": " ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util", "label": 0}, {"snippet_id": 57965, "code": ".GET.get('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)'", "label": 0}, {"snippet_id": 21223, "code": " import argparse as ap flatten=lambda l:[item for sublist in l for item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request", "label": 0}, {"snippet_id": 61160, "code": "(-1j * theta/2 * Z) def fr3(a, b, c): r\"\"\"Arbitrary one-qubit rotation using three Euler angles. Args: a,b,c(float): rotation angles Returns: array: unitary 2x2 rotation matrix rz(c) @ ry(b) @ rz(a) \"\"", "label": 0}, {"snippet_id": 53074, "code": "\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run", "label": 0}, {"snippet_id": 30870, "code": ".output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion", "label": 0}, {"snippet_id": 16153, "code": ".general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest,", "label": 0}, {"snippet_id": 57718, "code": "'No plan record found.') confirm_status_name='CONFIRMED' plan.run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count", "label": 0}, {"snippet_id": 44621, "code": " if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True", "label": 0}, {"snippet_id": 31445, "code": "\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s", "label": 0}, {"snippet_id": 59747, "code": "['gate_fusion', 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device", "label": 0}, {"snippet_id": 26154, "code": "' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2", "label": 1}, {"snippet_id": 43207, "code": "(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start", "label": 0}, {"snippet_id": 23421, "code": "=None): \"\"\" Create user account with 'username' \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is", "label": 1}, {"snippet_id": 34255, "code": "): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, *", "label": 0}, {"snippet_id": 25641, "code": "'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp", "label": 0}, {"snippet_id": 30658, "code": "(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input", "label": 0}, {"snippet_id": 27716, "code": " self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 65223, "code": ": FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE", "label": 0}, {"snippet_id": 63150, "code": " final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state", "label": 1}, {"snippet_id": 91590, "code": " PyTest, PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest, python_setup, source_root_config): \"\"\"Runs pytest for one target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download", "label": 1}, {"snippet_id": 91513, "code": " pants.engine.isolated_process import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult) from pants.engine.legacy.graph import BuildFileAddresses, TransitiveHydratedTargets from", "label": 0}, {"snippet_id": 49909, "code": ".params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config", "label": 0}, {"snippet_id": 35246, "code": " rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches", "label": 1}, {"snippet_id": 64961, "code": " Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import", "label": 0}, {"snippet_id": 22608, "code": " Currently we do not set the hostname when WAAgent starts up, so I am passing on setting it here too. :param hostname: The hostname to set on the device \"\"\" return None def set_dhcp_hostname(self, hostname): \"", "label": 0}, {"snippet_id": 47711, "code": " os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand", "label": 0}, {"snippet_id": 67978, "code": ", 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target", "label": 0}, {"snippet_id": 85955, "code": ", javac_plugin_target): javac_plugin_info_file=os.path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod", "label": 0}, {"snippet_id": 72630, "code": " output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\"", "label": 0}, {"snippet_id": 84627, "code": " fingerprint=True, help='Show information about files ignored by cloc.') def console_output(self, targets): if not self.get_options().transitive: targets=self.context.target_roots input_snapshots=tuple( target", "label": 0}, {"snippet_id": 70689, "code": "~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR", "label": 0}, {"snippet_id": 19559, "code": " argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg", "label": 0}, {"snippet_id": 41706, "code": ".expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\"", "label": 1}, {"snippet_id": 86854, "code": "): return('-C-nowarn', '-C-Xlint:none', '-S-nowarn', '-S-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-S-Xfatal-warnings', '-C-Werror') @classmethod def get_fatal_warnings_disabled_args_default", "label": 0}, {"snippet_id": 22095, "code": ".inventory=inventory.Inventory( loader=self.loader, variable_manager=self.variable_manager, host_list='/etc/ansible/hosts' ) self.variable_manager.set_inventory(self.inventory) pb_dir=os.path.abspath('", "label": 0}, {"snippet_id": 75042, "code": " **kvargs): super().__init__() self.ev_init=ev_init self.bind_kt_ticker=Ticker() self.bind_kt=5 def handle_evaluate(self, reqid, interface, method, data): domain, page=data self.p.log.info('Recvd page ", "label": 0}, {"snippet_id": 61817, "code": ".reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1.6,[0", "label": 0}, {"snippet_id": 17749, "code": " return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse", "label": 0}, {"snippet_id": 50921, "code": "(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self", "label": 0}, {"snippet_id": 80284, "code": ".install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon", "label": 0}, {"snippet_id": 2982, "code": ".debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window", "label": 0}, {"snippet_id": 43189, "code": " of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in", "label": 0}, {"snippet_id": 10416, "code": " % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code", "label": 0}, {"snippet_id": 64561, "code": "(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path", "label": 1}, {"snippet_id": 71930, "code": ".append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes", "label": 0}, {"snippet_id": 55621, "code": ".overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw", "label": 0}, {"snippet_id": 37235, "code": " bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self)", "label": 0}, {"snippet_id": 20933, "code": ".0) if self._listenerthread.is_alive(): warnings.warn('session listener still running') self._check_handlers() def _listen(self): try: for msg in self._conn.iter_messages(): if self.VERBOSE: print(' ->", "label": 0}, {"snippet_id": 66802, "code": ": ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self", "label": 0}, {"snippet_id": 87212, "code": " self.context.products.safe_create_data('zinc_args', lambda: defaultdict(list)) def javac_classpath(self): return Java.global_javac_classpath(self.context.products) def scalac_classpath(self): return ScalaPlatform", "label": 0}, {"snippet_id": 86033, "code": " product_types(cls): return['runtime_classpath'] def __init__(self, *args, **kwargs): super(JavacCompile, self).__init__(*args, **kwargs) self.set_distribution(jdk=True) def select(self, target): if not", "label": 0}, {"snippet_id": 93223, "code": " ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[]", "label": 0}, {"snippet_id": 28209, "code": "'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, ", "label": 0}, {"snippet_id": 91988, "code": " pydist_has_native_sources(self, target): return target.has_sources(extension=tuple(self._native_source_extensions)) @memoized_property def _native_target_matchers(self): return{ SubclassesOf(PythonDistribution", "label": 0}, {"snippet_id": 30245, "code": "): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name", "label": 0}, {"snippet_id": 89121, "code": " \"\"\" core=set(self.targets(on_predicate)) dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in target.dependencies: if dependency in core: dependees[target].add(dependency", "label": 0}, {"snippet_id": 90016, "code": "') as fp: fp.write(pkgutil.get_data(__name__, 'SystemProperties.class')) cmd=[java, '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout", "label": 0}, {"snippet_id": 12948, "code": "]=True REQUEST_JSON[\"files\"]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs in data[\"diff\"].items(): if len(diffs) !=0:", "label": 0}, {"snippet_id": 17162, "code": " YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client", "label": 0}, {"snippet_id": 95110, "code": "[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp", "label": 1}, {"snippet_id": 87229, "code": ".compiler_classpath(self.context.products) def write_extra_resources(self, compile_context): \"\"\"Override write_extra_resources to produce plugin and annotation processor files.\"\"\" target=compile_context.target if", "label": 0}, {"snippet_id": 11454, "code": " hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config(self.source) if raw_yaml_config is None: raise SystemExit(\"Raw yaml config from source '%s' is 'None", "label": 0}, {"snippet_id": 56660, "code": "', test_case_tags) run_counter=_TagCounter('num_runs', test_run_tags) for tag in all_tags: tag.num_plans=plan_counter.calculate_tag_count(tag) tag.num_cases=case_counter.calculate_tag_count(tag) tag.num_runs", "label": 0}, {"snippet_id": 71157, "code": "] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=", "label": 0}, {"snippet_id": 49493, "code": ".relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None:", "label": 0}, {"snippet_id": 20583, "code": "=kwargs.get('timeout'), ) return cls(conn, owned=True, **kwargs) @classmethod def create_server(cls, addr=None, **kwargs): if addr is None: addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_server", "label": 0}, {"snippet_id": 3937, "code": " controlling it. The \" \"control is taken care of the remote master invoking \" \"this command.\\nIf run with the --kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\"", "label": 0}, {"snippet_id": 76419, "code": " frames[1:]) except wzrpc.WZError as e: self.log.warn(e) if socks.get(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg(self, frames): try: for", "label": 0}, {"snippet_id": 71080, "code": "], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout", "label": 0}, {"snippet_id": 28714, "code": " self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 83875, "code": "( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata", "label": 0}, {"snippet_id": 13042, "code": " r.json(): if repo[\"description\"]: if data[\"target_repo_fullname\"] in repo[\"description\"]: FORKED=True r=requests.delete(\"https://api.github.com/repos/\" \"{}\".format(repo[\"full_name\"]), headers=headers,", "label": 0}, {"snippet_id": 86117, "code": " processors): with safe_open(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip())) def execute(self): if JvmPlatform.global_instance().get_options().compiler", "label": 0}, {"snippet_id": 51276, "code": ".add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\"", "label": 0}, {"snippet_id": 70736, "code": ".startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets ", "label": 1}, {"snippet_id": 26456, "code": " self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property", "label": 0}, {"snippet_id": 50842, "code": "._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property", "label": 0}, {"snippet_id": 5409, "code": " iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False):", "label": 0}, {"snippet_id": 91343, "code": "): PythonLibrary, PythonTests.alias(): PythonTests, PythonDistribution.alias(): PythonDistribution, 'python_requirement_library': PythonRequirementLibrary, Resources.alias(): Resources, UnpackedWheels.alias", "label": 0}, {"snippet_id": 69337, "code": "=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes", "label": 0}, {"snippet_id": 2835, "code": " res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug", "label": 0}, {"snippet_id": 42046, "code": "=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 95579, "code": "(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, file_path_local)) else", "label": 0}, {"snippet_id": 78801, "code": "\t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself", "label": 0}, {"snippet_id": 88849, "code": " global lock for the root directory associated with this context. When a goal requires serialization, it will call this to acquire the lock. :API: public \"\"\" if self.options.for_global_scope().lock: if not", "label": 0}, {"snippet_id": 28023, "code": "=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"", "label": 0}, {"snippet_id": 73723, "code": " Initializes the configuration representation with a supplied file. \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not", "label": 0}, {"snippet_id": 31567, "code": "=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1:", "label": 0}, {"snippet_id": 73637, "code": ".path from pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return:", "label": 0}, {"snippet_id": 37904, "code": "() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params,", "label": 0}, {"snippet_id": 63368, "code": "( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure", "label": 1}, {"snippet_id": 44851, "code": ".set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params", "label": 0}, {"snippet_id": 76313, "code": ".make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.success, data) def send_error_rep(self, reqid, data): self.send_rep(reqid", "label": 0}, {"snippet_id": 78250, "code": ".scan_targets_loop) else: self.schedule(self.comment_loop) def add_comment(self, t, msg): if True: try: self.postmsg(t[1], msg, t[0]) except exc.Success as e: self.counters['comments'] +=1 self.w.sleep", "label": 0}, {"snippet_id": 76295, "code": ", f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep", "label": 0}, {"snippet_id": 25136, "code": " STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES", "label": 1}, {"snippet_id": 31186, "code": "**variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self", "label": 0}, {"snippet_id": 49099, "code": "): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder", "label": 0}, {"snippet_id": 87251, "code": "._write_scalac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, AnnotationProcessor) and target", "label": 0}, {"snippet_id": 26890, "code": "] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0", "label": 0}, {"snippet_id": 45444, "code": " def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property", "label": 1}, {"snippet_id": 52877, "code": ")) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException", "label": 0}, {"snippet_id": 72743, "code": " determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark", "label": 1}, {"snippet_id": 21307, "code": ".ArgumentParser(usage='%(prog)s[options] <subreddit>[--[mpv-arguments]]', description='Play the youtube links from your favourite subreddit.') parser.add_argument('--depth', metavar='d', type=int, default=0", "label": 0}, {"snippet_id": 50850, "code": " a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property", "label": 1}, {"snippet_id": 60164, "code": " Coherent, DensityMatrix, DisplacedSqueezed, Fock, Ket, Squeezed, Thermal, Gaussian) from strawberryfields.ops import(GaussianTransform, Interferometer) from strawberryfields.ops import(BSgate, CKgate,", "label": 0}, {"snippet_id": 269, "code": " currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0", "label": 0}, {"snippet_id": 6019, "code": "(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems", "label": 1}, {"snippet_id": 50024, "code": " done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats", "label": 0}, {"snippet_id": 61499, "code": "._observe) if self.shots==0: ev=self.ev(A,[self._observe.wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self._observe.wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self.shots", "label": 0}, {"snippet_id": 49339, "code": " docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource", "label": 0}, {"snippet_id": 93310, "code": " session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init", "label": 0}, {"snippet_id": 75344, "code": ", msg, interface, method): try: handler=self.sig_handlers[(interface, method)] except KeyError: raise WZENoHandler(iden, 'No handler for sig %s,%s'%(interface, method)) handler(interface, method, msg[1", "label": 0}, {"snippet_id": 43935, "code": ".rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets", "label": 0}, {"snippet_id": 11576, "code": "}\") @staticmethod def value_to_icinga(value): \"\"\"Convert a scalar or list to Icinga value format. Lists are concatenated by, and empty(None) values produce an empty string\"\"\" if isinstance(value, list)", "label": 0}, {"snippet_id": 63164, "code": " __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper):", "label": 0}, {"snippet_id": 77674, "code": " domains.update(data['domains']) if 'sets' in data: self.log.debug('Other sets were loaded') self.pc.sets.update(data['sets']) def load_bumplimit_set(self): if not os.path.isfile(self.bumplimitfile): return", "label": 0}, {"snippet_id": 78791, "code": ",formAction=None,inputName=None): \t\tself.logger=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself", "label": 0}, {"snippet_id": 10228, "code": " clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches)", "label": 0}, {"snippet_id": 76965, "code": ")) self.log.info('Uploading %s as new avatar', av) self.site.uploadavatar('0', av) ud[0]['avatar']=av ud[0]['avatar_uploaded']=True from lib.mailinator import Mailinator def create_spawn(proxy, proxytype", "label": 0}, {"snippet_id": 42803, "code": " output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self", "label": 0}, {"snippet_id": 23479, "code": " out)) def del_account(self, username): if self.is_sys_user(username): logger.error(\"{0} is a system user. Will not delete it.\", username) shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y", "label": 0}, {"snippet_id": 64874, "code": ".Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall", "label": 0}, {"snippet_id": 810, "code": " in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor()", "label": 0}, {"snippet_id": 41556, "code": "=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64", "label": 0}, {"snippet_id": 2769, "code": "'host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger", "label": 0}, {"snippet_id": 12229, "code": " file_to_check: file_to_check.write(r.text) cmd='pycodestyle{config[pycodestyle_cmd_config]} file_to_check.py'.format( config=config) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc", "label": 0}, {"snippet_id": 37840, "code": ")), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize", "label": 0}, {"snippet_id": 84375, "code": "=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths", "label": 0}, {"snippet_id": 68536, "code": " % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True", "label": 0}, {"snippet_id": 41518, "code": " if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input:", "label": 0}, {"snippet_id": 46215, "code": " Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join", "label": 0}, {"snippet_id": 78724, "code": " remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request", "label": 0}, {"snippet_id": 24154, "code": "=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS,", "label": 1}, {"snippet_id": 16900, "code": " handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod", "label": 0}, {"snippet_id": 61243, "code": " ValueError(\"Operator must be a square matrix.\") if not np.allclose(U @ U.conj().T, np.identity(U.shape[0]), atol=tolerance): raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args)", "label": 0}, {"snippet_id": 20813, "code": "{!r}'.format(event) evt=self._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result[\"msg\"], evt) def _get_awaiter_for_request(self, req, **kwargs): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 73778, "code": "] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config", "label": 0}, {"snippet_id": 42216, "code": ".append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output", "label": 0}, {"snippet_id": 88271, "code": " Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products import Products from pants.goal.workspace import ScmWorkspace from pants.process.lock import OwnerPrintingInterProcessFileLock", "label": 1}, {"snippet_id": 11641, "code": " version='0.1.0') start_time=datetime.now() try: file_name=MonitoringConfigGenerator(arg['URL'], arg['--debug'], arg['--targetdir'], arg['--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN if", "label": 0}, {"snippet_id": 50383, "code": ".benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name", "label": 0}, {"snippet_id": 23228, "code": ".fileno(), 0x8912, param) retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned more than{0} up ' 'network interfaces.'), expected) sock=buff.tostring", "label": 0}, {"snippet_id": 63990, "code": "[\"none\", \"local\", \"remote\"]: raise Exception(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client):", "label": 0}, {"snippet_id": 39518, "code": "(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version", "label": 0}, {"snippet_id": 36958, "code": ".dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1,", "label": 0}, {"snippet_id": 24703, "code": "'battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 57349, "code": " action='Field{} changed from{} to{}.'.format( field, getattr(t, field), TestCaseRunStatus.id_to_string(value), ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value", "label": 0}, {"snippet_id": 19924, "code": " attach_socket(self, addr=None, adapter=None, **kwargs): if self.closed: raise RuntimeError('debug client closed') if adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError", "label": 0}, {"snippet_id": 68739, "code": "): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\")", "label": 0}, {"snippet_id": 85037, "code": " register('--suffix-version', advanced=True, default=None, help='Scala suffix to be used in `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar` lookups for", "label": 0}, {"snippet_id": 85405, "code": ".Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope='zinc' @classmethod def subsystem_dependencies", "label": 0}, {"snippet_id": 71349, "code": " AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\",", "label": 0}, {"snippet_id": 42427, "code": ".message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set", "label": 0}, {"snippet_id": 15321, "code": "'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join(", "label": 0}, {"snippet_id": 91742, "code": ".directory_digest, prefix=source_root.path ) ) for snapshot, source_root in sources_snapshots_and_source_roots ] sources_digest=yield Get( Digest, DirectoriesToMerge(directories=tuple(all_sources_digests)", "label": 0}, {"snippet_id": 5017, "code": " for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return:", "label": 0}, {"snippet_id": 22425, "code": "!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys config\" rc=shellutil.run(cmd) if rc !=0: logger.error(\"WARNING: Cannot save sys config on 1st boot.\") return rc def restart_ssh_service(self", "label": 0}, {"snippet_id": 38719, "code": " forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try:", "label": 0}, {"snippet_id": 57321, "code": " say_yes() @require_POST def update_case_run_status(request): \"\"\" Update Case Run status. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type\") vtype=data.get('value_type',", "label": 0}, {"snippet_id": 87686, "code": ".ZINC_COMPILE_MAIN] +zinc_args) req=ExecuteProcessRequest( argv=argv, input_files=merged_input_digest, output_files=(analysis_cache,), output_directories=(classes_dir,), description=\"zinc compile for{}", "label": 0}, {"snippet_id": 59030, "code": " test_get_env_properties(self): response=self.client.get(self.get_info_url,{'info_type': 'env_properties'}) expected_json=json.loads( serializers.serialize( 'json', EnvProperty.objects.all(), fields=('name', ", "label": 0}, {"snippet_id": 52580, "code": " wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files", "label": 0}, {"snippet_id": 19994, "code": " if adapter is None: adapter=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError('detach not supported') self._detach() def _close(self): if self._session is not", "label": 0}, {"snippet_id": 3406, "code": ".window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file", "label": 0}, {"snippet_id": 7367, "code": ", keywords[kw], encode_for_xml(categories[kw]))) for field, keywords in((auth_field, output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field", "label": 0}, {"snippet_id": 14841, "code": " not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description': x.description } for x in rawsnips]", "label": 0}, {"snippet_id": 23194, "code": " python_arc=platform.architecture()[0] if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' ", "label": 0}, {"snippet_id": 63764, "code": ": log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno", "label": 0}, {"snippet_id": 44410, "code": "(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag", "label": 0}, {"snippet_id": 70986, "code": "(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0:", "label": 0}, {"snippet_id": 78888, "code": " \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet", "label": 0}, {"snippet_id": 31872, "code": ".items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark)", "label": 0}, {"snippet_id": 62642, "code": "=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__", "label": 0}, {"snippet_id": 50610, "code": "=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow:", "label": 0}, {"snippet_id": 29779, "code": " raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag", "label": 0}, {"snippet_id": 66316, "code": ") if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 51105, "code": ".dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\", "label": 0}, {"snippet_id": 42187, "code": " class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self", "label": 0}, {"snippet_id": 78853, "code": "(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept", "label": 0}, {"snippet_id": 59160, "code": " transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .. autosummary:: init_plugin Classes -----", "label": 0}, {"snippet_id": 56528, "code": "=request.GET.get('format') if not q_format: q_format='p' if not q_app_form: return HttpResponse('Unrecognizable app_form') q_app, q_form=q_app_form.split('.')[0], q_app_form.split('.')[1] exec('from tcms", "label": 1}, {"snippet_id": 25972, "code": " self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 83352, "code": ".__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters( client) unstructured_path_rewrites={} if compute_environment: unstructured_path_rewrites=compute_environment", "label": 0}, {"snippet_id": 89650, "code": " this distribution is not valid according to the configured constraints. \"\"\" return self._get_version(self.java) def find_libs(self, names): \"\"\"Looks for jars in the distribution lib folder(s). If the distribution", "label": 0}, {"snippet_id": 84710, "code": "=ignored', '--list-file=input_files_list', '--report-file=report', ) req=ExecuteProcessRequest( argv=cmd, input_files=directory_digest, output_files=('ignored', 'report'), description='cloc', ) exec_result", "label": 1}, {"snippet_id": 74924, "code": " benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"] if", "label": 0}, {"snippet_id": 8101, "code": "=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename", "label": 0}, {"snippet_id": 48644, "code": " is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}", "label": 0}, {"snippet_id": 63316, "code": " tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters: compute_environment=LwrComputeEnvironment( client, job_wrapper, remote_job_config) prepare_kwds", "label": 0}, {"snippet_id": 41212, "code": " pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries", "label": 0}, {"snippet_id": 45919, "code": " return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value", "label": 0}, {"snippet_id": 63501, "code": " job_destination_params=job_state.job_destination.params job_id=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self", "label": 0}, {"snippet_id": 3412, "code": ".error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self", "label": 0}, {"snippet_id": 76667, "code": "-only-cache', '-C', action='store_true', help=\"Disables any requests in DataLoader(includes Witch)\") parser.add_argument('--no-shell', '-N', action='store_true', help=\"Sleep instead of starting the shell", "label": 0}, {"snippet_id": 41805, "code": "(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing:", "label": 0}, {"snippet_id": 40226, "code": ".dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None", "label": 1}, {"snippet_id": 10098, "code": " fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches", "label": 0}, {"snippet_id": 10268, "code": " by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison:", "label": 0}, {"snippet_id": 74562, "code": "(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4", "label": 0}, {"snippet_id": 64109, "code": "(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']", "label": 0}, {"snippet_id": 35252, "code": "(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise", "label": 1}, {"snippet_id": 56177, "code": " django.db.models import Q, Count from django.contrib.auth.models import User from django.core import serializers from django.core.exceptions import ObjectDoesNotExist from django.apps import apps from", "label": 0}, {"snippet_id": 33279, "code": "(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules", "label": 0}, {"snippet_id": 4537, "code": "(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords", "label": 0}, {"snippet_id": 33454, "code": " lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph", "label": 0}, {"snippet_id": 33567, "code": " cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for", "label": 0}, {"snippet_id": 48461, "code": " for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self", "label": 0}, {"snippet_id": 32087, "code": "\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified", "label": 0}, {"snippet_id": 91946, "code": ", fingerprint=True, advanced=True, help='The extensions recognized for native source files in `python_dist()` sources.') @classmethod def subsystem_dependencies(cls): return super(PythonNativeCode, cls", "label": 0}, {"snippet_id": 60558, "code": ". \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock', 'X', 'P", "label": 0}, {"snippet_id": 68904, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs", "label": 0}, {"snippet_id": 74861, "code": " the benchmark module's configuration. \"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_aggregations=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self", "label": 1}, {"snippet_id": 70340, "code": ".get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self", "label": 0}, {"snippet_id": 83657, "code": " job_destination_params=job_state.job_destination.params job_id=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self", "label": 0}, {"snippet_id": 40474, "code": " def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic", "label": 0}, {"snippet_id": 46255, "code": " Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )", "label": 0}, {"snippet_id": 92232, "code": " pants.util.contextutil import(InvalidZipPath, Timer, environment_as, exception_logging, hermetic_environment_as, maybe_profiled, open_zip, pushd, signal_handler_as, stdio_as, temporary_dir, temporary_file)", "label": 0}, {"snippet_id": 53383, "code": " i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output", "label": 0}, {"snippet_id": 8171, "code": " field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_'", "label": 0}, {"snippet_id": 69671, "code": " install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:", "label": 0}, {"snippet_id": 48630, "code": ", wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards", "label": 0}, {"snippet_id": 68004, "code": " ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start", "label": 0}, {"snippet_id": 19355, "code": " test_url(httpbin): native={ 'origin': '127.0.0.1', 'args':{}, } source=httpbin.url +'/get' result=load_source(source) assert isinstance(result, collections.Mapping) result.pop('headers') result.pop('url", "label": 0}, {"snippet_id": 90442, "code": "._possible_environments=possible_environments @property def jvm_locations(self): return itertools.chain(*(pe.jvm_locations for pe in self._possible_environments)) class _Locator(object): class Error(Distribution.Error", "label": 0}, {"snippet_id": 66871, "code": "'.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params", "label": 0}, {"snippet_id": 2658, "code": " node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" ", "label": 0}, {"snippet_id": 91530, "code": " BuildFileAddresses, TransitiveHydratedTargets from pants.engine.legacy.structs import PythonTestsAdaptor from pants.engine.rules import UnionRule, optionable_rule, rule from pants.engine.selectors import Get from pants", "label": 0}, {"snippet_id": 84767, "code": ".jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.zinc_language_mixin import ZincLanguageMixin from pants.backend.jvm.targets.jar_library import JarLibrary from pants.build_graph.address import", "label": 0}, {"snippet_id": 94111, "code": "=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self", "label": 0}, {"snippet_id": 32679, "code": " comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list(", "label": 0}, {"snippet_id": 65261, "code": " target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs", "label": 0}, {"snippet_id": 69794, "code": "\"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if", "label": 1}, {"snippet_id": 6326, "code": " executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory, executable)): return True return", "label": 1}, {"snippet_id": 24115, "code": ".io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS", "label": 1}, {"snippet_id": 25510, "code": "(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for", "label": 0}, {"snippet_id": 64379, "code": " import commandList from Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def", "label": 0}, {"snippet_id": 93296, "code": ".logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config", "label": 0}, {"snippet_id": 80546, "code": ".proxyCreds: \t\tproxyUser=args.proxyCreds[\"username\"] \t\tproxyPass=args.proxyCreds[\"password\"] \telse: \t\tproxyUser=args.proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] ", "label": 0}, {"snippet_id": 62109, "code": " or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" name='ProjectQ OpenQML", "label": 0}, {"snippet_id": 34078, "code": " named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority", "label": 0}, {"snippet_id": 66446, "code": "%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print", "label": 0}, {"snippet_id": 67861, "code": " result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes,", "label": 0}, {"snippet_id": 74388, "code": " def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False class ConfigurationRepresentation(object)", "label": 0}, {"snippet_id": 59444, "code": "): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n", "label": 0}, {"snippet_id": 38709, "code": ") targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 65708, "code": " if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status", "label": 0}, {"snippet_id": 15178, "code": " SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync", "label": 0}, {"snippet_id": 16459, "code": " CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request", "label": 0}, {"snippet_id": 11900, "code": "=False for file in files: if file[-3:]=='.py': pythonic=True break return pythonic def get_config(data): \"\"\" Get.pep8speaks.yml config file from the repository and return the config dictionary \"\"\" config", "label": 0}, {"snippet_id": 86065, "code": ": return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath(self.context.products) def write_extra_resources(self, compile_context): \"\"\"Override write_extra_resources", "label": 0}, {"snippet_id": 87522, "code": "(self._get_zinc_arguments(settings)) zinc_args.append('-transactional') for option_set in compiler_option_sets: enabled_args=self.get_options().compiler_option_sets_enabled_args.get(option_set,[]) if option_set", "label": 0}, {"snippet_id": 64067, "code": " there. Alternatively, one can use the remote datatype config -but there is no guarentee that it will contain all the datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none", "label": 0}, {"snippet_id": 46250, "code": " of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\",", "label": 0}, {"snippet_id": 74613, "code": " blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): \"\"\" Creates an object representation of VCF to Zarr Conversion module configuration data. :param runtime_config:", "label": 0}, {"snippet_id": 68920, "code": ".CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class", "label": 0}, {"snippet_id": 52969, "code": " self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__", "label": 0}, {"snippet_id": 61149, "code": " Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm(-1j * theta/2 * Z) def fr3(a, b, c): r\"\"\"Arbitrary one-qubit rotation using three Euler angles. Args: a,b,c(float", "label": 0}, {"snippet_id": 47569, "code": " return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value", "label": 0}, {"snippet_id": 93731, "code": " or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self", "label": 0}, {"snippet_id": 5533, "code": "(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault(", "label": 0}, {"snippet_id": 19707, "code": ".address=Address.as_server(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns", "label": 0}, {"snippet_id": 34810, "code": "=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex", "label": 1}, {"snippet_id": 25732, "code": "=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state", "label": 0}, {"snippet_id": 22438, "code": ".error(\"WARNING: Cannot save sys config on 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err=False) def stop_agent_service(self): return", "label": 0}, {"snippet_id": 56253, "code": " tcms.testcases.models import Category from tcms.testcases.models import TestCaseStatus, TestCaseTag from tcms.testcases.views import plan_from_request_or_none from tcms.testplans.models import TestPlan", "label": 0}, {"snippet_id": 25039, "code": " elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station)", "label": 0}, {"snippet_id": 78109, "code": " login, 'passwd': passwd}, False) def send_to_wm(frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) sig_sock.send_multipart(msg) def send_passthrough(frames): msg=[b", "label": 0}, {"snippet_id": 92318, "code": ") self.assertEqual('False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as(HORK=None):", "label": 0}, {"snippet_id": 38250, "code": ".persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(),", "label": 0}, {"snippet_id": 15958, "code": "=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def", "label": 1}, {"snippet_id": 35998, "code": " jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule", "label": 0}, {"snippet_id": 56825, "code": " tag_name: str \"\"\" self.obj=obj self.tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name", "label": 0}, {"snippet_id": 46387, "code": " if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item", "label": 0}, {"snippet_id": 69159, "code": " ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle", "label": 1}, {"snippet_id": 8346, "code": " fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists", "label": 0}, {"snippet_id": 3536, "code": " self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check", "label": 0}, {"snippet_id": 86485, "code": " pants.backend.jvm.targets.javac_plugin import JavacPlugin from pants.backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend", "label": 0}, {"snippet_id": 69284, "code": "\"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\"", "label": 1}, {"snippet_id": 22249, "code": " self.conf: log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template(template, data) ) runner=Runner(playbook", "label": 0}, {"snippet_id": 38251, "code": " from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None", "label": 0}, {"snippet_id": 7036, "code": ", this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords", "label": 0}, {"snippet_id": 19124, "code": " request=None if raw_request is not None: request=normalize_request(raw_request) response=None if raw_response is not None: response=normalize_response(raw_response, request=request) if response is not", "label": 0}, {"snippet_id": 71568, "code": ".__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR", "label": 0}, {"snippet_id": 25589, "code": "._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6'", "label": 0}, {"snippet_id": 57891, "code": ".POST.copy() comment=data.get('comment', None) if not comment: return say_no('Comments needed') run_ids=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.", "label": 0}, {"snippet_id": 25028, "code": "'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object", "label": 0}, {"snippet_id": 55577, "code": " self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir", "label": 0}, {"snippet_id": 13847, "code": " vim import requests import urlparse from retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import", "label": 0}, {"snippet_id": 26796, "code": " data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 64771, "code": " def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR", "label": 0}, {"snippet_id": 86630, "code": "(javac_plugin_info_file, 'w') as f: classname=javac_plugin_target.classname if PY3 else javac_plugin_target.classname.decode('utf-8') f.write(classname) @staticmethod def validate_arguments(log, whitelisted_args,", "label": 0}, {"snippet_id": 57318, "code": ", tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"\" Update Case Run status. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type", "label": 0}, {"snippet_id": 53580, "code": ", output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files", "label": 0}, {"snippet_id": 75847, "code": "*1000) if rs.finished: if rs.retry: msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) rs.finished=False rs.retry=False continue return elapsed", "label": 0}, {"snippet_id": 35312, "code": "**wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns", "label": 0}, {"snippet_id": 59656, "code": " \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend", "label": 0}, {"snippet_id": 14825, "code": "=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager", "label": 0}, {"snippet_id": 67359, "code": " fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem", "label": 0}, {"snippet_id": 50597, "code": " f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None", "label": 0}, {"snippet_id": 22525, "code": ". For our purposes at this time though, I would hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this", "label": 0}, {"snippet_id": 4736, "code": " composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according", "label": 0}, {"snippet_id": 71571, "code": " def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR", "label": 0}, {"snippet_id": 47365, "code": " chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare(", "label": 0}, {"snippet_id": 11811, "code": "/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key,{}), value) else: base[key]=head[key] else", "label": 1}, {"snippet_id": 5271, "code": " the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author", "label": 0}, {"snippet_id": 68618, "code": "\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status", "label": 0}, {"snippet_id": 95919, "code": " Converts the original data(VCF) to a Zarr format. Only converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config", "label": 0}, {"snippet_id": 13232, "code": " for ref in r.json(): if ref[\"ref\"].split(\"/\")[-1]==data[\"target_repo_branch\"]: sha=ref[\"object\"][\"sha\"] url=\"https://api.github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch", "label": 0}, {"snippet_id": 80198, "code": "-agents.txt\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template", "label": 0}, {"snippet_id": 85821, "code": " all_extra_cp_entries.extend(extra_cp_entries) return ClasspathUtil.compute_classpath_entries(iter(dependencies), classpath_product, all_extra_cp_entries, self.DEFAULT_CONFS, ) def compile_classpath(self", "label": 0}, {"snippet_id": 51455, "code": " write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag", "label": 0}, {"snippet_id": 8013, "code": " return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1", "label": 0}, {"snippet_id": 16324, "code": "}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format", "label": 0}, {"snippet_id": 61258, "code": "(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args(array): square hermitian matrix. Returns: array: square hermitian matrix", "label": 0}, {"snippet_id": 68199, "code": "\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"", "label": 1}, {"snippet_id": 29676, "code": " ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value", "label": 0}, {"snippet_id": 64303, "code": "=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self,", "label": 0}, {"snippet_id": 74960, "code": "=VCFtoZarrConfigurationRepresentation(runtime_config=runtime_config) def read_configuration(location): \"\"\" Args: location of the configuration file, existing configuration dictionary Returns: a dictionary of the form <dict>", "label": 0}, {"snippet_id": 66089, "code": " type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info", "label": 0}, {"snippet_id": 66608, "code": ".CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task", "label": 1}, {"snippet_id": 87783, "code": " should be absolute. ' '{} is not.'.format(path)) if is_outside(path, self.get_options().pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath entries provided to", "label": 0}, {"snippet_id": 32740, "code": " j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return", "label": 0}, {"snippet_id": 72691, "code": "=input_directory, temp_dir=temp_directory, output_dir=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service.setup_vcf_to_zarr", "label": 1}, {"snippet_id": 87653, "code": " be present for hermetic \" \"execution\".format(dep) ) if scala_path: snapshots.append( self.context._scheduler.capture_snapshots((PathGlobsAndRoot( PathGlobs(scala_path), get_buildroot(), ),))[0] ) merged_input_digest", "label": 0}, {"snippet_id": 76275, "code": ".wz_wait_reply(accept, *self.wz.make_auth_clear_data()) def bind_methods(self): for i, m, f, t in self.wz_bind_methods: self.set_route_type(i, m, t) self.bind_route(i, m, f) def unbind_methods(self): for i, m, f", "label": 0}, {"snippet_id": 70833, "code": "\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1", "label": 0}, {"snippet_id": 15219, "code": ") NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 32181, "code": "): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)", "label": 0}, {"snippet_id": 7307, "code": ": string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield", "label": 0}, {"snippet_id": 57726, "code": ".run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case.count", "label": 0}, {"snippet_id": 16458, "code": "._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()):", "label": 0}, {"snippet_id": 61601, "code": " one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem Returns: float: expectation value:math:`\\expect{A", "label": 0}, {"snippet_id": 59725, "code": " by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits", "label": 0}, {"snippet_id": 41862, "code": ": if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files", "label": 0}, {"snippet_id": 72473, "code": " where is the config file. \"\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands", "label": 0}, {"snippet_id": 47307, "code": "=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories", "label": 0}, {"snippet_id": 16699, "code": " crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr", "label": 0}, {"snippet_id": 52960, "code": ".rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self", "label": 0}, {"snippet_id": 22079, "code": ": if options is None: self.options=Options() self.options.verbosity=verbosity self.loader=dataloader.DataLoader() self.variable_manager=vars.VariableManager() self.inventory=inventory.Inventory( loader", "label": 0}, {"snippet_id": 59789, "code": ") self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ", "label": 0}, {"snippet_id": 85306, "code": "\n from __future__ import absolute_import, division, print_function, unicode_literals from builtins import object from pants.backend.jvm.subsystems.dependency_context import DependencyContext from pants", "label": 0}, {"snippet_id": 23628, "code": " it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run(\"/etc/rc.d/dhclient start{0}\".format", "label": 0}, {"snippet_id": 28872, "code": "'GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'", "label": 0}, {"snippet_id": 24068, "code": " in output.rstrip().split(','): if not possible.startswith('pass'): return possible cmd_search_storvsc=\"camcontrol devlist -b | grep storvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil", "label": 0}, {"snippet_id": 9643, "code": ")) for field, keywords in((auth_field, output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for", "label": 0}, {"snippet_id": 278, "code": "\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet", "label": 0}, {"snippet_id": 55501, "code": "(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included:", "label": 0}, {"snippet_id": 24817, "code": " data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self", "label": 0}, {"snippet_id": 1425, "code": " ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass", "label": 0}, {"snippet_id": 31815, "code": " Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile", "label": 0}, {"snippet_id": 91595, "code": " source_root_config): \"\"\"Runs pytest for one target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download/v1.6.6/pex' digest=Digest('61bb79384db0da8c844678440bd368bcbfac17bbdb865721ad3f9cb0ab29b629", "label": 1}, {"snippet_id": 44826, "code": " self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input:", "label": 0}, {"snippet_id": 36514, "code": ".intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output", "label": 0}, {"snippet_id": 22280, "code": " from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger as logger import azurelinuxagent", "label": 0}, {"snippet_id": 79456, "code": "\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True", "label": 0}, {"snippet_id": 81720, "code": "=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file\"}) \t\t\t\tif len(fileInputs) > 0: \t\t\t\t\treturnForms.append", "label": 0}, {"snippet_id": 23879, "code": "(output)) ifaces=output.split() if not ifaces: raise OSUtilError(\"Can't find ether interface.\") iface=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError", "label": 0}, {"snippet_id": 81715, "code": " detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{", "label": 0}, {"snippet_id": 87020, "code": "\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. \"\"\" return self.get_options", "label": 0}, {"snippet_id": 3889, "code": " subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run", "label": 0}, {"snippet_id": 45003, "code": ".func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 38563, "code": " keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph", "label": 0}, {"snippet_id": 43721, "code": " self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals", "label": 0}, {"snippet_id": 46428, "code": " -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index", "label": 0}, {"snippet_id": 46524, "code": "=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]:", "label": 0}, {"snippet_id": 28220, "code": " None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value'", "label": 0}, {"snippet_id": 25787, "code": " elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" ", "label": 0}, {"snippet_id": 75778, "code": " def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method, data))) raise Resume() self.wz.set_sig_handler(b'WZWorker', b'resume', term_handler) self", "label": 1}, {"snippet_id": 39352, "code": " is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global", "label": 0}, {"snippet_id": 1510, "code": " JsonResponse({\"version_info\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse", "label": 0}, {"snippet_id": 2669, "code": ") except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self", "label": 0}, {"snippet_id": 35346, "code": ", str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for", "label": 0}, {"snippet_id": 73863, "code": "(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\",", "label": 0}, {"snippet_id": 92291, "code": ", stdout=output).wait() output.seek(0) self.assertEqual('BORK\\n', output.read()) with temporary_file(binary_mode=False) as new_output: subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\" in", "label": 0}, {"snippet_id": 58285, "code": " user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories import EnvGroupFactory from tcms.tests.factories import EnvGroupPropertyMapFactory from tcms.tests.factories", "label": 0}, {"snippet_id": 10729, "code": "%(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an", "label": 1}, {"snippet_id": 52205, "code": " attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake", "label": 1}, {"snippet_id": 76661, "code": "=argparse.ArgumentParser(add_help=True) parser.add_argument('--only-cache', '-C', action='store_true', help=\"Disables any requests in DataLoader(includes Witch)\") parser.add_argument('--no-shell', '-N'", "label": 0}, {"snippet_id": 62476, "code": " has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key", "label": 0}, {"snippet_id": 9803, "code": "[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted", "label": 0}, {"snippet_id": 93145, "code": " dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from", "label": 0}, {"snippet_id": 3591, "code": "][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive", "label": 0}, {"snippet_id": 8575, "code": ") os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists", "label": 1}, {"snippet_id": 30453, "code": " valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks", "label": 0}, {"snippet_id": 76641, "code": " \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random.randint(0, 9999999999))) return '\\n'.join(msg) def sbjfun(): return sup.randstr(1, 30) import argparse parser=argparse.ArgumentParser(add_help=True)", "label": 0}, {"snippet_id": 44802, "code": "*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames", "label": 0}, {"snippet_id": 85127, "code": " compiler_classpath(self, products): return self._tool_classpath('scalac', products) def style_classpath(self, products): return self._tool_classpath('scalastyle', products) @property def version(self): return", "label": 0}, {"snippet_id": 89925, "code": "} is too new; expecting no older than' '{} and got{}'.format(java, self._maximum_version, version)) self._bin_path=os.path.join(self.home, 'bin') try: self._validated_executable('javac') self._is_jdk=True", "label": 0}, {"snippet_id": 84683, "code": " text_type(tmpdir), ), ))[0] cloc_path, cloc_snapshot=ClocBinary.global_instance().hackily_snapshot(self.context) directory_digest=self.context._scheduler.merge_directories(tuple(s.directory_digest for", "label": 0}, {"snippet_id": 39441, "code": "*ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if", "label": 0}, {"snippet_id": 3751, "code": "] def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def", "label": 0}, {"snippet_id": 85287, "code": " JarLibrary, jars=jars, scope='forced') elif not build_graph.get_target(target_address).is_synthetic: raise build_graph.ManualSyntheticTargetError(target_address) @property def injectables_spec_mapping(self)", "label": 0}, {"snippet_id": 1654, "code": "=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else", "label": 0}, {"snippet_id": 10990, "code": "(url, e) raise HostUnreachableException(msg) except Timeout as e: msg=\"Connect timed out for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except RequestException as e: msg=\"Could not get", "label": 0}, {"snippet_id": 56316, "code": ".items(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters @require_GET def info(request): \"\"\"Ajax responder for misc information\"\"\" objects=_InfoObjects(request=request", "label": 1}, {"snippet_id": 13451, "code": "[\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code==201: data[\"pr_url\"]=r.json()[\"html_url\"]", "label": 0}, {"snippet_id": 36927, "code": ", *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message", "label": 0}, {"snippet_id": 52848, "code": "=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self", "label": 0}, {"snippet_id": 4918, "code": " don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record", "label": 0}, {"snippet_id": 24855, "code": "] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle", "label": 0}, {"snippet_id": 2996, "code": "]) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window", "label": 0}, {"snippet_id": 85840, "code": " from __future__ import absolute_import, division, print_function, unicode_literals import logging import os from builtins import str from future.utils import text_type from pants.backend.jvm import argfile", "label": 0}, {"snippet_id": 35463, "code": " in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os", "label": 0}, {"snippet_id": 69779, "code": " %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print", "label": 1}, {"snippet_id": 58199, "code": " **kwargs): objects.update(**kwargs) kwargs['instances']=objects if objects.model.__name__==TestCaseRun.__name__ and kwargs.get( 'case_run_status', None): POST_UPDATE_SIGNAL.send(sender=None, **kwargs)", "label": 0}, {"snippet_id": 85380, "code": " JarDependency from pants.subsystem.subsystem import Subsystem from pants.util.dirutil import fast_relpath from pants.util.memo import memoized_method, memoized_property class Zinc(object): \"\"\"Configuration for", "label": 1}, {"snippet_id": 13517, "code": " io=GPIO() io.setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def updateMouth():\r lastMouthEvent=0\r lastMouthEventTime=0\r \r while", "label": 0}, {"snippet_id": 18294, "code": "._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port)", "label": 1}, {"snippet_id": 48382, "code": " strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items", "label": 0}, {"snippet_id": 57158, "code": ".get_model(*ctype.split(\".\", 1)) targets=model._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s has no field", "label": 0}, {"snippet_id": 29619, "code": "\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 28174, "code": ":['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], ", "label": 0}, {"snippet_id": 65903, "code": "(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(", "label": 0}, {"snippet_id": 80492, "code": " associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys(): \t\ts.cookies[key]=args.cookies", "label": 0}, {"snippet_id": 33060, "code": ": \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules", "label": 0}, {"snippet_id": 22714, "code": "-access add{ all-partitions{ role admin}} shell bash\" %(username) retcode, out=shellutil.run_get_output(cmd, log_cmd=True, chk_err=True) if retcode !=0: raise OSUtilError( \"Failed to create user account:{0}", "label": 0}, {"snippet_id": 13156, "code": " ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json={ \"name\": name, \"description", "label": 0}, {"snippet_id": 40299, "code": ".compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files", "label": 0}, {"snippet_id": 93509, "code": "' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s", "label": 0}, {"snippet_id": 27014, "code": "'wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56:", "label": 0}, {"snippet_id": 61362, "code": " convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Default OpenQML plugin' short_name='default.qubit' api_version='0.1.0' version='0.1.0' author=", "label": 0}, {"snippet_id": 91984, "code": " PythonSetup.global_instance() def pydist_has_native_sources(self, target): return target.has_sources(extension=tuple(self._native_source_extensions)) @memoized_property def _native_target_matchers(self", "label": 0}, {"snippet_id": 60013, "code": "'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience", "label": 0}, {"snippet_id": 89592, "code": ".join(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version=_parse_java_version(\"minimum_version\", minimum_version) self._maximum_version=_parse_java_version(\"maximum_version\", maximum_version", "label": 0}, {"snippet_id": 75064, "code": " self.p.log.info('Recvd page %s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log.info('Done, sending answer: %s', res) self.p.send_success_rep(reqid,[v.encode('utf-8') for v in res])", "label": 0}, {"snippet_id": 51436, "code": " flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, ", "label": 0}, {"snippet_id": 12769, "code": "(last_comment_id)) response=requests.patch(query, json={\"body\": comment}, headers=headers, auth=auth) def autopep8(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os", "label": 0}, {"snippet_id": 66441, "code": "(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os", "label": 1}, {"snippet_id": 17587, "code": "'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave", "label": 0}, {"snippet_id": 33995, "code": ".target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name)", "label": 0}, {"snippet_id": 37090, "code": ".norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self", "label": 0}, {"snippet_id": 212, "code": " }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete',", "label": 0}, {"snippet_id": 34062, "code": " integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda", "label": 0}, {"snippet_id": 16042, "code": ", 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData", "label": 0}, {"snippet_id": 38441, "code": " self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name", "label": 0}, {"snippet_id": 25597, "code": "(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp", "label": 0}, {"snippet_id": 1848, "code": "(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows", "label": 0}, {"snippet_id": 27635, "code": "\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state", "label": 0}, {"snippet_id": 309, "code": "(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address)", "label": 0}, {"snippet_id": 94892, "code": " csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch", "label": 1}, {"snippet_id": 11044, "code": ") mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y %H:%M:%S %Z').strftime('%s') if mtime else int(time()) else: msg=\"Request %s returned with status %s. I don't know how to handle that.\" %(url, response", "label": 0}, {"snippet_id": 64862, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import", "label": 0}, {"snippet_id": 2833, "code": ".nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name", "label": 0}, {"snippet_id": 94022, "code": ".node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res: if \"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep,", "label": 0}, {"snippet_id": 8098, "code": "=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text", "label": 0}, {"snippet_id": 9230, "code": " text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8", "label": 0}, {"snippet_id": 7406, "code": " return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER):", "label": 0}, {"snippet_id": 91726, "code": ".snapshot tgt_source_root=source_roots.find_by_path(maybe_source_target.address.spec_path) sources_snapshots_and_source_roots.append((tgt_snapshot, tgt_source_root)) all_sources_digests=yield[ Get( Digest", "label": 0}, {"snippet_id": 12761, "code": "/issues/comments/{}\" query=query.format(data[\"repository\"], str(last_comment_id)) response=requests.patch(query, json={\"body\": comment}, headers=headers, auth=auth) def autopep8(data, config): headers=", "label": 0}, {"snippet_id": 79831, "code": " complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution", "label": 0}, {"snippet_id": 55959, "code": " decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd", "label": 0}, {"snippet_id": 29849, "code": " matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value):", "label": 0}, {"snippet_id": 11640, "code": "(): arg=docopt(__doc__, version='0.1.0') start_time=datetime.now() try: file_name=MonitoringConfigGenerator(arg['URL'], arg['--debug'], arg['--targetdir'], arg['--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN", "label": 0}, {"snippet_id": 83918, "code": ".check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(", "label": 0}, {"snippet_id": 45610, "code": ": with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return", "label": 1}, {"snippet_id": 24840, "code": " data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 8593, "code": " words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os", "label": 1}, {"snippet_id": 58785, "code": " str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission Dinied.'}) def test_change_case_run_status(self): self.client.login( username=self.tester.username, password", "label": 0}, {"snippet_id": 7563, "code": " extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\"", "label": 0}, {"snippet_id": 24308, "code": " vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass", "label": 0}, {"snippet_id": 17502, "code": ": if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request", "label": 0}, {"snippet_id": 42629, "code": ", _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards", "label": 0}, {"snippet_id": 53095, "code": ".append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s", "label": 0}, {"snippet_id": 92641, "code": ", 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False) as path: self.assertTrue(os.path.exists(path), 'Temporary dir", "label": 0}, {"snippet_id": 3631, "code": " finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else:", "label": 0}, {"snippet_id": 75890, "code": ".sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0]) rslist.append(rs) msg=self.wz.make_req_msg(request[1][0], request[1][1]", "label": 0}, {"snippet_id": 83620, "code": " 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties", "label": 0}, {"snippet_id": 54414, "code": "\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import", "label": 0}, {"snippet_id": 93818, "code": "'name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" %", "label": 0}, {"snippet_id": 77131, "code": " socket %s', self.th_ba) self.th_back_sock=self.p.ctx.socket(zmq.ROUTER) self.th_back_sock.bind(self.th_ba) def init_pr_sock(self): self.log.info( 'Initializing interprocess signal socket %s', self.pr_sa", "label": 0}, {"snippet_id": 32905, "code": "[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config", "label": 0}, {"snippet_id": 36200, "code": "\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 90940, "code": "{}'.format(e)) options_scope='jvm-distributions' @classmethod def register_options(cls, register): super(DistributionLocator, cls).register_options(register) human_readable_os_aliases=', '.join('{}:[{}", "label": 0}, {"snippet_id": 12991, "code": ".environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked", "label": 0}, {"snippet_id": 77267, "code": ".info('Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self, wclass, count, args=(", "label": 0}, {"snippet_id": 22081, "code": " options is None: self.options=Options() self.options.verbosity=verbosity self.loader=dataloader.DataLoader() self.variable_manager=vars.VariableManager() self.inventory=inventory.Inventory( loader=self", "label": 0}, {"snippet_id": 79845, "code": "\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group", "label": 0}, {"snippet_id": 1851, "code": "=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[]", "label": 0}, {"snippet_id": 73059, "code": " folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp.nlst()", "label": 0}, {"snippet_id": 91755, "code": "), ) inits_digest=yield Get(InjectedInitDigest, Digest, sources_digest) all_input_digests=[ sources_digest, inits_digest.directory_digest, requirements_pex_response.output_directory_digest, ] merged_input_files", "label": 0}, {"snippet_id": 56388, "code": "'value'))) class _InfoObjects(object): def __init__(self, request, product_id=None): self.request=request try: self.product_id=int(product_id) except(ValueError, TypeError): self.product_id=0 def builds", "label": 0}, {"snippet_id": 38986, "code": " turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag", "label": 0}, {"snippet_id": 60178, "code": "(GaussianTransform, Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import", "label": 0}, {"snippet_id": 68517, "code": "% c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append", "label": 0}, {"snippet_id": 88362, "code": "(self, run_tracker): self._run_tracker=run_tracker def debug(self, *msg_elements): self._run_tracker.log(Report.DEBUG, *msg_elements) def info(self, *msg_elements): self._run_tracker.log(Report.INFO, *msg_elements", "label": 0}, {"snippet_id": 79622, "code": ")s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName", "label": 0}, {"snippet_id": 13450, "code": " data[\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code==201: data[\"pr_url\"]=r.json()[\"html_url", "label": 0}, {"snippet_id": 64172, "code": "): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file', None) if not remote_datatypes_config: log.warn(NO_REMOTE_DATATYPES_CONFIG) remote_datatypes_config=os.path.join(remote_galaxy_home", "label": 0}, {"snippet_id": 42656, "code": " return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput)", "label": 0}, {"snippet_id": 29825, "code": " for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 80353, "code": ") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print(\"", "label": 0}, {"snippet_id": 50339, "code": "(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority", "label": 0}, {"snippet_id": 85507, "code": "'org.scala-sbt', name='compiler-interface', rev=zinc_rev), ], main='no.such.main.Main', custom_rules=shader_rules) cls.register_jvm_tool(register, Zinc.ZINC_EXTRACTOR_TOOL_NAME, classpath=[ JarDependency(", "label": 1}, {"snippet_id": 95954, "code": " None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel", "label": 0}, {"snippet_id": 18889, "code": " import validate_request from flex.validation.response import validate_response def load_source(source): \"\"\" Common entry point for loading some form of raw swagger schema. Supports: -python object(dictionary", "label": 0}, {"snippet_id": 57954, "code": "'bugs']=request.GET.get('bug_id', '').split(',') data['runs']=map(int, request.GET.get('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs", "label": 0}, {"snippet_id": 48578, "code": " InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.", "label": 0}, {"snippet_id": 33834, "code": "=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self", "label": 0}, {"snippet_id": 72557, "code": " required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.", "label": 0}, {"snippet_id": 18797, "code": " expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript", "label": 0}, {"snippet_id": 84376, "code": "=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths()", "label": 0}, {"snippet_id": 50485, "code": " return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads", "label": 0}, {"snippet_id": 91135, "code": ".backend.python.pants_requirement import PantsRequirement from pants.backend.python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants", "label": 0}, {"snippet_id": 28443, "code": "=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\"", "label": 0}, {"snippet_id": 82340, "code": ".userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline", "label": 0}, {"snippet_id": 20928, "code": "._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still running') self._check_handlers() def _listen(self): try: for msg in self._conn.iter_messages", "label": 0}, {"snippet_id": 71387, "code": "\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 28175, "code": " 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':", "label": 0}, {"snippet_id": 86753, "code": "): try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) logger", "label": 0}, {"snippet_id": 13466, "code": " HERE FROM TWITTER'\r consumerSecret='INSERT YOUR CONSUMER SECRET HERE FROM TWITTER'\r accessTokenKey='INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR ACCESS TOKEN SECRET HERE", "label": 0}, {"snippet_id": 60290, "code": " Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock', 'X', 'P', 'Homodyne'} _circuits", "label": 0}, {"snippet_id": 38872, "code": " can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self", "label": 0}, {"snippet_id": 24053, "code": ".*(//'| sed -e 's/).*//'\".format(output) err, output=shellutil.run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible cmd_search_storvsc", "label": 0}, {"snippet_id": 25901, "code": " data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self", "label": 0}, {"snippet_id": 24091, "code": "=shellutil.run_get_output(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*(//'| sed -e 's/).*//'\".format(output)", "label": 0}, {"snippet_id": 78420, "code": " self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10) except exc.UnknownAnswer as e: self.log.warning('%s: %s', e, e.answer) self.w.sleep(self.errortimeout) except exc.PermanentError as", "label": 0}, {"snippet_id": 33590, "code": " dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag", "label": 0}, {"snippet_id": 81499, "code": "\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n", "label": 0}, {"snippet_id": 88215, "code": " return target.has_sources('.java') or target.has_sources('.scala') def select_source(self, source_file_path): return source_file_path.endswith('.java') or source_file_path.endswith('.scala') def execute", "label": 0}, {"snippet_id": 92324, "code": ".read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as(HORK=None): subprocess.Popen([sys.executable, '-c',", "label": 0}, {"snippet_id": 92996, "code": ".assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self", "label": 0}, {"snippet_id": 42715, "code": " self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of", "label": 0}, {"snippet_id": 48240, "code": " output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 14597, "code": " extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self)", "label": 0}, {"snippet_id": 39340, "code": " def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def", "label": 0}, {"snippet_id": 84205, "code": " ways for same reason -datatypes may not match. One can push the local datatypes config to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the", "label": 0}, {"snippet_id": 50331, "code": " to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority", "label": 0}, {"snippet_id": 41532, "code": ".touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule", "label": 0}, {"snippet_id": 77979, "code": " raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu(urls): for user, domain,", "label": 0}, {"snippet_id": 72173, "code": ") remote_parser.add_argument('command', nargs=utils.IRCParser.REMAINDER) @utils.add_cmd def remote(irc, source, args): \"\"\"<network>[--service <service name>] <command> Runs <command> on the remote network", "label": 0}, {"snippet_id": 87471, "code": ") zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala-path', ':'.join(scala_path)]) zinc_args.extend(self._javac_plugin_args(javac_plugin_map)) scalac_plugin_search_classpath", "label": 1}, {"snippet_id": 94006, "code": "=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current", "label": 0}, {"snippet_id": 81048, "code": ".status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable", "label": 0}, {"snippet_id": 4147, "code": " import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify", "label": 1}, {"snippet_id": 14750, "code": " _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self", "label": 0}, {"snippet_id": 83572, "code": " prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files", "label": 0}, {"snippet_id": 70380, "code": ".set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc", "label": 0}, {"snippet_id": 75623, "code": "''Exception to raise on suspend signal''' def __init__(self, interval, *args, **kvargs): self.interval=interval super().__init__(*args, **kvargs) class Resume(Exception): '''Exception to raise when suspend", "label": 0}, {"snippet_id": 15711, "code": " BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format(", "label": 0}, {"snippet_id": 79739, "code": "\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File", "label": 0}, {"snippet_id": 42170, "code": "._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason", "label": 0}, {"snippet_id": 92144, "code": "() for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires-pex' @classmethod def register_options(cls, register): super(BuildSetupRequiresPex", "label": 0}, {"snippet_id": 39497, "code": ", resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not", "label": 0}, {"snippet_id": 94518, "code": " check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check", "label": 0}, {"snippet_id": 38900, "code": " logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False", "label": 0}, {"snippet_id": 74886, "code": " the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is", "label": 0}, {"snippet_id": 93554, "code": ".session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host']", "label": 0}, {"snippet_id": 23493, "code": " shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user", "label": 0}, {"snippet_id": 14991, "code": "=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest,", "label": 0}, {"snippet_id": 16617, "code": "'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False)", "label": 0}, {"snippet_id": 38929, "code": " logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag", "label": 0}, {"snippet_id": 88504, "code": "\"\" return self._options @property def log(self): \"\"\"Returns the preferred logger for goals to use. :API: public \"\"\" return self._log @property def products(self): \"\"\"Returns the Products manager for the", "label": 0}, {"snippet_id": 41659, "code": ".shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell", "label": 0}, {"snippet_id": 95558, "code": " fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp=ftp.nlst() if", "label": 0}, {"snippet_id": 20694, "code": ".closed: raise RuntimeError('session closed') wait=args.pop('wait', False) req=self._create_request(command, **args) if self.VERBOSE: msg=parse_message(req) print(' <-', msg) if wait: with self.wait_for_response", "label": 0}, {"snippet_id": 59389, "code": "**kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs:", "label": 0}, {"snippet_id": 51997, "code": " def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError:", "label": 0}, {"snippet_id": 45954, "code": " flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type", "label": 0}, {"snippet_id": 8093, "code": " in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig", "label": 0}, {"snippet_id": 76294, "code": " for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def", "label": 0}, {"snippet_id": 27211, "code": "'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, ", "label": 0}, {"snippet_id": 39661, "code": " def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return", "label": 0}, {"snippet_id": 86667, "code": " for pattern, has_argument in valid_patterns.items(): if pattern.match(arg): return 2 if has_argument else 1 log.warn(\"Zinc argument '{}' is not supported, and is subject to change/removal!\".format(arg", "label": 0}, {"snippet_id": 49444, "code": "=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict()", "label": 0}, {"snippet_id": 95453, "code": " remote_subdirs_list=None): \"\"\" Recursive function that automatically downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory", "label": 0}, {"snippet_id": 26979, "code": "': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High", "label": 0}, {"snippet_id": 42654, "code": "(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, *", "label": 0}, {"snippet_id": 10248, "code": " kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie", "label": 0}, {"snippet_id": 50539, "code": "=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 84705, "code": "/bin/perl', cloc_path, '--skip-uniqueness', '--ignored=ignored', '--list-file=input_files_list', '--report-file=report', ) req=ExecuteProcessRequest( argv=cmd, input_files=directory_digest, output_files=(", "label": 0}, {"snippet_id": 54139, "code": " self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return", "label": 0}, {"snippet_id": 42830, "code": ".input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 4390, "code": " list of strings :param text_lines: list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw", "label": 1}, {"snippet_id": 67949, "code": " Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet", "label": 0}, {"snippet_id": 37571, "code": " in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item", "label": 0}, {"snippet_id": 85105, "code": "'scalastyle') def _tool_classpath(self, tool, products): \"\"\"Return the proper classpath based on products and scala version.\"\"\" return self.tool_classpath_from_products(products, self._key_for_tool_version(tool,", "label": 1}, {"snippet_id": 9190, "code": "(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader", "label": 0}, {"snippet_id": 71018, "code": "(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted", "label": 0}, {"snippet_id": 72210, "code": ".checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args(args) netname=args.network if netname==irc.name: irc.error(\"Cannot remote-send a command to the local network; use a normal command!\")", "label": 0}, {"snippet_id": 33167, "code": ", ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes", "label": 0}, {"snippet_id": 69319, "code": "* from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes", "label": 0}, {"snippet_id": 14046, "code": "'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData", "label": 0}, {"snippet_id": 26769, "code": "=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data[", "label": 0}, {"snippet_id": 65101, "code": " Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler):", "label": 0}, {"snippet_id": 93804, "code": "]) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window", "label": 0}, {"snippet_id": 23451, "code": "-m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode !=0: raise OSUtilError((\"Failed to create user account:{0}, \" \"retcode", "label": 0}, {"snippet_id": 86189, "code": ")] javac_cmd.extend([ '-classpath', ':'.join(classpath), ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with ", "label": 0}, {"snippet_id": 65539, "code": " system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR:", "label": 0}, {"snippet_id": 75343, "code": " iden, msg, interface, method): try: handler=self.sig_handlers[(interface, method)] except KeyError: raise WZENoHandler(iden, 'No handler for sig %s,%s'%(interface, method)) handler(interface, method, msg", "label": 0}, {"snippet_id": 71474, "code": " from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client", "label": 0}, {"snippet_id": 62008, "code": " Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If", "label": 0}, {"snippet_id": 93693, "code": " in line\" % comp['name']) else: self.logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self", "label": 0}, {"snippet_id": 60443, "code": " context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix", "label": 0}, {"snippet_id": 45700, "code": " __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(", "label": 0}, {"snippet_id": 79071, "code": "\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern+\"$captGroup$\"", "label": 0}, {"snippet_id": 8921, "code": "=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined", "label": 1}, {"snippet_id": 10922, "code": " def read_config(uri): uri_parsed=urlparse.urlparse(uri) if is_file(uri_parsed): return read_config_from_file(uri_parsed.path) elif is_host(uri_parsed): return read_config_from_host(uri) else: raise ValueError", "label": 0}, {"snippet_id": 71225, "code": ") elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled", "label": 0}, {"snippet_id": 52617, "code": "\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property", "label": 0}, {"snippet_id": 22313, "code": " class BigIpOSUtil(DefaultOSUtil): def __init__(self): super(BigIpOSUtil, self).__init__() def _wait_until_mcpd_is_initialized(self): \"\"\"Wait for mcpd to become available All configuration happens in mcpd", "label": 0}, {"snippet_id": 57222, "code": "=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception", "label": 0}, {"snippet_id": 38723, "code": "=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait", "label": 0}, {"snippet_id": 27343, "code": " pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found',", "label": 1}, {"snippet_id": 9409, "code": ", categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords, _kw(_sort_kw_matches", "label": 0}, {"snippet_id": 77732, "code": " def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru' and t['forum']=='anonymous': try: add_target_exc(t['id'], t['user']) except ValueError: pass def terminate(self): msg=[b", "label": 0}, {"snippet_id": 26149, "code": " cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature", "label": 1}, {"snippet_id": 8584, "code": "\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory", "label": 1}, {"snippet_id": 34770, "code": ".file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f:", "label": 0}, {"snippet_id": 63260, "code": " except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper", "label": 0}, {"snippet_id": 1623, "code": "(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\"", "label": 0}, {"snippet_id": 21200, "code": ") self.req=req self._result_getter=result_getter @property def resp(self): return self._result_getter() class AwaitableEvent(Awaitable): def __init__(self, name, result_getter, event=None): super(AwaitableEvent", "label": 0}, {"snippet_id": 7026, "code": " representing the keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords", "label": 0}, {"snippet_id": 49550, "code": " allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as", "label": 0}, {"snippet_id": 17925, "code": "( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return", "label": 1}, {"snippet_id": 57156, "code": ") model=apps.get_model(*ctype.split(\".\", 1)) targets=model._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s", "label": 0}, {"snippet_id": 68688, "code": ">=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target", "label": 0}, {"snippet_id": 53542, "code": " products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"", "label": 0}, {"snippet_id": 20273, "code": ", *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ filename, ", "label": 0}, {"snippet_id": 32651, "code": "\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self,", "label": 0}, {"snippet_id": 67973, "code": ", MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start", "label": 0}, {"snippet_id": 95833, "code": " output directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted", "label": 0}, {"snippet_id": 35197, "code": " flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, ", "label": 0}, {"snippet_id": 76747, "code": "'http_request conlimit') parser.add_argument('--noproxy-timeout', type=int, default=5, help='noproxy_rp timeout') parser.add_argument('--caprate_minp', type=int, default=5, help='Cap rate minimum possible", "label": 0}, {"snippet_id": 39878, "code": ".workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self", "label": 0}, {"snippet_id": 60575, "code": " _observables={'Fock', 'X', 'P', 'Homodyne', 'Heterodyne'} _circuits={} def __init__(self, wires, *, shots=0, hbar=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name", "label": 0}, {"snippet_id": 74278, "code": ">] and the corresponding values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string", "label": 0}, {"snippet_id": 36776, "code": "(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self", "label": 0}, {"snippet_id": 24594, "code": " self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] ", "label": 0}, {"snippet_id": 9399, "code": " _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions[s](complete_output, categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw", "label": 0}, {"snippet_id": 93162, "code": " subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message", "label": 0}, {"snippet_id": 25870, "code": "=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle", "label": 0}, {"snippet_id": 26940, "code": "'GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)", "label": 0}, {"snippet_id": 3075, "code": " comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def", "label": 1}, {"snippet_id": 9822, "code": ". :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms", "label": 0}, {"snippet_id": 52214, "code": " format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs", "label": 0}, {"snippet_id": 5282, "code": " :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean", "label": 0}, {"snippet_id": 41736, "code": ".rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list", "label": 0}, {"snippet_id": 9919, "code": "{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires", "label": 0}, {"snippet_id": 93401, "code": "]]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']:", "label": 0}, {"snippet_id": 24405, "code": " pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the", "label": 0}, {"snippet_id": 1774, "code": "=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse", "label": 0}, {"snippet_id": 7819, "code": "(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def", "label": 0}, {"snippet_id": 83129, "code": " misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote", "label": 0}, {"snippet_id": 25079, "code": " API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData", "label": 1}, {"snippet_id": 41509, "code": "=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_", "label": 0}, {"snippet_id": 32082, "code": " SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output:", "label": 0}, {"snippet_id": 88339, "code": " mapping of products a goal creates to the targets the products are associated with. :API: public \"\"\" class Log(object): \"\"\"A logger facade that logs into the pants reporting framework.\"\"\" def __init__", "label": 0}, {"snippet_id": 50232, "code": " self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule", "label": 0}, {"snippet_id": 78218, "code": " rate): if not self.logined: self._capdata=(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self): for t in self.targets: self.schedule", "label": 0}, {"snippet_id": 23916, "code": "-1: inet=line.split()[1] elif line.find('ether ') !=-1: mac=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id", "label": 0}, {"snippet_id": 84385, "code": "=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config.working_directory()", "label": 0}, {"snippet_id": 62623, "code": " OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set", "label": 0}, {"snippet_id": 1981, "code": ") elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows:", "label": 0}, {"snippet_id": 34450, "code": ".path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self", "label": 0}, {"snippet_id": 32334, "code": "(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input", "label": 0}, {"snippet_id": 22698, "code": ".get_userentry(username): logger.info(\"User{0} already exists, skip useradd\", username) return None cmd=\"/usr/bin/tmsh create auth user %s partition-access add{ all-partitions{ role admin}} shell bash\" %", "label": 0}, {"snippet_id": 56381, "code": "(serializers.serialize('json', info_type(), fields=('name', 'value'))) class _InfoObjects(object): def __init__(self, request, product_id=None): self.request=request try: self.product_id=int(product_id) except", "label": 0}, {"snippet_id": 89736, "code": " return list(collect_existing_libs()) @property def home(self): \"\"\"Returns the distribution JAVA_HOME.\"\"\" if not self._home: home=self._get_system_properties(self.java)['java.home'] if os.path.basename(home)", "label": 0}, {"snippet_id": 62727, "code": " \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables", "label": 0}, {"snippet_id": 3922, "code": " the setup specified by the --config argument\") subparser_remote=subparsers.add_parser('slave', help=\"Run a component locally without controlling it. The \" \"control is taken care of the remote master invoking", "label": 0}, {"snippet_id": 81132, "code": "\"name\"] \t\tself.logger.debug(\"Found the following file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\"", "label": 0}, {"snippet_id": 28063, "code": " self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES)", "label": 1}, {"snippet_id": 39657, "code": " return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo):", "label": 0}, {"snippet_id": 52078, "code": " try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load", "label": 0}, {"snippet_id": 4686, "code": " Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return", "label": 0}, {"snippet_id": 16762, "code": ".add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory", "label": 0}, {"snippet_id": 56653, "code": ")).order_by('tag') plan_counter=_TagCounter('num_plans', test_plan_tags) case_counter=_TagCounter('num_cases', test_case_tags) run_counter=_TagCounter('num_runs', test_run_tags) for tag in all_tags: tag", "label": 0}, {"snippet_id": 49876, "code": " True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence", "label": 0}, {"snippet_id": 33, "code": " from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager", "label": 1}, {"snippet_id": 76104, "code": ".name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m])) def set_route_type(self, i, m, t): self.log.debug('Setting %s,%s", "label": 0}, {"snippet_id": 28004, "code": " elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data", "label": 0}, {"snippet_id": 22255, "code": "(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template(template, data) ) runner=Runner(playbook=playbook, verbosity=0) stats=runner.run(job_id=context.last_job_id", "label": 0}, {"snippet_id": 46421, "code": " last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self", "label": 0}, {"snippet_id": 37816, "code": "(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards", "label": 0}, {"snippet_id": 9853, "code": " :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output", "label": 0}, {"snippet_id": 79634, "code": ") templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done", "label": 0}, {"snippet_id": 77058, "code": " *args, **kvargs): super().__init__(*args, **kvargs) self.newproxyfile='newproxies.txt' self.proxylist=set() self.c=config self.threads=[] self.processes=[] self.th_sa='inproc://wm-wth.sock' self.th_ba", "label": 0}, {"snippet_id": 11879, "code": " str(signature)): abort(403) return True def check_pythonic_pr(data): \"\"\" Return True if the PR contains at least one Python file \"\"\" files=list(get_files_involved_in_pr(data).keys()) pythonic=False for", "label": 0}, {"snippet_id": 9377, "code": " in single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit", "label": 0}, {"snippet_id": 14664, "code": "()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport", "label": 0}, {"snippet_id": 26554, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise':", "label": 0}, {"snippet_id": 10704, "code": " document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d", "label": 1}, {"snippet_id": 74098, "code": "\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to integer.\")", "label": 0}, {"snippet_id": 5335, "code": " spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches", "label": 0}, {"snippet_id": 40154, "code": " lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall", "label": 1}, {"snippet_id": 31584, "code": "=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles", "label": 0}, {"snippet_id": 39292, "code": "(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print", "label": 0}, {"snippet_id": 25431, "code": ".netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement", "label": 0}, {"snippet_id": 36832, "code": "\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input", "label": 0}, {"snippet_id": 58453, "code": "'response': 'Comments needed'}) def test_refuse_if_missing_no_case_run_pk(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, ", "label": 0}, {"snippet_id": 44389, "code": "\" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input", "label": 0}, {"snippet_id": 79542, "code": "\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode", "label": 0}, {"snippet_id": 34503, "code": "\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]), path)", "label": 0}, {"snippet_id": 91906, "code": ") class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope='python-native-code' default_native_source_extensions=['.c', '", "label": 0}, {"snippet_id": 61649, "code": ".warning('Nonvanishing imaginary part{} in expectation value.'.format(expectation.imag)) return expectation.real def reset(self): \"\"\"Reset the device\"\"\" self._state =None self._out=None def expand_one(self", "label": 0}, {"snippet_id": 82711, "code": "\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass ", "label": 0}, {"snippet_id": 50755, "code": " os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError", "label": 1}, {"snippet_id": 88838, "code": " as workunit: yield workunit def acquire_lock(self): \"\"\" Acquire the global lock for the root directory associated with this context. When a goal requires serialization, it will call this to acquire the", "label": 0}, {"snippet_id": 52146, "code": " level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P", "label": 0}, {"snippet_id": 51320, "code": ") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing:", "label": 0}, {"snippet_id": 28211, "code": "'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None", "label": 0}, {"snippet_id": 34380, "code": ".threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow", "label": 0}, {"snippet_id": 29083, "code": " Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600)", "label": 1}, {"snippet_id": 61531, "code": "=np.random.binomial(self.shots, p0) ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A", "label": 0}, {"snippet_id": 25264, "code": " 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None", "label": 0}, {"snippet_id": 10631, "code": " @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 ", "label": 0}, {"snippet_id": 1861, "code": " cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem", "label": 0}, {"snippet_id": 75396, "code": " args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface, method, args, fun, reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer): iden=self", "label": 0}, {"snippet_id": 34098, "code": ".resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule", "label": 0}, {"snippet_id": 8807, "code": "('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path", "label": 0}, {"snippet_id": 30692, "code": " if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input:", "label": 0}, {"snippet_id": 39054, "code": "(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items", "label": 0}, {"snippet_id": 49312, "code": ") if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards,", "label": 0}, {"snippet_id": 82096, "code": ",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs", "label": 0}, {"snippet_id": 54882, "code": " self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items)", "label": 0}, {"snippet_id": 7387, "code": " tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw])", "label": 0}, {"snippet_id": 5565, "code": "[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var", "label": 0}, {"snippet_id": 94178, "code": "-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path", "label": 0}, {"snippet_id": 29583, "code": ": f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear", "label": 0}, {"snippet_id": 75128, "code": " rebinding'. format(wzrpc.name_status(status))) self.p.auth_requests() self.p.bind_methods() elif status==wzrpc.status.e_timeout: self.p.log.warn('Keepalive timeout') else: self.p.log.warn('Keepalive status{0", "label": 0}, {"snippet_id": 43400, "code": " ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular", "label": 0}, {"snippet_id": 28720, "code": "='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 94179, "code": "-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=", "label": 0}, {"snippet_id": 68433, "code": " len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status", "label": 0}, {"snippet_id": 42050, "code": ",)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException", "label": 0}, {"snippet_id": 90091, "code": ".path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{} executable,{} does not", "label": 0}, {"snippet_id": 19399, "code": "-DEBUG_RECORD_SOCKET_READS', '--cmd-line', '--module', '--multiproc', '--multiprocess', '--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support", "label": 0}, {"snippet_id": 17992, "code": " handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession", "label": 0}, {"snippet_id": 24082, "code": "} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed", "label": 0}, {"snippet_id": 33463, "code": "--unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets", "label": 0}, {"snippet_id": 59909, "code": " Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset", "label": 0}, {"snippet_id": 82722, "code": "=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif", "label": 0}, {"snippet_id": 42270, "code": ".append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s)", "label": 0}, {"snippet_id": 10974, "code": "'%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except", "label": 0}, {"snippet_id": 61878, "code": " the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()\t", "label": 0}, {"snippet_id": 89337, "code": " from pants.java.util import execute_java, execute_java_async from pants.subsystem.subsystem import Subsystem from pants.util.contextutil import temporary_dir from pants.util.memo import memoized_method", "label": 0}, {"snippet_id": 6383, "code": " for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import", "label": 0}, {"snippet_id": 25202, "code": "'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl", "label": 0}, {"snippet_id": 71612, "code": ".install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not", "label": 0}, {"snippet_id": 27324, "code": " discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try:", "label": 1}, {"snippet_id": 4923, "code": " reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag=\"001\"", "label": 0}, {"snippet_id": 89727, "code": ".exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate{} library'.format(name)) return list(collect_existing_libs()) @property def home(self): \"\"\"Returns the distribution", "label": 0}, {"snippet_id": 76546, "code": " WZWorkerProcess(WZWorkerBase, multiprocessing.Process): def start(self, sig_addr, *args, **kvargs): self.sig_addr=sig_addr multiprocessing.Process.start(self, *args, **kvargs) def __sinit__(self): self", "label": 0}, {"snippet_id": 10710, "code": " line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb", "label": 1}, {"snippet_id": 75641, "code": " Resume(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=(), kvargs={}, name=None, start_timer=None, poll_timeout=None, pargs=", "label": 0}, {"snippet_id": 1574, "code": "\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save()", "label": 0}, {"snippet_id": 21921, "code": " vault_password_files=None, new_vault_password_file=None, output_file=None, tags=None, skip_tags=None, one_line=None, tree=None, ask_sudo_pass=None, ask_su_pass=None, sudo=None, sudo_user=None, become=None, become_method", "label": 0}, {"snippet_id": 10159, "code": " i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches:", "label": 0}, {"snippet_id": 61835, "code": " z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1.6,[0]) qm.RY(y,[1]) qm.CNOT([1, 0]) qm.RX(z,[0]) qm.CNOT([0, 1]) qm.expectation.Hermitian(np.array([[0, 1],[1, 0]]), 0) circuits={'demo_ev': QNode(node, dev)}", "label": 0}, {"snippet_id": 53974, "code": ".allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item", "label": 0}, {"snippet_id": 53737, "code": " may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only", "label": 0}, {"snippet_id": 55614, "code": ".load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir", "label": 0}, {"snippet_id": 19507, "code": " for arg in argv: if arg=='-h' or arg=='--help': return argv,[], script gottarget=False skip=0 for i in range(len(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except IndexError:", "label": 0}, {"snippet_id": 80875, "code": "\t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown", "label": 0}, {"snippet_id": 82460, "code": " needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser", "label": 0}, {"snippet_id": 27376, "code": " variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for", "label": 0}, {"snippet_id": 36569, "code": "\"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self", "label": 0}, {"snippet_id": 82690, "code": "--proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds[\"username\"] \t\tproxyPass=args.proxyCreds[\"password\"] \telse: \t\tproxyUser=args.proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol", "label": 0}, {"snippet_id": 92735, "code": "=FakeClock() with Timer(clock=clock) as t: self.assertLess(t.start, clock.time()) self.assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t.elapsed, 0.1) clock.sleep(0.1) self.assertTrue(t", "label": 0}, {"snippet_id": 3108, "code": " hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s", "label": 0}, {"snippet_id": 91070, "code": ".warning('Multiple OS names alias to \"{}\"; combining results.'.format(rename)) normalized[rename].extend(paths) else: normalized[rename]=paths return normalized def _get_explicit_jdk_paths(self): if not", "label": 0}, {"snippet_id": 53362, "code": " enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in", "label": 1}, {"snippet_id": 22486, "code": "=False) def unregister_agent_service(self): return shellutil.run(\"/sbin/chkconfig --del waagent\", chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"/sbin/pidof dhclient\") return ret[1]", "label": 0}, {"snippet_id": 30429, "code": " ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError", "label": 0}, {"snippet_id": 65278, "code": "=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost", "label": 0}, {"snippet_id": 66519, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None", "label": 0}, {"snippet_id": 80254, "code": " \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger", "label": 0}, {"snippet_id": 87937, "code": " list of plugin classpath entries. The first entry in each list is the classpath entry containing the plugin metadata. The rest are the internal transitive deps of the plugin. This allows us to have in", "label": 0}, {"snippet_id": 68314, "code": ".LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout", "label": 0}, {"snippet_id": 1266, "code": "-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"", "label": 0}, {"snippet_id": 57190, "code": "=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), value ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model,", "label": 0}, {"snippet_id": 60372, "code": "(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self", "label": 0}, {"snippet_id": 83074, "code": " from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time", "label": 0}, {"snippet_id": 74704, "code": ".chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value", "label": 0}, {"snippet_id": 40799, "code": " **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format", "label": 0}, {"snippet_id": 20194, "code": "._run_server_ex=None def run(): try: self._session=self.SESSION.create_server(addr, **kwargs) except Exception as ex: self._run_server_ex=traceback.format_exc() t=new_hidden_thread( target=run, name='test.client'", "label": 0}, {"snippet_id": 8543, "code": "(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL", "label": 1}, {"snippet_id": 81777, "code": " \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server", "label": 0}, {"snippet_id": 10616, "code": " local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document", "label": 1}, {"snippet_id": 93960, "code": "'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name", "label": 0}, {"snippet_id": 23066, "code": " overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make when mounting the provisioningiso.iso DVD :param chk_err", "label": 0}, {"snippet_id": 12853, "code": "{}/{}\" url=url.format(data[\"repository\"], data[\"sha\"], file) r=requests.get(url, headers=headers, auth=auth) with open(\"file_to_fix.py\", 'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text", "label": 0}, {"snippet_id": 19746, "code": "'filename') if module is None: args.name=filename args.kind='script' else: args.name=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs): if nodebug: run_main", "label": 0}, {"snippet_id": 25721, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500:", "label": 0}, {"snippet_id": 11173, "code": " lines @staticmethod def parse(file_name): etag, mtime=None, 0 def extract(comment, current_value): value=None if line.startswith(comment): value=line.rstrip()[len(comment):] return value or current_value", "label": 0}, {"snippet_id": 94196, "code": " self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger", "label": 0}, {"snippet_id": 20013, "code": "(self): if self._session is not None: try: self._session.close() except ClosedError: pass if self._adapter is not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script", "label": 0}, {"snippet_id": 5736, "code": "(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len", "label": 0}, {"snippet_id": 74787, "code": "(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and", "label": 0}, {"snippet_id": 32376, "code": "[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if", "label": 0}, {"snippet_id": 70999, "code": "(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type", "label": 0}, {"snippet_id": 53729, "code": "): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif", "label": 0}, {"snippet_id": 24770, "code": "=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0", "label": 0}, {"snippet_id": 4159, "code": " encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER", "label": 0}, {"snippet_id": 92178, "code": " setuptools version to use when executing `setup.py` scripts.') register('--wheel-version', advanced=True, fingerprint=True, default='0.32.3', help='The wheel version to use when executing `setup.py` scripts.')", "label": 0}, {"snippet_id": 3143, "code": "['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name", "label": 0}, {"snippet_id": 93382, "code": "=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp)", "label": 0}, {"snippet_id": 12391, "code": "] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8 issues in", "label": 0}, {"snippet_id": 68044, "code": " Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self", "label": 0}, {"snippet_id": 61439, "code": "'QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError('State vector must be of length 2**wires.') continue", "label": 0}, {"snippet_id": 13209, "code": ".format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) sha=None r=requests.get(url, headers=headers", "label": 0}, {"snippet_id": 51971, "code": " items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def", "label": 0}, {"snippet_id": 88083, "code": ") active_plugins[name]=rel_classpath_elements if len(active_plugins)==len(plugin_names): return active_plugins unresolved_plugins=plugin_names -set(active_plugins.keys()) raise TaskError('Could not find", "label": 0}, {"snippet_id": 151, "code": " row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\"", "label": 1}, {"snippet_id": 13263, "code": ": \"refs/heads/{}\".format(data[\"new_branch\"]), \"sha\": sha, } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not create new branch in the", "label": 0}, {"snippet_id": 11057, "code": " %s returned with status %s. I don't know how to handle that.\" %(url, response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime=mtime) class Header", "label": 0}, {"snippet_id": 69018, "code": ") if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount", "label": 0}, {"snippet_id": 59071, "code": ") group=EnvGroup.objects.get(pk=self.group_new.pk) expected_json=json.loads( serializers.serialize( 'json', group.property.all(), fields=('name', 'value'))) self.assertJSONEqual( str(response.content, encoding", "label": 0}, {"snippet_id": 84966, "code": " advanced=True, type=dict, default={}, fingerprint=True, help='Map from scalac plugin name to list of arguments for that plugin.') cls.register_jvm_tool(register, 'scalac-plugin-dep', classpath=[], help=", "label": 0}, {"snippet_id": 69622, "code": " /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new", "label": 0}, {"snippet_id": 43422, "code": " matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict()", "label": 0}, {"snippet_id": 32196, "code": "(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log", "label": 0}, {"snippet_id": 65447, "code": "(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed", "label": 0}, {"snippet_id": 31789, "code": ".items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return", "label": 0}, {"snippet_id": 60590, "code": " self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if", "label": 1}, {"snippet_id": 1302, "code": ".PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password", "label": 0}, {"snippet_id": 79588, "code": ",datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y", "label": 0}, {"snippet_id": 93046, "code": ", **PATCH_OPTS) as mock_signal: mock_signal.return_value=mock_initial_handler try: with signal_handler_as(signal.SIGUSR2, mock_new_handler): raise NotImplementedError('blah') except NotImplementedError", "label": 0}, {"snippet_id": 17360, "code": "-stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest", "label": 0}, {"snippet_id": 54978, "code": ".wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall", "label": 0}, {"snippet_id": 5788, "code": " given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"", "label": 0}, {"snippet_id": 44789, "code": ") update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow", "label": 0}, {"snippet_id": 52797, "code": ".output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists]", "label": 0}, {"snippet_id": 18206, "code": "' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines", "label": 0}, {"snippet_id": 43044, "code": "(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str", "label": 0}, {"snippet_id": 83609, "code": " str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper", "label": 0}, {"snippet_id": 22900, "code": "._save_sys_config() return ret def del_account(self, username): \"\"\"Deletes a user account. Note that the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc", "label": 0}, {"snippet_id": 33028, "code": " self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name", "label": 0}, {"snippet_id": 34624, "code": " def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os", "label": 1}, {"snippet_id": 22552, "code": " nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly valid name", "label": 0}, {"snippet_id": 7393, "code": " in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches", "label": 0}, {"snippet_id": 19101, "code": " request=normalize_request(raw_request) with ErrorDict(): validate_request(request=request, schema=schema) def validate_api_response(schema, raw_response, request_method='get', raw_request=None): \"\"\" Validate", "label": 0}, {"snippet_id": 20121, "code": " client(i.e. editor).\"\"\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self", "label": 0}, {"snippet_id": 56579, "code": ") def tags(request): \"\"\" Get tags for TestPlan, TestCase or TestRun \"\"\" tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a')", "label": 1}, {"snippet_id": 18853, "code": " ValidationError from flex.loading.definitions import( definitions_validator, ) from flex.loading.schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single", "label": 0}, {"snippet_id": 37219, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"", "label": 0}, {"snippet_id": 86640, "code": ") f.write(classname) @staticmethod def validate_arguments(log, whitelisted_args, args): \"\"\"Validate that all arguments match whitelisted regexes.\"\"\" valid_patterns={re.compile(p): v for p, v in whitelisted_args", "label": 0}, {"snippet_id": 93738, "code": " +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING", "label": 0}, {"snippet_id": 69270, "code": ".message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e", "label": 1}, {"snippet_id": 3597, "code": "=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running ", "label": 0}, {"snippet_id": 74670, "code": "()==\"auto\": self.alt_number=None elif isint(alt_number_str): self.alt_number=int(alt_number_str) else: raise TypeError(\"Invalid value provided for alt_number in configuration.\\n\" \"Expected: \\\"auto\\\" or", "label": 0}, {"snippet_id": 4814, "code": " style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p=_sort_kw_matches(composite_keywords) for w in single_keywords_p: categories", "label": 0}, {"snippet_id": 84613, "code": " of the specified targets. ' 'Unset to operate only on the specified targets.') register('--ignored', type=bool, fingerprint=True, help='Show information about files ignored by cloc.') def console_output", "label": 0}, {"snippet_id": 95621, "code": " with open(local_file, 'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all", "label": 0}, {"snippet_id": 63111, "code": "(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self", "label": 0}, {"snippet_id": 11183, "code": "=None if line.startswith(comment): value=line.rstrip()[len(comment):] return value or current_value try: with open(file_name, 'r') as config_file: for line in config_file.xreadlines(): etag=extract(Header", "label": 0}, {"snippet_id": 74323, "code": " with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been generated successfully.\") else", "label": 0}, {"snippet_id": 84344, "code": "]=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append(integrates_datatypes_config) metadata_kwds['datatypes_config", "label": 0}, {"snippet_id": 67150, "code": " nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\"", "label": 0}, {"snippet_id": 69491, "code": " for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command", "label": 0}, {"snippet_id": 10821, "code": ".mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else:", "label": 1}, {"snippet_id": 59603, "code": "(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self.eng is not", "label": 0}, {"snippet_id": 15121, "code": ": return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'", "label": 0}, {"snippet_id": 83068, "code": ".jobs import ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none", "label": 0}, {"snippet_id": 529, "code": "(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+'", "label": 0}, {"snippet_id": 44778, "code": " Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self,", "label": 0}, {"snippet_id": 10032, "code": " the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for", "label": 0}, {"snippet_id": 2844, "code": "%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state", "label": 0}, {"snippet_id": 21971, "code": ", syntax=None, diff=None, force_handlers=None, flush_cache=None, listtasks=None, listtags=None, module_path=None): self.verbosity=verbosity self.inventory=inventory self.listhosts=listhosts self.subset", "label": 0}, {"snippet_id": 6521, "code": " read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path", "label": 0}, {"snippet_id": 78591, "code": ".sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError", "label": 0}, {"snippet_id": 15070, "code": " future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return", "label": 0}, {"snippet_id": 54560, "code": "=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile", "label": 0}, {"snippet_id": 49873, "code": "(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list", "label": 0}, {"snippet_id": 72820, "code": " from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The path to create dirs/subdirs for :type path: str", "label": 1}, {"snippet_id": 81093, "code": " 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(", "label": 0}, {"snippet_id": 50450, "code": " def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo", "label": 0}, {"snippet_id": 63887, "code": " in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model", "label": 0}, {"snippet_id": 92335, "code": "'): with environment_as(HORK=None): subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\" in os.environ)'], stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def", "label": 0}, {"snippet_id": 78757, "code": "(url, request) for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not available:", "label": 0}, {"snippet_id": 9090, "code": " taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of", "label": 1}, {"snippet_id": 17958, "code": " if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method", "label": 1}, {"snippet_id": 28345, "code": " monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions", "label": 0}, {"snippet_id": 12923, "code": "/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON", "label": 0}, {"snippet_id": 493, "code": "=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else", "label": 0}, {"snippet_id": 44077, "code": "(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list(", "label": 0}, {"snippet_id": 27653, "code": " self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000:", "label": 0}, {"snippet_id": 73814, "code": "\"enabled\"]) if \"server\" in runtime_config.ftp: self.server=runtime_config.ftp[\"server\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp:", "label": 0}, {"snippet_id": 47305, "code": " check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This", "label": 0}, {"snippet_id": 51981, "code": "): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone", "label": 0}, {"snippet_id": 66318, "code": " tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout", "label": 0}, {"snippet_id": 90852, "code": ". Paths listed for this operating system in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely locations on the file system such as `/usr/lib/jvm` on Linux machines. :API: public", "label": 0}, {"snippet_id": 9735, "code": "[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results", "label": 0}, {"snippet_id": 48544, "code": " in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems", "label": 0}, {"snippet_id": 48177, "code": ".dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards", "label": 0}, {"snippet_id": 23097, "code": " return super(BigIpOSUtil, self).mount_dvd(**kwargs) def eject_dvd(self, chk_err=True): \"\"\"Runs the eject command to eject the provisioning DVD BIG-IP does not include an eject command. It is sufficient", "label": 0}, {"snippet_id": 4097, "code": "(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is", "label": 0}, {"snippet_id": 75535, "code": ", method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None): if not reqid: reqid=self.make_reqid() args", "label": 0}, {"snippet_id": 20303, "code": " argv.insert(0, '--nodebug') self._launch(argv, **kwargs) return self._adapter, self._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed')", "label": 0}, {"snippet_id": 2216, "code": "'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess", "label": 0}, {"snippet_id": 60531, "code": "): \"\"\"StrawberryFields Gaussian device for OpenQML. wires(int): the number of modes to initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The", "label": 0}, {"snippet_id": 87599, "code": ") as fp: for arg in zinc_args: fp.write(arg) fp.write(b'\\n') if self.execution_strategy==self.HERMETIC: zinc_relpath=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context", "label": 0}, {"snippet_id": 19883, "code": "') if self._session is not None: self._detach() try: self._adapter.close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self.closed: raise RuntimeError('debug client", "label": 0}, {"snippet_id": 41422, "code": ": self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards", "label": 0}, {"snippet_id": 28984, "code": " data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type==", "label": 0}, {"snippet_id": 7108, "code": "[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text,", "label": 0}, {"snippet_id": 8581, "code": " in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available", "label": 1}, {"snippet_id": 25847, "code": "'WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self", "label": 0}, {"snippet_id": 14311, "code": ", options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format", "label": 0}, {"snippet_id": 83822, "code": " method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query", "label": 0}, {"snippet_id": 89477, "code": " return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the", "label": 0}, {"snippet_id": 9122, "code": "],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number", "label": 0}, {"snippet_id": 78309, "code": ".log.warn('%s: %s', e, e.answer) self.schedule(self.add_comment,(t, msg)) except exc.Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as", "label": 0}, {"snippet_id": 60761, "code": " \"\"\"Return a new object of the same class, passing the attribute name as the first parameter, along with any additional parameters.\"\"\" return cls(name, *args, **kwargs) return new_object class DeviceError", "label": 0}, {"snippet_id": 33138, "code": " nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config", "label": 0}, {"snippet_id": 57134, "code": " field=str(field) value, error=get_value_by_type(value, vtype) if error: return say_no(error) has_perms=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied.') model=apps", "label": 0}, {"snippet_id": 23885, "code": " ifaces: raise OSUtilError(\"Can't find ether interface.\") iface=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0", "label": 0}, {"snippet_id": 63273, "code": " lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination", "label": 0}, {"snippet_id": 56001, "code": " decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None", "label": 0}, {"snippet_id": 54154, "code": ".benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params", "label": 0}, {"snippet_id": 90349, "code": "(_DistributionEnvironment): _STANDARD_JAVA_DIST_DIRS=('/usr/lib/jvm', '/usr/lib64/jvm') @classmethod def standard(cls): return cls(*cls._STANDARD_JAVA_DIST_DIRS) def __init__(self, *java_dist_dirs): if len(java_dist_dirs)=", "label": 0}, {"snippet_id": 54036, "code": " is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems", "label": 0}, {"snippet_id": 44223, "code": "() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence", "label": 0}, {"snippet_id": 18878, "code": " normalize_response, ) from flex.validation.common import validate_object from flex.validation.request import validate_request from flex.validation.response import validate_response def load_source(source)", "label": 0}, {"snippet_id": 80769, "code": " in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(", "label": 1}, {"snippet_id": 76797, "code": " help='Topic success timeout') parser.add_argument('--errortimeout', type=float, default=3, help='Error timeout') parser.add_argument('--stop-on-closed', action='store_true', default=False, help='Forget", "label": 0}, {"snippet_id": 1587, "code": ") print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name", "label": 0}, {"snippet_id": 84035, "code": ".get_command_line() job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the", "label": 0}, {"snippet_id": 57523, "code": " from your organization.') else: if resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids", "label": 0}, {"snippet_id": 39303, "code": "=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile,", "label": 0}, {"snippet_id": 53869, "code": " set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item", "label": 0}, {"snippet_id": 52324, "code": "=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output:", "label": 0}, {"snippet_id": 92613, "code": " test_temporary_dir_no_args(self): with temporary_dir() as path: self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self.assertTrue(os.path.isdir(path), 'Temporary dir should be a", "label": 0}, {"snippet_id": 29603, "code": " same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard", "label": 0}, {"snippet_id": 94494, "code": " amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp[", "label": 0}, {"snippet_id": 62049, "code": " Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator", "label": 0}, {"snippet_id": 71892, "code": " self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy", "label": 0}, {"snippet_id": 39491, "code": " named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority", "label": 0}, {"snippet_id": 60439, "code": " module contains the device class and context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import", "label": 0}, {"snippet_id": 57921, "code": "('pk') if not runs: return say_no('No caserun found.') add_comment(runs, comment, request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG", "label": 0}, {"snippet_id": 25850, "code": "=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value", "label": 0}, {"snippet_id": 4730, "code": "'author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False", "label": 0}, {"snippet_id": 10088, "code": "): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes", "label": 0}, {"snippet_id": 91367, "code": "'python_requirements': PythonRequirements, PantsRequirement.alias: PantsRequirement, } ) def register_goals(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local", "label": 0}, {"snippet_id": 32056, "code": " be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"):", "label": 0}, {"snippet_id": 13749, "code": "} def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr", "label": 0}, {"snippet_id": 48473, "code": " def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else:", "label": 0}, {"snippet_id": 36720, "code": " self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return", "label": 0}, {"snippet_id": 26899, "code": " data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self", "label": 0}, {"snippet_id": 1891, "code": " counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val)", "label": 0}, {"snippet_id": 43899, "code": ") if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards,", "label": 0}, {"snippet_id": 2060, "code": " userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action", "label": 0}, {"snippet_id": 27198, "code": "'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl", "label": 0}, {"snippet_id": 6700, "code": "; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs.", "label": 0}, {"snippet_id": 50787, "code": " return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile", "label": 0}, {"snippet_id": 44479, "code": ": items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs", "label": 0}, {"snippet_id": 22780, "code": " also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param username: The username", "label": 0}, {"snippet_id": 91373, "code": " PantsRequirement, } ) def register_goals(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local-dists', action=BuildLocalPythonDistributions).install('pyprep') task(name=", "label": 0}, {"snippet_id": 10330, "code": "\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords", "label": 0}, {"snippet_id": 89660, "code": " find_libs(self, names): \"\"\"Looks for jars in the distribution lib folder(s). If the distribution is a JDK, both the `lib` and `jre/lib` dirs will be scanned. The endorsed and extension dirs are not checked. ", "label": 0}, {"snippet_id": 33101, "code": ".docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local", "label": 0}, {"snippet_id": 35575, "code": " self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name", "label": 0}, {"snippet_id": 29541, "code": " set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path", "label": 0}, {"snippet_id": 59582, "code": " ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend", "label": 0}, {"snippet_id": 57269, "code": ") if t.tested_by !=request.user: field='tested_by' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), request.user ) ) field='assignee' try: assignee=t", "label": 0}, {"snippet_id": 36829, "code": "\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output", "label": 0}, {"snippet_id": 2872, "code": " state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component", "label": 0}, {"snippet_id": 9199, "code": ",[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords", "label": 0}, {"snippet_id": 2822, "code": " cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node", "label": 0}, {"snippet_id": 54980, "code": " latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles,", "label": 0}, {"snippet_id": 70097, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(", "label": 0}, {"snippet_id": 80688, "code": " up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog", "label": 0}, {"snippet_id": 70656, "code": ".install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug", "label": 0}, {"snippet_id": 57534, "code": ".') def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids=map(int, self.request.POST.getlist('case')) self._update_objects=TestCase.objects.filter(pk__in=case_ids) return", "label": 0}, {"snippet_id": 51708, "code": "=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames):", "label": 0}, {"snippet_id": 82904, "code": "=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime", "label": 1}, {"snippet_id": 78354, "code": ".errortimeout) except exc.PermanentError as e: try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception(e) self.w.sleep(self", "label": 0}, {"snippet_id": 82646, "code": ".data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys(): \t\ts.cookies[key]=args.cookies[key] s.headers={'User-Agent':args.userAgent} s.trust_env=False if args.proxy: \tif args.proxy[", "label": 0}, {"snippet_id": 80711, "code": ".startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\"", "label": 0}, {"snippet_id": 27940, "code": " data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 48073, "code": ".setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files.", "label": 0}, {"snippet_id": 64274, "code": "._wrapper_output_paths results=[] for local_output_path in local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite( wrapper_path) results.append( self", "label": 0}, {"snippet_id": 7078, "code": " number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p", "label": 0}, {"snippet_id": 64345, "code": "( self): return self._sep def version_path( self): return self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites", "label": 0}, {"snippet_id": 44878, "code": " ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args,", "label": 0}, {"snippet_id": 74945, "code": "\"]) if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config", "label": 1}, {"snippet_id": 81735, "code": ",datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M", "label": 0}, {"snippet_id": 64190, "code": "=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append(integrates_datatypes_config) metadata_kwds['datatypes_config']", "label": 0}, {"snippet_id": 69202, "code": " in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd", "label": 0}, {"snippet_id": 78691, "code": ".argv) log.logger.debug('Executing locally') return self.execute() except BaseException as e: log.logger.exception(e) if log.logger.getEffectiveLevel() <=logging.DEBUG: if os.getenv('UNITTEST', 'False')==", "label": 0}, {"snippet_id": 84506, "code": "._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[ parameter_value]", "label": 0}, {"snippet_id": 69968, "code": " -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\"", "label": 0}, {"snippet_id": 60467, "code": " Squeezed, Thermal, Gaussian) from strawberryfields.ops import(GaussianTransform, Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate", "label": 0}, {"snippet_id": 79565, "code": "[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms", "label": 0}, {"snippet_id": 50598, "code": " RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources", "label": 0}, {"snippet_id": 5555, "code": "'*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return", "label": 0}, {"snippet_id": 67421, "code": " RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self)", "label": 0}, {"snippet_id": 90755, "code": "(home_path=location.home_path, bin_path=location.bin_path, minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) dist.validate() logger.debug('Located{} for constraints: minimum_version{},", "label": 0}, {"snippet_id": 35205, "code": " \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are", "label": 0}, {"snippet_id": 92477, "code": " test_nested_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2:", "label": 0}, {"snippet_id": 77118, "code": "(zmq.PUB) self.th_sock.bind(self.th_sa) def init_th_back_sock(self): self.log.info( 'Initializing intraprocess backward socket %s', self.th_ba) self.th_back_sock=self.p.ctx.socket(zmq.ROUTER) self.th_back_sock", "label": 0}, {"snippet_id": 29856, "code": ": if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards)", "label": 0}, {"snippet_id": 44796, "code": " def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self", "label": 0}, {"snippet_id": 80426, "code": "\t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print", "label": 0}, {"snippet_id": 94172, "code": " server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config", "label": 0}, {"snippet_id": 58304, "code": ".factories import EnvPropertyFactory class TestNavigation(test.TestCase): @classmethod def setUpTestData(cls): super(TestNavigation, cls).setUpTestData() cls.user=UserFactory(email='user+1@example.com'", "label": 0}, {"snippet_id": 33200, "code": "=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False", "label": 0}, {"snippet_id": 74529, "code": "\" in runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config", "label": 0}, {"snippet_id": 9655, "code": " keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml", "label": 0}, {"snippet_id": 8295, "code": "): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \"", "label": 1}, {"snippet_id": 77142, "code": " def init_pr_sock(self): self.log.info( 'Initializing interprocess signal socket %s', self.pr_sa) self.pr_sock=self.p.ctx.socket(zmq.PUB) self.pr_sock.bind(self.pr_sa) def init_pr_back_sock(self): self", "label": 0}, {"snippet_id": 7693, "code": " expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list", "label": 0}, {"snippet_id": 84534, "code": " division, print_function, unicode_literals import os from builtins import open from future.utils import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants.base", "label": 0}, {"snippet_id": 81853, "code": "\"\", type=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument", "label": 0}, {"snippet_id": 86758, "code": ".preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) logger.debug('Substituting \"$JAVA_HOME", "label": 0}, {"snippet_id": 83021, "code": "\t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown", "label": 0}, {"snippet_id": 94279, "code": "\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name", "label": 0}, {"snippet_id": 75060, "code": " domain, page=data self.p.log.info('Recvd page %s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log.info('Done, sending answer: %s', res) self.p.send_success_rep(reqid,[v.encode('utf", "label": 0}, {"snippet_id": 42881, "code": " may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow", "label": 0}, {"snippet_id": 23318, "code": " port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in here because BIG-IP may not have yet initialized this list of devices. :param port_id: :return: \"\"\" for retries in range(1, 100)", "label": 0}, {"snippet_id": 31321, "code": ".dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self", "label": 0}, {"snippet_id": 45120, "code": " decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs", "label": 0}, {"snippet_id": 30308, "code": " getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index", "label": 0}, {"snippet_id": 19059, "code": ", **kwargs): \"\"\" Given the python representation of a JSONschema as defined in the swagger spec, validate that the schema complies to spec. If `target` is provided, that target will be validated against", "label": 0}, {"snippet_id": 92448, "code": "(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir) as path: self.assertEqual(tempdir, path) self.assertEqual(os.path.realpath(tempdir), os.getcwd()) self.assertEqual(pre_cwd", "label": 0}, {"snippet_id": 89696, "code": " the jars could not be found. \"\"\" def collect_existing_libs(): def lib_paths(): yield os.path.join(self.home, 'lib') if self.jdk: yield os.path.join(self.home, 'jre', 'lib') for name in names: for path", "label": 0}, {"snippet_id": 4808, "code": " printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches", "label": 0}, {"snippet_id": 34225, "code": " def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def", "label": 0}, {"snippet_id": 62318, "code": " in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def shutdown(self): \"\"\"Shutdown. \"\"\" pass def _deallocate(self): \"", "label": 0}, {"snippet_id": 15992, "code": " method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest", "label": 0}, {"snippet_id": 79199, "code": ".search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult", "label": 0}, {"snippet_id": 73638, "code": " from pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool", "label": 0}, {"snippet_id": 13620, "code": " myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\" 2>", "label": 0}, {"snippet_id": 34694, "code": ".exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self", "label": 0}, {"snippet_id": 86755, "code": ": distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) logger.debug", "label": 0}, {"snippet_id": 38708, "code": "))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 18373, "code": ", stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode", "label": 0}, {"snippet_id": 92623, "code": ", 'Temporary dir should exist within the context.') self.assertTrue(os.path.isdir(path), 'Temporary dir should be a dir and not a file.') self.assertFalse(os.path.exists(path), 'Temporary dir should not", "label": 0}, {"snippet_id": 6640, "code": "=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs)", "label": 0}, {"snippet_id": 2799, "code": ".logger.info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\"", "label": 0}, {"snippet_id": 14439, "code": " return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport", "label": 0}, {"snippet_id": 65735, "code": " status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\",", "label": 0}, {"snippet_id": 75618, "code": " was interrupted at runtime') class Suspend(Exception): '''Exception to raise on suspend signal''' def __init__(self, interval, *args, **kvargs): self.interval=interval super().__init__(*args, **kvargs", "label": 0}, {"snippet_id": 52194, "code": " import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources,", "label": 1}, {"snippet_id": 33782, "code": ".info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats", "label": 0}, {"snippet_id": 7465, "code": "(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output,", "label": 0}, {"snippet_id": 83965, "code": " %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name", "label": 0}, {"snippet_id": 43219, "code": ".append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards", "label": 0}, {"snippet_id": 62556, "code": ", observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator", "label": 0}, {"snippet_id": 95429, "code": ") local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def", "label": 0}, {"snippet_id": 47395, "code": "\"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self", "label": 0}, {"snippet_id": 22623, "code": "\"\" return None def set_dhcp_hostname(self, hostname): \"\"\"Sets the DHCP hostname See `set_hostname` for an explanation of why I pass here :param hostname: The hostname to set on the device \"\"\" return None", "label": 0}, {"snippet_id": 14919, "code": ".PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout", "label": 0}, {"snippet_id": 82439, "code": ".DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot", "label": 0}, {"snippet_id": 53009, "code": "(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set()", "label": 0}, {"snippet_id": 31274, "code": "} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 23935, "code": " iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if port_id > 3: return None g0=\"00000000\" if port_id > 1: g0=\"00000001", "label": 0}, {"snippet_id": 23200, "code": " if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)) param=struct", "label": 0}, {"snippet_id": 92963, "code": "(stdout_data, tmp_stdout.read().strip()) self.assertEqual(stderr_data, tmp_stderr.read().strip()) def test_stdio_as(self): self.assertTrue(sys.stderr.fileno() > 2, \"Expected a pseudofile as stderr, got", "label": 0}, {"snippet_id": 41350, "code": "=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m.group(\"value\")", "label": 0}, {"snippet_id": 92941, "code": " self.assertEqual(stdin_data, sys.stdin.read().strip()) print(stdout_data, file=sys.stdout) yield print(stderr_data, file=sys.stderr) tmp_stdout.seek(0) tmp_stderr.seek(0) self.assertEqual(stdout_data,", "label": 0}, {"snippet_id": 55698, "code": "[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads", "label": 0}, {"snippet_id": 86204, "code": " for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings", "label": 0}, {"snippet_id": 95295, "code": "=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"", "label": 0}, {"snippet_id": 59105, "code": " optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...", "label": 0}, {"snippet_id": 50342, "code": " isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version", "label": 0}, {"snippet_id": 17163, "code": " ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request", "label": 0}, {"snippet_id": 31779, "code": ".touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params,", "label": 0}, {"snippet_id": 28048, "code": " latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): ", "label": 0}, {"snippet_id": 62261, "code": " if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return", "label": 0}, {"snippet_id": 34728, "code": "(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None", "label": 1}, {"snippet_id": 71362, "code": " AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT,", "label": 0}, {"snippet_id": 11696, "code": " import datetime import hmac import json import os import re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository", "label": 0}, {"snippet_id": 9546, "code": ":var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken", "label": 0}, {"snippet_id": 33868, "code": " logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code,", "label": 0}, {"snippet_id": 71049, "code": " % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted >", "label": 0}, {"snippet_id": 91097, "code": ".uname()[0].lower()) if os_name not in self._normalized_jdk_paths: logger.warning('--jvm-distributions-paths was specified, but has no entry for \"{}\".' .format(os_name)) return self._normalized_jdk_paths", "label": 0}, {"snippet_id": 68626, "code": "=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" %", "label": 0}, {"snippet_id": 71261, "code": "): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd", "label": 0}, {"snippet_id": 21238, "code": ": pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get('href') for a in soup('a') if a.get", "label": 0}, {"snippet_id": 86418, "code": ", (WorkUnitLabel.TASK, WorkUnitLabel.JVM), ) classes_directory=ctx.classes_dir self.context._scheduler.materialize_directories(( DirectoryToMaterialize(text_type(classes_directory), exec_result.output_directory_digest", "label": 0}, {"snippet_id": 53388, "code": ", old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output", "label": 0}, {"snippet_id": 17000, "code": " _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http:/", "label": 0}, {"snippet_id": 53773, "code": "(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified", "label": 0}, {"snippet_id": 67445, "code": "\"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path)", "label": 0}, {"snippet_id": 19379, "code": " handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py \"\"\" PYDEVD_OPTS={ '--file', ", "label": 0}, {"snippet_id": 65307, "code": ".debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel ", "label": 0}, {"snippet_id": 95198, "code": " server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def", "label": 1}, {"snippet_id": 17386, "code": "._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(", "label": 0}, {"snippet_id": 38916, "code": ".workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done", "label": 0}, {"snippet_id": 14457, "code": " server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and", "label": 0}, {"snippet_id": 64383, "code": " CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.", "label": 0}, {"snippet_id": 55731, "code": ".\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if", "label": 0}, {"snippet_id": 54056, "code": " is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule", "label": 0}, {"snippet_id": 53697, "code": ".protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"):", "label": 0}, {"snippet_id": 15482, "code": " extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def", "label": 0}, {"snippet_id": 20852, "code": " if msg.type !='response': return False result['msg']=msg return msg.request_seq==seq handlername='response(cmd:{} seq:{})'.format(command, seq) evt=self._get_message_handle(match, handlername) return AwaitableResponse", "label": 0}, {"snippet_id": 37041, "code": "=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self", "label": 0}, {"snippet_id": 51689, "code": " first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards", "label": 0}, {"snippet_id": 66592, "code": " import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import", "label": 0}, {"snippet_id": 66354, "code": " command aims to stop Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions", "label": 0}, {"snippet_id": 18142, "code": " import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from", "label": 0}, {"snippet_id": 8588, "code": ".info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH", "label": 1}, {"snippet_id": 59659, "code": " and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs", "label": 0}, {"snippet_id": 50906, "code": ".\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len", "label": 0}, {"snippet_id": 70092, "code": "\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print", "label": 0}, {"snippet_id": 2221, "code": "'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group',", "label": 0}, {"snippet_id": 42936, "code": " specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start", "label": 0}, {"snippet_id": 15305, "code": "=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'", "label": 1}, {"snippet_id": 80163, "code": " manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args(", "label": 0}, {"snippet_id": 26236, "code": ":thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle", "label": 0}, {"snippet_id": 65075, "code": " of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os", "label": 0}, {"snippet_id": 22245, "code": " if log_file is None: if 'log_file' in self.conf: log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template", "label": 0}, {"snippet_id": 11152, "code": " time_string)) if self.etag: lines.append(\"%s%s\" %(Header.ETAG_COMMENT, self.etag)) if self.mtime: lines.append(\"%s%d\" %(Header.MTIME_COMMMENT, self.mtime)) return lines @staticmethod def parse(file_name)", "label": 0}, {"snippet_id": 15199, "code": ".server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal", "label": 0}, {"snippet_id": 92958, "code": ".seek(0) tmp_stderr.seek(0) self.assertEqual(stdout_data, tmp_stdout.read().strip()) self.assertEqual(stderr_data, tmp_stderr.read().strip()) def test_stdio_as(self): self.assertTrue(sys.stderr.fileno(", "label": 0}, {"snippet_id": 74280, "code": " corresponding values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__", "label": 0}, {"snippet_id": 27564, "code": "['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure", "label": 0}, {"snippet_id": 76527, "code": ".Thread): def start(self, ctx, sig_addr, *args, **kvargs): self.ctx=ctx self.sig_addr=sig_addr threading.Thread.start(self, *args, **kvargs) class WZWorkerProcess(WZWorkerBase, multiprocessing.Process): def", "label": 0}, {"snippet_id": 72714, "code": " print(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config)", "label": 0}, {"snippet_id": 29757, "code": ": return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected", "label": 1}, {"snippet_id": 9314, "code": " limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords", "label": 0}, {"snippet_id": 28940, "code": " >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 40670, "code": "(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot", "label": 0}, {"snippet_id": 86130, "code": " def execute(self): if JvmPlatform.global_instance().get_options().compiler=='javac': return super(JavacCompile, self).execute() def compile(self, ctx, args, dependency_classpath, upstream_analysis, settings", "label": 0}, {"snippet_id": 60052, "code": " constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list", "label": 0}, {"snippet_id": 83164, "code": " LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the", "label": 0}, {"snippet_id": 28235, "code": "'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', ''", "label": 0}, {"snippet_id": 65099, "code": " strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre", "label": 0}, {"snippet_id": 41708, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all", "label": 1}, {"snippet_id": 2952, "code": " self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] ", "label": 0}, {"snippet_id": 48866, "code": " bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards", "label": 0}, {"snippet_id": 16410, "code": "') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else", "label": 0}, {"snippet_id": 6002, "code": " executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output", "label": 0}, {"snippet_id": 64162, "code": "=remote_system_properties.get('galaxy_config_file', default_config_file) metadata_kwds['dataset_files_path']=remote_system_properties.get('galaxy_dataset_files_path', None) if LwrJobRunner.__use_remote_datatypes_conf( client", "label": 0}, {"snippet_id": 77889, "code": ".save_targets() wm=workers.WZWorkerThread(c.router_addr, WipeManager,(c,), name='SpaghettiMonster') wm.start(ctx, sig_addr) def add_target(domain, id_, tuser=None): if domain not in targets: targets[domain]=[]", "label": 0}, {"snippet_id": 71684, "code": ".CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task", "label": 1}, {"snippet_id": 93127, "code": " temporary_dir() as td: profile_path=os.path.join(td, 'profile.prof') with maybe_profiled(profile_path): for _ in range(5): print('test') self.assertTrue(os.path.exists(profile_path)) pstats.Stats(profile_path", "label": 0}, {"snippet_id": 22673, "code": " is the admin account that is, or should be, built in to the system. :param username: The username that you want to add to the system :param expiration: The expiration date to use. We do not use this value", "label": 0}, {"snippet_id": 1258, "code": "-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(", "label": 0}, {"snippet_id": 66760, "code": "(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except KeyError: print \"Error ", "label": 1}, {"snippet_id": 9255, "code": "<keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v", "label": 0}, {"snippet_id": 92848, "code": " self.assertEqual(os.path.realpath(file_symlink), os.path.realpath(not_zip.name)) with self.assertRaisesRegexp(zipfile.BadZipfile, r'{}'.format(not_zip.name)): next(open_zip(file_symlink).gen) @contextmanager", "label": 0}, {"snippet_id": 85866, "code": ".backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin import JavacPlugin from", "label": 0}, {"snippet_id": 3458, "code": " self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done", "label": 0}, {"snippet_id": 7218, "code": ") composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('</record></collection>') return '\\n'.join(output", "label": 0}, {"snippet_id": 23755, "code": "/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\") if", "label": 0}, {"snippet_id": 80309, "code": " and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args", "label": 0}, {"snippet_id": 49501, "code": ".first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets", "label": 0}, {"snippet_id": 67908, "code": " enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import", "label": 0}, {"snippet_id": 89824, "code": "') >>> jar '/usr/bin/jar' >>> If this distribution has no valid command of the given name raises Distribution.Error. If this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if", "label": 0}, {"snippet_id": 62922, "code": " from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep import os from.lwr_client import build_client_manager", "label": 0}, {"snippet_id": 75395, "code": ", method, args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface, method, args, fun, reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer):", "label": 0}, {"snippet_id": 12390, "code": "\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8", "label": 0}, {"snippet_id": 39601, "code": " ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo", "label": 0}, {"snippet_id": 90941, "code": "'.format(e)) options_scope='jvm-distributions' @classmethod def register_options(cls, register): super(DistributionLocator, cls).register_options(register) human_readable_os_aliases=', '.join('{}:[{}]'", "label": 0}, {"snippet_id": 44471, "code": "))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes", "label": 0}, {"snippet_id": 17125, "code": " import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers", "label": 0}, {"snippet_id": 50099, "code": ".path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile)", "label": 0}, {"snippet_id": 86606, "code": "/name> <classname>{}</classname> </plugin> \"\"\".format(scalac_plugin_target.plugin, scalac_plugin_target.classname)).strip()) @staticmethod def _write_javac_plugin_info(resources_dir, javac_plugin_target):", "label": 0}, {"snippet_id": 70393, "code": " mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status", "label": 0}, {"snippet_id": 11372, "code": " self.target_dir) LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s, writing to %s\" % (self.source, self.target_dir)) def _is_newer(self, header_source", "label": 0}, {"snippet_id": 83727, "code": " exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED]", "label": 0}, {"snippet_id": 46559, "code": " self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self", "label": 0}, {"snippet_id": 82483, "code": "\"At least one detection method must be provided, either with --not-regex or with --true-regex.\") if args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs", "label": 0}, {"snippet_id": 75317, "code": "): try: handler=self.response_handlers[reqid] if seqnum==0: del self.response_handlers[reqid] except KeyError: raise WZENoHandler(iden, 'No rep handler for reqid') handler(reqid, seqnum, status, msg[1:", "label": 0}, {"snippet_id": 1931, "code": "'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess", "label": 0}, {"snippet_id": 4300, "code": " text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False,", "label": 0}, {"snippet_id": 4241, "code": "(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.')", "label": 0}, {"snippet_id": 71948, "code": ".join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params)", "label": 0}, {"snippet_id": 69140, "code": " ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import", "label": 0}, {"snippet_id": 53411, "code": ") if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp", "label": 0}, {"snippet_id": 15646, "code": " return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface", "label": 0}, {"snippet_id": 62792, "code": "' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset", "label": 0}, {"snippet_id": 60602, "code": "\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self", "label": 0}, {"snippet_id": 25750, "code": "\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=", "label": 0}, {"snippet_id": 48864, "code": "()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments", "label": 0}, {"snippet_id": 94415, "code": " pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger", "label": 1}, {"snippet_id": 1722, "code": "\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows", "label": 0}, {"snippet_id": 4064, "code": " main methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords", "label": 0}, {"snippet_id": 20119, "code": "\"A high-level abstraction of a debug client(i.e. editor).\"\"\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 95112, "code": "=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory", "label": 1}, {"snippet_id": 18972, "code": "(response.content, six.binary_type): raw_source=six.text_type(response.content, encoding='utf-8') else: raw_source=response.content else: raw_source=source try: try: return json.loads(raw_source) except", "label": 0}, {"snippet_id": 44555, "code": ".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if", "label": 0}, {"snippet_id": 69391, "code": ": command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes", "label": 0}, {"snippet_id": 55833, "code": ", string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return", "label": 0}, {"snippet_id": 41923, "code": ".dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n", "label": 0}, {"snippet_id": 44036, "code": " subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[", "label": 0}, {"snippet_id": 89366, "code": " normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version): if isinstance(version, string_types): version=Revision.lenient(version) if", "label": 0}, {"snippet_id": 22058, "code": " self.force_handlers=force_handlers self.flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self, playbook, options=None", "label": 0}, {"snippet_id": 39982, "code": "=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls", "label": 0}, {"snippet_id": 37692, "code": ".\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return", "label": 0}, {"snippet_id": 88844, "code": " acquire_lock(self): \"\"\" Acquire the global lock for the root directory associated with this context. When a goal requires serialization, it will call this to acquire the lock. :API: public \"\"\" if self", "label": 0}, {"snippet_id": 94723, "code": ") subparser_val=subparsers.add_parser('validate', help=\"Validate the setup specified by the --config argument\") subparser_remote=subparsers.add_parser('slave', help=\"Run a component locally without controlling", "label": 0}, {"snippet_id": 9040, "code": "(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms", "label": 0}, {"snippet_id": 88889, "code": " :API: public \"\"\" if not self._lock.acquired: return False else: self._lock.release() return True def is_unlocked(self): \"\"\"Whether the global lock object is actively holding the lock. :API: public \"\"\"", "label": 0}, {"snippet_id": 91282, "code": ".python_repl import PythonRepl from pants.backend.python.tasks.python_run import PythonRun from pants.backend.python.tasks.resolve_requirements import ResolveRequirements from pants.backend.python.tasks", "label": 0}, {"snippet_id": 11908, "code": ": pythonic=True break return pythonic def get_config(data): \"\"\" Get.pep8speaks.yml config file from the repository and return the config dictionary \"\"\" config={ \"message\":{ \"opened\":{ \"header\": \"\", \"footer", "label": 0}, {"snippet_id": 84643, "code": " input_snapshots=tuple( target.sources_snapshot(scheduler=self.context._scheduler) for target in targets ) input_files={f.path for snapshot in input_snapshots for f in snapshot.files} with temporary_dir", "label": 0}, {"snippet_id": 55179, "code": ".subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag", "label": 0}, {"snippet_id": 13572, "code": ".set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 0)\r \r def updateEyes():\r while isRunning:\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time", "label": 0}, {"snippet_id": 4839, "code": " complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc", "label": 0}, {"snippet_id": 31970, "code": " self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output", "label": 0}, {"snippet_id": 81569, "code": "\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile", "label": 1}, {"snippet_id": 17472, "code": "._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self", "label": 0}, {"snippet_id": 42969, "code": " strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items", "label": 0}, {"snippet_id": 79445, "code": "=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself", "label": 1}, {"snippet_id": 41941, "code": "\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output", "label": 0}, {"snippet_id": 38138, "code": "): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp", "label": 0}, {"snippet_id": 31312, "code": ": if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__", "label": 0}, {"snippet_id": 26092, "code": " data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self", "label": 1}, {"snippet_id": 5252, "code": " list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does", "label": 0}, {"snippet_id": 62615, "code": " expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator", "label": 0}, {"snippet_id": 69124, "code": ".CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands", "label": 0}, {"snippet_id": 46851, "code": ".wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio,", "label": 0}, {"snippet_id": 3195, "code": ".session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name", "label": 0}, {"snippet_id": 73894, "code": " VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation of VCF to Zarr conversion module configuration. \"\"\" enabled=False fields=None alt_number=None chunk_length=None chunk_width=None compressor", "label": 0}, {"snippet_id": 11514, "code": " yaml_config, header): self.icinga_lines=[] self.indent=CONFIG['INDENT'] self.icinga_lines.extend(header.serialize()) self.write_section('host', yaml_config.host) for service in yaml_config.services: self", "label": 0}, {"snippet_id": 93411, "code": ".nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error", "label": 0}, {"snippet_id": 4893, "code": "(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords", "label": 0}, {"snippet_id": 44337, "code": ".updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self", "label": 0}, {"snippet_id": 29670, "code": "] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise", "label": 0}, {"snippet_id": 1714, "code": ".first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard", "label": 0}, {"snippet_id": 76562, "code": " import os, signal, logging, threading, re, traceback, time import random import zmq from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import", "label": 0}, {"snippet_id": 47004, "code": "\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self)", "label": 0}, {"snippet_id": 68057, "code": "[-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system", "label": 0}, {"snippet_id": 15667, "code": "(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport", "label": 0}, {"snippet_id": 68625, "code": " tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\"", "label": 0}, {"snippet_id": 92503, "code": ".path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual", "label": 0}, {"snippet_id": 51593, "code": "(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(", "label": 0}, {"snippet_id": 5006, "code": " output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword", "label": 0}, {"snippet_id": 57041, "code": " pipe=pipes.get(v_type, None) if pipe is None: error='Unsupported value type.' else: try: value=pipe(val) except Exception as e: error=str(e) return value, error def say_no(error_msg): ajax_response={'rc", "label": 0}, {"snippet_id": 52221, "code": " import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type", "label": 0}, {"snippet_id": 51904, "code": " names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index", "label": 0}, {"snippet_id": 79147, "code": ".uploadUrl,files={self.inputName:(filename,fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger", "label": 0}, {"snippet_id": 92118, "code": " following targets set platforms arguments other than['current'], which is unsupported for this reason. Please either remove the platforms argument from these targets, or set them to exactly['current']. Bad", "label": 0}, {"snippet_id": 69556, "code": "\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg", "label": 0}, {"snippet_id": 43930, "code": "(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name", "label": 0}, {"snippet_id": 11767, "code": " \"0\", } auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/user/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict", "label": 0}, {"snippet_id": 46132, "code": ": a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product", "label": 0}, {"snippet_id": 82314, "code": "\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads", "label": 0}, {"snippet_id": 35354, "code": "(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(", "label": 0}, {"snippet_id": 26024, "code": " if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class", "label": 0}, {"snippet_id": 39936, "code": " import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f", "label": 1}, {"snippet_id": 94166, "code": " check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting", "label": 0}, {"snippet_id": 26923, "code": "'GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 68732, "code": " target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag():", "label": 0}, {"snippet_id": 37476, "code": " if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer", "label": 0}, {"snippet_id": 15035, "code": " column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column", "label": 0}, {"snippet_id": 57145, "code": " has_perms=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied.') model=apps.get_model(*ctype.split(\".\", 1)) targets=model._default_manager.filter(pk__in=object_pk) if not", "label": 0}, {"snippet_id": 84786, "code": " from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem major_version_info=namedtuple('major_version_info", "label": 0}, {"snippet_id": 23768, "code": " ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\") if ret: raise OSUtilError(\"Failed to get processor cores.\") try: return int(output) except ValueError: raise OSUtilError(\"Failed", "label": 0}, {"snippet_id": 60022, "code": " the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']", "label": 0}, {"snippet_id": 39096, "code": ", local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing", "label": 0}, {"snippet_id": 47858, "code": " self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set", "label": 0}, {"snippet_id": 47555, "code": " False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self", "label": 0}, {"snippet_id": 93777, "code": " def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host", "label": 0}, {"snippet_id": 39836, "code": "._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if", "label": 0}, {"snippet_id": 58456, "code": "'Comments needed'}) def test_refuse_if_missing_no_case_run_pk(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new", "label": 0}, {"snippet_id": 59737, "code": " operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super", "label": 0}, {"snippet_id": 93152, "code": " socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI", "label": 0}, {"snippet_id": 79164, "code": " self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re", "label": 1}, {"snippet_id": 2894, "code": " of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state", "label": 0}, {"snippet_id": 38713, "code": "(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name", "label": 0}, {"snippet_id": 84503, "code": "._sep def version_path( self): return self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites:", "label": 0}, {"snippet_id": 90974, "code": "'Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS", "label": 0}, {"snippet_id": 46271, "code": "=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)", "label": 0}, {"snippet_id": 61854, "code": " openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends.", "label": 0}, {"snippet_id": 12120, "code": "=diff_headers, auth=auth) patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) files={} for patchset in patch: file=patchset.target_file[1:] files[file]=[] for hunk in patchset: for line", "label": 0}, {"snippet_id": 52526, "code": "): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule", "label": 1}, {"snippet_id": 35835, "code": ") except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files", "label": 0}, {"snippet_id": 95322, "code": ", local_directory): \"\"\" Get benchmarking data from a remote ftp server. :type ftp_config: config.FTPConfigurationRepresentation :type local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree", "label": 0}, {"snippet_id": 69175, "code": " \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage", "label": 0}, {"snippet_id": 66641, "code": " % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen", "label": 0}, {"snippet_id": 75655, "code": " start_timer=None, poll_timeout=None, pargs=(), pkvargs={}): super().__init__(*pargs, **pkvargs) self.name=name if name else type(self).__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout", "label": 0}, {"snippet_id": 36094, "code": ".output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output", "label": 0}, {"snippet_id": 72506, "code": " configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file", "label": 0}, {"snippet_id": 81820, "code": "\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\",", "label": 0}, {"snippet_id": 17032, "code": "=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath':", "label": 0}, {"snippet_id": 28729, "code": "'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self", "label": 0}, {"snippet_id": 31452, "code": " another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or", "label": 0}, {"snippet_id": 71097, "code": ", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 27239, "code": "', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None]", "label": 0}, {"snippet_id": 28208, "code": "], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS", "label": 0}, {"snippet_id": 8109, "code": ":get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os", "label": 0}, {"snippet_id": 45522, "code": " try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for", "label": 0}, {"snippet_id": 29700, "code": "(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance", "label": 0}, {"snippet_id": 37538, "code": "._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.", "label": 0}, {"snippet_id": 15964, "code": " if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method", "label": 1}, {"snippet_id": 33925, "code": " self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir", "label": 0}, {"snippet_id": 69473, "code": ".cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load", "label": 0}, {"snippet_id": 3038, "code": ".new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave'\" %(host,", "label": 0}, {"snippet_id": 67334, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None,", "label": 0}, {"snippet_id": 80913, "code": " logging,concurrent.futures from utils import * from urllib.parse import urljoin,urlparse from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder", "label": 0}, {"snippet_id": 95114, "code": "(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else", "label": 1}, {"snippet_id": 25253, "code": "':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength'", "label": 0}, {"snippet_id": 56838, "code": ".get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter(object): \"\"\" Used for counting the number of times a tag", "label": 0}, {"snippet_id": 10730, "code": "(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an", "label": 1}, {"snippet_id": 81431, "code": "\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e in extList: \t\t\t\ttmpExtList.append((e,getMime(extensions,e", "label": 0}, {"snippet_id": 49595, "code": " force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph", "label": 0}, {"snippet_id": 77243, "code": "(self, proxypairs): while self.running.is_set(): try: try: proxypair=proxypairs.pop() except Exception: return self.proxylist.add(proxypair) for spawn in create_spawn(proxypair[0], proxypair[1], self.pc", "label": 0}, {"snippet_id": 5940, "code": " text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import", "label": 1}, {"snippet_id": 73860, "code": "=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz", "label": 0}, {"snippet_id": 39828, "code": ".join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self):", "label": 0}, {"snippet_id": 21877, "code": " dataloader from ansible.utils.display import Display from dciclient.v1 import helper as dci_helper from dciagent.plugins import plugin import jinja2 import os import subprocess display=Display() class", "label": 1}, {"snippet_id": 84316, "code": " metadata_kwds['config_file']=remote_system_properties.get('galaxy_config_file', default_config_file) metadata_kwds['dataset_files_path']=remote_system_properties.get('galaxy_dataset_files_path', None)", "label": 0}, {"snippet_id": 21943, "code": " become_user=None, become_ask_pass=None, ask_pass=None, private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args", "label": 0}, {"snippet_id": 21939, "code": ", become=None, become_method=None, become_user=None, become_ask_pass=None, ask_pass=None, private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None", "label": 0}, {"snippet_id": 13800, "code": "']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self", "label": 0}, {"snippet_id": 15428, "code": ".PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen", "label": 0}, {"snippet_id": 46662, "code": " except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files", "label": 0}, {"snippet_id": 737, "code": "): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0", "label": 0}, {"snippet_id": 11508, "code": " class YamlToIcinga(object): def __init__(self, yaml_config, header): self.icinga_lines=[] self.indent=CONFIG['INDENT'] self.icinga_lines.extend(header.serialize()) self.write_section('host', yaml_config", "label": 0}, {"snippet_id": 79051, "code": " detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": ", "label": 0}, {"snippet_id": 13227, "code": "[\"BOT_PASSWORD\"]) sha=None r=requests.get(url, headers=headers, auth=auth) for ref in r.json(): if ref[\"ref\"].split(\"/\")[-1]==data[\"target_repo_branch\"]: sha=ref[\"object\"][\"sha\"] url=\"https://api.github", "label": 0}, {"snippet_id": 22980, "code": " my tests with 12.1.1 it will also find /dev/sr0 on occasion. This is NOT the correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists on all platforms", "label": 0}, {"snippet_id": 63900, "code": " LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner, self).shutdown() self", "label": 0}, {"snippet_id": 65937, "code": "(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if", "label": 0}, {"snippet_id": 35214, "code": " shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): ", "label": 0}, {"snippet_id": 9547, "code": " boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects", "label": 0}, {"snippet_id": 32272, "code": " TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"", "label": 0}, {"snippet_id": 23997, "code": " output=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk -F. '{print $3}'\" err, output=shellutil.run_get_output(cmd_extract_id) \"\"\" try to search 'blkvscX", "label": 0}, {"snippet_id": 94395, "code": "'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry", "label": 0}, {"snippet_id": 50118, "code": "(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print", "label": 0}, {"snippet_id": 87923, "code": ") return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin classpath entries. The first entry in each list is the classpath entry containing", "label": 0}, {"snippet_id": 93273, "code": ".server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else", "label": 0}, {"snippet_id": 78482, "code": "(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page))) for t in found: if(t in self.pc.sets['closed'] or t in self.pc.sets['bumplimit'] or", "label": 1}, {"snippet_id": 59975, "code": "() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits", "label": 0}, {"snippet_id": 17666, "code": ".PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self):", "label": 0}, {"snippet_id": 30066, "code": "]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if", "label": 0}, {"snippet_id": 12666, "code": " def create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https", "label": 0}, {"snippet_id": 17147, "code": " OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client", "label": 0}, {"snippet_id": 40259, "code": " first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill,", "label": 0}, {"snippet_id": 561, "code": "\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows", "label": 0}, {"snippet_id": 24743, "code": "'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif", "label": 0}, {"snippet_id": 47417, "code": " \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule", "label": 0}, {"snippet_id": 65557, "code": "(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname", "label": 1}, {"snippet_id": 34788, "code": " f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards", "label": 1}, {"snippet_id": 17523, "code": " FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 20648, "code": "=new_hidden_thread( target=self._listen, name='test.session', ) self._listenerthread.start() @property def is_client(self): return self._conn.is_client @property def received(self): return list(self._received", "label": 0}, {"snippet_id": 5684, "code": "): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone", "label": 0}, {"snippet_id": 17556, "code": "._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if", "label": 0}, {"snippet_id": 89004, "code": "\"Selects targets in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during", "label": 0}, {"snippet_id": 71549, "code": "%s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name", "label": 0}, {"snippet_id": 91455, "code": ".install('binary') task(name='isort-prep', action=IsortPrep).install('fmt') task(name='isort', action=IsortRun).install('fmt') task(name='py', action=PythonBundle).install('bundle') task(name='unpack-wheels'", "label": 0}, {"snippet_id": 80467, "code": "\targs.legitExtensions=[x.lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(", "label": 0}, {"snippet_id": 19834, "code": " adapter(self): return self._adapter @property def session(self): return self._session def start_debugging(self, launchcfg): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not", "label": 0}, {"snippet_id": 54983, "code": ": logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles", "label": 0}, {"snippet_id": 36525, "code": " \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile", "label": 0}, {"snippet_id": 73541, "code": ": print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH", "label": 0}, {"snippet_id": 60539, "code": " wires(int): the number of modes to initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields", "label": 0}, {"snippet_id": 32961, "code": " @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in", "label": 0}, {"snippet_id": 75919, "code": " s.send_multipart(msg) while self.running.is_set(): flag=0 for rs in rslist: if rs.finished: if not rs.retry: del msgdict[rs] continue s.send_multipart(msgdict[rs]) rs.finished=False rs.retry=False flag", "label": 0}, {"snippet_id": 42963, "code": " SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params", "label": 0}, {"snippet_id": 13005, "code": "=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \" +os.environ[", "label": 0}, {"snippet_id": 7738, "code": ".append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes", "label": 0}, {"snippet_id": 56820, "code": ": The name of the tag to be manipulated :type tag_name: str \"\"\" self.obj=obj self.tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self", "label": 0}, {"snippet_id": 75171, "code": "-unbind-route'), (b'Router', b'auth-set-route-type')] self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self", "label": 0}, {"snippet_id": 18359, "code": "._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost", "label": 0}, {"snippet_id": 13510, "code": " chippyRuxpin_webFramework import WebFramework\r \r fullMsg=\"\"\r \r MOUTH_OPEN=408 MOUTH_CLOSE=412 EYES_OPEN=410 EYES_CLOSE=414 \r io=GPIO() io.setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io", "label": 0}, {"snippet_id": 18382, "code": "._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self", "label": 0}, {"snippet_id": 72593, "code": " required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory=\"./data/input", "label": 1}, {"snippet_id": 91943, "code": "=cls.default_native_source_extensions, fingerprint=True, advanced=True, help='The extensions recognized for native source files in `python_dist()` sources.') @classmethod def subsystem_dependencies(cls", "label": 0}, {"snippet_id": 16254, "code": "=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None", "label": 0}, {"snippet_id": 49382, "code": ", forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname", "label": 0}, {"snippet_id": 70926, "code": "==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target", "label": 0}, {"snippet_id": 62803, "code": "'IBMBackend' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is", "label": 0}, {"snippet_id": 11729, "code": ") is not False: query=r\"INSERT INTO Users(repository, created_at) VALUES('{}', now());\" \\ \"\".format(repository) try: cursor.execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def", "label": 0}, {"snippet_id": 14576, "code": " def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if", "label": 0}, {"snippet_id": 55038, "code": " True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory", "label": 0}, {"snippet_id": 8307, "code": "[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find", "label": 1}, {"snippet_id": 59142, "code": " only permits classical operations. -projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API", "label": 0}, {"snippet_id": 6957, "code": " text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8", "label": 0}, {"snippet_id": 89859, "code": ") return self._validated_executable(name) def validate(self): \"\"\"Validates this distribution against its configured constraints. Raises Distribution.Error if this distribution is not valid according to", "label": 0}, {"snippet_id": 21830, "code": " Dense classifier=Sequential() classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11)) classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))", "label": 1}, {"snippet_id": 65224, "code": " FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR", "label": 0}, {"snippet_id": 2820, "code": "\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self", "label": 0}, {"snippet_id": 23433, "code": ".get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None: cmd=\"pw useradd{0} -e{1} -m\".format(username, expiration) else: cmd", "label": 0}, {"snippet_id": 17554, "code": "( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self", "label": 0}, {"snippet_id": 46887, "code": " in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self", "label": 0}, {"snippet_id": 18675, "code": " vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug", "label": 0}, {"snippet_id": 82206, "code": ",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent", "label": 0}, {"snippet_id": 10239, "code": "\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): ", "label": 0}, {"snippet_id": 18416, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self):", "label": 0}, {"snippet_id": 51216, "code": ".path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re", "label": 0}, {"snippet_id": 19107, "code": "=schema) def validate_api_response(schema, raw_response, request_method='get', raw_request=None): \"\"\" Validate the response of an api call against a swagger schema. \"\"\" request=None if raw_request is not", "label": 0}, {"snippet_id": 81757, "code": " coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\"", "label": 0}, {"snippet_id": 36550, "code": ".dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"", "label": 0}, {"snippet_id": 66851, "code": ") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command", "label": 0}, {"snippet_id": 92310, "code": "\"HORK\" in os.environ)'], stdout=new_output).wait() new_output.seek(0) self.assertEqual('False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output:", "label": 0}, {"snippet_id": 14464, "code": "._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()):", "label": 0}, {"snippet_id": 68848, "code": "(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 37013, "code": ".docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output", "label": 0}, {"snippet_id": 75230, "code": " fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method)]=fun def del_req_handler(self, interface, method): del self.req_handlers", "label": 0}, {"snippet_id": 33607, "code": "(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed", "label": 0}, {"snippet_id": 85240, "code": " @property def repl(self): \"\"\"Return the repl tool key.\"\"\" return self._key_for_tool_version('scala-repl', self.version) def injectables(self, build_graph): if self.version=='custom': return specs_to_create", "label": 1}, {"snippet_id": 11992, "code": ", auth=auth) if r.status_code==200: try: new_config=yaml.load(r.text) config=update_dict(config, new_config) except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key, value in confs", "label": 0}, {"snippet_id": 40234, "code": "(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self)", "label": 0}, {"snippet_id": 63175, "code": " found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config, compute_environment=self.__prepare_job", "label": 0}, {"snippet_id": 9713, "code": " _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws", "label": 0}, {"snippet_id": 8812, "code": ", filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file", "label": 0}, {"snippet_id": 21270, "code": "[x for x in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label", "label": 0}, {"snippet_id": 45049, "code": "*kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return", "label": 0}, {"snippet_id": 27112, "code": "\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY", "label": 1}, {"snippet_id": 95323, "code": " local_directory): \"\"\" Get benchmarking data from a remote ftp server. :type ftp_config: config.FTPConfigurationRepresentation :type local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree", "label": 0}, {"snippet_id": 21454, "code": " pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) else: print(\"Reddytt: Working directory found. Loading variables.\") with open", "label": 0}, {"snippet_id": 82702, "code": "=args.proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: ", "label": 0}, {"snippet_id": 11242, "code": "--skip-checks][URL] monconfgenerator -h Options: -h Show this message. --debug Print additional information. --targetdir=DIR The generated Icinga monitoring configuration is written into this directory", "label": 0}, {"snippet_id": 29029, "code": "=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth,", "label": 0}, {"snippet_id": 63775, "code": " sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror", "label": 0}, {"snippet_id": 84427, "code": "( self): local_output_paths=self._wrapper_output_paths results=[] for local_output_path in local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite", "label": 0}, {"snippet_id": 51734, "code": ") match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides", "label": 0}, {"snippet_id": 48410, "code": " def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self", "label": 0}, {"snippet_id": 39250, "code": " overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1])", "label": 0}, {"snippet_id": 12175, "code": " the data dictionary \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository\"] after_commit_hash=data[", "label": 0}, {"snippet_id": 12654, "code": "(): break elif 'quiet' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False return PERMITTED_TO_COMMENT def create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token", "label": 0}, {"snippet_id": 62555, "code": " def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value", "label": 0}, {"snippet_id": 82022, "code": "\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"", "label": 0}, {"snippet_id": 38382, "code": " chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException", "label": 0}, {"snippet_id": 54842, "code": "=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None", "label": 0}, {"snippet_id": 66131, "code": " else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"", "label": 0}, {"snippet_id": 6344, "code": " output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module", "label": 0}, {"snippet_id": 63614, "code": ": job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message", "label": 0}, {"snippet_id": 45659, "code": " self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return", "label": 0}, {"snippet_id": 40200, "code": ") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f", "label": 1}, {"snippet_id": 26023, "code": "'wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full", "label": 0}, {"snippet_id": 59192, "code": " from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate", "label": 0}, {"snippet_id": 50178, "code": " is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global", "label": 0}, {"snippet_id": 14312, "code": " options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self", "label": 0}, {"snippet_id": 31643, "code": ".subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names", "label": 0}, {"snippet_id": 68185, "code": "=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self", "label": 1}, {"snippet_id": 19847, "code": ".closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None raise NotImplementedError def stop_debugging(self)", "label": 0}, {"snippet_id": 50719, "code": "[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path)", "label": 0}, {"snippet_id": 36736, "code": " self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash", "label": 0}, {"snippet_id": 89355, "code": " from pants.util.meta import AbstractClass from pants.util.osutil import OS_ALIASES, normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version", "label": 0}, {"snippet_id": 78552, "code": ") if c==0: self.log.info('No targets found at all, sleeping for 30 seconds') self.long_sleep(30) self.schedule(self.comment_loop) if len(self.forums)==0: self.schedule(self.wait_loop) def wait_loop(self", "label": 0}, {"snippet_id": 5909, "code": " %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error(\"Please use bibclassify_cli from now", "label": 0}, {"snippet_id": 36125, "code": "=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__(", "label": 0}, {"snippet_id": 84515, "code": " parameter_value] if parameter_value in unstructured_path_rewrites.itervalues(): return parameter_value rewrite, new_unstructured_path_rewrites=self.path_mapper.check_for_arbitrary_rewrite( parameter_value", "label": 0}, {"snippet_id": 40794, "code": ") def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard", "label": 0}, {"snippet_id": 25680, "code": "'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp", "label": 0}, {"snippet_id": 8970, "code": " match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract", "label": 0}, {"snippet_id": 43587, "code": " __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from", "label": 0}, {"snippet_id": 92544, "code": ".assertTrue(os.path.exists(fp.name)==False, 'Temporary file should not exist outside of the context.') def test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue", "label": 0}, {"snippet_id": 552, "code": ".all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard", "label": 0}, {"snippet_id": 71717, "code": " % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen", "label": 0}, {"snippet_id": 45113, "code": " ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version", "label": 0}, {"snippet_id": 48990, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib", "label": 0}, {"snippet_id": 10675, "code": "=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please", "label": 1}, {"snippet_id": 37930, "code": " dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self", "label": 0}, {"snippet_id": 45396, "code": " f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file", "label": 0}, {"snippet_id": 2065, "code": ") configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action)", "label": 0}, {"snippet_id": 55413, "code": ".needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())", "label": 0}, {"snippet_id": 4590, "code": ", skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var", "label": 0}, {"snippet_id": 21003, "code": " required)) def _check_handlers(self): unhandled=[] for handle_msg, name, required in self._handlers: if not required: continue unhandled.append(name or repr(handle_msg)) if unhandled: raise RuntimeError", "label": 0}, {"snippet_id": 38296, "code": "=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[]", "label": 0}, {"snippet_id": 92636, "code": ".') self.assertFalse(os.path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False) as path: self.assertTrue", "label": 0}, {"snippet_id": 80331, "code": " if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not-regex or with --true-regex.\") if args.legitExtensions: \targs.legitExtensions", "label": 0}, {"snippet_id": 65540, "code": " status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR}", "label": 0}, {"snippet_id": 71199, "code": ": status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size", "label": 0}, {"snippet_id": 13173, "code": "\"name\": name, \"description\": \"Forked from @{}'s{}\".format(author, full_name) } r=requests.patch(url, data=json.dumps(request_json), headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could", "label": 0}, {"snippet_id": 21712, "code": "'red', 'green'))(i), label=j) plt.title('Classifier(Training set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors import ListedColormap X_set, y_set=X_test", "label": 0}, {"snippet_id": 75594, "code": " import logging from sup.ticker import Ticker import wzrpc from wzrpc.wzhandler import WZHandler import wzauth_data class WorkerInterrupt(Exception): '''Exception to raise when self.running is cleared''", "label": 0}, {"snippet_id": 9374, "code": "[w[0].concept]=w[0].type for w in single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags", "label": 0}, {"snippet_id": 36161, "code": ".dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the", "label": 0}, {"snippet_id": 54179, "code": " cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer", "label": 0}, {"snippet_id": 8554, "code": ".write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file)", "label": 1}, {"snippet_id": 63058, "code": " self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state", "label": 0}, {"snippet_id": 6354, "code": " second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately", "label": 0}, {"snippet_id": 80899, "code": "\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found", "label": 0}, {"snippet_id": 15112, "code": " return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']", "label": 0}, {"snippet_id": 7188, "code": ":keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output", "label": 0}, {"snippet_id": 40791, "code": " wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern", "label": 0}, {"snippet_id": 25369, "code": "(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev", "label": 1}, {"snippet_id": 79805, "code": " '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates", "label": 0}, {"snippet_id": 38865, "code": " directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not", "label": 0}, {"snippet_id": 39365, "code": " Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self,", "label": 0}, {"snippet_id": 89655, "code": " \"\"\" return self._get_version(self.java) def find_libs(self, names): \"\"\"Looks for jars in the distribution lib folder(s). If the distribution is a JDK, both the `lib` and `jre/lib` dirs will be scanned", "label": 0}, {"snippet_id": 43065, "code": " if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self", "label": 0}, {"snippet_id": 76834, "code": ".parse_args() noproxy_rp=sup.net.RequestPerformer() noproxy_rp.proxy='' noproxy_rp.timeout=c.noproxy_timeout noproxy_rp.timeout=c.rp_timeout d=DataLoader(noproxy_rp, c.only_cache) c.router_addr=d.addrs[", "label": 0}, {"snippet_id": 89846, "code": " for the binary. \"\"\" if not isinstance(name, str): raise ValueError('name must be a binary name, given{} of type{}'.format(name, type(name))) self.validate() return self._validated_executable(name) def", "label": 0}, {"snippet_id": 54491, "code": " from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None,", "label": 0}, {"snippet_id": 15461, "code": "._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()):", "label": 0}, {"snippet_id": 45510, "code": ".file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file)", "label": 0}, {"snippet_id": 11693, "code": "\n import base64 import collections import datetime import hmac import json import os import re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import", "label": 0}, {"snippet_id": 87695, "code": ",), output_directories=(classes_dir,), description=\"zinc compile for{}\".format(ctx.target.address.spec), jdk_home=text_type(self._zinc.dist.home), ) res=self.context.execute_process_synchronously(req, self", "label": 1}, {"snippet_id": 57157, "code": "=apps.get_model(*ctype.split(\".\", 1)) targets=model._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s has no", "label": 0}, {"snippet_id": 51144, "code": " given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for", "label": 0}, {"snippet_id": 3012, "code": "\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window", "label": 0}, {"snippet_id": 27601, "code": "'battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self", "label": 0}, {"snippet_id": 29872, "code": " \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine", "label": 0}, {"snippet_id": 95215, "code": " the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks", "label": 0}, {"snippet_id": 6918, "code": "\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken", "label": 0}, {"snippet_id": 2333, "code": " from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph", "label": 0}, {"snippet_id": 12997, "code": "/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api", "label": 0}, {"snippet_id": 14254, "code": " self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request", "label": 0}, {"snippet_id": 3169, "code": ") send_main_session_command(self.session, cmd) def start_remote_clone_session(self, comp_name, session_name, hostname): remote_cmd=(\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\"ssh", "label": 0}, {"snippet_id": 49895, "code": ".persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items,", "label": 0}, {"snippet_id": 46360, "code": " __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys", "label": 0}, {"snippet_id": 55087, "code": " to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill", "label": 0}, {"snippet_id": 48968, "code": " Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp", "label": 0}, {"snippet_id": 16812, "code": "'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py", "label": 0}, {"snippet_id": 26046, "code": "=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data", "label": 0}, {"snippet_id": 29510, "code": ".info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format", "label": 0}, {"snippet_id": 25838, "code": " data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 40526, "code": "(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance", "label": 0}, {"snippet_id": 7842, "code": "(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of", "label": 0}, {"snippet_id": 29212, "code": "): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self", "label": 1}, {"snippet_id": 40889, "code": "() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re", "label": 0}, {"snippet_id": 22358, "code": " need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within roughly 50 minutes(100", "label": 0}, {"snippet_id": 4444, "code": " extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms", "label": 0}, {"snippet_id": 23937, "code": " mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if port_id > 3: return None g0=\"00000000\" if port_id > 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil", "label": 0}, {"snippet_id": 1479, "code": " request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address", "label": 0}, {"snippet_id": 84404, "code": "=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path(", "label": 0}, {"snippet_id": 39905, "code": " they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None", "label": 0}, {"snippet_id": 46770, "code": " __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from", "label": 0}, {"snippet_id": 65069, "code": ".get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node,", "label": 0}, {"snippet_id": 73222, "code": " containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type", "label": 0}, {"snippet_id": 27317, "code": "}) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get", "label": 0}, {"snippet_id": 6932, "code": " empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext", "label": 0}, {"snippet_id": 73848, "code": ".ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files", "label": 0}, {"snippet_id": 5210, "code": "(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text format. :return: str, html", "label": 0}, {"snippet_id": 86543, "code": ".distribution import DistributionLocator from pants.util.contextutil import open_zip from pants.util.dirutil import fast_relpath, safe_open from pants.util.memo import memoized_method, memoized_property", "label": 0}, {"snippet_id": 21719, "code": "(Training set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors import ListedColormap X_set, y_set=X_test, y_test X1, X2=np.meshgrid(np.arange(start=X_set", "label": 0}, {"snippet_id": 71160, "code": " jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state", "label": 0}, {"snippet_id": 22111, "code": " playbook_path=\"%s/%s\" %(pb_dir, playbook) display.verbosity=self.options.verbosity self.pbex=playbook_executor.PlaybookExecutor( playbooks=[playbook], inventory=self.inventory, variable_manager=self.variable_manager", "label": 1}, {"snippet_id": 93924, "code": " % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!\" % hostname) def", "label": 0}, {"snippet_id": 38790, "code": " list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence", "label": 0}, {"snippet_id": 64658, "code": "* from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem", "label": 0}, {"snippet_id": 72727, "code": "=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def main(): try:", "label": 0}, {"snippet_id": 85559, "code": " cls.options_scope) def create(self, products): \"\"\"Create a Zinc instance from products active in the current Pants run. :param products: The active Pants run products to pluck classpaths from. :type products", "label": 0}, {"snippet_id": 48336, "code": ") if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try:", "label": 0}, {"snippet_id": 61744, "code": " array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires <", "label": 0}, {"snippet_id": 67918, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import", "label": 0}, {"snippet_id": 30389, "code": "): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as", "label": 0}, {"snippet_id": 85574, "code": ":param products: The active Pants run products to pluck classpaths from. :type products::class:`pants.goal.products.Products` :returns: A Zinc instance with access to relevant Zinc compiler wrapper jars", "label": 0}, {"snippet_id": 70007, "code": " It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine", "label": 0}, {"snippet_id": 60681, "code": " var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self", "label": 0}, {"snippet_id": 70157, "code": ", target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message", "label": 0}, {"snippet_id": 78651, "code": ": self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run())) except BaseException as e: log.logger.exception(e) return -1 return 0 def execute(self): \"\"\"To be overridden by sub", "label": 0}, {"snippet_id": 5936, "code": " module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE", "label": 0}, {"snippet_id": 35152, "code": "=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def", "label": 1}, {"snippet_id": 79423, "code": "\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile", "label": 1}, {"snippet_id": 89710, "code": "(self.home, 'jre', 'lib') for name in names: for path in lib_paths(): lib_path=os.path.join(path, name) if os.path.exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate", "label": 0}, {"snippet_id": 11222, "code": " valid Icinga configuration file. If no URL is given it reads it's default configuration from file system. The configuration file is: /etc/monitoring_config_generator/config.yaml' Usage: monconfgenerator", "label": 0}, {"snippet_id": 70810, "code": " else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index],", "label": 0}, {"snippet_id": 48284, "code": ".protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"):", "label": 0}, {"snippet_id": 32349, "code": " item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio", "label": 0}, {"snippet_id": 24995, "code": "=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data", "label": 0}, {"snippet_id": 13430, "code": ".environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/pulls\" url=url.format(data[\"target_repo_fullname\"]) request_json={ \"title\": \"Fix pep8 errors\", \"head\": \"pep8speaks:{}\".format(data[\"new_branch\"]", "label": 0}, {"snippet_id": 11746, "code": " cursor.execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def follow_user(user): \"\"\"Follow the user of the service\"\"\" headers={ \"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 45995, "code": " AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError(", "label": 1}, {"snippet_id": 26792, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self", "label": 0}, {"snippet_id": 64699, "code": "> 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node", "label": 1}, {"snippet_id": 53377, "code": " KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old", "label": 0}, {"snippet_id": 3618, "code": "\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp)", "label": 1}, {"snippet_id": 71754, "code": "): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print", "label": 0}, {"snippet_id": 31843, "code": "): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item", "label": 0}, {"snippet_id": 72151, "code": "% seconds) return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument('network') remote_parser.add_argument('--service', type=str, default", "label": 0}, {"snippet_id": 51895, "code": " index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for", "label": 0}, {"snippet_id": 42460, "code": ".protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log", "label": 0}, {"snippet_id": 20805, "code": " msg.event==event and condition(msg) handlername='event{!r}'.format(event) evt=self._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result[\"msg\"], evt) def _get_awaiter_for_request", "label": 0}, {"snippet_id": 20222, "code": " if t.is_alive(): warnings.warn('timed out waiting for connection') if self._session is None: message='unable to connect after{} secs'.format( self._connecttimeout) if self._run_server_ex is None: raise", "label": 0}, {"snippet_id": 38311, "code": "(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict", "label": 0}, {"snippet_id": 8200, "code": " supported: PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file", "label": 0}, {"snippet_id": 85909, "code": " from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator from pants.util.dirutil import safe_open from pants.util.process_handler", "label": 0}, {"snippet_id": 43622, "code": " CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler", "label": 0}, {"snippet_id": 86341, "code": ", javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg,", "label": 0}, {"snippet_id": 7513, "code": "=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output ", "label": 0}, {"snippet_id": 13722, "code": ".parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals", "label": 0}, {"snippet_id": 33335, "code": " False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules", "label": 0}, {"snippet_id": 23899, "code": "'ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0}\".format(iface)) for line in output.split('\\n'): if line.find('inet ') !=-1: inet=line.split()[1] elif line.find(", "label": 0}, {"snippet_id": 85884, "code": " JavacPlugin from pants.backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants.base.exceptions import TaskError from pants.base.workunit", "label": 0}, {"snippet_id": 26508, "code": "(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for", "label": 0}, {"snippet_id": 75076, "code": ": %s', res) self.p.send_success_rep(reqid,[v.encode('utf-8') for v in res]) def send_keepalive(self): msg=self.p.wz.make_req_msg(b'Router', b'bind-keepalive',[], self.handle_keepalive_reply) msg.insert", "label": 0}, {"snippet_id": 65387, "code": " from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 91859, "code": ".backend.python.subsystems import pex_build_util from pants.backend.python.subsystems.python_setup import PythonSetup from pants.backend.python.targets.python_distribution import PythonDistribution from", "label": 0}, {"snippet_id": 42156, "code": " return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value", "label": 0}, {"snippet_id": 9202, "code": "...] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db", "label": 0}, {"snippet_id": 69896, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of", "label": 0}, {"snippet_id": 17826, "code": " 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger", "label": 0}, {"snippet_id": 41563, "code": ": for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) )", "label": 0}, {"snippet_id": 62061, "code": " True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in", "label": 0}, {"snippet_id": 38596, "code": "=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock", "label": 0}, {"snippet_id": 5051, "code": "\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code", "label": 0}, {"snippet_id": 95903, "code": "(path_zarr_output)) convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config", "label": 1}, {"snippet_id": 53490, "code": "=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list", "label": 0}, {"snippet_id": 26042, "code": "._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self", "label": 0}, {"snippet_id": 27715, "code": "'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp", "label": 0}, {"snippet_id": 28644, "code": ".module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self", "label": 0}, {"snippet_id": 39007, "code": ") if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True", "label": 0}, {"snippet_id": 75080, "code": "(reqid,[v.encode('utf-8') for v in res]) def send_keepalive(self): msg=self.p.wz.make_req_msg(b'Router', b'bind-keepalive',[], self.handle_keepalive_reply) msg.insert(0, b'') self.p.wz_sock.send_multipart", "label": 0}, {"snippet_id": 90171, "code": " Location(namedtuple('Location',['home_path', 'bin_path'])): \"\"\"Represents the location of a java distribution.\"\"\" @classmethod def from_home(cls, home): \"\"\"Creates a location given the JAVA_HOME directory", "label": 0}, {"snippet_id": 42857, "code": ".temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise", "label": 0}, {"snippet_id": 3131, "code": " '%s' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux", "label": 0}, {"snippet_id": 23472, "code": "{1}, \" \"output:{2}\").format(username, retcode, out)) def del_account(self, username): if self.is_sys_user(username): logger.error(\"{0} is a system user. Will not delete it.\", username) shellutil.run('>", "label": 0}, {"snippet_id": 32372, "code": " ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not", "label": 0}, {"snippet_id": 76655, "code": "(msg) def sbjfun(): return sup.randstr(1, 30) import argparse parser=argparse.ArgumentParser(add_help=True) parser.add_argument('--only-cache', '-C', action='store_true', help=\"Disables any requests in", "label": 0}, {"snippet_id": 93536, "code": "' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp[", "label": 0}, {"snippet_id": 58846, "code": "': 'testcases.CaseAutomatedForm'}) form=CaseAutomatedForm() self.assertHTMLEqual(str(response.content, encoding=settings.DEFAULT_CHARSET), form.as_p()) class TestUpdateCasePriority(BasePlanCase): \"\"\"Test", "label": 1}, {"snippet_id": 40882, "code": "=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames):", "label": 0}, {"snippet_id": 40359, "code": "(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None", "label": 0}, {"snippet_id": 39050, "code": " True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence", "label": 0}, {"snippet_id": 36965, "code": ".temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark", "label": 0}, {"snippet_id": 30740, "code": ".output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\"", "label": 0}, {"snippet_id": 15059, "code": "=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error", "label": 0}, {"snippet_id": 42442, "code": "=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output", "label": 0}, {"snippet_id": 37263, "code": "**kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(", "label": 0}, {"snippet_id": 4818, "code": " only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p=_sort_kw_matches(composite_keywords) for w in single_keywords_p: categories[w[0].concept]=w[0", "label": 0}, {"snippet_id": 64972, "code": " Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction", "label": 0}, {"snippet_id": 79686, "code": "=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1", "label": 0}, {"snippet_id": 51951, "code": " self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for", "label": 0}, {"snippet_id": 10528, "code": "'BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not", "label": 1}, {"snippet_id": 94602, "code": "\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file", "label": 0}, {"snippet_id": 78529, "code": " no new targets in forum %s:%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0:", "label": 0}, {"snippet_id": 30564, "code": " listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type", "label": 0}, {"snippet_id": 37605, "code": " for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log", "label": 0}, {"snippet_id": 51370, "code": ", flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value", "label": 0}, {"snippet_id": 73108, "code": " fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp", "label": 0}, {"snippet_id": 83389, "code": "=client.env, rewrite_paths=rewrite_paths, arbitrary_files=unstructured_path_rewrites, ) job_id=lwr_submit_job(client, client_job_description, remote_job_config) log.info(\"lwr job submitted with job_id %s\"", "label": 0}, {"snippet_id": 28622, "code": "['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5'", "label": 0}, {"snippet_id": 2692, "code": ".append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style", "label": 0}, {"snippet_id": 18061, "code": " future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return", "label": 0}, {"snippet_id": 3010, "code": "'name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" %", "label": 0}, {"snippet_id": 66870, "code": ".shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node,", "label": 0}, {"snippet_id": 81201, "code": "\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex", "label": 0}, {"snippet_id": 91153, "code": " from pants.backend.python.python_requirements import PythonRequirements from pants.backend.python.rules import inject_init, python_test_runner from pants.backend.python.targets.python_app import PythonApp", "label": 0}, {"snippet_id": 72051, "code": "] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1: network name(case sensitive)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive", "label": 0}, {"snippet_id": 15595, "code": " OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup", "label": 0}, {"snippet_id": 26244, "code": "'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle", "label": 0}, {"snippet_id": 79981, "code": " exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest", "label": 0}, {"snippet_id": 39083, "code": ".params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config", "label": 0}, {"snippet_id": 3685, "code": " amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp", "label": 0}, {"snippet_id": 36076, "code": "=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio", "label": 0}, {"snippet_id": 50640, "code": "=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os", "label": 0}, {"snippet_id": 41257, "code": "\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file", "label": 0}, {"snippet_id": 12569, "code": " quite and resume status or duplicate comments\"\"\" PERMITTED_TO_COMMENT=True repository=data[\"repository\"] headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"", "label": 0}, {"snippet_id": 59768, "code": " the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs", "label": 0}, {"snippet_id": 18647, "code": ".DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try:", "label": 0}, {"snippet_id": 2300, "code": "'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet)", "label": 0}, {"snippet_id": 71800, "code": "%s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message", "label": 1}, {"snippet_id": 21103, "code": ".sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'", "label": 0}, {"snippet_id": 77378, "code": "'Exception \"%s\" raised on %s spawn', e, wname) def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr", "label": 0}, {"snippet_id": 89948, "code": ") self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please check you have a JDK ' 'installed. Original error:{}'.format(e)) raise def execute_java", "label": 0}, {"snippet_id": 92111, "code": " Pants doesn't currently support cross-compiling native code. The following targets set platforms arguments other than['current'], which is unsupported for this reason. Please either remove the platforms", "label": 0}, {"snippet_id": 68188, "code": ".status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view", "label": 1}, {"snippet_id": 56831, "code": ".tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter", "label": 0}, {"snippet_id": 88064, "code": " rel_classpath_elements=rel_classpath_elements or[classpath_element] if active_plugins.get(name, rel_classpath_elements) !=rel_classpath_elements: raise TaskError('Plugin{} defined in{} and in{}'.format", "label": 0}, {"snippet_id": 87315, "code": " is specific to each scala version, and is lazily computed by zinc if the appropriate version does not exist. Eventually it would be great to just fetch this rather than compiling it. \"\"\" hasher=sha1()", "label": 1}, {"snippet_id": 43968, "code": "=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None,", "label": 0}, {"snippet_id": 5613, "code": " i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches:", "label": 0}, {"snippet_id": 54938, "code": ")) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if", "label": 0}, {"snippet_id": 44306, "code": " in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow", "label": 0}, {"snippet_id": 58493, "code": " comment'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self): self.client", "label": 0}, {"snippet_id": 21972, "code": "=None, diff=None, force_handlers=None, flush_cache=None, listtasks=None, listtags=None, module_path=None): self.verbosity=verbosity self.inventory=inventory self.listhosts=listhosts self.subset=subset self", "label": 0}, {"snippet_id": 91120, "code": ") environment=_UnknownEnvironment( _ExplicitEnvironment(*homes), _UnknownEnvironment( _EnvVarEnvironment(), _LinuxEnvironment.standard(), _OSXEnvironment.standard() ) ) return _Locator(environment, self", "label": 0}, {"snippet_id": 54652, "code": " lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name", "label": 0}, {"snippet_id": 90690, "code": " jdk=jdk) self._cache[key]=dist return dist def _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets any given constraints and returns it. :param", "label": 0}, {"snippet_id": 13255, "code": "]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data[\"target_repo_branch\"]) request_json={ \"ref\": \"refs/heads/{}\".format(data[\"new_branch\"]), \"sha\": sha, } r=requests.post(url, json=request_json, headers=headers", "label": 0}, {"snippet_id": 90241, "code": ": An iterator over all discovered jvm locations. :rtype: iterator of:class:`DistributionEnvironment.Location` \"\"\" class _EnvVarEnvironment(_DistributionEnvironment): @property def jvm_locations(self): def", "label": 0}, {"snippet_id": 31341, "code": "(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction", "label": 0}, {"snippet_id": 35666, "code": " as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in", "label": 0}, {"snippet_id": 57188, "code": ": t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), value ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value", "label": 0}, {"snippet_id": 39334, "code": ".included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os", "label": 0}, {"snippet_id": 79887, "code": ". Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex", "label": 0}, {"snippet_id": 46014, "code": "(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected", "label": 0}, {"snippet_id": 57938, "code": " clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data={} try: data['bugs']=request.GET.get('bug_id', '').split(',')", "label": 0}, {"snippet_id": 67627, "code": ") self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node", "label": 0}, {"snippet_id": 2829, "code": " comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name", "label": 0}, {"snippet_id": 22355, "code": " the provisioning does not need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within", "label": 0}, {"snippet_id": 60032, "code": " kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset(self)", "label": 0}, {"snippet_id": 64617, "code": "\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f ", "label": 0}, {"snippet_id": 93215, "code": " STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes", "label": 0}, {"snippet_id": 39479, "code": ") rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int", "label": 0}, {"snippet_id": 46733, "code": " level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P", "label": 0}, {"snippet_id": 17572, "code": " SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data", "label": 0}, {"snippet_id": 82216, "code": ".add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests", "label": 0}, {"snippet_id": 9304, "code": " the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords ", "label": 0}, {"snippet_id": 86102, "code": " processor_info_file=os.path.join(compile_context.classes_dir, _PROCESSOR_INFO_FILE) self._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file,", "label": 0}, {"snippet_id": 75577, "code": " make_auth_clear_data(self, reqid=None): if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return self.make_req_msg(d[0], d[1], d[2], fun, d", "label": 0}, {"snippet_id": 16637, "code": "._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self)", "label": 0}, {"snippet_id": 43396, "code": " snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"", "label": 0}, {"snippet_id": 44296, "code": " self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets", "label": 0}, {"snippet_id": 59503, "code": " for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name", "label": 0}, {"snippet_id": 60438, "code": "\"\"\"This module contains the device class and context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields", "label": 0}, {"snippet_id": 92815, "code": ": falsey=(None, '', False) for invalid in falsey: with self.assertRaises(InvalidZipPath): next(open_zip(invalid).gen) def test_open_zip_returns_realpath_on_badzipfile(self): with temporary_file() as not_zip", "label": 0}, {"snippet_id": 92558, "code": " test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the context.') self.assertTrue(os.path.exists(fp.name), 'Temporary file", "label": 0}, {"snippet_id": 26911, "code": " elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" ", "label": 0}, {"snippet_id": 37831, "code": "\"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards", "label": 0}, {"snippet_id": 32489, "code": ")) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output", "label": 0}, {"snippet_id": 599, "code": ".connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],", "label": 0}, {"snippet_id": 29575, "code": ": f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group", "label": 0}, {"snippet_id": 29467, "code": " isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))", "label": 0}, {"snippet_id": 74092, "code": " raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in", "label": 0}, {"snippet_id": 59923, "code": " self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args:", "label": 0}, {"snippet_id": 53234, "code": "=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self", "label": 0}, {"snippet_id": 89101, "code": "**kwargs ) def dependents(self, on_predicate=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate to targets they depend on that satisfy the on_predicate. :API: public", "label": 0}, {"snippet_id": 24544, "code": " self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1':", "label": 0}, {"snippet_id": 39724, "code": "=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 46272, "code": ".dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards", "label": 0}, {"snippet_id": 90898, "code": " given constraints and returns it. :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg, 1.7).", "label": 0}, {"snippet_id": 60740, "code": " based on undefined methods. The dynamic methods pass their arguments directly to __init__ of the inheriting class.\"\"\" def __getattr__(cls, name): \"\"\"Get the attribute call via name\"\"\" def new_object(*args,", "label": 0}, {"snippet_id": 2395, "code": "=(\"%s/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile", "label": 0}, {"snippet_id": 171, "code": "\"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi", "label": 1}, {"snippet_id": 57139, "code": " error=get_value_by_type(value, vtype) if error: return say_no(error) has_perms=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied.') model=apps.get_model(*ctype.split(\".\",", "label": 0}, {"snippet_id": 38817, "code": ".error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please", "label": 0}, {"snippet_id": 854, "code": " processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets", "label": 0}, {"snippet_id": 29210, "code": " @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return", "label": 1}, {"snippet_id": 13422, "code": ".environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/pulls\" url=url.format(data[\"target_repo_fullname\"]) request_json={ \"title\": \"Fix", "label": 0}, {"snippet_id": 68974, "code": " client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self,", "label": 1}, {"snippet_id": 75532, "code": "[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None)", "label": 0}, {"snippet_id": 22273, "code": " logger import azurelinuxagent.common.utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError", "label": 0}, {"snippet_id": 68347, "code": " AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,", "label": 0}, {"snippet_id": 77173, "code": ".pr_back_sock=self.p.ctx.socket(zmq.ROUTER) self.pr_back_sock.bind(self.pr_ba) def read_newproxies(self): if not os.path.isfile(self.newproxyfile): return newproxies=set() with open(self.newproxyfile, 'rt') as f", "label": 0}, {"snippet_id": 4365, "code": "(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False", "label": 0}, {"snippet_id": 20288, "code": " None: raise RuntimeError('debugger already running') assert self._session is None argv=[ filename, ] +list(argv) if kwargs.pop('nodebug', False): argv.insert(0, '--nodebug') self._launch(argv, **kwargs)", "label": 0}, {"snippet_id": 39576, "code": ".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string", "label": 0}, {"snippet_id": 85502, "code": " cls.register_jvm_tool(register, 'compiler-interface', classpath=[ JarDependency(org='org.scala-sbt', name='compiler-interface', rev=zinc_rev), ], main='no.such.main.Main', custom_rules=shader_rules) cls", "label": 0}, {"snippet_id": 26532, "code": " found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self", "label": 0}, {"snippet_id": 83037, "code": " \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime", "label": 0}, {"snippet_id": 47520, "code": ".rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__", "label": 0}, {"snippet_id": 80201, "code": ": \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template", "label": 0}, {"snippet_id": 14264, "code": " user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self", "label": 0}, {"snippet_id": 30556, "code": ", Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException", "label": 1}, {"snippet_id": 83764, "code": " lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=", "label": 0}, {"snippet_id": 73958, "code": "]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr[\"alt_number\"] if str(alt_number_str).lower()==\"auto\": self.alt_number=None elif isint(alt_number_str): self.alt_number", "label": 0}, {"snippet_id": 68769, "code": "\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name", "label": 0}, {"snippet_id": 76152, "code": "('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply", "label": 0}, {"snippet_id": 45900, "code": " format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{", "label": 0}, {"snippet_id": 68029, "code": " ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class", "label": 0}, {"snippet_id": 44869, "code": ": rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources", "label": 0}, {"snippet_id": 34161, "code": "\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring", "label": 0}, {"snippet_id": 23681, "code": " chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device(", "label": 0}, {"snippet_id": 63093, "code": ".mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status=", "label": 0}, {"snippet_id": 80671, "code": ",args.n,args.legitExtensions) \telse: \t\tn=up.detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error", "label": 0}, {"snippet_id": 34754, "code": " e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else", "label": 0}, {"snippet_id": 8275, "code": " executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output", "label": 0}, {"snippet_id": 13932, "code": "=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler,", "label": 0}, {"snippet_id": 47364, "code": " f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f", "label": 0}, {"snippet_id": 86863, "code": " get_fatal_warnings_enabled_args_default(cls): return('-S-Xfatal-warnings', '-C-Werror') @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super", "label": 0}, {"snippet_id": 83223, "code": " params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager, 'ensure_has_status_update_callback'):", "label": 0}, {"snippet_id": 3546, "code": " found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell", "label": 0}, {"snippet_id": 6093, "code": " if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else", "label": 0}, {"snippet_id": 72477, "code": " \"\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser", "label": 0}, {"snippet_id": 41627, "code": " else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule", "label": 0}, {"snippet_id": 1030, "code": "\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE)", "label": 0}, {"snippet_id": 43707, "code": "._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self", "label": 0}, {"snippet_id": 21076, "code": " not match(msg): return msg, False event.set() return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object): @classmethod def wait_all(cls, *awaitables): timeout", "label": 0}, {"snippet_id": 19571, "code": " in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in('--host',", "label": 0}, {"snippet_id": 18623, "code": "=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList", "label": 0}, {"snippet_id": 54196, "code": " True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"", "label": 0}, {"snippet_id": 80828, "code": " t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures", "label": 1}, {"snippet_id": 37610, "code": " if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self", "label": 0}, {"snippet_id": 73817, "code": " runtime_config.ftp: self.server=runtime_config.ftp[\"server\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config.ftp[", "label": 0}, {"snippet_id": 49201, "code": " concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder", "label": 0}, {"snippet_id": 10902, "code": " HostUnreachableException from monitoring_config_generator.yaml_tools.merger import merge_yaml_files def is_file(parsed_uri): return parsed_uri.scheme in['', 'file'] def is_host(parsed_uri): return parsed_uri", "label": 0}, {"snippet_id": 22877, "code": " user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin':{0}\".format(output", "label": 0}, {"snippet_id": 30839, "code": " None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self", "label": 0}, {"snippet_id": 8617, "code": " output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module", "label": 0}, {"snippet_id": 73934, "code": " data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config", "label": 0}, {"snippet_id": 71965, "code": "._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer", "label": 1}, {"snippet_id": 31496, "code": " snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args", "label": 0}, {"snippet_id": 10690, "code": ".warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re", "label": 1}, {"snippet_id": 76057, "code": ".success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i, m) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status", "label": 0}, {"snippet_id": 70013, "code": " installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine", "label": 0}, {"snippet_id": 58837, "code": "\"\" def test_get_form(self): response=self.client.get(reverse('ajax-form'), {'app_form': 'testcases.CaseAutomatedForm'}) form=CaseAutomatedForm() self.assertHTMLEqual(str(response.content, encoding=settings", "label": 1}, {"snippet_id": 4075, "code": "(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different", "label": 0}, {"snippet_id": 93881, "code": " check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove", "label": 1}, {"snippet_id": 23545, "code": " log_cmd=False) if ret !=0: raise OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format(username, output)) def del_root_password(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError", "label": 0}, {"snippet_id": 35451, "code": " else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list()", "label": 0}, {"snippet_id": 49117, "code": ".workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile", "label": 0}, {"snippet_id": 52882, "code": "*_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self", "label": 0}, {"snippet_id": 3906, "code": "=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser('validate', help=\"Validate the setup specified by the --config argument\")", "label": 0}, {"snippet_id": 63536, "code": " get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds) def finish_job( self, job_state): stderr", "label": 0}, {"snippet_id": 23482, "code": " username): if self.is_sys_user(username): logger.error(\"{0} is a system user. Will not delete it.\", username) shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y ' +username) self.conf_sudoer", "label": 0}, {"snippet_id": 27268, "code": " 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status", "label": 0}, {"snippet_id": 3094, "code": " res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" %", "label": 0}, {"snippet_id": 44103, "code": ")) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse", "label": 0}, {"snippet_id": 82386, "code": ".lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0]", "label": 0}, {"snippet_id": 7441, "code": " ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires", "label": 0}, {"snippet_id": 31437, "code": "=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job", "label": 0}, {"snippet_id": 40282, "code": " \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>", "label": 0}, {"snippet_id": 41022, "code": " the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self", "label": 0}, {"snippet_id": 34815, "code": " rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re", "label": 1}, {"snippet_id": 52584, "code": "(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f", "label": 0}, {"snippet_id": 39914, "code": " \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]),", "label": 0}, {"snippet_id": 43167, "code": "(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self", "label": 0}, {"snippet_id": 77150, "code": " signal socket %s', self.pr_sa) self.pr_sock=self.p.ctx.socket(zmq.PUB) self.pr_sock.bind(self.pr_sa) def init_pr_back_sock(self): self.log.info( 'Initializing interprocess backward socket %s', self.pr_ba", "label": 0}, {"snippet_id": 54617, "code": "( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause:", "label": 0}, {"snippet_id": 82536, "code": "\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal", "label": 0}, {"snippet_id": 74350, "code": " :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation", "label": 0}, {"snippet_id": 6480, "code": ", taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags", "label": 0}, {"snippet_id": 84933, "code": ".register_jvm_tool(register, cls._key_for_tool_version('scalastyle', version), classpath=[scala_style_jar]) super(ScalaPlatform, cls).register_options(register) register('--scalac-plugins', advanced=True", "label": 1}, {"snippet_id": 48506, "code": ", start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested", "label": 0}, {"snippet_id": 6988, "code": ".] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords", "label": 0}, {"snippet_id": 15204, "code": "=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE", "label": 0}, {"snippet_id": 57981, "code": "'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id']=int(request.GET.get('bug_system_id', 1)) if request.GET.get('a') not in('add', 'remove'): return(None", "label": 0}, {"snippet_id": 42421, "code": ".workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies", "label": 0}, {"snippet_id": 5854, "code": " os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path", "label": 0}, {"snippet_id": 8886, "code": "%s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires", "label": 0}, {"snippet_id": 59665, "code": "'IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items", "label": 0}, {"snippet_id": 45598, "code": "=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self", "label": 0}, {"snippet_id": 85643, "code": " compiler-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property def compiler_interface(self): \"\"\"Return the path to the Zinc compiler-interface jar. ", "label": 0}, {"snippet_id": 13223, "code": " auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) sha=None r=requests.get(url, headers=headers, auth=auth) for ref in r.json(): if ref[\"ref\"].split(\"/\")[-1]==data[\"target_repo_branch\"]: sha", "label": 0}, {"snippet_id": 59101, "code": " OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq", "label": 0}, {"snippet_id": 83221, "code": "( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager, 'ensure_has_status_update_callback", "label": 0}, {"snippet_id": 44167, "code": ", targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete", "label": 0}, {"snippet_id": 31950, "code": " wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else:", "label": 0}, {"snippet_id": 101, "code": " -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0])", "label": 0}, {"snippet_id": 47254, "code": " self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f", "label": 0}, {"snippet_id": 42137, "code": " other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def", "label": 0}, {"snippet_id": 66691, "code": " print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self,", "label": 0}, {"snippet_id": 21756, "code": " pd dataset=pd.read_csv('Churn_Modelling.csv') X=dataset.iloc[:, 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X", "label": 1}, {"snippet_id": 71812, "code": ".print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration:", "label": 1}, {"snippet_id": 27499, "code": " entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self", "label": 0}, {"snippet_id": 14786, "code": " current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def", "label": 0}, {"snippet_id": 32480, "code": " self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark", "label": 0}, {"snippet_id": 63147, "code": "\"Failed to find job corresponding to final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id", "label": 1}, {"snippet_id": 16962, "code": "=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return", "label": 1}, {"snippet_id": 79114, "code": " uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t", "label": 1}, {"snippet_id": 34315, "code": " *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate", "label": 0}, {"snippet_id": 49206, "code": " for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename)", "label": 0}, {"snippet_id": 9099, "code": " extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ ", "label": 1}, {"snippet_id": 6591, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\"", "label": 1}, {"snippet_id": 60574, "code": ")) _observables={'Fock', 'X', 'P', 'Homodyne', 'Heterodyne'} _circuits={} def __init__(self, wires, *, shots=0, hbar=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self", "label": 0}, {"snippet_id": 4467, "code": "\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name", "label": 0}, {"snippet_id": 7319, "code": "<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield", "label": 0}, {"snippet_id": 54098, "code": ", wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self", "label": 0}, {"snippet_id": 81062, "code": " \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here", "label": 0}, {"snippet_id": 34617, "code": ") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file)", "label": 1}, {"snippet_id": 22661, "code": "-IP instance. The first account is the one that the user specified when they did the instance creation. The second one is the admin account that is, or should be, built in to the system. :param username", "label": 0}, {"snippet_id": 40881, "code": "=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames", "label": 0}, {"snippet_id": 35506, "code": " getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider", "label": 0}, {"snippet_id": 17527, "code": " vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self", "label": 0}, {"snippet_id": 57848, "code": "(self.target_field): reviewers[0]}) @require_POST def update_cases_default_tester(request): \"\"\"Update default tester upon selected TestCases\"\"\" proxy=TestCaseUpdateActions(request) return proxy.update()", "label": 0}, {"snippet_id": 75371, "code": ", fun, reqid=None): if not reqid: reqid=self.make_reqid() msg=make_req_msg(interface, method, args, reqid) self.set_response_handler(reqid, fun) return msg def make_router_req_msg(self, iden, interface", "label": 0}, {"snippet_id": 53194, "code": "=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input", "label": 0}, {"snippet_id": 16571, "code": " deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return", "label": 0}, {"snippet_id": 47260, "code": " if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic", "label": 0}, {"snippet_id": 90653, "code": "(minimum_version, self._minimum_version, \"minimum_version\", max) maximum_version=_get_stricter_version(maximum_version, self._maximum_version, \"maximum_version\", min) key=(minimum_version, maximum_version, jdk)", "label": 0}, {"snippet_id": 37859, "code": ", wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self", "label": 0}, {"snippet_id": 26168, "code": " None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '", "label": 0}, {"snippet_id": 77707, "code": ".loads(f.read())) def save_targets(self): data={ 'targets': targets, 'forums': forums, 'domains': domains, 'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle", "label": 0}, {"snippet_id": 46456, "code": " setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names", "label": 0}, {"snippet_id": 43698, "code": ".first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0", "label": 0}, {"snippet_id": 84639, "code": ".get_options().transitive: targets=self.context.target_roots input_snapshots=tuple( target.sources_snapshot(scheduler=self.context._scheduler) for target in targets ) input_files={f.path for snapshot in", "label": 0}, {"snippet_id": 71894, "code": ".debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=", "label": 0}, {"snippet_id": 55776, "code": " rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark", "label": 0}, {"snippet_id": 4443, "code": " boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords,", "label": 0}, {"snippet_id": 7602, "code": " ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords", "label": 0}, {"snippet_id": 49912, "code": " print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync", "label": 0}, {"snippet_id": 21355, "code": " subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ['HOME'] +\"/.reddytt\" sr_dir=work_dir +\"/%s\" % subreddit seen_file", "label": 1}, {"snippet_id": 29183, "code": "=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property", "label": 0}, {"snippet_id": 34505, "code": "\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product", "label": 0}, {"snippet_id": 40504, "code": ": if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return", "label": 0}, {"snippet_id": 62250, "code": "(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result", "label": 0}, {"snippet_id": 77392, "code": " self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif type_==1: if not hasattr(self,", "label": 0}, {"snippet_id": 33310, "code": "=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait", "label": 0}, {"snippet_id": 69811, "code": " client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name", "label": 0}, {"snippet_id": 7422, "code": "=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\":", "label": 0}, {"snippet_id": 33869, "code": ".info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap", "label": 0}, {"snippet_id": 42511, "code": "): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for", "label": 0}, {"snippet_id": 40426, "code": "\"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)", "label": 0}, {"snippet_id": 88131, "code": " raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return plugin_info.find('name').text if os.path.isdir(classpath_element): try: with open", "label": 0}, {"snippet_id": 94630, "code": "% file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def", "label": 0}, {"snippet_id": 20180, "code": "._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None addr=('localhost', self._addr.port) self._run_server_ex=None def run(): try: self._session=self.SESSION", "label": 0}, {"snippet_id": 25014, "code": "._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=", "label": 0}, {"snippet_id": 54967, "code": " rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False", "label": 0}, {"snippet_id": 60758, "code": "*args, **kwargs): \"\"\"Return a new object of the same class, passing the attribute name as the first parameter, along with any additional parameters.\"\"\" return cls(name, *args, **kwargs) return new_object", "label": 0}, {"snippet_id": 42074, "code": "=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value", "label": 0}, {"snippet_id": 32711, "code": " rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order", "label": 0}, {"snippet_id": 85662, "code": " self._zinc_factory._compiler_interface(self._products) @memoized_method def snapshot(self, scheduler): buildroot=get_buildroot() return scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs( tuple", "label": 0}, {"snippet_id": 25512, "code": "\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self", "label": 0}, {"snippet_id": 95828, "code": " in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir", "label": 0}, {"snippet_id": 26468, "code": " icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self", "label": 0}, {"snippet_id": 56136, "code": " in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path", "label": 0}, {"snippet_id": 74567, "code": "]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\", \"lz4hc\", \"zlib\", \"snappy", "label": 0}, {"snippet_id": 57102, "code": " object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no", "label": 0}, {"snippet_id": 28411, "code": "\"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None", "label": 0}, {"snippet_id": 88497, "code": " @property def options(self): \"\"\"Returns the new-style options. :API: public \"\"\" return self._options @property def log(self): \"\"\"Returns the preferred logger for goals to use. :API: public \"\"\" return self._log", "label": 0}, {"snippet_id": 642, "code": "'getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={", "label": 0}, {"snippet_id": 23914, "code": "') !=-1: inet=line.split()[1] elif line.find('ether ') !=-1: mac=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id", "label": 0}, {"snippet_id": 88150, "code": "(os.path.join(classpath_element, _SCALAC_PLUGIN_INFO_FILE), 'r') as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except IOError as e: if e.errno !=errno.ENOENT: raise", "label": 0}, {"snippet_id": 64251, "code": " self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path() new_version_path=self.path_mapper", "label": 0}, {"snippet_id": 60027, "code": " is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__", "label": 0}, {"snippet_id": 13050, "code": "[\"description\"]: FORKED=True r=requests.delete(\"https://api.github.com/repos/\" \"{}\".format(repo[\"full_name\"]), headers=headers, auth=auth) return FORKED def fork_for_pr(data): FORKED=False url=\"https:/", "label": 0}, {"snippet_id": 64682, "code": " * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print \"%s", "label": 0}, {"snippet_id": 83631, "code": ") for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env=getattr( job_wrapper.job_destination, \"env\",[]) return self.get_client", "label": 0}, {"snippet_id": 56059, "code": "=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path", "label": 0}, {"snippet_id": 90527, "code": ".java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version and dist.version > maximum_version: continue if", "label": 0}, {"snippet_id": 35250, "code": "\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(", "label": 1}, {"snippet_id": 49236, "code": " add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used", "label": 0}, {"snippet_id": 42886, "code": " self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError(", "label": 0}, {"snippet_id": 64593, "code": ": nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print", "label": 0}, {"snippet_id": 44371, "code": " f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster", "label": 0}, {"snippet_id": 22248, "code": " if 'log_file' in self.conf: log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template(template, data) ) runner", "label": 0}, {"snippet_id": 23893, "code": "=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0}\".format(iface)) for line in output.split('\\n'): if line.find(", "label": 0}, {"snippet_id": 30728, "code": "[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id", "label": 0}, {"snippet_id": 21622, "code": "() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors", "label": 0}, {"snippet_id": 74910, "code": "(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input\" in runtime_config.benchmark: benchmark_data_input_temp=runtime_config.benchmark[\"benchmark_data_input\"]", "label": 0}, {"snippet_id": 59729, "code": ".simulator' _gates=set(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion'", "label": 0}, {"snippet_id": 7741, "code": ")) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict", "label": 0}, {"snippet_id": 77042, "code": ".conlimit=c.conlimit w.comment_successtimeout=0.2 if c.upload_avatar: w.hooks['post_login'].append(upload_avatar) yield w class WipeManager: def __init__(self, config, *args, **kvargs): super().__init__(", "label": 0}, {"snippet_id": 40014, "code": " file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists", "label": 0}, {"snippet_id": 58669, "code": " encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission Dinied.'}) def test_update_plan_is_active(self): self.client.login( username=self.tester.username, password='password') post_data={", "label": 0}, {"snippet_id": 51363, "code": " value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString", "label": 0}, {"snippet_id": 50394, "code": "=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def", "label": 0}, {"snippet_id": 68452, "code": ")) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len", "label": 0}, {"snippet_id": 19825, "code": "=connecttimeout self._adapter=None self._session=None self._breakpoints=breakpoints @property def adapter(self): return self._adapter @property def session(self): return self._session def start_debugging(self,", "label": 0}, {"snippet_id": 68317, "code": " AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(", "label": 0}, {"snippet_id": 12958, "code": "'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs in data[\"diff\"].items(): if len(diffs) !=0: REQUEST_JSON[\"files\"][file.split(\"/\")[-1] +\".diff\"]={ \"content\": diffs } headers", "label": 0}, {"snippet_id": 2438, "code": ".load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful", "label": 0}, {"snippet_id": 42057, "code": "*_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self,", "label": 0}, {"snippet_id": 54961, "code": ".update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files,", "label": 0}, {"snippet_id": 71899, "code": "=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" ", "label": 0}, {"snippet_id": 74943, "code": "(runtime_config.benchmark[\"benchmark_aggregations\"]) if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config", "label": 1}, {"snippet_id": 48622, "code": "[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len", "label": 0}, {"snippet_id": 26447, "code": "=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\"", "label": 0}, {"snippet_id": 88910, "code": " self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots) def add_new_target(self, address, target_type, target_base=None, dependencies=None, derived_from=None, *", "label": 0}, {"snippet_id": 43252, "code": ".wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 84092, "code": " job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path", "label": 0}, {"snippet_id": 70762, "code": " target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state", "label": 0}, {"snippet_id": 23448, "code": "{0} -e{1} -m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode !=0: raise OSUtilError((\"Failed to create user account:{0}", "label": 0}, {"snippet_id": 45796, "code": " None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match", "label": 0}, {"snippet_id": 90918, "code": " could be found. \"\"\" try: return cls.global_instance()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem", "label": 0}, {"snippet_id": 70402, "code": " if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors", "label": 0}, {"snippet_id": 18026, "code": " column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column", "label": 0}, {"snippet_id": 3276, "code": "\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode", "label": 0}, {"snippet_id": 91739, "code": ", DirectoryWithPrefixToStrip( directory_digest=snapshot.directory_digest, prefix=source_root.path ) ) for snapshot, source_root in sources_snapshots_and_source_roots ] sources_digest=yield Get( Digest,", "label": 0}, {"snippet_id": 74715, "code": " \\\"default\\\" or integer value\") if \"chunk_width\" in runtime_config.vcf_to_zarr: chunk_width_str=runtime_config.vcf_to_zarr[\"chunk_width\"] if chunk_width_str==\"default\": self.chunk_width=None elif isint", "label": 0}, {"snippet_id": 9658, "code": ") and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories", "label": 0}, {"snippet_id": 76084, "code": "() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return", "label": 0}, {"snippet_id": 25128, "code": " homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import", "label": 1}, {"snippet_id": 44937, "code": ": raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0]", "label": 0}, {"snippet_id": 1936, "code": ", 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b'", "label": 0}, {"snippet_id": 54365, "code": " rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause", "label": 0}, {"snippet_id": 92130, "code": ". Please either remove the platforms argument from these targets, or set them to exactly['current']. Bad targets: {} \"\"\".format('\\n'.join(sorted(target.address.reference() for target in bad_targets))) ", "label": 0}, {"snippet_id": 40734, "code": " if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(", "label": 0}, {"snippet_id": 64998, "code": ".Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0:", "label": 0}, {"snippet_id": 73708, "code": " ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): \"\"\" Initializes the configuration representation", "label": 0}, {"snippet_id": 53317, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io", "label": 0}, {"snippet_id": 43405, "code": ".snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments", "label": 0}, {"snippet_id": 1424, "code": " wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\":", "label": 0}, {"snippet_id": 27092, "code": " self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self.station_data.lastData", "label": 1}, {"snippet_id": 15972, "code": "=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if", "label": 0}, {"snippet_id": 63342, "code": ") remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper", "label": 0}, {"snippet_id": 28799, "code": " data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self", "label": 0}, {"snippet_id": 91977, "code": "): return NativeToolchain.scoped_instance(self) @memoized_property def _python_setup(self): return PythonSetup.global_instance() def pydist_has_native_sources(self, target): return target.has_sources(extension", "label": 0}, {"snippet_id": 82413, "code": ".verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %", "label": 0}, {"snippet_id": 94986, "code": ".\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required", "label": 0}, {"snippet_id": 28258, "code": " 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None", "label": 0}, {"snippet_id": 62080, "code": " True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience", "label": 0}, {"snippet_id": 14031, "code": " BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport", "label": 0}, {"snippet_id": 20105, "code": "=self._session if session is None: return self._session=None try: session.close() except ClosedError: pass class DebugClient(_LifecycleClient): \"\"\"A high-level abstraction of a debug client(i.e. editor)", "label": 0}, {"snippet_id": 78426, "code": ".UnknownAnswer as e: self.log.warning('%s: %s', e, e.answer) self.w.sleep(self.errortimeout) except exc.PermanentError as e: self.log.error(e) self.w.sleep(self.errortimeout) except exc.TemporaryError as e", "label": 0}, {"snippet_id": 6085, "code": " @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 ", "label": 0}, {"snippet_id": 73952, "code": " self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr[\"alt_number\"] if str(alt_number_str).lower()", "label": 0}, {"snippet_id": 7374, "code": " output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output", "label": 0}, {"snippet_id": 24138, "code": " STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES", "label": 1}, {"snippet_id": 94933, "code": "=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser.add_parser(\"config\", help='Setting up the", "label": 0}, {"snippet_id": 20639, "code": ": self._add_handler(handler) else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread( target=self._listen, name='test.session', ) self._listenerthread.start() @property", "label": 0}, {"snippet_id": 77230, "code": ": self.log.exception('Line %s raised exception %s', line, e) return newproxies.difference(self.proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try: proxypair=proxypairs.pop", "label": 0}, {"snippet_id": 20945, "code": " self._conn.iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message(self, msg): for i, handler in", "label": 1}, {"snippet_id": 4533, "code": "=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode", "label": 0}, {"snippet_id": 48830, "code": "\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 26378, "code": " variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for", "label": 0}, {"snippet_id": 57174, "code": "(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field %s changed from %s to %s.'", "label": 0}, {"snippet_id": 1377, "code": " wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps)", "label": 0}, {"snippet_id": 31269, "code": " value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\"", "label": 0}, {"snippet_id": 34867, "code": ".dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s", "label": 0}, {"snippet_id": 30947, "code": " Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f", "label": 0}, {"snippet_id": 16999, "code": " _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location", "label": 0}, {"snippet_id": 85812, "code": ".all_dependencies(target) all_extra_cp_entries=list(self._compiler_plugins_cp_entries()) if extra_cp_entries: all_extra_cp_entries.extend(extra_cp_entries) return ClasspathUtil.compute_classpath_entries", "label": 0}, {"snippet_id": 10492, "code": " determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE", "label": 1}, {"snippet_id": 21002, "code": ", required)) def _check_handlers(self): unhandled=[] for handle_msg, name, required in self._handlers: if not required: continue unhandled.append(name or repr(handle_msg)) if unhandled: raise RuntimeError", "label": 0}, {"snippet_id": 32446, "code": ", wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self", "label": 0}, {"snippet_id": 86513, "code": " import JvmCompile from pants.base.build_environment import get_buildroot from pants.base.exceptions import TaskError from pants.base.hash_utils import hash_file from pants.base.workunit import WorkUnitLabel", "label": 0}, {"snippet_id": 15330, "code": " SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port", "label": 0}, {"snippet_id": 92919, "code": ") with stdio_as(stdout_fd=tmp_stdout.fileno(), stderr_fd=tmp_stderr.fileno(), stdin_fd=tmp_stdin.fileno()): self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual", "label": 0}, {"snippet_id": 32374, "code": " None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio", "label": 0}, {"snippet_id": 55843, "code": " input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths", "label": 0}, {"snippet_id": 84984, "code": "(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default='2.12', choices=['2.10', '2", "label": 0}, {"snippet_id": 19483, "code": " if script: extra +=script return args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index('--') except ValueError: script=[] else: script=argv[pos +1:] argv=argv[:pos] for", "label": 0}, {"snippet_id": 11687, "code": " SystemExit as e: exit_code=e.code except BaseException as e: LOG.error(e) exit_code=EXIT_CODE_ERROR finally: stop_time=datetime.now() LOG.info(\"finished in %s\" %(stop_time -start_time)) sys.exit(exit_code", "label": 0}, {"snippet_id": 72901, "code": ".username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory", "label": 0}, {"snippet_id": 84330, "code": "=remote_system_properties.get('galaxy_datatypes_config_file', None) if not remote_datatypes_config: log.warn(NO_REMOTE_DATATYPES_CONFIG) remote_datatypes_config=os.path.join(remote_galaxy_home, 'datatypes_conf.xml", "label": 0}, {"snippet_id": 88510, "code": "\"\"\"Returns the preferred logger for goals to use. :API: public \"\"\" return self._log @property def products(self): \"\"\"Returns the Products manager for the current run. :API: public \"\"\" return self._products", "label": 0}, {"snippet_id": 88968, "code": "): self.source_roots.add_source_root(rel_target_base) if dependencies: dependencies=[dep.address for dep in dependencies] self.build_graph.inject_synthetic_target(address=address, target_type=target_type", "label": 0}, {"snippet_id": 81088, "code": "\texit() \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1])", "label": 0}, {"snippet_id": 3506, "code": " self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not", "label": 0}, {"snippet_id": 92074, "code": "(targets): return False platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys()) if not platform_names or platform_names=", "label": 0}, {"snippet_id": 62519, "code": "(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. ", "label": 0}, {"snippet_id": 38080, "code": " rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__", "label": 0}, {"snippet_id": 68165, "code": ") if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max", "label": 0}, {"snippet_id": 31306, "code": " return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other", "label": 0}, {"snippet_id": 57315, "code": " pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"\" Update Case Run status. \"\"\" now=datetime.datetime.now() data=request", "label": 0}, {"snippet_id": 77580, "code": " in range(uqsize): uds.append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self,", "label": 0}, {"snippet_id": 12101, "code": "\"author\"] diff_url=\"https://api.github.com/repos/{}/pulls/{}\" diff_url=diff_url.format(repository, str(data[\"pr_number\"])) r=requests.get(diff_url, headers=diff_headers, auth=auth) patch=unidiff.PatchSet", "label": 0}, {"snippet_id": 66521, "code": " execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel", "label": 0}, {"snippet_id": 60384, "code": " op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('fock', cutoff_dim=self.cutoff) reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon", "label": 0}, {"snippet_id": 78191, "code": " msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets) super().__init__", "label": 0}, {"snippet_id": 54403, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib", "label": 0}, {"snippet_id": 18904, "code": " Common entry point for loading some form of raw swagger schema. Supports: -python object(dictionary-like) -path to yaml file -path to json file -file object(json or yaml). -json string. -yaml string. \"", "label": 0}, {"snippet_id": 56325, "code": " parameters @require_GET def info(request): \"\"\"Ajax responder for misc information\"\"\" objects=_InfoObjects(request=request, product_id=request.GET.get('product_id')) info_type=getattr(objects, request.GET.get(", "label": 1}, {"snippet_id": 40935, "code": " to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone -", "label": 0}, {"snippet_id": 62704, "code": " Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool", "label": 0}, {"snippet_id": 44287, "code": " \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets", "label": 0}, {"snippet_id": 38682, "code": "=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules", "label": 0}, {"snippet_id": 87181, "code": "(compile_context.zinc_args_file, 'r') as fp: args=fp.read().split() zinc_args[compile_context.target]=args def create_empty_extra_products(self): if self.context.products.is_required_data('zinc_analysis'", "label": 0}, {"snippet_id": 17586, "code": " 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave", "label": 0}, {"snippet_id": 11362, "code": " MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s,", "label": 0}, {"snippet_id": 61178, "code": " 2x2 rotation matrix rz(c) @ ry(b) @ rz(a) \"\"\" return frz(c) @(fry(b) @ frz(a)) def ket(*args): r\"\"\"Input validation for an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised", "label": 0}, {"snippet_id": 65230, "code": "\"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 24026, "code": " devlist -b | grep blkvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk ", "label": 0}, {"snippet_id": 21188, "code": " AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None): super(AwaitableResponse, self).__init__(req[\"command\"], event) self.req=req self._result_getter=result_getter @property def resp(self):", "label": 0}, {"snippet_id": 23137, "code": " to check for errors raised by the eject command \"\"\" logger.warn(\"Eject is not supported on this platform\") def get_first_if(self): \"\"\"Return the interface name, and ip addr of the management interface", "label": 0}, {"snippet_id": 35495, "code": ") match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides", "label": 0}, {"snippet_id": 74678, "code": " raise TypeError(\"Invalid value provided for alt_number in configuration.\\n\" \"Expected: \\\"auto\\\" or integer value\") if \"chunk_length\" in runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr", "label": 0}, {"snippet_id": 15561, "code": "._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file", "label": 0}, {"snippet_id": 47042, "code": " except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule", "label": 0}, {"snippet_id": 46785, "code": " import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format", "label": 1}, {"snippet_id": 81636, "code": " %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"", "label": 1}, {"snippet_id": 57969, "code": "',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id", "label": 0}, {"snippet_id": 86562, "code": "' _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class BaseZincCompile", "label": 0}, {"snippet_id": 44253, "code": " Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake", "label": 0}, {"snippet_id": 88797, "code": "): self.log.debug('subproc_map result still not ready...') return res.get() except KeyboardInterrupt: SubprocPool.shutdown(True) raise @contextmanager def new_workunit(self, name, labels=None, cmd='', log_config", "label": 0}, {"snippet_id": 54726, "code": " not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules", "label": 0}, {"snippet_id": 11140, "code": "(\"%Y-%m-%d %H:%M:%S\", localtime()) lines.append(\"%s on %s\" %(Header.MON_CONF_GEN_COMMENT, time_string)) if self.etag: lines.append(\"%s%s\" %(Header.ETAG_COMMENT, self.etag)) if self.mtime: lines.append(", "label": 0}, {"snippet_id": 22576, "code": " When WAAgent gets around to running though, tmsh will reject that value because it is not a fully qualified domain name. The proper value should have been bigip.xxx.yyy WAAgent will not fail if this command", "label": 0}, {"snippet_id": 65581, "code": "(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self", "label": 0}, {"snippet_id": 46339, "code": " wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone", "label": 0}, {"snippet_id": 66584, "code": " Globals from Commands.CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import", "label": 0}, {"snippet_id": 54655, "code": "\"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno", "label": 0}, {"snippet_id": 11925, "code": "\"updated\":{ \"header\": \"\", \"footer\": \"\" } }, \"scanner\":{\"diff_only\": False}, \"pycodestyle\":{ \"ignore\":[], \"max-line-length\": 79, \"count\": False, \"first\": False, \"show-pep8\": False, \"filename\":[], \"exclude", "label": 0}, {"snippet_id": 50263, "code": ".input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], *", "label": 0}, {"snippet_id": 93754, "code": " if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp)", "label": 0}, {"snippet_id": 16498, "code": "): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands", "label": 0}, {"snippet_id": 41107, "code": " in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name)", "label": 0}, {"snippet_id": 95998, "code": "[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr", "label": 0}, {"snippet_id": 6503, "code": "=extract_acronyms ) if api: return output else: if isinstance(output, dict): for i in output: print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"", "label": 0}, {"snippet_id": 95195, "code": "; if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location", "label": 1}, {"snippet_id": 64854, "code": ".get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" ", "label": 1}, {"snippet_id": 57103, "code": "(\"object_pk\") field=data.get('field') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields", "label": 0}, {"snippet_id": 20900, "code": "'response(cmd:{} seq:{})'.format(command, seq) with self._wait_for_message(match, handlername, **kwargs): yield result def _close(self): if self._owned: try: self._conn.close() except ClosedError: pass", "label": 0}, {"snippet_id": 19199, "code": "=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors['response'].add_error(err.messages", "label": 0}, {"snippet_id": 88000, "code": " entire external classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published as \"fat jars\"(which appears to be the norm, since SBT doesn't support plugins with", "label": 0}, {"snippet_id": 49115, "code": ".overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile", "label": 0}, {"snippet_id": 73386, "code": " directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data ", "label": 0}, {"snippet_id": 41587, "code": ")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input)", "label": 0}, {"snippet_id": 63786, "code": ": %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID ", "label": 0}, {"snippet_id": 32348, "code": "=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete)", "label": 0}, {"snippet_id": 14775, "code": " _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not", "label": 0}, {"snippet_id": 71818, "code": " e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e", "label": 1}, {"snippet_id": 26998, "code": "\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if", "label": 0}, {"snippet_id": 81250, "code": " path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek", "label": 0}, {"snippet_id": 31683, "code": "): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict", "label": 0}, {"snippet_id": 93007, "code": ", 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self): with self._stdio_as_tempfiles(): with stdio_as", "label": 0}, {"snippet_id": 95732, "code": "}\".format(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip(path_str, path_temp_output) pathlist_vcf_temp=pathlib.Path(temp_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_temp: path_temp_str", "label": 0}, {"snippet_id": 53124, "code": " os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand", "label": 0}, {"snippet_id": 60887, "code": "._observe is None: raise DeviceError('A qfunc must always conclude with a classical expectation value.') Device._current_context=None self.execute() @property def gates(self): \"\"\"Get the supported gate set.", "label": 0}, {"snippet_id": 93123, "code": "'error!') def test_maybe_profiled(self): with temporary_dir() as td: profile_path=os.path.join(td, 'profile.prof') with maybe_profiled(profile_path): for _ in range(5): print('test') self.assertTrue(os.path", "label": 0}, {"snippet_id": 15436, "code": " return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport", "label": 0}, {"snippet_id": 76251, "code": " def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Auth records on router were cleared') else: self.log.warn('Status %s, passing', wzrpc.name_status(status", "label": 0}, {"snippet_id": 70417, "code": " command classes. The status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand", "label": 0}, {"snippet_id": 83865, "code": " True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e", "label": 0}, {"snippet_id": 17498, "code": " SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def", "label": 0}, {"snippet_id": 84581, "code": " code.\"\"\" @classmethod def subsystem_dependencies(cls): return super(CountLinesOfCode, cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register): super(CountLinesOfCode", "label": 0}, {"snippet_id": 64614, "code": " install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs", "label": 0}, {"snippet_id": 24803, "code": "\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 10866, "code": " words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os", "label": 1}, {"snippet_id": 80704, "code": " cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json", "label": 0}, {"snippet_id": 38637, "code": " None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files:", "label": 0}, {"snippet_id": 46833, "code": " format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards", "label": 0}, {"snippet_id": 5303, "code": ": int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format", "label": 0}, {"snippet_id": 51195, "code": ".group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file", "label": 0}, {"snippet_id": 67580, "code": "\\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s", "label": 0}, {"snippet_id": 18726, "code": "=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 23760, "code": "(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\") if ret: raise OSUtilError(\"Failed to get processor", "label": 0}, {"snippet_id": 86652, "code": " whitelisted regexes.\"\"\" valid_patterns={re.compile(p): v for p, v in whitelisted_args.items()} def validate(idx): arg=args[idx] for pattern, has_argument in valid_patterns.items(): if pattern.match(arg): return", "label": 0}, {"snippet_id": 7745, "code": "=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches", "label": 0}, {"snippet_id": 3632, "code": ". Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger", "label": 0}, {"snippet_id": 50833, "code": " obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly", "label": 0}, {"snippet_id": 76519, "code": ".sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx, sig_addr, *args, **kvargs): self.ctx=ctx self.sig_addr=sig_addr threading", "label": 0}, {"snippet_id": 2458, "code": ".debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found", "label": 0}, {"snippet_id": 35583, "code": "): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None", "label": 0}, {"snippet_id": 40617, "code": ". \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are", "label": 0}, {"snippet_id": 5576, "code": "\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: set of formatted", "label": 0}, {"snippet_id": 82623, "code": ": \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON", "label": 0}, {"snippet_id": 76448, "code": " self.wz_sock.send_multipart(nfr) except wzrpc.WZErrorRep as e: self.log.info(e) self.wz_sock.send_multipart(e.rep_msg) except wzrpc.WZError as e: self.log.warn(e) def run(self): self.__sinit__() if self", "label": 0}, {"snippet_id": 10652, "code": "-enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return", "label": 0}, {"snippet_id": 50679, "code": " self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths", "label": 0}, {"snippet_id": 48328, "code": ": self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as", "label": 0}, {"snippet_id": 24609, "code": " self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium", "label": 0}, {"snippet_id": 62280, "code": "._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name]", "label": 0}, {"snippet_id": 82694, "code": ".proxyCreds[\"username\"] \t\tproxyPass=args.proxyCreds[\"password\"] \telse: \t\tproxyUser=args.proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy", "label": 0}, {"snippet_id": 32038, "code": " raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\"", "label": 0}, {"snippet_id": 60813, "code": " _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots self._out=None self._queue=[] self._observe=None def __repr__(self): \"\"\"String representation.\"\"\" return self.__module__ +'.' +self", "label": 0}, {"snippet_id": 60942, "code": " result(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out @classmethod def capabilities(cls): \"\"\"Get the other capabilities of the plugin. Measurements, batching etc. Returns:", "label": 0}, {"snippet_id": 77307, "code": ".init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess): type_=1 if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not hasattr", "label": 0}, {"snippet_id": 17419, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self):", "label": 0}, {"snippet_id": 88262, "code": " pants.base.workunit import WorkUnit, WorkUnitLabel from pants.build_graph.target import Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products import Products", "label": 1}, {"snippet_id": 8991, "code": " from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output", "label": 0}, {"snippet_id": 36642, "code": "(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties", "label": 0}, {"snippet_id": 43074, "code": "=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log))", "label": 0}, {"snippet_id": 13678, "code": " CREDENTIALS. Please read README.md for instructions.\") \r else:\r twitter=ChippyTwitter(consumerKey,consumerSecret,accessTokenKey,accessTokenSecret)\r \r web=WebFramework(talk)\r isRunning=False\r io.cleanup", "label": 0}, {"snippet_id": 63285, "code": ".old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and", "label": 0}, {"snippet_id": 43608, "code": " attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException", "label": 0}, {"snippet_id": 5573, "code": " _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword", "label": 0}, {"snippet_id": 77088, "code": "://wm-back.sock' self.userqueues={} self.usersfile='wm_users.pickle' self.targetsfile='wm_targets.pickle' self.bumplimitfile='wm_bumplimit.pickle' def init_th_sock(self): self.log.info( 'Initializing intraprocess", "label": 0}, {"snippet_id": 51374, "code": "(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value", "label": 0}, {"snippet_id": 81886, "code": " for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files", "label": 0}, {"snippet_id": 46692, "code": " valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks", "label": 0}, {"snippet_id": 4863, "code": ", categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords, _kw(_sort_kw_matches", "label": 0}, {"snippet_id": 77850, "code": " if self.c.ecount > 0: self.spawn_evaluators() try: while self.running.is_set(): if self.c.tcount==0: self.inter_sleep(5) continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep", "label": 0}, {"snippet_id": 52772, "code": " unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_", "label": 0}, {"snippet_id": 17677, "code": " ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server", "label": 0}, {"snippet_id": 29365, "code": " def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file", "label": 0}, {"snippet_id": 88198, "code": " def product_types(cls): return['runtime_classpath', 'zinc_analysis', 'zinc_args'] def select(self, target): if not isinstance(target, JvmTarget): return False return target.has_sources('.java') or target", "label": 0}, {"snippet_id": 88996, "code": " return new_target def targets(self, predicate=None, **kwargs): \"\"\"Selects targets in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created", "label": 0}, {"snippet_id": 90979, "code": " jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS can be specified via several different", "label": 0}, {"snippet_id": 45799, "code": ": if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer", "label": 0}, {"snippet_id": 4452, "code": ": if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not", "label": 0}, {"snippet_id": 84459, "code": "=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self,", "label": 0}, {"snippet_id": 82289, "code": " upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"", "label": 0}, {"snippet_id": 19578, "code": " is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in('--host', '--server-host', '--port', '-m'): if arg=='", "label": 0}, {"snippet_id": 35839, "code": " try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load", "label": 0}, {"snippet_id": 22663, "code": " first account is the one that the user specified when they did the instance creation. The second one is the admin account that is, or should be, built in to the system. :param username: The username that", "label": 0}, {"snippet_id": 57387, "code": "=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun", "label": 0}, {"snippet_id": 45116, "code": " priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo", "label": 0}, {"snippet_id": 76619, "code": " targets=dict() protected=set() forums=dict() def message(): msg=[] msg.append('[image-original-none-http://simg4.gelbooru.com/' +'/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]') msg.append('\u041a\u0430\u0436\u0434\u044b\u0439", "label": 0}, {"snippet_id": 82719, "code": " proxyProtocol !=None: \t\tproxy +=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy", "label": 0}, {"snippet_id": 30005, "code": " \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard", "label": 0}, {"snippet_id": 40704, "code": " wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default", "label": 0}, {"snippet_id": 11215, "code": " which it receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is given it reads it's default configuration from file system. The configuration", "label": 0}, {"snippet_id": 53056, "code": " always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \",", "label": 0}, {"snippet_id": 1446, "code": ": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method==", "label": 0}, {"snippet_id": 12535, "code": " request.json[\"action\"]==\"opened\": comment_footer.append(config[\"message\"][\"opened\"][\"footer\"]) elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: comment_footer.append(config[\"message\"][\"updated\"][", "label": 0}, {"snippet_id": 47720, "code": " snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged", "label": 0}, {"snippet_id": 9731, "code": "=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results", "label": 0}, {"snippet_id": 39022, "code": ".summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed", "label": 0}, {"snippet_id": 65207, "code": " rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return", "label": 0}, {"snippet_id": 8653, "code": " standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"", "label": 0}, {"snippet_id": 60769, "code": " along with any additional parameters.\"\"\" return cls(name, *args, **kwargs) return new_object class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an illegal operation", "label": 0}, {"snippet_id": 63890, "code": ".states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue", "label": 0}, {"snippet_id": 79075, "code": " capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t\t\telse: \t\t", "label": 0}, {"snippet_id": 5131, "code": "))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER", "label": 0}, {"snippet_id": 46115, "code": " \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per", "label": 0}, {"snippet_id": 92898, "code": " with temporary_file(binary_mode=False) as tmp_stdin,\\ temporary_file(binary_mode=False) as tmp_stdout,\\ temporary_file(binary_mode=False) as tmp_stderr: print(stdin_data, file=tmp_stdin) tmp_stdin.seek(0)", "label": 0}, {"snippet_id": 62513, "code": ", **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly", "label": 0}, {"snippet_id": 62818, "code": " is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset", "label": 0}, {"snippet_id": 83943, "code": ": Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully", "label": 0}, {"snippet_id": 68610, "code": " fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type", "label": 0}, {"snippet_id": 3797, "code": " window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys", "label": 0}, {"snippet_id": 74692, "code": " chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError", "label": 0}, {"snippet_id": 3014, "code": " in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name", "label": 0}, {"snippet_id": 87017, "code": "(self): \"\"\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. \"\"\" return", "label": 0}, {"snippet_id": 57033, "code": ": lambda x: str(x), 'None': lambda x: None, } pipe=pipes.get(v_type, None) if pipe is None: error='Unsupported value type.' else: try: value=pipe(val) except Exception as e: error=str(e) return value, error", "label": 0}, {"snippet_id": 69648, "code": " print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes", "label": 1}, {"snippet_id": 33890, "code": "=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile,", "label": 0}, {"snippet_id": 76713, "code": "', action='store_true', default=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default='randav', help='Directory with avatars') parser.add_argument('--rp-timeout", "label": 0}, {"snippet_id": 61492, "code": ") self._state=U @ self._state A=DefaultQubit._get_operator_matrix(self._observe) if self.shots==0: ev=self.ev(A,[self._observe.wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self", "label": 0}, {"snippet_id": 18449, "code": "=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and", "label": 0}, {"snippet_id": 63819, "code": ": %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id ", "label": 0}, {"snippet_id": 18560, "code": "', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer", "label": 0}, {"snippet_id": 28430, "code": "=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module", "label": 0}, {"snippet_id": 78161, "code": " try: import IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except KeyboardInterrupt: print(\"KeyboardInterrupt\") except SystemExit: break except: print(traceback.format_exc", "label": 1}, {"snippet_id": 20991, "code": ".append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[] for handle_msg, name,", "label": 0}, {"snippet_id": 54186, "code": ", str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if", "label": 0}, {"snippet_id": 24914, "code": "] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0", "label": 0}, {"snippet_id": 37202, "code": ".items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return", "label": 0}, {"snippet_id": 81565, "code": "\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None", "label": 1}, {"snippet_id": 36017, "code": "=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards))", "label": 0}, {"snippet_id": 32165, "code": ": self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try:", "label": 0}, {"snippet_id": 51442, "code": " for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary", "label": 0}, {"snippet_id": 48341, "code": " elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item:", "label": 0}, {"snippet_id": 76607, "code": "=logging.getLogger() ctx=zmq.Context() sig_addr='ipc://signals' sig_sock=ctx.socket(zmq.PUB) sig_sock.bind(sig_addr) domains=set() targets=dict() protected=set() forums=dict() def message(): msg=[] msg", "label": 0}, {"snippet_id": 29290, "code": " raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod", "label": 0}, {"snippet_id": 54320, "code": " < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other", "label": 0}, {"snippet_id": 79813, "code": "-template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the", "label": 0}, {"snippet_id": 21178, "code": " else: message +='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None): super(AwaitableResponse, self).__init__", "label": 0}, {"snippet_id": 45645, "code": "(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self", "label": 0}, {"snippet_id": 42832, "code": "): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self", "label": 0}, {"snippet_id": 94200, "code": ".flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided", "label": 0}, {"snippet_id": 87859, "code": " javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret", "label": 0}, {"snippet_id": 45617, "code": " wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing,", "label": 1}, {"snippet_id": 32178, "code": " str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start,", "label": 0}, {"snippet_id": 12343, "code": "\"action\"]==\"opened\": if config[\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n", "label": 0}, {"snippet_id": 43439, "code": " bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict", "label": 0}, {"snippet_id": 25763, "code": "': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif", "label": 0}, {"snippet_id": 63191, "code": " if not command_line: return try: dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters( client) unstructured_path_rewrites", "label": 0}, {"snippet_id": 29100, "code": " __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException", "label": 1}, {"snippet_id": 6325, "code": " def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory, executable)): return", "label": 1}, {"snippet_id": 46108, "code": " return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional", "label": 0}, {"snippet_id": 39801, "code": "=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self", "label": 0}, {"snippet_id": 54643, "code": ": raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules", "label": 0}, {"snippet_id": 11300, "code": " monitoring_config_generator import set_log_level_to_debug from monitoring_config_generator.yaml_tools.readers import Header, read_config from monitoring_config_generator.yaml_tools.config import YamlConfig", "label": 0}, {"snippet_id": 50568, "code": " shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self", "label": 0}, {"snippet_id": 28509, "code": " updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN", "label": 0}, {"snippet_id": 69113, "code": ".umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\"", "label": 1}, {"snippet_id": 62225, "code": "(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not", "label": 1}, {"snippet_id": 95040, "code": " type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory=\"", "label": 1}, {"snippet_id": 82419, "code": " if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if", "label": 0}, {"snippet_id": 29066, "code": "(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"", "label": 1}, {"snippet_id": 21788, "code": "=[1]) X=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0) from", "label": 1}, {"snippet_id": 68728, "code": "(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\"", "label": 0}, {"snippet_id": 63149, "code": " corresponding to final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for", "label": 1}, {"snippet_id": 92894, "code": "'stdout') stderr_data=u('stderr') with temporary_file(binary_mode=False) as tmp_stdin,\\ temporary_file(binary_mode=False) as tmp_stdout,\\ temporary_file(binary_mode=False) as tmp_stderr: print(stdin_data,", "label": 0}, {"snippet_id": 59782, "code": "\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits", "label": 0}, {"snippet_id": 23715, "code": " dvd: ret={0}\".format(retcode)) def restart_if(self, ifname): shellutil.run(\"/etc/rc.d/dhclient restart{0}\".format(ifname), chk_err=False) def get_total_mem(self): cmd=\"sysctl hw.physmem |awk '{print $2", "label": 0}, {"snippet_id": 45084, "code": "=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate", "label": 0}, {"snippet_id": 80559, "code": "\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\":", "label": 0}, {"snippet_id": 73474, "code": " a Zarr format. Only converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data", "label": 0}, {"snippet_id": 24539, "code": ") self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data", "label": 0}, {"snippet_id": 5758, "code": " component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"", "label": 0}, {"snippet_id": 86389, "code": "), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd), input_files=input_snapshot.directory_digest, output_files", "label": 0}, {"snippet_id": 79826, "code": " code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1,dest", "label": 0}, {"snippet_id": 66321, "code": ".set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\"", "label": 0}, {"snippet_id": 51123, "code": " return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to", "label": 0}, {"snippet_id": 4517, "code": " single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors", "label": 0}, {"snippet_id": 83447, "code": ".monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and LWR client for this job. \"\"\" command_line=None client=None remote_job_config=None compute_environment", "label": 0}, {"snippet_id": 44166, "code": " targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity,", "label": 0}, {"snippet_id": 77689, "code": "']) def load_bumplimit_set(self): if not os.path.isfile(self.bumplimitfile): return with open(self.bumplimitfile, 'rb') as f: self.pc.sets['bumplimit'].update(pickle.loads(f.read())) def save_targets(self", "label": 0}, {"snippet_id": 874, "code": ", 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e','docker", "label": 0}, {"snippet_id": 6364, "code": ". This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and", "label": 0}, {"snippet_id": 7254, "code": " :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean", "label": 0}, {"snippet_id": 46088, "code": " matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value):", "label": 0}, {"snippet_id": 22121, "code": ".pbex=playbook_executor.PlaybookExecutor( playbooks=[playbook], inventory=self.inventory, variable_manager=self.variable_manager, loader=self.loader, options=self.options, passwords={}) def run(self, job_id", "label": 0}, {"snippet_id": 26028, "code": "._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the", "label": 0}, {"snippet_id": 8913, "code": "=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs)", "label": 0}, {"snippet_id": 88020, "code": "'t support plugins with dependencies anyway). \"\"\" plugin_names={p for val in scalac_plugins for p in val.split(',')} if not plugin_names: return{} active_plugins={} buildroot=get_buildroot() cp_product", "label": 0}, {"snippet_id": 88992, "code": " derived_from=derived_from, **kwargs) new_target=self.build_graph.get_target(address) return new_target def targets(self, predicate=None, **kwargs): \"\"\"Selects targets in-play in this run from the target", "label": 0}, {"snippet_id": 32392, "code": " wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict()", "label": 0}, {"snippet_id": 44246, "code": ".persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n", "label": 0}, {"snippet_id": 54402, "code": ": comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order.__iter__()", "label": 0}, {"snippet_id": 42872, "code": ".protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output:", "label": 0}, {"snippet_id": 55867, "code": ", kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def", "label": 0}, {"snippet_id": 91497, "code": ".subsystems.pytest import PyTest from pants.backend.python.subsystems.python_setup import PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch", "label": 0}, {"snippet_id": 91927, "code": ": pass @classmethod def register_options(cls, register): super(PythonNativeCode, cls).register_options(register) register('--native-source-extensions', type=list, default=cls.default_native_source_extensions", "label": 0}, {"snippet_id": 78126, "code": " send_passthrough(frames): msg=[b'WipeManager'] msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames)) sig_sock.send_multipart(msg) def drop_users(): send_passthrough([b'WipeSkel', b'WipeSkel',", "label": 0}, {"snippet_id": 22360, "code": " for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within roughly 50 minutes(100 * 30 seconds", "label": 0}, {"snippet_id": 1321, "code": " wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans", "label": 1}, {"snippet_id": 43029, "code": "=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item", "label": 0}, {"snippet_id": 62739, "code": " XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[", "label": 0}, {"snippet_id": 49204, "code": "( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause:", "label": 0}, {"snippet_id": 23416, "code": " sshd restart', chk_err=False) def useradd(self, username, expiration=None): \"\"\" Create user account with 'username' \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0", "label": 1}, {"snippet_id": 55082, "code": " Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this", "label": 0}, {"snippet_id": 64829, "code": "=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname))", "label": 0}, {"snippet_id": 17158, "code": " FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client", "label": 0}, {"snippet_id": 17999, "code": " _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def", "label": 0}, {"snippet_id": 16785, "code": "[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr", "label": 0}, {"snippet_id": 83758, "code": "=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more", "label": 0}, {"snippet_id": 17277, "code": ") self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename", "label": 1}, {"snippet_id": 12220, "code": "=auth) with open(\"file_to_check.py\", 'w+', encoding=r.encoding) as file_to_check: file_to_check.write(r.text) cmd='pycodestyle{config[pycodestyle_cmd_config]} file_to_check.py'.format( config=config) proc", "label": 0}, {"snippet_id": 81175, "code": " folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using", "label": 0}, {"snippet_id": 13861, "code": ".unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content", "label": 0}, {"snippet_id": 24820, "code": " data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 31, "code": ".decorators import list_route from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3,", "label": 1}, {"snippet_id": 29463, "code": "): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^", "label": 0}, {"snippet_id": 17470, "code": "._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=", "label": 0}, {"snippet_id": 89776, "code": "\"\"Real path to the distribution java.home(resolving links).\"\"\" return os.path.realpath(self.home) @property def java(self): \"\"\"Returns the path to this distribution's java command. If this distribution", "label": 0}, {"snippet_id": 67033, "code": "(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(", "label": 0}, {"snippet_id": 49139, "code": ".snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd", "label": 0}, {"snippet_id": 91144, "code": " import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements from pants.backend.python.rules import", "label": 0}, {"snippet_id": 81068, "code": " unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit() \t\tif len(detectedForms)", "label": 0}, {"snippet_id": 86351, "code": "(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin:{}{}'.format(plugin, ' '.join(args))) return", "label": 0}, {"snippet_id": 81174, "code": " uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be", "label": 0}, {"snippet_id": 13476, "code": "'INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR ACCESS TOKEN SECRET HERE FROM TWITTER'\r \r import sys\r import time\r import subprocess\r import os\r from random import randint\r", "label": 0}, {"snippet_id": 29436, "code": " self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__", "label": 0}, {"snippet_id": 68245, "code": " enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED:", "label": 0}, {"snippet_id": 6055, "code": "\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if", "label": 1}, {"snippet_id": 70473, "code": ".Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable", "label": 0}, {"snippet_id": 63252, "code": ".set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running", "label": 0}, {"snippet_id": 46087, "code": " matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value", "label": 0}, {"snippet_id": 7255, "code": " skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean,", "label": 0}, {"snippet_id": 31355, "code": "\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self", "label": 0}, {"snippet_id": 52110, "code": " raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath", "label": 0}, {"snippet_id": 42492, "code": " self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule)", "label": 0}, {"snippet_id": 50444, "code": " output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params", "label": 0}, {"snippet_id": 46144, "code": "\"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values", "label": 0}, {"snippet_id": 9941, "code": "[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str", "label": 0}, {"snippet_id": 13465, "code": " CONSUMER KEY HERE FROM TWITTER'\r consumerSecret='INSERT YOUR CONSUMER SECRET HERE FROM TWITTER'\r accessTokenKey='INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR ACCESS TOKEN", "label": 0}, {"snippet_id": 66277, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal", "label": 0}, {"snippet_id": 20427, "code": " addr, **kwargs) @classmethod def create_server(cls, addr, **kwargs): def connect(addr, timeout): server=create_server(addr) with socket_timeout(server, timeout): client, _=server.accept() return Connection", "label": 0}, {"snippet_id": 7118, "code": " author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw", "label": 0}, {"snippet_id": 31327, "code": ", other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None", "label": 0}, {"snippet_id": 2944, "code": "=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self", "label": 0}, {"snippet_id": 49862, "code": " elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence", "label": 0}, {"snippet_id": 81997, "code": " code execution. Overrides the default code execution detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group('Required named arguments') requiredNamedArgs", "label": 0}, {"snippet_id": 21111, "code": " not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'.format(awaitable.name)) else: messages.append('Response{}'.format(awaitable", "label": 0}, {"snippet_id": 78258, "code": " msg, t[0]) except exc.Success as e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment", "label": 0}, {"snippet_id": 59293, "code": " Keyword Args for IBMBackend backend: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default", "label": 0}, {"snippet_id": 52730, "code": " prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason", "label": 0}, {"snippet_id": 11052, "code": "'%s') if mtime else int(time()) else: msg=\"Request %s returned with status %s. I don't know how to handle that.\" %(url, response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config", "label": 0}, {"snippet_id": 80389, "code": "+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal", "label": 0}, {"snippet_id": 18971, "code": "(source) if isinstance(response.content, six.binary_type): raw_source=six.text_type(response.content, encoding='utf-8') else: raw_source=response.content else: raw_source=source try: try: return json.loads", "label": 0}, {"snippet_id": 88511, "code": " goals to use. :API: public \"\"\" return self._log @property def products(self): \"\"\"Returns the Products manager for the current run. :API: public \"\"\" return self._products @property def source_roots(self", "label": 0}, {"snippet_id": 66401, "code": ".FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1:", "label": 0}, {"snippet_id": 59451, "code": "().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued", "label": 1}, {"snippet_id": 94187, "code": " found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self", "label": 0}, {"snippet_id": 64106, "code": "} if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception", "label": 0}, {"snippet_id": 43432, "code": "-a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict", "label": 0}, {"snippet_id": 9046, "code": "==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations", "label": 0}, {"snippet_id": 4558, "code": " single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position..", "label": 1}, {"snippet_id": 73356, "code": " read_file_contents(local_filepath): if os.path.isfile(local_filepath): with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config", "label": 0}, {"snippet_id": 64215, "code": " lwr_client, job_wrapper, remote_job_config): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={}", "label": 0}, {"snippet_id": 42051, "code": ")) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException", "label": 0}, {"snippet_id": 41275, "code": ".YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads", "label": 0}, {"snippet_id": 26395, "code": ".warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def", "label": 0}, {"snippet_id": 76548, "code": "(WZWorkerBase, multiprocessing.Process): def start(self, sig_addr, *args, **kvargs): self.sig_addr=sig_addr multiprocessing.Process.start(self, *args, **kvargs) def __sinit__(self): self.ctx=zmq.Context", "label": 0}, {"snippet_id": 11579, "code": " def value_to_icinga(value): \"\"\"Convert a scalar or list to Icinga value format. Lists are concatenated by, and empty(None) values produce an empty string\"\"\" if isinstance(value, list): return \",\".join", "label": 0}, {"snippet_id": 86517, "code": " import get_buildroot from pants.base.exceptions import TaskError from pants.base.hash_utils import hash_file from pants.base.workunit import WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize", "label": 0}, {"snippet_id": 62092, "code": " the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default", "label": 0}, {"snippet_id": 47876, "code": ".touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self", "label": 0}, {"snippet_id": 10673, "code": ".strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't", "label": 1}, {"snippet_id": 62251, "code": " not supported by device{}\".format(operation.name, self.short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self", "label": 0}, {"snippet_id": 25287, "code": "'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol", "label": 1}, {"snippet_id": 78885, "code": " self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s ", "label": 0}, {"snippet_id": 5881, "code": " % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field", "label": 0}, {"snippet_id": 40456, "code": "(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False", "label": 0}, {"snippet_id": 78024, "code": " user) def get_forum_id(name): id_=d.bm_id_forum.get_key(name) int(id_, 10) return id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not in", "label": 0}, {"snippet_id": 72644, "code": "\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments", "label": 1}, {"snippet_id": 31659, "code": "._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch", "label": 0}, {"snippet_id": 39041, "code": ".persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep", "label": 0}, {"snippet_id": 33453, "code": ", \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and", "label": 0}, {"snippet_id": 71761, "code": ".get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd", "label": 0}, {"snippet_id": 39273, "code": ".path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile)", "label": 0}, {"snippet_id": 82056, "code": ".add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group() exclusiveArgs.add_argument", "label": 0}, {"snippet_id": 52813, "code": " files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove", "label": 0}, {"snippet_id": 52201, "code": " chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions", "label": 1}, {"snippet_id": 40145, "code": " mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e", "label": 1}, {"snippet_id": 28146, "code": "=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS,", "label": 1}, {"snippet_id": 64219, "code": "=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths", "label": 0}, {"snippet_id": 82594, "code": "\"+str(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for", "label": 0}, {"snippet_id": 30079, "code": "=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list", "label": 0}, {"snippet_id": 43944, "code": ".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets", "label": 0}, {"snippet_id": 16117, "code": " except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}", "label": 0}, {"snippet_id": 94392, "code": "'cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend", "label": 0}, {"snippet_id": 59208, "code": " import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian", "label": 0}, {"snippet_id": 37791, "code": "=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name:", "label": 0}, {"snippet_id": 52696, "code": "=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def", "label": 0}, {"snippet_id": 542, "code": "='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username", "label": 0}, {"snippet_id": 9067, "code": "=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else:", "label": 0}, {"snippet_id": 48900, "code": "=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self", "label": 0}, {"snippet_id": 54949, "code": " targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 54519, "code": " self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 78767, "code": " logging,concurrent.futures from utils import * from urllib.parse import urljoin,urlparse from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder", "label": 0}, {"snippet_id": 65832, "code": "[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error", "label": 0}, {"snippet_id": 13963, "code": "), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1", "label": 1}, {"snippet_id": 22408, "code": " if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin", "label": 0}, {"snippet_id": 61388, "code": ".keys()) _observables={} _circuits={} def __init__(self, wires, *, shots=0): self.wires=wires self.eng=None self._state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued", "label": 1}, {"snippet_id": 29390, "code": "(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self):", "label": 1}, {"snippet_id": 3377, "code": "(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self", "label": 0}, {"snippet_id": 60250, "code": "\"StrawberryFields Fock device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the", "label": 0}, {"snippet_id": 47565, "code": " __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction", "label": 0}, {"snippet_id": 61591, "code": " operator_map[A.name](*p) def ev(self, A, wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int])", "label": 0}, {"snippet_id": 69672, "code": ": nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print ", "label": 0}, {"snippet_id": 45095, "code": "=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority", "label": 0}, {"snippet_id": 30926, "code": "())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input", "label": 0}, {"snippet_id": 8718, "code": "=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False", "label": 0}, {"snippet_id": 80909, "code": "\t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(\"Found the following entry points: \") print", "label": 0}, {"snippet_id": 18887, "code": " validate_object from flex.validation.request import validate_request from flex.validation.response import validate_response def load_source(source): \"\"\" Common entry point for loading some form of raw", "label": 0}, {"snippet_id": 23789, "code": "(\"Failed to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout", "label": 0}, {"snippet_id": 70513, "code": " GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start", "label": 0}, {"snippet_id": 34974, "code": "(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern", "label": 0}, {"snippet_id": 41784, "code": " def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime", "label": 0}, {"snippet_id": 20141, "code": " client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None self._adapter=DebugAdapter.start(argv, port=self._port) return self._adapter def", "label": 0}, {"snippet_id": 54472, "code": " snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config", "label": 1}, {"snippet_id": 3092, "code": " dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host ", "label": 0}, {"snippet_id": 58523, "code": ": 'new comment', 'run': '99999998,1009900'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No caserun found.'}) def test_add_comment_to_case_runs", "label": 0}, {"snippet_id": 72846, "code": "=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str", "label": 0}, {"snippet_id": 15850, "code": ".sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError", "label": 0}, {"snippet_id": 52087, "code": " \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError", "label": 0}, {"snippet_id": 23849, "code": " iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We will sleep and retry as the network must be up. \"\"\" iface='' inet='' mac='' err, output=shellutil.run_get_output('ifconfig -l ether", "label": 0}, {"snippet_id": 67008, "code": ", \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if", "label": 0}, {"snippet_id": 16239, "code": " console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self", "label": 0}, {"snippet_id": 4116, "code": " the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify", "label": 0}, {"snippet_id": 4987, "code": " ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is", "label": 0}, {"snippet_id": 42002, "code": ":\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables", "label": 0}, {"snippet_id": 92134, "code": " to exactly['current']. Bad targets: {} \"\"\".format('\\n'.join(sorted(target.address.reference() for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup", "label": 0}, {"snippet_id": 64913, "code": " file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs(conf_dir_path, 0755) except OSError, ex:", "label": 0}, {"snippet_id": 70795, "code": "\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()]", "label": 0}, {"snippet_id": 17291, "code": " tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter", "label": 1}, {"snippet_id": 38162, "code": " elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order", "label": 0}, {"snippet_id": 37643, "code": "._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name", "label": 0}, {"snippet_id": 33526, "code": ".subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input", "label": 0}, {"snippet_id": 24033, "code": "{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's", "label": 0}, {"snippet_id": 91329, "code": " pants.goal.task_registrar import TaskRegistrar as task def build_file_aliases(): return BuildFileAliases( targets={ PythonApp.alias(): PythonApp, PythonBinary.alias(): PythonBinary, PythonLibrary.alias()", "label": 0}, {"snippet_id": 5451, "code": "] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]", "label": 0}, {"snippet_id": 57393, "code": ") if mail_context: mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=='case_run_status': for t in targets: field", "label": 0}, {"snippet_id": 14111, "code": " response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data", "label": 0}, {"snippet_id": 75993, "code": "},{1}),{2}:{3}'.\\ format(i, m, wzrpc.name_status(status), repr(data))) elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warning('Recvd unknown", "label": 0}, {"snippet_id": 1450, "code": ", wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action", "label": 0}, {"snippet_id": 66779, "code": " import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None", "label": 0}, {"snippet_id": 47719, "code": " from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards,", "label": 0}, {"snippet_id": 78637, "code": "'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run())) except BaseException", "label": 0}, {"snippet_id": 31692, "code": " input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try", "label": 0}, {"snippet_id": 55984, "code": " decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo", "label": 0}, {"snippet_id": 2705, "code": " comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host))", "label": 0}, {"snippet_id": 3956, "code": "--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch", "label": 0}, {"snippet_id": 18423, "code": " self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename", "label": 0}, {"snippet_id": 242, "code": "=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap", "label": 0}, {"snippet_id": 4006, "code": "'run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args", "label": 0}, {"snippet_id": 93094, "code": " temporary_dir(permissions=0o644) as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self): fake_logger=mock.Mock() with self.assertRaises(AssertionError): with exception_logging", "label": 0}, {"snippet_id": 47770, "code": ".name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self", "label": 0}, {"snippet_id": 18412, "code": "-NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen", "label": 0}, {"snippet_id": 34880, "code": " isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))", "label": 0}, {"snippet_id": 53569, "code": " output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in", "label": 0}, {"snippet_id": 95607, "code": " file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file): with open(local_file", "label": 0}, {"snippet_id": 44931, "code": "(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version", "label": 0}, {"snippet_id": 82675, "code": "] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args", "label": 0}, {"snippet_id": 19416, "code": "', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT -m MODULE[arg...] {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT", "label": 0}, {"snippet_id": 80709, "code": " cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read(", "label": 0}, {"snippet_id": 66503, "code": " MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self", "label": 0}, {"snippet_id": 80590, "code": " proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif", "label": 0}, {"snippet_id": 90434, "code": " ValueError('At least two possible environments must be supplied.') self._possible_environments=possible_environments @property def jvm_locations(self): return itertools.chain(*(pe.jvm_locations for pe", "label": 0}, {"snippet_id": 52742, "code": " files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output", "label": 0}, {"snippet_id": 44339, "code": " for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag", "label": 0}, {"snippet_id": 4086, "code": "(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in", "label": 0}, {"snippet_id": 18941, "code": "=source.read() elif os.path.exists(os.path.expanduser(str(source))): with open(os.path.expanduser(str(source)), 'r') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types)", "label": 0}, {"snippet_id": 42798, "code": ".wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name -", "label": 0}, {"snippet_id": 24263, "code": "'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio'", "label": 0}, {"snippet_id": 6947, "code": " def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var", "label": 0}, {"snippet_id": 54221, "code": " statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self", "label": 0}, {"snippet_id": 10101, "code": "'*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return", "label": 0}, {"snippet_id": 31806, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"", "label": 0}, {"snippet_id": 50110, "code": " include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile,", "label": 0}, {"snippet_id": 13237, "code": ".split(\"/\")[-1]==data[\"target_repo_branch\"]: sha=ref[\"object\"][\"sha\"] url=\"https://api.github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data", "label": 0}, {"snippet_id": 38906, "code": ".name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target", "label": 0}, {"snippet_id": 58273, "code": " import BaseCaseRun from tcms.tests import BasePlanCase from tcms.tests import remove_perm_from_user from tcms.tests import user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests", "label": 0}, {"snippet_id": 84482, "code": "( \".dat\")] return local_dataset_path.with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory", "label": 0}, {"snippet_id": 75555, "code": " reqid=self.make_reqid() args=[interface, method, struct.pack('!B', type_), make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-set-route-type', args, reqid) def make_auth_clear_data", "label": 0}, {"snippet_id": 42545, "code": "*wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_", "label": 1}, {"snippet_id": 47015, "code": "\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards", "label": 0}, {"snippet_id": 19523, "code": "(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except IndexError: nextarg=None if gottarget: script=argv[i:] +script break if arg=='--client': arg='--host' elif arg=='--file': if", "label": 0}, {"snippet_id": 86870, "code": " def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super(BaseZincCompile, cls).register_options(register) register('--whitelisted-args', advanced", "label": 0}, {"snippet_id": 66150, "code": ">=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target", "label": 0}, {"snippet_id": 57573, "code": ": mail_context=TestCase.mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user'", "label": 0}, {"snippet_id": 48747, "code": ".benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \"", "label": 0}, {"snippet_id": 52537, "code": ".dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output", "label": 1}, {"snippet_id": 23169, "code": " Azure(Stack) as 32 bit and without adjusting the struct_size, we can't get the information we need. I believe this may be caused by only python i686 being shipped with BIG-IP instead of python x86_64?? \"", "label": 0}, {"snippet_id": 79153, "code": ".postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t", "label": 0}, {"snippet_id": 6245, "code": " expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent", "label": 1}, {"snippet_id": 33704, "code": " drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if", "label": 0}, {"snippet_id": 43579, "code": "\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict", "label": 0}, {"snippet_id": 73815, "code": " \"server\" in runtime_config.ftp: self.server=runtime_config.ftp[\"server\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password", "label": 0}, {"snippet_id": 51672, "code": " \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname", "label": 0}, {"snippet_id": 17430, "code": " return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport", "label": 0}, {"snippet_id": 19543, "code": "=='--file': if nextarg is None: pydevd.append(arg) continue if nextarg.endswith(':') and '--module' in pydevd: pydevd.remove('--module') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip ", "label": 0}, {"snippet_id": 53206, "code": ".protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set", "label": 0}, {"snippet_id": 56173, "code": " strtobool from django import http from django.db.models import Q, Count from django.contrib.auth.models import User from django.core import serializers from django.core.exceptions import ObjectDoesNotExist", "label": 0}, {"snippet_id": 26205, "code": ", 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], ", "label": 0}, {"snippet_id": 75213, "code": ".iden_reqid_map=BijectiveSetMap() def set_req_handler(self, interface, method, fun): self.req_handlers[(interface, method)]=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]", "label": 0}, {"snippet_id": 70598, "code": "][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.", "label": 0}, {"snippet_id": 45705, "code": " isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?", "label": 0}, {"snippet_id": 511, "code": " expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\"", "label": 0}, {"snippet_id": 73206, "code": " output_dir Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir", "label": 0}, {"snippet_id": 93530, "code": "' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd", "label": 0}, {"snippet_id": 48700, "code": " output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in", "label": 0}, {"snippet_id": 18613, "code": " def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self", "label": 0}, {"snippet_id": 33961, "code": "=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name,", "label": 0}, {"snippet_id": 83504, "code": ".__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory", "label": 0}, {"snippet_id": 21728, "code": ") plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors import ListedColormap X_set, y_set=X_test, y_test X1, X2=np.meshgrid(np.arange(start=X_set[:, 0].min() -1, stop=X_set[:, 0", "label": 0}, {"snippet_id": 42347, "code": " of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params(", "label": 0}, {"snippet_id": 84340, "code": "'datatypes_conf.xml') metadata_kwds['datatypes_config']=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append", "label": 0}, {"snippet_id": 41568, "code": "._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf", "label": 0}, {"snippet_id": 4298, "code": "\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER", "label": 1}, {"snippet_id": 27621, "code": "._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and", "label": 0}, {"snippet_id": 49598, "code": ", ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 52139, "code": " WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum", "label": 0}, {"snippet_id": 72749, "code": " from the server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static():", "label": 1}, {"snippet_id": 85456, "code": " recursive=True), Shader.exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-compiler_2", "label": 1}, {"snippet_id": 92229, "code": " from future.utils import PY3 from pants.util.contextutil import(InvalidZipPath, Timer, environment_as, exception_logging, hermetic_environment_as, maybe_profiled, open_zip, pushd, signal_handler_as, stdio_as", "label": 0}, {"snippet_id": 56098, "code": " os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths", "label": 0}, {"snippet_id": 64434, "code": ", cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string", "label": 0}, {"snippet_id": 32235, "code": " _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try", "label": 0}, {"snippet_id": 48081, "code": " input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self", "label": 0}, {"snippet_id": 23364, "code": ".default import DefaultOSUtil from azurelinuxagent.common.future import ustr class FreeBSDOSUtil(DefaultOSUtil): def __init__(self): super(FreeBSDOSUtil, self).__init__() self._scsi_disks_timeout_set=False", "label": 0}, {"snippet_id": 82941, "code": "\"suffix\":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] ", "label": 1}, {"snippet_id": 76435, "code": " return socks def process_wz_msg(self, frames): try: for nfr in self.wz.parse_router_msg(frames): self.wz_sock.send_multipart(nfr) except wzrpc.WZErrorRep as e: self.log.info(e) self.wz_sock.send_multipart(e", "label": 0}, {"snippet_id": 75690, "code": ".wz_poll_timeout=30 def __sinit__(self): '''Initializes thread-local interface on startup''' self.log=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker=Ticker() self.poller=zmq.Poller(", "label": 1}, {"snippet_id": 59544, "code": ") if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented", "label": 0}, {"snippet_id": 28112, "code": " logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE", "label": 1}, {"snippet_id": 38747, "code": " return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules", "label": 0}, {"snippet_id": 30436, "code": "\"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError", "label": 0}, {"snippet_id": 36627, "code": " resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(", "label": 0}, {"snippet_id": 83538, "code": "=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '') return", "label": 0}, {"snippet_id": 37637, "code": " self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile", "label": 0}, {"snippet_id": 20198, "code": "(): try: self._session=self.SESSION.create_server(addr, **kwargs) except Exception as ex: self._run_server_ex=traceback.format_exc() t=new_hidden_thread( target=run, name='test.client', ) t.start() def", "label": 0}, {"snippet_id": 16211, "code": ",localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last", "label": 0}, {"snippet_id": 66995, "code": "=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self,", "label": 0}, {"snippet_id": 6839, "code": " fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext", "label": 0}, {"snippet_id": 1230, "code": " of your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(", "label": 0}, {"snippet_id": 53361, "code": ", f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i", "label": 1}, {"snippet_id": 11985, "code": " data[\"after_commit_hash\"]) r=requests.get(url, headers=headers, auth=auth) if r.status_code==200: try: new_config=yaml.load(r.text) config=update_dict(config, new_config) except yaml.YAMLError: pass arguments", "label": 0}, {"snippet_id": 27490, "code": " device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest", "label": 0}, {"snippet_id": 78464, "code": ".debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user", "label": 0}, {"snippet_id": 51153, "code": " f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing", "label": 0}, {"snippet_id": 80613, "code": ".manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\"", "label": 0}, {"snippet_id": 11208, "code": " monitoring configuration. It does it by querying an URL from which it receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is given it reads it's", "label": 0}, {"snippet_id": 5027, "code": ", we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1", "label": 0}, {"snippet_id": 22496, "code": ", chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"/sbin/pidof dhclient\") return ret[1] if ret[0]==0 else None def set_hostname(self, hostname): \"\"\"Set the static hostname of the device", "label": 0}, {"snippet_id": 15504, "code": " SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def", "label": 0}, {"snippet_id": 2273, "code": "(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate(", "label": 0}, {"snippet_id": 74452, "code": " dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. ", "label": 0}, {"snippet_id": 16028, "code": " query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num", "label": 0}, {"snippet_id": 58801, "code": "(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.update_url,{ 'content_type': 'testruns.testcaserun', 'object_pk': self.case_run_1.pk, 'field", "label": 0}, {"snippet_id": 60305, "code": "', 'Homodyne'} _circuits={} def __init__(self, wires, *, shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name", "label": 0}, {"snippet_id": 36178, "code": "\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self)", "label": 0}, {"snippet_id": 35450, "code": " first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards", "label": 0}, {"snippet_id": 89916, "code": "=self._get_version(java) if version > self._maximum_version: raise self.Error('The java distribution at{} is too new; expecting no older than' '{} and got{}'.format(java, self._maximum_version, version", "label": 0}, {"snippet_id": 6858, "code": "} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects", "label": 0}, {"snippet_id": 15016, "code": ", handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column", "label": 0}, {"snippet_id": 18048, "code": "'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests", "label": 0}, {"snippet_id": 42612, "code": " name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards", "label": 0}, {"snippet_id": 78451, "code": ".log.warn(e) self.w.sleep(self.errortimeout) def get_targets(self): found_count=0 for user, forum in self.forums: targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self", "label": 0}, {"snippet_id": 20883, "code": " wait_for_response(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq'] result={'msg':", "label": 0}, {"snippet_id": 1790, "code": " row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor", "label": 0}, {"snippet_id": 22706, "code": " username) return None cmd=\"/usr/bin/tmsh create auth user %s partition-access add{ all-partitions{ role admin}} shell bash\" %(username) retcode, out=shellutil.run_get_output(cmd, log_cmd=True, chk_err", "label": 0}, {"snippet_id": 90980, "code": " will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS can be specified via several different ' 'aliases, according", "label": 0}, {"snippet_id": 86393, "code": " input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd), input_files=input_snapshot.directory_digest, output_files=output_files, description='Compiling{} with", "label": 0}, {"snippet_id": 27034, "code": "\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station", "label": 0}, {"snippet_id": 48425, "code": ".add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have", "label": 0}, {"snippet_id": 83153, "code": " but LWR is not configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name", "label": 0}, {"snippet_id": 48971, "code": " priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError", "label": 0}, {"snippet_id": 72035, "code": " command, use REHASH to reload the networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error(", "label": 0}, {"snippet_id": 64242, "code": ".local_path_config.working_directory()) self._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"", "label": 0}, {"snippet_id": 86153, "code": ",) +tuple(ce.path for ce in dependency_classpath) if self.get_options().capture_classpath: self._record_compile_classpath(classpath, ctx.target, ctx.classes_dir) try: distribution=JvmPlatform.preferred_jvm_distribution", "label": 0}, {"snippet_id": 38864, "code": " on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows", "label": 0}, {"snippet_id": 80802, "code": "\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a in attempts: \t\t\tsuffix=a", "label": 1}, {"snippet_id": 70745, "code": ".get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other)", "label": 1}, {"snippet_id": 64933, "code": " any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions", "label": 0}, {"snippet_id": 22739, "code": ", out) ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id=6, salt_len=10): \"\"\"Change a user's password with tmsh Since we are creating the user specified account and", "label": 0}, {"snippet_id": 61754, "code": " ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires < 0) or np.any(wires >=self.wires) or wires[0]==wires[1]: raise", "label": 0}, {"snippet_id": 45135, "code": "): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def", "label": 0}, {"snippet_id": 92315, "code": "() new_output.seek(0) self.assertEqual('False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as", "label": 0}, {"snippet_id": 91440, "code": " task(name='py', action=PythonBinaryCreate).install('binary') task(name='py-wheels', action=LocalPythonDistributionArtifact).install('binary') task(name='isort-prep', action=IsortPrep).install('fmt') task", "label": 0}, {"snippet_id": 92946, "code": "().strip()) print(stdout_data, file=sys.stdout) yield print(stderr_data, file=sys.stderr) tmp_stdout.seek(0) tmp_stderr.seek(0) self.assertEqual(stdout_data, tmp_stdout.read().strip()) self.assertEqual", "label": 0}, {"snippet_id": 54604, "code": "._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file", "label": 0}, {"snippet_id": 28594, "code": ") elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self", "label": 0}, {"snippet_id": 12751, "code": " comment=comment.format(time_now) query=\"https://api.github.com/repos/{}/issues/comments/{}\" query=query.format(data[\"repository\"], str(last_comment_id)) response=requests.patch(query, json={\"body\": comment", "label": 0}, {"snippet_id": 88092, "code": " unresolved_plugins=plugin_names -set(active_plugins.keys()) raise TaskError('Could not find requested plugins:{}'.format(list(unresolved_plugins))) @classmethod @memoized_method def _maybe_get_plugin_name", "label": 0}, {"snippet_id": 77970, "code": " id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append", "label": 0}, {"snippet_id": 50101, "code": " snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack", "label": 0}, {"snippet_id": 14483, "code": "{} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None)", "label": 0}, {"snippet_id": 85541, "code": "): return cls.tool_jar_from_products(products, 'compiler-bridge', cls.options_scope) @classmethod def _compiler_interface(cls, products): return cls.tool_jar_from_products(products, 'compiler-interface", "label": 0}, {"snippet_id": 1227, "code": ")] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return", "label": 0}, {"snippet_id": 11966, "code": "\"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://raw.githubusercontent.com/{}/{}/.pep8speaks.yml\" url=url.format(data[\"repository\"], data", "label": 0}, {"snippet_id": 8086, "code": " fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length)", "label": 0}, {"snippet_id": 93793, "code": "' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name", "label": 0}, {"snippet_id": 55117, "code": "\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow", "label": 0}, {"snippet_id": 26438, "code": "] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1", "label": 0}, {"snippet_id": 6517, "code": ": log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry", "label": 0}, {"snippet_id": 88956, "code": "(get_buildroot(), rel_target_base) if not os.path.exists(abs_target_base): os.makedirs(abs_target_base) if not self.source_roots.find_by_path(rel_target_base): self.source_roots.add_source_root(rel_target_base", "label": 0}, {"snippet_id": 40006, "code": "._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be", "label": 0}, {"snippet_id": 62965, "code": "( __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home", "label": 0}, {"snippet_id": 31218, "code": " log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex)", "label": 0}, {"snippet_id": 32624, "code": ".groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values", "label": 0}, {"snippet_id": 68272, "code": " else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index],", "label": 0}, {"snippet_id": 93062, "code": " NotImplementedError: pass self.assertEqual(mock_signal.call_count, 2) mock_signal.assert_has_calls([ mock.call(signal.SIGUSR2, mock_new_handler), mock.call(signal.SIGUSR2, mock_initial_handler) ]) def", "label": 0}, {"snippet_id": 53309, "code": "._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other", "label": 0}, {"snippet_id": 71360, "code": " \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 95142, "code": "=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service.setup_vcf_to_zarr(input_vcf_dir=vcf_directory, output_zarr_dir", "label": 1}, {"snippet_id": 56011, "code": " RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources", "label": 0}, {"snippet_id": 12919, "code": " \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff", "label": 0}, {"snippet_id": 55402, "code": " resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources", "label": 0}, {"snippet_id": 9369, "code": "=_sort_kw_matches(single_keywords) composite_keywords_p=_sort_kw_matches(composite_keywords) for w in single_keywords_p: categories[w[0].concept]=w[0].type for w in single_keywords_p: categories[w[0].concept", "label": 0}, {"snippet_id": 85542, "code": " return cls.tool_jar_from_products(products, 'compiler-bridge', cls.options_scope) @classmethod def _compiler_interface(cls, products): return cls.tool_jar_from_products(products, 'compiler-interface',", "label": 0}, {"snippet_id": 8073, "code": " sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20%", "label": 0}, {"snippet_id": 38681, "code": " None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files", "label": 0}, {"snippet_id": 17731, "code": ") filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not", "label": 0}, {"snippet_id": 41007, "code": " to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"", "label": 0}, {"snippet_id": 34870, "code": "*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+", "label": 0}, {"snippet_id": 21038, "code": ".TIMEOUT lock, wait=get_locked_and_waiter() def handler(msg): if not match(msg): return msg, False lock.release() return msg, True self._add_handler(handler, handlername) try: yield finally: wait(timeout", "label": 0}, {"snippet_id": 37198, "code": "]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards", "label": 0}, {"snippet_id": 20725, "code": " resp_awaiter=self._get_awaiter_for_request(req, **args) self._conn.send(req) return resp_awaiter def add_handler(self, handler, **kwargs): if self.closed: raise RuntimeError('session closed') self._add_handler", "label": 0}, {"snippet_id": 89008, "code": " in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of the run.", "label": 0}, {"snippet_id": 5375, "code": "[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers", "label": 0}, {"snippet_id": 61671, "code": "(self, U, wires): \"\"\"Expand a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(2, 2): raise", "label": 0}, {"snippet_id": 87093, "code": ".get_options().pants_workdir, get_buildroot()) except ValueError: raise TaskError( \"Hermetic zinc execution currently requires the workdir to be a child of the buildroot \" \"but workdir was{} and buildroot", "label": 0}, {"snippet_id": 64191, "code": "=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append(integrates_datatypes_config) metadata_kwds['datatypes_config']=os.path", "label": 0}, {"snippet_id": 11422, "code": " file_name, yaml_icinga): lines=yaml_icinga.icinga_lines output_writer=OutputWriter(self.output_path(file_name)) output_writer.write_lines(lines) @staticmethod def create_filename(hostname): name='%s.cfg' ", "label": 0}, {"snippet_id": 70086, "code": " handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False)", "label": 0}, {"snippet_id": 78561, "code": ".long_sleep(30) self.schedule(self.comment_loop) if len(self.forums)==0: self.schedule(self.wait_loop) def wait_loop(self): if len(self.targets) > 0: self.schedule(self.comment_loop) return if len(self", "label": 0}, {"snippet_id": 53407, "code": ".discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output", "label": 0}, {"snippet_id": 2427, "code": ".DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as", "label": 0}, {"snippet_id": 67789, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname", "label": 0}, {"snippet_id": 80861, "code": "=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 ", "label": 0}, {"snippet_id": 95561, "code": "=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp=ftp.nlst() if not os.path.isfile(file_path_local)", "label": 0}, {"snippet_id": 62731, "code": ".ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val)", "label": 0}, {"snippet_id": 74304, "code": " output_location is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\"", "label": 0}, {"snippet_id": 80869, "code": "\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: ", "label": 0}, {"snippet_id": 52025, "code": " __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist", "label": 0}, {"snippet_id": 15730, "code": "._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return", "label": 0}, {"snippet_id": 77694, "code": " os.path.isfile(self.bumplimitfile): return with open(self.bumplimitfile, 'rb') as f: self.pc.sets['bumplimit'].update(pickle.loads(f.read())) def save_targets(self): data={ 'targets': targets, 'forums':", "label": 0}, {"snippet_id": 14835, "code": " 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger", "label": 0}, {"snippet_id": 86586, "code": ".\"\"\" _name='zinc' @staticmethod def _write_scalac_plugin_info(resources_dir, scalac_plugin_target): scalac_plugin_info_file=os.path.join(resources_dir, _SCALAC_PLUGIN_INFO_FILE) with safe_open(scalac_plugin_info_file", "label": 0}, {"snippet_id": 49098, "code": "=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir)", "label": 0}, {"snippet_id": 71397, "code": ".set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\"", "label": 0}, {"snippet_id": 18240, "code": " def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options", "label": 0}, {"snippet_id": 28687, "code": " data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 29088, "code": " self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self.station_data.lastData", "label": 1}, {"snippet_id": 60345, "code": ".eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name,", "label": 0}, {"snippet_id": 46596, "code": " plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \"", "label": 0}, {"snippet_id": 30448, "code": " yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath):", "label": 0}, {"snippet_id": 20525, "code": " if self.VERBOSE: print(repr(msg)) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed write=send_as_write(self._sock) body", "label": 0}, {"snippet_id": 14404, "code": " _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r')", "label": 0}, {"snippet_id": 32829, "code": ", glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None", "label": 1}, {"snippet_id": 26429, "code": ".netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement", "label": 0}, {"snippet_id": 3229, "code": ": for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node", "label": 0}, {"snippet_id": 15128, "code": " data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data[ 'message']))", "label": 0}, {"snippet_id": 43904, "code": " UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info", "label": 0}, {"snippet_id": 2690, "code": ", comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile", "label": 0}, {"snippet_id": 36376, "code": " file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property", "label": 0}, {"snippet_id": 33709, "code": "=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info", "label": 0}, {"snippet_id": 33715, "code": "=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores", "label": 0}, {"snippet_id": 23865, "code": " output=shellutil.run_get_output('ifconfig -l ether', chk_err=False) if err: raise OSUtilError(\"Can't find ether interface:{0}\".format(output)) ifaces=output.split() if not ifaces: raise OSUtilError(\"Can", "label": 0}, {"snippet_id": 60219, "code": "'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'Kerr': Kgate, 'QuadraticPhase", "label": 0}, {"snippet_id": 44386, "code": "\" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"", "label": 0}, {"snippet_id": 63375, "code": " include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\"", "label": 1}, {"snippet_id": 62696, "code": " IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator", "label": 0}, {"snippet_id": 67905, "code": " if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration", "label": 0}, {"snippet_id": 23805, "code": "'sysctl kern.cam.da.default_timeout={0}'.format(timeout)) if ret: raise OSUtilError(\"Failed set SCSI disks timeout:{0}\".format(output)) self._scsi_disks_timeout_set=True def check_pid_alive(self, pid):", "label": 0}, {"snippet_id": 37871, "code": ", wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards", "label": 0}, {"snippet_id": 82428, "code": ": \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\")", "label": 0}, {"snippet_id": 63849, "code": " def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck in the queued/running state when Galaxy started\"\"\" job_state=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id())", "label": 0}, {"snippet_id": 10520, "code": " urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\"", "label": 1}, {"snippet_id": 25386, "code": " if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return", "label": 0}, {"snippet_id": 19208, "code": " unicode_literals import tempfile import collections import six import json import yaml from flex.core import load_source def test_native_mapping_is_passthrough(): source={'foo': 'bar'} result=load_source(source", "label": 0}, {"snippet_id": 40668, "code": ") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( ", "label": 1}, {"snippet_id": 44927, "code": ".priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if", "label": 0}, {"snippet_id": 39893, "code": "[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path)", "label": 0}, {"snippet_id": 50820, "code": "\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self)", "label": 0}, {"snippet_id": 94882, "code": " the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"", "label": 1}, {"snippet_id": 5235, "code": " list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted", "label": 0}, {"snippet_id": 57489, "code": " return say_no(\"You don't have enough permission to update TestCases.\") action=self.get_update_action() if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return", "label": 0}, {"snippet_id": 8237, "code": " invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open", "label": 1}, {"snippet_id": 3488, "code": "\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(", "label": 0}, {"snippet_id": 9183, "code": " skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object", "label": 0}, {"snippet_id": 53420, "code": ".protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for", "label": 0}, {"snippet_id": 65531, "code": ".view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE:", "label": 0}, {"snippet_id": 28476, "code": "\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return", "label": 0}, {"snippet_id": 71509, "code": " client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path)", "label": 1}, {"snippet_id": 57893, "code": "'comment', None) if not comment: return say_no('Comments needed') run_ids=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter", "label": 0}, {"snippet_id": 76083, "code": ".auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry", "label": 0}, {"snippet_id": 95116, "code": " print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled", "label": 1}, {"snippet_id": 90243, "code": " jvm locations. :rtype: iterator of:class:`DistributionEnvironment.Location` \"\"\" class _EnvVarEnvironment(_DistributionEnvironment): @property def jvm_locations(self): def env_home(home_env_var): home=os", "label": 0}, {"snippet_id": 15764, "code": "._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles(", "label": 0}, {"snippet_id": 72980, "code": " file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter ", "label": 0}, {"snippet_id": 89912, "code": "._minimum_version, version)) if self._maximum_version: version=self._get_version(java) if version > self._maximum_version: raise self.Error('The java distribution at{} is too new; expecting no older than' '{} and got", "label": 0}, {"snippet_id": 65855, "code": " elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR:", "label": 0}, {"snippet_id": 42671, "code": "._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item", "label": 0}, {"snippet_id": 48777, "code": "=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True", "label": 0}, {"snippet_id": 26689, "code": "': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low", "label": 0}, {"snippet_id": 54621, "code": " chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException", "label": 0}, {"snippet_id": 24888, "code": " >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 87070, "code": "*kwargs) self._processor_info_dir=os.path.join(self.workdir, 'apt-processor-info') ZincCompile.validate_arguments(self.context.log, self.get_options().whitelisted_args, self._args) if self.execution_strategy", "label": 0}, {"snippet_id": 48785, "code": " is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement", "label": 0}, {"snippet_id": 39516, "code": " isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version", "label": 0}, {"snippet_id": 76919, "code": ".proxy_type=sup.proxytype.socks4 elif proxytype=='SOCKS5': net.proxy_type=sup.proxytype.socks5 else: raise TypeError('Invalid proxytype %s' % proxytype) net.useragent=random.choice(d.ua_list) net.timeout", "label": 1}, {"snippet_id": 13157, "code": " +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json={ \"name\": name, \"description\": \"Forked", "label": 0}, {"snippet_id": 26469, "code": " icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self):", "label": 0}, {"snippet_id": 23335, "code": ".common.utils.fileutil as fileutil import azurelinuxagent.common.utils.shellutil as shellutil import azurelinuxagent.common.utils.textutil as textutil import azurelinuxagent.common.logger as logger from", "label": 0}, {"snippet_id": 11233, "code": ". The configuration file is: /etc/monitoring_config_generator/config.yaml' Usage: monconfgenerator[--debug][--targetdir=<directory>][--skip-checks][URL] monconfgenerator -h Options: -h Show this message", "label": 0}, {"snippet_id": 79894, "code": "=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=", "label": 0}, {"snippet_id": 23656, "code": " set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def remove_route_for_dhcp_broadcast(self, ifname): shellutil.run(\"route delete 255.255.255.255", "label": 0}, {"snippet_id": 93253, "code": "'debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name", "label": 0}, {"snippet_id": 92560, "code": " with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the context.') self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist", "label": 0}, {"snippet_id": 34969, "code": ") is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for", "label": 0}, {"snippet_id": 94918, "code": " benchmark run), and config argument for where is the config file. \"\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser", "label": 0}, {"snippet_id": 35320, "code": "] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items", "label": 0}, {"snippet_id": 38631, "code": ".0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules", "label": 0}, {"snippet_id": 52939, "code": ".output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self", "label": 0}, {"snippet_id": 91370, "code": " PantsRequirement.alias: PantsRequirement, } ) def register_goals(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local-dists', action=BuildLocalPythonDistributions).install", "label": 0}, {"snippet_id": 17034, "code": "{ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data", "label": 0}, {"snippet_id": 23568, "code": "') if err: raise OSUtilError(\"Failed to delete root password: Failed to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info() if data[0]==ifname: return data[2].replace(':", "label": 0}, {"snippet_id": 26312, "code": "{ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors", "label": 0}, {"snippet_id": 52697, "code": " files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self", "label": 0}, {"snippet_id": 95209, "code": " run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files(ftp_server, ftp_directory, files=None): pass def record_runtime(benchmark, timestamp): pass def main", "label": 1}, {"snippet_id": 8472, "code": " number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True", "label": 1}, {"snippet_id": 32479, "code": " rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile)", "label": 0}, {"snippet_id": 92040, "code": " whether the current target closure has native sources and if so, ensures that Pants is only targeting the current platform. :param tgts: a list of:class:`Target` objects. :return: a boolean value indicating", "label": 0}, {"snippet_id": 70353, "code": ", fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt", "label": 0}, {"snippet_id": 3090, "code": "=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host", "label": 0}, {"snippet_id": 28601, "code": " self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium", "label": 0}, {"snippet_id": 30029, "code": "]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex", "label": 0}, {"snippet_id": 75173, "code": "'Router', b'auth-set-route-type')] self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init() self", "label": 0}, {"snippet_id": 16657, "code": ".GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if ", "label": 0}, {"snippet_id": 65986, "code": ")\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [", "label": 0}, {"snippet_id": 58358, "code": " class TestIndex(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self.client.get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-login'),", "label": 0}, {"snippet_id": 16249, "code": " user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request", "label": 0}, {"snippet_id": 76224, "code": " self.log.warn('Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_unbind_route_data(i, m, wzauth_data.bind_route[i, m])) def clear_auth(self): self.log", "label": 0}, {"snippet_id": 87684, "code": " zinc_relpath, Zinc.ZINC_COMPILE_MAIN] +zinc_args) req=ExecuteProcessRequest( argv=argv, input_files=merged_input_digest, output_files=(analysis_cache,), output_directories=(classes_dir,), description=", "label": 0}, {"snippet_id": 48748, "code": " else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined", "label": 0}, {"snippet_id": 58777, "code": "(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission Dinied.'}) def", "label": 0}, {"snippet_id": 13489, "code": " time\r import subprocess\r import os\r from random import randint\r from threading import Thread\r from chippyRuxpin_audioPlayer import AudioPlayer\r from chippyRuxpin_gpio import GPIO\r from chippyRuxpin_twitter", "label": 0}, {"snippet_id": 30856, "code": "\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self", "label": 0}, {"snippet_id": 25859, "code": "._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if", "label": 0}, {"snippet_id": 73575, "code": "(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)", "label": 0}, {"snippet_id": 8630, "code": " keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion", "label": 0}, {"snippet_id": 43277, "code": " ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()", "label": 0}, {"snippet_id": 27645, "code": " and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 90178, "code": " of a java distribution.\"\"\" @classmethod def from_home(cls, home): \"\"\"Creates a location given the JAVA_HOME directory. :param string home: The path of the JAVA_HOME directory. :returns: The java distribution", "label": 0}, {"snippet_id": 12577, "code": "\"] headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/issues/{}/comments\" url=url.format(repository", "label": 0}, {"snippet_id": 90450, "code": " itertools.chain(*(pe.jvm_locations for pe in self._possible_environments)) class _Locator(object): class Error(Distribution.Error): \"\"\"Error locating a java distribution.\"\"\" def __init__(self, distribution_environment", "label": 0}, {"snippet_id": 24836, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self", "label": 0}, {"snippet_id": 28554, "code": "._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self", "label": 0}, {"snippet_id": 47194, "code": " not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and", "label": 0}, {"snippet_id": 81999, "code": " the default code execution detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group('Required named arguments') requiredNamedArgs.add_argument(\"-u", "label": 0}, {"snippet_id": 30019, "code": " wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if", "label": 0}, {"snippet_id": 84919, "code": ".full_version ) classpath.append(jline_dep) cls.register_jvm_tool(register, cls._key_for_tool_version('scala-repl', version), classpath=classpath) def register_style_tool(version): cls.register_jvm_tool", "label": 1}, {"snippet_id": 37488, "code": " is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name:", "label": 0}, {"snippet_id": 70683, "code": ": view=view.lower() if view.startswith(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs", "label": 1}, {"snippet_id": 5678, "code": " %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match", "label": 0}, {"snippet_id": 49360, "code": "(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall", "label": 0}, {"snippet_id": 66365, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base", "label": 0}, {"snippet_id": 30693, "code": ".rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio", "label": 0}, {"snippet_id": 24209, "code": ", 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], ", "label": 0}, {"snippet_id": 53221, "code": ".version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0", "label": 0}, {"snippet_id": 5356, "code": " for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,", "label": 0}, {"snippet_id": 88387, "code": "(Report.WARN, *msg_elements) def error(self, *msg_elements): self._run_tracker.log(Report.ERROR, *msg_elements) def fatal(self, *msg_elements): self._run_tracker.log(Report.FATAL, *msg_elements) def __init__", "label": 0}, {"snippet_id": 30390, "code": " pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON", "label": 0}, {"snippet_id": 80205, "code": "+=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging", "label": 0}, {"snippet_id": 17741, "code": " _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self", "label": 0}, {"snippet_id": 73373, "code": " output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input", "label": 0}, {"snippet_id": 94011, "code": " deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res", "label": 0}, {"snippet_id": 47617, "code": "=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output", "label": 0}, {"snippet_id": 9867, "code": "{0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword", "label": 0}, {"snippet_id": 87914, "code": "))) for arg in scalac_plugin_map[name]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin", "label": 0}, {"snippet_id": 5980, "code": " urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns", "label": 1}, {"snippet_id": 409, "code": "=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname", "label": 0}, {"snippet_id": 22687, "code": " system :param expiration: The expiration date to use. We do not use this value. \"\"\" if self.get_userentry(username): logger.info(\"User{0} already exists, skip useradd\", username) return None cmd=\"/usr/bin", "label": 0}, {"snippet_id": 82762, "code": "=\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex", "label": 0}, {"snippet_id": 28616, "code": " data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\"", "label": 0}, {"snippet_id": 49287, "code": "\"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self", "label": 0}, {"snippet_id": 37003, "code": "[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params", "label": 0}, {"snippet_id": 28213, "code": " None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle'", "label": 0}, {"snippet_id": 91271, "code": " PythonBinaryCreate from pants.backend.python.tasks.python_bundle import PythonBundle from pants.backend.python.tasks.python_repl import PythonRepl from pants.backend.python.tasks.python_run import PythonRun from", "label": 0}, {"snippet_id": 61939, "code": " autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as", "label": 0}, {"snippet_id": 24754, "code": " elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle", "label": 0}, {"snippet_id": 14416, "code": "') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else", "label": 0}, {"snippet_id": 53036, "code": " __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules", "label": 0}, {"snippet_id": 8108, "code": "(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir", "label": 0}, {"snippet_id": 51205, "code": " return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern):", "label": 0}, {"snippet_id": 66633, "code": "\\w+):\", s) if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\"", "label": 0}, {"snippet_id": 11365, "code": " directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s, writing to %s\"", "label": 0}, {"snippet_id": 60425, "code": ".quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self.observe.params) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex", "label": 0}, {"snippet_id": 43540, "code": ",... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1", "label": 0}, {"snippet_id": 68759, "code": ".append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index]", "label": 0}, {"snippet_id": 61849, "code": ":`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ", "label": 0}, {"snippet_id": 59079, "code": "================== **Module name:**:mod:`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize", "label": 0}, {"snippet_id": 76753, "code": " default=5, help='noproxy_rp timeout') parser.add_argument('--caprate_minp', type=int, default=5, help='Cap rate minimum possible count for limit check') parser.add_argument('--caprate_limit', type=float,", "label": 0}, {"snippet_id": 10474, "code": " PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order", "label": 0}, {"snippet_id": 40062, "code": "(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self,", "label": 1}, {"snippet_id": 25172, "code": "], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY", "label": 0}, {"snippet_id": 77662, "code": " loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data['domains']) if 'sets' in data: self.log.debug('Other sets were loaded') self.pc.sets", "label": 0}, {"snippet_id": 62468, "code": " True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\"", "label": 0}, {"snippet_id": 80668, "code": " \t\tn=up.detectValidExtensions(extensions,args.n,args.legitExtensions) \telse: \t\tn=up.detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions", "label": 0}, {"snippet_id": 16715, "code": " self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self", "label": 0}, {"snippet_id": 44981, "code": "=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def", "label": 0}, {"snippet_id": 5538, "code": "(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires", "label": 0}, {"snippet_id": 51116, "code": " f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\", "label": 0}, {"snippet_id": 48966, "code": "\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0", "label": 0}, {"snippet_id": 62651, "code": "={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the", "label": 0}, {"snippet_id": 55257, "code": " return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list", "label": 0}, {"snippet_id": 84069, "code": "): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) if not remote_work_dir_copy", "label": 1}, {"snippet_id": 17662, "code": ": debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage", "label": 0}, {"snippet_id": 81294, "code": "{self.inputName:(filename,fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2:", "label": 0}, {"snippet_id": 54501, "code": "=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"", "label": 0}, {"snippet_id": 88699, "code": " submit_background_work_chain(self, work_chain, parent_workunit_name=None): \"\"\" :API: public \"\"\" background_root_workunit=self.run_tracker.get_background_root_workunit() if parent_workunit_name: workunit_parent_ctx=self", "label": 0}, {"snippet_id": 32339, "code": " InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.", "label": 0}, {"snippet_id": 33205, "code": "=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict()", "label": 0}, {"snippet_id": 65503, "code": " message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv", "label": 0}, {"snippet_id": 24682, "code": "'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp", "label": 0}, {"snippet_id": 53143, "code": " Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule", "label": 0}, {"snippet_id": 49874, "code": "=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self", "label": 0}, {"snippet_id": 87946, "code": " containing the plugin metadata. The rest are the internal transitive deps of the plugin. This allows us to have in-repo plugins with dependencies(unlike javac, scalac doesn't load plugins or their deps", "label": 0}, {"snippet_id": 31753, "code": " branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output:", "label": 0}, {"snippet_id": 75768, "code": ".term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method", "label": 1}, {"snippet_id": 61796, "code": "] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before", "label": 0}, {"snippet_id": 38119, "code": "): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"", "label": 0}, {"snippet_id": 85906, "code": ".engine.fs import DirectoryToMaterialize from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator from pants.util.dirutil import", "label": 0}, {"snippet_id": 66190, "code": "(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\"", "label": 0}, {"snippet_id": 1279, "code": "(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 10874, "code": "\nimport datetime import os import os.path import urlparse import socket from time import localtime, strftime, time from requests.exceptions import RequestException, ConnectionError, Timeout import requests", "label": 0}, {"snippet_id": 87703, "code": ".target.address.spec), jdk_home=text_type(self._zinc.dist.home), ) res=self.context.execute_process_synchronously(req, self.name(),[WorkUnitLabel.COMPILER]) self.context._scheduler.materialize_directories((", "label": 1}, {"snippet_id": 75869, "code": "=t.elapsed(False) if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self", "label": 0}, {"snippet_id": 44295, "code": " return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list", "label": 0}, {"snippet_id": 92682, "code": " test_temporary_dir_with_root_dir(self): with temporary_dir() as path1: with temporary_dir(root_dir=path1) as path2: self.assertTrue(os.path.realpath(path2).startswith(os.path.realpath(path1)), 'Nested temporary dir should be", "label": 0}, {"snippet_id": 26074, "code": "\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo", "label": 1}, {"snippet_id": 2054, "code": "'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi", "label": 0}, {"snippet_id": 85625, "code": "._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list of str \"\"\" return self._zinc_factory.dist @memoized_property def compiler_bridge(self): \"\"\"Return the path to the", "label": 0}, {"snippet_id": 76375, "code": "(timeout * 1000) while self.sleep_ticker.elapsed(False) < timeout: try: self.poll(timeout * 1000) except Resume as e: return def poll(self, timeout=None): try: socks=dict(self.poller.poll(timeout if timeout !", "label": 1}, {"snippet_id": 12924, "code": "{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON", "label": 0}, {"snippet_id": 76139, "code": " type for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests()", "label": 0}, {"snippet_id": 71658, "code": ".Globals import Globals from Commands.CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration", "label": 0}, {"snippet_id": 29360, "code": ".lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards,", "label": 0}, {"snippet_id": 14057, "code": "} if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result", "label": 0}, {"snippet_id": 69755, "code": ".Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self", "label": 0}, {"snippet_id": 19599, "code": "'-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith('-'): supported.append", "label": 1}, {"snippet_id": 49292, "code": " Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self", "label": 0}, {"snippet_id": 50661, "code": ".path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self", "label": 0}, {"snippet_id": 31586, "code": ")==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output", "label": 0}, {"snippet_id": 2033, "code": " i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e", "label": 0}, {"snippet_id": 11390, "code": " hostname): if not hostname: raise NoSuchHostname('hostname not found') output_path=self.output_path(self.create_filename(hostname)) old_header=Header.parse(output_path) return header_source.is_newer_than", "label": 0}, {"snippet_id": 25165, "code": " SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise", "label": 0}, {"snippet_id": 48811, "code": "=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary", "label": 0}, {"snippet_id": 36581, "code": " to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, ", "label": 0}, {"snippet_id": 813, "code": "(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID", "label": 0}, {"snippet_id": 2719, "code": ".logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger", "label": 0}, {"snippet_id": 20920, "code": " ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still running') self._check_handlers", "label": 0}, {"snippet_id": 67241, "code": " %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print", "label": 1}, {"snippet_id": 48402, "code": " kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name)", "label": 0}, {"snippet_id": 72410, "code": "(needs 1: protocol module name)') return proto=utils.getProtocolModule(name) importlib.reload(proto) irc.reply(\"Done. You will have to manually disconnect and reconnect any network using the %r module for", "label": 0}, {"snippet_id": 1016, "code": ", 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn", "label": 0}, {"snippet_id": 38046, "code": "() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards", "label": 0}, {"snippet_id": 50418, "code": " decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths,", "label": 0}, {"snippet_id": 77352, "code": " else 'th{0}').format(i))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception", "label": 0}, {"snippet_id": 94575, "code": "\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name)", "label": 0}, {"snippet_id": 12024, "code": " arguments.append(\"--{}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments.append(\"--{}={}\".format(key, ','.join(value))) config[\"pycodestyle_cmd_config\"", "label": 0}, {"snippet_id": 40404, "code": " for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError", "label": 0}, {"snippet_id": 10887, "code": " ConnectionError, Timeout import requests import yaml from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, HostUnreachableException from monitoring_config_generator.yaml_tools", "label": 0}, {"snippet_id": 69664, "code": "), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name", "label": 0}, {"snippet_id": 83261, "code": " lwr_status): if lwr_status==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model", "label": 0}, {"snippet_id": 84732, "code": "(WorkUnitLabel.TOOL,)) files_content_tuple=self.context._scheduler.product_request( FilesContent, [exec_result.output_directory_digest] )[0].dependencies files_content={fc.path: fc.content.decode('utf-8') for fc", "label": 1}, {"snippet_id": 13266, "code": "{}\".format(data[\"new_branch\"]), \"sha\": sha, } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not create new branch in the fork\" def autopep8ify", "label": 0}, {"snippet_id": 80317, "code": " without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must", "label": 0}, {"snippet_id": 38266, "code": "=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self", "label": 0}, {"snippet_id": 60275, "code": " commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac", "label": 0}, {"snippet_id": 29683, "code": "\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not", "label": 0}, {"snippet_id": 36257, "code": " RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\"", "label": 0}, {"snippet_id": 19000, "code": ": return yaml.load(raw_source) except(yaml.scanner.ScannerError, yaml.parser.ParserError): pass except NameError: pass raise ValueError( \"Unable to parse `{0}`. Tried yaml and json.\".format(source), ) def", "label": 1}, {"snippet_id": 30119, "code": "\"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist", "label": 0}, {"snippet_id": 65841, "code": " target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering", "label": 0}, {"snippet_id": 56300, "code": " tuple(ctype.split('.')) if request.user.has_perm(perm): return True return False def strip_parameters(request_dict, skip_parameters): parameters={} for key, value in request_dict.items(): if key not in", "label": 0}, {"snippet_id": 16149, "code": " OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm", "label": 0}, {"snippet_id": 36890, "code": " sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params,", "label": 0}, {"snippet_id": 54573, "code": "=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict()", "label": 0}, {"snippet_id": 74028, "code": " chunk_width_str==\"default\": self.chunk_width=None elif isint(chunk_width_str): self.chunk_width=int(chunk_width_str) else: raise TypeError(\"Invalid value provided for chunk_width in configuration.\\n\" ", "label": 0}, {"snippet_id": 70295, "code": "][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING", "label": 0}, {"snippet_id": 5043, "code": " MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">", "label": 0}, {"snippet_id": 371, "code": ".data, safe=False) elif action=='loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data", "label": 0}, {"snippet_id": 73284, "code": "}\".format(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip(path_str, path_temp_output) pathlist_vcf_temp=pathlib.Path(temp_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_temp: path_temp_str", "label": 0}, {"snippet_id": 73427, "code": "**/*.vcf\") for path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir,", "label": 0}, {"snippet_id": 69410, "code": ".join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params)", "label": 0}, {"snippet_id": 1823, "code": " rows: data={'state': row[0], 'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data)", "label": 0}, {"snippet_id": 88884, "code": " the lock was held before this call. :API: public \"\"\" if not self._lock.acquired: return False else: self._lock.release() return True def is_unlocked(self): \"\"\"Whether the global lock object is actively", "label": 0}, {"snippet_id": 29084, "code": " to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else:", "label": 1}, {"snippet_id": 15157, "code": " syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData", "label": 0}, {"snippet_id": 73167, "code": " urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file): with open(local_file, 'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in", "label": 0}, {"snippet_id": 41037, "code": "(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for", "label": 0}, {"snippet_id": 48438, "code": " self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, ", "label": 0}, {"snippet_id": 71854, "code": " ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type", "label": 0}, {"snippet_id": 26536, "code": " self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data[", "label": 0}, {"snippet_id": 28862, "code": "='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 55730, "code": " named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority", "label": 0}, {"snippet_id": 43034, "code": " SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items():", "label": 0}, {"snippet_id": 95036, "code": ".\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return", "label": 0}, {"snippet_id": 87337, "code": " cp_entry in[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os", "label": 1}, {"snippet_id": 34509, "code": " Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple", "label": 0}, {"snippet_id": 45122, "code": "(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, *", "label": 0}, {"snippet_id": 51214, "code": "(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern)", "label": 0}, {"snippet_id": 20996, "code": " handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[] for handle_msg, name, required in self._handlers: if not required:", "label": 0}, {"snippet_id": 49546, "code": ".update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io", "label": 0}, {"snippet_id": 27718, "code": "\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self", "label": 0}, {"snippet_id": 48242, "code": " self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 52107, "code": " YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a", "label": 0}, {"snippet_id": 17748, "code": "']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list", "label": 0}, {"snippet_id": 30239, "code": ".items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j", "label": 0}, {"snippet_id": 38071, "code": ") def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return", "label": 0}, {"snippet_id": 68191, "code": " view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\"", "label": 1}, {"snippet_id": 48257, "code": " is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 89566, "code": "'The specified binary path is invalid:{}'.format(bin_path)) if not bool(home_path) ^ bool(bin_path): raise ValueError('Exactly one of home path or bin path should be supplied, given: ' 'home_path={} bin_path", "label": 0}, {"snippet_id": 30830, "code": "(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown", "label": 0}, {"snippet_id": 85942, "code": " logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): \"\"\"Compile Java code using Javac.\"\"\" _name='java' @staticmethod def _write_javac_plugin_info(resources_dir, javac_plugin_target): javac_plugin_info_file", "label": 0}, {"snippet_id": 63895, "code": " in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner", "label": 0}, {"snippet_id": 87501, "code": "['-analysis-map', ','.join('{}:{}'.format( relative_to_exec_root(k), relative_to_exec_root(v) ) for k, v in upstream_analysis.items())]) zinc_args.extend(self._zinc.rebase_map_args) zinc_args.extend(args", "label": 0}, {"snippet_id": 83505, "code": " client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory'],", "label": 0}, {"snippet_id": 12237, "code": "[pycodestyle_cmd_config]} file_to_check.py'.format( config=config) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"extra_results\"][filename]=stdout.decode(r", "label": 0}, {"snippet_id": 38461, "code": "\"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self", "label": 0}, {"snippet_id": 34794, "code": "=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic,", "label": 1}, {"snippet_id": 84265, "code": "(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']", "label": 0}, {"snippet_id": 62784, "code": "\"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend", "label": 0}, {"snippet_id": 69764, "code": ".EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name", "label": 0}, {"snippet_id": 43823, "code": " add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used", "label": 0}, {"snippet_id": 15349, "code": "=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append", "label": 0}, {"snippet_id": 9413, "code": " 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords, _kw(_sort_kw_matches(acronyms, output_limit))) else", "label": 0}, {"snippet_id": 6190, "code": "): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines", "label": 1}, {"snippet_id": 48436, "code": " if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self", "label": 0}, {"snippet_id": 8499, "code": " @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number ", "label": 1}, {"snippet_id": 83328, "code": "( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config", "label": 0}, {"snippet_id": 6535, "code": " continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile", "label": 0}, {"snippet_id": 45352, "code": " chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f", "label": 1}, {"snippet_id": 57927, "code": " caserun found.') add_comment(runs, comment, request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on", "label": 0}, {"snippet_id": 29946, "code": " return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format", "label": 0}, {"snippet_id": 36619, "code": ".output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables", "label": 0}, {"snippet_id": 1899, "code": ": cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0]", "label": 0}, {"snippet_id": 21235, "code": " getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get('href') for a in soup(", "label": 0}, {"snippet_id": 792, "code": "=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split", "label": 0}, {"snippet_id": 40389, "code": " os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append", "label": 0}, {"snippet_id": 79109, "code": ".\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd", "label": 1}, {"snippet_id": 78442, "code": ") self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.log.warn(e) self.w.sleep(self.errortimeout) def get_targets(self): found_count=0 for user, forum in self.forums: targets=[] self.log", "label": 0}, {"snippet_id": 88921, "code": " target_type, target_base=None, dependencies=None, derived_from=None, **kwargs): \"\"\"Creates a new target, adds it to the context and returns it. This method ensures the target resolves files against the", "label": 0}, {"snippet_id": 93086, "code": "(permissions=0o700) as f: self.assertEqual(0o700, os.stat(f.name)[0] & 0o777) with temporary_dir(permissions=0o644) as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self", "label": 0}, {"snippet_id": 66232, "code": ".dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status", "label": 0}, {"snippet_id": 16102, "code": "'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData", "label": 1}, {"snippet_id": 70561, "code": " message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS", "label": 0}, {"snippet_id": 2212, "code": " JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(", "label": 0}, {"snippet_id": 45465, "code": ".file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self", "label": 1}, {"snippet_id": 95265, "code": " numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The", "label": 1}, {"snippet_id": 14562, "code": "._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start", "label": 0}, {"snippet_id": 40996, "code": "): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None", "label": 0}, {"snippet_id": 89704, "code": ".path.join(self.home, 'lib') if self.jdk: yield os.path.join(self.home, 'jre', 'lib') for name in names: for path in lib_paths(): lib_path=os.path.join(path, name) if os.path.exists(lib_path): yield lib_path", "label": 0}, {"snippet_id": 48680, "code": "=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output", "label": 0}, {"snippet_id": 42605, "code": ".touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params,", "label": 0}, {"snippet_id": 39499, "code": ")): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo", "label": 0}, {"snippet_id": 69392, "code": ".append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes", "label": 0}, {"snippet_id": 71532, "code": " client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name", "label": 0}, {"snippet_id": 4553, "code": " extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ ", "label": 1}, {"snippet_id": 40178, "code": " not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open", "label": 0}, {"snippet_id": 54583, "code": ": None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows", "label": 0}, {"snippet_id": 62757, "code": "', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified", "label": 0}, {"snippet_id": 18077, "code": ".json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy", "label": 0}, {"snippet_id": 67629, "code": ") def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type", "label": 0}, {"snippet_id": 41142, "code": " def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name", "label": 0}, {"snippet_id": 51354, "code": " return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value,", "label": 0}, {"snippet_id": 69800, "code": " \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print", "label": 0}, {"snippet_id": 8085, "code": " of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 *", "label": 0}, {"snippet_id": 11534, "code": ".services: self.write_section('service', service) def write_line(self, line): self.icinga_lines.append(line) def write_section(self, section_name, section_data): self.write_line(\"\") self.write_line(\"define", "label": 0}, {"snippet_id": 1993, "code": ".cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate(", "label": 0}, {"snippet_id": 45628, "code": "(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self", "label": 1}, {"snippet_id": 89348, "code": ".contextutil import temporary_dir from pants.util.memo import memoized_method, memoized_property from pants.util.meta import AbstractClass from pants.util.osutil import OS_ALIASES, normalize_os_name from pants", "label": 0}, {"snippet_id": 74219, "code": "=runtime_config.benchmark[\"benchmark_data_input\"] if benchmark_data_input_temp in benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark:", "label": 0}, {"snippet_id": 67946, "code": " CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import", "label": 0}, {"snippet_id": 78394, "code": ".sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min exc caught, topic_successtimeout +0.1, cur: %f', self.topic_successtimeout", "label": 0}, {"snippet_id": 50802, "code": " follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\"", "label": 0}, {"snippet_id": 80834, "code": "\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested ", "label": 1}, {"snippet_id": 31007, "code": "\"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 6471, "code": " output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache", "label": 0}, {"snippet_id": 27055, "code": " auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list", "label": 0}, {"snippet_id": 55011, "code": ", ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 17010, "code": ", handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column", "label": 0}, {"snippet_id": 61926, "code": " PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as", "label": 0}, {"snippet_id": 25299, "code": " 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string", "label": 1}, {"snippet_id": 82771, "code": " Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName)", "label": 0}, {"snippet_id": 88695, "code": "(self.build_graph) self.run_tracker.pantsd_stats.set_affected_targets_size(target_count) return target_count def submit_background_work_chain(self, work_chain, parent_workunit_name=None): \"\"\" :API: public ", "label": 0}, {"snippet_id": 92764, "code": "(t.finish, clock.time()) def test_open_zipDefault(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w') as zf: self.assertTrue(zf._allowZip64) def test_open_zipTrue(self", "label": 0}, {"snippet_id": 70425, "code": " of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to", "label": 0}, {"snippet_id": 61685, "code": " target subsystem Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(2, 2): raise ValueError('2x2 matrix required.') if len(wires) !=1: raise ValueError('One target subsystem required.') wires=wires[0] before", "label": 0}, {"snippet_id": 57551, "code": " self._update_objects=TestCase.objects.filter(pk__in=case_ids) return self._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none(self.request, pk_enough) except Http404", "label": 0}, {"snippet_id": 33976, "code": "*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames", "label": 0}, {"snippet_id": 6427, "code": ".utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode", "label": 1}, {"snippet_id": 11737, "code": " VALUES('{}', now());\" \\ \"\".format(repository) try: cursor.execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def follow_user(user): \"\"\"Follow the user of the service\"\"\" headers", "label": 0}, {"snippet_id": 31237, "code": " +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name", "label": 0}, {"snippet_id": 85216, "code": ") elif name.endswith(self.version): raise ValueError('The name \"{0}\" should not be suffixed with the scala platform version ' '({1}): it will be added automatically.'.format(name, self.version)) return", "label": 0}, {"snippet_id": 10537, "code": ") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak", "label": 1}, {"snippet_id": 13567, "code": " time.time() -lastMouthEventTime > 0.4):\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 0)\r \r def updateEyes():\r while isRunning:\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set(", "label": 0}, {"snippet_id": 64628, "code": " classes. The mount command aims to start Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine", "label": 0}, {"snippet_id": 51400, "code": " v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after", "label": 1}, {"snippet_id": 84187, "code": " setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason -datatypes may", "label": 0}, {"snippet_id": 16758, "code": " return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles", "label": 0}, {"snippet_id": 22177, "code": " templateEnv=jinja2.Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template.render( data) return outputText def run(self, state, data=None, context=None):", "label": 0}, {"snippet_id": 29916, "code": "[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values", "label": 0}, {"snippet_id": 63165, "code": " self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination", "label": 0}, {"snippet_id": 42031, "code": ", output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update", "label": 0}, {"snippet_id": 4053, "code": " def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center) main_window.show() sys.exit(app.exec_(", "label": 0}, {"snippet_id": 8558, "code": " except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines:", "label": 1}, {"snippet_id": 5915, "code": "\" BibClassify text extractor. This module provides method to extract the fulltext from local or remote documents. Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide", "label": 1}, {"snippet_id": 40897, "code": " in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards", "label": 0}, {"snippet_id": 83199, "code": "'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"", "label": 0}, {"snippet_id": 1910, "code": "(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name'", "label": 0}, {"snippet_id": 41388, "code": " format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs", "label": 0}, {"snippet_id": 40851, "code": ".normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names", "label": 0}, {"snippet_id": 5722, "code": " by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison:", "label": 0}, {"snippet_id": 94381, "code": " check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if", "label": 0}, {"snippet_id": 63371, "code": " include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True", "label": 1}, {"snippet_id": 25272, "code": " 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status", "label": 0}, {"snippet_id": 63610, "code": " failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate", "label": 0}, {"snippet_id": 51984, "code": "[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def", "label": 0}, {"snippet_id": 56132, "code": "[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path)", "label": 0}, {"snippet_id": 36949, "code": "=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self", "label": 0}, {"snippet_id": 32365, "code": ", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete", "label": 0}, {"snippet_id": 73401, "code": " Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation", "label": 0}, {"snippet_id": 16741, "code": " x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0", "label": 0}, {"snippet_id": 77040, "code": ".caprate_limit w.conlimit=c.conlimit w.comment_successtimeout=0.2 if c.upload_avatar: w.hooks['post_login'].append(upload_avatar) yield w class WipeManager: def __init__(self, config, *args, **kvargs):", "label": 0}, {"snippet_id": 37836, "code": ".name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input", "label": 0}, {"snippet_id": 58054, "code": "'bug_system_id'] bug_ids=data['bugs'] try: validate_bug_id(bug_ids, bug_system_id) except ValidationError as e: return say_no(str(e)) bz_external_track=data['bz_external_track'] action=data['action'] try: if", "label": 0}, {"snippet_id": 21615, "code": " random_state=0) from sklearn.preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics", "label": 0}, {"snippet_id": 25809, "code": "'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 88203, "code": "'zinc_analysis', 'zinc_args'] def select(self, target): if not isinstance(target, JvmTarget): return False return target.has_sources('.java') or target.has_sources('.scala') def select_source(self, source_file_path", "label": 0}, {"snippet_id": 32099, "code": " inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len", "label": 0}, {"snippet_id": 52725, "code": ": raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output", "label": 0}, {"snippet_id": 81326, "code": "\t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex", "label": 0}, {"snippet_id": 75246, "code": " method): del self.req_handlers[(interface, method)] def del_response_handler(self, reqid): del self.response_handlers[reqid] def del_sig_handler(self, interface, method): del self.sig_handlers[(interface", "label": 0}, {"snippet_id": 69579, "code": " next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError", "label": 0}, {"snippet_id": 30818, "code": ".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError", "label": 0}, {"snippet_id": 44151, "code": ".io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules,", "label": 0}, {"snippet_id": 30297, "code": ": for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len", "label": 0}, {"snippet_id": 35536, "code": " toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"", "label": 0}, {"snippet_id": 80864, "code": "\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint", "label": 0}, {"snippet_id": 56566, "code": "] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan", "label": 1}, {"snippet_id": 69967, "code": " preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file", "label": 0}, {"snippet_id": 2164, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi':", "label": 0}, {"snippet_id": 41264, "code": " install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(", "label": 0}, {"snippet_id": 93595, "code": "%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion", "label": 0}, {"snippet_id": 63707, "code": ".kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" ", "label": 0}, {"snippet_id": 65965, "code": ".get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime", "label": 0}, {"snippet_id": 11373, "code": " LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s, writing to %s\" % (self.source, self.target_dir)) def _is_newer(self, header_source, hostname): if not", "label": 0}, {"snippet_id": 39745, "code": " decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo", "label": 0}, {"snippet_id": 81869, "code": ":password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format:", "label": 0}, {"snippet_id": 46571, "code": "[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def", "label": 0}, {"snippet_id": 51602, "code": "*comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, ", "label": 0}, {"snippet_id": 22044, "code": "=scp_extra_args self.ssh_extra_args=ssh_extra_args self.poll_interval=poll_interval self.seconds=seconds self.check=check self.syntax=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache", "label": 0}, {"snippet_id": 12806, "code": "=r.encoding) py_files={} for patchset in patch: if patchset.target_file[-3:]=='.py': py_file=patchset.target_file[1:] py_files[py_file]=[] for hunk in patchset: for line in hunk.target_lines(): if line", "label": 0}, {"snippet_id": 23798, "code": ", timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout={0}'.format(timeout)) if ret: raise OSUtilError(\"Failed set SCSI disks timeout", "label": 0}, {"snippet_id": 84182, "code": "( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for", "label": 0}, {"snippet_id": 11842, "code": " GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get('X-Hub-Signature') if header_signature is None: abort(403) sha_name, signature=header_signature.split", "label": 0}, {"snippet_id": 82857, "code": ".startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\"", "label": 0}, {"snippet_id": 33359, "code": ", ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 63286, "code": "=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and LWR client", "label": 0}, {"snippet_id": 42580, "code": ".temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch", "label": 0}, {"snippet_id": 69205, "code": "): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error", "label": 0}, {"snippet_id": 10325, "code": " return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator", "label": 0}, {"snippet_id": 28795, "code": "\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 44744, "code": ".first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not", "label": 0}, {"snippet_id": 94404, "code": " pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is", "label": 0}, {"snippet_id": 93337, "code": ".config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp", "label": 0}, {"snippet_id": 94316, "code": ": self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState", "label": 0}, {"snippet_id": 9614, "code": "/datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template ", "label": 0}, {"snippet_id": 94619, "code": "\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i ", "label": 0}, {"snippet_id": 53248, "code": ".workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict", "label": 0}, {"snippet_id": 54030, "code": "=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name:", "label": 0}, {"snippet_id": 51228, "code": "[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(", "label": 0}, {"snippet_id": 39446, "code": ": rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int)", "label": 0}, {"snippet_id": 6776, "code": "(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords", "label": 0}, {"snippet_id": 2695, "code": "\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger", "label": 0}, {"snippet_id": 54453, "code": ", print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from", "label": 1}, {"snippet_id": 67534, "code": " * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self", "label": 0}, {"snippet_id": 6118, "code": " log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines", "label": 1}, {"snippet_id": 42431, "code": "._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self", "label": 0}, {"snippet_id": 41897, "code": " protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files.", "label": 0}, {"snippet_id": 88622, "code": " invalidation_report(self): return self._invalidation_report def __str__(self): ident=Target.identify(self.targets()) return 'Context(id:{}, targets:{})'.format(ident, self.targets()) @contextmanager def", "label": 0}, {"snippet_id": 74975, "code": " dictionary of the form <dict>.<section>[<option>] and the corresponding values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite", "label": 0}, {"snippet_id": 35110, "code": " format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type", "label": 0}, {"snippet_id": 21784, "code": ":, 2]) onehotencoder=OneHotEncoder(categorical_features=[1]) X=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split", "label": 1}, {"snippet_id": 62411, "code": " because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction", "label": 0}, {"snippet_id": 406, "code": " action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user", "label": 0}, {"snippet_id": 5010, "code": " not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies", "label": 0}, {"snippet_id": 47916, "code": ".norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self", "label": 0}, {"snippet_id": 664, "code": "'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset", "label": 0}, {"snippet_id": 79080, "code": "\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t\t\telse: \t\t\t\tself.logger.warning(\"Code execution detection", "label": 0}, {"snippet_id": 62315, "code": "[self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def shutdown(self): \"\"\"Shutdown. \"\"\" pass def _deallocate", "label": 0}, {"snippet_id": 90691, "code": " return dist def _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets any given constraints and returns it. :param minimum_version: minimum jvm version", "label": 0}, {"snippet_id": 7247, "code": "'BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author", "label": 0}, {"snippet_id": 6470, "code": " output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode", "label": 0}, {"snippet_id": 9116, "code": " format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a", "label": 0}, {"snippet_id": 15606, "code": "): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished", "label": 0}, {"snippet_id": 14606, "code": " SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive():", "label": 0}, {"snippet_id": 34763, "code": " \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException:", "label": 0}, {"snippet_id": 71004, "code": "(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets", "label": 0}, {"snippet_id": 32544, "code": " True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"", "label": 0}, {"snippet_id": 90814, "code": "}') else: error_format=('Failed to locate a{} distribution with minimum_version{}, ' 'maximum_version{}') raise self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)", "label": 0}, {"snippet_id": 34443, "code": " None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os", "label": 0}, {"snippet_id": 11866, "code": " mac=hmac.new(os.environ[\"GITHUB_PAYLOAD_SECRET\"].encode(), msg=request.data, digestmod=\"sha1\") if not hmac.compare_digest(str(mac.hexdigest()), str(signature)): abort(403) return True def check_pythonic_pr", "label": 0}, {"snippet_id": 36298, "code": ".dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output", "label": 1}, {"snippet_id": 30061, "code": " wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path", "label": 0}, {"snippet_id": 83340, "code": " command_line, client, remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if not command_line: return try: dependencies_description=LwrJobRunner.__dependencies_description", "label": 0}, {"snippet_id": 79235, "code": "(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t", "label": 0}, {"snippet_id": 49358, "code": " logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets", "label": 0}, {"snippet_id": 52137, "code": " WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int)", "label": 0}, {"snippet_id": 92882, "code": " as a contextmanager to allow for recursive tests. \"\"\" uuid_str=str(uuid.uuid4()) def u(string): return '{} stdin_data=u('stdio') stdout_data=u('stdout') stderr_data=u('stderr') with temporary_file(binary_mode", "label": 0}, {"snippet_id": 70501, "code": ".Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler", "label": 0}, {"snippet_id": 38229, "code": " import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake", "label": 1}, {"snippet_id": 50400, "code": "\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring", "label": 0}, {"snippet_id": 72689, "code": " data_service.process_data_files(input_dir=input_directory, temp_dir=temp_directory, output_dir=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config", "label": 1}, {"snippet_id": 60511, "code": " 'Beamsplitter': BSgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeeze': Sgate, } class", "label": 0}, {"snippet_id": 19203, "code": " raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors['response'].add_error(err.messages or getattr(err, 'detail'))", "label": 0}, {"snippet_id": 92852, "code": " os.path.realpath(not_zip.name)) with self.assertRaisesRegexp(zipfile.BadZipfile, r'{}'.format(not_zip.name)): next(open_zip(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness", "label": 0}, {"snippet_id": 48471, "code": " name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name", "label": 0}, {"snippet_id": 41929, "code": ") if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for", "label": 0}, {"snippet_id": 77711, "code": "'targets': targets, 'forums': forums, 'domains': domains, 'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self):", "label": 0}, {"snippet_id": 58879, "code": "-update_cases_default_tester') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission) self.client.login( username", "label": 0}, {"snippet_id": 3839, "code": "(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger", "label": 0}, {"snippet_id": 46195, "code": ")) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments", "label": 0}, {"snippet_id": 41817, "code": " input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set()", "label": 0}, {"snippet_id": 85134, "code": " products) def style_classpath(self, products): return self._tool_classpath('scalastyle', products) @property def version(self): return self.get_options().version def suffix_version(self, name): \"\"\"Appends the", "label": 0}, {"snippet_id": 5789, "code": " length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return", "label": 0}, {"snippet_id": 53592, "code": "( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all", "label": 0}, {"snippet_id": 1736, "code": "\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action", "label": 0}, {"snippet_id": 21085, "code": " return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object): @classmethod def wait_all(cls, *awaitables): timeout=3.0 messages=[] for _ in range(int(timeout * 10", "label": 0}, {"snippet_id": 16631, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics)", "label": 0}, {"snippet_id": 53434, "code": ".clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch", "label": 0}, {"snippet_id": 55347, "code": "=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats", "label": 0}, {"snippet_id": 7241, "code": " auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list", "label": 0}, {"snippet_id": 52035, "code": " InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile", "label": 0}, {"snippet_id": 55858, "code": "(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params", "label": 0}, {"snippet_id": 89370, "code": "=logging.getLogger(__name__) def _parse_java_version(name, version): if isinstance(version, string_types): version=Revision.lenient(version) if version and not isinstance(version, Revision): raise ValueError(", "label": 0}, {"snippet_id": 58532, "code": ".DEFAULT_CHARSET), {'rc': 1, 'response': 'No caserun found.'}) def test_add_comment_to_case_runs(self): self.client.login( username=self.tester.username, password='password') new_comment='new comment' response", "label": 0}, {"snippet_id": 38983, "code": "\" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs", "label": 0}, {"snippet_id": 59397, "code": "]) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs", "label": 0}, {"snippet_id": 45212, "code": "=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile", "label": 0}, {"snippet_id": 60517, "code": "': Dgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeeze': Sgate, } class StrawberryFieldsGaussian(Device): \"\"\"StrawberryFields Gaussian device for OpenQML. wires(int)", "label": 0}, {"snippet_id": 87208, "code": ".context.products.is_required_data('zinc_args'): self.context.products.safe_create_data('zinc_args', lambda: defaultdict(list)) def javac_classpath(self): return Java.global_javac_classpath(self.context", "label": 0}, {"snippet_id": 37821, "code": " wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, ", "label": 0}, {"snippet_id": 14890, "code": " pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( ''", "label": 0}, {"snippet_id": 25802, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 38482, "code": "\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets", "label": 0}, {"snippet_id": 78739, "code": ", port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson.items(response,", "label": 0}, {"snippet_id": 15529, "code": " FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 89455, "code": ", its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception): \"\"\"Indicates an invalid java distribution.\"\"\"", "label": 0}, {"snippet_id": 51477, "code": " for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 51535, "code": "-first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with", "label": 0}, {"snippet_id": 75220, "code": ": self.req_handlers[(interface, method)]=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface", "label": 0}, {"snippet_id": 26445, "code": "._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.", "label": 0}, {"snippet_id": 74553, "code": " runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else:", "label": 0}, {"snippet_id": 31343, "code": " self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class", "label": 0}, {"snippet_id": 69236, "code": " msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e", "label": 0}, {"snippet_id": 24547, "code": "._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1", "label": 0}, {"snippet_id": 84291, "code": "] outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds", "label": 0}, {"snippet_id": 14477, "code": ")): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request", "label": 0}, {"snippet_id": 54362, "code": " of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed", "label": 0}, {"snippet_id": 89974, "code": "*kwargs) def execute_java_async(self, *args, **kwargs): return execute_java_async(*args, distribution=self, **kwargs) @memoized_method def _get_version(self, java): return _parse_java_version('java.version", "label": 0}, {"snippet_id": 29966, "code": "}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format", "label": 0}, {"snippet_id": 75051, "code": "=Ticker() self.bind_kt=5 def handle_evaluate(self, reqid, interface, method, data): domain, page=data self.p.log.info('Recvd page %s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log", "label": 0}, {"snippet_id": 81570, "code": "+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime", "label": 1}, {"snippet_id": 27461, "code": " the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor", "label": 0}, {"snippet_id": 34686, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode &", "label": 0}, {"snippet_id": 59476, "code": " queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name,", "label": 0}, {"snippet_id": 2714, "code": "'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host", "label": 0}, {"snippet_id": 705, "code": ".fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU", "label": 0}, {"snippet_id": 17257, "code": "( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set", "label": 0}, {"snippet_id": 19078, "code": " target will be validated against the provided schema. \"\"\" schema=schema_validator(raw_schema, **kwargs) if target is not None: validate_object(target, schema=schema, **kwargs) def validate_api_request", "label": 0}, {"snippet_id": 61007, "code": " __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]", "label": 0}, {"snippet_id": 81455, "code": "[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit", "label": 0}, {"snippet_id": 27697, "code": "'battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 92923, "code": "(), stderr_fd=tmp_stderr.fileno(), stdin_fd=tmp_stdin.fileno()): self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual", "label": 0}, {"snippet_id": 71600, "code": " result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self", "label": 0}, {"snippet_id": 12977, "code": ": diffs } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON", "label": 0}, {"snippet_id": 23032, "code": ": return \"/dev/{0}\".format(dvd.group(0)) raise OSUtilError(\"Failed to get dvd device\") def mount_dvd(self, **kwargs): \"\"\"Mount the DVD containing the provisioningiso.iso file This is the _first_ hook that", "label": 0}, {"snippet_id": 38536, "code": "(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun", "label": 0}, {"snippet_id": 64513, "code": " from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF", "label": 0}, {"snippet_id": 77896, "code": ",), name='SpaghettiMonster') wm.start(ctx, sig_addr) def add_target(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser,", "label": 0}, {"snippet_id": 95029, "code": "=str, default=\"run\", metavar=\"RUN_LABEL\", help=\"Label for the benchmark run.\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to a configuration file.", "label": 1}, {"snippet_id": 66690, "code": "): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self", "label": 0}, {"snippet_id": 37528, "code": " inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 7438, "code": " keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords", "label": 0}, {"snippet_id": 34069, "code": "\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values", "label": 0}, {"snippet_id": 23279, "code": " sock[offset:offset+16].split(b'\\0', 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using tmsh. :param net: :param mask: :param gateway: :return: \"\"\" cmd=(\"/usr/bin/tmsh create net", "label": 0}, {"snippet_id": 92485, "code": " with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os", "label": 0}, {"snippet_id": 25928, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] ", "label": 0}, {"snippet_id": 33230, "code": " self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items)", "label": 0}, {"snippet_id": 25363, "code": "%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data", "label": 1}, {"snippet_id": 19273, "code": " json_file: result=load_source(json_file) assert result==native def test_json_file_path(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.json')", "label": 0}, {"snippet_id": 66586, "code": ".CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands", "label": 0}, {"snippet_id": 94222, "code": " component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config", "label": 0}, {"snippet_id": 77624, "code": "]=uq return uq def load_targets(self): fname=self.targetsfile if not os.path.isfile(fname): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list", "label": 0}, {"snippet_id": 30382, "code": ") class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile", "label": 0}, {"snippet_id": 61824, "code": ", temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1.6,[0]) qm.RY(y,[1]) qm.CNOT([1, 0]) qm.RX(z,[0]", "label": 0}, {"snippet_id": 71200, "code": "=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG", "label": 0}, {"snippet_id": 38134, "code": ") def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i", "label": 0}, {"snippet_id": 73026, "code": " if(remote_subdirs_list is not None) and(len(remote_subdirs_list) > 0): remote_path_relative=\"/\".join(remote_subdirs_list) remote_path_absolute=\"/\" +remote_directory +\"/\" +remote_path_relative +\"/\" else", "label": 0}, {"snippet_id": 57958, "code": ",') data['runs']=map(int, request.GET.get('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs),", "label": 0}, {"snippet_id": 60805, "code": " author='' _capabilities={} _gates={} _observables={} _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots self._out=None self._queue=[] self._observe=None def __repr__(self): ", "label": 0}, {"snippet_id": 38417, "code": " rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno", "label": 0}, {"snippet_id": 87005, "code": "): super(BaseZincCompile, cls).prepare(options, round_manager) ScalaPlatform.prepare_tools(round_manager) @property def incremental(self): \"\"\"Zinc implements incremental compilation. Setting this property", "label": 0}, {"snippet_id": 58955, "code": ".DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) for pk in(self.case_1.pk, self.case_3.pk): self.assertEqual('P3', TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test", "label": 0}, {"snippet_id": 66349, "code": " AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout)", "label": 0}, {"snippet_id": 78076, "code": " user, domain, forum in r_udf.findall(urls): if len(forum) > 0: get_forum_id(forum) logger.info('Removing %s:%s from forums[%s]', user, forum, domain) forums[domain].remove((user, forum)) def add_user(domain", "label": 0}, {"snippet_id": 22633, "code": " for an explanation of why I pass here :param hostname: The hostname to set on the device \"\"\" return None def useradd(self, username, expiration=None): \"\"\"Create user account using tmsh Our policy is to", "label": 1}, {"snippet_id": 29793, "code": "\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually", "label": 0}, {"snippet_id": 93629, "code": "\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug", "label": 0}, {"snippet_id": 20052, "code": ".start_wrapper_script( script, *args, **kwargs) else: start=DebugAdapter.start new_addr=Address.as_server if detachable else Address.as_client addr=new_addr(None, self._addr.port) self._adapter=start(argv", "label": 0}, {"snippet_id": 60646, "code": ".params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('gaussian') reg=self._observe", "label": 0}, {"snippet_id": 50736, "code": ". \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow", "label": 0}, {"snippet_id": 43890, "code": " name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False", "label": 0}, {"snippet_id": 31486, "code": " Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException,", "label": 0}, {"snippet_id": 64549, "code": "/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system", "label": 0}, {"snippet_id": 21334, "code": " parser.add_argument('subreddit', type=str, help='The subreddit you want to play.') parser.add_argument('mpv', nargs=ap.REMAINDER, help='Arguments to pass to `mpv`.') args=parser.parse_args() subreddit", "label": 0}, {"snippet_id": 88727, "code": " workunit_parent_ctx.__exit__(None, None, None) else: workunit_parent=background_root_workunit done_hook=None self.run_tracker.background_worker_pool().submit_async_work_chain( work_chain, workunit_parent", "label": 0}, {"snippet_id": 90381, "code": " self._java_dist_dirs: if os.path.isdir(java_dist_dir): for path in os.listdir(java_dist_dir): home=os.path.join(java_dist_dir, path) if os.path.isdir(home): yield self.Location.from_home(home) class _ExplicitEnvironment", "label": 0}, {"snippet_id": 13907, "code": "._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout", "label": 0}, {"snippet_id": 84101, "code": ", version_file=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution", "label": 1}, {"snippet_id": 77444, "code": ".'.join((wname, 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'pr{0}'", "label": 0}, {"snippet_id": 68592, "code": "%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" ", "label": 0}, {"snippet_id": 60728, "code": "(type): \"\"\"Metaclass that allows derived classes to dynamically instantiate new objects based on undefined methods. The dynamic methods pass their arguments directly to __init__ of the inheriting class.\"", "label": 0}, {"snippet_id": 49210, "code": " not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix", "label": 0}, {"snippet_id": 54594, "code": "(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files", "label": 0}, {"snippet_id": 39850, "code": "): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if", "label": 0}, {"snippet_id": 6748, "code": "(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references", "label": 0}, {"snippet_id": 5391, "code": " output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms:", "label": 0}, {"snippet_id": 82830, "code": " \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start", "label": 0}, {"snippet_id": 59761, "code": "*kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq", "label": 0}, {"snippet_id": 87798, "code": ".pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath entries provided to zinc should be in working directory or ' 'part of the JDK.{} is not.'.format(path)) if path !", "label": 0}, {"snippet_id": 83917, "code": " not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning", "label": 0}, {"snippet_id": 68762, "code": "(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target", "label": 0}, {"snippet_id": 80904, "code": "._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests", "label": 0}, {"snippet_id": 82264, "code": "-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple", "label": 0}, {"snippet_id": 71366, "code": " i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout", "label": 0}, {"snippet_id": 35997, "code": "), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule", "label": 0}, {"snippet_id": 48642, "code": "(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards", "label": 0}, {"snippet_id": 19574, "code": " pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in('--host', '--server-host',", "label": 0}, {"snippet_id": 45217, "code": " def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None:", "label": 0}, {"snippet_id": 48908, "code": "< 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other)", "label": 0}, {"snippet_id": 36636, "code": " rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex:", "label": 0}, {"snippet_id": 57006, "code": " \"\"\" value=error=None def get_time(time): date_time=datetime.datetime if time=='NOW': return date_time.now() return date_time.strptime(time, '%Y%m%d %H%M%S') pipes={ 'bool': lambda x: x=='True' and 1 or", "label": 0}, {"snippet_id": 44299, "code": " printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( ", "label": 0}, {"snippet_id": 28514, "code": ".update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self", "label": 0}, {"snippet_id": 51466, "code": " mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule", "label": 0}, {"snippet_id": 1156, "code": " BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all(", "label": 0}, {"snippet_id": 49141, "code": ".included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self", "label": 0}, {"snippet_id": 13508, "code": " ChippyTwitter\r from chippyRuxpin_webFramework import WebFramework\r \r fullMsg=\"\"\r \r MOUTH_OPEN=408 MOUTH_CLOSE=412 EYES_OPEN=410 EYES_CLOSE=414 \r io=GPIO() io.setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io", "label": 0}, {"snippet_id": 53199, "code": ".dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority", "label": 0}, {"snippet_id": 30107, "code": " list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"", "label": 0}, {"snippet_id": 22055, "code": "=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self,", "label": 0}, {"snippet_id": 58642, "code": ".tester.username, password='password') remove_perm_from_user(self.tester, self.permission) post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False", "label": 0}, {"snippet_id": 47827, "code": "=1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output)", "label": 0}, {"snippet_id": 17745, "code": "._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype", "label": 0}, {"snippet_id": 22431, "code": " save sys config\" rc=shellutil.run(cmd) if rc !=0: logger.error(\"WARNING: Cannot save sys config on 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd", "label": 0}, {"snippet_id": 81728, "code": ",requests,argparse,logging,os,coloredlogs,datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5", "label": 0}, {"snippet_id": 49505, "code": " prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun))", "label": 0}, {"snippet_id": 81539, "code": ".get(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1", "label": 0}, {"snippet_id": 23103, "code": " def eject_dvd(self, chk_err=True): \"\"\"Runs the eject command to eject the provisioning DVD BIG-IP does not include an eject command. It is sufficient to just umount the DVD disk. But I will log that we", "label": 0}, {"snippet_id": 35007, "code": ".group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.", "label": 0}, {"snippet_id": 4336, "code": "\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit", "label": 0}, {"snippet_id": 75130, "code": "'. format(wzrpc.name_status(status))) self.p.auth_requests() self.p.bind_methods() elif status==wzrpc.status.e_timeout: self.p.log.warn('Keepalive timeout') else: self.p.log.warn('Keepalive status{0}'.", "label": 0}, {"snippet_id": 39643, "code": " kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 86174, "code": "], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) javac_cmd=['{}/bin/javac'.format(distribution.real_home)] javac_cmd.extend", "label": 0}, {"snippet_id": 80651, "code": ".uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not args.skipRecon: \tif len(args.legitExtensions) > 0: \t\tn=up", "label": 0}, {"snippet_id": 984, "code": "=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE)", "label": 0}, {"snippet_id": 24605, "code": "._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 32122, "code": " for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as", "label": 0}, {"snippet_id": 2500, "code": ".server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file", "label": 0}, {"snippet_id": 43124, "code": "(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize", "label": 0}, {"snippet_id": 32395, "code": " is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set", "label": 0}, {"snippet_id": 73540, "code": ") else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH", "label": 0}, {"snippet_id": 92056, "code": ":`Target` objects. :return: a boolean value indicating whether the current target closure has native sources. :raises::class:`pants.base.exceptions.IncompatiblePlatformsError` \"\"\" if not self._any_targets_have_native_sources", "label": 0}, {"snippet_id": 73123, "code": " except error_perm: temp=ftp.nlst() if not os.path.isfile(file_path_local): with open(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({", "label": 0}, {"snippet_id": 55018, "code": "( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f", "label": 0}, {"snippet_id": 62119, "code": "-running the circuit(e.g., if previous run timed out). \"\"\" name='ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={", "label": 0}, {"snippet_id": 65119, "code": " self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1:", "label": 0}, {"snippet_id": 49440, "code": "=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False)", "label": 0}, {"snippet_id": 27961, "code": "._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data", "label": 0}, {"snippet_id": 25755, "code": "': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle", "label": 0}, {"snippet_id": 53138, "code": " Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException,", "label": 0}, {"snippet_id": 72019, "code": " \"\"\"<network> Disconnects the network <network>. When all networks are disconnected, PyLink will automatically exit. To reconnect a network disconnected using this command, use REHASH to reload the networks", "label": 0}, {"snippet_id": 67104, "code": "\"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support", "label": 1}, {"snippet_id": 10318, "code": " keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list", "label": 0}, {"snippet_id": 7281, "code": ": it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience:", "label": 0}, {"snippet_id": 15692, "code": "._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format", "label": 0}, {"snippet_id": 3790, "code": " window=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log", "label": 0}, {"snippet_id": 27310, "code": "{ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors", "label": 0}, {"snippet_id": 74375, "code": "/data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value", "label": 0}, {"snippet_id": 4976, "code": ": \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var", "label": 0}, {"snippet_id": 33488, "code": ".info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag", "label": 0}, {"snippet_id": 56976, "code": " get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid literal for int() with base", "label": 0}, {"snippet_id": 13796, "code": " np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals", "label": 0}, {"snippet_id": 63797, "code": ".errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job", "label": 0}, {"snippet_id": 5044, "code": " kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n", "label": 0}, {"snippet_id": 63994, "code": "(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client", "label": 0}, {"snippet_id": 49993, "code": ") ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored", "label": 0}, {"snippet_id": 56264, "code": " from tcms.testcases.views import plan_from_request_or_none from tcms.testplans.models import TestPlan, TestCasePlan, TestPlanTag from tcms.testruns.models import TestRun, TestCaseRun, TestCaseRunStatus", "label": 0}, {"snippet_id": 73093, "code": "(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file)", "label": 0}, {"snippet_id": 34638, "code": "(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not", "label": 1}, {"snippet_id": 29653, "code": "=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError", "label": 0}, {"snippet_id": 27236, "code": ", 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle',", "label": 0}, {"snippet_id": 25587, "code": "'co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id", "label": 0}, {"snippet_id": 55065, "code": " have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create", "label": 0}, {"snippet_id": 57620, "code": ".update(**{str(self.target_field): self.new_value}) def _update_default_tester(self): try: user=User.objects.get(Q(username=self.new_value) | Q(email=self.new_value)) except User.DoesNotExist: raise ObjectDoesNotExist", "label": 0}, {"snippet_id": 36646, "code": " ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes", "label": 0}, {"snippet_id": 5766, "code": "(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords", "label": 0}, {"snippet_id": 24080, "code": " | grep storvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F ", "label": 0}, {"snippet_id": 80757, "code": "\tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime", "label": 1}, {"snippet_id": 69944, "code": ".Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class", "label": 0}, {"snippet_id": 13096, "code": "=headers, auth=auth) if r.status_code==202: data[\"fork_fullname\"]=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github", "label": 0}, {"snippet_id": 67132, "code": "=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre", "label": 0}, {"snippet_id": 96067, "code": " print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length", "label": 1}, {"snippet_id": 40611, "code": "(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp", "label": 0}, {"snippet_id": 81688, "code": "\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode", "label": 0}, {"snippet_id": 73649, "code": "\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation", "label": 0}, {"snippet_id": 85088, "code": ".format(key)) cls.register_jvm_tool(register, cls._key_for_tool_version(key, 'custom'), classpath=[dummy_jardep]) register_custom_tool('scalac') register_custom_tool('scala-repl') register_custom_tool(", "label": 1}, {"snippet_id": 73293, "code": "=pathlib.Path(temp_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_temp: path_temp_str=str(path) filename_str=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move", "label": 0}, {"snippet_id": 53064, "code": " shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(", "label": 0}, {"snippet_id": 24212, "code": "':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi", "label": 0}, {"snippet_id": 21177, "code": ".name) else: message +='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None): super(AwaitableResponse, self).__init__", "label": 0}, {"snippet_id": 14829, "code": "( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except", "label": 0}, {"snippet_id": 17235, "code": "' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False", "label": 0}, {"snippet_id": 75539, "code": " return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, struct", "label": 0}, {"snippet_id": 58998, "code": "(name='NewGroup') cls.property_os=EnvPropertyFactory(name='os') cls.property_python=EnvPropertyFactory(name='python') cls.property_django=EnvPropertyFactory(name='django') EnvGroupPropertyMapFactory(group", "label": 0}, {"snippet_id": 19002, "code": ") except(yaml.scanner.ScannerError, yaml.parser.ParserError): pass except NameError: pass raise ValueError( \"Unable to parse `{0}`. Tried yaml and json.\".format(source), ) def parse(raw_schema): context", "label": 1}, {"snippet_id": 76172, "code": " return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug('Route", "label": 0}, {"snippet_id": 35068, "code": " dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value", "label": 0}, {"snippet_id": 38636, "code": " is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files", "label": 0}, {"snippet_id": 36687, "code": "} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 35777, "code": "(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles", "label": 0}, {"snippet_id": 20979, "code": ", handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers.append", "label": 0}, {"snippet_id": 44290, "code": " argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow", "label": 0}, {"snippet_id": 36902, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError,", "label": 0}, {"snippet_id": 60664, "code": ".state=self.eng.run('gaussian') reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name=='X': ex, var=self.state.quad_expectation(reg, 0) elif", "label": 0}, {"snippet_id": 83623, "code": " %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user", "label": 0}, {"snippet_id": 69924, "code": ".set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount", "label": 1}, {"snippet_id": 15952, "code": " return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS", "label": 1}, {"snippet_id": 42488, "code": "=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input", "label": 0}, {"snippet_id": 68744, "code": "(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target", "label": 0}, {"snippet_id": 63811, "code": "%d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id", "label": 0}, {"snippet_id": 71101, "code": "\"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3", "label": 0}, {"snippet_id": 20399, "code": "=create_client() for _ in range(int(timeout * 10)): try: sock.connect(addr) except(OSError, socket.error): if cls.VERBOSE: print('+', end='') sys.stdout.flush() time.sleep(0.1) else: break else: raise RuntimeError", "label": 0}, {"snippet_id": 45979, "code": " return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value", "label": 1}, {"snippet_id": 83554, "code": " command_line, client, remote_job_config, compute_environment def __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, ", "label": 0}, {"snippet_id": 50148, "code": "(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror", "label": 0}, {"snippet_id": 38685, "code": ": forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets", "label": 0}, {"snippet_id": 51606, "code": "(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit", "label": 0}, {"snippet_id": 53394, "code": " exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output", "label": 0}, {"snippet_id": 88275, "code": " FallibleExecuteProcessResult from pants.goal.products import Products from pants.goal.workspace import ScmWorkspace from pants.process.lock import OwnerPrintingInterProcessFileLock from pants.reporting.report import", "label": 1}, {"snippet_id": 91678, "code": " ] +interpreter_constraint_args +[ text_type(req) for req in all_requirements ] requirements_pex_request=ExecuteProcessRequest( argv=tuple(requirements_pex_argv), env={'PATH': text_type(os.pathsep.join", "label": 1}, {"snippet_id": 78915, "code": " Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML", "label": 0}, {"snippet_id": 49521, "code": "(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain", "label": 0}, {"snippet_id": 89720, "code": ": lib_path=os.path.join(path, name) if os.path.exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate{} library'.format(name)) return list(collect_existing_libs()) @property", "label": 0}, {"snippet_id": 15878, "code": "=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def", "label": 0}, {"snippet_id": 7166, "code": "(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords", "label": 0}, {"snippet_id": 57171, "code": " record found') if not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action", "label": 0}, {"snippet_id": 66137, "code": "=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO:", "label": 0}, {"snippet_id": 20881, "code": ".contextmanager def wait_for_response(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq']", "label": 0}, {"snippet_id": 35357, "code": " in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for", "label": 0}, {"snippet_id": 1128, "code": " wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors", "label": 0}, {"snippet_id": 24657, "code": "'battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data[", "label": 0}, {"snippet_id": 80145, "code": ".\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\"", "label": 0}, {"snippet_id": 19715, "code": " clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')) else: args.address=Address.as_client(clienthost, ns.pop", "label": 0}, {"snippet_id": 19200, "code": "=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors['response'].add_error(err.messages or", "label": 0}, {"snippet_id": 18795, "code": " expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']", "label": 0}, {"snippet_id": 44906, "code": " not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance", "label": 0}, {"snippet_id": 42760, "code": " if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self", "label": 0}, {"snippet_id": 9775, "code": " output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n", "label": 0}, {"snippet_id": 88943, "code": " the given target_base, creating the directory if needed and registering a source root. :API: public \"\"\" rel_target_base=target_base or address.spec_path abs_target_base=os.path.join(get_buildroot(), rel_target_base", "label": 0}, {"snippet_id": 48623, "code": " is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems", "label": 0}, {"snippet_id": 46309, "code": ", filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr", "label": 0}, {"snippet_id": 71466, "code": " from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self", "label": 0}, {"snippet_id": 92870, "code": "(self): \"\"\"Harness to replace `sys.std*` with tempfiles. Validates that all files are read/written/flushed correctly, and acts as a contextmanager to allow for recursive tests. \"\"\" uuid_str=str(uuid.uuid4", "label": 0}, {"snippet_id": 44209, "code": ".persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error", "label": 0}, {"snippet_id": 478, "code": " Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\"", "label": 0}, {"snippet_id": 52449, "code": ".message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:", "label": 0}, {"snippet_id": 80993, "code": "\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry:", "label": 0}, {"snippet_id": 5518, "code": "(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents", "label": 0}, {"snippet_id": 15220, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( ", "label": 0}, {"snippet_id": 82106, "code": " to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=\"verbose\",help=", "label": 0}, {"snippet_id": 91, "code": " get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[", "label": 0}, {"snippet_id": 60510, "code": " Gaussian, 'Beamsplitter': BSgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeeze': Sgate", "label": 0}, {"snippet_id": 8898, "code": ", no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name", "label": 0}, {"snippet_id": 49231, "code": " raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules", "label": 0}, {"snippet_id": 73178, "code": " file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *", "label": 0}, {"snippet_id": 92723, "code": "._time self._time +=0.0001 return ret def sleep(self, duration): self._time +=duration clock=FakeClock() with Timer(clock=clock) as t: self.assertLess(t.start, clock.time()) self.assertGreater(t.elapsed, 0)", "label": 0}, {"snippet_id": 40167, "code": " e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else", "label": 0}, {"snippet_id": 11909, "code": "=True break return pythonic def get_config(data): \"\"\" Get.pep8speaks.yml config file from the repository and return the config dictionary \"\"\" config={ \"message\":{ \"opened\":{ \"header\": \"\", \"footer\": \"\" }", "label": 0}, {"snippet_id": 91702, "code": ",), ) requirements_pex_response=yield Get( ExecuteProcessResult, ExecuteProcessRequest, requirements_pex_request) source_roots=source_root_config.get_source_roots() sources_snapshots_and_source_roots=[", "label": 0}, {"snippet_id": 67094, "code": ".lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument", "label": 1}, {"snippet_id": 72218, "code": " netname=args.network if netname==irc.name: irc.error(\"Cannot remote-send a command to the local network; use a normal command!\") return try: remoteirc=world.networkobjects[netname] except KeyError: irc", "label": 0}, {"snippet_id": 15986, "code": " _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit", "label": 0}, {"snippet_id": 20843, "code": " AttributeError: command, seq=req['command'], req['seq'] result={'msg': None} def match(msg): if msg.type !='response': return False result['msg']=msg return msg.request_seq==seq handlername='response(cmd:{} seq:{}", "label": 0}, {"snippet_id": 1409, "code": "'delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={", "label": 0}, {"snippet_id": 44475, "code": "=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map", "label": 0}, {"snippet_id": 8251, "code": ".url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks", "label": 1}, {"snippet_id": 57090, "code": ".datetime.now() data=request.POST.copy() ctype=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value') object_pk", "label": 0}, {"snippet_id": 2471, "code": ".session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self.logger.info('starting new session by", "label": 0}, {"snippet_id": 4169, "code": ", output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False,", "label": 0}, {"snippet_id": 84452, "code": "._wrapper_input_paths results=[] for local_input_path in local_input_paths: wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self", "label": 0}, {"snippet_id": 67364, "code": ", None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf", "label": 0}, {"snippet_id": 57476, "code": "'_update_%s' % self.target_field, None) def update(self): has_perms=check_permission(self.request, self.ctype) if not has_perms: return say_no(\"You don't have enough permission to update TestCases.\") action", "label": 0}, {"snippet_id": 7484, "code": "): return{ \"complete_output\": complete_output, \"categories\": categories } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text format. :return: str, html formatted output", "label": 0}, {"snippet_id": 50370, "code": " **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func", "label": 0}, {"snippet_id": 41769, "code": " missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output", "label": 0}, {"snippet_id": 35016, "code": " same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard", "label": 0}, {"snippet_id": 44031, "code": "=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict()", "label": 0}, {"snippet_id": 28256, "code": ":['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', ''", "label": 0}, {"snippet_id": 62697, "code": " device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs", "label": 0}, {"snippet_id": 94643, "code": "\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs", "label": 0}, {"snippet_id": 20354, "code": " ClosedError from.message import( raw_read_all as read_messages, raw_write_one as write_message ) from.socket import( Connection, create_server, create_client, close, recv_as_read, send_as_write, timeout as", "label": 0}, {"snippet_id": 91157, "code": " PythonRequirements from pants.backend.python.rules import inject_init, python_test_runner from pants.backend.python.targets.python_app import PythonApp from pants.backend.python.targets.python_binary import", "label": 0}, {"snippet_id": 49519, "code": "(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))", "label": 0}, {"snippet_id": 83819, "code": ": log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"", "label": 0}, {"snippet_id": 91599, "code": " for one target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download/v1.6.6/pex' digest=Digest('61bb79384db0da8c844678440bd368bcbfac17bbdb865721ad3f9cb0ab29b629', 1826945) pex_snapshot=yield Get", "label": 0}, {"snippet_id": 81426, "code": " information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e in extList", "label": 0}, {"snippet_id": 17265, "code": " self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive", "label": 1}, {"snippet_id": 52193, "code": " import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources", "label": 1}, {"snippet_id": 22581, "code": " though, tmsh will reject that value because it is not a fully qualified domain name. The proper value should have been bigip.xxx.yyy WAAgent will not fail if this command fails, but the hostname will not", "label": 0}, {"snippet_id": 18218, "code": "+ 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!'", "label": 0}, {"snippet_id": 4675, "code": " extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db:", "label": 0}, {"snippet_id": 34381, "code": ".resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self", "label": 0}, {"snippet_id": 18138, "code": " DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm", "label": 0}, {"snippet_id": 59519, "code": "._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name]", "label": 0}, {"snippet_id": 39387, "code": "._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules", "label": 0}, {"snippet_id": 53021, "code": ".updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(", "label": 0}, {"snippet_id": 15392, "code": "._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(", "label": 0}, {"snippet_id": 4296, "code": "=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name", "label": 1}, {"snippet_id": 8699, "code": " invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name,", "label": 1}, {"snippet_id": 2636, "code": ".nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res: if node is not master_node: dep_string=\"%s -> %s\" %", "label": 0}, {"snippet_id": 33988, "code": " workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self", "label": 0}, {"snippet_id": 85092, "code": "._key_for_tool_version(key, 'custom'), classpath=[dummy_jardep]) register_custom_tool('scalac') register_custom_tool('scala-repl') register_custom_tool('scalastyle') def _tool_classpath(self, tool, products", "label": 1}, {"snippet_id": 76055, "code": " status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i, m) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}", "label": 0}, {"snippet_id": 88856, "code": " serialization, it will call this to acquire the lock. :API: public \"\"\" if self.options.for_global_scope().lock: if not self._lock.acquired: self._lock.acquire() def release_lock(self): \"\"\"Release the global lock", "label": 0}, {"snippet_id": 32737, "code": ": try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards", "label": 0}, {"snippet_id": 42633, "code": "(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def", "label": 0}, {"snippet_id": 94002, "code": " send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node", "label": 0}, {"snippet_id": 34173, "code": " rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate", "label": 0}, {"snippet_id": 94217, "code": ".log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self", "label": 0}, {"snippet_id": 483, "code": " returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd=", "label": 0}, {"snippet_id": 6813, "code": " get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find", "label": 1}, {"snippet_id": 50116, "code": " self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if", "label": 0}, {"snippet_id": 59088, "code": ":`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ", "label": 0}, {"snippet_id": 76646, "code": "(random.randint(0, 9999999999))) return '\\n'.join(msg) def sbjfun(): return sup.randstr(1, 30) import argparse parser=argparse.ArgumentParser(add_help=True) parser.add_argument('--only-cache', '-C', action", "label": 0}, {"snippet_id": 82294, "code": "\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\"", "label": 0}, {"snippet_id": 31281, "code": ".rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__", "label": 0}, {"snippet_id": 14369, "code": "-stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest", "label": 0}, {"snippet_id": 67383, "code": "(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0", "label": 1}, {"snippet_id": 79516, "code": " \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes", "label": 0}, {"snippet_id": 7057, "code": " taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int", "label": 0}, {"snippet_id": 15875, "code": "/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response", "label": 0}, {"snippet_id": 64113, "code": ".get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory=remote_job_config['outputs_directory", "label": 0}, {"snippet_id": 30144, "code": " list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key,", "label": 0}, {"snippet_id": 40975, "code": " toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item", "label": 0}, {"snippet_id": 77355, "code": "(i))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s", "label": 0}, {"snippet_id": 74341, "code": " resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower()", "label": 0}, {"snippet_id": 4776, "code": " composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of", "label": 0}, {"snippet_id": 36264, "code": "\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in", "label": 0}, {"snippet_id": 19276, "code": ") assert result==native def test_json_file_path(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.json') tmp_file.write(source) tmp_file.flush()", "label": 0}, {"snippet_id": 26572, "code": "': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif", "label": 0}, {"snippet_id": 69969, "code": "<filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden", "label": 0}, {"snippet_id": 51075, "code": ".file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target", "label": 0}, {"snippet_id": 59273, "code": " If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default", "label": 0}, {"snippet_id": 15546, "code": "): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data", "label": 0}, {"snippet_id": 33019, "code": "{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name", "label": 0}, {"snippet_id": 4363, "code": " def get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords", "label": 0}, {"snippet_id": 55162, "code": ".updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.", "label": 0}, {"snippet_id": 64881, "code": ".RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__", "label": 0}, {"snippet_id": 94766, "code": "\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch to kill", "label": 0}, {"snippet_id": 42917, "code": "[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append", "label": 0}, {"snippet_id": 41980, "code": " cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n", "label": 0}, {"snippet_id": 1956, "code": ",'-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse", "label": 0}, {"snippet_id": 63714, "code": ".debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job(", "label": 0}, {"snippet_id": 1006, "code": "'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password", "label": 0}, {"snippet_id": 67690, "code": ", target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" ", "label": 0}, {"snippet_id": 29844, "code": "(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot", "label": 0}, {"snippet_id": 39021, "code": "(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed", "label": 0}, {"snippet_id": 29082, "code": "\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station", "label": 1}, {"snippet_id": 20134, "code": ".\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None self._adapter=DebugAdapter.start", "label": 0}, {"snippet_id": 45709, "code": " def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"", "label": 0}, {"snippet_id": 55160, "code": ": return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger", "label": 0}, {"snippet_id": 38406, "code": "( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name)", "label": 0}, {"snippet_id": 35355, "code": ") for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values", "label": 0}, {"snippet_id": 89690, "code": " libraries :raises: `Distribution.Error` if any of the jars could not be found. \"\"\" def collect_existing_libs(): def lib_paths(): yield os.path.join(self.home, 'lib') if self.jdk: yield os.path.join(self", "label": 0}, {"snippet_id": 40573, "code": " for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed", "label": 1}, {"snippet_id": 17269, "code": "._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self):", "label": 1}, {"snippet_id": 37264, "code": "*kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self", "label": 0}, {"snippet_id": 23917, "code": ": inet=line.split()[1] elif line.find('ether ') !=-1: mac=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id)", "label": 0}, {"snippet_id": 5530, "code": " fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires", "label": 0}, {"snippet_id": 11943, "code": " False, \"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors\": True", "label": 0}, {"snippet_id": 70557, "code": ".dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s", "label": 0}, {"snippet_id": 82522, "code": " _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider", "label": 0}, {"snippet_id": 83420, "code": "=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state", "label": 0}, {"snippet_id": 6926, "code": ",[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords", "label": 0}, {"snippet_id": 78388, "code": " exc.Success as e: self.counters['topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min exc caught", "label": 0}, {"snippet_id": 7551, "code": " skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires:", "label": 0}, {"snippet_id": 53098, "code": " input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__", "label": 0}, {"snippet_id": 71395, "code": "=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 83368, "code": " command_line=command_line, input_files=self.get_input_files(job_wrapper), client_outputs=self.__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool", "label": 0}, {"snippet_id": 18356, "code": "--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest", "label": 0}, {"snippet_id": 23821, "code": ")) self._scsi_disks_timeout_set=True def check_pid_alive(self, pid): return shellutil.run('ps -p{0}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD", "label": 0}, {"snippet_id": 40969, "code": "\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key", "label": 0}, {"snippet_id": 17230, "code": "=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self", "label": 0}, {"snippet_id": 73184, "code": ".copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir. Additionally moves", "label": 0}, {"snippet_id": 59206, "code": " projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate", "label": 0}, {"snippet_id": 83384, "code": ", dependencies_description=dependencies_description, env=client.env, rewrite_paths=rewrite_paths, arbitrary_files=unstructured_path_rewrites, ) job_id=lwr_submit_job(client, client_job_description, remote_job_config", "label": 0}, {"snippet_id": 58400, "code": "[self.tester.username]), target_status_code=HTTPStatus.OK) class TestCommentCaseRuns(BaseCaseRun): \"\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns,", "label": 0}, {"snippet_id": 80372, "code": " --input-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m ", "label": 0}, {"snippet_id": 72668, "code": " print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled", "label": 1}, {"snippet_id": 29337, "code": " lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self", "label": 1}, {"snippet_id": 69752, "code": ".EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node", "label": 0}, {"snippet_id": 35581, "code": " in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name", "label": 0}, {"snippet_id": 38820, "code": " Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that", "label": 0}, {"snippet_id": 71517, "code": "(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os", "label": 1}, {"snippet_id": 39209, "code": " dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else", "label": 0}, {"snippet_id": 52479, "code": ". \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 51685, "code": ".dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards", "label": 0}, {"snippet_id": 16348, "code": "=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'", "label": 0}, {"snippet_id": 45274, "code": ".isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow", "label": 0}, {"snippet_id": 15492, "code": " if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer", "label": 0}, {"snippet_id": 65349, "code": " of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to", "label": 0}, {"snippet_id": 70352, "code": ")) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt", "label": 0}, {"snippet_id": 45868, "code": ", match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing", "label": 0}, {"snippet_id": 46455, "code": ") else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names", "label": 0}, {"snippet_id": 10676, "code": ".decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate", "label": 1}, {"snippet_id": 36516, "code": ") if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for", "label": 0}, {"snippet_id": 92667, "code": ") self.assertTrue(os.path.exists(path), 'Temporary dir should exist outside of context if cleanup=False.') shutil.rmtree(path) def test_temporary_dir_with_root_dir(self): with temporary_dir() as path1:", "label": 0}, {"snippet_id": 51742, "code": ", value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable", "label": 0}, {"snippet_id": 45010, "code": " ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths", "label": 0}, {"snippet_id": 57023, "code": ": x=='True' and 1 or 0, 'datetime': get_time, 'int': lambda x: str(int(x)), 'str': lambda x: str(x), 'None': lambda x: None, } pipe=pipes.get(v_type, None) if pipe is None: error='Unsupported value type", "label": 0}, {"snippet_id": 87112, "code": "( self.get_options().pants_workdir, get_buildroot(), ) ) if self.get_options().use_classpath_jars: raise TaskError(\"Hermetic zinc execution currently doesn't work with classpath jars\") def select(self,", "label": 0}, {"snippet_id": 3201, "code": " strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for", "label": 0}, {"snippet_id": 60311, "code": " def __init__(self, wires, *, shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"", "label": 1}, {"snippet_id": 33742, "code": " will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set", "label": 0}, {"snippet_id": 89288, "code": " ) as workunit: result=self._scheduler.product_request(FallibleExecuteProcessResult,[execute_process_request])[0] workunit.output(\"stdout\").write(result.stdout) workunit.output(\"stderr\").write(result.stderr", "label": 0}, {"snippet_id": 69577, "code": " new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg", "label": 0}, {"snippet_id": 62921, "code": " import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep import os from.lwr_client", "label": 0}, {"snippet_id": 80756, "code": "\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions:", "label": 1}, {"snippet_id": 78506, "code": " in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in forum %s:%s', lt, user, forum) else: self.log.debug('Found no new targets", "label": 1}, {"snippet_id": 2462, "code": ") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server", "label": 0}, {"snippet_id": 56636, "code": "=all_tags).values('tag').annotate(num_cases=Count('tag')).order_by('tag') test_run_tags=TestRunTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_runs=Count('tag')).order_by('tag') plan_counter", "label": 0}, {"snippet_id": 77499, "code": "'Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount,", "label": 0}, {"snippet_id": 57897, "code": " needed') run_ids=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no(", "label": 0}, {"snippet_id": 44591, "code": ".resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\")", "label": 0}, {"snippet_id": 34639, "code": ".file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self", "label": 1}, {"snippet_id": 11260, "code": " monitoring configuration is written into this directory. If no target directory is given its value is read from /etc/monitoring_config_generator/config.yaml --skip-checks Do not run checks on the yaml", "label": 0}, {"snippet_id": 36765, "code": " dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output", "label": 0}, {"snippet_id": 27824, "code": " data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 17456, "code": " CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request", "label": 0}, {"snippet_id": 14589, "code": " not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return", "label": 0}, {"snippet_id": 43488, "code": ".workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self)", "label": 0}, {"snippet_id": 45105, "code": " decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate", "label": 0}, {"snippet_id": 72709, "code": ", conversion_config=vcf_to_zarr_config) elif command==\"exec\": print(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config", "label": 1}, {"snippet_id": 72963, "code": "{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close", "label": 0}, {"snippet_id": 24676, "code": "'battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif", "label": 0}, {"snippet_id": 77506, "code": "(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount, (ev_init,)) def load_users(self): if not os.path.isfile(self.usersfile", "label": 0}, {"snippet_id": 38466, "code": " Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self", "label": 0}, {"snippet_id": 63790, "code": " signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d", "label": 0}, {"snippet_id": 53567, "code": " in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item", "label": 0}, {"snippet_id": 69627, "code": "\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute", "label": 0}, {"snippet_id": 94591, "code": "\", cmd, \"Enter\") def find_window(session, window_name): window=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, ", "label": 0}, {"snippet_id": 91007, "code": "-minimum-version', advanced=True, help='Minimum version of the JVM pants will use') register('--maximum-version', advanced=True, help='Maximum version of the JVM pants will use') def all_jdk_paths(self)", "label": 0}, {"snippet_id": 52911, "code": " res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local", "label": 0}, {"snippet_id": 11420, "code": "(self, file_name, yaml_icinga): lines=yaml_icinga.icinga_lines output_writer=OutputWriter(self.output_path(file_name)) output_writer.write_lines(lines) @staticmethod def create_filename(hostname): name", "label": 0}, {"snippet_id": 9686, "code": " ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches", "label": 0}, {"snippet_id": 10587, "code": "' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document", "label": 0}, {"snippet_id": 70968, "code": " % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len", "label": 0}, {"snippet_id": 9056, "code": ") acronyms={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords", "label": 0}, {"snippet_id": 56311, "code": " parameters={} for key, value in request_dict.items(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters @require_GET def info(request): \"\"\"Ajax responder for misc information", "label": 1}, {"snippet_id": 33996, "code": " def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate", "label": 0}, {"snippet_id": 63686, "code": "\"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return", "label": 0}, {"snippet_id": 3887, "code": " test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers", "label": 0}, {"snippet_id": 30133, "code": " shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone", "label": 0}, {"snippet_id": 63652, "code": " resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job(", "label": 0}, {"snippet_id": 89749, "code": " home=self._get_system_properties(self.java)['java.home'] if os.path.basename(home)=='jre': jdk_dir=os.path.dirname(home) if self._is_executable(os.path.join(jdk_dir, 'bin', 'javac')): home=jdk_dir self", "label": 0}, {"snippet_id": 37467, "code": "\"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged", "label": 0}, {"snippet_id": 33534, "code": " dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency", "label": 0}, {"snippet_id": 47587, "code": " omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run", "label": 0}, {"snippet_id": 91904, "code": "(__name__) class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope='python-native-code' default_native_source_extensions=[", "label": 0}, {"snippet_id": 91860, "code": ".python.subsystems import pex_build_util from pants.backend.python.subsystems.python_setup import PythonSetup from pants.backend.python.targets.python_distribution import PythonDistribution from pants.base", "label": 0}, {"snippet_id": 51817, "code": ".get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name,", "label": 0}, {"snippet_id": 68470, "code": ") if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes", "label": 0}, {"snippet_id": 41953, "code": "*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for", "label": 0}, {"snippet_id": 30303, "code": " yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in", "label": 0}, {"snippet_id": 48633, "code": " if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names", "label": 0}, {"snippet_id": 4170, "code": ", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False", "label": 0}, {"snippet_id": 88113, "code": " plugin, returns its name. Returns None otherwise. \"\"\" def process_info_file(cp_elem, info_file): plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag !='plugin': raise TaskError('File{}", "label": 0}, {"snippet_id": 67637, "code": " strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre", "label": 0}, {"snippet_id": 37779, "code": ") concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize", "label": 0}, {"snippet_id": 32207, "code": " raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs", "label": 0}, {"snippet_id": 26680, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920:", "label": 0}, {"snippet_id": 17477, "code": " force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest", "label": 0}, {"snippet_id": 40153, "code": " else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule", "label": 1}, {"snippet_id": 1570, "code": "=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname", "label": 0}, {"snippet_id": 29731, "code": " return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag", "label": 0}, {"snippet_id": 13812, "code": "() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value", "label": 0}, {"snippet_id": 77994, "code": " domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target(domain, id_, user) def rtfu(urls): for user, domain, id1, id2", "label": 0}, {"snippet_id": 86098, "code": ", AnnotationProcessor) and target.processors: processor_info_file=os.path.join(compile_context.classes_dir, _PROCESSOR_INFO_FILE) self._write_processor_info(processor_info_file, target.processors) def _write_processor_info", "label": 0}, {"snippet_id": 89400, "code": " version class Distribution(object): \"\"\"Represents a java distribution -either a JRE or a JDK installed on the local system. In particular provides access to the distribution's binaries; ie: java while", "label": 0}, {"snippet_id": 34240, "code": "): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads", "label": 0}, {"snippet_id": 73417, "code": " input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir) create_directory_tree(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(\"**/*.vcf\") for", "label": 0}, {"snippet_id": 66067, "code": ": lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False", "label": 0}, {"snippet_id": 28343, "code": " in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for", "label": 0}, {"snippet_id": 61459, "code": " must be of length 2**wires.') continue U=DefaultQubit._get_operator_matrix(operation) if len(operation.wires)==1: U=self.expand_one(U, operation.wires) elif len(operation.wires)==2: U=self.expand_two(U,", "label": 0}, {"snippet_id": 13971, "code": "=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return", "label": 1}, {"snippet_id": 5718, "code": " keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1]", "label": 0}, {"snippet_id": 36877, "code": " __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile,", "label": 0}, {"snippet_id": 9526, "code": " MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms ", "label": 0}, {"snippet_id": 27723, "code": " and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 64770, "code": " get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR,", "label": 0}, {"snippet_id": 1549, "code": ", many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname", "label": 0}, {"snippet_id": 82626, "code": "\t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests", "label": 0}, {"snippet_id": 55807, "code": "=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def", "label": 0}, {"snippet_id": 8329, "code": " > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True", "label": 1}, {"snippet_id": 10324, "code": " r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator", "label": 0}, {"snippet_id": 15203, "code": " UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 64401, "code": "): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self", "label": 0}, {"snippet_id": 40125, "code": ".S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path", "label": 0}, {"snippet_id": 33328, "code": " latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles,", "label": 0}, {"snippet_id": 63216, "code": ", client_outputs=self.__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description=dependencies_description", "label": 0}, {"snippet_id": 88146, "code": "(classpath_element): try: with open(os.path.join(classpath_element, _SCALAC_PLUGIN_INFO_FILE), 'r') as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except IOError as e", "label": 0}, {"snippet_id": 41645, "code": ", rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise", "label": 0}, {"snippet_id": 47062, "code": "(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule", "label": 0}, {"snippet_id": 4807, "code": " keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches", "label": 0}, {"snippet_id": 84974, "code": " help='Map from scalac plugin name to list of arguments for that plugin.') cls.register_jvm_tool(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit", "label": 0}, {"snippet_id": 54765, "code": " resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores", "label": 0}, {"snippet_id": 57879, "code": "(request): \"\"\" Add comment to one or more caseruns at a time. \"\"\" data=request.POST.copy() comment=data.get('comment', None) if not comment: return say_no('Comments needed') run_ids=[i for i in data.get", "label": 0}, {"snippet_id": 87186, "code": ": args=fp.read().split() zinc_args[compile_context.target]=args def create_empty_extra_products(self): if self.context.products.is_required_data('zinc_analysis'): self.context.products.safe_create_data", "label": 0}, {"snippet_id": 42960, "code": "(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params", "label": 0}, {"snippet_id": 77215, "code": ") > 2: self.log.debug('Line %s has too much spaces', line) proxypair=(proxypair[0], proxypair[1]) newproxies.add(proxypair) except Exception as e: self.log.exception('Line %s raised exception %s', line", "label": 0}, {"snippet_id": 80791, "code": ") \t\t\t\tattempts.append({\"suffix\":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as", "label": 1}, {"snippet_id": 51107, "code": ".dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(", "label": 0}, {"snippet_id": 56645, "code": ".objects.filter( tag__in=all_tags).values('tag').annotate(num_runs=Count('tag')).order_by('tag') plan_counter=_TagCounter('num_plans', test_plan_tags) case_counter=_TagCounter('num_cases', test_case_tags", "label": 0}, {"snippet_id": 59598, "code": "'Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces", "label": 0}, {"snippet_id": 29628, "code": ")\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern", "label": 0}, {"snippet_id": 9047, "code": "\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations", "label": 0}, {"snippet_id": 33687, "code": "=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason", "label": 0}, {"snippet_id": 84831, "code": " ZincLanguageMixin, InjectablesMixin, Subsystem): \"\"\"A scala platform. :API: public \"\"\" options_scope='scala' @classmethod def _create_jardep(cls, name, version): return JarDependency(org='org.scala-lang', name=name,", "label": 0}, {"snippet_id": 94454, "code": " successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED elif check_available and run_component_check(comp", "label": 0}, {"snippet_id": 34237, "code": ", message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate", "label": 0}, {"snippet_id": 12412, "code": " issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link", "label": 0}, {"snippet_id": 37396, "code": " be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance", "label": 0}, {"snippet_id": 75960, "code": " raise WorkerInterrupt() def auth_requests(self): for i, m in self.wz_auth_requests: def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Successfull auth for(%s", "label": 0}, {"snippet_id": 95401, "code": " ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}", "label": 0}, {"snippet_id": 55700, "code": "**ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo", "label": 0}, {"snippet_id": 73757, "code": ")} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\" password", "label": 0}, {"snippet_id": 44342, "code": " logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag", "label": 0}, {"snippet_id": 57449, "code": " specific update logic. \"\"\" ctype='testcases.testcase' def __init__(self, request): self.request=request self.target_field=request.POST.get('target_field') self.new_value=request.POST.get('new_value') def", "label": 0}, {"snippet_id": 44928, "code": " if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo", "label": 0}, {"snippet_id": 69895, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client", "label": 0}, {"snippet_id": 30795, "code": ".format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message", "label": 0}, {"snippet_id": 43779, "code": "() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not", "label": 0}, {"snippet_id": 83749, "code": ".__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed", "label": 0}, {"snippet_id": 73503, "code": " if conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in", "label": 0}, {"snippet_id": 14655, "code": " UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not", "label": 0}, {"snippet_id": 88193, "code": " Java code to classfiles using Zinc.\"\"\" @classmethod def product_types(cls): return['runtime_classpath', 'zinc_analysis', 'zinc_args'] def select(self, target): if not isinstance(target, JvmTarget): return", "label": 0}, {"snippet_id": 76499, "code": ".exception(e) self.log.info('Terminating') else: self.log.info('Aborted') self.running.set() self.unbind_methods() self.running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running", "label": 0}, {"snippet_id": 31964, "code": " \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item", "label": 0}, {"snippet_id": 23707, "code": " if chk_err and retcode !=0: raise OSUtilError(\"Failed to eject dvd: ret={0}\".format(retcode)) def restart_if(self, ifname): shellutil.run(\"/etc/rc.d/dhclient restart{0}\".format(ifname), chk_err=False)", "label": 0}, {"snippet_id": 19605, "code": ".append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd", "label": 1}, {"snippet_id": 90809, "code": " constraints for{} ' 'distribution: minimum_version{}, maximum_version{}') else: error_format=('Failed to locate a{} distribution with minimum_version{}, ' 'maximum_version{}') raise self.Error(error_format", "label": 0}, {"snippet_id": 34747, "code": ".file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file,", "label": 1}, {"snippet_id": 48381, "code": " be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item", "label": 0}, {"snippet_id": 28890, "code": " >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle']", "label": 0}, {"snippet_id": 87366, "code": ", javac_plugin_map, scalac_plugin_map): absolute_classpath=(ctx.classes_dir,) +tuple(ce.path for ce in dependency_classpath) if self.get_options().capture_classpath: self._record_compile_classpath(absolute_classpath", "label": 0}, {"snippet_id": 39963, "code": " times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None", "label": 0}, {"snippet_id": 23431, "code": " userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None: cmd=\"pw useradd{0} -e{1} -m\".format(username", "label": 0}, {"snippet_id": 18532, "code": ".CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data=", "label": 0}, {"snippet_id": 13601, "code": ".sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText):\r if( myText.find( \"twitter\") >=0):\r myText +=\"0\"\r myText=myText[7:-1]\r try:\r \t myText=twitter", "label": 0}, {"snippet_id": 85272, "code": ".injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address): jars=[create_jardep_func(self.version)] build_graph.inject_synthetic_target(target_address", "label": 0}, {"snippet_id": 69471, "code": "{} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd", "label": 0}, {"snippet_id": 2305, "code": " safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all(", "label": 0}, {"snippet_id": 60778, "code": ", **kwargs) return new_object class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an illegal operation in the quantum circuit. \"\"\" pass class Device(abc.ABC): \"\"\"Abstract", "label": 0}, {"snippet_id": 83050, "code": "._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests", "label": 0}, {"snippet_id": 93459, "code": " node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(", "label": 0}, {"snippet_id": 85452, "code": " recursive=True), Shader.exclude_package('xsbti', recursive=True), Shader.exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath=", "label": 0}, {"snippet_id": 35984, "code": " RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)", "label": 0}, {"snippet_id": 89800, "code": " command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the path to the command of the given name for this distribution. For example::: >>> d=Distribution(", "label": 0}, {"snippet_id": 68250, "code": " status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN", "label": 0}, {"snippet_id": 8536, "code": " user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\") local_stream.write", "label": 1}, {"snippet_id": 38017, "code": " wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len", "label": 0}, {"snippet_id": 88774, "code": ":API: public :param f: A multiproc-friendly(importable) work function. :param items: A iterable of pickleable arguments to f. \"\"\" try: res=SubprocPool.foreground().map_async(f, items) while not res.ready", "label": 0}, {"snippet_id": 54670, "code": "\"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule", "label": 0}, {"snippet_id": 41159, "code": "+add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__", "label": 0}, {"snippet_id": 79314, "code": ".futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size))", "label": 0}, {"snippet_id": 83007, "code": "=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 ", "label": 0}, {"snippet_id": 45756, "code": "( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names", "label": 0}, {"snippet_id": 32300, "code": " return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards", "label": 0}, {"snippet_id": 18303, "code": "(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'", "label": 0}, {"snippet_id": 87342, "code": ".compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self.get_options().pants_bootstrapdir, 'zinc'", "label": 1}, {"snippet_id": 71301, "code": " [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags", "label": 0}, {"snippet_id": 77018, "code": "(proxy if proxy else 'noproxy')+'_'+domain w=UniWipe(fset, tlist, sbjfun, message, pc, net, domain, Mailinator, uq(domain) if uq else None) w.stoponclose=c.stop_on_closed w.die_on_neterror=c.die_on_neterror", "label": 0}, {"snippet_id": 7054, "code": ":var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc", "label": 0}, {"snippet_id": 53760, "code": " \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name", "label": 0}, {"snippet_id": 28926, "code": "] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0", "label": 0}, {"snippet_id": 41346, "code": ")$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None:", "label": 0}, {"snippet_id": 63019, "code": " self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict()", "label": 0}, {"snippet_id": 49435, "code": "=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None", "label": 0}, {"snippet_id": 21417, "code": ", f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working directory found, but no subreddit directory", "label": 0}, {"snippet_id": 17851, "code": ".unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json", "label": 0}, {"snippet_id": 68548, "code": "[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\",", "label": 0}, {"snippet_id": 91412, "code": "'py', action=PythonRun).install('run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install('repl')", "label": 0}, {"snippet_id": 53576, "code": ".items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not", "label": 0}, {"snippet_id": 32220, "code": "*kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable", "label": 0}, {"snippet_id": 50753, "code": "=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException,", "label": 1}, {"snippet_id": 6478, "code": "=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords,", "label": 0}, {"snippet_id": 22225, "code": " if 'template' in self.conf[state]: template=self.conf[state]['template'] if playbook is None: playbook=self.conf['playbook'] if template is None and template in self.conf: template=self.conf['template']", "label": 0}, {"snippet_id": 32864, "code": " controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self", "label": 0}, {"snippet_id": 52310, "code": "(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input", "label": 0}, {"snippet_id": 33690, "code": ", cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds", "label": 0}, {"snippet_id": 87791, "code": " is_outside(path, self.get_options().pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath entries provided to zinc should be in working directory or ' 'part of the JDK.{", "label": 0}, {"snippet_id": 16372, "code": "]: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed(", "label": 0}, {"snippet_id": 32243, "code": "(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log", "label": 0}, {"snippet_id": 1912, "code": " for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1", "label": 0}, {"snippet_id": 31424, "code": ".missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(", "label": 0}, {"snippet_id": 45026, "code": "(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, ", "label": 0}, {"snippet_id": 28405, "code": "\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0", "label": 0}, {"snippet_id": 88359, "code": "\"\" def __init__(self, run_tracker): self._run_tracker=run_tracker def debug(self, *msg_elements): self._run_tracker.log(Report.DEBUG, *msg_elements) def info(self, *msg_elements): self._run_tracker.log", "label": 0}, {"snippet_id": 78544, "code": " WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c==0: self.log.info('No targets found at all, sleeping for 30 seconds') self.long_sleep(30) self.schedule(self.comment_loop)", "label": 0}, {"snippet_id": 21648, "code": " matplotlib.colors import ListedColormap X_set, y_set=X_train, y_train X1, X2=np.meshgrid(np.arange(start=X_set[:, 0].min() -1, stop=X_set[:, 0].max() +1, step=0.01), np.arange(start=X_set[:, 1].min() -1", "label": 0}, {"snippet_id": 66793, "code": " __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug", "label": 0}, {"snippet_id": 20630, "code": "._owned=owned self._handlers=[] for handler in handlers: if callable(handler): self._add_handler(handler) else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread( target", "label": 0}, {"snippet_id": 2090, "code": ".POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 91885, "code": " import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import memoized_property from pants.util.objects import SubclassesOf logger=logging.getLogger(__name__) class", "label": 1}, {"snippet_id": 14618, "code": "._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request", "label": 0}, {"snippet_id": 31238, "code": "(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name,", "label": 0}, {"snippet_id": 28541, "code": "], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24", "label": 0}, {"snippet_id": 70910, "code": "=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target", "label": 0}, {"snippet_id": 64509, "code": " new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError(opt) command.parse(new_args)", "label": 0}, {"snippet_id": 87871, "code": " raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-C-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _scalac_plugin_args(self", "label": 0}, {"snippet_id": 56179, "code": " import Q, Count from django.contrib.auth.models import User from django.core import serializers from django.core.exceptions import ObjectDoesNotExist from django.apps import apps from django.forms import", "label": 0}, {"snippet_id": 95369, "code": " remote_directory=ftp_config.directory) else: ftp.cwd(ftp_config.directory) file_counter=1 file_list_total=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath", "label": 0}, {"snippet_id": 6060, "code": " text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!", "label": 1}, {"snippet_id": 94983, "code": " if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument", "label": 0}, {"snippet_id": 13270, "code": "\"sha\": sha, } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not create new branch in the fork\" def autopep8ify(data, config): headers=", "label": 0}, {"snippet_id": 89106, "code": "=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate to targets they depend on that satisfy the on_predicate. :API: public \"\"\" core=set(self.targets(on_predicate))", "label": 0}, {"snippet_id": 91447, "code": "') task(name='py-wheels', action=LocalPythonDistributionArtifact).install('binary') task(name='isort-prep', action=IsortPrep).install('fmt') task(name='isort', action=IsortRun).install('fmt') task(name", "label": 0}, {"snippet_id": 285, "code": ": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method==", "label": 0}, {"snippet_id": 89126, "code": ") dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in target.dependencies: if dependency in core: dependees[target].add(dependency) return dependees def resolve(self", "label": 0}, {"snippet_id": 34803, "code": "(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self):", "label": 1}, {"snippet_id": 21951, "code": " private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args=None, poll_interval=None, seconds=None, check=None, syntax=None,", "label": 0}, {"snippet_id": 95306, "code": " path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors=True) def fetch_data_via_ftp(ftp_config, local_directory): \"", "label": 0}, {"snippet_id": 50443, "code": " decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 79587, "code": ",datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/", "label": 0}, {"snippet_id": 51966, "code": ": yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index", "label": 0}, {"snippet_id": 10777, "code": "(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\")", "label": 1}, {"snippet_id": 16746, "code": " extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded", "label": 0}, {"snippet_id": 6990, "code": "{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords", "label": 0}, {"snippet_id": 70844, "code": ", \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout", "label": 0}, {"snippet_id": 64358, "code": " unstructured_path_rewrites: return unstructured_path_rewrites[ parameter_value] if parameter_value in unstructured_path_rewrites.itervalues(): return parameter_value rewrite, new_unstructured_path_rewrites=self.path_mapper", "label": 0}, {"snippet_id": 77389, "code": "): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif type_", "label": 0}, {"snippet_id": 63740, "code": "=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid(", "label": 0}, {"snippet_id": 10998, "code": "', error: %s\" %(url, e) raise HostUnreachableException(msg) except RequestException as e: msg=\"Could not get monitoring yaml from '%s', error: %s\" %(url, e) raise MonitoringConfigGeneratorException(msg", "label": 0}, {"snippet_id": 73737, "code": "(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section", "label": 0}, {"snippet_id": 23285, "code": ".split(b'\\0', 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using tmsh. :param net: :param mask: :param gateway: :return: \"\"\" cmd=(\"/usr/bin/tmsh create net route \" \"{0}/{1} gw{2}\"", "label": 0}, {"snippet_id": 85923, "code": " safe_open from pants.util.process_handler import subprocess _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor'", "label": 0}, {"snippet_id": 35024, "code": " first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group", "label": 0}, {"snippet_id": 54725, "code": ") if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards,", "label": 0}, {"snippet_id": 69714, "code": "\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import", "label": 0}, {"snippet_id": 10095, "code": " % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords", "label": 0}, {"snippet_id": 94060, "code": " \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) deps.edge(ex", "label": 0}, {"snippet_id": 15657, "code": "): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler", "label": 0}, {"snippet_id": 91917, "code": "' default_native_source_extensions=['.c', '.cpp', '.cc'] class PythonNativeCodeError(Exception): pass @classmethod def register_options(cls, register): super(PythonNativeCode, cls).register_options(register", "label": 0}, {"snippet_id": 49061, "code": ".io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow:", "label": 1}, {"snippet_id": 93344, "code": "!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name'], comp['host'])) if comp", "label": 0}, {"snippet_id": 94596, "code": "(session, window_name): window=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd,", "label": 0}, {"snippet_id": 28867, "code": ".type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(", "label": 0}, {"snippet_id": 58565, "code": "(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct=ContentType.objects.get_for_model(TestCaseRun) for case_run_pk", "label": 0}, {"snippet_id": 33174, "code": ", stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False", "label": 0}, {"snippet_id": 83277, "code": ".running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id", "label": 0}, {"snippet_id": 77646, "code": " self.log.debug('Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug(", "label": 0}, {"snippet_id": 64831, "code": "=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support", "label": 0}, {"snippet_id": 28740, "code": " data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self", "label": 0}, {"snippet_id": 5714, "code": "): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len", "label": 0}, {"snippet_id": 21051, "code": " return msg, True self._add_handler(handler, handlername) try: yield finally: wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event", "label": 0}, {"snippet_id": 8076, "code": " sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the", "label": 0}, {"snippet_id": 29217, "code": ".access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self):", "label": 1}, {"snippet_id": 38565, "code": " printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag", "label": 0}, {"snippet_id": 66495, "code": " def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR", "label": 0}, {"snippet_id": 70342, "code": " self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset", "label": 0}, {"snippet_id": 34042, "code": ".params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule", "label": 0}, {"snippet_id": 73375, "code": "): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located", "label": 0}, {"snippet_id": 89239, "code": "=None): \"\"\"Executes a process(possibly remotely), and returns information about its output. :param execute_process_request: The ExecuteProcessRequest to run. :param name: A descriptive name representing", "label": 1}, {"snippet_id": 34998, "code": ".escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string", "label": 0}, {"snippet_id": 26813, "code": " data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self", "label": 0}, {"snippet_id": 76022, "code": "%s, %s) %s: %s', i, m, wzrpc.name_status(status), repr(data)) self.wz_wait_reply(accept, *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m])) def bind_route(self, i, m, f): self.log.debug('Binding", "label": 0}, {"snippet_id": 60447, "code": " import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix, DisplacedSqueezed,", "label": 0}, {"snippet_id": 46293, "code": " Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames,", "label": 0}, {"snippet_id": 52402, "code": " b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to", "label": 0}, {"snippet_id": 86456, "code": " pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend", "label": 0}, {"snippet_id": 22429, "code": "\"/usr/bin/tmsh save sys config\" rc=shellutil.run(cmd) if rc !=0: logger.error(\"WARNING: Cannot save sys config on 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart", "label": 0}, {"snippet_id": 94984, "code": " it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(", "label": 0}, {"snippet_id": 73036, "code": "\" else: remote_subdirs_list=[] remote_path_relative=\"\" remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP", "label": 0}, {"snippet_id": 74519, "code": ".server=runtime_config.ftp[\"server\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if", "label": 0}, {"snippet_id": 52713, "code": ".exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def", "label": 0}, {"snippet_id": 49229, "code": ".is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len", "label": 0}, {"snippet_id": 14323, "code": " '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os", "label": 0}, {"snippet_id": 69708, "code": " to start Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import ", "label": 0}, {"snippet_id": 23329, "code": " yet initialized this list of devices. :param port_id: :return: \"\"\" for retries in range(1, 100): if os.path.exists(\"/sys/bus/vmbus/devices/\"): break else: time.sleep(10) return super(BigIpOSUtil, self)", "label": 0}, {"snippet_id": 59847, "code": "{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number", "label": 0}, {"snippet_id": 55982, "code": "(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func", "label": 0}, {"snippet_id": 16453, "code": ") self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled", "label": 0}, {"snippet_id": 36864, "code": " s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced", "label": 0}, {"snippet_id": 89357, "code": " import AbstractClass from pants.util.osutil import OS_ALIASES, normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version", "label": 0}, {"snippet_id": 90079, "code": " return self._system_properties def _validate_executable(self, name): def bin_paths(): yield self._bin_path if self._is_jdk: yield os.path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe", "label": 0}, {"snippet_id": 57060, "code": " def say_no(error_msg): ajax_response={'rc': 1, 'response': error_msg} return HttpResponse(json.dumps(ajax_response)) def say_yes(): return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'})) @require_POST", "label": 0}, {"snippet_id": 37754, "code": "(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self", "label": 0}, {"snippet_id": 37579, "code": "._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len", "label": 0}, {"snippet_id": 76980, "code": "=True from lib.mailinator import Mailinator def create_spawn(proxy, proxytype, pc, uq=None): for domain in domains: if domain in targets: tlist=targets[domain] else: tlist=list() targets[domain]=tlist if", "label": 0}, {"snippet_id": 69844, "code": ".__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR", "label": 0}, {"snippet_id": 86128, "code": "(processor.strip())) def execute(self): if JvmPlatform.global_instance().get_options().compiler=='javac': return super(JavacCompile, self).execute() def compile(self, ctx, args, dependency_classpath, upstream_analysis", "label": 0}, {"snippet_id": 22920, "code": " on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. We also don't use sudo, so we remove that method call as well. :param username", "label": 0}, {"snippet_id": 71213, "code": "=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO:", "label": 0}, {"snippet_id": 51438, "code": "\"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise", "label": 0}, {"snippet_id": 14700, "code": "(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format(", "label": 0}, {"snippet_id": 17185, "code": ".event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError:", "label": 0}, {"snippet_id": 62141, "code": " list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose", "label": 0}, {"snippet_id": 14859, "code": ".unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': ", "label": 0}, {"snippet_id": 16874, "code": "=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{", "label": 0}, {"snippet_id": 79702, "code": " via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy", "label": 0}, {"snippet_id": 1884, "code": " cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0", "label": 0}, {"snippet_id": 38010, "code": " files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None", "label": 0}, {"snippet_id": 85173, "code": " return '{0}_{1}'.format(name, suffix) else: raise RuntimeError('Suffix version must be specified if using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala", "label": 0}, {"snippet_id": 5419, "code": " expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return", "label": 0}, {"snippet_id": 28320, "code": " add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import", "label": 1}, {"snippet_id": 57776, "code": " except ValueError: return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets=self", "label": 0}, {"snippet_id": 11470, "code": " % self.source) yaml_config=YamlConfig(raw_yaml_config, skip_checks=self.skip_checks) if yaml_config.host and self._is_newer(header_source, yaml_config.host_name): file_name=self.create_filename(yaml_config", "label": 0}, {"snippet_id": 5204, "code": "]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories } def _output_text(complete_output, categories", "label": 0}, {"snippet_id": 80424, "code": " program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime", "label": 0}, {"snippet_id": 85407, "code": " DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope='zinc' @classmethod def subsystem_dependencies(cls):", "label": 0}, {"snippet_id": 72343, "code": ") world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally: log.debug('(%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname) remoteirc", "label": 1}, {"snippet_id": 74362, "code": " '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data", "label": 0}, {"snippet_id": 32592, "code": " Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"", "label": 0}, {"snippet_id": 18175, "code": " CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import", "label": 0}, {"snippet_id": 82593, "code": " at \"+str(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower()", "label": 0}, {"snippet_id": 83123, "code": " __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.", "label": 0}, {"snippet_id": 46846, "code": "(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output", "label": 0}, {"snippet_id": 26548, "code": " elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self", "label": 0}, {"snippet_id": 80972, "code": "\tself.inputName=inputName \t\tself.uploadsFolder=uploadsFolder \t\tself.size=size \t\tself.validExtensions=[] \t\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None \t\tself.logLock=Lock() \t\tself.stopThreads=False ", "label": 0}, {"snippet_id": 12026, "code": "\"--{}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments.append(\"--{}={}\".format(key, ','.join(value))) config[\"pycodestyle_cmd_config\"]='{arguments", "label": 0}, {"snippet_id": 88830, "code": " \"\"\" with self.run_tracker.new_workunit(name=name, labels=labels, cmd=cmd, log_config=log_config) as workunit: yield workunit def acquire_lock(self): \"\"\" Acquire the global lock for the root directory associated", "label": 0}, {"snippet_id": 94067, "code": " ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color", "label": 0}, {"snippet_id": 87277, "code": "._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f: for processor in processors: f.write(", "label": 0}, {"snippet_id": 78785, "code": ",trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t\tself.logger=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse", "label": 0}, {"snippet_id": 85203, "code": " '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would use the suffix version \"2.10\".') elif name.endswith(self.version): raise ValueError('The name \"{0}\" should not be suffixed with", "label": 0}, {"snippet_id": 37347, "code": " if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self", "label": 0}, {"snippet_id": 55806, "code": "=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate", "label": 0}, {"snippet_id": 17694, "code": " debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid)", "label": 0}, {"snippet_id": 7849, "code": "\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: set of formatted", "label": 0}, {"snippet_id": 25525, "code": "(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif", "label": 0}, {"snippet_id": 74533, "code": ".password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config", "label": 0}, {"snippet_id": 16412, "code": ".join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR", "label": 0}, {"snippet_id": 32496, "code": ", wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except", "label": 0}, {"snippet_id": 16520, "code": "._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def", "label": 0}, {"snippet_id": 84117, "code": "=\"remote\" if not remote_dependency_resolution: return None requirements=job_wrapper.tool.requirements or[] installed_tool_dependencies=job_wrapper.tool.installed_tool_dependencies or[] return dependencies", "label": 0}, {"snippet_id": 12348, "code": "\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[\"synchronize", "label": 0}, {"snippet_id": 93316, "code": " self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not", "label": 0}, {"snippet_id": 66717, "code": ".cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message)", "label": 0}, {"snippet_id": 67291, "code": "\\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount", "label": 0}, {"snippet_id": 74890, "code": ". :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"benchmark", "label": 0}, {"snippet_id": 81615, "code": " mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif", "label": 0}, {"snippet_id": 4521, "code": "=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else:", "label": 0}, {"snippet_id": 5107, "code": "\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience", "label": 0}, {"snippet_id": 86284, "code": ".execution_strategy==self.HERMETIC: self._execute_hermetic_compile(javac_cmd, ctx) else: with self.context.new_workunit(name='javac', cmd=' '.join(javac_cmd), labels=[WorkUnitLabel.COMPILER]) as workunit", "label": 0}, {"snippet_id": 69738, "code": ".RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class", "label": 0}, {"snippet_id": 29427, "code": " def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match", "label": 0}, {"snippet_id": 30277, "code": " allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None", "label": 0}, {"snippet_id": 81984, "code": "\",\"--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the template", "label": 0}, {"snippet_id": 13705, "code": "(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 ", "label": 0}, {"snippet_id": 6136, "code": ".close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb", "label": 1}, {"snippet_id": 88812, "code": " @contextmanager def new_workunit(self, name, labels=None, cmd='', log_config=None): \"\"\"Create a new workunit under the calling thread's current workunit. :API: public \"\"\" with self.run_tracker.new_workunit(name=name", "label": 0}, {"snippet_id": 51470, "code": "(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value", "label": 1}, {"snippet_id": 83979, "code": " to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id", "label": 0}, {"snippet_id": 88084, "code": " active_plugins[name]=rel_classpath_elements if len(active_plugins)==len(plugin_names): return active_plugins unresolved_plugins=plugin_names -set(active_plugins.keys()) raise TaskError('Could not find", "label": 0}, {"snippet_id": 82531, "code": "[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable", "label": 0}, {"snippet_id": 14662, "code": ".UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), ", "label": 0}, {"snippet_id": 3636, "code": ") if check_available and run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available", "label": 0}, {"snippet_id": 1341, "code": "(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \"802-11-wireless\":{ \"security\": \"802-11", "label": 0}, {"snippet_id": 75440, "code": " def get_iden(self, reqid): return self.iden_reqid_map.get_key(reqid) def get_reqids(self, iden): return self.iden_reqid_map.get_values(iden) def make_reqid(self): while True: reqid=random.randint(1,(2", "label": 0}, {"snippet_id": 41078, "code": " names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index", "label": 0}, {"snippet_id": 58033, "code": " or more caserun at a time. \"\"\" data, error=clean_bug_form(request) if error: return say_no(error) runs=TestCaseRun.objects.filter(pk__in=data['runs']) bug_system_id=data['bug_system_id'] bug_ids=data[", "label": 0}, {"snippet_id": 92280, "code": " subprocess.Popen([sys.executable, '-c', 'import os; print(os.environ[\"HORK\"])'], stdout=output).wait() output.seek(0) self.assertEqual('BORK\\n', output.read()) with temporary_file(binary_mode=False) as", "label": 0}, {"snippet_id": 93628, "code": "\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self", "label": 0}, {"snippet_id": 47527, "code": " \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other", "label": 0}, {"snippet_id": 8402, "code": "=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please", "label": 1}, {"snippet_id": 44720, "code": ".overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule", "label": 0}, {"snippet_id": 15840, "code": " import vim import requests import urlparse from retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm", "label": 0}, {"snippet_id": 30456, "code": "\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict", "label": 0}, {"snippet_id": 72635, "code": "] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\": print(\"[Setup] Setting up benchmark data", "label": 0}, {"snippet_id": 63682, "code": " threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os", "label": 0}, {"snippet_id": 88898, "code": " is_unlocked(self): \"\"\"Whether the global lock object is actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots", "label": 0}, {"snippet_id": 47162, "code": " combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self", "label": 0}, {"snippet_id": 4768, "code": " limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords", "label": 0}, {"snippet_id": 41948, "code": " if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self", "label": 0}, {"snippet_id": 15116, "code": " try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data", "label": 0}, {"snippet_id": 45166, "code": " decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo:", "label": 0}, {"snippet_id": 20490, "code": ") self._sock=sock self._ownsock=ownsock @property def is_client(self): try: return self._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 80027, "code": " and filtered by the server. Needs -l switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first", "label": 0}, {"snippet_id": 55528, "code": " return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd", "label": 0}, {"snippet_id": 47354, "code": "\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output", "label": 0}, {"snippet_id": 59132, "code": " C++-based kernels. -projectq.backends.ClassicalSimulator()\t A simple introspective simulator that only permits classical operations. -projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class", "label": 0}, {"snippet_id": 11449, "code": " host name %r\" raise Exception(msg % hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config(self.source) if raw_yaml_config is None: raise SystemExit(\"Raw yaml", "label": 0}, {"snippet_id": 63112, "code": " return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status", "label": 0}, {"snippet_id": 10979, "code": " HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except Timeout as e: msg=\"Connect timed out for", "label": 0}, {"snippet_id": 43752, "code": ".config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property", "label": 0}, {"snippet_id": 37853, "code": "(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 84447, "code": ", remote_path)) return results def input_paths( self): local_input_paths=self._wrapper_input_paths results=[] for local_input_path in local_input_paths: wrapper_path=str( local_input_path) remote_path=self", "label": 0}, {"snippet_id": 58910, "code": ".pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': \"You don't have enough permission to \" \"update", "label": 0}, {"snippet_id": 47615, "code": ") self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input", "label": 0}, {"snippet_id": 76796, "code": ", help='Topic success timeout') parser.add_argument('--errortimeout', type=float, default=3, help='Error timeout') parser.add_argument('--stop-on-closed', action='store_true', default=False, help='Forget", "label": 0}, {"snippet_id": 20788, "code": "=lambda msg: True, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event and condition(msg", "label": 0}, {"snippet_id": 87495, "code": "} ) zinc_args.extend(self._scalac_plugin_args(scalac_plugin_map, scalac_plugin_search_classpath)) if upstream_analysis: zinc_args.extend(['-analysis-map', ','.join('{}:{}'.format( relative_to_exec_root", "label": 0}, {"snippet_id": 31455, "code": "\", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or self.nooutput", "label": 0}, {"snippet_id": 88773, "code": ". :API: public :param f: A multiproc-friendly(importable) work function. :param items: A iterable of pickleable arguments to f. \"\"\" try: res=SubprocPool.foreground().map_async(f, items) while not res.ready", "label": 0}, {"snippet_id": 15113, "code": " response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf", "label": 0}, {"snippet_id": 66276, "code": "\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT", "label": 0}, {"snippet_id": 50275, "code": "], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value", "label": 0}, {"snippet_id": 76415, "code": "() try: self.wz.parse_msg(frames[0], frames[1:]) except wzrpc.WZError as e: self.log.warn(e) if socks.get(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg", "label": 0}, {"snippet_id": 30685, "code": " if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule", "label": 0}, {"snippet_id": 89151, "code": " target(s) the given address points to. :API: public \"\"\" return self.build_graph.resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found", "label": 0}, {"snippet_id": 77556, "code": " self.userqueues[domain]=uq except Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users(self): users={} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds", "label": 0}, {"snippet_id": 54881, "code": "]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule,", "label": 0}, {"snippet_id": 33880, "code": " self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code)", "label": 0}, {"snippet_id": 50696, "code": " workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for", "label": 0}, {"snippet_id": 11039, "code": ".load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y %H:%M:%S %Z').strftime('%s') if mtime else int(time()) else", "label": 1}, {"snippet_id": 38507, "code": " rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not", "label": 0}, {"snippet_id": 79684, "code": ",description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example", "label": 0}, {"snippet_id": 28200, "code": ", 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None", "label": 0}, {"snippet_id": 58258, "code": ".testplans.models import TestPlan from tcms.testruns.models import TestCaseRun from tcms.testruns.models import TestCaseRunStatus from tcms.tests import BaseCaseRun from tcms.tests import BasePlanCase from", "label": 0}, {"snippet_id": 38504, "code": "=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource", "label": 0}, {"snippet_id": 93024, "code": "(stdout_fd=-1, stderr_fd=-1, stdin_fd=-1): self.assertEqual('', sys.stdin.read()) print('garbage', file=sys.stdout) print('garbage', file=sys.stderr) def test_signal_handler_as(self): mock_initial_handler=1", "label": 0}, {"snippet_id": 66582, "code": ".Globals import Globals from Commands.CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration", "label": 0}, {"snippet_id": 87185, "code": " as fp: args=fp.read().split() zinc_args[compile_context.target]=args def create_empty_extra_products(self): if self.context.products.is_required_data('zinc_analysis'): self.context.products.safe_create_data", "label": 0}, {"snippet_id": 13412, "code": "=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https:", "label": 0}, {"snippet_id": 89496, "code": " wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param string home_path: the path to the java distribution's home dir :param string bin_path: the", "label": 0}, {"snippet_id": 29942, "code": ") for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values", "label": 0}, {"snippet_id": 18143, "code": " OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm", "label": 0}, {"snippet_id": 40000, "code": " file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(", "label": 0}, {"snippet_id": 1963, "code": ".split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con", "label": 0}, {"snippet_id": 79447, "code": ",mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1", "label": 1}, {"snippet_id": 79509, "code": "\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern", "label": 1}, {"snippet_id": 82521, "code": ";32m ___ _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage", "label": 0}, {"snippet_id": 27135, "code": " from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION", "label": 1}, {"snippet_id": 40314, "code": ", latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info", "label": 0}, {"snippet_id": 3894, "code": "=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument", "label": 0}, {"snippet_id": 68091, "code": " RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support", "label": 1}, {"snippet_id": 65649, "code": "\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support", "label": 1}, {"snippet_id": 71808, "code": ".message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e", "label": 1}, {"snippet_id": 8051, "code": " r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator", "label": 0}, {"snippet_id": 77691, "code": " load_bumplimit_set(self): if not os.path.isfile(self.bumplimitfile): return with open(self.bumplimitfile, 'rb') as f: self.pc.sets['bumplimit'].update(pickle.loads(f.read())) def save_targets(self): data={ 'targets", "label": 0}, {"snippet_id": 39090, "code": "\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname,", "label": 0}, {"snippet_id": 46696, "code": ") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.", "label": 0}, {"snippet_id": 37635, "code": " for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self", "label": 0}, {"snippet_id": 54506, "code": "=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir", "label": 0}, {"snippet_id": 33718, "code": " not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores", "label": 0}, {"snippet_id": 28839, "code": "'WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state", "label": 0}, {"snippet_id": 54273, "code": ": l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the", "label": 0}, {"snippet_id": 93357, "code": " (comp['name'], group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self", "label": 0}, {"snippet_id": 62436, "code": "))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device", "label": 0}, {"snippet_id": 72887, "code": " local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p", "label": 0}, {"snippet_id": 26594, "code": " self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full", "label": 0}, {"snippet_id": 50849, "code": " specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK)", "label": 1}, {"snippet_id": 67400, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import", "label": 0}, {"snippet_id": 67409, "code": " Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand):", "label": 0}, {"snippet_id": 43234, "code": " wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, ", "label": 0}, {"snippet_id": 16476, "code": " extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive(", "label": 0}, {"snippet_id": 30489, "code": " be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic", "label": 0}, {"snippet_id": 88852, "code": " associated with this context. When a goal requires serialization, it will call this to acquire the lock. :API: public \"\"\" if self.options.for_global_scope().lock: if not self._lock.acquired: self._lock.acquire(", "label": 0}, {"snippet_id": 57497, "code": "=self.get_update_action() if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception: return say_no('Update failed. Please try", "label": 0}, {"snippet_id": 12665, "code": " PERMITTED_TO_COMMENT def create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"])", "label": 0}, {"snippet_id": 24869, "code": ".type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" ", "label": 0}, {"snippet_id": 59423, "code": "] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg", "label": 0}, {"snippet_id": 35730, "code": " insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name", "label": 0}, {"snippet_id": 51512, "code": "\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given", "label": 0}, {"snippet_id": 23400, "code": "(rc_file_path, \"\\n\".join(conf_file)) shellutil.run(\"hostname{0}\".format(hostname), chk_err=False) def restart_ssh_service(self): return shellutil.run('service sshd restart', chk_err=False) def useradd(self", "label": 1}, {"snippet_id": 66083, "code": "\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif", "label": 0}, {"snippet_id": 41389, "code": " format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs,", "label": 0}, {"snippet_id": 90523, "code": " the cache. :rtype::class:`pants.java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version and dist.version", "label": 0}, {"snippet_id": 74357, "code": " return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir", "label": 0}, {"snippet_id": 52864, "code": " threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as", "label": 0}, {"snippet_id": 11558, "code": " sorted_keys=section_data.keys() sorted_keys.sort() for key in sorted_keys: value=section_data[key] self.icinga_lines.append((\"%s%-45s%s\" %(self.indent, key, self.value_to_icinga(value)))) self.write_line(\"", "label": 1}, {"snippet_id": 57467, "code": "=request.POST.get('new_value') def get_update_action(self): return getattr(self, '_update_%s' % self.target_field, None) def update(self): has_perms=check_permission(self.request, self.ctype) if not has_perms", "label": 0}, {"snippet_id": 3365, "code": ".session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile", "label": 0}, {"snippet_id": 23086, "code": ":param chk_err: Whether to check for errors or not in the mounting commands \"\"\" self._wait_until_mcpd_is_initialized() return super(BigIpOSUtil, self).mount_dvd(**kwargs) def eject_dvd(self, chk_err=True", "label": 0}, {"snippet_id": 73504, "code": " conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.", "label": 0}, {"snippet_id": 6373, "code": " or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the", "label": 0}, {"snippet_id": 79462, "code": "\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself", "label": 0}, {"snippet_id": 30431, "code": "\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file", "label": 0}, {"snippet_id": 28884, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self", "label": 0}, {"snippet_id": 8629, "code": " outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a", "label": 0}, {"snippet_id": 89470, "code": " distribution.\"\"\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version=None, maximum_version", "label": 0}, {"snippet_id": 56587, "code": "\" tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr", "label": 0}, {"snippet_id": 78539, "code": ".extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c==0: self.log.info('No targets found", "label": 0}, {"snippet_id": 93671, "code": ".check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to", "label": 0}, {"snippet_id": 87357, "code": " 'zinc', key) def compile(self, ctx, args, dependency_classpath, upstream_analysis, settings, compiler_option_sets, zinc_file_manager, javac_plugin_map, scalac_plugin_map): absolute_classpath=(ctx.classes_dir", "label": 1}, {"snippet_id": 37329, "code": " output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not", "label": 0}, {"snippet_id": 12975, "code": "]={ \"content\": diffs } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post", "label": 0}, {"snippet_id": 45578, "code": " except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile", "label": 0}, {"snippet_id": 87458, "code": ").colors: zinc_args.append('-no-color') zinc_args.extend(['-compiler-interface', compiler_interface]) zinc_args.extend(['-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir", "label": 1}, {"snippet_id": 57305, "code": ", request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"", "label": 0}, {"snippet_id": 24350, "code": " if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name", "label": 0}, {"snippet_id": 93376, "code": "'name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']:", "label": 0}, {"snippet_id": 53425, "code": " branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len", "label": 0}, {"snippet_id": 12400, "code": "\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8 issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else:", "label": 0}, {"snippet_id": 91250, "code": " from pants.backend.python.tasks.pytest_prep import PytestPrep from pants.backend.python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import PythonBinaryCreate", "label": 0}, {"snippet_id": 23185, "code": " shipped with BIG-IP instead of python x86_64?? \"\"\" iface='' expected=16 python_arc=platform.architecture()[0] if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET", "label": 0}, {"snippet_id": 83351, "code": " dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters( client) unstructured_path_rewrites={} if compute_environment:", "label": 0}, {"snippet_id": 71773, "code": " print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError", "label": 0}, {"snippet_id": 59391, "code": "'shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs", "label": 0}, {"snippet_id": 57252, "code": ": field='close_date' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), now ) ) if t.tested_by !=request.user: field='tested_by' t.log_action( who=request", "label": 0}, {"snippet_id": 10641, "code": " executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document,", "label": 0}, {"snippet_id": 18272, "code": " self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False", "label": 0}, {"snippet_id": 9817, "code": " the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author", "label": 0}, {"snippet_id": 50533, "code": " decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs", "label": 0}, {"snippet_id": 35344, "code": "): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten", "label": 0}, {"snippet_id": 95538, "code": ".path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list", "label": 0}, {"snippet_id": 65566, "code": ") vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel", "label": 0}, {"snippet_id": 46478, "code": ".items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j", "label": 0}, {"snippet_id": 94683, "code": "-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser('edit', help=", "label": 0}, {"snippet_id": 4001, "code": "='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(", "label": 0}, {"snippet_id": 39995, "code": " def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function", "label": 0}, {"snippet_id": 35404, "code": "{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns", "label": 0}, {"snippet_id": 74424, "code": " the configuration representation with a supplied file. \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format", "label": 0}, {"snippet_id": 42087, "code": " res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule", "label": 0}, {"snippet_id": 87371, "code": " +tuple(ce.path for ce in dependency_classpath) if self.get_options().capture_classpath: self._record_compile_classpath(absolute_classpath, ctx.target, ctx.classes_dir) self._verify_zinc_classpath(absolute_classpath", "label": 0}, {"snippet_id": 31392, "code": "\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are", "label": 0}, {"snippet_id": 73554, "code": ":{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format", "label": 0}, {"snippet_id": 14425, "code": " vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return", "label": 0}, {"snippet_id": 41517, "code": ") if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input", "label": 0}, {"snippet_id": 91881, "code": " IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import memoized_property from pants.util.objects import", "label": 1}, {"snippet_id": 52655, "code": "(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark)", "label": 0}, {"snippet_id": 73998, "code": " chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\"", "label": 0}, {"snippet_id": 37784, "code": "(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio", "label": 0}, {"snippet_id": 93179, "code": ")s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\"", "label": 0}, {"snippet_id": 3734, "code": " is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name", "label": 0}, {"snippet_id": 54201, "code": " output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile", "label": 0}, {"snippet_id": 5973, "code": " import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,", "label": 1}, {"snippet_id": 43341, "code": " benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str", "label": 0}, {"snippet_id": 91748, "code": ", source_root in sources_snapshots_and_source_roots ] sources_digest=yield Get( Digest, DirectoriesToMerge(directories=tuple(all_sources_digests)), ) inits_digest=yield Get(InjectedInitDigest, Digest, sources_digest", "label": 0}, {"snippet_id": 57896, "code": "('Comments needed') run_ids=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return", "label": 0}, {"snippet_id": 42733, "code": " are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True", "label": 0}, {"snippet_id": 66433, "code": " client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path)", "label": 1}, {"snippet_id": 90505, "code": " maximum jvm version to look for(eg, 1.7.9999). :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None if no matching distribution is in the cache. ", "label": 0}, {"snippet_id": 24947, "code": "'GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 8627, "code": " second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately", "label": 0}, {"snippet_id": 61361, "code": "(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Default OpenQML plugin' short_name='default.qubit' api_version='0.1.0' version='0", "label": 0}, {"snippet_id": 19995, "code": " adapter is None: adapter=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError('detach not supported') self._detach() def _close(self): if self._session is not None:", "label": 0}, {"snippet_id": 352, "code": "\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False", "label": 0}, {"snippet_id": 58407, "code": "\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls).setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs') def test_refuse_if_missing_comment", "label": 0}, {"snippet_id": 10978, "code": ") raise HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except Timeout as e: msg=\"Connect", "label": 0}, {"snippet_id": 91515, "code": ".isolated_process import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult) from pants.engine.legacy.graph import BuildFileAddresses, TransitiveHydratedTargets from pants.engine", "label": 0}, {"snippet_id": 46663, "code": " ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\")", "label": 0}, {"snippet_id": 85659, "code": ":rtype: str \"\"\" return self._zinc_factory._compiler_interface(self._products) @memoized_method def snapshot(self, scheduler): buildroot=get_buildroot() return scheduler.capture_snapshots(( PathGlobsAndRoot", "label": 0}, {"snippet_id": 72920, "code": "=local_directory, remote_directory=ftp_config.directory) else: ftp.cwd(ftp_config.directory) file_counter=1 file_list_total=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename", "label": 0}, {"snippet_id": 61094, "code": " theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_x \\theta/2}` \"\"\" return expm(-1j * theta/2 * X) def fry(theta): r\"\"\"One-qubit rotation about the y axis. Args", "label": 0}, {"snippet_id": 93285, "code": ") self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server", "label": 0}, {"snippet_id": 95434, "code": "[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory", "label": 0}, {"snippet_id": 46958, "code": ".add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash", "label": 0}, {"snippet_id": 65350, "code": " Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to enquire", "label": 0}, {"snippet_id": 72121, "code": ".networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 2: network name(case sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No such network \"%s", "label": 0}, {"snippet_id": 30796, "code": ".rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell", "label": 0}, {"snippet_id": 3120, "code": " self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp)", "label": 0}, {"snippet_id": 68763, "code": " [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags", "label": 0}, {"snippet_id": 84523, "code": " new_unstructured_path_rewrites=self.path_mapper.check_for_arbitrary_rewrite( parameter_value) if rewrite: unstructured_path_rewrites.update(new_unstructured_path_rewrites) return rewrite else: return parameter_value", "label": 0}, {"snippet_id": 53088, "code": ")) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated", "label": 0}, {"snippet_id": 29392, "code": " IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self", "label": 1}, {"snippet_id": 21074, "code": "(msg): if not match(msg): return msg, False event.set() return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object): @classmethod def wait_all(cls, *awaitables)", "label": 0}, {"snippet_id": 31619, "code": " self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set", "label": 0}, {"snippet_id": 22039, "code": "=ssh_common_args self.sftp_extra_args=sftp_extra_args self.scp_extra_args=scp_extra_args self.ssh_extra_args=ssh_extra_args self.poll_interval=poll_interval self.seconds=seconds self.check=check self.syntax=syntax", "label": 0}, {"snippet_id": 7574, "code": " boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} <", "label": 0}, {"snippet_id": 6795, "code": ", fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else: single_keywords", "label": 0}, {"snippet_id": 47101, "code": " Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 27107, "code": "/home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const", "label": 1}, {"snippet_id": 86893, "code": "-C.*': False, '-file-filter': True, '-msg-filter': True, }, help='A dict of option regexes that make up pants\\' supported API for zinc. ' 'Options not listed here are subject to change/removal. The value", "label": 0}, {"snippet_id": 19377, "code": " PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py \"\"\" PYDEVD_OPTS=", "label": 0}, {"snippet_id": 85201, "code": " specified in ' '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would use the suffix version \"2.10\".') elif name.endswith(self.version): raise ValueError('The name \"{0}\" should not", "label": 0}, {"snippet_id": 85932, "code": "/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): \"\"\"Compile Java code using", "label": 0}, {"snippet_id": 77666, "code": "'forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data['domains']) if 'sets' in data: self.log.debug('Other sets were loaded') self.pc.sets.update(data['sets']) def", "label": 0}, {"snippet_id": 37141, "code": ", io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch", "label": 0}, {"snippet_id": 70758, "code": " print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type", "label": 0}, {"snippet_id": 52299, "code": " res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set(", "label": 0}, {"snippet_id": 68168, "code": " defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result", "label": 0}, {"snippet_id": 57655, "code": ".objects.get(pk=self.new_value) except TestCaseStatus.DoesNotExist: raise ObjectDoesNotExist('The status you choose does not exist.') update_object=self.get_update_targets() if not update_object: return", "label": 0}, {"snippet_id": 38097, "code": " return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"", "label": 0}, {"snippet_id": 31098, "code": ".dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}", "label": 0}, {"snippet_id": 77216, "code": ": self.log.debug('Line %s has too much spaces', line) proxypair=(proxypair[0], proxypair[1]) newproxies.add(proxypair) except Exception as e: self.log.exception('Line %s raised exception %s', line, e) return", "label": 0}, {"snippet_id": 13619, "code": " myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\"", "label": 0}, {"snippet_id": 61314, "code": "'QubitUnitary': unitary, 'Hermitian': hermitian, 'Identity': I, 'PauliX': X, 'PauliY': Y, 'PauliZ': Z, 'CNOT': CNOT, 'SWAP': SWAP, 'RX': frx, 'RY': fry, 'RZ': frz, 'Rot': fr3 } class DefaultQubit(Device): ", "label": 0}, {"snippet_id": 30934, "code": " combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in", "label": 0}, {"snippet_id": 33414, "code": " the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" ", "label": 0}, {"snippet_id": 51517, "code": " files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns", "label": 0}, {"snippet_id": 75172, "code": " (b'Router', b'auth-set-route-type')] self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init", "label": 0}, {"snippet_id": 75829, "code": "(fun) msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) t.tick() while self.running.is_set(): p(timeout*1000) if rs.finished: if rs.retry: msg", "label": 0}, {"snippet_id": 12978, "code": "={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers", "label": 0}, {"snippet_id": 76996, "code": " targets: tlist=targets[domain] else: tlist=list() targets[domain]=tlist if domain in forums: fset=forums[domain] else: fset=set() forums[domain]=fset net=make_net(proxy, proxytype) net.cookiefname=(proxy if", "label": 0}, {"snippet_id": 61864, "code": " ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends", "label": 0}, {"snippet_id": 73534, "code": ") numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:", "label": 0}, {"snippet_id": 5837, "code": "(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir", "label": 0}, {"snippet_id": 32294, "code": " isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems", "label": 0}, {"snippet_id": 61641, "code": "._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation value.'.format(expectation.imag)) return expectation.real def reset(self): \"\"\"Reset the device", "label": 0}, {"snippet_id": 74094, "code": " blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level", "label": 0}, {"snippet_id": 73851, "code": "\"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files\"]) if files_str==\"*\"", "label": 0}, {"snippet_id": 18768, "code": ".eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return", "label": 0}, {"snippet_id": 60187, "code": " Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CatState:", "label": 0}, {"snippet_id": 79402, "code": "(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(", "label": 0}, {"snippet_id": 50692, "code": ".join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path", "label": 0}, {"snippet_id": 69555, "code": " args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif", "label": 0}, {"snippet_id": 39072, "code": ", dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler", "label": 0}, {"snippet_id": 56902, "code": " 0} def calculate_tag_count(self, tag): \"\"\" :param tag: the tag you do the counting for :type tag::class:`tcms.management.models.Tag` :return: the number of times a tag is assigned to object :rtype: int", "label": 0}, {"snippet_id": 82826, "code": ".info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: ", "label": 0}, {"snippet_id": 16021, "code": "://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data", "label": 0}, {"snippet_id": 67269, "code": "(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" %", "label": 0}, {"snippet_id": 47432, "code": " the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self", "label": 0}, {"snippet_id": 93826, "code": "']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window,", "label": 0}, {"snippet_id": 20629, "code": " self._owned=owned self._handlers=[] for handler in handlers: if callable(handler): self._add_handler(handler) else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread(", "label": 0}, {"snippet_id": 16578, "code": "': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave", "label": 0}, {"snippet_id": 89993, "code": " _parse_java_version('java.version', self._get_system_properties(java)['java.version']) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open(os.path.join", "label": 0}, {"snippet_id": 35358, "code": " try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\"", "label": 0}, {"snippet_id": 46128, "code": " filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0]", "label": 0}, {"snippet_id": 68487, "code": " len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(", "label": 0}, {"snippet_id": 81450, "code": "\t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t", "label": 0}, {"snippet_id": 56769, "code": ") def run(self): return 'run/get_tag.html', TestRun.objects.get(pk=self.object_pk) class _TagActions(object): \"\"\" Used for performing the 'add' and 'remove' actions on a given tag \"\"\" def __init__(self", "label": 0}, {"snippet_id": 66011, "code": "\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1", "label": 0}, {"snippet_id": 68115, "code": ".iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset()", "label": 0}, {"snippet_id": 91330, "code": ".goal.task_registrar import TaskRegistrar as task def build_file_aliases(): return BuildFileAliases( targets={ PythonApp.alias(): PythonApp, PythonBinary.alias(): PythonBinary, PythonLibrary.alias(): PythonLibrary", "label": 0}, {"snippet_id": 997, "code": ":')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username", "label": 0}, {"snippet_id": 13149, "code": ".get(url, headers=headers, auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json", "label": 0}, {"snippet_id": 40697, "code": "(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function", "label": 0}, {"snippet_id": 45241, "code": ".join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self):", "label": 0}, {"snippet_id": 61214, "code": ".linalg.norm(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]", "label": 0}, {"snippet_id": 43547, "code": ") def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i", "label": 0}, {"snippet_id": 53322, "code": " self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule", "label": 0}, {"snippet_id": 42001, "code": " corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict(", "label": 0}, {"snippet_id": 28005, "code": "'rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status", "label": 0}, {"snippet_id": 32596, "code": " matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict()", "label": 0}, {"snippet_id": 58619, "code": ") cls.permission='testplans.change_testplan' cls.update_url=reverse('ajax-update') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): self", "label": 0}, {"snippet_id": 22684, "code": " username that you want to add to the system :param expiration: The expiration date to use. We do not use this value. \"\"\" if self.get_userentry(username): logger.info(\"User{0} already exists, skip useradd\"", "label": 0}, {"snippet_id": 78047, "code": "(urls): if domain not in forums: forums[domain]=set() if len(forum) > 0: get_forum_id(forum) logger.info('Appending %s:%s to forums[%s]', user, forum, domain) forums[domain].add((user, forum)) def rffu", "label": 0}, {"snippet_id": 85346, "code": " pants.backend.jvm.targets.scala_jar_dependency import ScalaJarDependency from pants.backend.jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil", "label": 0}, {"snippet_id": 91061, "code": " for name, paths in sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to \"{}\"; combining results.'.format(rename)) normalized[rename", "label": 0}, {"snippet_id": 82733, "code": "+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update", "label": 0}, {"snippet_id": 70363, "code": "'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug", "label": 0}, {"snippet_id": 67977, "code": "(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node", "label": 0}, {"snippet_id": 55961, "code": "): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def", "label": 0}, {"snippet_id": 83359, "code": "{} if compute_environment: unstructured_path_rewrites=compute_environment.unstructured_path_rewrites client_job_description=ClientJobDescription( command_line=command_line, input_files=self.get_input_files", "label": 0}, {"snippet_id": 7458, "code": "=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results", "label": 0}, {"snippet_id": 44572, "code": " provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict", "label": 0}, {"snippet_id": 47795, "code": " self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno", "label": 0}, {"snippet_id": 75691, "code": ".wz_poll_timeout=30 def __sinit__(self): '''Initializes thread-local interface on startup''' self.log=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker=Ticker() self.poller=zmq.Poller() s", "label": 1}, {"snippet_id": 92109, "code": "\"\"\"\\ Pants doesn't currently support cross-compiling native code. The following targets set platforms arguments other than['current'], which is unsupported for this reason. Please either remove the platforms", "label": 0}, {"snippet_id": 35518, "code": " A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False", "label": 0}, {"snippet_id": 76508, "code": ") self.running.set() self.unbind_methods() self.running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def", "label": 0}, {"snippet_id": 16214, "code": " signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'", "label": 0}, {"snippet_id": 11348, "code": ".source=url if debug_enabled: set_log_level_to_debug() if not self.target_dir or not os.path.isdir(self.target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG", "label": 0}, {"snippet_id": 74623, "code": " object representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation", "label": 0}, {"snippet_id": 53667, "code": "=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output:", "label": 0}, {"snippet_id": 61558, "code": ": operation/observable. Returns: array: matrix representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)) if not callable(operator_map", "label": 0}, {"snippet_id": 9574, "code": " would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s", "label": 0}, {"snippet_id": 84862, "code": " @classmethod def _create_compiler_jardep(cls, version): return cls._create_jardep('scala-compiler', version) @classmethod def _key_for_tool_version(cls, tool, version): if version=='custom': return tool", "label": 1}, {"snippet_id": 69466, "code": " def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available", "label": 0}, {"snippet_id": 85935, "code": ".source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): \"\"\"Compile Java code using Javac.\"", "label": 0}, {"snippet_id": 1187, "code": " from rest_framework import viewsets from rest_framework.decorators import list_route from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer", "label": 0}, {"snippet_id": 41171, "code": " def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError:", "label": 0}, {"snippet_id": 76493, "code": " self.log.warn(e) except Exception as e: self.log.exception(e) self.log.info('Terminating') else: self.log.info('Aborted') self.running.set() self.unbind_methods() self.running.clear() self.wz_sock.close", "label": 0}, {"snippet_id": 47120, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return", "label": 1}, {"snippet_id": 89309, "code": " logging import os import pkgutil import plistlib from abc import abstractproperty from builtins import object, open, str from collections import namedtuple from contextlib import contextmanager from future", "label": 1}, {"snippet_id": 45842, "code": " same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard", "label": 0}, {"snippet_id": 29396, "code": ", fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self", "label": 1}, {"snippet_id": 19439, "code": "-host HOST] --port PORT FILENAME[arg...] \"\"\" def parse_args(argv=None): \"\"\"Return the parsed args to use in main().\"\"\" if argv is None: argv=sys.argv prog=argv[0] if prog==__file__: prog='{} -m ptvsd'.format", "label": 0}, {"snippet_id": 43437, "code": " requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l", "label": 0}, {"snippet_id": 77274, "code": ") except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self, wclass, count, args=(), kvargs={}): wname=str(wclass.__name__) self.log.info('Starting %s", "label": 0}, {"snippet_id": 56321, "code": " parameters[str(key)]=value return parameters @require_GET def info(request): \"\"\"Ajax responder for misc information\"\"\" objects=_InfoObjects(request=request, product_id=request.GET.get('product_id')) info_type", "label": 1}, {"snippet_id": 27114, "code": " logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE", "label": 1}, {"snippet_id": 27973, "code": "'GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 83799, "code": ") return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log", "label": 0}, {"snippet_id": 94052, "code": " color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\"", "label": 0}, {"snippet_id": 42522, "code": ".output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed", "label": 0}, {"snippet_id": 20534, "code": " req): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed write=send_as_write(self._sock) body=json.dumps(req) write_message(write, body, stop=stop) def _close(self)", "label": 0}, {"snippet_id": 41655, "code": " try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 2141, "code": "': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker']", "label": 0}, {"snippet_id": 71177, "code": " status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state", "label": 0}, {"snippet_id": 41547, "code": " if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o", "label": 0}, {"snippet_id": 76169, "code": ".name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self", "label": 0}, {"snippet_id": 56606, "code": " tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_plans=Count('tag')).order_by(", "label": 0}, {"snippet_id": 2612, "code": " in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '%s'!\" %(dep, node.comp_name)", "label": 0}, {"snippet_id": 15900, "code": " BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data,", "label": 0}, {"snippet_id": 87396, "code": " def relative_to_exec_root(path): return fast_relpath(path, get_buildroot()) scala_path=self.scalac_classpath() compiler_interface=self._zinc.compiler_interface compiler_bridge=self._zinc.compiler_bridge", "label": 1}, {"snippet_id": 7781, "code": " skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes", "label": 0}, {"snippet_id": 57486, "code": "=check_permission(self.request, self.ctype) if not has_perms: return say_no(\"You don't have enough permission to update TestCases.\") action=self.get_update_action() if action is not None: try: resp=action() self", "label": 0}, {"snippet_id": 10453, "code": " < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log", "label": 0}, {"snippet_id": 93884, "code": "(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname", "label": 1}, {"snippet_id": 44088, "code": ".first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets", "label": 0}, {"snippet_id": 27641, "code": " Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=", "label": 0}, {"snippet_id": 4198, "code": " output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache", "label": 0}, {"snippet_id": 54293, "code": " Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self", "label": 0}, {"snippet_id": 60780, "code": " return new_object class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an illegal operation in the quantum circuit. \"\"\" pass class Device(abc.ABC): \"\"\"Abstract base", "label": 0}, {"snippet_id": 67516, "code": " Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre", "label": 0}, {"snippet_id": 73084, "code": "=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"", "label": 0}, {"snippet_id": 75121, "code": ".e_req_denied: self.p.log.warn('Keepalive status{0}, reauthentificating and rebinding'. format(wzrpc.name_status(status))) self.p.auth_requests() self.p.bind_methods() elif status==wzrpc.status.e_timeout", "label": 0}, {"snippet_id": 30001, "code": "() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path", "label": 0}, {"snippet_id": 7338, "code": ">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output", "label": 0}, {"snippet_id": 73971, "code": "==\"auto\": self.alt_number=None elif isint(alt_number_str): self.alt_number=int(alt_number_str) else: raise TypeError(\"Invalid value provided for alt_number in configuration.\\n\" \"Expected: \\\"auto\\\" or integer", "label": 0}, {"snippet_id": 82869, "code": " open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates", "label": 0}, {"snippet_id": 52868, "code": ".resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \"", "label": 0}, {"snippet_id": 2492, "code": " name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml", "label": 0}, {"snippet_id": 86113, "code": " target.processors) def _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip()", "label": 0}, {"snippet_id": 67243, "code": "%(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s:", "label": 1}, {"snippet_id": 17236, "code": " console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self", "label": 0}, {"snippet_id": 73498, "code": ":type conversion_config: config.VCFtoZarrConfigurationRepresentation \"\"\" if conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr", "label": 0}, {"snippet_id": 44115, "code": " filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles)", "label": 0}, {"snippet_id": 53237, "code": " elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles", "label": 0}, {"snippet_id": 44824, "code": "(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo):", "label": 0}, {"snippet_id": 38852, "code": " the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can", "label": 0}, {"snippet_id": 38770, "code": " force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or", "label": 0}, {"snippet_id": 18204, "code": "='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + ", "label": 0}, {"snippet_id": 93562, "code": "'localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else:", "label": 0}, {"snippet_id": 23499, "code": " shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user(username): raise OSUtilError((\"User{0", "label": 0}, {"snippet_id": 92366, "code": ".assertNotIn('USER', os.environ) def test_hermetic_environment_subprocesses(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**dict(AAA='333')): output=subprocess.check_output('env'", "label": 1}, {"snippet_id": 74224, "code": " benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"] if", "label": 1}, {"snippet_id": 79676, "code": "\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar", "label": 0}, {"snippet_id": 17540, "code": "): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data", "label": 0}, {"snippet_id": 38625, "code": " updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self", "label": 0}, {"snippet_id": 81457, "code": "=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0", "label": 0}, {"snippet_id": 7576, "code": ": int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format", "label": 0}, {"snippet_id": 84298, "code": "), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home", "label": 0}, {"snippet_id": 51447, "code": " def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return", "label": 0}, {"snippet_id": 71888, "code": " assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes)", "label": 0}, {"snippet_id": 68584, "code": " AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"", "label": 0}, {"snippet_id": 62395, "code": ".deallocate_qubit(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. ", "label": 0}, {"snippet_id": 64343, "code": " self.working_directory() def sep( self): return self._sep def version_path( self): return self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites", "label": 0}, {"snippet_id": 50693, "code": ".workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths]", "label": 0}, {"snippet_id": 74363, "code": "'1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data", "label": 0}, {"snippet_id": 86731, "code": "\"\"\" zinc_args=[ '-C-source', '-C{}'.format(settings.source_level), '-C-target', '-C{}'.format(settings.target_level), ] if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings", "label": 0}, {"snippet_id": 19982, "code": "'debug client closed') if self._session is None: raise RuntimeError('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError", "label": 0}, {"snippet_id": 79506, "code": "\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)", "label": 1}, {"snippet_id": 42967, "code": " have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name,", "label": 0}, {"snippet_id": 14089, "code": ".json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy", "label": 0}, {"snippet_id": 12058, "code": "\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return a list of file names modified/added in the PR \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]}", "label": 0}, {"snippet_id": 52372, "code": "(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^", "label": 0}, {"snippet_id": 61799, "code": "[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye", "label": 0}, {"snippet_id": 54199, "code": " producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement", "label": 0}, {"snippet_id": 83516, "code": "], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy", "label": 1}, {"snippet_id": 60488, "code": ", Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CoherentState': Coherent, 'DisplacedSqueezed': DisplacedSqueezed", "label": 0}, {"snippet_id": 58575, "code": "'response': 'ok'}) case_run_ct=ContentType.objects.get_for_model(TestCaseRun) for case_run_pk in(self.case_run_1.pk, self.case_run_2.pk): comments=Comment.objects.filter(object_pk=case_run_pk, content_type", "label": 0}, {"snippet_id": 32798, "code": " \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser", "label": 0}, {"snippet_id": 83683, "code": " files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager", "label": 0}, {"snippet_id": 35157, "code": ", flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file", "label": 1}, {"snippet_id": 19568, "code": "+=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in", "label": 0}, {"snippet_id": 53568, "code": " output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not", "label": 0}, {"snippet_id": 26926, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] ", "label": 0}, {"snippet_id": 60270, "code": " qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock'", "label": 0}, {"snippet_id": 81907, "code": " files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45", "label": 0}, {"snippet_id": 10901, "code": " MonitoringConfigGeneratorException, HostUnreachableException from monitoring_config_generator.yaml_tools.merger import merge_yaml_files def is_file(parsed_uri): return parsed_uri.scheme in['', 'file'] def is_host(parsed_uri): return", "label": 0}, {"snippet_id": 68019, "code": ".dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s", "label": 0}, {"snippet_id": 78457, "code": " get_targets(self): found_count=0 for user, forum in self.forums: targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp", "label": 0}, {"snippet_id": 80598, "code": "\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and", "label": 0}, {"snippet_id": 93449, "code": "'master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res: if node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree", "label": 0}, {"snippet_id": 65860, "code": "(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append", "label": 0}, {"snippet_id": 32032, "code": ") if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 71879, "code": " ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug", "label": 0}, {"snippet_id": 35840, "code": ": import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except", "label": 0}, {"snippet_id": 78628, "code": ": 'differ', 'dbexec': 'executer', 'dbexport': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try", "label": 0}, {"snippet_id": 7588, "code": ">Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches,", "label": 0}, {"snippet_id": 35768, "code": " plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return ", "label": 0}, {"snippet_id": 58737, "code": ".update_url=reverse('ajax-update_case_run_status') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self", "label": 0}, {"snippet_id": 76881, "code": "(signal, frame): pass def terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler) signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net", "label": 0}, {"snippet_id": 29761, "code": " return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually", "label": 0}, {"snippet_id": 58116, "code": "): \"\"\" Get Component, Version, Category, and Build\\n Return[(id, name),(id, name)] \"\"\" ctypes={ 'component':(Component, 'name'), 'version':(Version, 'value'), 'build':(Build, 'name'), 'category':(Category", "label": 0}, {"snippet_id": 71280, "code": ") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [", "label": 0}, {"snippet_id": 78719, "code": " log.log_error(e) def executer(self, *args): \"\"\"Execute remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]", "label": 1}, {"snippet_id": 80827, "code": " in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed", "label": 1}, {"snippet_id": 19564, "code": ":-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported", "label": 0}, {"snippet_id": 91207, "code": " from pants.backend.python.targets.unpacked_whls import UnpackedWheels from pants.backend.python.tasks.build_local_python_distributions import \\ BuildLocalPythonDistributions from pants.backend.python.tasks", "label": 0}, {"snippet_id": 78268, "code": "+=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment,(t, msg)) except(exc.Closed, exc.UserDeny) as e: try: self", "label": 0}, {"snippet_id": 3968, "code": ".add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch to kill mode\", action=\"store_true\") remote_mutex.add_argument('-c', '--check', help=\"Run a component check\"", "label": 0}, {"snippet_id": 25010, "code": " elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data", "label": 0}, {"snippet_id": 92530, "code": "(self): with temporary_file() as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the context.') self.assertTrue(os.path.exists(fp.name)==False, 'Temporary file should not", "label": 0}, {"snippet_id": 87896, "code": ": return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret=[] for name, cp_entries in plugin_jar_map.items(): ret.append('-S-Xplugin:{}'.format(':'.join(cp_entries", "label": 0}, {"snippet_id": 65168, "code": " target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc", "label": 0}, {"snippet_id": 12843, "code": "\"--ignore \" +to_ignore for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format(data[\"repository\"], data[\"sha\"], file) r=requests.get(url, headers=headers", "label": 0}, {"snippet_id": 38292, "code": "(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath", "label": 0}, {"snippet_id": 53637, "code": " output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if", "label": 0}, {"snippet_id": 38691, "code": "(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards", "label": 0}, {"snippet_id": 10436, "code": " abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field", "label": 0}, {"snippet_id": 85078, "code": "') register_scala_repl_tool('2.12') register_style_tool('2.12') def register_custom_tool(key): dummy_jardep=JarDependency('missing spec', ' //:{}'.format(key)) cls.register_jvm_tool(register, cls._key_for_tool_version", "label": 1}, {"snippet_id": 12863, "code": " auth=auth) with open(\"file_to_fix.py\", 'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc", "label": 0}, {"snippet_id": 40492, "code": ".group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing", "label": 0}, {"snippet_id": 93944, "code": " /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host", "label": 0}, {"snippet_id": 59795, "code": ", observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator", "label": 0}, {"snippet_id": 71351, "code": "(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT", "label": 0}, {"snippet_id": 63290, "code": "=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and LWR client for this job. \"\"\" command_line=None client=None remote_job_config=None", "label": 0}, {"snippet_id": 47750, "code": " InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name", "label": 0}, {"snippet_id": 85411, "code": "' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope='zinc' @classmethod def subsystem_dependencies(cls): return super(Zinc.Factory, cls).subsystem_dependencies", "label": 0}, {"snippet_id": 90208, "code": " from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable. :returns: The java distribution location. \"", "label": 0}, {"snippet_id": 88651, "code": ".run_tracker.pantsd_stats.set_scheduler_metrics(self._scheduler.metrics()) self._set_affected_target_count_in_runtracker() def _set_target_root_count_in_runtracker(self): \"\"\"Sets the target root count in", "label": 0}, {"snippet_id": 61273, "code": " arbitary Hermitian observable. Args: args(array): square hermitian matrix. Returns: array: square hermitian matrix. \"\"\" A=np.asarray(args[0]) if A.shape[0] !=A.shape[1]: raise ValueError(\"Observable must", "label": 0}, {"snippet_id": 39031, "code": "(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes", "label": 0}, {"snippet_id": 54566, "code": "._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None", "label": 0}, {"snippet_id": 81263, "code": ".NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: ", "label": 1}, {"snippet_id": 14371, "code": "._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost", "label": 0}, {"snippet_id": 71059, "code": " status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count", "label": 0}, {"snippet_id": 2196, "code": " if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers", "label": 0}, {"snippet_id": 24582, "code": "=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp", "label": 0}, {"snippet_id": 34076, "code": " raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources", "label": 0}, {"snippet_id": 42315, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError,", "label": 0}, {"snippet_id": 1359, "code": "\"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap)", "label": 0}, {"snippet_id": 33295, "code": "))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 34262, "code": " decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources", "label": 0}, {"snippet_id": 58684, "code": " self.client.login( username=self.tester.username, password='password') post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False', 'value_type':", "label": 0}, {"snippet_id": 73912, "code": "\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): \"\"\" Creates an object representation of VCF to Zarr Conversion", "label": 0}, {"snippet_id": 89623, "code": " return self._is_jdk @property def system_properties(self): \"\"\"Returns a dict containing the system properties of this java distribution.\"\"\" return dict(self._get_system_properties(self.java)) @property", "label": 0}, {"snippet_id": 60363, "code": ".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation", "label": 0}, {"snippet_id": 72566, "code": ") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\", metavar", "label": 1}, {"snippet_id": 74540, "code": "=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[", "label": 0}, {"snippet_id": 5919, "code": " to extract the fulltext from local or remote documents. Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file", "label": 0}, {"snippet_id": 29753, "code": " isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected", "label": 1}, {"snippet_id": 75743, "code": "(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) self.wz_sock=s self.wz=WZHandler() def term_handler(interface, method, data): self.log.info( 'Termination signal %s recieved'", "label": 1}, {"snippet_id": 59819, "code": "=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg] variance=[1 -e**2 for e in", "label": 0}, {"snippet_id": 69919, "code": "-fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc", "label": 1}, {"snippet_id": 61067, "code": "[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0]]) SWAP=np.array([[1, 0, 0, 0],[0, 0, 1, 0],[0, 1, 0, 0],[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle", "label": 0}, {"snippet_id": 53639, "code": " --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies", "label": 0}, {"snippet_id": 79629, "code": "\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the", "label": 0}, {"snippet_id": 76526, "code": " threading.Thread): def start(self, ctx, sig_addr, *args, **kvargs): self.ctx=ctx self.sig_addr=sig_addr threading.Thread.start(self, *args, **kvargs) class WZWorkerProcess(WZWorkerBase, multiprocessing", "label": 0}, {"snippet_id": 74888, "code": " Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None:", "label": 0}, {"snippet_id": 75528, "code": " reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method", "label": 0}, {"snippet_id": 9204, "code": "] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext", "label": 0}, {"snippet_id": 70885, "code": " AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,", "label": 0}, {"snippet_id": 28408, "code": " __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name", "label": 0}, {"snippet_id": 71782, "code": ", cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException", "label": 0}, {"snippet_id": 17882, "code": " Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler", "label": 0}, {"snippet_id": 86777, "code": ".' .format(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings.args) zinc_args.extend(settings_args) return zinc_args @classmethod def implementation_version", "label": 0}, {"snippet_id": 41872, "code": ".add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self)", "label": 0}, {"snippet_id": 91180, "code": ".backend.python.targets.python_distribution import PythonDistribution from pants.backend.python.targets.python_library import PythonLibrary from pants.backend.python.targets.python_requirement_library import", "label": 0}, {"snippet_id": 77796, "code": ":])) self.th_sock.send_multipart(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self.log=parent.log self.inter_sleep=parent.inter_sleep self.running=parent.running self", "label": 0}, {"snippet_id": 42981, "code": "*kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str", "label": 0}, {"snippet_id": 58286, "code": " user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories import EnvGroupFactory from tcms.tests.factories import EnvGroupPropertyMapFactory from tcms.tests.factories import", "label": 0}, {"snippet_id": 21298, "code": "/www.youtube.com/watch?v=' +videolabel) return new_links, links if __name__=='__main__': parser=ap.ArgumentParser(usage='%(prog)s[options] <subreddit>[--[mpv-arguments]]', description='Play the youtube", "label": 0}, {"snippet_id": 65050, "code": " target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type.upper()", "label": 0}, {"snippet_id": 78648, "code": " def __init__(self, options=None): self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run())) except BaseException as e: log.logger.exception(e) return -1 return 0 def execute", "label": 0}, {"snippet_id": 67820, "code": "=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type)", "label": 0}, {"snippet_id": 53470, "code": " wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property", "label": 0}, {"snippet_id": 64975, "code": " import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from", "label": 0}, {"snippet_id": 68511, "code": " % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted >", "label": 0}, {"snippet_id": 15122, "code": " return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format", "label": 0}, {"snippet_id": 14199, "code": " EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']=", "label": 0}, {"snippet_id": 89448, "code": " TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception): ", "label": 0}, {"snippet_id": 68437, "code": "%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online))", "label": 0}, {"snippet_id": 87969, "code": " regular classpath, so we have to provide these entries separately, in the -Xplugin: flag). Note that we don't currently support external plugins with dependencies, as we can't know which external classpath", "label": 0}, {"snippet_id": 77700, "code": " with open(self.bumplimitfile, 'rb') as f: self.pc.sets['bumplimit'].update(pickle.loads(f.read())) def save_targets(self): data={ 'targets': targets, 'forums': forums, 'domains': domains, 'sets': self.pc", "label": 0}, {"snippet_id": 73875, "code": ", \"blosclz\", \"lz4\", \"lz4hc\", \"zlib\", \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility", "label": 0}, {"snippet_id": 64634, "code": " Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base", "label": 0}, {"snippet_id": 68194, "code": ".status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets", "label": 1}, {"snippet_id": 19082, "code": ". \"\"\" schema=schema_validator(raw_schema, **kwargs) if target is not None: validate_object(target, schema=schema, **kwargs) def validate_api_request(schema, raw_request): request=normalize_request(raw_request", "label": 0}, {"snippet_id": 58962, "code": " in(self.case_1.pk, self.case_3.pk): self.assertEqual('P3', TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view method\"\"\" @classmethod def setUpTestData", "label": 0}, {"snippet_id": 12418, "code": "\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link\"])) for issue in issues: error_string=issue.replace(file +\"", "label": 0}, {"snippet_id": 19743, "code": "') filename=ns.pop('filename') if module is None: args.name=filename args.kind='script' else: args.name=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs", "label": 0}, {"snippet_id": 23991, "code": " dev.storvsc | grep pnpinfo | grep deviceid={0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk -F. '{print $3}'\" err, output", "label": 0}, {"snippet_id": 59812, "code": "(str(observable)[-1]+'0'), self.reg) variance=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for", "label": 0}, {"snippet_id": 24047, "code": "'{{print $2}}'|sed -e 's/.*(//'| sed -e 's/).*//'\".format(output) err, output=shellutil.run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith(", "label": 0}, {"snippet_id": 36575, "code": ". \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))", "label": 0}, {"snippet_id": 91010, "code": " advanced=True, help='Minimum version of the JVM pants will use') register('--maximum-version', advanced=True, help='Maximum version of the JVM pants will use') def all_jdk_paths(self): \"\"\"Get all explicitly", "label": 0}, {"snippet_id": 29172, "code": "=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else", "label": 0}, {"snippet_id": 15491, "code": " extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments", "label": 0}, {"snippet_id": 81701, "code": "\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms", "label": 0}, {"snippet_id": 5683, "code": "(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not", "label": 0}, {"snippet_id": 154, "code": " entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn", "label": 1}, {"snippet_id": 26876, "code": "'GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'", "label": 0}, {"snippet_id": 61134, "code": "-1j * theta/2 * Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm", "label": 0}, {"snippet_id": 3731, "code": ".debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for p in r", "label": 0}, {"snippet_id": 37696, "code": "=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f", "label": 0}, {"snippet_id": 35032, "code": "\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 35688, "code": ", getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self", "label": 0}, {"snippet_id": 31404, "code": " always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \",", "label": 0}, {"snippet_id": 40717, "code": " arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1", "label": 0}, {"snippet_id": 32043, "code": " self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic", "label": 0}, {"snippet_id": 20759, "code": ") result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event handlername='event{!r}'.format(event) with self._wait_for_message(match, handlername, **kwargs): yield", "label": 0}, {"snippet_id": 85687, "code": ") ), buildroot, ), ))[0] @memoized_property def rebase_map_args(self): \"\"\"We rebase known stable paths in zinc analysis to make it portable across machines.\"\"\" rebases={ self.dist.real_home: '/dev/null", "label": 0}, {"snippet_id": 45106, "code": "): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self", "label": 0}, {"snippet_id": 63056, "code": " url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try", "label": 0}, {"snippet_id": 88419, "code": " console_outstream=None, scm=None, workspace=None, invalidation_report=None, scheduler=None): self._options=options self.build_graph=build_graph self.build_file_parser=build_file_parser self.address_mapper", "label": 0}, {"snippet_id": 1005, "code": " JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get", "label": 0}, {"snippet_id": 75792, "code": ".set_sig_handler(b'WZWorker', b'resume', term_handler) self.running.set() def wz_connect(self): self.wz_sock.connect(self.wz_addr) def wz_wait_reply(self, fun, interface, method, data, reqid=None, timeout", "label": 1}, {"snippet_id": 67616, "code": "\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr", "label": 0}, {"snippet_id": 39921, "code": " 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable", "label": 0}, {"snippet_id": 57553, "code": ".objects.filter(pk__in=case_ids) return self._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none(self.request, pk_enough) except Http404: return None def _sendmail", "label": 0}, {"snippet_id": 81248, "code": " possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd", "label": 0}, {"snippet_id": 81365, "code": "\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text", "label": 0}, {"snippet_id": 92594, "code": " with temporary_file(root_dir=path) as f: self.assertTrue(os.path.realpath(f.name).startswith(os.path.realpath(path)), 'file should be created in root_dir if specified.') def test_temporary_dir_no_args", "label": 0}, {"snippet_id": 10335, "code": " length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return", "label": 0}, {"snippet_id": 3663, "code": " check_available and run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient pid amount", "label": 0}, {"snippet_id": 11562, "code": " for key in sorted_keys: value=section_data[key] self.icinga_lines.append((\"%s%-45s%s\" %(self.indent, key, self.value_to_icinga(value)))) self.write_line(\"}\") @staticmethod def value_to_icinga(value): \"\"", "label": 1}, {"snippet_id": 64285, "code": ".remote_output_path_rewrite( wrapper_path) results.append( self._dataset_path( local_output_path, remote_path)) return results def input_paths( self): local_input_paths=self._wrapper_input_paths results=[]", "label": 0}, {"snippet_id": 27665, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'", "label": 0}, {"snippet_id": 19053, "code": ") return parse(raw_schema) def validate(raw_schema, target=None, **kwargs): \"\"\" Given the python representation of a JSONschema as defined in the swagger spec, validate that the schema complies to spec", "label": 0}, {"snippet_id": 38137, "code": " rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp", "label": 0}, {"snippet_id": 19888, "code": " self._detach() try: self._adapter.close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is", "label": 0}, {"snippet_id": 53859, "code": " raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs", "label": 0}, {"snippet_id": 77030, "code": ") w.stoponclose=c.stop_on_closed w.die_on_neterror=c.die_on_neterror w.caprate_minp=c.caprate_minp w.caprate_limit=c.caprate_limit w.conlimit=c.conlimit w.comment_successtimeout=0.2 if c.upload_avatar:", "label": 0}, {"snippet_id": 79993, "code": ",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon", "label": 0}, {"snippet_id": 26394, "code": " _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"", "label": 0}, {"snippet_id": 1131, "code": ":userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request", "label": 0}, {"snippet_id": 39932, "code": " import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake", "label": 1}, {"snippet_id": 7243, "code": ".CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords ", "label": 0}, {"snippet_id": 13589, "code": ", 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText", "label": 0}, {"snippet_id": 54323, "code": "(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name", "label": 0}, {"snippet_id": 54119, "code": ".output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f,", "label": 0}, {"snippet_id": 38345, "code": "._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values", "label": 0}, {"snippet_id": 18162, "code": " import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import", "label": 0}, {"snippet_id": 93001, "code": "(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self)", "label": 0}, {"snippet_id": 55792, "code": ".message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__", "label": 0}, {"snippet_id": 18447, "code": ") self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled", "label": 0}, {"snippet_id": 17709, "code": ":{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def", "label": 0}, {"snippet_id": 7732, "code": ")) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires", "label": 0}, {"snippet_id": 62089, "code": " the end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to", "label": 0}, {"snippet_id": 29018, "code": " if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class", "label": 0}, {"snippet_id": 45941, "code": " return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value,", "label": 0}, {"snippet_id": 18377, "code": ".server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed(", "label": 0}, {"snippet_id": 26901, "code": " elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" ", "label": 0}, {"snippet_id": 93277, "code": ".session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self.logger.info('starting new", "label": 0}, {"snippet_id": 2350, "code": " import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname", "label": 0}, {"snippet_id": 19217, "code": " def test_native_mapping_is_passthrough(): source={'foo': 'bar'} result=load_source(source) assert result==source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source", "label": 1}, {"snippet_id": 13637, "code": " os.system( \"espeak \\\",...\\\" 2>/dev/null\") time.sleep( 0.5)\r os.system( \"espeak -w speech.wav \\\"\" +myText +\"\\\" -s 130\")\r audio.play(\"speech.wav\")\r return myText\r \r mouthThread=Thread(target=updateMouth)\r", "label": 1}, {"snippet_id": 18660, "code": "=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str", "label": 0}, {"snippet_id": 45821, "code": "(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name ", "label": 0}, {"snippet_id": 32200, "code": ".params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs)", "label": 0}, {"snippet_id": 20130, "code": "\"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session", "label": 0}, {"snippet_id": 82105, "code": " common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=", "label": 0}, {"snippet_id": 79969, "code": " exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose", "label": 0}, {"snippet_id": 46738, "code": " PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat", "label": 0}, {"snippet_id": 92077, "code": " platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys()) if not platform_names or platform_names==['current']: return True bad_targets", "label": 0}, {"snippet_id": 10963, "code": " mtime=mtime) def read_config_from_host(url): try: response=requests.get(url) except socket.error as e: msg=\"Could not open socket for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except", "label": 0}, {"snippet_id": 25914, "code": " data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" %", "label": 0}, {"snippet_id": 94558, "code": " in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window", "label": 0}, {"snippet_id": 18903, "code": " Common entry point for loading some form of raw swagger schema. Supports: -python object(dictionary-like) -path to yaml file -path to json file -file object(json or yaml). -json string. -yaml string. ", "label": 0}, {"snippet_id": 18769, "code": "()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ ", "label": 0}, {"snippet_id": 86688, "code": " 1 arg_index=0 while arg_index < len(args): arg_index +=validate(arg_index) @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform settings", "label": 0}, {"snippet_id": 65849, "code": ".state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target", "label": 0}, {"snippet_id": 30552, "code": " import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from", "label": 1}, {"snippet_id": 8780, "code": " else: if isinstance(output, dict): for i in output: print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for", "label": 0}, {"snippet_id": 88350, "code": "(object): \"\"\"A logger facade that logs into the pants reporting framework.\"\"\" def __init__(self, run_tracker): self._run_tracker=run_tracker def debug(self, *msg_elements): self._run_tracker.log(Report", "label": 0}, {"snippet_id": 13410, "code": ".put(url, json=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"", "label": 0}, {"snippet_id": 47161, "code": ".dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def", "label": 0}, {"snippet_id": 77939, "code": "[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Removing %s from targets[%s]', repr(t), domain) tlist.remove(t) def add_target_exc(domain, id_, tuser=None): if domain not in targets", "label": 0}, {"snippet_id": 91018, "code": ") register('--maximum-version', advanced=True, help='Maximum version of the JVM pants will use') def all_jdk_paths(self): \"\"\"Get all explicitly configured JDK paths. :return: mapping of os name -> list", "label": 0}, {"snippet_id": 48490, "code": " item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 2319, "code": ".ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class", "label": 0}, {"snippet_id": 79594, "code": " utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install", "label": 0}, {"snippet_id": 78443, "code": ".sleep(self.errortimeout) except exc.TemporaryError as e: self.log.warn(e) self.w.sleep(self.errortimeout) def get_targets(self): found_count=0 for user, forum in self.forums: targets=[] self.log.debug(", "label": 0}, {"snippet_id": 62699, "code": ": wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to", "label": 0}, {"snippet_id": 58240, "code": " import EnvGroup from tcms.management.models import EnvProperty from tcms.testcases.forms import CaseAutomatedForm from tcms.testcases.forms import TestCase from tcms.testplans.models import TestPlan from", "label": 1}, {"snippet_id": 37897, "code": "(f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if", "label": 0}, {"snippet_id": 24486, "code": " of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement", "label": 0}, {"snippet_id": 55875, "code": "*kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return", "label": 0}, {"snippet_id": 44672, "code": "(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath", "label": 0}, {"snippet_id": 14378, "code": "]: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed(", "label": 0}, {"snippet_id": 22251, "code": "=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template(template, data) ) runner=Runner(playbook=playbook, verbosity", "label": 0}, {"snippet_id": 82028, "code": "\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex", "label": 0}, {"snippet_id": 88589, "code": "(self): \"\"\"Returns the output stream to write console messages to. :API: public \"\"\" return self._console_outstream @property def scm(self): \"\"\"Returns the current workspace's scm, if any. :API: public \"\"\"", "label": 0}, {"snippet_id": 95102, "code": " data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if", "label": 1}, {"snippet_id": 60237, "code": ": Rgate, 'TwoModeSqueezing': S2gate, 'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML. wires(int): the number of modes to initialize", "label": 0}, {"snippet_id": 590, "code": "=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=", "label": 0}, {"snippet_id": 33845, "code": ".urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path", "label": 0}, {"snippet_id": 15380, "code": "._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode", "label": 0}, {"snippet_id": 14546, "code": ".NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded", "label": 0}, {"snippet_id": 89394, "code": ", given:{}'.format(name, version)) return version class Distribution(object): \"\"\"Represents a java distribution -either a JRE or a JDK installed on the local system. In particular provides access to the", "label": 0}, {"snippet_id": 11616, "code": " OutputWriter(object): def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with open(self.output_file, 'w') as f: for line in lines: f.write(line +\"\\n\") LOG.debug", "label": 0}, {"snippet_id": 36237, "code": "\"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 50667, "code": ".workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os", "label": 0}, {"snippet_id": 87275, "code": "._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f: for processor in processors", "label": 0}, {"snippet_id": 28327, "code": " available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name", "label": 1}, {"snippet_id": 59794, "code": " def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value", "label": 0}, {"snippet_id": 34021, "code": " if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params", "label": 0}, {"snippet_id": 3481, "code": "!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file", "label": 0}, {"snippet_id": 68876, "code": ".set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 19798, "code": ".debugsession import DebugSession class _LifecycleClient(Closeable): SESSION=DebugSession def __init__( self, addr=None, port=8888, breakpoints=None, connecttimeout=1.0, ): super(_LifecycleClient, self).__init__", "label": 0}, {"snippet_id": 53336, "code": " def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict", "label": 0}, {"snippet_id": 57610, "code": " exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets().update(**{str(self.target_field): self.new_value}) def _update_default_tester(self):", "label": 0}, {"snippet_id": 7494, "code": " results obtained in text format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result", "label": 0}, {"snippet_id": 95342, "code": " create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config", "label": 0}, {"snippet_id": 39388, "code": ".add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, ", "label": 0}, {"snippet_id": 47885, "code": ".resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno", "label": 0}, {"snippet_id": 27463, "code": " return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class", "label": 0}, {"snippet_id": 78494, "code": ")) for t in found: if(t in self.pc.sets['closed'] or t in self.pc.sets['bumplimit'] or t in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d", "label": 1}, {"snippet_id": 23225, "code": ", buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno(), 0x8912, param) retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned more than{0} up ' 'network", "label": 0}, {"snippet_id": 95759, "code": ".move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf", "label": 0}, {"snippet_id": 10549, "code": "('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file", "label": 0}, {"snippet_id": 45182, "code": "): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads", "label": 0}, {"snippet_id": 95596, "code": " file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file)", "label": 0}, {"snippet_id": 26347, "code": " in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for", "label": 0}, {"snippet_id": 3339, "code": "=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session", "label": 0}, {"snippet_id": 91996, "code": " def _native_target_matchers(self): return{ SubclassesOf(PythonDistribution): self.pydist_has_native_sources, SubclassesOf(NativeLibrary): NativeLibrary.produces_ctypes_native_library, } def _any_targets_have_native_sources", "label": 0}, {"snippet_id": 94226, "code": " load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self", "label": 0}, {"snippet_id": 52661, "code": " missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self", "label": 0}, {"snippet_id": 21600, "code": " y=dataset.iloc[:, 4].values from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=0) from sklearn.preprocessing import", "label": 0}, {"snippet_id": 84694, "code": ".hackily_snapshot(self.context) directory_digest=self.context._scheduler.merge_directories(tuple(s.directory_digest for s in input_snapshots +( cloc_snapshot, list_file_snapshot, ))) cmd=( '/usr/bin/perl', cloc_path", "label": 0}, {"snippet_id": 76853, "code": ".router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b'WZWorker', b'terminate']) for t in threading.enumerate", "label": 0}, {"snippet_id": 54856, "code": "=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict", "label": 0}, {"snippet_id": 44163, "code": " self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules,", "label": 0}, {"snippet_id": 81597, "code": ".text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu", "label": 0}, {"snippet_id": 82580, "code": ".proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print(\"[*] starting at \"+str(now.hour)+\":\"+str(now.minute)", "label": 0}, {"snippet_id": 17258, "code": " user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set(", "label": 0}, {"snippet_id": 10383, "code": "(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir", "label": 0}, {"snippet_id": 92537, "code": ".name), 'Temporary file should exist within the context.') self.assertTrue(os.path.exists(fp.name)==False, 'Temporary file should not exist outside of the context.') def test_temporary_file_without_cleanup", "label": 0}, {"snippet_id": 32204, "code": ") except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item)", "label": 0}, {"snippet_id": 15560, "code": "( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self", "label": 0}, {"snippet_id": 63032, "code": " self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none", "label": 0}, {"snippet_id": 20127, "code": "(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert", "label": 0}, {"snippet_id": 91284, "code": " PythonRepl from pants.backend.python.tasks.python_run import PythonRun from pants.backend.python.tasks.resolve_requirements import ResolveRequirements from pants.backend.python.tasks.select_interpreter import", "label": 0}, {"snippet_id": 85533, "code": ".tool_jar_from_products(products, Zinc.ZINC_COMPILER_TOOL_NAME, cls.options_scope) @classmethod def _compiler_bridge(cls, products): return cls.tool_jar_from_products(products, 'compiler-bridge', cls.options_scope", "label": 0}, {"snippet_id": 37735, "code": ".allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item", "label": 0}, {"snippet_id": 4279, "code": ") elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent", "label": 1}, {"snippet_id": 19935, "code": " client closed') if adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError('already using managed adapter') if adapter is None: raise RuntimeError('debugger not running", "label": 0}, {"snippet_id": 28380, "code": " if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return", "label": 0}, {"snippet_id": 79435, "code": "\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,", "label": 1}, {"snippet_id": 3095, "code": ") res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname", "label": 0}, {"snippet_id": 19981, "code": ".closed: raise RuntimeError('debug client closed') if self._session is None: raise RuntimeError('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not self._session", "label": 0}, {"snippet_id": 40444, "code": "})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 40554, "code": "[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def", "label": 0}, {"snippet_id": 21949, "code": ", private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args=None, poll_interval=None, seconds=None, check=None", "label": 0}, {"snippet_id": 2447, "code": "-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self", "label": 0}, {"snippet_id": 62940, "code": ".lwr_client import build_client_manager from.lwr_client import url_to_destination_params from.lwr_client import finish_job as lwr_finish_job from.lwr_client import submit_job as lwr_submit_job from.lwr_client", "label": 0}, {"snippet_id": 3947, "code": "--kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group", "label": 0}, {"snippet_id": 47735, "code": " snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args", "label": 0}, {"snippet_id": 51167, "code": " files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))", "label": 0}, {"snippet_id": 63297, "code": " LWR client for this job. \"\"\" command_line=None client=None remote_job_config=None compute_environment=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config", "label": 0}, {"snippet_id": 90546, "code": " maximum_version: continue if jdk and not dist.jdk: continue return dist def locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets the given constraints and", "label": 0}, {"snippet_id": 86472, "code": " from pants.backend.jvm.subsystems.zinc import Zinc from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin import JavacPlugin from pants", "label": 0}, {"snippet_id": 34930, "code": "( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names", "label": 0}, {"snippet_id": 10646, "code": " available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file", "label": 0}, {"snippet_id": 54623, "code": " not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix", "label": 0}, {"snippet_id": 32936, "code": " None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules", "label": 0}, {"snippet_id": 35169, "code": " AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError(", "label": 1}, {"snippet_id": 2841, "code": " for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name)", "label": 0}, {"snippet_id": 45909, "code": "] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise", "label": 0}, {"snippet_id": 2157, "code": "=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser',", "label": 0}, {"snippet_id": 18803, "code": " extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join(", "label": 0}, {"snippet_id": 10280, "code": "=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1", "label": 0}, {"snippet_id": 83735, "code": "=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client", "label": 0}, {"snippet_id": 76626, "code": "=[] msg.append('[image-original-none-http://simg4.gelbooru.com/' +'/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]') msg.append('\u041a\u0430\u0436\u0434\u044b\u0439 \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random.randint", "label": 0}, {"snippet_id": 52799, "code": " in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(", "label": 0}, {"snippet_id": 47743, "code": " snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name", "label": 0}, {"snippet_id": 78361, "code": ") except ValueError as e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception(e) self.w.sleep(self.errortimeout) def forumwipe_loop(self): for f in self.forums: self", "label": 1}, {"snippet_id": 23627, "code": " manually to get it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run(\"/etc/rc.d/dhclient start{0}", "label": 0}, {"snippet_id": 50316, "code": " RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update", "label": 0}, {"snippet_id": 58367, "code": ")) self.assertRedirects( response, reverse('tcms-login'), target_status_code=HTTPStatus.OK) def test_when_logged_in_index_page_redirects_to_dashboard(self): self.client.login( username=self.tester.username", "label": 0}, {"snippet_id": 78424, "code": ".long_sleep(10) except exc.UnknownAnswer as e: self.log.warning('%s: %s', e, e.answer) self.w.sleep(self.errortimeout) except exc.PermanentError as e: self.log.error(e) self.w.sleep(self.errortimeout) except exc", "label": 0}, {"snippet_id": 13238, "code": "/\")[-1]==data[\"target_repo_branch\"]: sha=ref[\"object\"][\"sha\"] url=\"https://api.github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data[\"target_repo_branch", "label": 0}, {"snippet_id": 12481, "code": ".replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file", "label": 0}, {"snippet_id": 31593, "code": ".name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params", "label": 0}, {"snippet_id": 9309, "code": ", this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords", "label": 0}, {"snippet_id": 28858, "code": "'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state", "label": 0}, {"snippet_id": 33912, "code": " self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self", "label": 0}, {"snippet_id": 19577, "code": " nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in('--host', '--server-host', '--port', '-m'): if", "label": 0}, {"snippet_id": 36871, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from", "label": 0}, {"snippet_id": 41935, "code": " output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self", "label": 0}, {"snippet_id": 79258, "code": "\t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r)", "label": 0}, {"snippet_id": 77238, "code": ".difference(self.proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try: proxypair=proxypairs.pop() except Exception: return self.proxylist.add(proxypair) for spawn in create_spawn", "label": 0}, {"snippet_id": 35591, "code": "\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the", "label": 0}, {"snippet_id": 36157, "code": "=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property", "label": 0}, {"snippet_id": 18570, "code": "'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync(", "label": 0}, {"snippet_id": 57390, "code": "=ctype, object_pk=object_pk, ) if mail_context: mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=='case_run_status':", "label": 0}, {"snippet_id": 41701, "code": " f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else", "label": 1}, {"snippet_id": 8587, "code": " log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv", "label": 1}, {"snippet_id": 41282, "code": "\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict", "label": 0}, {"snippet_id": 63677, "code": " Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message", "label": 0}, {"snippet_id": 64807, "code": " fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes,", "label": 0}, {"snippet_id": 3335, "code": "\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info", "label": 0}, {"snippet_id": 81171, "code": " and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No", "label": 0}, {"snippet_id": 30753, "code": ".b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize", "label": 0}, {"snippet_id": 71603, "code": ".verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs", "label": 0}, {"snippet_id": 27560, "code": " elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self", "label": 0}, {"snippet_id": 69617, "code": "(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc", "label": 0}, {"snippet_id": 28365, "code": " module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data", "label": 1}, {"snippet_id": 5077, "code": " in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw],", "label": 0}, {"snippet_id": 86040, "code": "*kwargs): super(JavacCompile, self).__init__(*args, **kwargs) self.set_distribution(jdk=True) def select(self, target): if not isinstance(target, JvmTarget): return False return target.has_sources('.java", "label": 0}, {"snippet_id": 93954, "code": " kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'", "label": 0}, {"snippet_id": 54739, "code": " rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set(", "label": 0}, {"snippet_id": 26515, "code": "\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type", "label": 0}, {"snippet_id": 30165, "code": ".get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name,", "label": 0}, {"snippet_id": 92674, "code": " of context if cleanup=False.') shutil.rmtree(path) def test_temporary_dir_with_root_dir(self): with temporary_dir() as path1: with temporary_dir(root_dir=path1) as path2: self.assertTrue(os.path.realpath", "label": 0}, {"snippet_id": 49340, "code": ".docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local", "label": 0}, {"snippet_id": 44717, "code": "(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\")", "label": 0}, {"snippet_id": 85565, "code": "\"\"Create a Zinc instance from products active in the current Pants run. :param products: The active Pants run products to pluck classpaths from. :type products::class:`pants.goal.products.Products` :returns", "label": 0}, {"snippet_id": 49616, "code": " list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence", "label": 0}, {"snippet_id": 13654, "code": ".play(\"speech.wav\")\r return myText\r \r mouthThread=Thread(target=updateMouth)\r mouthThread.start()\r eyesThread=Thread(target=updateEyes)\r eyesThread.start() \r audio=AudioPlayer()\r \r if( consumerKey.find", "label": 0}, {"snippet_id": 53204, "code": ".temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark", "label": 0}, {"snippet_id": 49193, "code": " @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file", "label": 0}, {"snippet_id": 26443, "code": ".type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"", "label": 0}, {"snippet_id": 47993, "code": ".temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch", "label": 0}, {"snippet_id": 85752, "code": " toolname): scope=instance.options_scope return instance.tool_classpath_from_products(self._products, toolname, scope=scope) classpaths=(cp(java_options_src, 'javac-plugin-dep') + cp(scala_options_src, ", "label": 0}, {"snippet_id": 7903, "code": "]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output", "label": 0}, {"snippet_id": 74069, "code": "=blosc_compression_algorithm_temp if \"blosc_compression_level\" in runtime_config.vcf_to_zarr: blosc_compression_level_str=runtime_config.vcf_to_zarr[\"blosc_compression_level\"] if isint(blosc_compression_level_str", "label": 0}, {"snippet_id": 59445, "code": "=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute", "label": 1}, {"snippet_id": 55716, "code": ".\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance", "label": 0}, {"snippet_id": 75576, "code": " reqid) def make_auth_clear_data(self, reqid=None): if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return self.make_req_msg(d[0], d[1]", "label": 0}, {"snippet_id": 15773, "code": ", extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options", "label": 0}, {"snippet_id": 78325, "code": " msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout", "label": 1}, {"snippet_id": 69644, "code": " system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs", "label": 1}, {"snippet_id": 916, "code": ":configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE)", "label": 0}, {"snippet_id": 55253, "code": " True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return", "label": 0}, {"snippet_id": 77294, "code": "%s(s)', wname) if issubclass(wclass, workers.WZWorkerThread): type_=0 if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass", "label": 0}, {"snippet_id": 77931, "code": "), domain) tlist.append(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Removing %s from targets[%s]', repr(t), domain) tlist", "label": 0}, {"snippet_id": 34429, "code": ".basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self", "label": 0}, {"snippet_id": 87382, "code": "(absolute_classpath, ctx.target, ctx.classes_dir) self._verify_zinc_classpath(absolute_classpath, allow_dist=(self.execution_strategy !=self.HERMETIC)) self._verify_zinc_classpath(upstream_analysis.keys()) def", "label": 0}, {"snippet_id": 76698, "code": ".add_argument('--ecount', '-e', type=int, default=0, help='EvaluatorProxy count') parser.add_argument('--upload-avatar', action='store_true', default=False, help='Upload random avatar after registration')", "label": 0}, {"snippet_id": 88536, "code": ".source.source_root.SourceRoots` instance for the current run. :API: public \"\"\" return self._source_roots @property def target_roots(self): \"\"\"Returns the targets specified on the command line. This set", "label": 0}, {"snippet_id": 40391, "code": ": try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 79048, "code": ", code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont", "label": 0}, {"snippet_id": 27962, "code": "%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status", "label": 0}, {"snippet_id": 19309, "code": "'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.flush() with open(tmp_file.name) as yaml_file: result=load_source(yaml_file) assert result==native", "label": 0}, {"snippet_id": 33348, "code": ", priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp", "label": 0}, {"snippet_id": 66439, "code": "%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message)", "label": 1}, {"snippet_id": 32576, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files", "label": 0}, {"snippet_id": 14880, "code": "=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{", "label": 0}, {"snippet_id": 38044, "code": "=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return", "label": 0}, {"snippet_id": 59884, "code": "(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs)", "label": 0}, {"snippet_id": 3989, "code": " check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter", "label": 0}, {"snippet_id": 56953, "code": " get_value_by_type('True', 'bool') (1, None) 2. get_value_by_type('19860624 123059', 'datetime') (datetime.datetime(1986, 6, 24, 12, 30, 59), None) 3. get_value_by_type('5', 'int') ('5', None) 4. get_value_by_type", "label": 0}, {"snippet_id": 78896, "code": "\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as", "label": 0}, {"snippet_id": 19844, "code": " launchcfg): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None raise NotImplementedError def", "label": 0}, {"snippet_id": 9243, "code": ":var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or", "label": 0}, {"snippet_id": 20221, "code": "._connecttimeout) if t.is_alive(): warnings.warn('timed out waiting for connection') if self._session is None: message='unable to connect after{} secs'.format( self._connecttimeout) if self._run_server_ex is None", "label": 0}, {"snippet_id": 15092, "code": " urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy", "label": 1}, {"snippet_id": 57114, "code": " for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field and value.') field=str(field", "label": 0}, {"snippet_id": 92496, "code": " temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(os.path", "label": 0}, {"snippet_id": 45259, "code": "._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return", "label": 0}, {"snippet_id": 21588, "code": " numpy as np import matplotlib.pyplot as plt import pandas as pd dataset=pd.read_csv('Social_Network_Ads.csv') X=dataset.iloc[:,[2, 3]].values y=dataset.iloc[:, 4].values from sklearn.model_selection import", "label": 1}, {"snippet_id": 28711, "code": "\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state", "label": 0}, {"snippet_id": 59757, "code": ".__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial", "label": 0}, {"snippet_id": 76906, "code": " proxytype=='HTTP' or proxytype=='HTTPS': net.proxy_type=sup.proxytype.http elif proxytype=='SOCKS4': net.proxy_type=sup.proxytype.socks4 elif proxytype=='SOCKS5': net.proxy_type=sup.proxytype.socks5 else", "label": 1}, {"snippet_id": 6305, "code": "=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"", "label": 1}, {"snippet_id": 90760, "code": " minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) dist.validate() logger.debug('Located{} for constraints: minimum_version{}, maximum_version{}, jdk{}' .format(dist, minimum_version", "label": 0}, {"snippet_id": 71566, "code": "): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE,", "label": 0}, {"snippet_id": 54367, "code": ".. \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name", "label": 0}, {"snippet_id": 84545, "code": " import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants.base.workunit import WorkUnitLabel from pants.engine.fs import FilesContent, PathGlobs, PathGlobsAndRoot", "label": 0}, {"snippet_id": 39511, "code": ".resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule", "label": 0}, {"snippet_id": 70835, "code": ".sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT", "label": 0}, {"snippet_id": 30978, "code": ".append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing", "label": 0}, {"snippet_id": 17683, "code": " self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at", "label": 0}, {"snippet_id": 92139, "code": "{} \"\"\".format('\\n'.join(sorted(target.address.reference() for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires-pex' @classmethod def register_options", "label": 0}, {"snippet_id": 7010, "code": " composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the", "label": 0}, {"snippet_id": 19691, "code": ".version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None) clienthost=ns.pop('host', None) if serverhost: args.address=Address.as_server(serverhost, ns.pop('port')", "label": 0}, {"snippet_id": 19509, "code": " arg=='-h' or arg=='--help': return argv,[], script gottarget=False skip=0 for i in range(len(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except IndexError: nextarg=None if gottarget", "label": 0}, {"snippet_id": 32644, "code": " values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self", "label": 0}, {"snippet_id": 4985, "code": " keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output", "label": 0}, {"snippet_id": 12902, "code": "=stdout.decode(r.encoding) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/", "label": 0}, {"snippet_id": 36179, "code": " Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): ", "label": 0}, {"snippet_id": 30077, "code": " dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list)", "label": 0}, {"snippet_id": 29112, "code": " product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os", "label": 1}, {"snippet_id": 51909, "code": " for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items()", "label": 0}, {"snippet_id": 36675, "code": " in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule", "label": 0}, {"snippet_id": 19341, "code": "=tempfile.NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_url(httpbin): native={ 'origin': '127.0.0", "label": 0}, {"snippet_id": 40972, "code": " self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items", "label": 0}, {"snippet_id": 23647, "code": "{0}\".format(self.get_if_name()), chk_err=False) def allow_dhcp_broadcast(self): pass def set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255 -iface{0}\".format(ifname", "label": 0}, {"snippet_id": 82184, "code": "(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser.add_argument(\"-T\",\"--threads\",metavar=", "label": 0}, {"snippet_id": 59213, "code": " YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate,", "label": 0}, {"snippet_id": 35148, "code": " value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString", "label": 0}, {"snippet_id": 64228, "code": " self._wrapper_input_paths=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config", "label": 0}, {"snippet_id": 34924, "code": "\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format(", "label": 0}, {"snippet_id": 15433, "code": " not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def", "label": 0}, {"snippet_id": 87758, "code": " classpath, allow_dist=True): def is_outside(path, putative_parent): return os.path.relpath(path, putative_parent).startswith(os.pardir) dist=self._zinc.dist for path in classpath: if not os.path.isabs(path):", "label": 0}, {"snippet_id": 19363, "code": " os.path import sys from ptvsd._local import debug_main, run_main from ptvsd.socket import Address from ptvsd.version import __version__, __author__ \"\"\" For the PyDevd CLI handling see: https://github.com", "label": 0}, {"snippet_id": 68386, "code": " if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online", "label": 0}, {"snippet_id": 67162, "code": " MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f %s' to initialize the file system.\" % \\ fs_conf.get_fs_name() return", "label": 1}, {"snippet_id": 67215, "code": " from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client", "label": 0}, {"snippet_id": 28619, "code": "._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and", "label": 0}, {"snippet_id": 33213, "code": ", keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources", "label": 0}, {"snippet_id": 23638, "code": " True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run(\"/etc/rc.d/dhclient start{0}\".format(self.get_if_name()), chk_err=False) def allow_dhcp_broadcast(self): pass def", "label": 0}, {"snippet_id": 88555, "code": " the command line. This set is strictly a subset of all targets in play for the run as returned by self.targets(). Note that for a command line invocation that uses wildcard selectors: or::, the targets", "label": 0}, {"snippet_id": 61408, "code": "\"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self._state is None: self._state=np.zeros(2**self.wires, dtype=complex) self._state[0]=1 self._out=np.full(self.wires, np", "label": 0}, {"snippet_id": 43288, "code": ".apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items", "label": 0}, {"snippet_id": 38290, "code": ".workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath", "label": 0}, {"snippet_id": 48836, "code": " files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None", "label": 0}, {"snippet_id": 41027, "code": " --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"", "label": 0}, {"snippet_id": 2563, "code": ".copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups", "label": 0}, {"snippet_id": 85948, "code": ".\"\"\" _name='java' @staticmethod def _write_javac_plugin_info(resources_dir, javac_plugin_target): javac_plugin_info_file=os.path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file", "label": 0}, {"snippet_id": 49310, "code": ": raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse", "label": 0}, {"snippet_id": 50621, "code": "=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile", "label": 0}, {"snippet_id": 19421, "code": "-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT -m MODULE[arg...] {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT FILENAME[arg...] \"\"", "label": 0}, {"snippet_id": 40285, "code": "\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)", "label": 0}, {"snippet_id": 14067, "code": "=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status", "label": 0}, {"snippet_id": 22542, "code": "(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example,", "label": 0}, {"snippet_id": 52773, "code": ") if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self", "label": 0}, {"snippet_id": 43737, "code": ".globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self", "label": 0}, {"snippet_id": 85182, "code": " must be specified if using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not specified, then the version specified in ' '--scala-suffix-version", "label": 0}, {"snippet_id": 81188, "code": " self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?", "label": 0}, {"snippet_id": 59431, "code": ".backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__(", "label": 0}, {"snippet_id": 28000, "code": ">=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self", "label": 0}, {"snippet_id": 95922, "code": " a Zarr format. Only converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data", "label": 0}, {"snippet_id": 50883, "code": " return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to", "label": 1}, {"snippet_id": 52909, "code": " resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self", "label": 0}, {"snippet_id": 87457, "code": ".get_options().colors: zinc_args.append('-no-color') zinc_args.extend(['-compiler-interface', compiler_interface]) zinc_args.extend(['-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache", "label": 1}, {"snippet_id": 35012, "code": " ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format", "label": 0}, {"snippet_id": 59496, "code": ".short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self", "label": 0}, {"snippet_id": 53632, "code": "\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input", "label": 0}, {"snippet_id": 93395, "code": "]: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends", "label": 0}, {"snippet_id": 45471, "code": ".getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.", "label": 1}, {"snippet_id": 1934, "code": " datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top'", "label": 0}, {"snippet_id": 24439, "code": "._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name", "label": 0}, {"snippet_id": 16907, "code": " handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 32162, "code": " for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self", "label": 0}, {"snippet_id": 36321, "code": " f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items", "label": 0}, {"snippet_id": 51824, "code": ".append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set", "label": 0}, {"snippet_id": 84010, "code": " in the queued/running state when Galaxy started\"\"\" job_state=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state", "label": 0}, {"snippet_id": 55191, "code": ") if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but", "label": 0}, {"snippet_id": 58084, "code": "(bug_id=bug_id, bug_system_id=bug_system_id, bz_external_track=bz_external_track) else: bugs=Bug.objects.filter(bug_id__in=bug_ids) for run in runs: for bug in bugs: if bug.case_run_id==run.pk: run.remove_bug", "label": 0}, {"snippet_id": 63598, "code": "( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper", "label": 0}, {"snippet_id": 92797, "code": " self.assertTrue(zf._allowZip64) def test_open_zipFalse(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=False) as zf: self.assertFalse(zf._allowZip64)", "label": 0}, {"snippet_id": 66472, "code": ": %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name", "label": 0}, {"snippet_id": 36899, "code": " Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException,", "label": 0}, {"snippet_id": 56146, "code": " accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path", "label": 0}, {"snippet_id": 4313, "code": "=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file.", "label": 1}, {"snippet_id": 40807, "code": " as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern", "label": 0}, {"snippet_id": 33853, "code": "=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\"", "label": 0}, {"snippet_id": 42707, "code": "(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add", "label": 0}, {"snippet_id": 9346, "code": " text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags:", "label": 0}, {"snippet_id": 83177, "code": ", cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self", "label": 0}, {"snippet_id": 31089, "code": " dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following", "label": 0}, {"snippet_id": 88802, "code": "'subproc_map result still not ready...') return res.get() except KeyboardInterrupt: SubprocPool.shutdown(True) raise @contextmanager def new_workunit(self, name, labels=None, cmd='', log_config=None): \"\"\"Create", "label": 0}, {"snippet_id": 84824, "code": "'org.scalastyle', 'scalastyle_2.11', '0.8.0') class ScalaPlatform(JvmToolMixin, ZincLanguageMixin, InjectablesMixin, Subsystem): \"\"\"A scala platform. :API: public \"\"\" options_scope='scala' @classmethod", "label": 0}, {"snippet_id": 58904, "code": "': self.plan.pk, 'case':[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, ", "label": 0}, {"snippet_id": 486, "code": "=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password", "label": 0}, {"snippet_id": 39618, "code": " output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params", "label": 0}, {"snippet_id": 33730, "code": ")) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources", "label": 0}, {"snippet_id": 63331, "code": "=compute_environment job_wrapper.prepare( **prepare_kwds) self.__prepare_input_files_locally(job_wrapper) remote_metadata=LwrJobRunner.__remote_metadata( client) remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy", "label": 0}, {"snippet_id": 28947, "code": "'GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self", "label": 0}, {"snippet_id": 86795, "code": " implementation_version(cls): return super(BaseZincCompile, cls).implementation_version() +[('BaseZincCompile', 7)] @classmethod def get_jvm_options_default(cls, bootstrap_option_values): return('-Dfile", "label": 0}, {"snippet_id": 34428, "code": ".workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os", "label": 0}, {"snippet_id": 29911, "code": "=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str", "label": 0}, {"snippet_id": 49325, "code": " rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set", "label": 0}, {"snippet_id": 76755, "code": "='noproxy_rp timeout') parser.add_argument('--caprate_minp', type=int, default=5, help='Cap rate minimum possible count for limit check') parser.add_argument('--caprate_limit', type=float, default=0.8,", "label": 0}, {"snippet_id": 323, "code": " print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse", "label": 0}, {"snippet_id": 87866, "code": " javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-C-Xplugin:{}{}'.format(plugin, ", "label": 0}, {"snippet_id": 47427, "code": "\"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards", "label": 0}, {"snippet_id": 59434, "code": "'backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' ", "label": 0}, {"snippet_id": 63559, "code": ".get_client_from_state(job_state) run_results=client.full_status() stdout=run_results.get('stdout', '') stderr=run_results.get('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs", "label": 0}, {"snippet_id": 68418, "code": ".state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" %", "label": 0}, {"snippet_id": 59845, "code": " observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int", "label": 0}, {"snippet_id": 7935, "code": " kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output", "label": 0}, {"snippet_id": 78413, "code": ".topic_successtimeout) self.w.sleep(self.topic_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10) except exc.UnknownAnswer as e: self.log.warning('%s: %s'", "label": 0}, {"snippet_id": 59185, "code": " import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq", "label": 0}, {"snippet_id": 24222, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle", "label": 0}, {"snippet_id": 8881, "code": "(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit", "label": 0}, {"snippet_id": 51721, "code": " dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items", "label": 0}, {"snippet_id": 39084, "code": ", dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config,", "label": 0}, {"snippet_id": 32608, "code": "\"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch", "label": 0}, {"snippet_id": 48825, "code": " requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output", "label": 0}, {"snippet_id": 94674, "code": " parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers", "label": 0}, {"snippet_id": 88931, "code": "\"Creates a new target, adds it to the context and returns it. This method ensures the target resolves files against the given target_base, creating the directory if needed and registering a source root. ", "label": 0}, {"snippet_id": 7473, "code": "(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\":", "label": 0}, {"snippet_id": 57267, "code": " field), now ) ) if t.tested_by !=request.user: field='tested_by' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), request.user ) ) field='assignee' try:", "label": 0}, {"snippet_id": 66498, "code": " file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 93744, "code": "%s'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start", "label": 0}, {"snippet_id": 90465, "code": ", distribution_environment, minimum_version=None, maximum_version=None): self._cache={} self._distribution_environment=distribution_environment self._minimum_version=minimum_version self._maximum_version", "label": 0}, {"snippet_id": 78869, "code": "\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: ", "label": 0}, {"snippet_id": 27154, "code": "'station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud',", "label": 1}, {"snippet_id": 56926, "code": "\"\" if self.counter['tag'] !=tag.pk: try: self.counter=self.test_tags.__next__() except StopIteration: return 0 if tag.pk==self.counter['tag']: return self.counter[self.key] return 0 def get_value_by_type", "label": 0}, {"snippet_id": 2378, "code": " datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts", "label": 0}, {"snippet_id": 19505, "code": "=argv[:pos] for arg in argv: if arg=='-h' or arg=='--help': return argv,[], script gottarget=False skip=0 for i in range(len(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except", "label": 0}, {"snippet_id": 92164, "code": ", cls).register_options(register) register('--setuptools-version', advanced=True, fingerprint=True, default='40.6.3', help='The setuptools version to use when executing `setup.py` scripts.') register('", "label": 0}, {"snippet_id": 30859, "code": ") @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic", "label": 0}, {"snippet_id": 79363, "code": "\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity", "label": 0}, {"snippet_id": 29146, "code": " return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or", "label": 0}, {"snippet_id": 42826, "code": "=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output", "label": 0}, {"snippet_id": 12908, "code": "[filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository", "label": 0}, {"snippet_id": 77991, "code": "%s]', repr(t), domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target(domain, id_, user) def rtfu(urls): for user", "label": 0}, {"snippet_id": 31124, "code": " for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output", "label": 0}, {"snippet_id": 16420, "code": ".PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self", "label": 0}, {"snippet_id": 55783, "code": " **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func", "label": 0}, {"snippet_id": 86596, "code": " scalac_plugin_target): scalac_plugin_info_file=os.path.join(resources_dir, _SCALAC_PLUGIN_INFO_FILE) with safe_open(scalac_plugin_info_file, 'w') as f: f.write(textwrap.dedent(\"\"\" <plugin> <name>{}</name> <classname>{}", "label": 0}, {"snippet_id": 42424, "code": ".docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies", "label": 0}, {"snippet_id": 4689, "code": "\"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a", "label": 0}, {"snippet_id": 87149, "code": "(compile_contexts[t]) for t in targets] zinc_analysis=self.context.products.get_data('zinc_analysis') zinc_args=self.context.products.get_data('zinc_args') if zinc_analysis is not None: for compile_context in", "label": 0}, {"snippet_id": 69999, "code": " command aims to start Lustre filesystem servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os", "label": 0}, {"snippet_id": 95055, "code": ": input_directory=\"./data/input/\" download_directory=input_directory +\"download/\" temp_directory=\"./data/temp/\" vcf_directory=\"./data/vcf/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=", "label": 1}, {"snippet_id": 86882, "code": "(cls, register): super(BaseZincCompile, cls).register_options(register) register('--whitelisted-args', advanced=True, type=dict, default={ '-S.*': False, '-C.*': False, '-file-filter': True, '-msg-filter'", "label": 0}, {"snippet_id": 84707, "code": "--skip-uniqueness', '--ignored=ignored', '--list-file=input_files_list', '--report-file=report', ) req=ExecuteProcessRequest( argv=cmd, input_files=directory_digest, output_files=('ignored', 'report'),", "label": 0}, {"snippet_id": 84584, "code": "): return super(CountLinesOfCode, cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register): super(CountLinesOfCode, cls).register_options(register) register('--transitive", "label": 0}, {"snippet_id": 55024, "code": " summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init", "label": 0}, {"snippet_id": 31996, "code": " the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, ", "label": 0}, {"snippet_id": 61294, "code": " a square matrix.\") if not np.allclose(A, A.conj().T, atol=tolerance): raise ValueError(\"Observable must be Hermitian.\") return A operator_map={ 'QubitStateVector': ket, 'QubitUnitary': unitary, 'Hermitian", "label": 0}, {"snippet_id": 83999, "code": ")) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck in the queued/running state when Galaxy started\"\"\" job_state=AsynchronousJobState", "label": 0}, {"snippet_id": 93089, "code": ".assertEqual(0o700, os.stat(f.name)[0] & 0o777) with temporary_dir(permissions=0o644) as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self): fake_logger=mock.Mock(", "label": 0}, {"snippet_id": 35858, "code": " try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)", "label": 0}, {"snippet_id": 81056, "code": ",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) ", "label": 0}, {"snippet_id": 21257, "code": ") if a.get('href')] new_links=[x for x in links if re.match(\"^https://youtu\\.be\", x)] newer_links=[x for x in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel", "label": 0}, {"snippet_id": 91573, "code": "=[] for constraint in sorted(constraints): constraints_args.extend([\"--interpreter-constraint\", text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor, PyTest, PythonSetup", "label": 1}, {"snippet_id": 75278, "code": ".req_handlers[(interface, method)] except KeyError: try: handler=self.req_handlers[(interface, None)] except KeyError: raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s'%(interface, method)) if iden", "label": 0}, {"snippet_id": 73608, "code": " raise ValueError(\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr", "label": 1}, {"snippet_id": 47073, "code": ") if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:", "label": 0}, {"snippet_id": 23924, "code": "=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if", "label": 0}, {"snippet_id": 74593, "code": " VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation of VCF to Zarr conversion module configuration. \"\"\" enabled=False fields=None alt_number=None chunk_length=None chunk_width", "label": 0}, {"snippet_id": 30731, "code": "() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self", "label": 0}, {"snippet_id": 52613, "code": "\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing", "label": 0}, {"snippet_id": 51377, "code": ": value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for", "label": 0}, {"snippet_id": 67509, "code": " from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies", "label": 0}, {"snippet_id": 37349, "code": ".dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names:", "label": 0}, {"snippet_id": 43011, "code": " self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 82979, "code": "[0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested", "label": 1}, {"snippet_id": 25951, "code": "'GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state", "label": 0}, {"snippet_id": 18979, "code": ".text_type(response.content, encoding='utf-8') else: raw_source=response.content else: raw_source=source try: try: return json.loads(raw_source) except ValueError: pass try: return yaml.load(raw_source)", "label": 1}, {"snippet_id": 52883, "code": "*_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self,", "label": 0}, {"snippet_id": 27989, "code": "=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data", "label": 0}, {"snippet_id": 32805, "code": " WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected,", "label": 1}, {"snippet_id": 95127, "code": "=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled. Skipping FTP download...\") data_service.process_data_files(input_dir=input_directory, temp_dir=temp_directory", "label": 1}, {"snippet_id": 15847, "code": " import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from", "label": 0}, {"snippet_id": 14846, "code": " requests import urlparse from retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from", "label": 0}, {"snippet_id": 64126, "code": "['outputs_directory'] configs_directory=remote_job_config['configs_directory'] working_directory=remote_job_config['working_directory'] outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path", "label": 0}, {"snippet_id": 68660, "code": "=TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA", "label": 0}, {"snippet_id": 55322, "code": ".params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config", "label": 0}, {"snippet_id": 6288, "code": ".error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re", "label": 1}, {"snippet_id": 62421, "code": " self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs)", "label": 0}, {"snippet_id": 2147, "code": ".POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0]", "label": 0}, {"snippet_id": 59953, "code": " ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map", "label": 0}, {"snippet_id": 63834, "code": " log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id)) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper): \"\"\"Recovers", "label": 0}, {"snippet_id": 69825, "code": " %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self", "label": 0}, {"snippet_id": 72231, "code": " use a normal command!\") return try: remoteirc=world.networkobjects[netname] except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return if args.service not in world.services: irc", "label": 0}, {"snippet_id": 82328, "code": "\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt\",\"r\") as fd: \t\tnb", "label": 0}, {"snippet_id": 38792, "code": " list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger", "label": 0}, {"snippet_id": 53311, "code": "._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch", "label": 0}, {"snippet_id": 90827, "code": "(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions are searched", "label": 0}, {"snippet_id": 92854, "code": ".name)) with self.assertRaisesRegexp(zipfile.BadZipfile, r'{}'.format(not_zip.name)): next(open_zip(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness to replace `sys.std*` with", "label": 0}, {"snippet_id": 8573, "code": "=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" ", "label": 1}, {"snippet_id": 89891, "code": " as java: if self._minimum_version: version=self._get_version(java) if version < self._minimum_version: raise self.Error('The java distribution at{} is too old; expecting at least{} and' ' got{}'.format", "label": 0}, {"snippet_id": 94252, "code": " self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" %", "label": 0}, {"snippet_id": 91769, "code": "=yield Get( Digest, DirectoriesToMerge, DirectoriesToMerge(directories=tuple(all_input_digests)), ) request=ExecuteProcessRequest( argv=(python_binary, './{}'.format(output_pytest_requirements_pex_filename", "label": 0}, {"snippet_id": 28020, "code": " if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class", "label": 0}, {"snippet_id": 69920, "code": ".get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK", "label": 1}, {"snippet_id": 55382, "code": ")) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources", "label": 0}, {"snippet_id": 8866, "code": " only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing", "label": 1}, {"snippet_id": 12639, "code": ".replace(\"submitting\", \"updating\"): PERMITTED_TO_COMMENT=False \"\"\" for old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body'].lower(): break elif", "label": 0}, {"snippet_id": 17403, "code": "=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice", "label": 0}, {"snippet_id": 49524, "code": "(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles", "label": 0}, {"snippet_id": 62914, "code": " ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util", "label": 0}, {"snippet_id": 24931, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30:", "label": 0}, {"snippet_id": 5945, "code": " uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as", "label": 1}, {"snippet_id": 90705, "code": " given constraints and returns it. :param minimum_version: minimum jvm version to look for(eg, 1.7). :param maximum_version: maximum jvm version to look for(eg, 1.7.9999). :param bool jdk: whether the found", "label": 0}, {"snippet_id": 50174, "code": " workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with", "label": 0}, {"snippet_id": 95602, "code": " already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def", "label": 0}, {"snippet_id": 15571, "code": "._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit(", "label": 0}, {"snippet_id": 93917, "code": " hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is", "label": 0}, {"snippet_id": 8218, "code": " uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as", "label": 1}, {"snippet_id": 79421, "code": " > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu", "label": 1}, {"snippet_id": 43386, "code": " return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException", "label": 0}, {"snippet_id": 74105, "code": " for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str=runtime_config", "label": 0}, {"snippet_id": 44611, "code": " done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats", "label": 0}, {"snippet_id": 88702, "code": "\" :API: public \"\"\" background_root_workunit=self.run_tracker.get_background_root_workunit() if parent_workunit_name: workunit_parent_ctx=self.run_tracker.new_workunit_under_parent( name=parent_workunit_name", "label": 0}, {"snippet_id": 34331, "code": ": def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo", "label": 0}, {"snippet_id": 44913, "code": ": raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority", "label": 0}, {"snippet_id": 53352, "code": ", dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)", "label": 0}, {"snippet_id": 23658, "code": " ifname): return shellutil.run(\"route add 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def remove_route_for_dhcp_broadcast(self, ifname): shellutil.run(\"route delete 255.255.255.255 -iface{0}\"", "label": 0}, {"snippet_id": 1280, "code": " print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE)", "label": 0}, {"snippet_id": 4133, "code": " import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import", "label": 0}, {"snippet_id": 42033, "code": "=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format", "label": 0}, {"snippet_id": 77361, "code": " self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname)", "label": 0}, {"snippet_id": 45804, "code": ": try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 51701, "code": ") for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames", "label": 0}, {"snippet_id": 31790, "code": " if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch,", "label": 0}, {"snippet_id": 35512, "code": ") return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self", "label": 0}, {"snippet_id": 37516, "code": " callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self", "label": 0}, {"snippet_id": 82890, "code": "\"filename\"],\"rb\") \ttemplatesData[template[\"templateName\"]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants", "label": 1}, {"snippet_id": 38145, "code": " priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError", "label": 0}, {"snippet_id": 2700, "code": ".yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"", "label": 0}, {"snippet_id": 37294, "code": "(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add", "label": 0}, {"snippet_id": 74211, "code": "\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input\" in runtime_config.benchmark: benchmark_data_input_temp=runtime_config.benchmark[\"benchmark_data_input\"] if benchmark_data_input_temp in", "label": 0}, {"snippet_id": 994, "code": "(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi", "label": 0}, {"snippet_id": 52708, "code": " @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected", "label": 0}, {"snippet_id": 10364, "code": " composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for", "label": 0}, {"snippet_id": 4565, "code": " objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db", "label": 0}, {"snippet_id": 65886, "code": " status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" ", "label": 0}, {"snippet_id": 36551, "code": " os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove", "label": 0}, {"snippet_id": 69117, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) return result", "label": 1}, {"snippet_id": 864, "code": " nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess", "label": 0}, {"snippet_id": 89305, "code": ", unicode_literals import itertools import logging import os import pkgutil import plistlib from abc import abstractproperty from builtins import object, open, str from collections import namedtuple from", "label": 0}, {"snippet_id": 26586, "code": " self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id==", "label": 0}, {"snippet_id": 69562, "code": "] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if", "label": 0}, {"snippet_id": 14375, "code": "._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port", "label": 0}, {"snippet_id": 83309, "code": "\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched", "label": 1}, {"snippet_id": 75226, "code": "=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method)]=fun def del_req_handler(self", "label": 0}, {"snippet_id": 75583, "code": ".make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return self.make_req_msg(d[0], d[1], d[2], fun, d[3]) def _parse_err(self, iden, msg, status): pass def _handle_nil", "label": 0}, {"snippet_id": 21581, "code": "(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove(link) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb')", "label": 0}, {"snippet_id": 37653, "code": "(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item", "label": 0}, {"snippet_id": 1311, "code": "] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass", "label": 1}, {"snippet_id": 25259, "code": ", None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status", "label": 0}, {"snippet_id": 42282, "code": " \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or self.nooutput", "label": 0}, {"snippet_id": 82180, "code": "\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser.add_argument(\"-T", "label": 0}, {"snippet_id": 93987, "code": "%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\"ssh %s 'bash -s' < %s\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True", "label": 0}, {"snippet_id": 44057, "code": ".global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def", "label": 0}, {"snippet_id": 79231, "code": "\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions", "label": 0}, {"snippet_id": 61707, "code": "') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U def expand_two(self, U, wires): \"\"\"Expand a two-qubit operator into a full", "label": 0}, {"snippet_id": 21224, "code": " import argparse as ap flatten=lambda l:[item for sublist in l for item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request(", "label": 0}, {"snippet_id": 53886, "code": " def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else:", "label": 0}, {"snippet_id": 81652, "code": "\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)", "label": 1}, {"snippet_id": 23019, "code": " patten=r'(sr[0-9]|hd[c-z]|cdrom[0-9]?)' for dvd in[re.match(patten, dev) for dev in os.listdir(dev_dir)]: if dvd is not None: return \"/dev/{0}\".format(dvd.group(0)) raise OSUtilError(\"Failed to get dvd", "label": 0}, {"snippet_id": 45237, "code": " is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self", "label": 0}, {"snippet_id": 34634, "code": " mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is", "label": 0}, {"snippet_id": 90925, "code": ".global_instance()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java distribution:{}'.format(e", "label": 0}, {"snippet_id": 50073, "code": "=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self", "label": 0}, {"snippet_id": 51513, "code": " raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given", "label": 0}, {"snippet_id": 1278, "code": " name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout", "label": 0}, {"snippet_id": 53823, "code": " def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self", "label": 0}, {"snippet_id": 40588, "code": "(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return", "label": 0}, {"snippet_id": 68023, "code": " message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS", "label": 0}, {"snippet_id": 51784, "code": " toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str,", "label": 0}, {"snippet_id": 10117, "code": " output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,.", "label": 0}, {"snippet_id": 35303, "code": " second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)", "label": 0}, {"snippet_id": 18332, "code": "), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout", "label": 0}, {"snippet_id": 67677, "code": " print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s", "label": 0}, {"snippet_id": 67309, "code": " def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR", "label": 0}, {"snippet_id": 84185, "code": "\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason ", "label": 0}, {"snippet_id": 62904, "code": " galaxy import model from galaxy.jobs.runners import AsynchronousJobState, AsynchronousJobRunner from galaxy.jobs import ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory", "label": 0}, {"snippet_id": 41823, "code": ".exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark", "label": 0}, {"snippet_id": 61250, "code": " @ U.conj().T, np.identity(U.shape[0]), atol=tolerance): raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args", "label": 0}, {"snippet_id": 35129, "code": " flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]", "label": 0}, {"snippet_id": 27411, "code": " netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name", "label": 0}, {"snippet_id": 30861, "code": " \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 19633, "code": ": parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ) parser.add_argument('--nodebug', action='store_true') host=parser.add_mutually_exclusive_group() host.add_argument('--host') host", "label": 0}, {"snippet_id": 67936, "code": " import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import", "label": 0}, {"snippet_id": 75876, "code": " 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in", "label": 0}, {"snippet_id": 21567, "code": " Forced exit detected. Saving and exiting.\") with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link", "label": 0}, {"snippet_id": 44881, "code": " int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException", "label": 0}, {"snippet_id": 16848, "code": ".sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError,", "label": 0}, {"snippet_id": 65826, "code": "(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target", "label": 0}, {"snippet_id": 45407, "code": "\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self)", "label": 0}, {"snippet_id": 23603, "code": "}{1}{2}'.format(net, gateway, mask) return shellutil.run(cmd, chk_err=False) def is_missing_default_route(self): \"\"\" For FreeBSD, the default broadcast goes to current default gw, not a all-ones broadcast", "label": 0}, {"snippet_id": 90676, "code": "._scan_constraint_match(minimum_version, maximum_version, jdk) if not dist: dist=self._locate(minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) self._cache[key]=dist return dist def _locate(self,", "label": 0}, {"snippet_id": 51342, "code": " WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self", "label": 0}, {"snippet_id": 13757, "code": " def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals, self.locals) if __name__=='__main__': for k", "label": 0}, {"snippet_id": 14285, "code": "._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file", "label": 0}, {"snippet_id": 88571, "code": " invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots @property def console_outstream(self): \"", "label": 0}, {"snippet_id": 67205, "code": " import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler):", "label": 0}, {"snippet_id": 83725, "code": "'stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job", "label": 0}, {"snippet_id": 94944, "code": ") subparser.required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument", "label": 0}, {"snippet_id": 83767, "code": "=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job", "label": 0}, {"snippet_id": 3337, "code": "): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new", "label": 0}, {"snippet_id": 38699, "code": ")) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if", "label": 0}, {"snippet_id": 72432, "code": ", runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments", "label": 1}, {"snippet_id": 31083, "code": " includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output", "label": 0}, {"snippet_id": 51614, "code": " values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists ", "label": 0}, {"snippet_id": 40888, "code": "=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f", "label": 0}, {"snippet_id": 78593, "code": ") self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError as e:", "label": 0}, {"snippet_id": 68175, "code": " nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"):", "label": 1}, {"snippet_id": 3702, "code": " is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState", "label": 0}, {"snippet_id": 4382, "code": " extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the", "label": 1}, {"snippet_id": 57298, "code": " from %s to %s.' %( field, getattr(t, field), request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST", "label": 0}, {"snippet_id": 87788, "code": ".format(path)) if is_outside(path, self.get_options().pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath entries provided to zinc should be in working directory", "label": 0}, {"snippet_id": 62866, "code": "*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities", "label": 0}, {"snippet_id": 82589, "code": "\") now=datetime.datetime.now() print(\"[*] starting at \"+str(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args", "label": 0}, {"snippet_id": 79245, "code": "[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t", "label": 0}, {"snippet_id": 9144, "code": " the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already", "label": 0}, {"snippet_id": 3272, "code": ".node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self", "label": 0}, {"snippet_id": 63735, "code": " job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning( \"stop_job(): %s: no", "label": 0}, {"snippet_id": 84761, "code": " collections import namedtuple from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.zinc_language_mixin import ZincLanguageMixin from pants.backend.jvm.targets", "label": 0}, {"snippet_id": 39571, "code": ".shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate", "label": 0}, {"snippet_id": 5179, "code": "(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]", "label": 0}, {"snippet_id": 68087, "code": " RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 1}, {"snippet_id": 91368, "code": "'python_requirements': PythonRequirements, PantsRequirement.alias: PantsRequirement, } ) def register_goals(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local-dists'", "label": 0}, {"snippet_id": 91612, "code": " 1826945) pex_snapshot=yield Get(Snapshot, UrlToFetch(url, digest)) transitive_hydrated_targets=yield Get( TransitiveHydratedTargets, BuildFileAddresses((test_target.address,)) ) all_targets=[t.adaptor for t", "label": 0}, {"snippet_id": 20497, "code": " @property def is_client(self): try: return self._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self", "label": 0}, {"snippet_id": 2020, "code": "[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset", "label": 0}, {"snippet_id": 70958, "code": "(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) >", "label": 0}, {"snippet_id": 15716, "code": "{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def", "label": 0}, {"snippet_id": 17126, "code": " vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all", "label": 0}, {"snippet_id": 44839, "code": "(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0]", "label": 0}, {"snippet_id": 73736, "code": "=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))} self.__dict__.update", "label": 0}, {"snippet_id": 57849, "code": "): reviewers[0]}) @require_POST def update_cases_default_tester(request): \"\"\"Update default tester upon selected TestCases\"\"\" proxy=TestCaseUpdateActions(request) return proxy.update() update_cases_priority", "label": 0}, {"snippet_id": 49925, "code": " dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa,", "label": 0}, {"snippet_id": 39641, "code": ".params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def", "label": 0}, {"snippet_id": 88961, "code": ".path.exists(abs_target_base): os.makedirs(abs_target_base) if not self.source_roots.find_by_path(rel_target_base): self.source_roots.add_source_root(rel_target_base) if dependencies: dependencies=[dep", "label": 0}, {"snippet_id": 6682, "code": " output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of", "label": 0}, {"snippet_id": 3180, "code": "(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\"ssh %s 'bash -s' < %s\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps", "label": 0}, {"snippet_id": 52782, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self", "label": 0}, {"snippet_id": 80298, "code": "\tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.", "label": 0}, {"snippet_id": 70788, "code": " status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN", "label": 0}, {"snippet_id": 94839, "code": ") cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl", "label": 0}, {"snippet_id": 76150, "code": ".status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that", "label": 0}, {"snippet_id": 3011, "code": ": self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window", "label": 0}, {"snippet_id": 85416, "code": " Factory(Subsystem, JvmToolMixin): options_scope='zinc' @classmethod def subsystem_dependencies(cls): return super(Zinc.Factory, cls).subsystem_dependencies() +(DependencyContext, Java, ScalaPlatform) @classmethod", "label": 0}, {"snippet_id": 94850, "code": ".config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui", "label": 0}, {"snippet_id": 17322, "code": ".format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format", "label": 0}, {"snippet_id": 26444, "code": " self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the", "label": 0}, {"snippet_id": 8377, "code": ") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1", "label": 0}, {"snippet_id": 57535, "code": " def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids=map(int, self.request.POST.getlist('case')) self._update_objects=TestCase.objects.filter(pk__in=case_ids) return", "label": 0}, {"snippet_id": 63763, "code": " pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s:", "label": 0}, {"snippet_id": 58745, "code": "(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission) self.client.login( username=self.tester.username, password='password') response", "label": 0}, {"snippet_id": 50364, "code": " ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule", "label": 0}, {"snippet_id": 32141, "code": " have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name,", "label": 0}, {"snippet_id": 10420, "code": ".path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and", "label": 0}, {"snippet_id": 86715, "code": " $JAVA_HOME with the path to an appropriate jvm distribution. :param settings: The jvm platform settings from which to extract the arguments. :type settings::class:`JvmPlatformSettings` \"\"\" zinc_args=[", "label": 0}, {"snippet_id": 4720, "code": ", v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords", "label": 0}, {"snippet_id": 77975, "code": ", id_) if t in protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu", "label": 0}, {"snippet_id": 61229, "code": " matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape[0] !=U.shape[1]: raise ValueError(\"Operator must be a square matrix.\") if not np.allclose(U @ U.conj().T, np.identity", "label": 0}, {"snippet_id": 6178, "code": " remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text", "label": 1}, {"snippet_id": 19123, "code": " \"\"\" request=None if raw_request is not None: request=normalize_request(raw_request) response=None if raw_response is not None: response=normalize_response(raw_response, request=request) if response is", "label": 0}, {"snippet_id": 48171, "code": " self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names(", "label": 0}, {"snippet_id": 47349, "code": " of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards", "label": 0}, {"snippet_id": 66393, "code": " import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose", "label": 0}, {"snippet_id": 95746, "code": "\") for path in pathlist_vcf_temp: path_temp_str=str(path) filename_str=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree", "label": 0}, {"snippet_id": 26842, "code": "% data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self", "label": 0}, {"snippet_id": 66783, "code": " class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self)", "label": 0}, {"snippet_id": 67783, "code": " RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target", "label": 0}, {"snippet_id": 48920, "code": " def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add", "label": 0}, {"snippet_id": 48167, "code": ", output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files", "label": 0}, {"snippet_id": 38800, "code": " dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed", "label": 0}, {"snippet_id": 27833, "code": " elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" %", "label": 0}, {"snippet_id": 80404, "code": " illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"", "label": 0}, {"snippet_id": 87860, "code": ": ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append", "label": 0}, {"snippet_id": 54674, "code": " by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def", "label": 0}, {"snippet_id": 14225, "code": " 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart", "label": 0}, {"snippet_id": 78852, "code": " setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={", "label": 0}, {"snippet_id": 24337, "code": "\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\", "label": 1}, {"snippet_id": 34933, "code": "(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set", "label": 0}, {"snippet_id": 82961, "code": "\t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a[\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit", "label": 1}, {"snippet_id": 45488, "code": " WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)", "label": 0}, {"snippet_id": 53365, "code": " dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion", "label": 1}, {"snippet_id": 8263, "code": "-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching", "label": 1}, {"snippet_id": 28641, "code": ".type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 18745, "code": "']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list", "label": 0}, {"snippet_id": 43070, "code": ": self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name", "label": 0}, {"snippet_id": 75667, "code": " self.name=name if name else type(self).__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests", "label": 0}, {"snippet_id": 15489, "code": "._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive():", "label": 0}, {"snippet_id": 35630, "code": " setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names", "label": 0}, {"snippet_id": 87108, "code": " \" \"but workdir was{} and buildroot was{}\".format( self.get_options().pants_workdir, get_buildroot(), ) ) if self.get_options().use_classpath_jars: raise TaskError(\"Hermetic zinc execution currently doesn", "label": 0}, {"snippet_id": 14162, "code": " from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm", "label": 0}, {"snippet_id": 29552, "code": " return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern", "label": 0}, {"snippet_id": 92344, "code": " print(\"HORK\" in os.environ)'], stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as", "label": 1}, {"snippet_id": 77239, "code": ".proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try: proxypair=proxypairs.pop() except Exception: return self.proxylist.add(proxypair) for spawn in create_spawn(proxypair[0", "label": 0}, {"snippet_id": 35399, "code": " pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the", "label": 0}, {"snippet_id": 67392, "code": ".get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" ", "label": 1}, {"snippet_id": 61329, "code": "': fry, 'RZ': frz, 'Rot': fr3 } class DefaultQubit(Device): \"\"\"Default qubit device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must", "label": 0}, {"snippet_id": 7237, "code": "(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format", "label": 0}, {"snippet_id": 79146, "code": ".post(self.uploadUrl,files={self.inputName:(filename,fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif", "label": 0}, {"snippet_id": 47926, "code": " return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f", "label": 0}, {"snippet_id": 39455, "code": ".params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule", "label": 0}, {"snippet_id": 74226, "code": " self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"] if \"benchmark_allele_count\" in", "label": 1}, {"snippet_id": 65905, "code": ".append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)", "label": 0}, {"snippet_id": 19192, "code": " or getattr(err, 'detail')) return response=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError", "label": 0}, {"snippet_id": 17561, "code": "=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( ", "label": 0}, {"snippet_id": 74115, "code": ": blosc_shuffle_mode_str=runtime_config.vcf_to_zarr[\"blosc_shuffle_mode\"] if isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types", "label": 0}, {"snippet_id": 1478, "code": "\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address", "label": 0}, {"snippet_id": 32784, "code": " from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException", "label": 0}, {"snippet_id": 74649, "code": " in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr[\"alt_number", "label": 0}, {"snippet_id": 40683, "code": " if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards):", "label": 0}, {"snippet_id": 49943, "code": " drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if", "label": 0}, {"snippet_id": 53581, "code": " output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\"", "label": 0}, {"snippet_id": 302, "code": ".method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST", "label": 0}, {"snippet_id": 51848, "code": " the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self", "label": 0}, {"snippet_id": 65789, "code": " layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\",", "label": 0}, {"snippet_id": 50673, "code": " @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def", "label": 0}, {"snippet_id": 63988, "code": " in[\"none\", \"local\", \"remote\"]: raise Exception(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client", "label": 0}, {"snippet_id": 58351, "code": " urlencode({'author__email__startswith': self.user.email})) class TestIndex(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self.client.get(reverse('core-views-index'))", "label": 0}, {"snippet_id": 60957, "code": ". Measurements, batching etc. Returns: dict[str->*]: results \"\"\" return cls._capabilities @abc.abstractmethod def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation", "label": 1}, {"snippet_id": 52765, "code": " when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill", "label": 0}, {"snippet_id": 43322, "code": ", wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except", "label": 0}, {"snippet_id": 49684, "code": " are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument", "label": 0}, {"snippet_id": 27941, "code": "'GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 59237, "code": "'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The", "label": 0}, {"snippet_id": 83881, "code": "%s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata", "label": 0}, {"snippet_id": 6687, "code": " output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache", "label": 0}, {"snippet_id": 41968, "code": " zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output", "label": 0}, {"snippet_id": 32160, "code": "._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append", "label": 0}, {"snippet_id": 80486, "code": " can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in", "label": 0}, {"snippet_id": 89148, "code": "\"Returns an iterator over the target(s) the given address points to. :API: public \"\"\" return self.build_graph.resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``", "label": 0}, {"snippet_id": 73344, "code": ".path.split(path) return head def path_leaf(path): head, tail=os.path.split(path) return tail or os.path.basename(head) def read_file_contents(local_filepath): if os.path.isfile(local_filepath): with open", "label": 0}, {"snippet_id": 10908, "code": " def is_file(parsed_uri): return parsed_uri.scheme in['', 'file'] def is_host(parsed_uri): return parsed_uri.scheme in['http', 'https'] def read_config(uri): uri_parsed=urlparse.urlparse(uri) if is_file", "label": 0}, {"snippet_id": 8932, "code": "\"\"\"Extract keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode", "label": 1}, {"snippet_id": 40124, "code": " ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod", "label": 0}, {"snippet_id": 56893, "code": " TestRunTag :type test_tags: QuerySet \"\"\" self.key=key self.test_tags=iter(test_tags) self.counter={'tag': 0} def calculate_tag_count(self, tag): \"\"\" :param tag: the tag you do the counting for :type tag", "label": 0}, {"snippet_id": 44096, "code": " if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set", "label": 0}, {"snippet_id": 8249, "code": ": from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document", "label": 1}, {"snippet_id": 78519, "code": " new targets in forum %s:%s', lt, user, forum) else: self.log.debug('Found no new targets in forum %s:%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with", "label": 0}, {"snippet_id": 91779, "code": "'./{}'.format(output_pytest_requirements_pex_filename)), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=merged_input_files, description='Run pytest for{}'.format", "label": 0}, {"snippet_id": 50644, "code": "=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os", "label": 0}, {"snippet_id": 76714, "code": " action='store_true', default=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default='randav', help='Directory with avatars') parser.add_argument('--rp-timeout',", "label": 0}, {"snippet_id": 32718, "code": " self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j", "label": 0}, {"snippet_id": 67656, "code": " print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self", "label": 0}, {"snippet_id": 26072, "code": "(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"", "label": 1}, {"snippet_id": 81035, "code": "\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet", "label": 0}, {"snippet_id": 73438, "code": " file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\"", "label": 0}, {"snippet_id": 66066, "code": " View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False", "label": 0}, {"snippet_id": 74442, "code": "{0} not found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility", "label": 0}, {"snippet_id": 86856, "code": "-Xlint:none', '-S-nowarn', '-S-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-S-Xfatal-warnings', '-C-Werror') @classmethod def get_fatal_warnings_disabled_args_default", "label": 0}, {"snippet_id": 3610, "code": " entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window", "label": 1}, {"snippet_id": 42428, "code": "=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output", "label": 0}, {"snippet_id": 55871, "code": " params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message", "label": 0}, {"snippet_id": 76817, "code": "='Forget about closed topics') parser.add_argument('--die-on-neterror', action='store_true', default=False, help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net", "label": 0}, {"snippet_id": 91081, "code": ") normalized[rename].extend(paths) else: normalized[rename]=paths return normalized def _get_explicit_jdk_paths(self): if not self._normalized_jdk_paths: return() os_name=normalize_os_name(os.uname()[0", "label": 0}, {"snippet_id": 63590, "code": ".cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs", "label": 0}, {"snippet_id": 57667, "code": " update_object=self.get_update_targets() if not update_object: return say_no('No record(s) found') for testcase in update_object: if hasattr(testcase, 'log_action'): testcase.log_action( who=self.request.user", "label": 0}, {"snippet_id": 41530, "code": " in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input", "label": 0}, {"snippet_id": 83967, "code": "%d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id", "label": 0}, {"snippet_id": 68212, "code": " def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[]", "label": 0}, {"snippet_id": 71541, "code": "=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__", "label": 0}, {"snippet_id": 1847, "code": "(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print", "label": 0}, {"snippet_id": 7381, "code": "): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml", "label": 0}, {"snippet_id": 34973, "code": ": if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer", "label": 0}, {"snippet_id": 31150, "code": ".benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job", "label": 0}, {"snippet_id": 86542, "code": ".java.distribution.distribution import DistributionLocator from pants.util.contextutil import open_zip from pants.util.dirutil import fast_relpath, safe_open from pants.util.memo import memoized_method", "label": 0}, {"snippet_id": 91853, "code": ".backend.python.python_requirement import PythonRequirement from pants.backend.python.subsystems import pex_build_util from pants.backend.python.subsystems.python_setup import PythonSetup from pants.backend", "label": 0}, {"snippet_id": 6777, "code": "=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords=extract_single_keywords", "label": 0}, {"snippet_id": 21388, "code": " reddytt working directory(%s).\" % work_dir) if not os.path.isdir(work_dir): print(\"Reddytt: Working directory not found. Creating %s, and files.\" % work_dir) os.mkdir(work_dir) os.mkdir(sr_dir) os.system", "label": 0}, {"snippet_id": 79690, "code": ") parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument", "label": 0}, {"snippet_id": 77204, "code": "')) if len(proxypair) < 2: self.log.warning('Line %s has too few spaces', line) continue if len(proxypair) > 2: self.log.debug('Line %s has too much spaces', line) proxypair=(proxypair[0], proxypair[1]", "label": 0}, {"snippet_id": 73642, "code": " from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true'", "label": 0}, {"snippet_id": 9231, "code": " string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string", "label": 0}, {"snippet_id": 62783, "code": " the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']", "label": 0}, {"snippet_id": 33697, "code": "=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness", "label": 0}, {"snippet_id": 76916, "code": "='SOCKS4': net.proxy_type=sup.proxytype.socks4 elif proxytype=='SOCKS5': net.proxy_type=sup.proxytype.socks5 else: raise TypeError('Invalid proxytype %s' % proxytype) net.useragent=random.choice(d.ua_list", "label": 1}, {"snippet_id": 59695, "code": " Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only", "label": 0}, {"snippet_id": 66753, "code": " %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self", "label": 1}, {"snippet_id": 28459, "code": " the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor", "label": 0}, {"snippet_id": 56111, "code": " paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for", "label": 0}, {"snippet_id": 25606, "code": "'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=", "label": 0}, {"snippet_id": 69614, "code": " import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self):", "label": 0}, {"snippet_id": 42770, "code": " not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain", "label": 0}, {"snippet_id": 14461, "code": "=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and", "label": 0}, {"snippet_id": 1212, "code": ", os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase", "label": 1}, {"snippet_id": 46346, "code": " list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"", "label": 0}, {"snippet_id": 60011, "code": " **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum", "label": 0}, {"snippet_id": 38512, "code": "=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info", "label": 0}, {"snippet_id": 45505, "code": " path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !", "label": 0}, {"snippet_id": 53738, "code": " a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files", "label": 0}, {"snippet_id": 65567, "code": " vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel))", "label": 0}, {"snippet_id": 30354, "code": ", plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return", "label": 0}, {"snippet_id": 21546, "code": ")s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt: That was: %s\" % link) if x==0: seen_links.append(link) save_links.remove(link) elif x==1024: print(\"Reddytt: Forced exit detected. Saving and exiting.\"", "label": 1}, {"snippet_id": 71064, "code": " if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\"", "label": 0}, {"snippet_id": 16735, "code": " filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self", "label": 0}, {"snippet_id": 71878, "code": ": ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self", "label": 0}, {"snippet_id": 80996, "code": ".shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self", "label": 0}, {"snippet_id": 82099, "code": ",default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"", "label": 0}, {"snippet_id": 16465, "code": " and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded", "label": 0}, {"snippet_id": 93677, "code": " CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name']) else:", "label": 0}, {"snippet_id": 4846, "code": ", spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s", "label": 0}, {"snippet_id": 60806, "code": "' _capabilities={} _gates={} _observables={} _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots self._out=None self._queue=[] self._observe=None def __repr__(self): \"\"\"String", "label": 0}, {"snippet_id": 33647, "code": " items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes", "label": 0}, {"snippet_id": 41079, "code": " as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in", "label": 0}, {"snippet_id": 88894, "code": ": self._lock.release() return True def is_unlocked(self): \"\"\"Whether the global lock object is actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots", "label": 0}, {"snippet_id": 9186, "code": "{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or", "label": 0}, {"snippet_id": 64918, "code": " Shine `start' command classes. The start command aims to start Lustre filesystem servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously", "label": 0}, {"snippet_id": 34906, "code": " be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files", "label": 0}, {"snippet_id": 78446, "code": " exc.TemporaryError as e: self.log.warn(e) self.w.sleep(self.errortimeout) def get_targets(self): found_count=0 for user, forum in self.forums: targets=[] self.log.debug('Scanning first page of the forum ", "label": 0}, {"snippet_id": 24896, "code": " data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" %", "label": 0}, {"snippet_id": 43754, "code": "=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows", "label": 0}, {"snippet_id": 18297, "code": " dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file", "label": 0}, {"snippet_id": 4534, "code": "(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit,", "label": 0}, {"snippet_id": 71243, "code": "=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags", "label": 0}, {"snippet_id": 39970, "code": ") def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file", "label": 0}, {"snippet_id": 36625, "code": " threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as", "label": 0}, {"snippet_id": 8139, "code": " def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory", "label": 0}, {"snippet_id": 49015, "code": " filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder", "label": 0}, {"snippet_id": 34691, "code": " 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if", "label": 0}, {"snippet_id": 31048, "code": "(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected", "label": 0}, {"snippet_id": 18075, "code": ".text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY", "label": 0}, {"snippet_id": 54793, "code": ", forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync", "label": 0}, {"snippet_id": 21279, "code": ".search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label:', lk) continue new_links.append('https://www.youtube.com/watch?v=' +videolabel) return new_links, links", "label": 0}, {"snippet_id": 6643, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list", "label": 1}, {"snippet_id": 7609, "code": "): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword", "label": 0}, {"snippet_id": 70648, "code": ".target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support", "label": 0}, {"snippet_id": 1792, "code": "} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW", "label": 0}, {"snippet_id": 60830, "code": " return self.__module__ +'.' +self.__class__.__name__ +'\\nInstance: ' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: '", "label": 0}, {"snippet_id": 83035, "code": " KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) ", "label": 0}, {"snippet_id": 38921, "code": ": return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger", "label": 0}, {"snippet_id": 20028, "code": " not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start", "label": 0}, {"snippet_id": 78381, "code": ": self.counter_tick() try: self.addtopic(self.msgfun(), self.sbjfun(), f) except exc.Success as e: self.counters['topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout", "label": 1}, {"snippet_id": 7739, "code": "(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var", "label": 0}, {"snippet_id": 64089, "code": " return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration", "label": 0}, {"snippet_id": 21149, "code": "))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message='Timeout waiting for ' if", "label": 0}, {"snippet_id": 51347, "code": "(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict(", "label": 0}, {"snippet_id": 56703, "code": ") from the database \"\"\" def __init__(self, request): \"\"\" :param request: An HTTP GET request, containing the primary key and the type of object to be selected :type request: HttpRequest \"\"\" for obj in[", "label": 0}, {"snippet_id": 43772, "code": "() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for", "label": 0}, {"snippet_id": 55585, "code": " workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global", "label": 0}, {"snippet_id": 23312, "code": "=False) def device_for_ide_port(self, port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in here because BIG-IP may not have yet initialized this list of devices. :param port_id: ", "label": 0}, {"snippet_id": 72034, "code": " command, use REHASH to reload the networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error", "label": 0}, {"snippet_id": 20415, "code": ".stdout.flush() time.sleep(0.1) else: break else: raise RuntimeError('could not connect') return sock return cls._create(connect, addr, **kwargs) @classmethod def create_server(cls, addr, **kwargs): def", "label": 0}, {"snippet_id": 60535, "code": " Gaussian device for OpenQML. wires(int): the number of modes to initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"", "label": 0}, {"snippet_id": 15932, "code": ", 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session", "label": 1}, {"snippet_id": 8348, "code": " file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\")", "label": 0}, {"snippet_id": 47487, "code": "=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value", "label": 0}, {"snippet_id": 38556, "code": ", forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname", "label": 0}, {"snippet_id": 1426, "code": " ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }", "label": 0}, {"snippet_id": 10172, "code": ".core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents", "label": 0}, {"snippet_id": 50039, "code": " and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and", "label": 0}, {"snippet_id": 94273, "code": " running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window", "label": 0}, {"snippet_id": 11143, "code": " %H:%M:%S\", localtime()) lines.append(\"%s on %s\" %(Header.MON_CONF_GEN_COMMENT, time_string)) if self.etag: lines.append(\"%s%s\" %(Header.ETAG_COMMENT, self.etag)) if self.mtime: lines.append(\"%s%d\" %(Header", "label": 0}, {"snippet_id": 54562, "code": ".globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 58047, "code": ".filter(pk__in=data['runs']) bug_system_id=data['bug_system_id'] bug_ids=data['bugs'] try: validate_bug_id(bug_ids, bug_system_id) except ValidationError as e: return say_no(str(e)) bz_external_track=data", "label": 0}, {"snippet_id": 38908, "code": " if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for", "label": 0}, {"snippet_id": 14361, "code": "='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles", "label": 0}, {"snippet_id": 26852, "code": " elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'", "label": 0}, {"snippet_id": 13399, "code": "\"content\": content_code, \"sha\": sha_blob, \"branch\": data.get(\"new_branch\"), } r=requests.put(url, json=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" ", "label": 0}, {"snippet_id": 13072, "code": "=False url=\"https://api.github.com/repos/{}/forks\" url=url.format(data[\"target_repo_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[", "label": 0}, {"snippet_id": 34731, "code": ", d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e:", "label": 1}, {"snippet_id": 31288, "code": " \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other", "label": 0}, {"snippet_id": 48497, "code": " start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def", "label": 0}, {"snippet_id": 76715, "code": " action='store_true', default=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default='randav', help='Directory with avatars') parser.add_argument('--rp-timeout', '-T',", "label": 0}, {"snippet_id": 2792, "code": " self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'", "label": 0}, {"snippet_id": 56964, "code": " 30, 59), None) 3. get_value_by_type('5', 'int') ('5', None) 4. get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy',", "label": 0}, {"snippet_id": 10546, "code": " Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return", "label": 1}, {"snippet_id": 58677, "code": "'response': 'Permission Dinied.'}) def test_update_plan_is_active(self): self.client.login( username=self.tester.username, password='password') post_data={ 'content_type': 'testplans.testplan', 'object_pk'", "label": 0}, {"snippet_id": 70348, "code": "(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options=", "label": 0}, {"snippet_id": 35505, "code": ".items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not", "label": 0}, {"snippet_id": 63365, "code": " ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception", "label": 1}, {"snippet_id": 34115, "code": "(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if", "label": 0}, {"snippet_id": 62472, "code": " certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map", "label": 0}, {"snippet_id": 72125, "code": ".error('Not enough arguments(needs 2: network name(case sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return except ValueError", "label": 0}, {"snippet_id": 74541, "code": "(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else:", "label": 0}, {"snippet_id": 72261, "code": " remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text, **kwargs): \"\"\" reply() rerouter for", "label": 0}, {"snippet_id": 80844, "code": "\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a \t\t", "label": 0}, {"snippet_id": 18194, "code": " UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 67446, "code": " def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs", "label": 0}, {"snippet_id": 39183, "code": ".resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\")", "label": 0}, {"snippet_id": 12722, "code": " response=requests.post(query, json={\"body\": comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B %d, %Y at ", "label": 0}, {"snippet_id": 9771, "code": ": str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse", "label": 0}, {"snippet_id": 68128, "code": ", indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None: view=\"fs\" else: view", "label": 1}, {"snippet_id": 75282, "code": ": try: handler=self.req_handlers[(interface, None)] except KeyError: raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value(tuple(iden", "label": 0}, {"snippet_id": 34479, "code": ", dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def", "label": 0}, {"snippet_id": 17200, "code": " ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd", "label": 0}, {"snippet_id": 37, "code": " escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass", "label": 1}, {"snippet_id": 70574, "code": " ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>", "label": 0}, {"snippet_id": 70211, "code": " self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start", "label": 0}, {"snippet_id": 92072, "code": "._any_targets_have_native_sources(targets): return False platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys()) if not", "label": 0}, {"snippet_id": 31498, "code": " apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile", "label": 0}, {"snippet_id": 8234, "code": " urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener(", "label": 1}, {"snippet_id": 82153, "code": " wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by", "label": 0}, {"snippet_id": 3087, "code": "'name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self", "label": 0}, {"snippet_id": 31111, "code": "{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value", "label": 0}, {"snippet_id": 57794, "code": "=self.get_update_targets() offset=0 step_length=500 queryset_filter=TestCasePlan.objects.filter data={self.target_field: sortkey} while 1: sub_cases=update_targets[offset:offset +step_length] case_pks=", "label": 0}, {"snippet_id": 44413, "code": ".extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary", "label": 0}, {"snippet_id": 68306, "code": ", \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout", "label": 0}, {"snippet_id": 26098, "code": "\"\"\" Support for the NetAtmo Weather Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime", "label": 1}, {"snippet_id": 93748, "code": "['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp[", "label": 0}, {"snippet_id": 20500, "code": " self._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed read=recv_as_read(self._sock", "label": 0}, {"snippet_id": 44439, "code": " return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 68150, "code": "\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets", "label": 0}, {"snippet_id": 72498, "code": ".required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config", "label": 0}, {"snippet_id": 16035, "code": "=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath':", "label": 0}, {"snippet_id": 56337, "code": "=request, product_id=request.GET.get('product_id')) info_type=getattr(objects, request.GET.get('info_type')) if not info_type: return HttpResponse('Unrecognizable info-type') if request.GET.get('format')==", "label": 0}, {"snippet_id": 38550, "code": " cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None", "label": 0}, {"snippet_id": 26377, "code": " variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var ", "label": 0}, {"snippet_id": 21776, "code": ".fit_transform(X[:, 1]) labelencoder_X_2=LabelEncoder() X[:, 2]=labelencoder_X_2.fit_transform(X[:, 2]) onehotencoder=OneHotEncoder(categorical_features=[1]) X=onehotencoder.fit_transform(X).toarray() X=X[", "label": 1}, {"snippet_id": 22556, "code": " restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly valid name. When WAAgent gets around to running though", "label": 0}, {"snippet_id": 58514, "code": ".tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run': '99999998,1009900'}) self.assertJSONEqual( str(response.content, encoding=settings", "label": 0}, {"snippet_id": 15389, "code": "+str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash", "label": 0}, {"snippet_id": 83931, "code": " sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror", "label": 0}, {"snippet_id": 77257, "code": " spawn in create_spawn(proxypair[0], proxypair[1], self.pc, self.get_userqueue): self.log.info('Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception", "label": 0}, {"snippet_id": 80873, "code": "],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt:", "label": 0}, {"snippet_id": 65501, "code": " rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>]", "label": 0}, {"snippet_id": 10179, "code": " category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info", "label": 0}, {"snippet_id": 40458, "code": "\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic", "label": 0}, {"snippet_id": 48873, "code": " bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards", "label": 0}, {"snippet_id": 4762, "code": " routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite", "label": 0}, {"snippet_id": 74857, "code": " class BenchmarkConfigurationRepresentation: \"\"\" Utility class for object representation of the benchmark module's configuration. \"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset", "label": 0}, {"snippet_id": 79052, "code": " still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern", "label": 0}, {"snippet_id": 13008, "code": "\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=", "label": 0}, {"snippet_id": 78657, "code": ".stdout.write(Writer.write(self.run())) except BaseException as e: log.logger.exception(e) return -1 return 0 def execute(self): \"\"\"To be overridden by sub classes\"\"\" pass def run(self): try: if self.options", "label": 1}, {"snippet_id": 10305, "code": "(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v", "label": 0}, {"snippet_id": 74872, "code": "\" benchmark_dataset=\"\" benchmark_aggregations=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\" Creates an object representation of the Benchmark module's configuration", "label": 1}, {"snippet_id": 54143, "code": "() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params,", "label": 0}, {"snippet_id": 4185, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: ", "label": 0}, {"snippet_id": 75866, "code": ".retry=False continue return elapsed=t.elapsed(False) if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock", "label": 0}, {"snippet_id": 18149, "code": " from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from", "label": 0}, {"snippet_id": 18043, "code": ", 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future", "label": 0}, {"snippet_id": 89593, "code": "(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version=_parse_java_version(\"minimum_version\", minimum_version) self._maximum_version=_parse_java_version(\"maximum_version\", maximum_version", "label": 0}, {"snippet_id": 11604, "code": " None) else \"\" for x in value]) else: return str(value) class OutputWriter(object): def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with open(self.output_file, ", "label": 0}, {"snippet_id": 55304, "code": " list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed", "label": 0}, {"snippet_id": 35603, "code": ") def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index", "label": 0}, {"snippet_id": 27407, "code": "\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0", "label": 0}, {"snippet_id": 79978, "code": "\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true", "label": 0}, {"snippet_id": 64146, "code": "(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home default_config_file=os.path.join(remote_galaxy_home, ", "label": 0}, {"snippet_id": 87345, "code": ".compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self.get_options().pants_bootstrapdir, 'zinc', key) def compile(self,", "label": 1}, {"snippet_id": 82924, "code": " \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime\":mime,\"templateName", "label": 1}, {"snippet_id": 50224, "code": "=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None", "label": 0}, {"snippet_id": 69494, "code": " cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command", "label": 0}, {"snippet_id": 59112, "code": " several different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer", "label": 0}, {"snippet_id": 4196, "code": "): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode", "label": 0}, {"snippet_id": 16311, "code": "-port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 40874, "code": ".group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames", "label": 0}, {"snippet_id": 83864, "code": ") return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode", "label": 0}, {"snippet_id": 85310, "code": " absolute_import, division, print_function, unicode_literals from builtins import object from pants.backend.jvm.subsystems.dependency_context import DependencyContext from pants.backend.jvm.subsystems.java import", "label": 0}, {"snippet_id": 71742, "code": " cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc())", "label": 0}, {"snippet_id": 7553, "code": " single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags", "label": 0}, {"snippet_id": 31977, "code": " output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self", "label": 0}, {"snippet_id": 74315, "code": " generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path", "label": 0}, {"snippet_id": 37563, "code": " self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self", "label": 0}, {"snippet_id": 11144, "code": "%M:%S\", localtime()) lines.append(\"%s on %s\" %(Header.MON_CONF_GEN_COMMENT, time_string)) if self.etag: lines.append(\"%s%s\" %(Header.ETAG_COMMENT, self.etag)) if self.mtime: lines.append(\"%s%d\" %(Header", "label": 0}, {"snippet_id": 90025, "code": "[java, '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self.Error(", "label": 0}, {"snippet_id": 59588, "code": " Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self)", "label": 0}, {"snippet_id": 40583, "code": ": return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected", "label": 1}, {"snippet_id": 29158, "code": "(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function", "label": 0}, {"snippet_id": 26069, "code": ".station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the", "label": 1}, {"snippet_id": 6742, "code": "=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name)", "label": 0}, {"snippet_id": 90739, "code": " java distribution could be found. \"\"\" for location in itertools.chain(self._distribution_environment.jvm_locations): try: dist=Distribution(home_path=location.home_path, bin_path=location.bin_path, minimum_version", "label": 0}, {"snippet_id": 48765, "code": " of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a", "label": 0}, {"snippet_id": 91729, "code": ".address.spec_path) sources_snapshots_and_source_roots.append((tgt_snapshot, tgt_source_root)) all_sources_digests=yield[ Get( Digest, DirectoryWithPrefixToStrip( directory_digest=snapshot.directory_digest,", "label": 0}, {"snippet_id": 17036, "code": ".CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport", "label": 0}, {"snippet_id": 15629, "code": ")) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None", "label": 0}, {"snippet_id": 5159, "code": "=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]", "label": 0}, {"snippet_id": 70297, "code": "\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK", "label": 0}, {"snippet_id": 36001, "code": "=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards", "label": 0}, {"snippet_id": 41634, "code": " RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return", "label": 0}, {"snippet_id": 62138, "code": "' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']", "label": 0}, {"snippet_id": 95608, "code": " file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file): with open(local_file,", "label": 0}, {"snippet_id": 26286, "code": ", 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES", "label": 1}, {"snippet_id": 20356, "code": " raw_read_all as read_messages, raw_write_one as write_message ) from.socket import( Connection, create_server, create_client, close, recv_as_read, send_as_write, timeout as socket_timeout) from.threading", "label": 0}, {"snippet_id": 76825, "code": "'store_true', default=False, help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net.RequestPerformer() noproxy_rp.proxy='' noproxy_rp.timeout=c.noproxy_timeout noproxy_rp", "label": 0}, {"snippet_id": 31691, "code": ") if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io", "label": 0}, {"snippet_id": 45887, "code": " def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic", "label": 0}, {"snippet_id": 69807, "code": "(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" %", "label": 0}, {"snippet_id": 47466, "code": "(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex)", "label": 0}, {"snippet_id": 22032, "code": "=remote_user self.connection=connection self.timeout=timeout self.ssh_common_args=ssh_common_args self.sftp_extra_args=sftp_extra_args self.scp_extra_args=scp_extra_args self.ssh_extra_args=ssh_extra_args", "label": 0}, {"snippet_id": 30211, "code": "(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for", "label": 0}, {"snippet_id": 12328, "code": "(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request.json[\"action\"]==\"opened\": if config[\"message\"][\"opened", "label": 0}, {"snippet_id": 49445, "code": "=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources", "label": 0}, {"snippet_id": 24242, "code": ", 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle',", "label": 0}, {"snippet_id": 30906, "code": " combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations", "label": 0}, {"snippet_id": 78377, "code": " def forumwipe_loop(self): for f in self.forums: self.counter_tick() try: self.addtopic(self.msgfun(), self.sbjfun(), f) except exc.Success as e: self.counters['topics'] +=1 self.w.sleep(self.topic_successtimeout", "label": 1}, {"snippet_id": 25994, "code": "\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status", "label": 0}, {"snippet_id": 43686, "code": "): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder", "label": 0}, {"snippet_id": 83680, "code": " job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ", "label": 0}, {"snippet_id": 55530, "code": "(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation", "label": 0}, {"snippet_id": 86430, "code": " unicode_literals import errno import logging import os import re import textwrap from builtins import open from collections import defaultdict from contextlib import closing from hashlib import sha1 from xml", "label": 1}, {"snippet_id": 5510, "code": " for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault", "label": 0}, {"snippet_id": 95777, "code": " path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head(path): head, tail=os.path.split(path) return head def path_leaf(path): head, tail=os.path", "label": 0}, {"snippet_id": 83195, "code": " self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(*", "label": 0}, {"snippet_id": 31128, "code": "(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log", "label": 0}, {"snippet_id": 51163, "code": "\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format(", "label": 0}, {"snippet_id": 86974, "code": " incremental compiles will be written to the cache. ' 'This is unset by default, because it is generally a good precaution to cache ' 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls)", "label": 0}, {"snippet_id": 7104, "code": " in single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit", "label": 0}, {"snippet_id": 72332, "code": ") of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally", "label": 1}, {"snippet_id": 21770, "code": ".preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X[:, 1]=labelencoder_X_1.fit_transform(X[:, 1]) labelencoder_X_2=LabelEncoder() X[:, 2]=labelencoder_X_2.fit_transform(X[:", "label": 0}, {"snippet_id": 55636, "code": ": sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno", "label": 0}, {"snippet_id": 54947, "code": "))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 50601, "code": " func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None", "label": 0}, {"snippet_id": 8331, "code": "-1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does", "label": 1}, {"snippet_id": 93414, "code": ") master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for", "label": 0}, {"snippet_id": 24178, "code": ":cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi", "label": 0}, {"snippet_id": 44373, "code": " job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster,", "label": 0}, {"snippet_id": 76268, "code": "'Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_clear_data()) def bind_methods(self): for i, m, f, t in self.wz_bind_methods: self.set_route_type(i, m, t", "label": 0}, {"snippet_id": 59796, "code": "): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator(str(observable", "label": 0}, {"snippet_id": 63188, "code": " job_wrapper, job_destination) if not command_line: return try: dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters", "label": 0}, {"snippet_id": 20709, "code": "-', msg) if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter=self._get_awaiter_for_request(req, **args) self", "label": 0}, {"snippet_id": 94706, "code": " the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser", "label": 0}, {"snippet_id": 22066, "code": ".listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self, playbook, options=None, verbosity=0): if options is None: self.options=Options() self.options", "label": 0}, {"snippet_id": 63388, "code": " log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '') return command_line, client, remote_job_config, compute_environment def __prepare_input_files_locally", "label": 0}, {"snippet_id": 21042, "code": "(msg): if not match(msg): return msg, False lock.release() return msg, True self._add_handler(handler, handlername) try: yield finally: wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle", "label": 0}, {"snippet_id": 74938, "code": " if \"benchmark_aggregations\" in runtime_config.benchmark: self.benchmark_aggregations=config_str_to_bool(runtime_config.benchmark[\"benchmark_aggregations\"]) if \"benchmark_PCA\" in runtime_config.benchmark", "label": 1}, {"snippet_id": 94289, "code": "!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file", "label": 0}, {"snippet_id": 43600, "code": " from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules", "label": 0}, {"snippet_id": 45099, "code": "(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority", "label": 0}, {"snippet_id": 30524, "code": "=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m.group(\"value\")", "label": 0}, {"snippet_id": 94926, "code": "\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser", "label": 0}, {"snippet_id": 61806, "code": " between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2", "label": 0}, {"snippet_id": 31642, "code": "=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other", "label": 0}, {"snippet_id": 70110, "code": " print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if", "label": 0}, {"snippet_id": 12823, "code": " for line in hunk.target_lines(): if line.is_added: py_files[py_file].append(line.target_line_no) to_ignore=\",\".join(config[\"pycodestyle\"][\"ignore\"]) arg_to_ignore=\"\" if len(to_ignore) > 0: arg_to_ignore", "label": 0}, {"snippet_id": 89480, "code": ") and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`", "label": 0}, {"snippet_id": 73990, "code": " runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str", "label": 0}, {"snippet_id": 32931, "code": ": None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows", "label": 0}, {"snippet_id": 30847, "code": " raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded", "label": 0}, {"snippet_id": 89063, "code": ") synthetics=OrderedSet() for synthetic_address in self.build_graph.synthetic_addresses: if self.build_graph.get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target", "label": 0}, {"snippet_id": 34733, "code": " for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno", "label": 1}, {"snippet_id": 48538, "code": "=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards", "label": 0}, {"snippet_id": 82780, "code": "=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName) else: \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath", "label": 0}, {"snippet_id": 10441, "code": "\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3]", "label": 0}, {"snippet_id": 94520, "code": "(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed", "label": 0}, {"snippet_id": 50026, "code": " not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json", "label": 0}, {"snippet_id": 62160, "code": "{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else:", "label": 0}, {"snippet_id": 35242, "code": " (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches", "label": 1}, {"snippet_id": 17486, "code": " if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer", "label": 0}, {"snippet_id": 35544, "code": " Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str", "label": 0}, {"snippet_id": 92304, "code": ".Popen([sys.executable, '-c', 'import os; print(\"HORK\" in os.environ)'], stdout=new_output).wait() new_output.seek(0) self.assertEqual('False\\n', new_output.read()) def test_environment_negation(self):", "label": 0}, {"snippet_id": 37649, "code": "(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self", "label": 0}, {"snippet_id": 35599, "code": " self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None", "label": 0}, {"snippet_id": 36975, "code": "=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None", "label": 0}, {"snippet_id": 14870, "code": " import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self", "label": 0}, {"snippet_id": 43253, "code": ")), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize", "label": 0}, {"snippet_id": 68096, "code": " status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in", "label": 1}, {"snippet_id": 31442, "code": " s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join", "label": 0}, {"snippet_id": 26958, "code": "] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status']", "label": 0}, {"snippet_id": 48706, "code": ".output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f,", "label": 0}, {"snippet_id": 81334, "code": ".notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and", "label": 0}, {"snippet_id": 48204, "code": " \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item ", "label": 0}, {"snippet_id": 31655, "code": "=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd", "label": 0}, {"snippet_id": 91403, "code": "'sources', action=GatherSources).install('pyprep') task(name='py', action=PythonRun).install('run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install", "label": 0}, {"snippet_id": 70817, "code": ")], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header", "label": 0}, {"snippet_id": 14035, "code": "=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line,", "label": 0}, {"snippet_id": 11680, "code": " contained undefined variables!\") exit_code=EXIT_CODE_ERROR except SystemExit as e: exit_code=e.code except BaseException as e: LOG.error(e) exit_code=EXIT_CODE_ERROR finally: stop_time=datetime.now() LOG", "label": 0}, {"snippet_id": 92323, "code": " new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as(HORK=None): subprocess.Popen([sys.executable, '", "label": 0}, {"snippet_id": 45395, "code": "=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls", "label": 0}, {"snippet_id": 11024, "code": "[field] if field in response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime", "label": 1}, {"snippet_id": 79050, "code": " code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\":", "label": 0}, {"snippet_id": 72602, "code": "=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory=\"./data/input/\" download_directory=input_directory +\"download/\" temp_directory=\"./data/temp/\" vcf_directory=\"./data/vcf", "label": 1}, {"snippet_id": 53734, "code": " SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output:", "label": 0}, {"snippet_id": 2543, "code": "(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp", "label": 0}, {"snippet_id": 88554, "code": " on the command line. This set is strictly a subset of all targets in play for the run as returned by self.targets(). Note that for a command line invocation that uses wildcard selectors: or::, the targets", "label": 0}, {"snippet_id": 10529, "code": ").open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists", "label": 1}, {"snippet_id": 57199, "code": ", value ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model, 'mail_scene'): mail_context=model.mail_scene( objects=targets, field=field, value", "label": 0}, {"snippet_id": 63403, "code": "(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds", "label": 0}, {"snippet_id": 93262, "code": " default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self", "label": 0}, {"snippet_id": 92926, "code": "(), stdin_fd=tmp_stdin.fileno()): self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(stdin_data, sys.stdin.read()", "label": 0}, {"snippet_id": 5133, "code": " return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER):", "label": 0}, {"snippet_id": 25927, "code": "=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle", "label": 0}, {"snippet_id": 47671, "code": ".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 47209, "code": " in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"", "label": 0}, {"snippet_id": 77730, "code": "(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru' and t['forum']=='anonymous': try: add_target_exc(t['id'], t['user']) except ValueError", "label": 0}, {"snippet_id": 9201, "code": ",....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db", "label": 0}, {"snippet_id": 38318, "code": "[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config", "label": 0}, {"snippet_id": 8419, "code": "%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines", "label": 1}, {"snippet_id": 36354, "code": " wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): ", "label": 0}, {"snippet_id": 87052, "code": ".incremental_caching @memoized_property def _zinc(self): return Zinc.Factory.global_instance().create(self.context.products) def __init__(self, *args, **kwargs): super(BaseZincCompile, self).__init__(*args, ", "label": 1}, {"snippet_id": 56935, "code": ".test_tags.__next__() except StopIteration: return 0 if tag.pk==self.counter['tag']: return self.counter[self.key] return 0 def get_value_by_type(val, v_type): \"\"\" Exampls: 1. get_value_by_type('True', 'bool')", "label": 0}, {"snippet_id": 57986, "code": " bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id']=int(request.GET.get('bug_system_id', 1)) if request.GET.get('a') not in('add', 'remove'): return(None, 'Actions only allow \"add\" and \"remove\"", "label": 0}, {"snippet_id": 77393, "code": ".log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif type_==1: if not hasattr(self, 'pr_sock", "label": 0}, {"snippet_id": 81193, "code": " provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\"", "label": 0}, {"snippet_id": 94409, "code": ".debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len", "label": 0}, {"snippet_id": 52217, "code": " listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type)", "label": 0}, {"snippet_id": 37652, "code": " if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self", "label": 0}, {"snippet_id": 24040, "code": "(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*(//'| sed -e 's/).*//'\".format(output) err, output=shellutil.run_get_output", "label": 0}, {"snippet_id": 78501, "code": "['closed'] or t in self.pc.sets['bumplimit'] or t in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in forum %s:%s', lt, user,", "label": 1}, {"snippet_id": 19398, "code": "'--DEBUG_RECORD_SOCKET_READS', '--cmd-line', '--module', '--multiproc', '--multiprocess', '--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support", "label": 0}, {"snippet_id": 42561, "code": ")] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output", "label": 0}, {"snippet_id": 15350, "code": "=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0", "label": 0}, {"snippet_id": 5339, "code": ": dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires", "label": 0}, {"snippet_id": 41604, "code": "._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule", "label": 0}, {"snippet_id": 83547, "code": " job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '') return command_line, client, remote_job_config, compute_environment def __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task", "label": 0}, {"snippet_id": 29666, "code": ".group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing", "label": 0}, {"snippet_id": 3049, "code": ", host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def check_component(self", "label": 0}, {"snippet_id": 16701, "code": " debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info ", "label": 0}, {"snippet_id": 91133, "code": " from pants.backend.python.pants_requirement import PantsRequirement from pants.backend.python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement", "label": 0}, {"snippet_id": 70854, "code": ", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 67708, "code": " print \"Start of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print", "label": 0}, {"snippet_id": 49935, "code": " immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats,", "label": 0}, {"snippet_id": 72017, "code": " source, args): \"\"\"<network> Disconnects the network <network>. When all networks are disconnected, PyLink will automatically exit. To reconnect a network disconnected using this command, use REHASH to", "label": 0}, {"snippet_id": 56063, "code": " is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self", "label": 0}, {"snippet_id": 39232, "code": " return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None):", "label": 0}, {"snippet_id": 53909, "code": " try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\"", "label": 0}, {"snippet_id": 11715, "code": " flask import abort def update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: query=r\"INSERT INTO Users(repository, created_at", "label": 0}, {"snippet_id": 55319, "code": " list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun", "label": 0}, {"snippet_id": 52157, "code": " Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat", "label": 0}, {"snippet_id": 63409, "code": ".\"\"\" prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception", "label": 0}, {"snippet_id": 20939, "code": " listener still running') self._check_handlers() def _listen(self): try: for msg in self._conn.iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close", "label": 1}, {"snippet_id": 36937, "code": " if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies", "label": 0}, {"snippet_id": 89908, "code": "'.format(java, self._minimum_version, version)) if self._maximum_version: version=self._get_version(java) if version > self._maximum_version: raise self.Error('The java distribution at{} is too new; expecting", "label": 0}, {"snippet_id": 5494, "code": ": dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault", "label": 0}, {"snippet_id": 17995, "code": " not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR)", "label": 0}, {"snippet_id": 13809, "code": ".total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__", "label": 0}, {"snippet_id": 41468, "code": "(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self", "label": 0}, {"snippet_id": 54635, "code": "._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\"", "label": 0}, {"snippet_id": 80428, "code": ".proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print(\"[*] starting", "label": 0}, {"snippet_id": 9031, "code": ") cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial", "label": 0}, {"snippet_id": 4269, "code": ".isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry", "label": 0}, {"snippet_id": 27850, "code": " elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'", "label": 0}, {"snippet_id": 88001, "code": " classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published as \"fat jars\"(which appears to be the norm, since SBT doesn't support plugins with dependencies anyway)", "label": 0}, {"snippet_id": 6468, "code": "\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires", "label": 0}, {"snippet_id": 33034, "code": "=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name -", "label": 0}, {"snippet_id": 27633, "code": " self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 63461, "code": " if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User", "label": 0}, {"snippet_id": 61077, "code": " 0],[0, 1, 0, 0],[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_x \\theta/2}` \"", "label": 0}, {"snippet_id": 12064, "code": "\"\"\" Return a list of file names modified/added in the PR \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} diff_headers=headers.copy() diff_headers[\"Accept\"]=\"application/vnd.github.VERSION", "label": 0}, {"snippet_id": 63310, "code": ".get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters", "label": 0}, {"snippet_id": 14411, "code": "._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 74302, "code": " None: overwrite=False if output_location is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination", "label": 0}, {"snippet_id": 49548, "code": ".update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files,", "label": 0}, {"snippet_id": 1997, "code": ".Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n", "label": 0}, {"snippet_id": 27525, "code": " data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity'", "label": 0}, {"snippet_id": 77492, "code": ".spawnqueue)) def spawn_evaluators(self): self.log.info('Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator(", "label": 0}, {"snippet_id": 37856, "code": "(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards", "label": 0}, {"snippet_id": 73309, "code": "(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str", "label": 0}, {"snippet_id": 28269, "code": "'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi'", "label": 0}, {"snippet_id": 26856, "code": " self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle", "label": 0}, {"snippet_id": 94488, "code": " custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window", "label": 0}, {"snippet_id": 70963, "code": "=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %", "label": 0}, {"snippet_id": 12466, "code": "\"_link\"] +\" error_string_list[1]=\"[{0}:{1}]({2}):\".format(line, col, line_url) error_string=\" \".join(error_string_list) error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\"", "label": 0}, {"snippet_id": 87893, "code": "): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret=[] for name, cp_entries in plugin_jar_map.items(): ret.append('-S-Xplugin:{", "label": 0}, {"snippet_id": 27993, "code": "] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self", "label": 0}, {"snippet_id": 66829, "code": " nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command", "label": 0}, {"snippet_id": 58893, "code": "'password') response=self.client.post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self.plan.pk, 'case':[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3", "label": 0}, {"snippet_id": 71730, "code": "() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for", "label": 0}, {"snippet_id": 70439, "code": " back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration", "label": 0}, {"snippet_id": 85703, "code": ".dist.real_home: '/dev/null/remapped_by_pants/java_home/', get_buildroot(): '/dev/null/remapped_by_pants/buildroot/', self._zinc_factory.get_options().pants_workdir: '/dev/null/remapped_by_pants/workdir/'", "label": 0}, {"snippet_id": 48360, "code": "(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified", "label": 0}, {"snippet_id": 15466, "code": " not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else", "label": 0}, {"snippet_id": 4317, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"", "label": 1}, {"snippet_id": 23754, "code": ")/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\")", "label": 0}, {"snippet_id": 30484, "code": " raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len", "label": 0}, {"snippet_id": 45663, "code": ")) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return", "label": 0}, {"snippet_id": 44905, "code": ".\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if", "label": 0}, {"snippet_id": 21268, "code": " x)] newer_links=[x for x in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL", "label": 0}, {"snippet_id": 49430, "code": ", detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files", "label": 0}, {"snippet_id": 70470, "code": " import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine", "label": 0}, {"snippet_id": 22620, "code": " on the device \"\"\" return None def set_dhcp_hostname(self, hostname): \"\"\"Sets the DHCP hostname See `set_hostname` for an explanation of why I pass here :param hostname: The hostname to set on the device", "label": 0}, {"snippet_id": 94126, "code": ": self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server", "label": 0}, {"snippet_id": 47883, "code": ".subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self", "label": 0}, {"snippet_id": 89502, "code": " `home_path` or `bin_path` should be supplied. :param string home_path: the path to the java distribution's home dir :param string bin_path: the path to the java distribution's bin dir :param minimum_version", "label": 0}, {"snippet_id": 41719, "code": " IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output", "label": 1}, {"snippet_id": 41048, "code": ")) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments", "label": 0}, {"snippet_id": 78123, "code": "])) sig_sock.send_multipart(msg) def send_passthrough(frames): msg=[b'WipeManager'] msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames)) sig_sock.send_multipart(msg) def drop_users():", "label": 0}, {"snippet_id": 902, "code": "].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print", "label": 0}, {"snippet_id": 65747, "code": ".servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT", "label": 0}, {"snippet_id": 34434, "code": " @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def", "label": 0}, {"snippet_id": 34720, "code": "): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove", "label": 0}, {"snippet_id": 31759, "code": ") if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp", "label": 0}, {"snippet_id": 16902, "code": " timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync", "label": 0}, {"snippet_id": 64963, "code": " import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 25250, "code": " 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None", "label": 0}, {"snippet_id": 78343, "code": ".errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t, msg)) self.w.sleep(self.errortimeout) except exc.PermanentError as e: try: self.targets.remove(t) except ValueError as e", "label": 0}, {"snippet_id": 44165, "code": "=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity", "label": 0}, {"snippet_id": 38401, "code": " not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None", "label": 0}, {"snippet_id": 37597, "code": " if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 12239, "code": " file_to_check.py'.format( config=config) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"extra_results\"][filename]=stdout.decode(r.encoding).splitlines", "label": 0}, {"snippet_id": 49931, "code": ", cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait", "label": 0}, {"snippet_id": 54417, "code": " os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake", "label": 0}, {"snippet_id": 13858, "code": " from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS", "label": 0}, {"snippet_id": 12659, "code": "' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False return PERMITTED_TO_COMMENT def create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 15306, "code": " dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file", "label": 0}, {"snippet_id": 36623, "code": "=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables", "label": 0}, {"snippet_id": 86844, "code": ":-serial', '-C-Xlint:-path', '-S-deprecation', '-S-unchecked', '-S-Xlint') @classmethod def get_no_warning_args_default(cls): return('-C-nowarn', '-C-Xlint:none', '-S-nowarn', '-S-Xlint:none',) @classmethod", "label": 0}, {"snippet_id": 18389, "code": " return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open", "label": 0}, {"snippet_id": 16288, "code": "): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file", "label": 1}, {"snippet_id": 46583, "code": " def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError", "label": 0}, {"snippet_id": 39176, "code": ".resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to", "label": 0}, {"snippet_id": 83867, "code": " if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror", "label": 0}, {"snippet_id": 27478, "code": "\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return", "label": 0}, {"snippet_id": 53947, "code": " isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems,", "label": 0}, {"snippet_id": 28484, "code": " state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement", "label": 0}, {"snippet_id": 49999, "code": " in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag", "label": 0}, {"snippet_id": 94831, "code": "=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args", "label": 0}, {"snippet_id": 3764, "code": " kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def", "label": 0}, {"snippet_id": 53131, "code": " import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import", "label": 0}, {"snippet_id": 68293, "code": " [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type", "label": 0}, {"snippet_id": 88946, "code": " needed and registering a source root. :API: public \"\"\" rel_target_base=target_base or address.spec_path abs_target_base=os.path.join(get_buildroot(), rel_target_base) if not os.path.exists(abs_target_base", "label": 0}, {"snippet_id": 84985, "code": "(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default='2.12', choices=['2.10', '2.11", "label": 0}, {"snippet_id": 26475, "code": "\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self", "label": 0}, {"snippet_id": 5440, "code": " out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output", "label": 0}, {"snippet_id": 51398, "code": "=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be", "label": 1}, {"snippet_id": 39735, "code": " ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo):", "label": 0}, {"snippet_id": 76108, "code": "=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m])) def set_route_type(self, i, m, t): self.log.debug('Setting %s,%s type to %d', i, m, t) def", "label": 0}, {"snippet_id": 56690, "code": " return render(request, template_name, context_data) class _TagObjects(object): \"\"\" Used for getting the chosen object(TestPlan, TestCase or TestRun) from the database \"\"\" def __init__(self, request): \"\"", "label": 0}, {"snippet_id": 91692, "code": "': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=pex_snapshot.directory_digest, description='Resolve requirements:{}'.format(\", \".join(all_requirements)), output_files", "label": 1}, {"snippet_id": 524, "code": " found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(", "label": 0}, {"snippet_id": 40039, "code": " return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file", "label": 1}, {"snippet_id": 454, "code": "\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user", "label": 0}, {"snippet_id": 2534, "code": " Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name'],", "label": 0}, {"snippet_id": 75781, "code": " data): self.log.info('Resume signal %s recieved', repr((interface, method, data))) raise Resume() self.wz.set_sig_handler(b'WZWorker', b'resume', term_handler) self.running.set() def wz_connect(self):", "label": 1}, {"snippet_id": 57577, "code": ".mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(*", "label": 0}, {"snippet_id": 28806, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 42065, "code": "=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self", "label": 0}, {"snippet_id": 71133, "code": ".print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def", "label": 0}, {"snippet_id": 42145, "code": ".rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def", "label": 0}, {"snippet_id": 30158, "code": "(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item", "label": 0}, {"snippet_id": 46819, "code": " jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag", "label": 0}, {"snippet_id": 85355, "code": ".jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.base.build_environment import get_buildroot from pants.engine.fs import PathGlobs", "label": 1}, {"snippet_id": 89358, "code": " import AbstractClass from pants.util.osutil import OS_ALIASES, normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version):", "label": 0}, {"snippet_id": 16671, "code": "'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive", "label": 0}, {"snippet_id": 2292, "code": ":userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request", "label": 0}, {"snippet_id": 63234, "code": ", rewrite_paths=rewrite_paths, arbitrary_files=unstructured_path_rewrites, ) job_id=lwr_submit_job(client, client_job_description, remote_job_config) log.info(\"lwr job submitted with job_id %s\" % job_id", "label": 0}, {"snippet_id": 43045, "code": " **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable", "label": 0}, {"snippet_id": 54671, "code": "{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name", "label": 0}, {"snippet_id": 74342, "code": " from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true'", "label": 0}, {"snippet_id": 46167, "code": " values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb", "label": 0}, {"snippet_id": 10124, "code": " for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: set of formatted core keywords \"", "label": 0}, {"snippet_id": 68189, "code": ".status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), ", "label": 1}, {"snippet_id": 13357, "code": "\"https://api.github.com/repos/{}/contents/{}\" url=url.format(fullname, file) params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha", "label": 0}, {"snippet_id": 49217, "code": "(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None,", "label": 0}, {"snippet_id": 8144, "code": " bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field", "label": 0}, {"snippet_id": 62582, "code": ": expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(", "label": 0}, {"snippet_id": 33278, "code": "(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards", "label": 0}, {"snippet_id": 4105, "code": " running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this", "label": 0}, {"snippet_id": 58931, "code": " to \" \"update TestCases.\"}) def test_update_case_priority(self): self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field': ", "label": 0}, {"snippet_id": 45359, "code": " MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times)", "label": 1}, {"snippet_id": 79228, "code": "(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif", "label": 0}, {"snippet_id": 63936, "code": " job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path", "label": 0}, {"snippet_id": 32189, "code": " try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as", "label": 0}, {"snippet_id": 69543, "code": ".cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=", "label": 0}, {"snippet_id": 27581, "code": "'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp", "label": 0}, {"snippet_id": 17772, "code": "()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ ", "label": 0}, {"snippet_id": 78221, "code": ".logined: self._capdata=(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self): for t in self.targets: self.schedule(self.add_comment,(t", "label": 0}, {"snippet_id": 19351, "code": ".flush() result=load_source(tmp_file.name) assert result==native def test_url(httpbin): native={ 'origin': '127.0.0.1', 'args':{}, } source=httpbin.url +'/get' result=load_source(source) assert isinstance", "label": 0}, {"snippet_id": 18977, "code": " raw_source=six.text_type(response.content, encoding='utf-8') else: raw_source=response.content else: raw_source=source try: try: return json.loads(raw_source) except ValueError: pass try: return yaml.load", "label": 1}, {"snippet_id": 40289, "code": "): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^", "label": 0}, {"snippet_id": 22502, "code": "/pidof dhclient\") return ret[1] if ret[0]==0 else None def set_hostname(self, hostname): \"\"\"Set the static hostname of the device Normally, tmsh is used to set the hostname for the system. For our purposes", "label": 0}, {"snippet_id": 47289, "code": ")) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda", "label": 0}, {"snippet_id": 5318, "code": " keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var", "label": 0}, {"snippet_id": 70193, "code": " rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if", "label": 0}, {"snippet_id": 39564, "code": " rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules", "label": 0}, {"snippet_id": 65950, "code": "],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(", "label": 0}, {"snippet_id": 93707, "code": "])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component(node.component) if", "label": 0}, {"snippet_id": 53645, "code": " name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule", "label": 0}, {"snippet_id": 85554, "code": ".tool_jar_from_products(products, 'compiler-interface', cls.options_scope) def create(self, products): \"\"\"Create a Zinc instance from products active in the current Pants run. :param products: The active Pants run", "label": 0}, {"snippet_id": 63924, "code": " remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) if not remote_work_dir_copy: work_dir_outputs=self.get_work_dir_outputs( job_wrapper) else: work_dir_outputs=[] output_files=self.get_output_files", "label": 1}, {"snippet_id": 45529, "code": " raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod", "label": 0}, {"snippet_id": 91163, "code": " inject_init, python_test_runner from pants.backend.python.targets.python_app import PythonApp from pants.backend.python.targets.python_binary import PythonBinary from pants.backend.python.targets.python_distribution", "label": 0}, {"snippet_id": 18060, "code": " JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json", "label": 0}, {"snippet_id": 85332, "code": ".jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.shader import Shader from pants.backend.jvm.targets.scala_jar_dependency", "label": 0}, {"snippet_id": 12864, "code": ") with open(\"file_to_fix.py\", 'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess", "label": 0}, {"snippet_id": 68635, "code": " in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state=", "label": 0}, {"snippet_id": 59693, "code": "\"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has", "label": 0}, {"snippet_id": 1008, "code": ":configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request", "label": 0}, {"snippet_id": 89631, "code": " properties of this java distribution.\"\"\" return dict(self._get_system_properties(self.java)) @property def version(self): \"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is", "label": 0}, {"snippet_id": 95365, "code": " fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=ftp_config.directory) else: ftp.cwd(ftp_config.directory) file_counter=1 file_list_total=len(ftp_config.files) for", "label": 0}, {"snippet_id": 47717, "code": " collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake", "label": 0}, {"snippet_id": 64994, "code": ".ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self,", "label": 0}, {"snippet_id": 53137, "code": ", dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import", "label": 0}, {"snippet_id": 44517, "code": " cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds", "label": 0}, {"snippet_id": 70605, "code": "(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING", "label": 0}, {"snippet_id": 24655, "code": " if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\"", "label": 0}, {"snippet_id": 66456, "code": " client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name", "label": 0}, {"snippet_id": 27813, "code": " elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" ", "label": 0}, {"snippet_id": 18453, "code": " CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request", "label": 0}, {"snippet_id": 91989, "code": ", target): return target.has_sources(extension=tuple(self._native_source_extensions)) @memoized_property def _native_target_matchers(self): return{ SubclassesOf(PythonDistribution): self.pydist_has_native_sources", "label": 0}, {"snippet_id": 80677, "code": ".detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime", "label": 0}, {"snippet_id": 35641, "code": " defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name", "label": 0}, {"snippet_id": 80441, "code": "]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print(\"[*] starting at \"+str(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file", "label": 0}, {"snippet_id": 16422, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self):", "label": 0}, {"snippet_id": 63035, "code": " nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url\": url", "label": 0}, {"snippet_id": 52400, "code": ".dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the", "label": 0}, {"snippet_id": 66470, "code": " from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self)", "label": 0}, {"snippet_id": 26952, "code": "] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type", "label": 0}, {"snippet_id": 7700, "code": " _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords", "label": 0}, {"snippet_id": 75833, "code": " method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) t.tick() while self.running.is_set(): p(timeout*1000) if rs.finished: if rs.retry: msg=self.wz.make_req_msg(interface, method, data,", "label": 0}, {"snippet_id": 512, "code": " crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\":username", "label": 0}, {"snippet_id": 56442, "code": " def components(self): return Component.objects.filter(product__id=self.product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties(self): if self.request.GET.get('env_group_id')", "label": 0}, {"snippet_id": 25256, "code": "'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy", "label": 0}, {"snippet_id": 76870, "code": "(): if isinstance(t, threading.Timer): t.cancel() logger.info('Exiting') def interrupt_handler(signal, frame): pass def terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler", "label": 0}, {"snippet_id": 87641, "code": " dep in dependency_classpath: if dep.directory_digest is None: logger.warning( \"ClasspathEntry{} didn't have a DirectoryDigest, so won't be present for hermetic \" \"execution\".format(dep) ) if scala_path", "label": 1}, {"snippet_id": 47915, "code": ".shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io", "label": 0}, {"snippet_id": 81254, "code": " pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename", "label": 1}, {"snippet_id": 78590, "code": ") self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except", "label": 0}, {"snippet_id": 89390, "code": "'{} must be a string or a Revision object, given:{}'.format(name, version)) return version class Distribution(object): \"\"\"Represents a java distribution -either a JRE or a JDK installed on the local system", "label": 0}, {"snippet_id": 4566, "code": " fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext", "label": 0}, {"snippet_id": 62953, "code": " as lwr_submit_job from.lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__) __all__", "label": 0}, {"snippet_id": 8556, "code": " local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for", "label": 1}, {"snippet_id": 26300, "code": " MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES)", "label": 0}, {"snippet_id": 44046, "code": ".global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self", "label": 0}, {"snippet_id": 82715, "code": "\tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" ", "label": 0}, {"snippet_id": 36668, "code": ".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, ", "label": 0}, {"snippet_id": 38199, "code": " logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException,", "label": 0}, {"snippet_id": 33576, "code": "-immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif", "label": 0}, {"snippet_id": 60299, "code": "=set(operator_map.keys()) _observables={'Fock', 'X', 'P', 'Homodyne'} _circuits={} def __init__(self, wires, *, shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng", "label": 0}, {"snippet_id": 14943, "code": "=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout)", "label": 1}, {"snippet_id": 44157, "code": ": logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles", "label": 0}, {"snippet_id": 80031, "code": ". Needs -l switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser", "label": 0}, {"snippet_id": 80357, "code": "=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _", "label": 0}, {"snippet_id": 27571, "code": "._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type", "label": 0}, {"snippet_id": 10565, "code": "(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems", "label": 1}, {"snippet_id": 64135, "code": "] outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds", "label": 0}, {"snippet_id": 45125, "code": "=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo", "label": 0}, {"snippet_id": 79781, "code": ". Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote", "label": 0}, {"snippet_id": 41847, "code": " if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic", "label": 0}, {"snippet_id": 21690, "code": "', 'green'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i", "label": 0}, {"snippet_id": 6030, "code": ") try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible", "label": 1}, {"snippet_id": 48231, "code": " items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item,", "label": 0}, {"snippet_id": 70303, "code": "\"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR,", "label": 0}, {"snippet_id": 17963, "code": " handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json", "label": 1}, {"snippet_id": 32750, "code": ": comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order.__iter__()", "label": 0}, {"snippet_id": 53945, "code": " if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems", "label": 0}, {"snippet_id": 11503, "code": "'%s' created.\" % file_name) return file_name class YamlToIcinga(object): def __init__(self, yaml_config, header): self.icinga_lines=[] self.indent=CONFIG['INDENT'] self.icinga_lines.extend(header.serialize", "label": 0}, {"snippet_id": 84828, "code": "') class ScalaPlatform(JvmToolMixin, ZincLanguageMixin, InjectablesMixin, Subsystem): \"\"\"A scala platform. :API: public \"\"\" options_scope='scala' @classmethod def _create_jardep(cls, name, version): return", "label": 0}, {"snippet_id": 76578, "code": " as workers from dataloader import DataLoader from uniwipe import UniWipe from wipeskel import * import wzrpc from beon import regexp import pickle from logging import config from logconfig import logging_config", "label": 0}, {"snippet_id": 13682, "code": " Please read README.md for instructions.\") \r else:\r twitter=ChippyTwitter(consumerKey,consumerSecret,accessTokenKey,accessTokenSecret)\r \r web=WebFramework(talk)\r isRunning=False\r io.cleanup()\r sys.exit(1)\r", "label": 0}, {"snippet_id": 45109, "code": "=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate", "label": 0}, {"snippet_id": 46647, "code": " a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(", "label": 0}, {"snippet_id": 1145, "code": " JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer", "label": 0}, {"snippet_id": 68427, "code": "(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering),", "label": 0}, {"snippet_id": 29501, "code": " f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing", "label": 0}, {"snippet_id": 74049, "code": " runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types: self.compressor=compressor_temp if \"blosc_compression_algorithm\"", "label": 0}, {"snippet_id": 90019, "code": " 'SystemProperties.class')) cmd=[java, '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process", "label": 0}, {"snippet_id": 29625, "code": " f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards", "label": 0}, {"snippet_id": 25558, "code": "=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data[", "label": 0}, {"snippet_id": 25286, "code": ", '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list", "label": 1}, {"snippet_id": 4111, "code": ", and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six", "label": 0}, {"snippet_id": 81386, "code": "()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for", "label": 0}, {"snippet_id": 51001, "code": " be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException", "label": 0}, {"snippet_id": 83268, "code": " return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status", "label": 0}, {"snippet_id": 35126, "code": " self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value)", "label": 0}, {"snippet_id": 82123, "code": "\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action", "label": 0}, {"snippet_id": 95672, "code": " process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type", "label": 0}, {"snippet_id": 62405, "code": " proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator'", "label": 0}, {"snippet_id": 9920, "code": "{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={", "label": 0}, {"snippet_id": 13251, "code": "/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data[\"target_repo_branch\"]) request_json={ \"ref\": \"refs/heads/{}\".format(data[\"new_branch\"]), \"sha\": sha", "label": 0}, {"snippet_id": 35040, "code": "{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern", "label": 0}, {"snippet_id": 47333, "code": ".check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \"", "label": 0}, {"snippet_id": 88737, "code": ".run_tracker.background_worker_pool().submit_async_work_chain( work_chain, workunit_parent=workunit_parent, done_hook=done_hook) def background_worker_pool(self): \"\"\"Returns the pool to which tasks can submit", "label": 0}, {"snippet_id": 19721, "code": ".as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')) else: args.address=Address.as_client(clienthost, ns.pop('port')) module=ns.pop('module') filename=ns.pop", "label": 0}, {"snippet_id": 26514, "code": " states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self", "label": 0}, {"snippet_id": 24890, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle']", "label": 0}, {"snippet_id": 21032, "code": " match, handlername, timeout=None): if timeout is None: timeout=self.TIMEOUT lock, wait=get_locked_and_waiter() def handler(msg): if not match(msg): return msg, False lock.release() return msg, True self", "label": 0}, {"snippet_id": 54157, "code": ") if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule", "label": 0}, {"snippet_id": 38472, "code": " name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name", "label": 0}, {"snippet_id": 19477, "code": ") args=_parse_args(prog, supported) extra=pydevd +['--'] if script: extra +=script return args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index('--') except ValueError", "label": 0}, {"snippet_id": 82034, "code": " Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex", "label": 0}, {"snippet_id": 30424, "code": " ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\")", "label": 0}, {"snippet_id": 95973, "code": ".\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration", "label": 0}, {"snippet_id": 89794, "code": " distribution's java command. If this distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the path to the command of the given", "label": 0}, {"snippet_id": 28255, "code": "'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio'", "label": 0}, {"snippet_id": 72131, "code": " sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return except ValueError: irc.error('Invalid argument \"%s\" for <seconds>.'", "label": 0}, {"snippet_id": 34643, "code": "() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to", "label": 1}, {"snippet_id": 82560, "code": " local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[", "label": 0}, {"snippet_id": 33469, "code": " return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list", "label": 0}, {"snippet_id": 46784, "code": " collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils", "label": 1}, {"snippet_id": 30201, "code": " --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"", "label": 0}, {"snippet_id": 18902, "code": "\"\" Common entry point for loading some form of raw swagger schema. Supports: -python object(dictionary-like) -path to yaml file -path to json file -file object(json or yaml). -json string. -yaml string", "label": 0}, {"snippet_id": 56013, "code": "(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority", "label": 0}, {"snippet_id": 52158, "code": "(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def", "label": 0}, {"snippet_id": 77872, "code": ") continue self.add_spawns(new) except WorkerInterrupt: pass except Exception as e: self.log.exception(e) self.terminate() self.join_threads() if self.c.tcount > 0: self.save_users() self.save_targets(", "label": 0}, {"snippet_id": 69468, "code": " self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for", "label": 0}, {"snippet_id": 87276, "code": "._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f: for processor in processors: f", "label": 0}, {"snippet_id": 22678, "code": " be, built in to the system. :param username: The username that you want to add to the system :param expiration: The expiration date to use. We do not use this value. \"\"\" if self.get_userentry(username)", "label": 0}, {"snippet_id": 36752, "code": " return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles", "label": 0}, {"snippet_id": 85864, "code": " import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin", "label": 0}, {"snippet_id": 8523, "code": " \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile", "label": 1}, {"snippet_id": 33177, "code": " force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3", "label": 0}, {"snippet_id": 95443, "code": ", filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"\" Recursive function that automatically downloads", "label": 0}, {"snippet_id": 40026, "code": " \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self", "label": 1}, {"snippet_id": 26015, "code": "'wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >", "label": 0}, {"snippet_id": 46934, "code": " self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self", "label": 0}, {"snippet_id": 95216, "code": " It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records", "label": 0}, {"snippet_id": 12380, "code": "\"Hello @\" +author +\"! Thanks for updating the PR.\\n\\n\" else: comment_header=config[\"message\"][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len", "label": 0}, {"snippet_id": 56015, "code": ": self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self", "label": 0}, {"snippet_id": 23248, "code": "() for i in range(0, struct_size * expected, struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock", "label": 0}, {"snippet_id": 48323, "code": " files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError(", "label": 0}, {"snippet_id": 7347, "code": ") for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw)", "label": 0}, {"snippet_id": 23770, "code": "=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\") if ret: raise OSUtilError(\"Failed to get processor cores.\") try: return int(output) except ValueError: raise OSUtilError(\"Failed to get total memory", "label": 0}, {"snippet_id": 20538, "code": " RuntimeError('connection closed') def stop(): return self.closed write=send_as_write(self._sock) body=json.dumps(req) write_message(write, body, stop=stop) def _close(self): if self._ownsock: close(self", "label": 0}, {"snippet_id": 91414, "code": ").install('run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install('repl') task(name='setup-py", "label": 0}, {"snippet_id": 43374, "code": " the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex", "label": 0}, {"snippet_id": 66558, "code": " raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc", "label": 0}, {"snippet_id": 15955, "code": " _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5,", "label": 1}, {"snippet_id": 9571, "code": " KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=", "label": 0}, {"snippet_id": 28115, "code": " timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN)", "label": 1}, {"snippet_id": 60333, "code": " queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue", "label": 0}, {"snippet_id": 82349, "code": "\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames", "label": 0}, {"snippet_id": 2009, "code": "'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id", "label": 0}, {"snippet_id": 8750, "code": ") output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords", "label": 0}, {"snippet_id": 12436, "code": "\"])) for issue in issues: error_string=issue.replace(file +\":\", \"Line \") error_string_list=error_string.split(\" \") code=error_string_list[2] code_url=\"https://duckduckgo.com/?q=pep8%20{0}\".format(code)", "label": 0}, {"snippet_id": 30173, "code": ".add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an", "label": 0}, {"snippet_id": 82434, "code": ")s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: ", "label": 0}, {"snippet_id": 40382, "code": ") is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for", "label": 0}, {"snippet_id": 28874, "code": " self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240:", "label": 0}, {"snippet_id": 92436, "code": ") self.assertEqual(os.environ['AAA'], expected_output) self.assertEqual(os.environ['XXX'], expected_output) def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir", "label": 0}, {"snippet_id": 68144, "code": " view=\"fs\" else: view=view.lower() if view.startswith(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS", "label": 1}, {"snippet_id": 89801, "code": " command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the path to the command of the given name for this distribution. For example::: >>> d=Distribution() >", "label": 0}, {"snippet_id": 47320, "code": "\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output", "label": 0}, {"snippet_id": 58341, "code": "-navigation')) self.assertContains(response, urlencode({'people': self.user.email})) self.assertContains(response, urlencode({'author__email__startswith': self.user.email})) class TestIndex(BaseCaseRun)", "label": 0}, {"snippet_id": 5448, "code": "=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)", "label": 0}, {"snippet_id": 20260, "code": "=script, wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script(self, filename, *argv, **kwargs): if self.closed: raise RuntimeError('debug client", "label": 0}, {"snippet_id": 30855, "code": "{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self", "label": 0}, {"snippet_id": 26446, "code": "._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"", "label": 0}, {"snippet_id": 64606, "code": " installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on ", "label": 0}, {"snippet_id": 30758, "code": ".encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in", "label": 0}, {"snippet_id": 58650, "code": " 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings", "label": 0}, {"snippet_id": 25626, "code": "\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self", "label": 0}, {"snippet_id": 59104, "code": " OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion", "label": 0}, {"snippet_id": 91303, "code": ".select_interpreter import SelectInterpreter from pants.backend.python.tasks.setup_py import SetupPy from pants.backend.python.tasks.unpack_wheels import UnpackWheels from pants.build_graph.build_file_aliases import", "label": 0}, {"snippet_id": 4005, "code": ".cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config", "label": 0}, {"snippet_id": 68460, "code": " len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[", "label": 0}, {"snippet_id": 42603, "code": "(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output", "label": 0}, {"snippet_id": 59619, "code": " Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': for qubit in self.reg: self.eng.deallocate_qubit(qubit) def _deallocate3(self): \"", "label": 0}, {"snippet_id": 43983, "code": ", printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete", "label": 0}, {"snippet_id": 76382, "code": ": try: self.poll(timeout * 1000) except Resume as e: return def poll(self, timeout=None): try: socks=dict(self.poller.poll(timeout if timeout !=None else self.poll_timeout)) except zmq.ZMQError as e: self", "label": 1}, {"snippet_id": 40793, "code": "\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(*", "label": 0}, {"snippet_id": 34369, "code": "=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None", "label": 0}, {"snippet_id": 29621, "code": " else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append", "label": 0}, {"snippet_id": 76004, "code": " repr(data))) elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warning('Recvd unknown reply for(%s, %s) %s: %s', i, m, wzrpc.name_status", "label": 0}, {"snippet_id": 19593, "code": "'--port', '-m'): if arg=='-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith", "label": 1}, {"snippet_id": 40676, "code": "(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value,", "label": 0}, {"snippet_id": 1540, "code": " print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps", "label": 0}, {"snippet_id": 69460, "code": " CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\"", "label": 0}, {"snippet_id": 73190, "code": "\" Iterates through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir. Additionally moves *.vcf files to output_dir Note: This method searches through all subdirectories", "label": 0}, {"snippet_id": 16515, "code": " GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype", "label": 0}, {"snippet_id": 16093, "code": ") SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json", "label": 1}, {"snippet_id": 13596, "code": ".set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText):\r if( myText.find( \"twitter\") >=0):\r myText +=\"0", "label": 0}, {"snippet_id": 80295, "code": " args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any", "label": 0}, {"snippet_id": 62781, "code": " specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs", "label": 0}, {"snippet_id": 80212, "code": " in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t", "label": 0}, {"snippet_id": 43855, "code": " lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the", "label": 0}, {"snippet_id": 40344, "code": " latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names", "label": 0}, {"snippet_id": 30078, "code": " dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\"", "label": 0}, {"snippet_id": 66445, "code": "\"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print", "label": 0}, {"snippet_id": 26691, "code": " data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 22346, "code": " at the first opportunity I have(during the DVD mounting call). This ensures that the rest of the provisioning does not need to wait for mcpd to be available unless it absolutely wants to. :return bool", "label": 0}, {"snippet_id": 22582, "code": " tmsh will reject that value because it is not a fully qualified domain name. The proper value should have been bigip.xxx.yyy WAAgent will not fail if this command fails, but the hostname will not be what", "label": 0}, {"snippet_id": 85617, "code": " Zinc wrapper compiler classpath. :rtype: list of str \"\"\" return self._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list of str \"\"\"", "label": 0}, {"snippet_id": 84053, "code": " state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner,", "label": 0}, {"snippet_id": 60329, "code": ") def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self", "label": 1}, {"snippet_id": 24161, "code": " DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None]", "label": 1}, {"snippet_id": 7612, "code": ": dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires", "label": 0}, {"snippet_id": 72632, "code": " output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\": print(\"", "label": 0}, {"snippet_id": 26343, "code": " dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s", "label": 1}, {"snippet_id": 5113, "code": " field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories", "label": 0}, {"snippet_id": 3897, "code": " help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers", "label": 0}, {"snippet_id": 25433, "code": "=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self", "label": 0}, {"snippet_id": 78189, "code": " targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets", "label": 0}, {"snippet_id": 29368, "code": ".touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file", "label": 0}, {"snippet_id": 27569, "code": "'sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure", "label": 0}, {"snippet_id": 36689, "code": " self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json", "label": 0}, {"snippet_id": 88948, "code": " and registering a source root. :API: public \"\"\" rel_target_base=target_base or address.spec_path abs_target_base=os.path.join(get_buildroot(), rel_target_base) if not os.path.exists(abs_target_base): os", "label": 0}, {"snippet_id": 31925, "code": ": self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define", "label": 0}, {"snippet_id": 73619, "code": " print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length", "label": 1}, {"snippet_id": 25421, "code": "'Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type", "label": 0}, {"snippet_id": 23210, "code": ".SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)) param=struct.pack('iL', expected*struct_size, buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno(), 0x8912, param", "label": 0}, {"snippet_id": 38964, "code": ".path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies", "label": 0}, {"snippet_id": 5083, "code": "\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw], encode_for_xml(categories[kw]))) for field, keywords in", "label": 0}, {"snippet_id": 10732, "code": " return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words", "label": 1}, {"snippet_id": 93399, "code": "[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component", "label": 0}, {"snippet_id": 51028, "code": " def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards,", "label": 1}, {"snippet_id": 19868, "code": " stop_debugging(self): if self.closed: raise RuntimeError('debug client closed') if self._adapter is None: raise RuntimeError('debugger not running') if self._session is not None: self._detach() try: self", "label": 0}, {"snippet_id": 63583, "code": " model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally", "label": 0}, {"snippet_id": 17358, "code": ")) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE", "label": 0}, {"snippet_id": 19268, "code": ".write(source) tmp_file.file.seek(0) with open(tmp_file.name) as json_file: result=load_source(json_file) assert result==native def test_json_file_path(): native={'foo': 'bar'} source=json.dumps(native", "label": 0}, {"snippet_id": 38835, "code": "() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you", "label": 0}, {"snippet_id": 4341, "code": ".\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode", "label": 0}, {"snippet_id": 60994, "code": " np from scipy.linalg import expm, eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral", "label": 0}, {"snippet_id": 68614, "code": ", other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target", "label": 0}, {"snippet_id": 20037, "code": " wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start(*args, **kwargs): return DebugAdapter.start_wrapper_script( script, *args, **kwargs) else: start", "label": 0}, {"snippet_id": 35253, "code": "\"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError", "label": 1}, {"snippet_id": 15686, "code": ".PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from", "label": 0}, {"snippet_id": 37409, "code": " the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, ", "label": 0}, {"snippet_id": 64671, "code": ".FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1):", "label": 0}, {"snippet_id": 36971, "code": ") self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile", "label": 0}, {"snippet_id": 61280, "code": " array: square hermitian matrix. \"\"\" A=np.asarray(args[0]) if A.shape[0] !=A.shape[1]: raise ValueError(\"Observable must be a square matrix.\") if not np.allclose(A, A.conj().T, atol=tolerance): raise ValueError", "label": 0}, {"snippet_id": 22821, "code": " encrypting the password, the length of the salt value used to do it. \"\"\" cmd=\"/usr/bin/tmsh modify auth user{0} password '{1}'\".format(username, password) ret, output=shellutil.run_get_output(cmd, log_cmd", "label": 0}, {"snippet_id": 50477, "code": " message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate", "label": 0}, {"snippet_id": 65601, "code": "=STATUS_ANY view=self.view_support.get_view() if view is None: view=\"fs\" else: view=view.lower() if view.startswith(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(", "label": 1}, {"snippet_id": 7653, "code": " get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1", "label": 0}, {"snippet_id": 31163, "code": "[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove", "label": 0}, {"snippet_id": 49464, "code": " resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items)", "label": 0}, {"snippet_id": 91876, "code": " from pants.base.exceptions import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import", "label": 0}, {"snippet_id": 45425, "code": " return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self", "label": 0}, {"snippet_id": 57889, "code": ". \"\"\" data=request.POST.copy() comment=data.get('comment', None) if not comment: return say_no('Comments needed') run_ids=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no(", "label": 0}, {"snippet_id": 57380, "code": " tcms.core.utils.mailto import mailto mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: mail_context['context']['user']=request", "label": 0}, {"snippet_id": 46908, "code": ".temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add", "label": 0}, {"snippet_id": 27059, "code": "\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 32331, "code": " item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_,", "label": 0}, {"snippet_id": 22569, "code": ", Azure(Stack) considers that a perfectly valid name. When WAAgent gets around to running though, tmsh will reject that value because it is not a fully qualified domain name. The proper value should have", "label": 0}, {"snippet_id": 47315, "code": ", protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output", "label": 0}, {"snippet_id": 84102, "code": "=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client", "label": 1}, {"snippet_id": 44551, "code": ": logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down", "label": 0}, {"snippet_id": 61941, "code": " Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq", "label": 0}, {"snippet_id": 30752, "code": " return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if", "label": 0}, {"snippet_id": 15565, "code": " self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive():", "label": 0}, {"snippet_id": 23357, "code": ".common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil from azurelinuxagent.common.future import ustr class FreeBSDOSUtil(DefaultOSUtil): def __init__(self)", "label": 0}, {"snippet_id": 53691, "code": "\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output", "label": 0}, {"snippet_id": 43813, "code": " clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if", "label": 0}, {"snippet_id": 37632, "code": " **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable", "label": 0}, {"snippet_id": 12072, "code": "\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} diff_headers=headers.copy() diff_headers[\"Accept\"]=\"application/vnd.github.VERSION.diff\" auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD", "label": 0}, {"snippet_id": 66263, "code": ".set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size", "label": 0}, {"snippet_id": 93392, "code": " group in self.config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node", "label": 0}, {"snippet_id": 30196, "code": " the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self", "label": 0}, {"snippet_id": 29189, "code": "(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self", "label": 0}, {"snippet_id": 12797, "code": "[\"diff_url\"], headers=headers, auth=auth) patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) py_files={} for patchset in patch: if patchset.target_file[-3:]=='.py': py_file=patchset.target_file", "label": 0}, {"snippet_id": 82923, "code": "(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime", "label": 1}, {"snippet_id": 69841, "code": "\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING:", "label": 0}, {"snippet_id": 21563, "code": ".remove(link) elif x==1024: print(\"Reddytt: Forced exit detected. Saving and exiting.\") with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links,", "label": 1}, {"snippet_id": 62292, "code": " gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple(", "label": 0}, {"snippet_id": 22551, "code": " that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly", "label": 0}, {"snippet_id": 47282, "code": " omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output)", "label": 0}, {"snippet_id": 32013, "code": ".rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not", "label": 0}, {"snippet_id": 58651, "code": ".plan.pk, 'field': 'is_active', 'value': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET)", "label": 0}, {"snippet_id": 92817, "code": " '', False) for invalid in falsey: with self.assertRaises(InvalidZipPath): next(open_zip(invalid).gen) def test_open_zip_returns_realpath_on_badzipfile(self): with temporary_file() as not_zip: with temporary_dir", "label": 0}, {"snippet_id": 15269, "code": "._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive()", "label": 1}, {"snippet_id": 74096, "code": " configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to", "label": 0}, {"snippet_id": 63698, "code": " job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid", "label": 0}, {"snippet_id": 74383, "code": "\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False", "label": 0}, {"snippet_id": 5012, "code": " in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that", "label": 0}, {"snippet_id": 73234, "code": ":param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir=str(temp_dir) output_dir", "label": 0}, {"snippet_id": 6823, "code": " only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary", "label": 1}, {"snippet_id": 46257, "code": " a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os", "label": 0}, {"snippet_id": 28099, "code": " more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from", "label": 1}, {"snippet_id": 41924, "code": ".dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}", "label": 0}, {"snippet_id": 84727, "code": ".execute_process_synchronously(req, 'cloc',(WorkUnitLabel.TOOL,)) files_content_tuple=self.context._scheduler.product_request( FilesContent, [exec_result.output_directory_digest] )[0].dependencies files_content", "label": 1}, {"snippet_id": 61973, "code": " YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate", "label": 0}, {"snippet_id": 71010, "code": "(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\",", "label": 0}, {"snippet_id": 28913, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60:", "label": 0}, {"snippet_id": 24512, "code": "(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for", "label": 0}, {"snippet_id": 11185, "code": ": value=line.rstrip()[len(comment):] return value or current_value try: with open(file_name, 'r') as config_file: for line in config_file.xreadlines(): etag=extract(Header.ETAG_COMMENT, etag) mtime=extract", "label": 0}, {"snippet_id": 34395, "code": " name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path", "label": 0}, {"snippet_id": 61540, "code": " self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A(openqml.Operation or openqml.Expectation): operation/observable. Returns: array: matrix", "label": 0}, {"snippet_id": 64928, "code": " some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration", "label": 0}, {"snippet_id": 94263, "code": "(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger", "label": 0}, {"snippet_id": 47055, "code": " command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except", "label": 0}, {"snippet_id": 72816, "code": " import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path:", "label": 1}, {"snippet_id": 70503, "code": ".Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler", "label": 0}, {"snippet_id": 42402, "code": ".wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow", "label": 0}, {"snippet_id": 9982, "code": ": list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches", "label": 0}, {"snippet_id": 89382, "code": ".lenient(version) if version and not isinstance(version, Revision): raise ValueError('{} must be a string or a Revision object, given:{}'.format(name, version)) return version class Distribution(object", "label": 0}, {"snippet_id": 73703, "code": ") return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name", "label": 0}, {"snippet_id": 55134, "code": " subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 93198, "code": "/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND", "label": 0}, {"snippet_id": 58969, "code": " TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view method\"\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData() cls", "label": 0}, {"snippet_id": 9841, "code": " acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title", "label": 0}, {"snippet_id": 53215, "code": "=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun", "label": 0}, {"snippet_id": 16930, "code": "'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session", "label": 1}, {"snippet_id": 62204, "code": "(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend ", "label": 0}, {"snippet_id": 90439, "code": " be supplied.') self._possible_environments=possible_environments @property def jvm_locations(self): return itertools.chain(*(pe.jvm_locations for pe in self._possible_environments)) class _Locator(object", "label": 0}, {"snippet_id": 22046, "code": "=ssh_extra_args self.poll_interval=poll_interval self.seconds=seconds self.check=check self.syntax=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache=flush_cache self.listtasks=listtasks", "label": 0}, {"snippet_id": 38995, "code": "\"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph", "label": 0}, {"snippet_id": 11045, "code": " mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y %H:%M:%S %Z').strftime('%s') if mtime else int(time()) else: msg=\"Request %s returned with status %s. I don't know how to handle that.\" %(url, response", "label": 0}, {"snippet_id": 46680, "code": " to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not", "label": 0}, {"snippet_id": 46742, "code": ", max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat", "label": 0}, {"snippet_id": 69566, "code": ".startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt", "label": 0}, {"snippet_id": 48567, "code": " if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item", "label": 0}, {"snippet_id": 59116, "code": " in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()", "label": 0}, {"snippet_id": 12420, "code": "])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link\"])) for issue in issues: error_string=issue.replace(file +\":\", ", "label": 0}, {"snippet_id": 56079, "code": ".abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir):", "label": 0}, {"snippet_id": 80508, "code": ".cookies.keys(): \t\ts.cookies[key]=args.cookies[key] s.headers={'User-Agent':args.userAgent} s.trust_env=False if args.proxy: \tif args.proxy[\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t", "label": 0}, {"snippet_id": 90725, "code": " java distribution is required to have a jdk. :return: the located Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" for", "label": 0}, {"snippet_id": 75293, "code": ", 'No req handler for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value(tuple(iden), reqid) handler(reqid, interface, method, msg[1:]) return() def _parse_rep(self, iden, msg, reqid, seqnum", "label": 0}, {"snippet_id": 53459, "code": "(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def", "label": 0}, {"snippet_id": 32990, "code": ".is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len", "label": 0}, {"snippet_id": 55341, "code": ", cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds", "label": 0}, {"snippet_id": 10028, "code": ": \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"", "label": 0}, {"snippet_id": 58654, "code": ": 'is_active', 'value': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response", "label": 0}, {"snippet_id": 26006, "code": "._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low", "label": 0}, {"snippet_id": 66065, "code": " fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled", "label": 0}, {"snippet_id": 12916, "code": ".replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create", "label": 0}, {"snippet_id": 15819, "code": " _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not", "label": 0}, {"snippet_id": 63858, "code": "=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination job_wrapper.command_line", "label": 0}, {"snippet_id": 10607, "code": " text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list", "label": 1}, {"snippet_id": 71020, "code": "\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status", "label": 0}, {"snippet_id": 52186, "code": ".edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from", "label": 1}, {"snippet_id": 74771, "code": " if \"blosc_compression_level\" in runtime_config.vcf_to_zarr: blosc_compression_level_str=runtime_config.vcf_to_zarr[\"blosc_compression_level\"] if isint(blosc_compression_level_str): compression_level_int", "label": 0}, {"snippet_id": 91411, "code": "'py', action=PythonRun).install('run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install('repl", "label": 0}, {"snippet_id": 83203, "code": " string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy URL to a", "label": 0}, {"snippet_id": 93309, "code": ".new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader)", "label": 0}, {"snippet_id": 91429, "code": ") task(name='py', action=PythonRepl).install('repl') task(name='setup-py', action=SetupPy).install() task(name='py', action=PythonBinaryCreate).install('binary') task(name='py-wheels', action=LocalPythonDistributionArtifact", "label": 0}, {"snippet_id": 35907, "code": " level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P", "label": 0}, {"snippet_id": 89234, "code": " execute_process_synchronously(self, execute_process_request, name, labels=None): \"\"\"Executes a process(possibly remotely), and returns information about its output. :param execute_process_request: The ExecuteProcessRequest to run", "label": 1}, {"snippet_id": 33886, "code": " first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile", "label": 0}, {"snippet_id": 89811, "code": ": \"\"\"Returns the path to the command of the given name for this distribution. For example::: >>> d=Distribution() >>> jar=d.binary('jar') >>> jar '/usr/bin/jar' >>> If this distribution has no valid command", "label": 0}, {"snippet_id": 63565, "code": " stderr=run_results.get('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job", "label": 0}, {"snippet_id": 54969, "code": ".name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self", "label": 0}, {"snippet_id": 64394, "code": " self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list", "label": 0}, {"snippet_id": 93778, "code": " start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])", "label": 0}, {"snippet_id": 19204, "code": "\nfrom __future__ import unicode_literals import tempfile import collections import six import json import yaml from flex.core import load_source def test_native_mapping_is_passthrough(): source={'foo':", "label": 0}, {"snippet_id": 88895, "code": "._lock.release() return True def is_unlocked(self): \"\"\"Whether the global lock object is actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots", "label": 0}, {"snippet_id": 46601, "code": " return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist", "label": 0}, {"snippet_id": 89073, "code": ".get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter", "label": 0}, {"snippet_id": 39787, "code": ".params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow", "label": 0}, {"snippet_id": 92780, "code": " self.assertTrue(zf._allowZip64) def test_open_zipTrue(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=True) as zf: self.assertTrue(zf._allowZip64) def", "label": 0}, {"snippet_id": 57569, "code": " Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import", "label": 0}, {"snippet_id": 49974, "code": ":{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources", "label": 0}, {"snippet_id": 3559, "code": " if call(comp['cmd'][1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available", "label": 0}, {"snippet_id": 17, "code": " import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response import Response from rest_framework import viewsets from rest_framework.decorators import list_route from", "label": 0}, {"snippet_id": 87466, "code": "-interface', compiler_interface]) zinc_args.extend(['-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala-path', ':'.join(scala_path)", "label": 1}, {"snippet_id": 43704, "code": ".workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile", "label": 0}, {"snippet_id": 55296, "code": ".code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True", "label": 0}, {"snippet_id": 95349, "code": ".username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory", "label": 0}, {"snippet_id": 43101, "code": " to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not", "label": 0}, {"snippet_id": 41813, "code": "): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output", "label": 0}, {"snippet_id": 14270, "code": "=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive", "label": 1}, {"snippet_id": 56788, "code": " __init__(self, obj, tag_name): \"\"\" :param obj: the object for which the tag actions would be performed :type obj: either a:class:`tcms.testplans.models.TestPlan`, a:class:`tcms.testcases.models.TestCase`", "label": 0}, {"snippet_id": 36960, "code": ".dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority", "label": 0}, {"snippet_id": 61532, "code": ".binomial(self.shots, p0) ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A(openqml.Operation", "label": 0}, {"snippet_id": 1855, "code": "(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc", "label": 0}, {"snippet_id": 49169, "code": "=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self", "label": 0}, {"snippet_id": 5501, "code": " :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len", "label": 0}, {"snippet_id": 63854, "code": " in the queued/running state when Galaxy started\"\"\" job_state=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state", "label": 0}, {"snippet_id": 13588, "code": " EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def", "label": 0}, {"snippet_id": 66423, "code": "%s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else", "label": 1}, {"snippet_id": 4475, "code": "(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references", "label": 0}, {"snippet_id": 23566, "code": " -') if err: raise OSUtilError(\"Failed to delete root password: Failed to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info() if data[0]==ifname: return data[2].replace(", "label": 0}, {"snippet_id": 72757, "code": "\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files(ftp_server, ftp_directory, files=None): pass def", "label": 1}, {"snippet_id": 34662, "code": " WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)", "label": 0}, {"snippet_id": 10861, "code": ".info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH", "label": 1}, {"snippet_id": 85618, "code": " wrapper compiler classpath. :rtype: list of str \"\"\" return self._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list of str \"\"\" return", "label": 0}, {"snippet_id": 28581, "code": "'co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id", "label": 0}, {"snippet_id": 22560, "code": " hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly valid name. When WAAgent gets around to running though, tmsh will reject that value because it", "label": 0}, {"snippet_id": 83974, "code": "\"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url ", "label": 0}, {"snippet_id": 17855, "code": " import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers", "label": 0}, {"snippet_id": 86173, "code": "[settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) javac_cmd=['{}/bin/javac'.format(distribution.real_home)] javac_cmd", "label": 0}, {"snippet_id": 21751, "code": "\n import numpy as np import matplotlib.pyplot as plt import pandas as pd dataset=pd.read_csv('Churn_Modelling.csv') X=dataset.iloc[:, 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing", "label": 1}, {"snippet_id": 12215, "code": "=url.format(repository, after_commit_hash, file) r=requests.get(url, headers=headers, auth=auth) with open(\"file_to_check.py\", 'w+', encoding=r.encoding) as file_to_check: file_to_check.write(r.text) cmd", "label": 0}, {"snippet_id": 35989, "code": " UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag", "label": 0}, {"snippet_id": 15857, "code": ".unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json", "label": 0}, {"snippet_id": 44271, "code": " are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument", "label": 0}, {"snippet_id": 95559, "code": "(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp=ftp.nlst() if not os.path", "label": 0}, {"snippet_id": 74005, "code": "=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if", "label": 0}, {"snippet_id": 26499, "code": " of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data", "label": 0}, {"snippet_id": 19799, "code": " DebugSession class _LifecycleClient(Closeable): SESSION=DebugSession def __init__( self, addr=None, port=8888, breakpoints=None, connecttimeout=1.0, ): super(_LifecycleClient, self).__init__() self._addr", "label": 0}, {"snippet_id": 51318, "code": ".group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing", "label": 0}, {"snippet_id": 39629, "code": " ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo", "label": 0}, {"snippet_id": 26992, "code": "\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status", "label": 0}, {"snippet_id": 60951, "code": " return self._out @classmethod def capabilities(cls): \"\"\"Get the other capabilities of the plugin. Measurements, batching etc. Returns: dict[str->*]: results \"\"\" return cls._capabilities @abc.abstractmethod", "label": 1}, {"snippet_id": 36421, "code": "\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 14960, "code": "), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1", "label": 1}, {"snippet_id": 70972, "code": "(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(", "label": 0}, {"snippet_id": 76138, "code": " route type for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests(", "label": 0}, {"snippet_id": 63971, "code": " or[] return dependencies.DependenciesDescription( requirements=requirements, installed_tool_dependencies=installed_tool_dependencies, ) @staticmethod def __dependency_resolution( lwr_client): dependency_resolution", "label": 0}, {"snippet_id": 47821, "code": "=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self", "label": 0}, {"snippet_id": 25349, "code": " in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for", "label": 0}, {"snippet_id": 2607, "code": " master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '", "label": 0}, {"snippet_id": 66622, "code": ".Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle>\" % m.group", "label": 1}, {"snippet_id": 70225, "code": "), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info", "label": 0}, {"snippet_id": 3052, "code": "\"ssh %s 'hyperion --config %s/%s.yaml slave'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def check_component(self, comp): return", "label": 1}, {"snippet_id": 78382, "code": " try: self.addtopic(self.msgfun(), self.sbjfun(), f) except exc.Success as e: self.counters['topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self", "label": 0}, {"snippet_id": 60955, "code": "\"Get the other capabilities of the plugin. Measurements, batching etc. Returns: dict[str->*]: results \"\"\" return cls._capabilities @abc.abstractmethod def execute(self): \"\"\"Apply the queued operations to", "label": 1}, {"snippet_id": 80420, "code": " are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]", "label": 0}, {"snippet_id": 12084, "code": "/vnd.github.VERSION.diff\" auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository\"] after_commit_hash=data[\"after_commit_hash\"] author=data[\"author\"] diff_url=\"https:/", "label": 0}, {"snippet_id": 86839, "code": "-deprecation', '-C-Xlint:all', '-C-Xlint:-serial', '-C-Xlint:-path', '-S-deprecation', '-S-unchecked', '-S-Xlint') @classmethod def get_no_warning_args_default(cls): return('-C-nowarn', '-C-Xlint:none', ", "label": 0}, {"snippet_id": 64287, "code": ") results.append( self._dataset_path( local_output_path, remote_path)) return results def input_paths( self): local_input_paths=self._wrapper_input_paths results=[] for local_input_path in local_input_paths", "label": 0}, {"snippet_id": 65271, "code": "(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh", "label": 0}, {"snippet_id": 59305, "code": "(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered", "label": 0}, {"snippet_id": 71451, "code": " from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine", "label": 0}, {"snippet_id": 4459, "code": ", acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild", "label": 0}, {"snippet_id": 77312, "code": "): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess): type_=1 if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock()", "label": 0}, {"snippet_id": 42094, "code": "{name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads", "label": 0}, {"snippet_id": 16779, "code": ".join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self", "label": 0}, {"snippet_id": 42362, "code": "=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self", "label": 0}, {"snippet_id": 45351, "code": " product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os", "label": 1}, {"snippet_id": 8484, "code": " 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float", "label": 1}, {"snippet_id": 15894, "code": "): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler", "label": 0}, {"snippet_id": 43833, "code": " name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile", "label": 0}, {"snippet_id": 93000, "code": ".fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null", "label": 0}, {"snippet_id": 38712, "code": "(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule", "label": 0}, {"snippet_id": 65045, "code": ".type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): ", "label": 0}, {"snippet_id": 2190, "code": "\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 79364, "code": ".stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t", "label": 0}, {"snippet_id": 59514, "code": " result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not", "label": 0}, {"snippet_id": 70264, "code": " strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine", "label": 0}, {"snippet_id": 14495, "code": " if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer", "label": 0}, {"snippet_id": 13671, "code": " consumerKey.find( 'TWITTER') >=0):\r print( \"WARNING: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\") \r else:\r twitter=ChippyTwitter(consumerKey,consumerSecret,accessTokenKey,accessTokenSecret", "label": 0}, {"snippet_id": 41483, "code": " self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set(", "label": 0}, {"snippet_id": 82411, "code": " \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime", "label": 0}, {"snippet_id": 39586, "code": " rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate", "label": 0}, {"snippet_id": 94044, "code": "(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error", "label": 0}, {"snippet_id": 10804, "code": "=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file", "label": 1}, {"snippet_id": 1457, "code": "\" List all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address", "label": 0}, {"snippet_id": 94048, "code": " dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference", "label": 0}, {"snippet_id": 30495, "code": "\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value", "label": 0}, {"snippet_id": 84262, "code": "} if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception", "label": 0}, {"snippet_id": 42268, "code": " s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join", "label": 0}, {"snippet_id": 3743, "code": "=window.cmd('list-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window)", "label": 0}, {"snippet_id": 18154, "code": " FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from", "label": 0}, {"snippet_id": 57394, "code": " mail_context: mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=='case_run_status': for t in targets: field='close_date", "label": 0}, {"snippet_id": 29914, "code": " combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values,", "label": 0}, {"snippet_id": 20471, "code": ".VERBOSE: print('connected') self=cls(sock, ownsock=True) self._addr=addr return self def __init__(self, sock, ownsock=False): super(DebugSessionConnection, self).__init__() self._sock=sock self._ownsock", "label": 0}, {"snippet_id": 29446, "code": "(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self", "label": 0}, {"snippet_id": 50872, "code": ") @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError", "label": 1}, {"snippet_id": 46788, "code": " chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions", "label": 1}, {"snippet_id": 31214, "code": " resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(", "label": 0}, {"snippet_id": 10458, "code": " field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error(\"Please use bibclassify_cli from now on.\")", "label": 0}, {"snippet_id": 72865, "code": " to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors=True) def fetch_data_via_ftp(ftp_config, local_directory): \"\"\" Get benchmarking data from a remote ftp server. ", "label": 0}, {"snippet_id": 80260, "code": ".regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0", "label": 0}, {"snippet_id": 80923, "code": " from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t\tself.logger=logging.getLogger", "label": 0}, {"snippet_id": 39486, "code": ", resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have", "label": 0}, {"snippet_id": 48767, "code": " be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the", "label": 0}, {"snippet_id": 30620, "code": " Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name:", "label": 0}, {"snippet_id": 3211, "code": ") for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res: if \"depends\" in node.component: for dep in node.component['depends']: if", "label": 0}, {"snippet_id": 69680, "code": " have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d", "label": 0}, {"snippet_id": 43309, "code": ".update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards", "label": 0}, {"snippet_id": 64936, "code": " previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import *", "label": 0}, {"snippet_id": 15168, "code": " YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client", "label": 0}, {"snippet_id": 59420, "code": ".n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self", "label": 0}, {"snippet_id": 3356, "code": " kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found", "label": 0}, {"snippet_id": 47018, "code": "(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None", "label": 0}, {"snippet_id": 31234, "code": " ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\"", "label": 0}, {"snippet_id": 78067, "code": ", forum, domain) forums[domain].add((user, forum)) def rffu(urls): for user, domain, forum in r_udf.findall(urls): if len(forum) > 0: get_forum_id(forum) logger.info('Removing %s:%s from forums[%s]', user", "label": 0}, {"snippet_id": 75642, "code": "(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=(), kvargs={}, name=None, start_timer=None, poll_timeout=None, pargs=(),", "label": 0}, {"snippet_id": 95976, "code": "(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config", "label": 0}, {"snippet_id": 3003, "code": "(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file,", "label": 0}, {"snippet_id": 51640, "code": "*{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to", "label": 0}, {"snippet_id": 35193, "code": "\"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall", "label": 0}, {"snippet_id": 84582, "code": " def subsystem_dependencies(cls): return super(CountLinesOfCode, cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register): super(CountLinesOfCode, cls).register_options", "label": 0}, {"snippet_id": 13394, "code": "\"message\": \"Fix pep8 errors in{}\".format(file), \"content\": content_code, \"sha\": sha_blob, \"branch\": data.get(\"new_branch\"), } r=requests.put(url, json=request_json, headers=headers, auth=auth) def create_pr", "label": 0}, {"snippet_id": 66818, "code": ".debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=", "label": 0}, {"snippet_id": 40776, "code": "*comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, ", "label": 0}, {"snippet_id": 95992, "code": " provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length", "label": 0}, {"snippet_id": 25257, "code": ":weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy", "label": 0}, {"snippet_id": 91562, "code": " constraints={ constraint for target_adaptor in python_target_adaptors for constraint in python_setup.compatibility_or_constraints( getattr(target_adaptor, 'compatibility', None) ) } constraints_args=[", "label": 0}, {"snippet_id": 88890, "code": ": public \"\"\" if not self._lock.acquired: return False else: self._lock.release() return True def is_unlocked(self): \"\"\"Whether the global lock object is actively holding the lock. :API: public \"\"\" return", "label": 0}, {"snippet_id": 76078, "code": "}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warn('Status", "label": 0}, {"snippet_id": 84299, "code": " for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home default_config_file", "label": 0}, {"snippet_id": 27878, "code": "': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0", "label": 0}, {"snippet_id": 23607, "code": " shellutil.run(cmd, chk_err=False) def is_missing_default_route(self): \"\"\" For FreeBSD, the default broadcast goes to current default gw, not a all-ones broadcast address, need to specify the route manually to", "label": 0}, {"snippet_id": 79272, "code": "\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger", "label": 0}, {"snippet_id": 13281, "code": ".status_code !=200: data[\"error\"]=\"Could not create new branch in the fork\" def autopep8ify(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"],", "label": 0}, {"snippet_id": 73403, "code": ":param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str", "label": 0}, {"snippet_id": 10725, "code": " log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares", "label": 1}, {"snippet_id": 19711, "code": "(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')) else: args", "label": 0}, {"snippet_id": 66643, "code": ": print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd", "label": 0}, {"snippet_id": 47280, "code": "=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists", "label": 0}, {"snippet_id": 11822, "code": ".Mapping): base[key]=update_dict(base.get(key,{}), value) else: base[key]=head[key] else: base={key: head[key]} return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"", "label": 1}, {"snippet_id": 69373, "code": " \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"", "label": 0}, {"snippet_id": 42996, "code": "=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item:", "label": 0}, {"snippet_id": 51627, "code": "*wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, ", "label": 0}, {"snippet_id": 50365, "code": ".log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring", "label": 0}, {"snippet_id": 14883, "code": " _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler,", "label": 0}, {"snippet_id": 81875, "code": "\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize", "label": 0}, {"snippet_id": 61296, "code": ".\") if not np.allclose(A, A.conj().T, atol=tolerance): raise ValueError(\"Observable must be Hermitian.\") return A operator_map={ 'QubitStateVector': ket, 'QubitUnitary': unitary, 'Hermitian': hermitian", "label": 0}, {"snippet_id": 32888, "code": " self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript", "label": 0}, {"snippet_id": 85928, "code": " _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): ", "label": 0}, {"snippet_id": 36912, "code": " apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None)", "label": 0}, {"snippet_id": 14611, "code": "._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished')", "label": 0}, {"snippet_id": 41454, "code": ".params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for", "label": 0}, {"snippet_id": 25823, "code": "\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30:", "label": 0}, {"snippet_id": 23336, "code": ".fileutil as fileutil import azurelinuxagent.common.utils.shellutil as shellutil import azurelinuxagent.common.utils.textutil as textutil import azurelinuxagent.common.logger as logger from azurelinuxagent", "label": 0}, {"snippet_id": 34067, "code": " rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int", "label": 0}, {"snippet_id": 46062, "code": "\"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 57602, "code": " _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets", "label": 0}, {"snippet_id": 56469, "code": ".property.all() return EnvProperty.objects.all() def env_values(self): return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id')) def users(self): query=strip_parameters(self.request", "label": 0}, {"snippet_id": 68912, "code": ".Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs", "label": 0}, {"snippet_id": 95990, "code": "[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if", "label": 0}, {"snippet_id": 11965, "code": "\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://raw.githubusercontent.com/{}/{}/.pep8speaks.yml\" url=url.format(data[\"repository", "label": 0}, {"snippet_id": 42186, "code": " omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False", "label": 0}, {"snippet_id": 90309, "code": ": self._osx_java_home_exe=osx_java_home_exe @property def jvm_locations(self): if os.path.exists(self._osx_java_home_exe): try: plist=subprocess.check_output([self._osx_java_home_exe, '--failfast', '--xml", "label": 0}, {"snippet_id": 84488, "code": " remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep(", "label": 0}, {"snippet_id": 56501, "code": ".filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters=['app_form', 'format'] parameters=strip_parameters(request", "label": 1}, {"snippet_id": 8797, "code": " entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines", "label": 0}, {"snippet_id": 75734, "code": ", bytes(self.name, 'utf-8')) self.sig_sock=s s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) self.wz_sock=s self.wz=WZHandler() def term_handler(interface", "label": 1}, {"snippet_id": 92247, "code": " temporary_dir, temporary_file) from pants.util.process_handler import subprocess PATCH_OPTS=dict(autospec=True, spec_set=True) class ContextutilTest(unittest.TestCase): def test_empty_environment(self): with", "label": 0}, {"snippet_id": 35956, "code": " import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from", "label": 1}, {"snippet_id": 58159, "code": "(request): \"\"\" View for updating product drop-down\\n in a Ajax way. \"\"\" data=request.GET.copy() target=data.get('target', None) p_pks=data.get('p_ids', None) sep=data.get('sep', None) if target and p_pks", "label": 0}, {"snippet_id": 35379, "code": "}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format", "label": 0}, {"snippet_id": 18626, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else:", "label": 0}, {"snippet_id": 7349, "code": " in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw]", "label": 0}, {"snippet_id": 6967, "code": " following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,", "label": 0}, {"snippet_id": 83114, "code": " from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE", "label": 0}, {"snippet_id": 67501, "code": " import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 8643, "code": "(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is", "label": 0}, {"snippet_id": 62631, "code": " short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate", "label": 0}, {"snippet_id": 36615, "code": ".update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self", "label": 0}, {"snippet_id": 25334, "code": " weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions", "label": 1}, {"snippet_id": 46909, "code": ", self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in", "label": 0}, {"snippet_id": 68457, "code": ")\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets", "label": 0}, {"snippet_id": 571, "code": " print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action", "label": 0}, {"snippet_id": 6677, "code": " string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str ", "label": 0}, {"snippet_id": 55499, "code": ".scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile", "label": 0}, {"snippet_id": 85320, "code": ".dependency_context import DependencyContext from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.scala_platform", "label": 0}, {"snippet_id": 3383, "code": "(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" ", "label": 0}, {"snippet_id": 65482, "code": " print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed", "label": 0}, {"snippet_id": 33430, "code": " Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this", "label": 0}, {"snippet_id": 20017, "code": ": self._session.close() except ClosedError: pass if self._adapter is not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable", "label": 0}, {"snippet_id": 76804, "code": " default=3, help='Error timeout') parser.add_argument('--stop-on-closed', action='store_true', default=False, help='Forget about closed topics') parser.add_argument('--die-on-neterror', action='store_true", "label": 0}, {"snippet_id": 3941, "code": " care of the remote master invoking \" \"this command.\\nIf run with the --kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\",", "label": 0}, {"snippet_id": 40496, "code": "] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise", "label": 0}, {"snippet_id": 19202, "code": " raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors['response'].add_error(err.messages or getattr(err, 'detail'", "label": 0}, {"snippet_id": 35737, "code": " for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self", "label": 0}, {"snippet_id": 13606, "code": " EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText):\r if( myText.find( \"twitter\") >=0):\r myText +=\"0\"\r myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR", "label": 0}, {"snippet_id": 11888, "code": " Return True if the PR contains at least one Python file \"\"\" files=list(get_files_involved_in_pr(data).keys()) pythonic=False for file in files: if file[-3:]=='.py': pythonic=True break return pythonic", "label": 0}, {"snippet_id": 87051, "code": ".incremental_caching @memoized_property def _zinc(self): return Zinc.Factory.global_instance().create(self.context.products) def __init__(self, *args, **kwargs): super(BaseZincCompile, self).__init__(*args", "label": 1}, {"snippet_id": 69292, "code": " return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error", "label": 1}, {"snippet_id": 56789, "code": " __init__(self, obj, tag_name): \"\"\" :param obj: the object for which the tag actions would be performed :type obj: either a:class:`tcms.testplans.models.TestPlan`, a:class:`tcms.testcases.models.TestCase` or a", "label": 0}, {"snippet_id": 53551, "code": "**kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item", "label": 0}, {"snippet_id": 39685, "code": " decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 81425, "code": " following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e", "label": 0}, {"snippet_id": 65981, "code": " if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type", "label": 0}, {"snippet_id": 9476, "code": " output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords", "label": 0}, {"snippet_id": 39100, "code": "=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason", "label": 0}, {"snippet_id": 84370, "code": ", lwr_client, job_wrapper, remote_job_config): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={", "label": 0}, {"snippet_id": 8286, "code": " to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except", "label": 1}, {"snippet_id": 66132, "code": " status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" ", "label": 0}, {"snippet_id": 12739, "code": ") time_now=utc_time.strftime(\"%B %d, %Y at %H:%M Hours UTC\") comment +=\"\\n\\n comment=comment.format(time_now) query=\"https://api.github.com/repos/{}/issues/comments/{}\" query=query.format(data[\"repository", "label": 0}, {"snippet_id": 4039, "code": "\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui", "label": 0}, {"snippet_id": 5821, "code": " in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT", "label": 0}, {"snippet_id": 15300, "code": " as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '", "label": 1}, {"snippet_id": 83703, "code": "*get_client_kwds) def finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state(job_state) run_results=client.full_status() stdout=run_results.get(", "label": 0}, {"snippet_id": 31549, "code": ".dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self", "label": 0}, {"snippet_id": 46113, "code": "*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values", "label": 0}, {"snippet_id": 74923, "code": " benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"]", "label": 0}, {"snippet_id": 24146, "code": " Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo", "label": 1}, {"snippet_id": 39305, "code": ", overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self", "label": 0}, {"snippet_id": 80984, "code": "\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None \t\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) ", "label": 0}, {"snippet_id": 11476, "code": ") if yaml_config.host and self._is_newer(header_source, yaml_config.host_name): file_name=self.create_filename(yaml_config.host_name) yaml_icinga=YamlToIcinga(yaml_config, header_source) self.write_output", "label": 0}, {"snippet_id": 20990, "code": " self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[] for handle_msg", "label": 0}, {"snippet_id": 1708, "code": ".get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=", "label": 0}, {"snippet_id": 503, "code": "\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" ", "label": 0}, {"snippet_id": 26435, "code": "._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name", "label": 0}, {"snippet_id": 48023, "code": " values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards", "label": 0}, {"snippet_id": 15452, "code": "( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 4187, "code": " extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text", "label": 0}, {"snippet_id": 88431, "code": ".build_graph=build_graph self.build_file_parser=build_file_parser self.address_mapper=address_mapper self.run_tracker=run_tracker self._log=self.Log(run_tracker) self._target_base=target_base or Target self", "label": 0}, {"snippet_id": 21900, "code": " class Options(object): def __init__(self, verbosity=None, inventory=None, listhosts=None, subset=None, module_paths=None, extra_vars=None, forks=None, ask_vault_pass=None, vault_password_files=None, new_vault_password_file", "label": 0}, {"snippet_id": 22466, "code": " chk_err=False) def start_agent_service(self): return shellutil.run(\"/sbin/service waagent start\", chk_err=False) def register_agent_service(self): return shellutil.run(\"/sbin/chkconfig --add waagent\",", "label": 0}, {"snippet_id": 96017, "code": "] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width", "label": 0}, {"snippet_id": 96031, "code": "\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)) if conversion_config.compressor==\"Blosc\": compressor=Blosc(cname=conversion_config.blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level", "label": 0}, {"snippet_id": 11123, "code": " is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self.mtime, other.mtime) > 0 else: return False def serialize(self): lines=[] time_string=strftime(\"%Y-%m-%d %H:%M:%S\"", "label": 0}, {"snippet_id": 87477, "code": "'-scala-path', ':'.join(scala_path)]) zinc_args.extend(self._javac_plugin_args(javac_plugin_map)) scalac_plugin_search_classpath=( (set(absolute_classpath) | set(self.scalac_plugin_classpath_elements()", "label": 0}, {"snippet_id": 51150, "code": " get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait", "label": 0}, {"snippet_id": 65020, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s ", "label": 0}, {"snippet_id": 35838, "code": "(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load", "label": 0}, {"snippet_id": 49557, "code": ".name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self,", "label": 0}, {"snippet_id": 95595, "code": " file_list_total, file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url,", "label": 0}, {"snippet_id": 34995, "code": "(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name ", "label": 0}, {"snippet_id": 36564, "code": ": self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since", "label": 0}, {"snippet_id": 58426, "code": " test_refuse_if_missing_comment(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'run':[self.case_run_1.pk, self.case_run_2", "label": 0}, {"snippet_id": 6743, "code": "(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0", "label": 0}, {"snippet_id": 65183, "code": ") def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 71920, "code": ".append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i", "label": 0}, {"snippet_id": 87442, "code": ".extend([ '-log-level', self.get_options().level, '-analysis-cache', analysis_cache, '-classpath', ':'.join(relative_classpath), '-d', classes_dir, ]) if not self.get_options().colors: zinc_args.append(", "label": 0}, {"snippet_id": 95096, "code": " benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]", "label": 1}, {"snippet_id": 66905, "code": " in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt", "label": 1}, {"snippet_id": 25690, "code": "='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state", "label": 0}, {"snippet_id": 55358, "code": " printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync", "label": 0}, {"snippet_id": 32977, "code": " def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self,", "label": 0}, {"snippet_id": 87832, "code": "\").{} is not.'.format(path)) def log_zinc_file(self, analysis_file): self.context.log.debug('Calling zinc on:{}({})' .format(analysis_file, hash_file(analysis_file).upper() if os.path.exists(analysis_file", "label": 0}, {"snippet_id": 31777, "code": "(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output", "label": 0}, {"snippet_id": 163, "code": ".crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap", "label": 1}, {"snippet_id": 57876, "code": " @require_POST def comment_case_runs(request): \"\"\" Add comment to one or more caseruns at a time. \"\"\" data=request.POST.copy() comment=data.get('comment', None) if not comment: return say_no('Comments needed", "label": 0}, {"snippet_id": 61138, "code": " Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm(-1j * theta/2", "label": 0}, {"snippet_id": 8589, "code": " file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\")", "label": 1}, {"snippet_id": 66590, "code": " Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands", "label": 0}, {"snippet_id": 17111, "code": " SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'", "label": 0}, {"snippet_id": 61798, "code": "[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U),", "label": 0}, {"snippet_id": 39230, "code": "(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False", "label": 0}, {"snippet_id": 2519, "code": " data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']:", "label": 0}, {"snippet_id": 15754, "code": "']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list", "label": 0}, {"snippet_id": 2450, "code": " as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self", "label": 0}, {"snippet_id": 27414, "code": "\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self", "label": 0}, {"snippet_id": 8790, "code": ": log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry", "label": 0}, {"snippet_id": 34510, "code": "\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake", "label": 1}, {"snippet_id": 23468, "code": " account:{0}, \" \"retcode:{1}, \" \"output:{2}\").format(username, retcode, out)) def del_account(self, username): if self.is_sys_user(username): logger.error(\"{0} is a system user. Will not delete it.\", username", "label": 0}, {"snippet_id": 20523, "code": "(read, stop=stop): if self.VERBOSE: print(repr(msg)) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed write=send_as_write", "label": 0}, {"snippet_id": 15485, "code": "'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments", "label": 0}, {"snippet_id": 66707, "code": ".get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException", "label": 0}, {"snippet_id": 47063, "code": "\"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 75791, "code": "() self.wz.set_sig_handler(b'WZWorker', b'resume', term_handler) self.running.set() def wz_connect(self): self.wz_sock.connect(self.wz_addr) def wz_wait_reply(self, fun, interface, method, data, reqid=None", "label": 1}, {"snippet_id": 50647, "code": " def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow", "label": 0}, {"snippet_id": 19386, "code": "/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py \"\"\" PYDEVD_OPTS={ '--file', '--client', '--vm_type', } PYDEVD_FLAGS={ '--DEBUG',", "label": 0}, {"snippet_id": 85809, "code": ")) else: dependencies=DependencyContext.global_instance().all_dependencies(target) all_extra_cp_entries=list(self._compiler_plugins_cp_entries()) if extra_cp_entries: all_extra_cp_entries.extend(extra_cp_entries", "label": 0}, {"snippet_id": 38426, "code": " if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count", "label": 0}, {"snippet_id": 14253, "code": " __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options)", "label": 0}, {"snippet_id": 40469, "code": ".append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try", "label": 0}, {"snippet_id": 88721, "code": "=background_root_workunit) workunit_parent=workunit_parent_ctx.__enter__() done_hook=lambda: workunit_parent_ctx.__exit__(None, None, None) else: workunit_parent=background_root_workunit done_hook=None", "label": 0}, {"snippet_id": 72591, "code": ", type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory", "label": 1}, {"snippet_id": 64655, "code": " Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler", "label": 0}, {"snippet_id": 27493, "code": " unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states", "label": 0}, {"snippet_id": 78641, "code": "': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run())) except BaseException as e: log.logger.exception", "label": 0}, {"snippet_id": 22836, "code": " password '{1}'\".format(username, password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for{0}:{1}\".format(username, output) ", "label": 0}, {"snippet_id": 89836, "code": " name raises Distribution.Error. If this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if not isinstance(name, str): raise ValueError('name must be a binary name, given{} of", "label": 0}, {"snippet_id": 77048, "code": ".hooks['post_login'].append(upload_avatar) yield w class WipeManager: def __init__(self, config, *args, **kvargs): super().__init__(*args, **kvargs) self.newproxyfile='newproxies.txt' self.proxylist=set(", "label": 0}, {"snippet_id": 75391, "code": " make_router_req_msg(self, iden, interface, method, args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface, method, args, fun, reqid)) return msg def make_router_rep_msg", "label": 0}, {"snippet_id": 95725, "code": "(pathlib.Path(temp_dir, file_output_str)) print(\"[Setup][Data] Decompressing file:{}\".format(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip(path_str, path_temp_output) pathlist_vcf_temp", "label": 0}, {"snippet_id": 90906, "code": " required to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" try: return cls.global_instance(", "label": 0}, {"snippet_id": 8786, "code": " print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('", "label": 0}, {"snippet_id": 9053, "code": "(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw", "label": 0}, {"snippet_id": 62621, "code": " ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]", "label": 0}, {"snippet_id": 88256, "code": " get_buildroot, get_scm from pants.base.worker_pool import SubprocPool from pants.base.workunit import WorkUnit, WorkUnitLabel from pants.build_graph.target import Target from pants.engine.isolated_process import", "label": 1}, {"snippet_id": 3156, "code": " cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name) send_main_session_command(self.session, cmd) def start_remote_clone_session", "label": 0}, {"snippet_id": 92711, "code": ": class FakeClock(object): def __init__(self): self._time=0.0 def time(self): ret=self._time self._time +=0.0001 return ret def sleep(self, duration): self._time +=duration clock=FakeClock() with Timer", "label": 0}, {"snippet_id": 73461, "code": " output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a Zarr format. Only", "label": 1}, {"snippet_id": 81104, "code": ") \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName", "label": 0}, {"snippet_id": 60837, "code": "+self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ' ", "label": 0}, {"snippet_id": 78064, "code": "', user, forum, domain) forums[domain].add((user, forum)) def rffu(urls): for user, domain, forum in r_udf.findall(urls): if len(forum) > 0: get_forum_id(forum) logger.info('Removing %s:%s from forums[", "label": 0}, {"snippet_id": 94755, "code": "--kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group", "label": 0}, {"snippet_id": 25875, "code": "'gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\"", "label": 0}, {"snippet_id": 81939, "code": "\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote server where uploads are put. Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar", "label": 0}, {"snippet_id": 66932, "code": " self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list", "label": 0}, {"snippet_id": 85402, "code": " ZINC_EXTRACT_MAIN='org.pantsbuild.zinc.extractor.Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope=", "label": 0}, {"snippet_id": 71134, "code": ") status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return", "label": 0}, {"snippet_id": 63276, "code": " lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state)", "label": 0}, {"snippet_id": 15852, "code": " from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS", "label": 0}, {"snippet_id": 11982, "code": "=url.format(data[\"repository\"], data[\"after_commit_hash\"]) r=requests.get(url, headers=headers, auth=auth) if r.status_code==200: try: new_config=yaml.load(r.text) config=update_dict(config, new_config", "label": 0}, {"snippet_id": 58930, "code": " to \" \"update TestCases.\"}) def test_update_case_priority(self): self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field'", "label": 0}, {"snippet_id": 28340, "code": " pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found", "label": 1}, {"snippet_id": 35883, "code": " JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" ", "label": 0}, {"snippet_id": 34557, "code": ") def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file", "label": 0}, {"snippet_id": 73231, "code": " unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir", "label": 0}, {"snippet_id": 50280, "code": " ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule", "label": 0}, {"snippet_id": 77779, "code": "): for t in self.threads: t.join() def send_passthrough(self, interface, method, frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) self.th_sock.send_multipart(msg", "label": 0}, {"snippet_id": 55147, "code": " if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for", "label": 0}, {"snippet_id": 36665, "code": " omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ ", "label": 0}, {"snippet_id": 93021, "code": " self._stdio_as_tempfiles(): with stdio_as(stdout_fd=-1, stderr_fd=-1, stdin_fd=-1): self.assertEqual('', sys.stdin.read()) print('garbage', file=sys.stdout) print('garbage', file=sys.stderr) def test_signal_handler_as", "label": 0}, {"snippet_id": 47367, "code": "(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log", "label": 0}, {"snippet_id": 55368, "code": "=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:", "label": 0}, {"snippet_id": 403, "code": "(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password", "label": 0}, {"snippet_id": 77857, "code": "): if self.c.tcount==0: self.inter_sleep(5) continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except WorkerInterrupt: pass except", "label": 0}, {"snippet_id": 91265, "code": ".backend.python.tasks.python_binary_create import PythonBinaryCreate from pants.backend.python.tasks.python_bundle import PythonBundle from pants.backend.python.tasks.python_repl import PythonRepl from", "label": 0}, {"snippet_id": 54941, "code": " filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles)", "label": 0}, {"snippet_id": 18317, "code": "-idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self", "label": 0}, {"snippet_id": 28086, "code": " to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else:", "label": 1}, {"snippet_id": 23252, "code": " * expected, struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name", "label": 0}, {"snippet_id": 90287, "code": ".split(os.pathsep): yield self.Location.from_bin(bin_path) class _OSXEnvironment(_DistributionEnvironment): _OSX_JAVA_HOME_EXE='/usr/libexec/java_home' @classmethod def standard(cls): return cls(cls._OSX_JAVA_HOME_EXE", "label": 0}, {"snippet_id": 34642, "code": ".check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError", "label": 1}, {"snippet_id": 52711, "code": " filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self", "label": 0}, {"snippet_id": 33120, "code": ".info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False", "label": 0}, {"snippet_id": 89783, "code": ".path.realpath(self.home) @property def java(self): \"\"\"Returns the path to this distribution's java command. If this distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary", "label": 0}, {"snippet_id": 29951, "code": " comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards", "label": 0}, {"snippet_id": 68276, "code": ".append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic", "label": 0}, {"snippet_id": 15023, "code": "='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data", "label": 0}, {"snippet_id": 36224, "code": " KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self", "label": 0}, {"snippet_id": 94371, "code": "[1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) >", "label": 0}, {"snippet_id": 51897, "code": "): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name", "label": 0}, {"snippet_id": 77719, "code": " domains, 'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru'", "label": 0}, {"snippet_id": 93690, "code": " %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps", "label": 0}, {"snippet_id": 15474, "code": ")): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request", "label": 0}, {"snippet_id": 92932, "code": " 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(stdin_data, sys.stdin.read().strip()) print(stdout_data, file=sys.stdout) yield print(stderr_data,", "label": 0}, {"snippet_id": 32937, "code": "=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return", "label": 0}, {"snippet_id": 84236, "code": "\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return", "label": 0}, {"snippet_id": 41524, "code": " if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self", "label": 0}, {"snippet_id": 56451, "code": " EnvGroup.objects.all() def env_properties(self): if self.request.GET.get('env_group_id'): return EnvGroup.objects.get(id=self.request.GET['env_group_id']).property.all() return EnvProperty.objects.all", "label": 0}, {"snippet_id": 89204, "code": ". :API: public :param string root: The path to scan; by default, the build root. :returns: A new build graph encapsulating the targets found. \"\"\" build_graph=self.build_graph.clone_new() for address in", "label": 0}, {"snippet_id": 45260, "code": " @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def", "label": 0}, {"snippet_id": 92890, "code": " stdin_data=u('stdio') stdout_data=u('stdout') stderr_data=u('stderr') with temporary_file(binary_mode=False) as tmp_stdin,\\ temporary_file(binary_mode=False) as tmp_stdout,\\ temporary_file(binary_mode=False", "label": 0}, {"snippet_id": 86235, "code": " str(settings.source_level), '-target', str(settings.target_level), ]) if self.execution_strategy==self.HERMETIC: javac_cmd.extend([ '-d', '.', ]) else: javac_cmd.extend([ '-d', ctx.classes_dir, ]) javac_cmd", "label": 0}, {"snippet_id": 30939, "code": " return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime", "label": 0}, {"snippet_id": 43171, "code": "=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems", "label": 0}, {"snippet_id": 57653, "code": " try: new_status=TestCaseStatus.objects.get(pk=self.new_value) except TestCaseStatus.DoesNotExist: raise ObjectDoesNotExist('The status you choose does not exist.') update_object=self.get_update_targets", "label": 0}, {"snippet_id": 21245, "code": ".where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get('href') for a in soup('a') if a.get('href')] new_links=[x for x in links if re.match(\"^https://youtu\\.be\",", "label": 0}, {"snippet_id": 12715, "code": "=old_comment[\"id\"] break if last_comment_id is None: response=requests.post(query, json={\"body\": comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime", "label": 0}, {"snippet_id": 59220, "code": " SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT", "label": 0}, {"snippet_id": 43771, "code": " rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule", "label": 0}, {"snippet_id": 46856, "code": " format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict", "label": 0}, {"snippet_id": 52338, "code": " f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output", "label": 0}, {"snippet_id": 56968, "code": "'int') ('5', None) 4. get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.'", "label": 0}, {"snippet_id": 10143, "code": " spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i])", "label": 0}, {"snippet_id": 61433, "code": " for operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError(", "label": 0}, {"snippet_id": 38378, "code": "( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause:", "label": 0}, {"snippet_id": 92435, "code": "', os.environ) self.assertEqual(os.environ['AAA'], expected_output) self.assertEqual(os.environ['XXX'], expected_output) def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir", "label": 0}, {"snippet_id": 5826, "code": "(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text", "label": 0}, {"snippet_id": 8594, "code": ".\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path", "label": 1}, {"snippet_id": 45790, "code": " contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex", "label": 0}, {"snippet_id": 92480, "code": " pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2)", "label": 0}, {"snippet_id": 38373, "code": ") @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause", "label": 0}, {"snippet_id": 51159, "code": ") if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after", "label": 0}, {"snippet_id": 73797, "code": " runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"ftp\"): if \"enabled\" in runtime_config.ftp: self.enabled=config_str_to_bool(runtime_config.ftp[", "label": 0}, {"snippet_id": 80296, "code": "==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry", "label": 0}, {"snippet_id": 95277, "code": " Creates directories for the path specified. :param path: The path to create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree", "label": 0}, {"snippet_id": 83121, "code": "( __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home", "label": 0}, {"snippet_id": 28214, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle", "label": 0}, {"snippet_id": 38554, "code": ", forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync", "label": 0}, {"snippet_id": 53571, "code": "._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output:", "label": 0}, {"snippet_id": 16649, "code": " UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not", "label": 0}, {"snippet_id": 37888, "code": " None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self", "label": 0}, {"snippet_id": 68146, "code": " if view.startswith(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags", "label": 0}, {"snippet_id": 50950, "code": " ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod", "label": 0}, {"snippet_id": 34493, "code": " can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return", "label": 0}, {"snippet_id": 40709, "code": "-first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with", "label": 0}, {"snippet_id": 76561, "code": "') import os, signal, logging, threading, re, traceback, time import random import zmq from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import", "label": 0}, {"snippet_id": 55630, "code": "(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update", "label": 0}, {"snippet_id": 1114, "code": " wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n'", "label": 0}, {"snippet_id": 51232, "code": " match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( ", "label": 0}, {"snippet_id": 23552, "code": " password for{0}:{1}\" \"\").format(username, output)) def del_root_password(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed to delete root password: Failed to update password", "label": 0}, {"snippet_id": 14017, "code": " return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data", "label": 0}, {"snippet_id": 68538, "code": "(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\"", "label": 0}, {"snippet_id": 11035, "code": ".status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y %H:%M:%S %Z').strftime", "label": 1}, {"snippet_id": 26573, "code": "._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type", "label": 0}, {"snippet_id": 86258, "code": " fatal_warnings: javac_cmd.extend(self.get_options().fatal_warnings_enabled_args) else: javac_cmd.extend(self.get_options().fatal_warnings_disabled_args) with argfile.safe_args(ctx.sources, self.get_options()", "label": 0}, {"snippet_id": 24158, "code": "' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2", "label": 1}, {"snippet_id": 35830, "code": " as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install", "label": 0}, {"snippet_id": 20859, "code": "=seq handlername='response(cmd:{} seq:{})'.format(command, seq) evt=self._get_message_handle(match, handlername) return AwaitableResponse(req, lambda: result[\"msg\"], evt) @contextlib.contextmanager def", "label": 0}, {"snippet_id": 85398, "code": "\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main' ZINC_EXTRACT_MAIN='org.pantsbuild.zinc.extractor.Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor", "label": 0}, {"snippet_id": 53153, "code": " is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create", "label": 0}, {"snippet_id": 32391, "code": ", wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards", "label": 0}, {"snippet_id": 90525, "code": ":class:`pants.java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version and dist.version > maximum_version", "label": 0}, {"snippet_id": 70218, "code": "%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper()", "label": 0}, {"snippet_id": 74565, "code": "(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\", \"lz4hc\",", "label": 0}, {"snippet_id": 10417, "code": " bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field", "label": 0}, {"snippet_id": 88370, "code": "._run_tracker.log(Report.DEBUG, *msg_elements) def info(self, *msg_elements): self._run_tracker.log(Report.INFO, *msg_elements) def warn(self, *msg_elements): self._run_tracker.log(Report.WARN, *msg_elements", "label": 0}, {"snippet_id": 30082, "code": ") match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides", "label": 0}, {"snippet_id": 90290, "code": ".Location.from_bin(bin_path) class _OSXEnvironment(_DistributionEnvironment): _OSX_JAVA_HOME_EXE='/usr/libexec/java_home' @classmethod def standard(cls): return cls(cls._OSX_JAVA_HOME_EXE) def __init__", "label": 0}, {"snippet_id": 23000, "code": " returning \"/dev/cdrom\" here if that device device exists on all platforms that are supported on Azure(Stack) :param dev_dir: The root directory from which to look for devices \"\"\" patten=r'(sr[0-9]|hd[c-z", "label": 0}, {"snippet_id": 30964, "code": "\"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property", "label": 0}, {"snippet_id": 25301, "code": " None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional", "label": 1}, {"snippet_id": 7049, "code": " composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of", "label": 0}, {"snippet_id": 48332, "code": "\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput", "label": 0}, {"snippet_id": 28021, "code": " data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class", "label": 0}, {"snippet_id": 48871, "code": ".groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len", "label": 0}, {"snippet_id": 54060, "code": " wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, ", "label": 0}, {"snippet_id": 88045, "code": "=self._maybe_get_plugin_name(classpath_element) if name in plugin_names: plugin_target_closure=self._plugin_targets('scalac').get(name,[]) rel_classpath_elements=[ os.path.relpath(cpe, buildroot) for cpe", "label": 0}, {"snippet_id": 1824, "code": " row[0], 'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse", "label": 0}, {"snippet_id": 81108, "code": " len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms[0][1", "label": 0}, {"snippet_id": 19843, "code": "(self, launchcfg): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None raise NotImplementedError", "label": 0}, {"snippet_id": 68289, "code": " [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 14412, "code": "=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice", "label": 0}, {"snippet_id": 68398, "code": "(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append", "label": 0}, {"snippet_id": 26841, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self", "label": 0}, {"snippet_id": 21062, "code": " or self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event() def handler(msg): if not match(msg): return msg, False event.set() return msg, True", "label": 0}, {"snippet_id": 73317, "code": "\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str", "label": 0}, {"snippet_id": 63522, "code": " job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id)", "label": 0}, {"snippet_id": 73925, "code": " representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\"", "label": 0}, {"snippet_id": 47604, "code": ".updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list()", "label": 0}, {"snippet_id": 68234, "code": "[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target", "label": 0}, {"snippet_id": 80779, "code": "\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime\":mime,\"templateName", "label": 1}, {"snippet_id": 84208, "code": " not match. One can push the local datatypes config to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there", "label": 0}, {"snippet_id": 9564, "code": " because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string", "label": 0}, {"snippet_id": 8680, "code": " config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer", "label": 0}, {"snippet_id": 80398, "code": " attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible", "label": 0}, {"snippet_id": 21786, "code": "(categorical_features=[1]) X=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2,", "label": 1}, {"snippet_id": 85427, "code": ") +(DependencyContext, Java, ScalaPlatform) @classmethod def register_options(cls, register): super(Zinc.Factory, cls).register_options(register) zinc_rev='1.0.3' shader_rules=[ Shader.exclude_package(", "label": 0}, {"snippet_id": 42295, "code": "\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from", "label": 0}, {"snippet_id": 83032, "code": " \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel", "label": 0}, {"snippet_id": 91366, "code": " context_aware_object_factories={ 'python_requirements': PythonRequirements, PantsRequirement.alias: PantsRequirement, } ) def register_goals(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task", "label": 0}, {"snippet_id": 76163, "code": ".log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def", "label": 0}, {"snippet_id": 72515, "code": " config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\", help=", "label": 0}, {"snippet_id": 55852, "code": "(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, ", "label": 0}, {"snippet_id": 28133, "code": " from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION", "label": 1}, {"snippet_id": 2739, "code": " comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping", "label": 0}, {"snippet_id": 76264, "code": " router were cleared') else: self.log.warn('Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_clear_data()) def bind_methods(self): for i, m, f, t in self", "label": 0}, {"snippet_id": 78362, "code": " ValueError as e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception(e) self.w.sleep(self.errortimeout) def forumwipe_loop(self): for f in self.forums: self.counter_tick()", "label": 1}, {"snippet_id": 20959, "code": "() except ClosedError: pass def _receive_message(self, msg): for i, handler in enumerate(list(self._handlers)): handle_message, _, _=handler handled=handle_message(msg) try: msg, handled=handled except", "label": 0}, {"snippet_id": 21714, "code": "(i), label=j) plt.title('Classifier(Training set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors import ListedColormap X_set, y_set=X_test, y_test X1,", "label": 0}, {"snippet_id": 69324, "code": "\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert", "label": 0}, {"snippet_id": 51751, "code": ") return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self", "label": 0}, {"snippet_id": 39092, "code": " scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit", "label": 0}, {"snippet_id": 25203, "code": "'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl'", "label": 0}, {"snippet_id": 8940, "code": " strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param", "label": 0}, {"snippet_id": 99, "code": ".Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi", "label": 0}, {"snippet_id": 25068, "code": "=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES", "label": 1}, {"snippet_id": 21571, "code": "(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove(link) with open(seen_file, 'wb", "label": 0}, {"snippet_id": 37865, "code": " params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies", "label": 0}, {"snippet_id": 59525, "code": " gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self", "label": 0}, {"snippet_id": 32062, "code": "(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files", "label": 0}, {"snippet_id": 77917, "code": "=tuser or '' t=(tuser, id_) logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=", "label": 0}, {"snippet_id": 58283, "code": " tcms.tests import user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories import EnvGroupFactory from tcms.tests.factories import EnvGroupPropertyMapFactory from tcms", "label": 0}, {"snippet_id": 57502, "code": " try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception: return say_no('Update failed. Please try again or request ' 'support from your organization", "label": 0}, {"snippet_id": 80238, "code": "\t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args", "label": 0}, {"snippet_id": 76082, "code": "(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status", "label": 0}, {"snippet_id": 81540, "code": "(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t", "label": 0}, {"snippet_id": 38211, "code": " \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser", "label": 0}, {"snippet_id": 79292, "code": "\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e in extList: \t\t\t\ttmpExtList.append((e,getMime(extensions,e))) \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith", "label": 0}, {"snippet_id": 92233, "code": ".contextutil import(InvalidZipPath, Timer, environment_as, exception_logging, hermetic_environment_as, maybe_profiled, open_zip, pushd, signal_handler_as, stdio_as, temporary_dir, temporary_file) from pants", "label": 0}, {"snippet_id": 76900, "code": "): net=sup.net.RequestPerformer() net.proxy=proxy if proxytype=='HTTP' or proxytype=='HTTPS': net.proxy_type=sup.proxytype.http elif proxytype=='SOCKS4': net.proxy_type=sup.proxytype.socks4 elif proxytype", "label": 0}, {"snippet_id": 28820, "code": "] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0", "label": 0}, {"snippet_id": 82348, "code": "=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in", "label": 0}, {"snippet_id": 53186, "code": "=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self", "label": 0}, {"snippet_id": 35137, "code": " AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value", "label": 0}, {"snippet_id": 89387, "code": ", Revision): raise ValueError('{} must be a string or a Revision object, given:{}'.format(name, version)) return version class Distribution(object): \"\"\"Represents a java distribution -either a JRE or a", "label": 0}, {"snippet_id": 94525, "code": "\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\")", "label": 0}, {"snippet_id": 35022, "code": " defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint", "label": 0}, {"snippet_id": 32183, "code": "(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise", "label": 0}, {"snippet_id": 14388, "code": ".server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed", "label": 0}, {"snippet_id": 30654, "code": ".resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(),", "label": 0}, {"snippet_id": 19672, "code": ".add_argument('filename', nargs='?') parser.add_argument('--single-session', action='store_true') parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv", "label": 0}, {"snippet_id": 16572, "code": " if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={}", "label": 0}, {"snippet_id": 42596, "code": ") if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards", "label": 0}, {"snippet_id": 35302, "code": " filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0]", "label": 0}, {"snippet_id": 84605, "code": "--transitive', type=bool, fingerprint=True, default=True, help='Operate on the transitive dependencies of the specified targets. ' 'Unset to operate only on the specified targets.') register('--ignored", "label": 0}, {"snippet_id": 75511, "code": " reqid, key)] return(b'Router', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method", "label": 0}, {"snippet_id": 64991, "code": ".Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self", "label": 0}, {"snippet_id": 63824, "code": " die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id))", "label": 0}, {"snippet_id": 56485, "code": ".request.GET, skip_parameters=('info_type', 'field', 'format')) return User.objects.filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request", "label": 1}, {"snippet_id": 6716, "code": " boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords,", "label": 0}, {"snippet_id": 80091, "code": ".default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\")", "label": 0}, {"snippet_id": 93189, "code": "=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts/start_named_clone_session.sh", "label": 0}, {"snippet_id": 79427, "code": ",r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload", "label": 1}, {"snippet_id": 66218, "code": " if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type", "label": 0}, {"snippet_id": 53861, "code": " specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item", "label": 0}, {"snippet_id": 53998, "code": "] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems", "label": 0}, {"snippet_id": 44200, "code": " list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if", "label": 0}, {"snippet_id": 65752, "code": ", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 30176, "code": " add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name -", "label": 0}, {"snippet_id": 26972, "code": "'guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'", "label": 0}, {"snippet_id": 28964, "code": "'GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=", "label": 0}, {"snippet_id": 32490, "code": " log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output,", "label": 0}, {"snippet_id": 82362, "code": ".readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead", "label": 0}, {"snippet_id": 90533, "code": "._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version and dist.version > maximum_version: continue if jdk and not dist.jdk: continue return dist def locate(self", "label": 0}, {"snippet_id": 14094, "code": " handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get(", "label": 1}, {"snippet_id": 79425, "code": "[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t", "label": 1}, {"snippet_id": 67042, "code": "=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise", "label": 0}, {"snippet_id": 63713, "code": ".ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def", "label": 0}, {"snippet_id": 92737, "code": " Timer(clock=clock) as t: self.assertLess(t.start, clock.time()) self.assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t.elapsed, 0.1) clock.sleep(0.1) self.assertTrue(t.finish is None) self", "label": 0}, {"snippet_id": 2341, "code": " logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import", "label": 0}, {"snippet_id": 74287, "code": "(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite", "label": 0}, {"snippet_id": 9156, "code": " to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position, position.", "label": 0}, {"snippet_id": 39947, "code": " MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f,", "label": 1}, {"snippet_id": 76277, "code": " *self.wz.make_auth_clear_data()) def bind_methods(self): for i, m, f, t in self.wz_bind_methods: self.set_route_type(i, m, t) self.bind_route(i, m, f) def unbind_methods(self): for i, m, f, t in self.wz_bind_methods", "label": 0}, {"snippet_id": 91255, "code": " import PytestPrep from pants.backend.python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import PythonBinaryCreate from pants.backend.python.tasks.python_bundle", "label": 0}, {"snippet_id": 57797, "code": "=0 step_length=500 queryset_filter=TestCasePlan.objects.filter data={self.target_field: sortkey} while 1: sub_cases=update_targets[offset:offset +step_length] case_pks=[case.pk for case in sub_cases] if", "label": 0}, {"snippet_id": 89215, "code": " the targets found. \"\"\" build_graph=self.build_graph.clone_new() for address in self.address_mapper.scan_addresses(root): build_graph.inject_address_closure(address) return build_graph def execute_process_synchronously", "label": 1}, {"snippet_id": 71862, "code": "\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert", "label": 0}, {"snippet_id": 51286, "code": ") last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic", "label": 0}, {"snippet_id": 39123, "code": " latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster", "label": 0}, {"snippet_id": 10444, "code": " field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_'", "label": 0}, {"snippet_id": 70602, "code": " def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ ", "label": 0}, {"snippet_id": 72130, "code": " sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return except ValueError: irc.error('Invalid argument \"%s\" for <seconds", "label": 0}, {"snippet_id": 5658, "code": " _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' ", "label": 0}, {"snippet_id": 31152, "code": ".benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might", "label": 0}, {"snippet_id": 46091, "code": "(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def", "label": 0}, {"snippet_id": 19189, "code": "'request'].add_error(err.messages or getattr(err, 'detail')) return response=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema", "label": 0}, {"snippet_id": 72600, "code": ") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory=\"./data/input/\" download_directory=input_directory +\"download/\" temp_directory=\"./data/temp/\"", "label": 1}, {"snippet_id": 90506, "code": " version to look for(eg, 1.7.9999). :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None if no matching distribution is in the cache. :rtype:", "label": 0}, {"snippet_id": 93721, "code": ".comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5)", "label": 0}, {"snippet_id": 48238, "code": " inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not", "label": 0}, {"snippet_id": 80023, "code": ", where fuxploider tries to determine what extensions are expected and filtered by the server. Needs -l switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\"", "label": 0}, {"snippet_id": 4394, "code": " strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param", "label": 0}, {"snippet_id": 13844, "code": ".locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals, self.locals) if __name__=='__main__': for k, v in _safe_locals.iteritems(): print k, v", "label": 0}, {"snippet_id": 65961, "code": "(c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if", "label": 0}, {"snippet_id": 77858, "code": ".tcount==0: self.inter_sleep(5) continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except WorkerInterrupt: pass except Exception as", "label": 0}, {"snippet_id": 4624, "code": " position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext", "label": 0}, {"snippet_id": 4011, "code": "=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph()", "label": 0}, {"snippet_id": 55231, "code": " input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag)", "label": 0}, {"snippet_id": 31917, "code": " output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in", "label": 0}, {"snippet_id": 26708, "code": "._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500:", "label": 0}, {"snippet_id": 44833, "code": ", lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if", "label": 0}, {"snippet_id": 83736, "code": " job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client", "label": 0}, {"snippet_id": 50277, "code": ".output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an", "label": 0}, {"snippet_id": 48012, "code": " branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len", "label": 0}, {"snippet_id": 5247, "code": "\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output", "label": 0}, {"snippet_id": 87048, "code": " return self.get_options().incremental_caching @memoized_property def _zinc(self): return Zinc.Factory.global_instance().create(self.context.products) def __init__(self, *args, **kwargs): super(BaseZincCompile", "label": 1}, {"snippet_id": 40493, "code": "\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing", "label": 0}, {"snippet_id": 7708, "code": ". :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in", "label": 0}, {"snippet_id": 3814, "code": "(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send", "label": 0}, {"snippet_id": 74334, "code": " ConfigParser from shutil import copyfile import os.path from pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert", "label": 0}, {"snippet_id": 57429, "code": " properties\"\"\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each possible proprety of TestCases Define your own method named _update_[property name] to hold specific update logic", "label": 0}, {"snippet_id": 66093, "code": " fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status", "label": 0}, {"snippet_id": 69399, "code": ".targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read()", "label": 0}, {"snippet_id": 74845, "code": "\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode could not be converted to integer.\") benchmark_data_input_types=[\"vcf\", \"zarr\"] class BenchmarkConfigurationRepresentation", "label": 0}, {"snippet_id": 73180, "code": "(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz files to", "label": 0}, {"snippet_id": 41203, "code": "\" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist", "label": 0}, {"snippet_id": 66103, "code": "\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR", "label": 0}, {"snippet_id": 40269, "code": ": return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return", "label": 0}, {"snippet_id": 79599, "code": " version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO", "label": 0}, {"snippet_id": 19890, "code": ".close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is None: raise RuntimeError('debugger", "label": 0}, {"snippet_id": 3239, "code": ".edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular", "label": 0}, {"snippet_id": 83371, "code": "(job_wrapper), client_outputs=self.__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description", "label": 0}, {"snippet_id": 48093, "code": " input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item,", "label": 0}, {"snippet_id": 4979, "code": " MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms", "label": 0}, {"snippet_id": 87812, "code": " working directory or ' 'part of the JDK.{} is not.'.format(path)) if path !=os.path.normpath(path): raise TaskError('Classpath entries provided to zinc should be normalized ' '(i.e. without \"..\" and \".\").{}", "label": 0}, {"snippet_id": 32134, "code": "(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params", "label": 0}, {"snippet_id": 8181, "code": " raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error", "label": 0}, {"snippet_id": 2108, "code": ".split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps", "label": 0}, {"snippet_id": 54260, "code": "\"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch", "label": 0}, {"snippet_id": 35515, "code": " Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None,", "label": 0}, {"snippet_id": 67153, "code": " print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print", "label": 0}, {"snippet_id": 92422, "code": "(XXX=UNICODE_CHAR)): self.assertEqual(os.environ['XXX'], expected_output) with hermetic_environment_as(**dict(AAA=UNICODE_CHAR)): self.assertIn('AAA', os.environ) self.assertEqual(os.environ['AAA'], expected_output", "label": 1}, {"snippet_id": 37890, "code": ".apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 72759, "code": " def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files(ftp_server, ftp_directory, files=None): pass def record_runtime(benchmark, timestamp", "label": 1}, {"snippet_id": 60729, "code": "(type): \"\"\"Metaclass that allows derived classes to dynamically instantiate new objects based on undefined methods. The dynamic methods pass their arguments directly to __init__ of the inheriting class.\"\"\"", "label": 0}, {"snippet_id": 52538, "code": ".dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"", "label": 1}, {"snippet_id": 46827, "code": "=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards", "label": 0}, {"snippet_id": 15417, "code": ".readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def", "label": 0}, {"snippet_id": 29565, "code": ": try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 5195, "code": "=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ ", "label": 0}, {"snippet_id": 48047, "code": "=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark", "label": 0}, {"snippet_id": 94370, "code": "'cmd'][1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']", "label": 0}, {"snippet_id": 30221, "code": "[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names", "label": 0}, {"snippet_id": 20567, "code": " TIMEOUT=None @classmethod def create_client(cls, addr=None, **kwargs): if addr is None: addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_client( addr, timeout=kwargs.get('timeout'), ) return", "label": 0}, {"snippet_id": 94890, "code": "\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object", "label": 1}, {"snippet_id": 23848, "code": " strings: iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We will sleep and retry as the network must be up. \"\"\" iface='' inet='' mac='' err, output=shellutil.run_get_output('ifconfig", "label": 0}, {"snippet_id": 66427, "code": "(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS", "label": 1}, {"snippet_id": 28120, "code": " import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant", "label": 1}, {"snippet_id": 75207, "code": "{} self.response_handlers={} self.sig_handlers={} self.iden_reqid_map=BijectiveSetMap() def set_req_handler(self, interface, method, fun): self.req_handlers[(interface, method)]=fun def set_response_handler", "label": 0}, {"snippet_id": 94199, "code": "'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided", "label": 0}, {"snippet_id": 94201, "code": "/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self", "label": 0}, {"snippet_id": 5546, "code": "(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def", "label": 0}, {"snippet_id": 41620, "code": ".format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable", "label": 0}, {"snippet_id": 90627, "code": " def _get_stricter_version(a, b, name, stricter): version_a=_parse_java_version(name, a) version_b=_parse_java_version(name, b) if version_a is None: return version_b if version_b is None: return version_a", "label": 0}, {"snippet_id": 29881, "code": " filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the", "label": 0}, {"snippet_id": 75515, "code": " b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method", "label": 0}, {"snippet_id": 30353, "code": "(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self", "label": 0}, {"snippet_id": 77261, "code": "], self.pc, self.get_userqueue): self.log.info('Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def", "label": 0}, {"snippet_id": 89997, "code": "._get_system_properties(java)['java.version']) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open(os.path.join(classpath, 'SystemProperties.class'), 'w+b", "label": 0}, {"snippet_id": 25483, "code": " device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit", "label": 0}, {"snippet_id": 93794, "code": "'%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window", "label": 0}, {"snippet_id": 29435, "code": " return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def", "label": 0}, {"snippet_id": 89462, "code": "/issues/3263 \"\"\" class Error(Exception): \"\"\"Indicates an invalid java distribution.\"\"\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self", "label": 0}, {"snippet_id": 31744, "code": " input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old", "label": 0}, {"snippet_id": 67380, "code": "-fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if", "label": 1}, {"snippet_id": 57461, "code": "=request self.target_field=request.POST.get('target_field') self.new_value=request.POST.get('new_value') def get_update_action(self): return getattr(self, '_update_%s' % self.target_field, None) def update", "label": 0}, {"snippet_id": 66611, "code": " from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search", "label": 1}, {"snippet_id": 44130, "code": " if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is", "label": 0}, {"snippet_id": 48749, "code": " input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output", "label": 0}, {"snippet_id": 41148, "code": "[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self):", "label": 0}, {"snippet_id": 57783, "code": "=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets=self.get_update_targets() offset=0 step_length=500 queryset_filter=TestCasePlan.objects", "label": 0}, {"snippet_id": 93034, "code": ", file=sys.stdout) print('garbage', file=sys.stderr) def test_signal_handler_as(self): mock_initial_handler=1 mock_new_handler=2 with mock.patch('signal.signal', **PATCH_OPTS) as mock_signal: mock_signal", "label": 0}, {"snippet_id": 5460, "code": " spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False", "label": 0}, {"snippet_id": 18632, "code": ".Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not", "label": 0}, {"snippet_id": 17254, "code": " user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen", "label": 0}, {"snippet_id": 8315, "code": " seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote", "label": 0}, {"snippet_id": 57716, "code": " return say_no('No plan record found.') confirm_status_name='CONFIRMED' plan.run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name", "label": 0}, {"snippet_id": 76132, "code": ", data): if status==wzrpc.status.success: self.log.debug('Succesfully set route type for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}", "label": 0}, {"snippet_id": 91738, "code": "=yield[ Get( Digest, DirectoryWithPrefixToStrip( directory_digest=snapshot.directory_digest, prefix=source_root.path ) ) for snapshot, source_root in sources_snapshots_and_source_roots ] sources_digest", "label": 0}, {"snippet_id": 12652, "code": " old_comment['body'].lower(): break elif 'quiet' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False return PERMITTED_TO_COMMENT def create_or_update_comment(data, comment): comment_mode=None headers={", "label": 0}, {"snippet_id": 52088, "code": "\"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError", "label": 0}, {"snippet_id": 49722, "code": " updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets", "label": 0}, {"snippet_id": 73983, "code": "\" \"Expected: \\\"auto\\\" or integer value\") if \"chunk_length\" in runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None", "label": 0}, {"snippet_id": 8623, "code": " URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text,", "label": 0}, {"snippet_id": 95949, "code": ".VCFtoZarrConfigurationRepresentation \"\"\" if conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by", "label": 0}, {"snippet_id": 37242, "code": "): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput", "label": 0}, {"snippet_id": 44083, "code": ".is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules", "label": 0}, {"snippet_id": 41579, "code": ".b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize", "label": 0}, {"snippet_id": 18734, "code": " all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes", "label": 0}, {"snippet_id": 84040, "code": ".get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state", "label": 0}, {"snippet_id": 9326, "code": " keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc", "label": 0}, {"snippet_id": 9722, "code": " keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires", "label": 0}, {"snippet_id": 71338, "code": "=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 18812, "code": ": dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA:", "label": 0}, {"snippet_id": 33366, "code": "( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f", "label": 0}, {"snippet_id": 67947, "code": " CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import ", "label": 0}, {"snippet_id": 32001, "code": " output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 75067, "code": "%s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log.info('Done, sending answer: %s', res) self.p.send_success_rep(reqid,[v.encode('utf-8') for v in res]) def send_keepalive(self):", "label": 0}, {"snippet_id": 29325, "code": "), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{}", "label": 1}, {"snippet_id": 17130, "code": " signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from", "label": 0}, {"snippet_id": 61594, "code": ") def ev(self, A, wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem", "label": 0}, {"snippet_id": 88664, "code": " tracker's daemon stats object.\"\"\" target_count=len(self._target_roots) self.run_tracker.pantsd_stats.set_target_root_size(target_count) return target_count def _set_affected_target_count_in_runtracker", "label": 0}, {"snippet_id": 82141, "code": " verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=", "label": 0}, {"snippet_id": 30759, "code": "\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self", "label": 0}, {"snippet_id": 77522, "code": " def load_users(self): if not os.path.isfile(self.usersfile): return with open(self.usersfile, 'rb') as f: users=pickle.loads(f.read()) try: for domain in users.keys(): uq=Queue() for ud in users[domain]:", "label": 0}, {"snippet_id": 20118, "code": "\"\"\"A high-level abstraction of a debug client(i.e. editor).\"\"\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 46776, "code": "\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import", "label": 1}, {"snippet_id": 87943, "code": " is the classpath entry containing the plugin metadata. The rest are the internal transitive deps of the plugin. This allows us to have in-repo plugins with dependencies(unlike javac, scalac doesn't load", "label": 0}, {"snippet_id": 29432, "code": ".file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self", "label": 0}, {"snippet_id": 35686, "code": ": yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for", "label": 0}, {"snippet_id": 95156, "code": "=zarr_directory_setup, conversion_config=vcf_to_zarr_config) elif command==\"exec\": print(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location=cli_arguments[\"config_file", "label": 1}, {"snippet_id": 55524, "code": "{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd", "label": 0}, {"snippet_id": 64080, "code": "\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return", "label": 0}, {"snippet_id": 12166, "code": " del files[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"", "label": 0}, {"snippet_id": 86775, "code": "}\" in jvm-platform args.' .format(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings.args) zinc_args.extend(settings_args) return zinc_args @classmethod def", "label": 0}, {"snippet_id": 18058, "code": " request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text", "label": 0}, {"snippet_id": 76850, "code": " c.only_cache) c.router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b'WZWorker', b'terminate']) for", "label": 0}, {"snippet_id": 79482, "code": "(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl", "label": 0}, {"snippet_id": 42475, "code": ".priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile", "label": 0}, {"snippet_id": 46028, "code": "\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and", "label": 0}, {"snippet_id": 58492, "code": "'comment': 'new comment'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self):", "label": 0}, {"snippet_id": 18292, "code": " options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port", "label": 1}, {"snippet_id": 71017, "code": " len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error", "label": 0}, {"snippet_id": 90770, "code": " minimum_version{}, maximum_version{}, jdk{}' .format(dist, minimum_version, maximum_version, jdk)) return dist except(ValueError, Distribution.Error) as e: logger.debug('{} is not a valid distribution because", "label": 0}, {"snippet_id": 17142, "code": " from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client", "label": 0}, {"snippet_id": 74900, "code": " None: if hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError", "label": 0}, {"snippet_id": 58899, "code": " 'target_field': 'priority', 'from_plan': self.plan.pk, 'case':[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding", "label": 0}, {"snippet_id": 28610, "code": "'battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data[", "label": 0}, {"snippet_id": 17327, "code": "'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr", "label": 0}, {"snippet_id": 86056, "code": ", JvmTarget): return False return target.has_sources('.java') def select_source(self, source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath", "label": 0}, {"snippet_id": 11328, "code": " MonitoringConfigGenerator(object): def __init__(self, url, debug_enabled=False, target_dir=None, skip_checks=False): self.skip_checks=skip_checks self.target_dir=target_dir if target_dir else CONFIG['TARGET_DIR", "label": 0}, {"snippet_id": 3452, "code": " self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting", "label": 0}, {"snippet_id": 35764, "code": ".__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self", "label": 0}, {"snippet_id": 69282, "code": " ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e:", "label": 1}, {"snippet_id": 26047, "code": " self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data", "label": 0}, {"snippet_id": 80749, "code": "\"templateName\"]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in", "label": 1}, {"snippet_id": 59708, "code": " cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq", "label": 0}, {"snippet_id": 23574, "code": " to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper() return None def get_first_if(self): return self._get_net_info", "label": 0}, {"snippet_id": 11026, "code": " in response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime.strptime", "label": 1}, {"snippet_id": 4815, "code": ":keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p=_sort_kw_matches(composite_keywords) for w in single_keywords_p: categories[w", "label": 0}, {"snippet_id": 93304, "code": ".session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file", "label": 0}, {"snippet_id": 61970, "code": ".setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version", "label": 0}, {"snippet_id": 87075, "code": "'apt-processor-info') ZincCompile.validate_arguments(self.context.log, self.get_options().whitelisted_args, self._args) if self.execution_strategy==self.HERMETIC: try: fast_relpath(self.get_options().pants_workdir", "label": 0}, {"snippet_id": 44886, "code": " value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if", "label": 0}, {"snippet_id": 37411, "code": "\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not", "label": 0}, {"snippet_id": 95750, "code": " filename_str=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir", "label": 0}, {"snippet_id": 64267, "code": ": version_path=new_version_path self._version_path=version_path def output_paths( self): local_output_paths=self._wrapper_output_paths results=[] for local_output_path in local_output_paths: wrapper_path", "label": 0}, {"snippet_id": 48378, "code": " output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item", "label": 0}, {"snippet_id": 76, "code": " as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli", "label": 0}, {"snippet_id": 78177, "code": " cstate from beon import exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self", "label": 0}, {"snippet_id": 85396, "code": " tool.\"\"\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main' ZINC_EXTRACT_MAIN='org.pantsbuild.zinc.extractor.Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME=", "label": 0}, {"snippet_id": 60864, "code": " if Device._current_context is None: Device._current_context=self self.reset() else: raise DeviceError('Only one device can be active at a time.') return self def __exit__(self, exc_type, exc_value, tb):", "label": 0}, {"snippet_id": 57402, "code": " getattr(t, field), request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return HttpResponse(json.dumps({'rc': 0, 'response': 'ok", "label": 0}, {"snippet_id": 53770, "code": " try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files", "label": 0}, {"snippet_id": 57691, "code": "%( self.target_field, testcase.case_status, new_status.name ) ) update_object.update(**{str(self.target_field): self.new_value}) try: plan=plan_from_request_or_none(self.request) except Http404: return", "label": 0}, {"snippet_id": 59275, "code": " only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend", "label": 0}, {"snippet_id": 13386, "code": "=base64.b64encode(new_file.encode()).decode(\"utf-8\") request_json={ \"path\": file, \"message\": \"Fix pep8 errors in{}\".format(file), \"content\": content_code, \"sha\": sha_blob, \"branch\": data.get(\"new_branch", "label": 0}, {"snippet_id": 867, "code": "={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep'", "label": 0}, {"snippet_id": 52293, "code": ".get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output", "label": 0}, {"snippet_id": 59457, "code": "): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure", "label": 1}, {"snippet_id": 60304, "code": ", 'P', 'Homodyne'} _circuits={} def __init__(self, wires, *, shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name", "label": 0}, {"snippet_id": 21867, "code": " inventory from ansible import vars from ansible.executor import playbook_executor from ansible.parsing import dataloader from ansible.utils.display import Display from dciclient.v1 import helper as dci_helper", "label": 0}, {"snippet_id": 11211, "code": " it by querying an URL from which it receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is given it reads it's default configuration from", "label": 0}, {"snippet_id": 69497, "code": " cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd", "label": 0}, {"snippet_id": 14716, "code": ".server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self", "label": 0}, {"snippet_id": 49151, "code": ") self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess", "label": 0}, {"snippet_id": 51467, "code": " exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run", "label": 0}, {"snippet_id": 84058, "code": "())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown", "label": 0}, {"snippet_id": 88566, "code": " Note that for a command line invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots @property", "label": 0}, {"snippet_id": 86546, "code": " from pants.util.contextutil import open_zip from pants.util.dirutil import fast_relpath, safe_open from pants.util.memo import memoized_method, memoized_property _SCALAC_PLUGIN_INFO_FILE='scalac-plugin", "label": 0}, {"snippet_id": 74235, "code": ".benchmark[\"benchmark_dataset\"] if \"benchmark_allele_count\" in runtime_config.benchmark: self.benchmark_allele_count=config_str_to_bool(runtime_config.benchmark[\"benchmark_allele_count\"]) if \"benchmark_PCA\" in", "label": 1}, {"snippet_id": 55461, "code": ": scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False", "label": 0}, {"snippet_id": 89884, "code": "._validated_binaries: return with self._valid_executable('java') as java: if self._minimum_version: version=self._get_version(java) if version < self._minimum_version: raise self.Error('The java distribution at{", "label": 0}, {"snippet_id": 59840, "code": " expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator", "label": 0}, {"snippet_id": 12257, "code": "\"][filename]=stdout.decode(r.encoding).splitlines() data[\"results\"][filename]=[] for error in list(data[\"extra_results\"][filename]): if re.search(\"^file_to_check.py:\\d+:\\d+:\\s[WE]\\d+\\s.*\", error): data", "label": 0}, {"snippet_id": 55671, "code": "(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params", "label": 0}, {"snippet_id": 16497, "code": " completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(", "label": 0}, {"snippet_id": 25471, "code": " icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self):", "label": 0}, {"snippet_id": 25719, "code": "'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp", "label": 0}, {"snippet_id": 46112, "code": ") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard", "label": 0}, {"snippet_id": 95395, "code": "): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath", "label": 0}, {"snippet_id": 7825, "code": " fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches", "label": 0}, {"snippet_id": 79575, "code": "(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file\"}) \t\t\t\tif len(fileInputs) > 0: \t\t\t\t\treturnForms.append((f,fileInputs", "label": 0}, {"snippet_id": 13328, "code": ".encoding) os.remove(\"file_to_fix.py\") def commit(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) fullname=data.get(", "label": 0}, {"snippet_id": 18790, "code": " BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data", "label": 0}, {"snippet_id": 22223, "code": "'log_file'] if 'template' in self.conf[state]: template=self.conf[state]['template'] if playbook is None: playbook=self.conf['playbook'] if template is None and template in self.conf: template=self.conf", "label": 0}, {"snippet_id": 52572, "code": ".wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value", "label": 0}, {"snippet_id": 36891, "code": " collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake", "label": 0}, {"snippet_id": 47706, "code": "\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp,", "label": 0}, {"snippet_id": 49711, "code": " not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info", "label": 0}, {"snippet_id": 3795, "code": " window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window", "label": 0}, {"snippet_id": 47965, "code": " replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements", "label": 0}, {"snippet_id": 9333, "code": " author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords", "label": 0}, {"snippet_id": 38011, "code": " to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o", "label": 0}, {"snippet_id": 82998, "code": "\t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix", "label": 0}, {"snippet_id": 66791, "code": " class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes", "label": 0}, {"snippet_id": 63228, "code": ", dependencies_description=dependencies_description, env=client.env, rewrite_paths=rewrite_paths, arbitrary_files=unstructured_path_rewrites, ) job_id=lwr_submit_job(client, client_job_description, remote_job_config", "label": 0}, {"snippet_id": 93800, "code": "(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name'", "label": 0}, {"snippet_id": 67752, "code": "][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={", "label": 0}, {"snippet_id": 45067, "code": ": ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads", "label": 0}, {"snippet_id": 57405, "code": ", request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'})) class ModelUpdateActions", "label": 0}, {"snippet_id": 49724, "code": ") if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files", "label": 0}, {"snippet_id": 21970, "code": "=None, syntax=None, diff=None, force_handlers=None, flush_cache=None, listtasks=None, listtags=None, module_path=None): self.verbosity=verbosity self.inventory=inventory self.listhosts=listhosts self.subset", "label": 0}, {"snippet_id": 39015, "code": " elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return", "label": 0}, {"snippet_id": 71265, "code": " target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag()", "label": 0}, {"snippet_id": 71693, "code": ".FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+): SHINE:\\d:(", "label": 1}, {"snippet_id": 59113, "code": " different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C+", "label": 0}, {"snippet_id": 57727, "code": ".run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case.count(", "label": 0}, {"snippet_id": 47862, "code": " self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict", "label": 0}, {"snippet_id": 2265, "code": " elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '", "label": 0}, {"snippet_id": 8074, "code": ":limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the", "label": 0}, {"snippet_id": 4685, "code": " string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string", "label": 0}, {"snippet_id": 51299, "code": ".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name", "label": 0}, {"snippet_id": 67374, "code": " not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc", "label": 0}, {"snippet_id": 68952, "code": " node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info:", "label": 0}, {"snippet_id": 92863, "code": "(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness to replace `sys.std*` with tempfiles. Validates that all files are read/written/flushed correctly, and acts as a contextmanager to", "label": 0}, {"snippet_id": 52581, "code": " wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. ", "label": 0}, {"snippet_id": 5288, "code": " dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted", "label": 0}, {"snippet_id": 79003, "code": ": \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: ", "label": 0}, {"snippet_id": 69031, "code": ".__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR:", "label": 0}, {"snippet_id": 57061, "code": " say_no(error_msg): ajax_response={'rc': 1, 'response': error_msg} return HttpResponse(json.dumps(ajax_response)) def say_yes(): return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'})) @require_POST", "label": 0}, {"snippet_id": 47376, "code": ".dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"", "label": 0}, {"snippet_id": 78, "code": " osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME", "label": 0}, {"snippet_id": 29273, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode &", "label": 0}, {"snippet_id": 5106, "code": " output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml", "label": 0}, {"snippet_id": 93525, "code": " outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host", "label": 0}, {"snippet_id": 56169, "code": " import sys import json from distutils.util import strtobool from django import http from django.db.models import Q, Count from django.contrib.auth.models import User from django.core import serializers", "label": 1}, {"snippet_id": 65851, "code": "=OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target)", "label": 0}, {"snippet_id": 69367, "code": " nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command", "label": 0}, {"snippet_id": 50108, "code": ".info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap", "label": 0}, {"snippet_id": 75630, "code": " interval, *args, **kvargs): self.interval=interval super().__init__(*args, **kvargs) class Resume(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self,", "label": 0}, {"snippet_id": 43517, "code": ".__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2", "label": 0}, {"snippet_id": 60880, "code": " exc_type, exc_value, tb): if self._observe is None: raise DeviceError('A qfunc must always conclude with a classical expectation value.') Device._current_context=None self.execute() @property def gates", "label": 0}, {"snippet_id": 86398, "code": ") ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd), input_files=input_snapshot.directory_digest, output_files=output_files, description='Compiling{} with javac'.format(ctx.target.address.spec", "label": 0}, {"snippet_id": 27867, "code": "'WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle']", "label": 0}, {"snippet_id": 52610, "code": " def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime", "label": 0}, {"snippet_id": 10337, "code": " sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version", "label": 0}, {"snippet_id": 9839, "code": " keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> ", "label": 0}, {"snippet_id": 49021, "code": " attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException", "label": 0}, {"snippet_id": 45631, "code": " IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self", "label": 1}, {"snippet_id": 10753, "code": "(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length", "label": 1}, {"snippet_id": 43370, "code": " True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"", "label": 0}, {"snippet_id": 5547, "code": ")).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords", "label": 0}, {"snippet_id": 93446, "code": " try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res: if node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self", "label": 0}, {"snippet_id": 37769, "code": " RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable", "label": 0}, {"snippet_id": 87191, "code": " zinc_args[compile_context.target]=args def create_empty_extra_products(self): if self.context.products.is_required_data('zinc_analysis'): self.context.products.safe_create_data('zinc_analysis', dict) if self", "label": 0}, {"snippet_id": 5905, "code": ") if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==", "label": 0}, {"snippet_id": 29818, "code": "(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value", "label": 1}, {"snippet_id": 21215, "code": " os import pickle from bs4 import BeautifulSoup import urllib3 import certifi import re import sys import argparse as ap flatten=lambda l:[item for sublist in l for item in sublist] def getytlinks(link", "label": 0}, {"snippet_id": 29196, "code": " is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file,", "label": 1}, {"snippet_id": 94394, "code": " and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process", "label": 0}, {"snippet_id": 38981, "code": " please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job", "label": 0}, {"snippet_id": 28932, "code": "\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] ", "label": 0}, {"snippet_id": 7471, "code": "=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output", "label": 0}, {"snippet_id": 87420, "code": "=relative_to_exec_root(compiler_interface) compiler_bridge=relative_to_exec_root(compiler_bridge) analysis_cache=relative_to_exec_root(analysis_cache) classes_dir=relative_to_exec_root(classes_dir) relative_classpath", "label": 1}, {"snippet_id": 86035, "code": "['runtime_classpath'] def __init__(self, *args, **kwargs): super(JavacCompile, self).__init__(*args, **kwargs) self.set_distribution(jdk=True) def select(self, target): if not isinstance(target, JvmTarget", "label": 0}, {"snippet_id": 66704, "code": " %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except", "label": 0}, {"snippet_id": 40581, "code": "(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise", "label": 1}, {"snippet_id": 67813, "code": "(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[", "label": 0}, {"snippet_id": 53975, "code": ".allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item", "label": 0}, {"snippet_id": 11652, "code": "['--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN if file_name else EXIT_CODE_NOT_WRITTEN except HostUnreachableException: LOG.warn(\"Target url{0} unreachable. Could not get yaml config!", "label": 0}, {"snippet_id": 84612, "code": " transitive dependencies of the specified targets. ' 'Unset to operate only on the specified targets.') register('--ignored', type=bool, fingerprint=True, help='Show information about files ignored by cloc", "label": 0}, {"snippet_id": 40779, "code": " in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\"", "label": 0}, {"snippet_id": 58804, "code": " 'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) self", "label": 0}, {"snippet_id": 17357, "code": " self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout", "label": 0}, {"snippet_id": 9837, "code": " extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return ", "label": 0}, {"snippet_id": 30131, "code": " Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str", "label": 0}, {"snippet_id": 44444, "code": "(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes", "label": 0}, {"snippet_id": 53055, "code": " always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( ", "label": 0}, {"snippet_id": 92633, "code": " a dir and not a file.') self.assertFalse(os.path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False)", "label": 0}, {"snippet_id": 32795, "code": ", CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler", "label": 0}, {"snippet_id": 2759, "code": "\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger", "label": 0}, {"snippet_id": 87130, "code": " def select(self, target): raise NotImplementedError() def select_source(self, source_file_path): raise NotImplementedError() def register_extra_products_from_contexts(self, targets, compile_contexts):", "label": 0}, {"snippet_id": 95002, "code": ".add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a", "label": 0}, {"snippet_id": 7392, "code": ", info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete", "label": 0}, {"snippet_id": 87483, "code": ".extend(self._javac_plugin_args(javac_plugin_map)) scalac_plugin_search_classpath=( (set(absolute_classpath) | set(self.scalac_plugin_classpath_elements())) - {ctx.classes_dir, ctx.jar_file} ) zinc_args", "label": 0}, {"snippet_id": 3269, "code": ", ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False", "label": 0}, {"snippet_id": 4586, "code": " extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects", "label": 0}, {"snippet_id": 5858, "code": ".mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os", "label": 0}, {"snippet_id": 32102, "code": " elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item:", "label": 0}, {"snippet_id": 40151, "code": "), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{}", "label": 1}, {"snippet_id": 46633, "code": ": pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\"", "label": 0}, {"snippet_id": 38040, "code": " bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards", "label": 0}, {"snippet_id": 46060, "code": " dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=", "label": 1}, {"snippet_id": 38588, "code": " stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False", "label": 0}, {"snippet_id": 85983, "code": "'-Xlint:-path') @classmethod def get_no_warning_args_default(cls): return('-nowarn', '-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-Werror',) @classmethod def get_fatal_warnings_disabled_args_default", "label": 0}, {"snippet_id": 14582, "code": "'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync(", "label": 0}, {"snippet_id": 49400, "code": " cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False", "label": 0}, {"snippet_id": 47567, "code": " other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None,", "label": 0}, {"snippet_id": 42823, "code": " item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\")", "label": 0}, {"snippet_id": 44501, "code": ", sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname", "label": 0}, {"snippet_id": 90669, "code": "._cache.get(key) if not dist: dist=self._scan_constraint_match(minimum_version, maximum_version, jdk) if not dist: dist=self._locate(minimum_version=minimum_version, maximum_version=maximum_version, jdk", "label": 0}, {"snippet_id": 50666, "code": ".abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir):", "label": 0}, {"snippet_id": 75581, "code": " reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return self.make_req_msg(d[0], d[1], d[2], fun, d[3]) def _parse_err(self, iden, msg, status)", "label": 0}, {"snippet_id": 5772, "code": " keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list", "label": 0}, {"snippet_id": 88489, "code": "(target_roots) self._invalidation_report=invalidation_report self._scheduler=scheduler @property def options(self): \"\"\"Returns the new-style options. :API: public \"\"\" return self._options @property def log", "label": 0}, {"snippet_id": 28288, "code": "'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({", "label": 1}, {"snippet_id": 31503, "code": " from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name ", "label": 0}, {"snippet_id": 59089, "code": ".plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ", "label": 0}, {"snippet_id": 75974, "code": " if status==wzrpc.status.success: self.log.debug('Successfull auth for(%s, %s)', i, m) elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3}", "label": 1}, {"snippet_id": 14950, "code": " method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri", "label": 1}, {"snippet_id": 32916, "code": " self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror", "label": 0}, {"snippet_id": 44329, "code": ".workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done", "label": 0}, {"snippet_id": 72528, "code": " config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for", "label": 0}, {"snippet_id": 33071, "code": ": raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse", "label": 0}, {"snippet_id": 24499, "code": " unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states", "label": 0}, {"snippet_id": 76161, "code": " else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i", "label": 0}, {"snippet_id": 76970, "code": " self.site.uploadavatar('0', av) ud[0]['avatar']=av ud[0]['avatar_uploaded']=True from lib.mailinator import Mailinator def create_spawn(proxy, proxytype, pc, uq=None): for domain in domains: if domain in", "label": 0}, {"snippet_id": 10262, "code": " Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1]", "label": 0}, {"snippet_id": 30554, "code": " snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions", "label": 1}, {"snippet_id": 77514, "code": " return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount, (ev_init,)) def load_users(self): if not os.path.isfile(self.usersfile): return with open(self.usersfile, 'rb') as f: users=pickle.loads(f.read()", "label": 0}, {"snippet_id": 12720, "code": " None: response=requests.post(query, json={\"body\": comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B", "label": 0}, {"snippet_id": 57565, "code": "(self.request, pk_enough) except Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context:", "label": 0}, {"snippet_id": 419, "code": " password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name", "label": 0}, {"snippet_id": 591, "code": " elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for", "label": 0}, {"snippet_id": 71737, "code": "(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen", "label": 0}, {"snippet_id": 33850, "code": " self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info", "label": 0}, {"snippet_id": 11759, "code": " headers={ \"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"], \"Content-Length\": \"0\", } auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/user/following/{}\" url", "label": 0}, {"snippet_id": 63469, "code": " job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env", "label": 0}, {"snippet_id": 66706, "code": ", cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException", "label": 0}, {"snippet_id": 54178, "code": " of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a", "label": 0}, {"snippet_id": 30302, "code": ": yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in", "label": 0}, {"snippet_id": 68086, "code": " RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self)", "label": 0}, {"snippet_id": 70941, "code": ".state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len", "label": 0}, {"snippet_id": 82346, "code": "\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args", "label": 0}, {"snippet_id": 66086, "code": "=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status", "label": 0}, {"snippet_id": 21017, "code": " repr(handle_msg)) if unhandled: raise RuntimeError('unhandled:{}'.format(unhandled)) @contextlib.contextmanager def _wait_for_message(self, match, handlername, timeout=None): if timeout is None: timeout", "label": 0}, {"snippet_id": 72564, "code": "\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default", "label": 1}, {"snippet_id": 19886, "code": " is not None: self._detach() try: self._adapter.close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self", "label": 0}, {"snippet_id": 48828, "code": " \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 88418, "code": "=None, console_outstream=None, scm=None, workspace=None, invalidation_report=None, scheduler=None): self._options=options self.build_graph=build_graph self.build_file_parser=build_file_parser self.address_mapper", "label": 0}, {"snippet_id": 20911, "code": "*kwargs): yield result def _close(self): if self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self", "label": 0}, {"snippet_id": 40797, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}", "label": 0}, {"snippet_id": 7055, "code": " taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword", "label": 0}, {"snippet_id": 93045, "code": "'signal.signal', **PATCH_OPTS) as mock_signal: mock_signal.return_value=mock_initial_handler try: with signal_handler_as(signal.SIGUSR2, mock_new_handler): raise NotImplementedError('blah') except NotImplementedError", "label": 0}, {"snippet_id": 25672, "code": "\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state", "label": 0}, {"snippet_id": 34783, "code": " MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)", "label": 0}, {"snippet_id": 34413, "code": "(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir", "label": 0}, {"snippet_id": 43001, "code": " name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self", "label": 0}, {"snippet_id": 43719, "code": " self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None", "label": 0}, {"snippet_id": 47236, "code": ".exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark", "label": 0}, {"snippet_id": 41404, "code": ".logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None):", "label": 0}, {"snippet_id": 55199, "code": " job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster,", "label": 0}, {"snippet_id": 94519, "code": " and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command", "label": 0}, {"snippet_id": 80723, "code": " open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates", "label": 0}, {"snippet_id": 23655, "code": " set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def remove_route_for_dhcp_broadcast(self, ifname): shellutil.run(\"route delete 255.255", "label": 0}, {"snippet_id": 64663, "code": " RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler", "label": 0}, {"snippet_id": 92241, "code": ", pushd, signal_handler_as, stdio_as, temporary_dir, temporary_file) from pants.util.process_handler import subprocess PATCH_OPTS=dict(autospec=True, spec_set=True) class ContextutilTest(unittest.TestCase", "label": 0}, {"snippet_id": 95075, "code": " command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode", "label": 0}, {"snippet_id": 66421, "code": " print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client", "label": 1}, {"snippet_id": 44813, "code": " snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None)", "label": 0}, {"snippet_id": 58430, "code": "( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'run':[self.case_run_1.pk, self.case_run_2.pk]}) self.assertJSONEqual( str(response.content, encoding", "label": 0}, {"snippet_id": 25422, "code": "'Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3", "label": 0}, {"snippet_id": 72065, "code": " such network \"%s\"(case sensitive).' % netname) return irc.reply(\"Done. If you want to reconnect this network, use the 'rehash' command.\") control.remove_network(network) @utils.add_cmd def autoconnect", "label": 0}, {"snippet_id": 50518, "code": " decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate", "label": 0}, {"snippet_id": 58638, "code": "): self.client.login( username=self.tester.username, password='password') remove_perm_from_user(self.tester, self.permission) post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk", "label": 0}, {"snippet_id": 43436, "code": " requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen ", "label": 0}, {"snippet_id": 72970, "code": " except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{})", "label": 0}, {"snippet_id": 49414, "code": " stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False", "label": 0}, {"snippet_id": 85536, "code": ", cls.options_scope) @classmethod def _compiler_bridge(cls, products): return cls.tool_jar_from_products(products, 'compiler-bridge', cls.options_scope) @classmethod def _compiler_interface(cls, products", "label": 0}, {"snippet_id": 17392, "code": " return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open", "label": 0}, {"snippet_id": 26529, "code": "(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity", "label": 0}, {"snippet_id": 71631, "code": "=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support", "label": 0}, {"snippet_id": 4024, "code": "(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill", "label": 0}, {"snippet_id": 81792, "code": "\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault", "label": 0}, {"snippet_id": 7213, "code": " recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('", "label": 0}, {"snippet_id": 12983, "code": "\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response", "label": 0}, {"snippet_id": 68577, "code": ".CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout", "label": 0}, {"snippet_id": 40956, "code": ". Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend", "label": 0}, {"snippet_id": 67082, "code": " shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return", "label": 0}, {"snippet_id": 66015, "code": " layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout", "label": 0}, {"snippet_id": 83755, "code": " client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail", "label": 0}, {"snippet_id": 19754, "code": " args.name=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs): if nodebug: run_main(addr, name, kind, *extra, **kwargs) else: debug_main(addr, name, kind", "label": 0}, {"snippet_id": 73879, "code": " \"lz4hc\", \"zlib\", \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object", "label": 0}, {"snippet_id": 20789, "code": " True, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event and condition(msg) handlername", "label": 0}, {"snippet_id": 63597, "code": " finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed", "label": 0}, {"snippet_id": 107, "code": "=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep", "label": 0}, {"snippet_id": 91879, "code": " import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import memoized_property from pants", "label": 1}, {"snippet_id": 6032, "code": "=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext", "label": 1}, {"snippet_id": 39767, "code": " @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None", "label": 0}, {"snippet_id": 31434, "code": "\".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 18749, "code": "] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def", "label": 0}, {"snippet_id": 3009, "code": "['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'", "label": 0}, {"snippet_id": 40152, "code": " mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of", "label": 1}, {"snippet_id": 20419, "code": " break else: raise RuntimeError('could not connect') return sock return cls._create(connect, addr, **kwargs) @classmethod def create_server(cls, addr, **kwargs): def connect(addr, timeout): server=create_server", "label": 0}, {"snippet_id": 28057, "code": "\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 27426, "code": ") self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement", "label": 0}, {"snippet_id": 25825, "code": " data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state", "label": 0}, {"snippet_id": 66922, "code": " CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\"", "label": 0}, {"snippet_id": 49077, "code": " from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None", "label": 0}, {"snippet_id": 56810, "code": ".models.TestPlan`, a:class:`tcms.testcases.models.TestCase` or a:class:`tcms.testruns.models.TestRun` :param tag_name: The name of the tag to be manipulated :type tag_name: str \"\"\" self.obj=obj self.tag_name", "label": 0}, {"snippet_id": 12844, "code": "+to_ignore for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format(data[\"repository\"], data[\"sha\"], file) r=requests.get(url, headers=headers, auth=auth) with", "label": 0}, {"snippet_id": 41712, "code": ".dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"", "label": 1}, {"snippet_id": 69525, "code": "=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs", "label": 0}, {"snippet_id": 65939, "code": " len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign", "label": 0}, {"snippet_id": 51681, "code": "]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex", "label": 0}, {"snippet_id": 51880, "code": " defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name", "label": 0}, {"snippet_id": 45156, "code": "(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func", "label": 0}, {"snippet_id": 60966, "code": "._capabilities @abc.abstractmethod def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" raise NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset", "label": 1}, {"snippet_id": 83141, "code": "\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information. Defaulting to datatypes_conf", "label": 0}, {"snippet_id": 37976, "code": ".error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile", "label": 0}, {"snippet_id": 37978, "code": " IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self", "label": 0}, {"snippet_id": 73507, "code": ": output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf", "label": 0}, {"snippet_id": 32778, "code": " chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake", "label": 0}, {"snippet_id": 56951, "code": " Exampls: 1. get_value_by_type('True', 'bool') (1, None) 2. get_value_by_type('19860624 123059', 'datetime') (datetime.datetime(1986, 6, 24, 12, 30, 59), None) 3. get_value_by_type('5', 'int') ('5', None", "label": 0}, {"snippet_id": 81645, "code": " self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes", "label": 1}, {"snippet_id": 34568, "code": " rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__", "label": 0}, {"snippet_id": 72372, "code": " reloadproto(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for changes to", "label": 0}, {"snippet_id": 73464, "code": "=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a Zarr format. Only converts a single VCF file. :param input_vcf_path", "label": 1}, {"snippet_id": 39538, "code": " ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule", "label": 0}, {"snippet_id": 55175, "code": "( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag", "label": 0}, {"snippet_id": 88403, "code": " *msg_elements) def __init__(self, options, run_tracker, target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser=None, address_mapper=None, console_outstream=None, scm", "label": 0}, {"snippet_id": 4601, "code": " found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already identified single keywords ", "label": 0}, {"snippet_id": 95624, "code": "'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and", "label": 0}, {"snippet_id": 25950, "code": "% data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self", "label": 0}, {"snippet_id": 90500, "code": " 1.7). :param Revision maximum_version: maximum jvm version to look for(eg, 1.7.9999). :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None", "label": 0}, {"snippet_id": 29175, "code": "._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile", "label": 0}, {"snippet_id": 8808, "code": " continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile", "label": 0}, {"snippet_id": 85352, "code": " from pants.backend.jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.base.build_environment import get_buildroot from pants", "label": 1}, {"snippet_id": 31623, "code": " self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict", "label": 0}, {"snippet_id": 49547, "code": " forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files", "label": 0}, {"snippet_id": 14637, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics)", "label": 0}, {"snippet_id": 76475, "code": ".running: self.log.info('Starting') try: self.child=self.call[0](*self.call[1], **self.call[2]) self.child(self) except WorkerInterrupt as e: self.log.warn(e) except Exception as e: self.log.exception(e", "label": 0}, {"snippet_id": 23527, "code": ")) passwd_hash=textutil.gen_password_hash(password, crypt_id, salt_len) cmd=\"echo '{0}'|pw usermod{1} -H 0 \".format(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret", "label": 0}, {"snippet_id": 26585, "code": "'co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id", "label": 0}, {"snippet_id": 23758, "code": " raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\") if ret: raise OSUtilError(\"Failed", "label": 0}, {"snippet_id": 92808, "code": "', allowZip64=False) as zf: self.assertFalse(zf._allowZip64) def test_open_zip_raises_exception_on_falsey_paths(self): falsey=(None, '', False) for invalid in falsey: with self.assertRaises(InvalidZipPath", "label": 0}, {"snippet_id": 68985, "code": " FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"", "label": 0}, {"snippet_id": 79578, "code": "] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file\"}) \t\t\t\tif len(fileInputs) > 0: \t\t\t\t\treturnForms.append((f,fileInputs)) \t\treturn returnForms", "label": 0}, {"snippet_id": 40421, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f", "label": 0}, {"snippet_id": 32986, "code": " in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\"", "label": 0}, {"snippet_id": 30587, "code": " Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards", "label": 0}, {"snippet_id": 76938, "code": "(d.ua_list) net.timeout=c.rp_timeout return net def upload_avatar(self, ud): if('avatar_uploaded' in ud[0] and ud[0]['avatar_uploaded'] is True): return files=[] for sd in os.walk(c.av_dir): files.extend", "label": 0}, {"snippet_id": 72363, "code": ".name, netname) remoteirc.reply=old_reply remoteirc.pseudoclient.account='' @utils.add_cmd def reloadproto(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without restart", "label": 1}, {"snippet_id": 47831, "code": "=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other", "label": 0}, {"snippet_id": 32528, "code": " be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the", "label": 0}, {"snippet_id": 67016, "code": "(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]]", "label": 0}, {"snippet_id": 15596, "code": " OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup()", "label": 0}, {"snippet_id": 3844, "code": " os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel", "label": 0}, {"snippet_id": 15255, "code": "._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request", "label": 0}, {"snippet_id": 73682, "code": "/data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError:", "label": 0}, {"snippet_id": 5529, "code": " in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*'", "label": 0}, {"snippet_id": 94529, "code": " check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid", "label": 0}, {"snippet_id": 89531, "code": ":param maximum_version: a modified semantic version string or else a Revision object :param bool jdk: ``True`` to require the distribution be a JDK vs a JRE \"\"\" if home_path and not os.path.isdir(home_path", "label": 0}, {"snippet_id": 35704, "code": " end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index,", "label": 0}, {"snippet_id": 63952, "code": " __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution==\"remote\" if not remote_dependency_resolution", "label": 0}, {"snippet_id": 70158, "code": " target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print ", "label": 0}, {"snippet_id": 45661, "code": ".compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def", "label": 0}, {"snippet_id": 30946, "code": " \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing", "label": 0}, {"snippet_id": 41794, "code": " f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self", "label": 0}, {"snippet_id": 82823, "code": ".detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime", "label": 0}, {"snippet_id": 63946, "code": "=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client", "label": 1}, {"snippet_id": 45816, "code": "] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint", "label": 0}, {"snippet_id": 89325, "code": " import contextmanager from future.utils import PY3 from six import string_types from pants.base.revision import Revision from pants.java.util import execute_java, execute_java_async from pants.subsystem", "label": 1}, {"snippet_id": 95109, "code": ".read_configuration(location=cli_arguments[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running FTP download...", "label": 0}, {"snippet_id": 95010, "code": " file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type", "label": 1}, {"snippet_id": 46433, "code": "): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone", "label": 0}, {"snippet_id": 15545, "code": " self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data", "label": 0}, {"snippet_id": 70404, "code": " 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s:", "label": 0}, {"snippet_id": 32168, "code": " name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i", "label": 0}, {"snippet_id": 3266, "code": " and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None", "label": 0}, {"snippet_id": 64850, "code": "()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR", "label": 1}, {"snippet_id": 1403, "code": "=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap", "label": 0}, {"snippet_id": 64885, "code": ".FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return", "label": 0}, {"snippet_id": 77908, "code": " not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) def remove_target(domain", "label": 0}, {"snippet_id": 882, "code": " return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist", "label": 0}, {"snippet_id": 36856, "code": ".append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s", "label": 0}, {"snippet_id": 93031, "code": ".stdin.read()) print('garbage', file=sys.stdout) print('garbage', file=sys.stderr) def test_signal_handler_as(self): mock_initial_handler=1 mock_new_handler=2 with mock.patch('signal.signal', **PATCH_OPTS", "label": 0}, {"snippet_id": 30909, "code": " in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items()))", "label": 0}, {"snippet_id": 14370, "code": "( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http", "label": 0}, {"snippet_id": 85724, "code": "'.format(src, dst) for src, dst in rebases.items()) ) @memoized_method def _compiler_plugins_cp_entries(self): \"\"\"Any additional global compiletime classpath entries for compiler plugins.\"\"\" java_options_src", "label": 0}, {"snippet_id": 82237, "code": ".default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\")", "label": 0}, {"snippet_id": 30377, "code": "\" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist", "label": 0}, {"snippet_id": 2726, "code": "'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp)", "label": 0}, {"snippet_id": 836, "code": ".Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n", "label": 0}, {"snippet_id": 7887, "code": "+=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if", "label": 0}, {"snippet_id": 20150, "code": "'debugger already running') assert self._session is None self._adapter=DebugAdapter.start(argv, port=self._port) return self._adapter def host_local_debugger(self, argv, script=None, env=None, cwd=None, *", "label": 0}, {"snippet_id": 29562, "code": "(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern)", "label": 0}, {"snippet_id": 56939, "code": " if tag.pk==self.counter['tag']: return self.counter[self.key] return 0 def get_value_by_type(val, v_type): \"\"\" Exampls: 1. get_value_by_type('True', 'bool') (1, None) 2. get_value_by_type('19860624 123059", "label": 0}, {"snippet_id": 35876, "code": "\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise", "label": 0}, {"snippet_id": 87339, "code": "[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self", "label": 1}, {"snippet_id": 15634, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics)", "label": 0}, {"snippet_id": 19018, "code": " 'deferred_references': set(), } swagger_definitions=definitions_validator(raw_schema, context=context) swagger_schema=swagger_schema_validator( raw_schema, context=swagger_definitions, ) return swagger_schema", "label": 0}, {"snippet_id": 55648, "code": " def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate", "label": 0}, {"snippet_id": 69425, "code": "._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(", "label": 0}, {"snippet_id": 75247, "code": " del self.req_handlers[(interface, method)] def del_response_handler(self, reqid): del self.response_handlers[reqid] def del_sig_handler(self, interface, method): del self.sig_handlers[(interface, method", "label": 0}, {"snippet_id": 54801, "code": " quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False", "label": 0}, {"snippet_id": 90776, "code": " .format(dist, minimum_version, maximum_version, jdk)) return dist except(ValueError, Distribution.Error) as e: logger.debug('{} is not a valid distribution because:{}' .format(location.home_path, str(e", "label": 0}, {"snippet_id": 1161, "code": "\nfrom django.shortcuts import render from django.http import HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework", "label": 0}, {"snippet_id": 48598, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=", "label": 0}, {"snippet_id": 14489, "code": "']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if", "label": 0}, {"snippet_id": 34061, "code": " to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all", "label": 0}, {"snippet_id": 46182, "code": " value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given", "label": 0}, {"snippet_id": 60969, "code": ": \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" raise NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset the backend state. After the reset the backend should", "label": 0}, {"snippet_id": 62078, "code": ") verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM", "label": 0}, {"snippet_id": 74313, "code": " \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data", "label": 0}, {"snippet_id": 16240, "code": " for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface", "label": 0}, {"snippet_id": 81007, "code": "\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity >", "label": 0}, {"snippet_id": 14545, "code": ") and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self", "label": 0}, {"snippet_id": 23392, "code": ".read_file(rc_file_path).split(\"\\n\") textutil.set_ini_config(conf_file, \"hostname\", hostname) fileutil.write_file(rc_file_path, \"\\n\".join(conf_file)) shellutil.run(\"hostname{0}\".format(hostname), chk_err", "label": 0}, {"snippet_id": 2417, "code": " __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self", "label": 0}, {"snippet_id": 81599, "code": "{\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t ", "label": 0}, {"snippet_id": 87450, "code": "':'.join(relative_classpath), '-d', classes_dir, ]) if not self.get_options().colors: zinc_args.append('-no-color') zinc_args.extend(['-compiler-interface', compiler_interface]) zinc_args.extend(['-compiler", "label": 1}, {"snippet_id": 77445, "code": "'.join((wname, 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'pr{0}'.format", "label": 0}, {"snippet_id": 61947, "code": " logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops", "label": 0}, {"snippet_id": 17133, "code": " from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import", "label": 0}, {"snippet_id": 49045, "code": " snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp,", "label": 1}, {"snippet_id": 59672, "code": " i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ", "label": 0}, {"snippet_id": 1808, "code": "=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id", "label": 0}, {"snippet_id": 29483, "code": "\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing", "label": 0}, {"snippet_id": 25351, "code": " monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions", "label": 0}, {"snippet_id": 39312, "code": ".path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack", "label": 0}, {"snippet_id": 15552, "code": "._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification(", "label": 0}, {"snippet_id": 37196, "code": " non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )", "label": 0}, {"snippet_id": 88447, "code": "._products=Products() self._buildroot=get_buildroot() self._source_roots=SourceRootConfig.global_instance().get_source_roots() self._lock=OwnerPrintingInterProcessFileLock(os.path.join(self._buildroot, '.pants", "label": 0}, {"snippet_id": 31694, "code": " else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for", "label": 0}, {"snippet_id": 40976, "code": " toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self", "label": 0}, {"snippet_id": 18739, "code": " self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded", "label": 0}, {"snippet_id": 67778, "code": " RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 0}, {"snippet_id": 39118, "code": "=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster", "label": 0}, {"snippet_id": 82489, "code": "-regex.\") if args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args", "label": 0}, {"snippet_id": 73756, "code": "(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\"", "label": 0}, {"snippet_id": 77426, "code": "'Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: if type_==0: w=workers.WZWorkerThread( self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'th{0}'.format(i))", "label": 0}, {"snippet_id": 59256, "code": "\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate", "label": 0}, {"snippet_id": 57723, "code": " confirm_status_name='CONFIRMED' plan.run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count()", "label": 0}, {"snippet_id": 31000, "code": " existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested)", "label": 0}, {"snippet_id": 15037, "code": " filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line", "label": 0}, {"snippet_id": 88982, "code": ".inject_synthetic_target(address=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from, **kwargs) new_target=self.build_graph.get_target(address) return new_target def targets(self, predicate", "label": 0}, {"snippet_id": 45174, "code": " decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input", "label": 0}, {"snippet_id": 85501, "code": " ]) cls.register_jvm_tool(register, 'compiler-interface', classpath=[ JarDependency(org='org.scala-sbt', name='compiler-interface', rev=zinc_rev), ], main='no.such.main.Main', custom_rules=shader_rules", "label": 0}, {"snippet_id": 60020, "code": " specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs", "label": 0}, {"snippet_id": 47801, "code": "=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None", "label": 0}, {"snippet_id": 49508, "code": "=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules", "label": 0}, {"snippet_id": 89513, "code": " bin_path: the path to the java distribution's bin dir :param minimum_version: a modified semantic version string or else a Revision object :param maximum_version: a modified semantic version string or", "label": 0}, {"snippet_id": 76019, "code": "'Recvd unknown reply for(%s, %s) %s: %s', i, m, wzrpc.name_status(status), repr(data)) self.wz_wait_reply(accept, *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m])) def bind_route(self, i, m, f)", "label": 0}, {"snippet_id": 63100, "code": " job_state def __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running:", "label": 0}, {"snippet_id": 45209, "code": ".priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile", "label": 0}, {"snippet_id": 30391, "code": " class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then", "label": 0}, {"snippet_id": 51579, "code": " wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb", "label": 0}, {"snippet_id": 23622, "code": " default gw, not a all-ones broadcast address, need to specify the route manually to get it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return", "label": 0}, {"snippet_id": 83594, "code": " output_paths=job_wrapper.get_output_fnames() return[ str( o) for o in output_paths] def get_input_files(self, job_wrapper): input_paths=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def", "label": 0}, {"snippet_id": 14732, "code": "._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'", "label": 0}, {"snippet_id": 9801, "code": ".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. ", "label": 0}, {"snippet_id": 41830, "code": ", requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f", "label": 0}, {"snippet_id": 9719, "code": " only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws", "label": 0}, {"snippet_id": 94446, "code": " run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\"", "label": 0}, {"snippet_id": 83329, "code": " async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config,", "label": 0}, {"snippet_id": 65115, "code": " if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target", "label": 0}, {"snippet_id": 71062, "code": ")\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [", "label": 0}, {"snippet_id": 17152, "code": " from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from", "label": 0}, {"snippet_id": 54202, "code": " output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self", "label": 0}, {"snippet_id": 78689, "code": "(*sys.argv) log.logger.debug('Executing locally') return self.execute() except BaseException as e: log.logger.exception(e) if log.logger.getEffectiveLevel() <=logging.DEBUG: if os.getenv('UNITTEST', 'False", "label": 0}, {"snippet_id": 16806, "code": "._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os", "label": 0}, {"snippet_id": 39201, "code": "(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats", "label": 0}, {"snippet_id": 42632, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"", "label": 0}, {"snippet_id": 25829, "code": "'WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 11043, "code": "'last-modified') mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y %H:%M:%S %Z').strftime('%s') if mtime else int(time()) else: msg=\"Request %s returned with status %s. I don't know how to handle that.", "label": 0}, {"snippet_id": 12291, "code": "(error) for error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com", "label": 0}, {"snippet_id": 80177, "code": " action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents", "label": 0}, {"snippet_id": 51258, "code": " in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{", "label": 0}, {"snippet_id": 6368, "code": " of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode", "label": 0}, {"snippet_id": 28674, "code": "'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp", "label": 0}, {"snippet_id": 63217, "code": ".__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description=dependencies_description", "label": 0}, {"snippet_id": 23060, "code": " the point where we should wait for mcpd to load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make", "label": 0}, {"snippet_id": 68609, "code": " DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets", "label": 0}, {"snippet_id": 41523, "code": "(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self", "label": 0}, {"snippet_id": 75089, "code": " b'bind-keepalive',[], self.handle_keepalive_reply) msg.insert(0, b'') self.p.wz_sock.send_multipart(msg) def handle_keepalive_reply(self, reqid, seqnum, status, data): if status==wzrpc.status.success:", "label": 0}, {"snippet_id": 69816, "code": " rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand)", "label": 0}, {"snippet_id": 37448, "code": "\"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may", "label": 0}, {"snippet_id": 78617, "code": " import pdb import urllib2 import json import ijson from dbnav.writer import Writer from dbnav import logger as log from dbnav.jsonable import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec': 'executer', ", "label": 0}, {"snippet_id": 29258, "code": " is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists", "label": 0}, {"snippet_id": 75678, "code": " 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests=[] self.wz_bind_methods=[] self.wz_poll_timeout=30 def __sinit__(self): '''Initializes thread-local interface on startup", "label": 1}, {"snippet_id": 87307, "code": " compiled copies of the `compiler-bridge`. The compiler-bridge is specific to each scala version, and is lazily computed by zinc if the appropriate version does not exist. Eventually it would be great to just", "label": 1}, {"snippet_id": 45884, "code": ") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards", "label": 0}, {"snippet_id": 8495, "code": " True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha", "label": 1}, {"snippet_id": 78270, "code": ".comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment,(t, msg)) except(exc.Closed, exc.UserDeny) as e: try: self.targets.remove(t) except", "label": 0}, {"snippet_id": 21180, "code": "+='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None): super(AwaitableResponse, self).__init__(req[\"command", "label": 0}, {"snippet_id": 49187, "code": " def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain", "label": 0}, {"snippet_id": 78534, "code": ":%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c=", "label": 0}, {"snippet_id": 52086, "code": " and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\")", "label": 0}, {"snippet_id": 92646, "code": " outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False) as path: self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self", "label": 0}, {"snippet_id": 54379, "code": "\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0", "label": 0}, {"snippet_id": 87405, "code": " compiler_interface=self._zinc.compiler_interface compiler_bridge=self._zinc.compiler_bridge classes_dir=ctx.classes_dir analysis_cache=ctx.analysis_file scala_path=tuple(relative_to_exec_root(c) for c", "label": 1}, {"snippet_id": 81480, "code": "\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f) \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt", "label": 0}, {"snippet_id": 74643, "code": " hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr", "label": 0}, {"snippet_id": 89840, "code": " this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if not isinstance(name, str): raise ValueError('name must be a binary name, given{} of type{}'.format(name, type(name))) self", "label": 0}, {"snippet_id": 21439, "code": " found, but no subreddit directory. Creating %s, and files.\" % sr_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s", "label": 0}, {"snippet_id": 21947, "code": " ask_pass=None, private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args=None, poll_interval=None, seconds", "label": 0}, {"snippet_id": 75205, "code": " self.req_handlers={} self.response_handlers={} self.sig_handlers={} self.iden_reqid_map=BijectiveSetMap() def set_req_handler(self, interface, method, fun): self.req_handlers[(interface, method)]=fun def", "label": 0}, {"snippet_id": 33756, "code": " ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" ", "label": 0}, {"snippet_id": 48944, "code": "*rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. ", "label": 0}, {"snippet_id": 46942, "code": "(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self", "label": 0}, {"snippet_id": 69589, "code": " from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF", "label": 0}, {"snippet_id": 31003, "code": "(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark)", "label": 0}, {"snippet_id": 35143, "code": "=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value", "label": 0}, {"snippet_id": 21047, "code": ", False lock.release() return msg, True self._add_handler(handler, handlername) try: yield finally: wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername", "label": 0}, {"snippet_id": 59020, "code": ".group_nitrate, property=cls.property_python) EnvGroupPropertyMapFactory(group=cls.group_new, property=cls.property_django) def test_get_env_properties(self): response=self.client.get(self.get_info_url", "label": 0}, {"snippet_id": 33750, "code": " resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources", "label": 0}, {"snippet_id": 76240, "code": " wzauth_data.bind_route[i, m])) def clear_auth(self): self.log.debug('Clearing our auth records') def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Auth records on", "label": 0}, {"snippet_id": 52872, "code": "=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 93079, "code": ", mock_initial_handler) ]) def test_permissions(self): with temporary_file(permissions=0o700) as f: self.assertEqual(0o700, os.stat(f.name)[0] & 0o777) with temporary_dir(permissions=0o644) as path: self", "label": 0}, {"snippet_id": 20326, "code": " RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ '-m', module, ] +list(argv) if kwargs.pop('nodebug', False)", "label": 0}, {"snippet_id": 18153, "code": " FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest", "label": 0}, {"snippet_id": 20157, "code": "._adapter=DebugAdapter.start(argv, port=self._port) return self._adapter def host_local_debugger(self, argv, script=None, env=None, cwd=None, **kwargs): if self.closed: raise RuntimeError('debug client closed'", "label": 0}, {"snippet_id": 74953, "code": ".benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config=runtime_config) def read_configuration(location): \"\"\"", "label": 1}, {"snippet_id": 58550, "code": "='password') new_comment='new comment' response=self.client.post( self.many_comments_url, {'comment': new_comment, 'run': ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual", "label": 0}, {"snippet_id": 68790, "code": "[\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 53033, "code": ".nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\")", "label": 0}, {"snippet_id": 15681, "code": " 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else", "label": 0}, {"snippet_id": 23673, "code": ": shellutil.run(\"route delete 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]=", "label": 0}, {"snippet_id": 93137, "code": " from setupParser import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import", "label": 0}, {"snippet_id": 49213, "code": ".contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition", "label": 0}, {"snippet_id": 5458, "code": ".append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches", "label": 0}, {"snippet_id": 79205, "code": "\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t", "label": 0}, {"snippet_id": 69984, "code": " def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs", "label": 0}, {"snippet_id": 7432, "code": "=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]", "label": 0}, {"snippet_id": 32218, "code": "(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str", "label": 0}, {"snippet_id": 30503, "code": ", max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat", "label": 0}, {"snippet_id": 14894, "code": ": return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout", "label": 0}, {"snippet_id": 89368, "code": " import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version): if isinstance(version, string_types): version=Revision.lenient(version) if version and not isinstance(version", "label": 0}, {"snippet_id": 36512, "code": ".reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format", "label": 0}, {"snippet_id": 36133, "code": "(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^", "label": 0}, {"snippet_id": 50245, "code": " name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input", "label": 0}, {"snippet_id": 90550, "code": " def locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets the given constraints and returns it. First looks for a cached version that was previously", "label": 0}, {"snippet_id": 69713, "code": "\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import", "label": 0}, {"snippet_id": 24488, "code": " return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if", "label": 0}, {"snippet_id": 31553, "code": "=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self", "label": 0}, {"snippet_id": 31239, "code": "=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self", "label": 0}, {"snippet_id": 21383, "code": " unseen_links=[] print(\"Reddytt: Checking for reddytt working directory(%s).\" % work_dir) if not os.path.isdir(work_dir): print(\"Reddytt: Working directory not found. Creating %s, and files.\" % work_dir) os", "label": 0}, {"snippet_id": 15047, "code": ", 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data", "label": 0}, {"snippet_id": 93330, "code": " Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s", "label": 0}, {"snippet_id": 74927, "code": ".benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"] if \"benchmark_aggregations\" in runtime_config", "label": 0}, {"snippet_id": 44227, "code": "\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( ", "label": 0}, {"snippet_id": 12461, "code": "=error_string_list[1][:-1].split(\":\") line_url=data[file +\"_link\"] +\" error_string_list[1]=\"[{0}:{1}]({2}):\".format(line, col, line_url) error_string=\" \".join(error_string_list) error_string=error_string.replace(\"Line[", "label": 0}, {"snippet_id": 29438, "code": ":first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other", "label": 0}, {"snippet_id": 95971, "code": " in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided", "label": 0}, {"snippet_id": 94796, "code": " a component check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode", "label": 0}, {"snippet_id": 71191, "code": " target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"", "label": 0}, {"snippet_id": 38219, "code": " snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp,", "label": 1}, {"snippet_id": 61769, "code": " np.any(wires >=self.wires) or wires[0]==wires[1]: raise ValueError('Bad target subsystems.') a=np.min(wires) b=np.max(wires) n_between=b-a-1 before =2**a after =2**(self.wires-b-1) between=2**n_between", "label": 0}, {"snippet_id": 39777, "code": ".func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version", "label": 0}, {"snippet_id": 3523, "code": " if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED", "label": 0}, {"snippet_id": 24558, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise':", "label": 0}, {"snippet_id": 17058, "code": "=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status", "label": 0}, {"snippet_id": 41227, "code": " pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except", "label": 0}, {"snippet_id": 27595, "code": "'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180", "label": 0}, {"snippet_id": 66162, "code": ".1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags", "label": 0}, {"snippet_id": 5137, "code": " _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw", "label": 0}, {"snippet_id": 40136, "code": " in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file)", "label": 0}, {"snippet_id": 71613, "code": "(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf", "label": 0}, {"snippet_id": 61478, "code": "=self.expand_two(U, operation.wires) else: raise ValueError('This plugin supports only one-and two-qubit gates.') self._state=U @ self._state A=DefaultQubit._get_operator_matrix(self._observe) if self.shots", "label": 0}, {"snippet_id": 95243, "code": ", FTP_TLS, error_perm import time import csv import logging import os.path import pathlib import allel import sys import functools import numpy as np import zarr import numcodecs from numcodecs import Blosc", "label": 1}, {"snippet_id": 44994, "code": "=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self", "label": 0}, {"snippet_id": 65082, "code": " target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print ", "label": 0}, {"snippet_id": 6899, "code": "..],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext", "label": 0}, {"snippet_id": 73710, "code": ": \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): \"\"\" Initializes the configuration representation with a supplied file. \"\"\" parser=ConfigParser", "label": 0}, {"snippet_id": 35206, "code": "\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually", "label": 0}, {"snippet_id": 45602, "code": ".snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic", "label": 0}, {"snippet_id": 23062, "code": " wait for mcpd to load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make when mounting the provisioningiso", "label": 0}, {"snippet_id": 11649, "code": "--targetdir'], arg['--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN if file_name else EXIT_CODE_NOT_WRITTEN except HostUnreachableException: LOG.warn(\"Target url{0} unreachable. Could not", "label": 0}, {"snippet_id": 16967, "code": ", headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data", "label": 1}, {"snippet_id": 47277, "code": " not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output", "label": 0}, {"snippet_id": 86468, "code": ".jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.zinc import Zinc from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm", "label": 0}, {"snippet_id": 51664, "code": " given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname", "label": 0}, {"snippet_id": 105, "code": "-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"", "label": 0}, {"snippet_id": 81140, "code": "=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload:", "label": 0}, {"snippet_id": 48445, "code": ": raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in", "label": 0}, {"snippet_id": 64035, "code": " from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason -datatypes may not match. One can push the local datatypes", "label": 0}, {"snippet_id": 49673, "code": " trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by", "label": 0}, {"snippet_id": 94234, "code": ": self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else", "label": 0}, {"snippet_id": 30007, "code": "\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re", "label": 0}, {"snippet_id": 82234, "code": ",default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting", "label": 0}, {"snippet_id": 39218, "code": "(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile", "label": 0}, {"snippet_id": 59715, "code": " has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key", "label": 0}, {"snippet_id": 30369, "code": "(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist", "label": 0}, {"snippet_id": 39009, "code": ") return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary:", "label": 0}, {"snippet_id": 13767, "code": ".parser as dp _safe_globals={\"__builtins__\":None} _safe_locals={} for k in[]: _safe_locals[k]=eval(k) for k, v in np.__dict__.iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start", "label": 1}, {"snippet_id": 91898, "code": ".objects import SubclassesOf logger=logging.getLogger(__name__) class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope=", "label": 1}, {"snippet_id": 90061, "code": ", stderr.decode('utf-8'))) props={} for line in stdout.decode('utf-8').split(os.linesep): key, _, val=line.partition('=') props[key]=val self._system_properties=props return self._system_properties def", "label": 0}, {"snippet_id": 72037, "code": " networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1", "label": 0}, {"snippet_id": 62815, "code": " importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm", "label": 0}, {"snippet_id": 56986, "code": "'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid literal for int() with base 10: 'string'\") \"\"\" value=error=None def get_time(time): date_time=datetime.datetime if time=", "label": 0}, {"snippet_id": 69233, "code": " msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except", "label": 0}, {"snippet_id": 67839, "code": ".get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if", "label": 0}, {"snippet_id": 65971, "code": "(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted", "label": 0}, {"snippet_id": 66515, "code": " def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support", "label": 0}, {"snippet_id": 15307, "code": " self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), ", "label": 0}, {"snippet_id": 52836, "code": " def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input", "label": 0}, {"snippet_id": 13071, "code": ": FORKED=False url=\"https://api.github.com/repos/{}/forks\" url=url.format(data[\"target_repo_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"],", "label": 0}, {"snippet_id": 27416, "code": "._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self", "label": 0}, {"snippet_id": 22236, "code": "=self.conf['playbook'] if template is None and template in self.conf: template=self.conf['template'] if log_file is None: if 'log_file' in self.conf: log_file=self.conf['log_file'] else: log_file=open(os", "label": 0}, {"snippet_id": 54312, "code": "): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__", "label": 0}, {"snippet_id": 8488, "code": " @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) /", "label": 1}, {"snippet_id": 54859, "code": "=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is", "label": 0}, {"snippet_id": 50847, "code": "\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access", "label": 1}, {"snippet_id": 16638, "code": ".Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not", "label": 0}, {"snippet_id": 36358, "code": "(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing", "label": 0}, {"snippet_id": 76731, "code": "'--rp-timeout', '-T', type=int, default=10, help='Default rp timeout in seconds') parser.add_argument('--conlimit', type=int, default=3, help='http_request conlimit') parser.add_argument('--noproxy-timeout", "label": 0}, {"snippet_id": 14834, "code": " dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ ", "label": 0}, {"snippet_id": 72708, "code": "=zarr_directory_setup, conversion_config=vcf_to_zarr_config) elif command==\"exec\": print(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location=cli_arguments[\"config_file", "label": 1}, {"snippet_id": 61393, "code": " __init__(self, wires, *, shots=0): self.wires=wires self.eng=None self._state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure", "label": 1}, {"snippet_id": 95173, "code": "(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def main()", "label": 0}, {"snippet_id": 39662, "code": " benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo", "label": 0}, {"snippet_id": 37640, "code": " kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str", "label": 0}, {"snippet_id": 69785, "code": ") def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client", "label": 1}, {"snippet_id": 12000, "code": ".text) config=update_dict(config, new_config) except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key, value in confs.items(): if value: if isinstance(value, int): if isinstance(value", "label": 0}, {"snippet_id": 21234, "code": "] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get('href') for a", "label": 0}, {"snippet_id": 14719, "code": "{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def", "label": 0}, {"snippet_id": 87911, "code": "}'.format(':'.join(cp_entries))) for arg in scalac_plugin_map[name]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from", "label": 0}, {"snippet_id": 58515, "code": " password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run': '99999998,1009900'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {", "label": 0}, {"snippet_id": 88758, "code": " self.run_tracker.background_worker_pool() def subproc_map(self, f, items): \"\"\"Map function `f` over `items` in subprocesses and return the result. :API: public :param f: A multiproc-friendly(importable)", "label": 0}, {"snippet_id": 42568, "code": " exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output", "label": 0}, {"snippet_id": 37795, "code": "): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start", "label": 0}, {"snippet_id": 63542, "code": " return self.client_manager.get_client( job_destination_params, **get_client_kwds) def finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state", "label": 0}, {"snippet_id": 49818, "code": " input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag)", "label": 0}, {"snippet_id": 5424, "code": "]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords", "label": 0}, {"snippet_id": 45289, "code": "(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input", "label": 0}, {"snippet_id": 15647, "code": ".ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics", "label": 0}, {"snippet_id": 20337, "code": " absolute_import, print_function import contextlib import json import socket import sys import time import threading import warnings from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.message", "label": 0}, {"snippet_id": 53346, "code": " else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for", "label": 0}, {"snippet_id": 25282, "code": " '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol", "label": 1}, {"snippet_id": 37253, "code": ") @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item", "label": 0}, {"snippet_id": 65138, "code": ": print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s", "label": 0}, {"snippet_id": 77120, "code": " self.th_sock.bind(self.th_sa) def init_th_back_sock(self): self.log.info( 'Initializing intraprocess backward socket %s', self.th_ba) self.th_back_sock=self.p.ctx.socket(zmq.ROUTER) self.th_back_sock.bind", "label": 0}, {"snippet_id": 88506, "code": " @property def log(self): \"\"\"Returns the preferred logger for goals to use. :API: public \"\"\" return self._log @property def products(self): \"\"\"Returns the Products manager for the current run. :API: public ", "label": 0}, {"snippet_id": 33629, "code": ".persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\"", "label": 0}, {"snippet_id": 36124, "code": ".input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule", "label": 0}, {"snippet_id": 40402, "code": "[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(", "label": 0}, {"snippet_id": 3234, "code": " self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException", "label": 0}, {"snippet_id": 92612, "code": " test_temporary_dir_no_args(self): with temporary_dir() as path: self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self.assertTrue(os.path.isdir(path), 'Temporary dir", "label": 0}, {"snippet_id": 546, "code": ".POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action", "label": 0}, {"snippet_id": 18968, "code": ": response=requests.get(source) if isinstance(response.content, six.binary_type): raw_source=six.text_type(response.content, encoding='utf-8') else: raw_source=response.content else: raw_source=source try", "label": 0}, {"snippet_id": 15403, "code": " if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output", "label": 0}, {"snippet_id": 26810, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 26162, "code": ") SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise", "label": 1}, {"snippet_id": 52433, "code": " f in self.input) return self._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except", "label": 0}, {"snippet_id": 66121, "code": ".state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size", "label": 0}, {"snippet_id": 52639, "code": "): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output", "label": 0}, {"snippet_id": 63710, "code": " OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid", "label": 0}, {"snippet_id": 84480, "code": " remote_path[ 0:-len( \".dat\")] return local_dataset_path.with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self", "label": 0}, {"snippet_id": 43004, "code": " str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start,", "label": 0}, {"snippet_id": 18027, "code": ".CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value':", "label": 0}, {"snippet_id": 24710, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'", "label": 0}, {"snippet_id": 85061, "code": ".10') register_scala_repl_tool('2.10', with_jline=True) register_style_tool('2.10') register_scala_compiler_tool('2.11') register_scala_repl_tool('2.11') register_style_tool('2.11') register_scala_compiler_tool", "label": 0}, {"snippet_id": 15499, "code": " self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler(", "label": 0}, {"snippet_id": 12238, "code": "[pycodestyle_cmd_config]} file_to_check.py'.format( config=config) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"extra_results\"][filename]=stdout.decode(r.encoding)", "label": 0}, {"snippet_id": 36850, "code": "=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job", "label": 0}, {"snippet_id": 41973, "code": " in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(", "label": 0}, {"snippet_id": 3993, "code": "\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc", "label": 0}, {"snippet_id": 30985, "code": " def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"", "label": 0}, {"snippet_id": 79918, "code": " an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group() exclusiveArgs.add_argument(\"-l\",\"--legit-extensions\",metavar=\"listOfExtensions\",dest=\"legitExtensions", "label": 0}, {"snippet_id": 64351, "code": "( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[ parameter_value] if parameter_value", "label": 0}, {"snippet_id": 90696, "code": " minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets any given constraints and returns it. :param minimum_version: minimum jvm version to look for(eg, 1.7). ", "label": 0}, {"snippet_id": 70323, "code": " fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target", "label": 0}, {"snippet_id": 39639, "code": "(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self", "label": 0}, {"snippet_id": 61559, "code": ". Returns: array: matrix representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)) if not callable(operator_map[A.name]): return", "label": 0}, {"snippet_id": 33734, "code": "\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info(", "label": 0}, {"snippet_id": 60420, "code": ": ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self.observe.params) if self.shots !=0: ex=np.random.normal(ex, np.sqrt", "label": 0}, {"snippet_id": 82888, "code": "(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[\"templateName\"]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants", "label": 1}, {"snippet_id": 29823, "code": "\"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 92509, "code": ".realpath(tempdir1), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_temporary_file_no_args(self)", "label": 0}, {"snippet_id": 32953, "code": "() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not", "label": 0}, {"snippet_id": 58100, "code": ".case_run_id==run.pk: run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs(p_pks, target): \"\"\" Get Component, Version, Category, and Build", "label": 0}, {"snippet_id": 66672, "code": ")) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help", "label": 0}, {"snippet_id": 27437, "code": "._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property", "label": 0}, {"snippet_id": 75254, "code": " del_response_handler(self, reqid): del self.response_handlers[reqid] def del_sig_handler(self, interface, method): del self.sig_handlers[(interface, method)] def _parse_req(self, iden, msg, reqid, interface, method):", "label": 0}, {"snippet_id": 7947, "code": "\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone", "label": 0}, {"snippet_id": 4597, "code": " bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary", "label": 0}, {"snippet_id": 29546, "code": " match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs", "label": 0}, {"snippet_id": 3468, "code": "\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" %", "label": 0}, {"snippet_id": 229, "code": "(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess", "label": 0}, {"snippet_id": 49322, "code": " list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources", "label": 0}, {"snippet_id": 44074, "code": " items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is", "label": 0}, {"snippet_id": 59635, "code": ".deallocate_qubit(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"", "label": 0}, {"snippet_id": 46150, "code": "=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str", "label": 0}, {"snippet_id": 18634, "code": "._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady", "label": 0}, {"snippet_id": 11648, "code": "['--targetdir'], arg['--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN if file_name else EXIT_CODE_NOT_WRITTEN except HostUnreachableException: LOG.warn(\"Target url{0} unreachable. Could not", "label": 0}, {"snippet_id": 77181, "code": " def read_newproxies(self): if not os.path.isfile(self.newproxyfile): return newproxies=set() with open(self.newproxyfile, 'rt') as f: for line in f: try: line=line.rstrip('\\n') proxypair=tuple(line.split", "label": 1}, {"snippet_id": 84713, "code": "', '--report-file=report', ) req=ExecuteProcessRequest( argv=cmd, input_files=directory_digest, output_files=('ignored', 'report'), description='cloc', ) exec_result=self.context.execute_process_synchronously", "label": 1}, {"snippet_id": 41641, "code": " variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self", "label": 0}, {"snippet_id": 70341, "code": " fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support", "label": 0}, {"snippet_id": 73405, "code": " the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir", "label": 0}, {"snippet_id": 19709, "code": "=Address.as_server(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port", "label": 0}, {"snippet_id": 37895, "code": " ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards", "label": 0}, {"snippet_id": 2838, "code": "(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" ", "label": 0}, {"snippet_id": 79111, "code": " \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif", "label": 1}, {"snippet_id": 57183, "code": " hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), value ) ) except(AttributeError, User.DoesNotExist", "label": 0}, {"snippet_id": 86648, "code": " that all arguments match whitelisted regexes.\"\"\" valid_patterns={re.compile(p): v for p, v in whitelisted_args.items()} def validate(idx): arg=args[idx] for pattern, has_argument in valid_patterns.items", "label": 0}, {"snippet_id": 70096, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s ", "label": 0}, {"snippet_id": 15031, "code": " query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num", "label": 0}, {"snippet_id": 49385, "code": ", prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False", "label": 0}, {"snippet_id": 87931, "code": "\"\"\"Returns a map from plugin name to list of plugin classpath entries. The first entry in each list is the classpath entry containing the plugin metadata. The rest are the internal transitive deps of the", "label": 0}, {"snippet_id": 18665, "code": "'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive", "label": 0}, {"snippet_id": 55568, "code": " self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is", "label": 0}, {"snippet_id": 44782, "code": " dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames", "label": 0}, {"snippet_id": 78743, "code": " request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError", "label": 0}, {"snippet_id": 36360, "code": " Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f", "label": 0}, {"snippet_id": 16365, "code": "._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost", "label": 0}, {"snippet_id": 50935, "code": " try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for", "label": 0}, {"snippet_id": 67019, "code": " a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args", "label": 0}, {"snippet_id": 23571, "code": " raise OSUtilError(\"Failed to delete root password: Failed to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper(", "label": 0}, {"snippet_id": 40796, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{", "label": 0}, {"snippet_id": 34134, "code": "]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule", "label": 0}, {"snippet_id": 82217, "code": " exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent", "label": 0}, {"snippet_id": 67154, "code": "\"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use", "label": 0}, {"snippet_id": 57703, "code": "(self.target_field): self.new_value}) try: plan=plan_from_request_or_none(self.request) except Http404: return say_no(\"No plan record found.\") else: if plan is None: return say_no('No plan record found.", "label": 0}, {"snippet_id": 33344, "code": ", forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete", "label": 0}, {"snippet_id": 17610, "code": "._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()", "label": 0}, {"snippet_id": 28281, "code": "'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol", "label": 1}, {"snippet_id": 56223, "code": " import POST_UPDATE_SIGNAL from tcms.management.models import Component, Build, Version from tcms.management.models import Priority from tcms.management.models import Tag from tcms.management.models import", "label": 0}, {"snippet_id": 92349, "code": " stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**{}): self.assertNotIn(", "label": 1}, {"snippet_id": 25609, "code": "='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 45482, "code": ". \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard", "label": 1}, {"snippet_id": 26761, "code": "': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif", "label": 0}, {"snippet_id": 4571, "code": ">,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite", "label": 0}, {"snippet_id": 61702, "code": "=1: raise ValueError('One target subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U def expand_two(self, U", "label": 0}, {"snippet_id": 81695, "code": " executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms", "label": 0}, {"snippet_id": 93832, "code": "], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name'", "label": 0}, {"snippet_id": 65111, "code": "), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start", "label": 0}, {"snippet_id": 79395, "code": ") \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t", "label": 0}, {"snippet_id": 16953, "code": " handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff", "label": 1}, {"snippet_id": 79035, "code": " possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use", "label": 0}, {"snippet_id": 67799, "code": " target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs", "label": 0}, {"snippet_id": 36593, "code": " for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables", "label": 0}, {"snippet_id": 71680, "code": " Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import", "label": 0}, {"snippet_id": 23901, "code": "+iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0}\".format(iface)) for line in output.split('\\n'): if line.find('inet ') !=-1: inet=line.split()[1] elif line.find('ether ')", "label": 0}, {"snippet_id": 24612, "code": " and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 81828, "code": "\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help", "label": 0}, {"snippet_id": 56227, "code": ".management.models import Component, Build, Version from tcms.management.models import Priority from tcms.management.models import Tag from tcms.management.models import EnvGroup, EnvProperty, EnvValue", "label": 0}, {"snippet_id": 11264, "code": " written into this directory. If no target directory is given its value is read from /etc/monitoring_config_generator/config.yaml --skip-checks Do not run checks on the yaml file received from the URL. \"", "label": 0}, {"snippet_id": 71154, "code": ": return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state", "label": 0}, {"snippet_id": 33848, "code": ".isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self", "label": 0}, {"snippet_id": 58766, "code": "{ 'content_type': 'testruns.testcaserun', 'object_pk': self.case_run_1.pk, 'field': 'case_run_status', 'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual", "label": 0}, {"snippet_id": 83184, "code": " runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport", "label": 0}, {"snippet_id": 18581, "code": " _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self", "label": 0}, {"snippet_id": 39287, "code": "(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self", "label": 0}, {"snippet_id": 19069, "code": " defined in the swagger spec, validate that the schema complies to spec. If `target` is provided, that target will be validated against the provided schema. \"\"\" schema=schema_validator(raw_schema, **kwargs", "label": 0}, {"snippet_id": 44089, "code": " not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules", "label": 0}, {"snippet_id": 26719, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500:", "label": 0}, {"snippet_id": 64894, "code": " name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self", "label": 0}, {"snippet_id": 39513, "code": "(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority", "label": 0}, {"snippet_id": 57261, "code": " from %s to %s.' %( field, getattr(t, field), now ) ) if t.tested_by !=request.user: field='tested_by' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field),", "label": 0}, {"snippet_id": 88834, "code": ".new_workunit(name=name, labels=labels, cmd=cmd, log_config=log_config) as workunit: yield workunit def acquire_lock(self): \"\"\" Acquire the global lock for the root directory associated with this context.", "label": 0}, {"snippet_id": 59586, "code": "/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure)", "label": 0}, {"snippet_id": 70085, "code": " handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients", "label": 0}, {"snippet_id": 51074, "code": ".compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def", "label": 0}, {"snippet_id": 6806, "code": "=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode", "label": 0}, {"snippet_id": 82432, "code": "'%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions", "label": 0}, {"snippet_id": 84300, "code": " path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home default_config_file", "label": 0}, {"snippet_id": 88216, "code": " target.has_sources('.java') or target.has_sources('.scala') def select_source(self, source_file_path): return source_file_path.endswith('.java') or source_file_path.endswith('.scala') def execute(self): if", "label": 0}, {"snippet_id": 95370, "code": "=ftp_config.directory) else: ftp.cwd(ftp_config.directory) file_counter=1 file_list_total=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join", "label": 0}, {"snippet_id": 2373, "code": "(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname", "label": 0}, {"snippet_id": 43572, "code": " comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self)", "label": 0}, {"snippet_id": 69015, "code": ".fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount", "label": 0}, {"snippet_id": 37007, "code": " self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self", "label": 0}, {"snippet_id": 68761, "code": " ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [", "label": 0}, {"snippet_id": 8132, "code": " file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory", "label": 0}, {"snippet_id": 53174, "code": " the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self", "label": 0}, {"snippet_id": 46095, "code": ": if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards)", "label": 0}, {"snippet_id": 64337, "code": "._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self._sep def version_path( self): return", "label": 0}, {"snippet_id": 40439, "code": " will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else ", "label": 0}, {"snippet_id": 66998, "code": ".getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine", "label": 0}, {"snippet_id": 81260, "code": " uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t", "label": 1}, {"snippet_id": 16886, "code": "( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET", "label": 0}, {"snippet_id": 8157, "code": " abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise", "label": 0}, {"snippet_id": 81078, "code": "(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit() \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to", "label": 0}, {"snippet_id": 45127, "code": " return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 89569, "code": " path is invalid:{}'.format(bin_path)) if not bool(home_path) ^ bool(bin_path): raise ValueError('Exactly one of home path or bin path should be supplied, given: ' 'home_path={} bin_path={}'.format(home_path", "label": 0}, {"snippet_id": 34743, "code": ", mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but", "label": 1}, {"snippet_id": 40020, "code": " ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os", "label": 1}, {"snippet_id": 92345, "code": " in os.environ)'], stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**", "label": 1}, {"snippet_id": 61753, "code": " ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires < 0) or np.any(wires >=self.wires) or wires[0]==wires[1]", "label": 0}, {"snippet_id": 68426, "code": " if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len", "label": 0}, {"snippet_id": 10844, "code": ": lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines", "label": 1}, {"snippet_id": 84897, "code": " classpath=[cls._create_compiler_jardep(version)]) def register_scala_repl_tool(version, with_jline=False): classpath=[cls._create_compiler_jardep(version)] if with_jline: jline_dep=JarDependency( org='org", "label": 0}, {"snippet_id": 50878, "code": ".file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self", "label": 1}, {"snippet_id": 42897, "code": " self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"", "label": 0}, {"snippet_id": 67589, "code": ".update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(),", "label": 0}, {"snippet_id": 1357, "code": " \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def", "label": 0}, {"snippet_id": 28688, "code": "'battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data[", "label": 0}, {"snippet_id": 8226, "code": " is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio", "label": 1}, {"snippet_id": 28119, "code": " homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity", "label": 0}, {"snippet_id": 80578, "code": "\telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": ", "label": 0}, {"snippet_id": 39605, "code": "(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths", "label": 0}, {"snippet_id": 50578, "code": " return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class", "label": 0}, {"snippet_id": 27547, "code": "=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data[", "label": 0}, {"snippet_id": 50623, "code": " self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir", "label": 0}, {"snippet_id": 31009, "code": " missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self", "label": 0}, {"snippet_id": 69662, "code": " fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully", "label": 0}, {"snippet_id": 70107, "code": " if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if", "label": 0}, {"snippet_id": 51, "code": ", os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase", "label": 1}, {"snippet_id": 39759, "code": " ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self", "label": 0}, {"snippet_id": 88400, "code": "._run_tracker.log(Report.FATAL, *msg_elements) def __init__(self, options, run_tracker, target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser=None, address_mapper=None", "label": 0}, {"snippet_id": 14678, "code": "'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive():", "label": 0}, {"snippet_id": 23873, "code": " OSUtilError(\"Can't find ether interface:{0}\".format(output)) ifaces=output.split() if not ifaces: raise OSUtilError(\"Can't find ether interface.\") iface=ifaces[0] err, output=shellutil.run_get_output(", "label": 0}, {"snippet_id": 82132, "code": "\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log", "label": 0}, {"snippet_id": 10696, "code": " \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if", "label": 1}, {"snippet_id": 88595, "code": ". :API: public \"\"\" return self._console_outstream @property def scm(self): \"\"\"Returns the current workspace's scm, if any. :API: public \"\"\" return self._scm @property def workspace(self): \"\"\"Returns the", "label": 0}, {"snippet_id": 66338, "code": ".set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 11447, "code": " attempt detected for host name %r\" raise Exception(msg % hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config(self.source) if raw_yaml_config is None: raise", "label": 0}, {"snippet_id": 73321, "code": " path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head", "label": 0}, {"snippet_id": 80493, "code": " associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys(): \t\ts.cookies[key]=args.cookies[key]", "label": 0}, {"snippet_id": 51670, "code": " a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os", "label": 0}, {"snippet_id": 90912, "code": ". :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" try: return cls.global_instance()._locator().locate( minimum_version=minimum_version", "label": 0}, {"snippet_id": 2017, "code": ").split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append", "label": 0}, {"snippet_id": 73886, "code": ", Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation of VCF to Zarr conversion module configuration. \"\"\" enabled", "label": 0}, {"snippet_id": 37194, "code": " branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch", "label": 0}, {"snippet_id": 49822, "code": "\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph", "label": 0}, {"snippet_id": 30304, "code": " item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names", "label": 0}, {"snippet_id": 52405, "code": ".b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize", "label": 0}, {"snippet_id": 47300, "code": ".exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def", "label": 0}, {"snippet_id": 57147, "code": "=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied.') model=apps.get_model(*ctype.split(\".\", 1)) targets=model._default_manager.filter(pk__in=object_pk) if not targets: return say_no", "label": 0}, {"snippet_id": 39484, "code": " ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException", "label": 0}, {"snippet_id": 51003, "code": " \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with", "label": 0}, {"snippet_id": 14568, "code": " self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive():", "label": 0}, {"snippet_id": 7375, "code": "\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template ", "label": 0}, {"snippet_id": 31653, "code": " self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other", "label": 0}, {"snippet_id": 43440, "code": " bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict()", "label": 0}, {"snippet_id": 66041, "code": "(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod", "label": 0}, {"snippet_id": 7597, "code": ".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to", "label": 0}, {"snippet_id": 54749, "code": ".rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split", "label": 0}, {"snippet_id": 31042, "code": ".wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self", "label": 0}, {"snippet_id": 96010, "code": ".chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width", "label": 0}, {"snippet_id": 47475, "code": "\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name", "label": 0}, {"snippet_id": 67305, "code": ": FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE:", "label": 0}, {"snippet_id": 15334, "code": " filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port", "label": 0}, {"snippet_id": 80914, "code": ",concurrent.futures from utils import * from urllib.parse import urljoin,urlparse from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None", "label": 0}, {"snippet_id": 16127, "code": " import os import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from", "label": 0}, {"snippet_id": 20075, "code": ") if wait_for_connect: wait_for_connect() else: wait_for_socket_server(addr) self._attach(addr, **kwargs) def _attach(self, addr, **kwargs): if addr is None: addr=self._addr assert addr.host=='localhost", "label": 1}, {"snippet_id": 6415, "code": " text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio", "label": 1}, {"snippet_id": 52517, "code": " output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not", "label": 0}, {"snippet_id": 2162, "code": " configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False", "label": 0}, {"snippet_id": 49942, "code": "=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag", "label": 0}, {"snippet_id": 59175, "code": "- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import", "label": 0}, {"snippet_id": 22947, "code": "/run/utmp\") shellutil.run(\"/usr/bin/tmsh delete auth user \" +username) def get_dvd_device(self, dev_dir='/dev'): \"\"\"Find BIG-IP's CD/DVD device This device is almost certainly /dev/cdrom so I added the", "label": 0}, {"snippet_id": 50082, "code": " if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile", "label": 0}, {"snippet_id": 84722, "code": "'), description='cloc', ) exec_result=self.context.execute_process_synchronously(req, 'cloc',(WorkUnitLabel.TOOL,)) files_content_tuple=self.context._scheduler.product_request( FilesContent, [exec_result", "label": 1}, {"snippet_id": 72658, "code": "(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module", "label": 1}, {"snippet_id": 4620, "code": ":return: dictionary of matches in a format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def", "label": 0}, {"snippet_id": 8490, "code": " text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words", "label": 1}, {"snippet_id": 59807, "code": ": expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator(str(observable)[-1]+'0'), self.reg) variance=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self", "label": 0}, {"snippet_id": 55385, "code": "(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info", "label": 0}, {"snippet_id": 56601, "code": " if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag.objects.filter( tag__in=all_tags).values(", "label": 0}, {"snippet_id": 70631, "code": ": RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self", "label": 1}, {"snippet_id": 51835, "code": " Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index", "label": 0}, {"snippet_id": 58472, "code": " {'comment': 'new comment', 'run':[]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) response=self.client.post(self.many_comments_url", "label": 0}, {"snippet_id": 70523, "code": "(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed", "label": 0}, {"snippet_id": 44233, "code": " Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that", "label": 0}, {"snippet_id": 30633, "code": ".ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() }", "label": 0}, {"snippet_id": 53123, "code": "\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io", "label": 0}, {"snippet_id": 63525, "code": ", kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return", "label": 0}, {"snippet_id": 75268, "code": "(self, iden, msg, reqid, interface, method): try: handler=self.req_handlers[(interface, method)] except KeyError: try: handler=self.req_handlers[(interface, None)] except KeyError: raise WZENoReqHandler", "label": 0}, {"snippet_id": 33302, "code": " priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)", "label": 0}, {"snippet_id": 59024, "code": " EnvGroupPropertyMapFactory(group=cls.group_new, property=cls.property_django) def test_get_env_properties(self): response=self.client.get(self.get_info_url,{'info_type': 'env_properties'}) expected_json=json", "label": 0}, {"snippet_id": 26249, "code": "'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None", "label": 0}, {"snippet_id": 89906, "code": " ' got{}'.format(java, self._minimum_version, version)) if self._maximum_version: version=self._get_version(java) if version > self._maximum_version: raise self.Error('The java distribution at{} is too", "label": 0}, {"snippet_id": 87821, "code": ".path.normpath(path): raise TaskError('Classpath entries provided to zinc should be normalized ' '(i.e. without \"..\" and \".\").{} is not.'.format(path)) def log_zinc_file(self, analysis_file): self.context", "label": 0}, {"snippet_id": 78097, "code": "(user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login': login, 'passwd': passwd}, False) def send_to_wm(frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames", "label": 0}, {"snippet_id": 37363, "code": " wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else:", "label": 0}, {"snippet_id": 22516, "code": " hostname of the device Normally, tmsh is used to set the hostname for the system. For our purposes at this time though, I would hesitate to trust this function. Azure(Stack) uses the name that you provide", "label": 0}, {"snippet_id": 24083, "code": " awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed", "label": 0}, {"snippet_id": 47245, "code": "): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self", "label": 0}, {"snippet_id": 84737, "code": ".product_request( FilesContent, [exec_result.output_directory_digest] )[0].dependencies files_content={fc.path: fc.content.decode('utf-8') for fc in files_content_tuple} for line in files_content['report'].split", "label": 0}, {"snippet_id": 44303, "code": " globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format", "label": 0}, {"snippet_id": 50484, "code": " ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 43368, "code": " \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException", "label": 0}, {"snippet_id": 27263, "code": "'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl", "label": 0}, {"snippet_id": 48739, "code": ") benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards", "label": 0}, {"snippet_id": 75980, "code": ".debug('Successfull auth for(%s, %s)', i, m) elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3}'.\\ format(i, m, wzrpc.name_status(status),", "label": 1}, {"snippet_id": 30443, "code": " files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath", "label": 0}, {"snippet_id": 25001, "code": "\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status'", "label": 0}, {"snippet_id": 82883, "code": " templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[\"templateName\"]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template", "label": 1}, {"snippet_id": 24893, "code": " data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self", "label": 0}, {"snippet_id": 17575, "code": "': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave", "label": 0}, {"snippet_id": 91666, "code": "='pytest-with-requirements.pex' requirements_pex_argv=[ python_binary, './{}'.format(pex_snapshot.files[0]), '-e', 'pytest:main', '-o', output_pytest_requirements_pex_filename, ] +interpreter_constraint_args", "label": 0}, {"snippet_id": 9211, "code": " acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches", "label": 0}, {"snippet_id": 59567, "code": " \"\"\"Shutdown. \"\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource", "label": 0}, {"snippet_id": 62956, "code": ".lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner", "label": 0}, {"snippet_id": 9573, "code": ", we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1", "label": 0}, {"snippet_id": 16446, "code": "( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False)", "label": 0}, {"snippet_id": 42006, "code": " for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables", "label": 0}, {"snippet_id": 27113, "code": " import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY,", "label": 1}, {"snippet_id": 41046, "code": "(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over", "label": 0}, {"snippet_id": 62392, "code": " self.reg: self.eng.deallocate_qubit(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for", "label": 0}, {"snippet_id": 10206, "code": "(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,", "label": 0}, {"snippet_id": 11397, "code": " not found') output_path=self.output_path(self.create_filename(hostname)) old_header=Header.parse(output_path) return header_source.is_newer_than(old_header) def output_path(self, file_name): return os", "label": 0}, {"snippet_id": 50940, "code": " if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for", "label": 0}, {"snippet_id": 57549, "code": "'case')) self._update_objects=TestCase.objects.filter(pk__in=case_ids) return self._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none(self.request, pk_enough) except", "label": 0}, {"snippet_id": 67818, "code": ".get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options", "label": 0}, {"snippet_id": 20823, "code": "\"], evt) def _get_awaiter_for_request(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'", "label": 0}, {"snippet_id": 95042, "code": ", help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory=\"./data/input/\" download_directory", "label": 1}, {"snippet_id": 39808, "code": " name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path", "label": 0}, {"snippet_id": 95606, "code": " file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file): with open", "label": 0}, {"snippet_id": 75900, "code": ": rs=wzrpc.RequestState(request[0]) rslist.append(rs) msg=self.wz.make_req_msg(request[1][0], request[1][1], request[1][2], rs.accept, request[1][3]) msg.insert(0, b'') msgdict[rs]=msg s.send_multipart", "label": 0}, {"snippet_id": 5662, "code": " kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output", "label": 0}, {"snippet_id": 81462, "code": "(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback", "label": 0}, {"snippet_id": 84816, "code": " major_version_info(full_version='2.12.4'), } scala_style_jar=JarDependency('org.scalastyle', 'scalastyle_2.11', '0.8.0') class ScalaPlatform(JvmToolMixin, ZincLanguageMixin, InjectablesMixin, Subsystem", "label": 0}, {"snippet_id": 52175, "code": "=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m.group(\"value", "label": 0}, {"snippet_id": 44106, "code": "(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))", "label": 0}, {"snippet_id": 29045, "code": " the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self)", "label": 0}, {"snippet_id": 60699, "code": ", var=self.state.quad_expectation(reg, *self._observe.params) elif self._observe.name=='Displacement': ex=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self", "label": 0}, {"snippet_id": 32104, "code": " output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item", "label": 0}, {"snippet_id": 83463, "code": "=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds", "label": 0}, {"snippet_id": 11067, "code": ", response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime=mtime) class Header(object): MON_CONF_GEN_COMMENT=' ETAG_COMMENT=' MTIME_COMMMENT=' def", "label": 0}, {"snippet_id": 19566, "code": " else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported", "label": 0}, {"snippet_id": 1723, "code": "\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall", "label": 0}, {"snippet_id": 15314, "code": "-port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 66228, "code": ".fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)],", "label": 0}, {"snippet_id": 90307, "code": " osx_java_home_exe): self._osx_java_home_exe=osx_java_home_exe @property def jvm_locations(self): if os.path.exists(self._osx_java_home_exe): try: plist=subprocess.check_output([self._osx_java_home_exe, ", "label": 0}, {"snippet_id": 11199, "code": " line in config_file.xreadlines(): etag=extract(Header.ETAG_COMMENT, etag) mtime=extract(Header.MTIME_COMMMENT, mtime) if etag and mtime: break except IOError as e: pass finally: return Header(etag=etag", "label": 0}, {"snippet_id": 38886, "code": " printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( ", "label": 0}, {"snippet_id": 79093, "code": "\"$captGroup$\"+suffixPattern \t\t\telse: \t\t\t\tself.logger.warning(\"Code execution detection will not be possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime", "label": 0}, {"snippet_id": 46643, "code": " pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try:", "label": 0}, {"snippet_id": 21512, "code": " progress deeper.\") else: newer_links, links=getytlinks(link) new_links +=newer_links new_links=list(set(new_links)) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link", "label": 0}, {"snippet_id": 73199, "code": ".vcf, placed in output_dir. Additionally moves *.vcf files to output_dir Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir", "label": 0}, {"snippet_id": 72511, "code": " configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f", "label": 0}, {"snippet_id": 29179, "code": "\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may", "label": 0}, {"snippet_id": 47767, "code": ": name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self", "label": 0}, {"snippet_id": 17060, "code": " request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response", "label": 0}, {"snippet_id": 18678, "code": " str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info", "label": 0}, {"snippet_id": 52434, "code": "._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise", "label": 0}, {"snippet_id": 90623, "code": " distribution could be found. \"\"\" def _get_stricter_version(a, b, name, stricter): version_a=_parse_java_version(name, a) version_b=_parse_java_version(name, b) if version_a is None: return version_b if", "label": 0}, {"snippet_id": 77841, "code": ".spawnqueue=Queue() self.load_bumplimit_set() self.load_targets() self.load_users() self.spawn_wipethreads() if self.c.ecount > 0: self.spawn_evaluators() try: while self.running.is_set(): if self.c.tcount=", "label": 0}, {"snippet_id": 21064, "code": ", handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event() def handler(msg): if not match(msg): return msg, False event.set() return msg, True self._add_handler", "label": 0}, {"snippet_id": 38470, "code": "._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name", "label": 0}, {"snippet_id": 62336, "code": "): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and", "label": 0}, {"snippet_id": 3953, "code": " subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k',", "label": 0}, {"snippet_id": 12539, "code": "\": comment_footer.append(config[\"message\"][\"opened\"][\"footer\"]) elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: comment_footer.append(config[\"message\"][\"updated\"][\"footer\"]) comment_footer='", "label": 0}, {"snippet_id": 5659, "code": "(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION", "label": 0}, {"snippet_id": 43209, "code": "[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len", "label": 0}, {"snippet_id": 21975, "code": ", flush_cache=None, listtasks=None, listtags=None, module_path=None): self.verbosity=verbosity self.inventory=inventory self.listhosts=listhosts self.subset=subset self.module_paths=module_paths self.extra_vars", "label": 0}, {"snippet_id": 23599, "code": " gateway): cmd='route add{0}{1}{2}'.format(net, gateway, mask) return shellutil.run(cmd, chk_err=False) def is_missing_default_route(self): \"\"\" For FreeBSD, the default broadcast goes to current default", "label": 0}, {"snippet_id": 37402, "code": " Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item", "label": 0}, {"snippet_id": 26865, "code": ".type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" ", "label": 0}, {"snippet_id": 59818, "code": ") variance=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg] variance=[1 -e*", "label": 0}, {"snippet_id": 60352, "code": ": for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else", "label": 0}, {"snippet_id": 37410, "code": " item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\")", "label": 0}, {"snippet_id": 41717, "code": ": yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self", "label": 1}, {"snippet_id": 26122, "code": " from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity", "label": 0}, {"snippet_id": 15444, "code": "._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self", "label": 0}, {"snippet_id": 80928, "code": "(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t\tself.logger=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl", "label": 0}, {"snippet_id": 27072, "code": "\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo", "label": 1}, {"snippet_id": 61866, "code": " optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...", "label": 0}, {"snippet_id": 75703, "code": "=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker=Ticker() self.poller=zmq.Poller() s=self.ctx.socket(zmq.SUB) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) s", "label": 0}, {"snippet_id": 32575, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output", "label": 0}, {"snippet_id": 6475, "code": "%s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords", "label": 0}, {"snippet_id": 59399, "code": "{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else:", "label": 0}, {"snippet_id": 685, "code": " JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall", "label": 0}, {"snippet_id": 22222, "code": "=self.conf[state]['log_file'] if 'template' in self.conf[state]: template=self.conf[state]['template'] if playbook is None: playbook=self.conf['playbook'] if template is None and template in self.conf:", "label": 0}, {"snippet_id": 1324, "code": ".crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap", "label": 1}, {"snippet_id": 30535, "code": "\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake", "label": 1}, {"snippet_id": 31370, "code": "=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution", "label": 0}, {"snippet_id": 55990, "code": " ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return", "label": 0}, {"snippet_id": 95108, "code": ".read_configuration(location=cli_arguments[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running FTP download", "label": 0}, {"snippet_id": 30157, "code": " toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a", "label": 0}, {"snippet_id": 58473, "code": "'new comment', 'run':[]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) response=self.client.post(self.many_comments_url, {", "label": 0}, {"snippet_id": 75253, "code": " del_response_handler(self, reqid): del self.response_handlers[reqid] def del_sig_handler(self, interface, method): del self.sig_handlers[(interface, method)] def _parse_req(self, iden, msg, reqid, interface", "label": 0}, {"snippet_id": 46434, "code": " \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone", "label": 0}, {"snippet_id": 34533, "code": " MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times)", "label": 1}, {"snippet_id": 44145, "code": " set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules,", "label": 0}, {"snippet_id": 15087, "code": ") return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy", "label": 0}, {"snippet_id": 862, "code": "]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings", "label": 0}, {"snippet_id": 88685, "code": " run tracker's daemon stats object.\"\"\" target_count=len(self.build_graph) self.run_tracker.pantsd_stats.set_affected_targets_size(target_count) return target_count def submit_background_work_chain(self", "label": 0}, {"snippet_id": 17915, "code": " @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data,", "label": 0}, {"snippet_id": 82735, "code": "\tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection:", "label": 0}, {"snippet_id": 25328, "code": " discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try:", "label": 1}, {"snippet_id": 46534, "code": " if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index", "label": 0}, {"snippet_id": 67522, "code": ".FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler", "label": 0}, {"snippet_id": 46723, "code": " raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len", "label": 0}, {"snippet_id": 71911, "code": " \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"", "label": 0}, {"snippet_id": 63650, "code": "._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job", "label": 0}, {"snippet_id": 21354, "code": " args=parser.parse_args() subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ['HOME'] +\"/.reddytt\" sr_dir=work_dir +\"/%s", "label": 1}, {"snippet_id": 22106, "code": ".inventory) pb_dir=os.path.abspath('.') playbook_path=\"%s/%s\" %(pb_dir, playbook) display.verbosity=self.options.verbosity self.pbex=playbook_executor.PlaybookExecutor( playbooks=[playbook], inventory=self", "label": 1}, {"snippet_id": 67816, "code": "=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost", "label": 0}, {"snippet_id": 8227, "code": " STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils", "label": 1}, {"snippet_id": 89424, "code": " basic constraints are met. For example a minimum version can be specified if you know need to compile source code or run bytecode that exercise features only available in that version forward. :API: public", "label": 0}, {"snippet_id": 19755, "code": "=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs): if nodebug: run_main(addr, name, kind, *extra, **kwargs) else: debug_main(addr, name, kind, *extra, *", "label": 0}, {"snippet_id": 61255, "code": " atol=tolerance): raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args(array): square hermitian matrix. Returns", "label": 0}, {"snippet_id": 17364, "code": ")) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str", "label": 0}, {"snippet_id": 10892, "code": " monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, HostUnreachableException from monitoring_config_generator.yaml_tools.merger import merge_yaml_files def is_file(parsed_uri", "label": 0}, {"snippet_id": 47574, "code": " __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"", "label": 0}, {"snippet_id": 68821, "code": " AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 87836, "code": ", analysis_file): self.context.log.debug('Calling zinc on:{}({})' .format(analysis_file, hash_file(analysis_file).upper() if os.path.exists(analysis_file) else 'nonexistent')) @classmethod def _javac_plugin_args", "label": 0}, {"snippet_id": 27028, "code": " elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data", "label": 0}, {"snippet_id": 3380, "code": " server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file", "label": 0}, {"snippet_id": 24648, "code": " self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium", "label": 0}, {"snippet_id": 7756, "code": "\"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes", "label": 0}, {"snippet_id": 55216, "code": "\"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input)", "label": 0}, {"snippet_id": 34148, "code": ".benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__", "label": 0}, {"snippet_id": 65421, "code": " import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824", "label": 0}, {"snippet_id": 41553, "code": ".subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property", "label": 0}, {"snippet_id": 61392, "code": " _circuits={} def __init__(self, wires, *, shots=0): self.wires=wires self.eng=None self._state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and", "label": 1}, {"snippet_id": 89998, "code": "['java.version']) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open(os.path.join(classpath, 'SystemProperties.class'), 'w+b') as fp: fp", "label": 0}, {"snippet_id": 75229, "code": ", fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method)]=fun def del_req_handler(self, interface, method): del self.req_handlers", "label": 0}, {"snippet_id": 41087, "code": " names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item", "label": 0}, {"snippet_id": 21285, "code": "[1] if videolabel is None: print('Reddytt: skipping URL without video label:', lk) continue new_links.append('https://www.youtube.com/watch?v=' +videolabel) return new_links, links if __name__=='__main__", "label": 0}, {"snippet_id": 7203, "code": " output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords", "label": 0}, {"snippet_id": 90670, "code": "(key) if not dist: dist=self._scan_constraint_match(minimum_version, maximum_version, jdk) if not dist: dist=self._locate(minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) self", "label": 0}, {"snippet_id": 52764, "code": " \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile", "label": 0}, {"snippet_id": 85733, "code": " _compiler_plugins_cp_entries(self): \"\"\"Any additional global compiletime classpath entries for compiler plugins.\"\"\" java_options_src=Java.global_instance() scala_options_src=ScalaPlatform.global_instance()", "label": 0}, {"snippet_id": 41842, "code": ".benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested:", "label": 0}, {"snippet_id": 26631, "code": "\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state", "label": 0}, {"snippet_id": 70281, "code": ", strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self", "label": 0}, {"snippet_id": 52235, "code": " chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile", "label": 0}, {"snippet_id": 14037, "code": ", column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column", "label": 0}, {"snippet_id": 62999, "code": " configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner", "label": 0}, {"snippet_id": 48582, "code": " not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_", "label": 0}, {"snippet_id": 74695, "code": ".vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for", "label": 0}, {"snippet_id": 81256, "code": "\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t", "label": 1}, {"snippet_id": 71313, "code": "\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout", "label": 0}, {"snippet_id": 16556, "code": "._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start", "label": 0}, {"snippet_id": 7730, "code": " matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes", "label": 0}, {"snippet_id": 7868, "code": " get the spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int", "label": 0}, {"snippet_id": 74738, "code": " raise TypeError(\"Invalid value provided for chunk_width in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr", "label": 0}, {"snippet_id": 61405, "code": " shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self._state is None: self._state=np.zeros(2**self.wires, dtype=complex) self._state[0]=1 self._out", "label": 1}, {"snippet_id": 51752, "code": " wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone", "label": 0}, {"snippet_id": 91488, "code": ".backend.python.rules.inject_init import InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest from pants.backend.python.subsystems.python_setup import PythonSetup from pants.engine", "label": 0}, {"snippet_id": 59934, "code": "\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM", "label": 0}, {"snippet_id": 26941, "code": " elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" %", "label": 0}, {"snippet_id": 33513, "code": " for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag", "label": 0}, {"snippet_id": 4141, "code": " import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from", "label": 1}, {"snippet_id": 9732, "code": "=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"", "label": 0}, {"snippet_id": 29829, "code": " (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches", "label": 1}, {"snippet_id": 82662, "code": "'User-Agent':args.userAgent} s.trust_env=False if args.proxy: \tif args.proxy[\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the -", "label": 0}, {"snippet_id": 64385, "code": "\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list", "label": 0}, {"snippet_id": 17956, "code": " timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method", "label": 1}, {"snippet_id": 42943, "code": "(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and", "label": 0}, {"snippet_id": 14500, "code": "._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive():", "label": 0}, {"snippet_id": 38601, "code": " list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None,", "label": 0}, {"snippet_id": 56746, "code": ") return func() def plan(self): return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk) def case(self): return 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk) def run", "label": 0}, {"snippet_id": 82344, "code": "-agents.txt\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template", "label": 0}, {"snippet_id": 21061, "code": " wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event() def handler(msg): if not match(msg): return msg, False event.set() return", "label": 0}, {"snippet_id": 33083, "code": " list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources", "label": 0}, {"snippet_id": 18862, "code": ".schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request, normalize_response", "label": 0}, {"snippet_id": 29520, "code": "(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set", "label": 0}, {"snippet_id": 95760, "code": ") remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str", "label": 0}, {"snippet_id": 44402, "code": "-immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif", "label": 0}, {"snippet_id": 37051, "code": "(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other", "label": 0}, {"snippet_id": 23936, "code": " mac) return iface, inet, mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if port_id > 3: return None g0=\"00000000\" if port_id > 1: g0=\"00000001\" port_id", "label": 0}, {"snippet_id": 86357, "code": " contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _execute_hermetic_compile(self, cmd, ctx): input_snapshot=ctx.target", "label": 0}, {"snippet_id": 45701, "code": "(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint", "label": 0}, {"snippet_id": 29058, "code": " self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle", "label": 1}, {"snippet_id": 93112, "code": " with exception_logging(fake_logger, 'error!'): assert True is False fake_logger.exception.assert_called_once_with('error!') def test_maybe_profiled(self): with temporary_dir() as td: profile_path=os.path", "label": 0}, {"snippet_id": 39890, "code": " targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. ", "label": 0}, {"snippet_id": 38465, "code": ". Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name", "label": 0}, {"snippet_id": 69748, "code": " import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose", "label": 0}, {"snippet_id": 55598, "code": "._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c", "label": 0}, {"snippet_id": 5140, "code": " ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches", "label": 0}, {"snippet_id": 66908, "code": " rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt -=1 if self.fs.action_refcnt", "label": 1}, {"snippet_id": 10555, "code": ". \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(", "label": 1}, {"snippet_id": 83576, "code": " in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths", "label": 0}, {"snippet_id": 28732, "code": "\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self", "label": 0}, {"snippet_id": 16875, "code": "=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def", "label": 0}, {"snippet_id": 4035, "code": "(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app", "label": 0}, {"snippet_id": 72286, "code": " to route reply back to the same \" \\ \"network, as this would cause a recursive loop\" log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name, text, placeholder_self.name) if 'source", "label": 0}, {"snippet_id": 46358, "code": "\"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist", "label": 0}, {"snippet_id": 45550, "code": "(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch", "label": 1}, {"snippet_id": 89262, "code": ": A tuple of WorkUnitLabels. :return: An ExecuteProcessResult with information about the execution. Note that this is an unstable, experimental API, which is subject to change with no notice. \"\"\" with self", "label": 0}, {"snippet_id": 9883, "code": "\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword", "label": 0}, {"snippet_id": 52232, "code": " jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag", "label": 0}, {"snippet_id": 84433, "code": " local_output_path in local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite( wrapper_path) results.append( self._dataset_path( local_output_path,", "label": 0}, {"snippet_id": 62995, "code": " setting metadata externally, but LWR is not configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR", "label": 0}, {"snippet_id": 42961, "code": ")) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams", "label": 0}, {"snippet_id": 23790, "code": " to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout={0}'", "label": 0}, {"snippet_id": 2613, "code": ".component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '%s'!\" %(dep, node.comp_name)) if exit_on_fail", "label": 0}, {"snippet_id": 22688, "code": " expiration: The expiration date to use. We do not use this value. \"\"\" if self.get_userentry(username): logger.info(\"User{0} already exists, skip useradd\", username) return None cmd=\"/usr/bin/tmsh create auth", "label": 0}, {"snippet_id": 20476, "code": " ownsock=True) self._addr=addr return self def __init__(self, sock, ownsock=False): super(DebugSessionConnection, self).__init__() self._sock=sock self._ownsock=ownsock @property def is_client(self): try", "label": 0}, {"snippet_id": 62196, "code": "(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend", "label": 0}, {"snippet_id": 23932, "code": "},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if port_id > 3: return None g0=\"00000000\" if port_id > 1:", "label": 0}, {"snippet_id": 22322, "code": " def _wait_until_mcpd_is_initialized(self): \"\"\"Wait for mcpd to become available All configuration happens in mcpd so we need to wait that this is available before we go provisioning the system. I call", "label": 0}, {"snippet_id": 23866, "code": " output=shellutil.run_get_output('ifconfig -l ether', chk_err=False) if err: raise OSUtilError(\"Can't find ether interface:{0}\".format(output)) ifaces=output.split() if not ifaces: raise OSUtilError(\"Can't", "label": 0}, {"snippet_id": 75438, "code": " answer)) return msg def get_iden(self, reqid): return self.iden_reqid_map.get_key(reqid) def get_reqids(self, iden): return self.iden_reqid_map.get_values(iden) def make_reqid(self): while True: reqid", "label": 0}, {"snippet_id": 46515, "code": " name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start", "label": 0}, {"snippet_id": 80320, "code": ".\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not", "label": 0}, {"snippet_id": 94823, "code": "(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args", "label": 0}, {"snippet_id": 12967, "code": "): if len(diffs) !=0: REQUEST_JSON[\"files\"][file.split(\"/\")[-1] +\".diff\"]={ \"content\": diffs } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ", "label": 0}, {"snippet_id": 20923, "code": "!=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still running') self._check_handlers() def _listen(self): try: for", "label": 0}, {"snippet_id": 7499, "code": " str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse", "label": 0}, {"snippet_id": 94660, "code": " if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", ", "label": 0}, {"snippet_id": 69132, "code": " ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre", "label": 0}, {"snippet_id": 10571, "code": "('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern", "label": 1}, {"snippet_id": 64798, "code": " execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel))", "label": 0}, {"snippet_id": 68572, "code": "\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name", "label": 0}, {"snippet_id": 81411, "code": " this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self", "label": 0}, {"snippet_id": 68283, "code": " [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column", "label": 0}, {"snippet_id": 13335, "code": "\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) fullname=data.get(\"fork_fullname\") for file, new_file in data[\"results\"].items(): url=", "label": 0}, {"snippet_id": 70098, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)..", "label": 0}, {"snippet_id": 14813, "code": " 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath", "label": 0}, {"snippet_id": 64464, "code": "':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command", "label": 0}, {"snippet_id": 69687, "code": "(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on", "label": 0}, {"snippet_id": 93658, "code": "'name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state", "label": 0}, {"snippet_id": 73671, "code": "/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return", "label": 0}, {"snippet_id": 25263, "code": "', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal", "label": 0}, {"snippet_id": 58681, "code": " test_update_plan_is_active(self): self.client.login( username=self.tester.username, password='password') post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active", "label": 0}, {"snippet_id": 94007, "code": "\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres", "label": 0}, {"snippet_id": 24466, "code": "\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of", "label": 0}, {"snippet_id": 68174, "code": ".proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view", "label": 1}, {"snippet_id": 51358, "code": ", Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value", "label": 0}, {"snippet_id": 93608, "code": ".info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd)", "label": 0}, {"snippet_id": 19619, "code": " supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ", "label": 0}, {"snippet_id": 53797, "code": " @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item", "label": 0}, {"snippet_id": 83812, "code": " job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"", "label": 0}, {"snippet_id": 29697, "code": " format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type", "label": 0}, {"snippet_id": 23956, "code": " 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=\"000\" +ustr(port_id) g0g1=\"{0}-{1}\".format(g0, g1)", "label": 0}, {"snippet_id": 14233, "code": "\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 94678, "code": ".add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers", "label": 0}, {"snippet_id": 52523, "code": ", self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield", "label": 1}, {"snippet_id": 77791, "code": ".make_sig_msg(frames[1], frames[2], frames[3:])) self.th_sock.send_multipart(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self.log=parent.log self.inter_sleep=parent.inter_sleep", "label": 0}, {"snippet_id": 74324, "code": " with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been generated successfully.\") else:", "label": 0}, {"snippet_id": 28664, "code": "._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640", "label": 0}, {"snippet_id": 54827, "code": " stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False", "label": 0}, {"snippet_id": 38559, "code": ", prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False", "label": 0}, {"snippet_id": 56724, "code": " \"\"\" for obj in['plan', 'case', 'run']: if request.GET.get(obj): self.object=obj self.object_pk=request.GET.get(obj) break def get(self): func=getattr(self, self.object) return func() def plan(self): return", "label": 0}, {"snippet_id": 45613, "code": ") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f", "label": 1}, {"snippet_id": 54350, "code": " class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self,", "label": 0}, {"snippet_id": 57575, "code": ".mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try", "label": 0}, {"snippet_id": 39390, "code": " def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self", "label": 0}, {"snippet_id": 66993, "code": ": continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg", "label": 0}, {"snippet_id": 87622, "code": ".target.sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests) !=len(dependency_classpath", "label": 1}, {"snippet_id": 4282, "code": ": text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string", "label": 1}, {"snippet_id": 47619, "code": "=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always", "label": 0}, {"snippet_id": 91016, "code": " pants will use') register('--maximum-version', advanced=True, help='Maximum version of the JVM pants will use') def all_jdk_paths(self): \"\"\"Get all explicitly configured JDK paths. :return: mapping of", "label": 0}, {"snippet_id": 64311, "code": "._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"%s_files\"", "label": 0}, {"snippet_id": 2067, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get", "label": 0}, {"snippet_id": 53929, "code": " specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f,", "label": 0}, {"snippet_id": 74110, "code": " to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str=runtime_config.vcf_to_zarr[\"blosc_shuffle_mode\"] if isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int", "label": 0}, {"snippet_id": 10141, "code": " get the spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int", "label": 0}, {"snippet_id": 49221, "code": "._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None):", "label": 0}, {"snippet_id": 25323, "code": " setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION", "label": 0}, {"snippet_id": 7368, "code": " encode_for_xml(categories[kw]))) for field, keywords in((auth_field, output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2", "label": 0}, {"snippet_id": 74889, "code": " configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config", "label": 0}, {"snippet_id": 74339, "code": " pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return", "label": 0}, {"snippet_id": 24008, "code": "\" err, output=shellutil.run_get_output(cmd_extract_id) \"\"\" try to search 'blkvscX' and 'storvscX' to find device name \"\"\" output=output.rstrip() cmd_search_blkvsc=\"camcontrol devlist -b | grep blkvsc{0", "label": 0}, {"snippet_id": 603, "code": "() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets", "label": 0}, {"snippet_id": 70260, "code": " ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr", "label": 0}, {"snippet_id": 66640, "code": ">\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self)", "label": 0}, {"snippet_id": 82848, "code": " detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open", "label": 0}, {"snippet_id": 77819, "code": "(zmq.SUBSCRIBE, b'WipeManager') self.p.wz.set_sig_handler(b'WipeManager', b'passthrough', self.send_passthrough) if self.c.tcount > 0: self.pc=ProcessContext(self.p.name, self.p.ctx, self.c.router_addr,", "label": 0}, {"snippet_id": 74202, "code": " hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass", "label": 0}, {"snippet_id": 87549, "code": " not in compiler_option_sets: if option_set=='fatal_warnings': disabled_args=self.get_options().fatal_warnings_disabled_args zinc_args.extend(disabled_args) if not self._clear_invalid_analysis: zinc_args", "label": 0}, {"snippet_id": 54812, "code": " cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete", "label": 0}, {"snippet_id": 73620, "code": "-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length", "label": 1}, {"snippet_id": 397, "code": "'getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\"", "label": 0}, {"snippet_id": 59938, "code": ": wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to", "label": 0}, {"snippet_id": 12491, "code": ") comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file:\\n\\n\") comment_body.append(\"> \" +\"\".join(data[\"extra_results\"][file]))", "label": 0}, {"snippet_id": 36047, "code": ", self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads", "label": 0}, {"snippet_id": 41624, "code": " if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\"", "label": 0}, {"snippet_id": 50706, "code": ", \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: ", "label": 0}, {"snippet_id": 88235, "code": " unicode_literals import os import sys from builtins import filter, object from collections import defaultdict from contextlib import contextmanager from twitter.common.collections import OrderedSet from pants.base", "label": 0}, {"snippet_id": 7011, "code": " taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style", "label": 0}, {"snippet_id": 31020, "code": " requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic", "label": 0}, {"snippet_id": 6862, "code": " fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones", "label": 0}, {"snippet_id": 94885, "code": " records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line", "label": 1}, {"snippet_id": 16522, "code": " self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return", "label": 0}, {"snippet_id": 64674, "code": " open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def", "label": 0}, {"snippet_id": 71401, "code": ", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout", "label": 0}, {"snippet_id": 74188, "code": " Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None:", "label": 0}, {"snippet_id": 71720, "code": " class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self", "label": 0}, {"snippet_id": 74546, "code": " runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp:", "label": 0}, {"snippet_id": 10112, "code": ", '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches", "label": 0}, {"snippet_id": 27960, "code": ": self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status'", "label": 0}, {"snippet_id": 98, "code": " \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':'", "label": 0}, {"snippet_id": 39547, "code": "]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule", "label": 0}, {"snippet_id": 433, "code": ") setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"", "label": 0}, {"snippet_id": 1731, "code": ": print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action", "label": 0}, {"snippet_id": 26274, "code": "'Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], ", "label": 1}, {"snippet_id": 48085, "code": " set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name", "label": 0}, {"snippet_id": 78389, "code": " e: self.counters['topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min exc caught, topic_successtimeout", "label": 0}, {"snippet_id": 44398, "code": " dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if", "label": 0}, {"snippet_id": 59498, "code": " par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate", "label": 0}, {"snippet_id": 84560, "code": " PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask from pants.util.contextutil import temporary_dir class CountLinesOfCode", "label": 0}, {"snippet_id": 6308, "code": " in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available", "label": 1}, {"snippet_id": 63693, "code": ".Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log", "label": 0}, {"snippet_id": 40484, "code": " keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as", "label": 0}, {"snippet_id": 6283, "code": " local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for", "label": 1}, {"snippet_id": 31905, "code": " Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item", "label": 0}, {"snippet_id": 53175, "code": "\"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies", "label": 0}, {"snippet_id": 68163, "code": ".status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self", "label": 0}, {"snippet_id": 78656, "code": " sys.stdout.write(Writer.write(self.run())) except BaseException as e: log.logger.exception(e) return -1 return 0 def execute(self): \"\"\"To be overridden by sub classes\"\"\" pass def run(self): try: if self", "label": 1}, {"snippet_id": 48295, "code": " be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"):", "label": 0}, {"snippet_id": 64201, "code": "'datatypes_config']=os.path.join(configs_directory, os.path.basename(integrates_datatypes_config)) return metadata_kwds class LwrComputeEnvironment( ComputeEnvironment): def __init__( self, lwr_client, job_wrapper", "label": 0}, {"snippet_id": 3006, "code": "=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger", "label": 0}, {"snippet_id": 80097, "code": "-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection arguments')", "label": 0}, {"snippet_id": 37681, "code": "(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given", "label": 0}, {"snippet_id": 12027, "code": "}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments.append(\"--{}={}\".format(key, ','.join(value))) config[\"pycodestyle_cmd_config\"]='{arguments}", "label": 0}, {"snippet_id": 39888, "code": " in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via", "label": 0}, {"snippet_id": 60374, "code": " for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('fock', cutoff_dim", "label": 0}, {"snippet_id": 65620, "code": " &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-", "label": 0}, {"snippet_id": 30521, "code": ".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m", "label": 0}, {"snippet_id": 9783, "code": "=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}", "label": 0}, {"snippet_id": 79133, "code": " \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:(filename,fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 ", "label": 0}, {"snippet_id": 29089, "code": ".station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self.station_data.lastData(exclude", "label": 1}, {"snippet_id": 18740, "code": " extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded", "label": 0}, {"snippet_id": 66615, "code": " Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+)", "label": 1}, {"snippet_id": 82414, "code": " if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s", "label": 0}, {"snippet_id": 13527, "code": ")\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def updateMouth():\r lastMouthEvent=0\r lastMouthEventTime=0\r \r while( audio==None):\r time.sleep( 0.1)\r \r while isRunning:\r if( audio.mouthValue ", "label": 0}, {"snippet_id": 22326, "code": "\"\"\"Wait for mcpd to become available All configuration happens in mcpd so we need to wait that this is available before we go provisioning the system. I call this method at the first opportunity I have", "label": 0}, {"snippet_id": 89621, "code": ".validate() return self._is_jdk @property def system_properties(self): \"\"\"Returns a dict containing the system properties of this java distribution.\"\"\" return dict(self._get_system_properties(self.java", "label": 0}, {"snippet_id": 44975, "code": ".benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]", "label": 0}, {"snippet_id": 77966, "code": "[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending %s to targets[%s", "label": 0}, {"snippet_id": 75711, "code": ") self.poller=zmq.Poller() s=self.ctx.socket(zmq.SUB) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) s.connect(self.sig_addr) s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL') s.setsockopt(zmq.SUBSCRIBE", "label": 0}, {"snippet_id": 42227, "code": "\"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files", "label": 0}, {"snippet_id": 81063, "code": "\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t", "label": 0}, {"snippet_id": 91136, "code": ".python.pants_requirement import PantsRequirement from pants.backend.python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend", "label": 0}, {"snippet_id": 95, "code": "-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row", "label": 0}, {"snippet_id": 95226, "code": "); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import", "label": 0}, {"snippet_id": 87627, "code": "=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests) !=len(dependency_classpath): for dep in dependency_classpath: if dep.directory_digest", "label": 1}, {"snippet_id": 94035, "code": "\"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not ", "label": 0}, {"snippet_id": 89539, "code": " jdk: ``True`` to require the distribution be a JDK vs a JRE \"\"\" if home_path and not os.path.isdir(home_path): raise ValueError('The specified java home path is invalid:{}'.format(home_path)) if bin_path", "label": 0}, {"snippet_id": 7308, "code": " identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' ", "label": 0}, {"snippet_id": 57229, "code": ": from tcms.core.utils.mailto import mailto mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=='case_run_status'", "label": 0}, {"snippet_id": 56444, "code": "(self): return Component.objects.filter(product__id=self.product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties(self): if self.request.GET.get('env_group_id'): return EnvGroup", "label": 0}, {"snippet_id": 18582, "code": ") SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface", "label": 0}, {"snippet_id": 10681, "code": " filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" %", "label": 1}, {"snippet_id": 66058, "code": ") status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return", "label": 0}, {"snippet_id": 73067, "code": ": Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp.nlst() file_counter=1 file_list_total=len(file_list) for file in file_list: file_path_local=local_directory", "label": 0}, {"snippet_id": 73323, "code": " pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head(path): head,", "label": 0}, {"snippet_id": 92838, "code": "=os.path.join(tempdir, 'foo') os.symlink(not_zip.name, file_symlink) self.assertEqual(os.path.realpath(file_symlink), os.path.realpath(not_zip.name)) with self.assertRaisesRegexp(zipfile.BadZipfile, r'", "label": 0}, {"snippet_id": 64442, "code": " Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and", "label": 0}, {"snippet_id": 6661, "code": " keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode:", "label": 1}, {"snippet_id": 3850, "code": "(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config", "label": 0}, {"snippet_id": 86556, "code": ".memo import memoized_method, memoized_property _SCALAC_PLUGIN_INFO_FILE='scalac-plugin.xml' _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services", "label": 0}, {"snippet_id": 88429, "code": "=options self.build_graph=build_graph self.build_file_parser=build_file_parser self.address_mapper=address_mapper self.run_tracker=run_tracker self._log=self.Log(run_tracker) self._target_base=target_base", "label": 0}, {"snippet_id": 74631, "code": ". :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"vcf_to_zarr", "label": 0}, {"snippet_id": 44573, "code": " provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if", "label": 0}, {"snippet_id": 74922, "code": " benchmark_data_input_temp in benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark", "label": 0}, {"snippet_id": 563, "code": ":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall", "label": 0}, {"snippet_id": 83887, "code": " return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, ''", "label": 0}, {"snippet_id": 41370, "code": " from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake", "label": 1}, {"snippet_id": 57175, "code": " field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field", "label": 0}, {"snippet_id": 3616, "code": "[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available", "label": 1}, {"snippet_id": 58519, "code": ".post(self.many_comments_url, {'comment': 'new comment', 'run': '99999998,1009900'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No caserun found", "label": 0}, {"snippet_id": 27682, "code": ".type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 94585, "code": ": setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name): window=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command", "label": 0}, {"snippet_id": 19282, "code": ": 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.json') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_yaml_file_object", "label": 0}, {"snippet_id": 8615, "code": ". The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer", "label": 0}, {"snippet_id": 18945, "code": "))): with open(os.path.expanduser(str(source)), 'r') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts.scheme and parts.netloc", "label": 0}, {"snippet_id": 89829, "code": "/jar' >>> If this distribution has no valid command of the given name raises Distribution.Error. If this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if not isinstance(name,", "label": 0}, {"snippet_id": 80430, "code": "\targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print(\"[*] starting at \"+str(now.hour", "label": 0}, {"snippet_id": 12181, "code": "\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository\"] after_commit_hash=data[\"after_commit_hash\"] author=data[\"author\"] py_files=get_python_files_involved_in_pr", "label": 0}, {"snippet_id": 69939, "code": " import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand", "label": 0}, {"snippet_id": 27453, "code": "'_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon", "label": 0}, {"snippet_id": 88487, "code": "._scm else None) self._replace_targets(target_roots) self._invalidation_report=invalidation_report self._scheduler=scheduler @property def options(self): \"\"\"Returns the new-style options. :API: public ", "label": 0}, {"snippet_id": 95813, "code": " as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output", "label": 0}, {"snippet_id": 53999, "code": " is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append", "label": 0}, {"snippet_id": 35305, "code": "): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator", "label": 0}, {"snippet_id": 27928, "code": "] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0", "label": 0}, {"snippet_id": 90729, "code": " a jdk. :return: the located Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" for location in itertools.chain(self._distribution_environment", "label": 0}, {"snippet_id": 64325, "code": " remote_path[ 0:-len( \".dat\")] return local_dataset_path.with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self): return", "label": 0}, {"snippet_id": 13117, "code": "/api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(url,", "label": 0}, {"snippet_id": 28888, "code": " data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" %", "label": 0}, {"snippet_id": 28985, "code": "=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl'", "label": 0}, {"snippet_id": 95145, "code": ".VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service.setup_vcf_to_zarr(input_vcf_dir=vcf_directory, output_zarr_dir=zarr_directory_setup, conversion_config=vcf_to_zarr_config", "label": 1}, {"snippet_id": 10313, "code": "))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the", "label": 0}, {"snippet_id": 71620, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of", "label": 0}, {"snippet_id": 35192, "code": " raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag", "label": 0}, {"snippet_id": 62917, "code": " JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import", "label": 0}, {"snippet_id": 28624, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'", "label": 0}, {"snippet_id": 12911, "code": ", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove", "label": 0}, {"snippet_id": 89989, "code": " _get_version(self, java): return _parse_java_version('java.version', self._get_system_properties(java)['java.version']) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir(", "label": 0}, {"snippet_id": 29750, "code": " value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage.", "label": 1}, {"snippet_id": 38769, "code": " force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph", "label": 0}, {"snippet_id": 424, "code": ".get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if", "label": 0}, {"snippet_id": 9433, "code": ", composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. ", "label": 0}, {"snippet_id": 39517, "code": " isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule", "label": 0}, {"snippet_id": 69432, "code": " def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes", "label": 1}, {"snippet_id": 53454, "code": "._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains", "label": 0}, {"snippet_id": 91091, "code": "._normalized_jdk_paths: return() os_name=normalize_os_name(os.uname()[0].lower()) if os_name not in self._normalized_jdk_paths: logger.warning('--jvm-distributions-paths was specified, but has no entry", "label": 0}, {"snippet_id": 90263, "code": " self.Location.from_home(home) if home else None jdk_home=env_home('JDK_HOME') if jdk_home: yield jdk_home java_home=env_home('JAVA_HOME') if java_home: yield java_home search_path=os.environ.get('PATH", "label": 0}, {"snippet_id": 72554, "code": ".add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a", "label": 0}, {"snippet_id": 27775, "code": "'WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 29831, "code": " expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file", "label": 1}, {"snippet_id": 58859, "code": " TestUpdateCasePriority(BasePlanCase): \"\"\"Test case for update_cases_default_tester\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateCasePriority, cls).setUpTestData() cls.permission='testcases.change_testcase'", "label": 0}, {"snippet_id": 37501, "code": " else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified", "label": 0}, {"snippet_id": 5035, "code": " identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' ", "label": 0}, {"snippet_id": 95615, "code": " urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file): with open(local_file, 'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in", "label": 0}, {"snippet_id": 79803, "code": " uploads are put. Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use", "label": 0}, {"snippet_id": 62383, "code": "\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': for qubit in self.reg: self.eng.deallocate_qubit(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate", "label": 0}, {"snippet_id": 12599, "code": "\" url=url.format(repository, str(data[\"pr_number\"])) comments=requests.get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507", "label": 0}, {"snippet_id": 79947, "code": " 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group", "label": 0}, {"snippet_id": 37313, "code": "*kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in", "label": 0}, {"snippet_id": 39911, "code": "\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow", "label": 0}, {"snippet_id": 42409, "code": ".norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output", "label": 0}, {"snippet_id": 57122, "code": " or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field and value.') field=str(field) value, error=get_value_by_type(value, vtype) if error: return say_no(error)", "label": 0}, {"snippet_id": 71838, "code": " NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except KeyError: print \"Error -Unrecognized action\" print", "label": 1}, {"snippet_id": 85034, "code": " version will be used.') register('--suffix-version', advanced=True, default=None, help='Scala suffix to be used in `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause", "label": 0}, {"snippet_id": 1926, "code": "'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action)", "label": 0}, {"snippet_id": 72322, "code": " remoteirc.reply_lock: try: log.debug('(%s) networks.remote: overriding reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service", "label": 1}, {"snippet_id": 72431, "code": " the server, runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments", "label": 1}, {"snippet_id": 44686, "code": ".path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile)", "label": 0}, {"snippet_id": 90089, "code": "._is_jdk: yield os.path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{} executable,", "label": 0}, {"snippet_id": 37238, "code": " def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self", "label": 0}, {"snippet_id": 81257, "code": " \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif", "label": 1}, {"snippet_id": 80085, "code": " while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\"", "label": 0}, {"snippet_id": 92313, "code": "=new_output).wait() new_output.seek(0) self.assertEqual('False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'):", "label": 0}, {"snippet_id": 13590, "code": ")\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText):\r", "label": 0}, {"snippet_id": 6600, "code": "\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file", "label": 1}, {"snippet_id": 83233, "code": ", 'ensure_has_status_update_callback'): self.client_manager.ensure_has_status_update_callback(self.__async_update) return job_state status=client.get_status() except Exception: self.mark_as_finished(job_state", "label": 0}, {"snippet_id": 32320, "code": " name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self", "label": 0}, {"snippet_id": 82929, "code": "=\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]", "label": 1}, {"snippet_id": 60738, "code": " instantiate new objects based on undefined methods. The dynamic methods pass their arguments directly to __init__ of the inheriting class.\"\"\" def __getattr__(cls, name): \"\"\"Get the attribute call via name", "label": 0}, {"snippet_id": 14212, "code": "=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with", "label": 0}, {"snippet_id": 91581, "code": "-constraint\", text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor, PyTest, PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest, python_setup, source_root_config", "label": 1}, {"snippet_id": 15049, "code": " start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query", "label": 0}, {"snippet_id": 19445, "code": "(argv=None): \"\"\"Return the parsed args to use in main().\"\"\" if argv is None: argv=sys.argv prog=argv[0] if prog==__file__: prog='{} -m ptvsd'.format(os.path.basename(sys.executable)) else: prog=argv[0]", "label": 0}, {"snippet_id": 1954, "code": ".Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)", "label": 0}, {"snippet_id": 61306, "code": " must be Hermitian.\") return A operator_map={ 'QubitStateVector': ket, 'QubitUnitary': unitary, 'Hermitian': hermitian, 'Identity': I, 'PauliX': X, 'PauliY': Y, 'PauliZ': Z, 'CNOT': CNOT, 'SWAP': SWAP, ", "label": 0}, {"snippet_id": 76040, "code": "(self, i, m, f): self.log.debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully", "label": 0}, {"snippet_id": 76469, "code": "() if self.start_timer: self.inter_sleep(self.start_timer) if self.running: self.log.info('Starting') try: self.child=self.call[0](*self.call[1], **self.call[2]) self.child(self) except WorkerInterrupt", "label": 0}, {"snippet_id": 60065, "code": "(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self", "label": 0}, {"snippet_id": 75101, "code": "(msg) def handle_keepalive_reply(self, reqid, seqnum, status, data): if status==wzrpc.status.success: self.p.log.debug('Keepalive was successfull') elif status==wzrpc.status.e_req_denied: self.p.log.warn(", "label": 0}, {"snippet_id": 77932, "code": "(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Removing %s from targets[%s]', repr(t), domain) tlist.remove(t) def add_target_exc", "label": 0}, {"snippet_id": 33137, "code": " cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None", "label": 0}, {"snippet_id": 83311, "code": ", self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state", "label": 1}, {"snippet_id": 24365, "code": "%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data", "label": 1}, {"snippet_id": 17755, "code": " return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles", "label": 0}, {"snippet_id": 15283, "code": ") self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename", "label": 1}, {"snippet_id": 56370, "code": "+obj_value.get(field, None) +'</li>' response_str +='</ul>' return HttpResponse(response_str) return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value'))) class _InfoObjects", "label": 0}, {"snippet_id": 54224, "code": "=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary", "label": 0}, {"snippet_id": 90784, "code": ".Error) as e: logger.debug('{} is not a valid distribution because:{}' .format(location.home_path, str(e))) pass if(minimum_version is not None and maximum_version is not None and maximum_version < minimum_version", "label": 0}, {"snippet_id": 62550, "code": ") self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ", "label": 0}, {"snippet_id": 49538, "code": "(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule", "label": 0}, {"snippet_id": 7151, "code": "(acronyms, output_limit))) else: my_styles[\"raw\"]=(single_keywords_p, composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires", "label": 0}, {"snippet_id": 46510, "code": " name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1", "label": 0}, {"snippet_id": 43340, "code": " benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self", "label": 0}, {"snippet_id": 87900, "code": "._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret=[] for name, cp_entries in plugin_jar_map.items(): ret.append('-S-Xplugin:{}'.format(':'.join(cp_entries))) for arg in scalac_plugin_map[name]", "label": 0}, {"snippet_id": 61143, "code": "\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm(-1j * theta/2 * Z) def fr3(a, b, c):", "label": 0}, {"snippet_id": 6520, "code": " to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os", "label": 0}, {"snippet_id": 89248, "code": ":param execute_process_request: The ExecuteProcessRequest to run. :param name: A descriptive name representing the process being executed. :param labels: A tuple of WorkUnitLabels. :return: An ExecuteProcessResult", "label": 0}, {"snippet_id": 79234, "code": " detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t", "label": 0}, {"snippet_id": 89333, "code": ".base.revision import Revision from pants.java.util import execute_java, execute_java_async from pants.subsystem.subsystem import Subsystem from pants.util.contextutil import temporary_dir from pants.util", "label": 0}, {"snippet_id": 30914, "code": " self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in", "label": 0}, {"snippet_id": 18846, "code": " import yaml from flex.context_managers import ErrorDict from flex.exceptions import ValidationError from flex.loading.definitions import( definitions_validator, ) from flex.loading.schema import( swagger_schema_validator", "label": 0}, {"snippet_id": 59003, "code": "(name='os') cls.property_python=EnvPropertyFactory(name='python') cls.property_django=EnvPropertyFactory(name='django') EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_os) EnvGroupPropertyMapFactory", "label": 0}, {"snippet_id": 43999, "code": ", drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary", "label": 0}, {"snippet_id": 37108, "code": " rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in", "label": 0}, {"snippet_id": 51548, "code": " wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)=", "label": 0}, {"snippet_id": 16494, "code": "._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive():", "label": 0}, {"snippet_id": 89409, "code": " a JRE or a JDK installed on the local system. In particular provides access to the distribution's binaries; ie: java while ensuring basic constraints are met. For example a minimum version can be specified", "label": 0}, {"snippet_id": 90441, "code": " self._possible_environments=possible_environments @property def jvm_locations(self): return itertools.chain(*(pe.jvm_locations for pe in self._possible_environments)) class _Locator(object): class Error", "label": 0}, {"snippet_id": 38252, "code": " from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None,", "label": 0}, {"snippet_id": 88519, "code": "\"\"Returns the Products manager for the current run. :API: public \"\"\" return self._products @property def source_roots(self): \"\"\"Returns the:class:`pants.source.source_root.SourceRoots` instance for the", "label": 0}, {"snippet_id": 23445, "code": " is not None: cmd=\"pw useradd{0} -e{1} -m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode !=0: raise OSUtilError((\"Failed", "label": 0}, {"snippet_id": 84268, "code": "=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory=remote_job_config", "label": 0}, {"snippet_id": 25090, "code": "\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station", "label": 1}, {"snippet_id": 73216, "code": " are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output", "label": 0}, {"snippet_id": 29074, "code": " self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station", "label": 1}, {"snippet_id": 71981, "code": " in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt", "label": 1}, {"snippet_id": 64784, "code": " RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 0}, {"snippet_id": 30918, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name", "label": 0}, {"snippet_id": 21265, "code": " re.match(\"^https://youtu\\.be\", x)] newer_links=[x for x in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None", "label": 0}, {"snippet_id": 81180, "code": " not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want", "label": 0}, {"snippet_id": 78988, "code": " following file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl", "label": 0}, {"snippet_id": 69989, "code": " file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs(conf_dir_path, 0755) except OSError, ex:", "label": 0}, {"snippet_id": 58263, "code": ".testruns.models import TestCaseRun from tcms.testruns.models import TestCaseRunStatus from tcms.tests import BaseCaseRun from tcms.tests import BasePlanCase from tcms.tests import remove_perm_from_user from", "label": 0}, {"snippet_id": 56833, "code": " def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter(object): ", "label": 0}, {"snippet_id": 17795, "code": " extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data", "label": 0}, {"snippet_id": 30223, "code": " get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names", "label": 0}, {"snippet_id": 68015, "code": " target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client", "label": 0}, {"snippet_id": 5078, "code": "(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw], encode_for_xml", "label": 0}, {"snippet_id": 25106, "code": " details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant", "label": 1}, {"snippet_id": 34498, "code": "\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow", "label": 0}, {"snippet_id": 93492, "code": " if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp", "label": 0}, {"snippet_id": 32897, "code": ".abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows", "label": 0}, {"snippet_id": 68970, "code": " client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path", "label": 1}, {"snippet_id": 89581, "code": " should be supplied, given: ' 'home_path={} bin_path={}'.format(home_path, bin_path)) self._home=home_path self._bin_path=bin_path or(os.path.join(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version", "label": 0}, {"snippet_id": 68528, "code": "> 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers", "label": 0}, {"snippet_id": 45545, "code": ".path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file", "label": 0}, {"snippet_id": 5205, "code": "=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories } def _output_text(complete_output, categories): \"", "label": 0}, {"snippet_id": 75929, "code": " rs.finished: if not rs.retry: del msgdict[rs] continue s.send_multipart(msgdict[rs]) rs.finished=False rs.retry=False flag=1 if not flag: return t.tick() p(timeout*1000) if t.elapsed(False) >=timeout:", "label": 0}, {"snippet_id": 24474, "code": "\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the", "label": 0}, {"snippet_id": 31469, "code": "\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from", "label": 0}, {"snippet_id": 92147, "code": " bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires-pex' @classmethod def register_options(cls, register): super(BuildSetupRequiresPex, cls).register_options", "label": 0}, {"snippet_id": 45073, "code": " decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads", "label": 0}, {"snippet_id": 69746, "code": ".FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1)", "label": 0}, {"snippet_id": 56383, "code": " info_type(), fields=('name', 'value'))) class _InfoObjects(object): def __init__(self, request, product_id=None): self.request=request try: self.product_id=int(product_id) except(ValueError, TypeError", "label": 0}, {"snippet_id": 69097, "code": " CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status", "label": 0}, {"snippet_id": 75822, "code": ".sleep_ticker, self.wz timeout=timeout if timeout else self.wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart", "label": 1}, {"snippet_id": 60186, "code": " Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ ", "label": 0}, {"snippet_id": 54066, "code": ".keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio", "label": 0}, {"snippet_id": 92275, "code": "=False) as output: with environment_as(HORK='BORK'): subprocess.Popen([sys.executable, '-c', 'import os; print(os.environ[\"HORK\"])'], stdout=output).wait() output.seek(0) self.assertEqual('BORK\\n', output", "label": 0}, {"snippet_id": 10960, "code": "(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url): try: response=requests.get(url) except socket.error as e: msg=\"Could not open socket for '%s', error: %s\" %(url, e", "label": 0}, {"snippet_id": 62957, "code": ".lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner']", "label": 0}, {"snippet_id": 76820, "code": ") parser.add_argument('--die-on-neterror', action='store_true', default=False, help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net.RequestPerformer() noproxy_rp", "label": 0}, {"snippet_id": 56997, "code": "\"invalid literal for int() with base 10: 'string'\") \"\"\" value=error=None def get_time(time): date_time=datetime.datetime if time=='NOW': return date_time.now() return date_time.strptime(time, '%Y%m%d %H%M%S')", "label": 0}, {"snippet_id": 69851, "code": " system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def", "label": 0}, {"snippet_id": 22531, "code": " hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the", "label": 0}, {"snippet_id": 37758, "code": "=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems", "label": 0}, {"snippet_id": 27647, "code": "='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state", "label": 0}, {"snippet_id": 79666, "code": " the following(name -description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__", "label": 0}, {"snippet_id": 75939, "code": ".finished=False rs.retry=False flag=1 if not flag: return t.tick() p(timeout*1000) if t.elapsed(False) >=timeout: for rs in rslist: if not rs.finished: rs.accept(None, 0, 255,[]) rs.finished=True raise", "label": 0}, {"snippet_id": 7059, "code": ":keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum", "label": 0}, {"snippet_id": 45865, "code": "}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern", "label": 0}, {"snippet_id": 64563, "code": "\"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler", "label": 1}, {"snippet_id": 67568, "code": "(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed", "label": 0}, {"snippet_id": 69876, "code": " result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self", "label": 0}, {"snippet_id": 25290, "code": "'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), })", "label": 1}, {"snippet_id": 23277, "code": " offset): return sock[offset:offset+16].split(b'\\0', 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using tmsh. :param net: :param mask: :param gateway: :return: \"\"\" cmd=(\"/usr/bin", "label": 0}, {"snippet_id": 24903, "code": " data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self", "label": 0}, {"snippet_id": 12897, "code": ".communicate() data[\"diff\"][filename]=stdout.decode(r.encoding) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\",", "label": 0}, {"snippet_id": 23626, "code": " manually to get it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run(\"/etc/rc.d/dhclient start", "label": 0}, {"snippet_id": 64956, "code": "* from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs", "label": 0}, {"snippet_id": 36940, "code": "=2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self", "label": 0}, {"snippet_id": 69863, "code": ": RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 1726, "code": ".username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows)", "label": 0}, {"snippet_id": 8356, "code": "(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q", "label": 0}, {"snippet_id": 68841, "code": " AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\",", "label": 0}, {"snippet_id": 88693, "code": " target_count=len(self.build_graph) self.run_tracker.pantsd_stats.set_affected_targets_size(target_count) return target_count def submit_background_work_chain(self, work_chain, parent_workunit_name=None): \"\"\" ", "label": 0}, {"snippet_id": 3707, "code": " comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window", "label": 0}, {"snippet_id": 44251, "code": " logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other", "label": 0}, {"snippet_id": 93829, "code": "(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0][", "label": 0}, {"snippet_id": 50658, "code": "\"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self", "label": 0}, {"snippet_id": 36329, "code": ", w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value", "label": 0}, {"snippet_id": 21940, "code": " become=None, become_method=None, become_user=None, become_ask_pass=None, ask_pass=None, private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None", "label": 0}, {"snippet_id": 50855, "code": ".\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file", "label": 1}, {"snippet_id": 81245, "code": " detection will not be possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd:", "label": 0}, {"snippet_id": 84321, "code": "]=remote_system_properties.get('galaxy_dataset_files_path', None) if LwrJobRunner.__use_remote_datatypes_conf( client): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file", "label": 0}, {"snippet_id": 77585, "code": "(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues[domain", "label": 0}, {"snippet_id": 47292, "code": ": files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self", "label": 0}, {"snippet_id": 25239, "code": "], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle'", "label": 0}, {"snippet_id": 79943, "code": ", for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example:", "label": 0}, {"snippet_id": 16893, "code": " GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout", "label": 0}, {"snippet_id": 47426, "code": ": \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards", "label": 0}, {"snippet_id": 17847, "code": " from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS=", "label": 0}, {"snippet_id": 40090, "code": " def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError", "label": 0}, {"snippet_id": 60707, "code": " self._observe.name=='Displacement': ex=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device\"\"\" if self", "label": 0}, {"snippet_id": 53274, "code": ".dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input", "label": 0}, {"snippet_id": 6150, "code": " \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if", "label": 1}, {"snippet_id": 1296, "code": "'nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return", "label": 0}, {"snippet_id": 1607, "code": "> 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request", "label": 0}, {"snippet_id": 88155, "code": " 'r') as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except IOError as e: if e.errno !=errno.ENOENT: raise else: with open_zip(classpath_element, 'r') as jarfile: try", "label": 0}, {"snippet_id": 61114, "code": " fry(theta): r\"\"\"One-qubit rotation about the y axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm(-1j * theta/2 * Y) def", "label": 0}, {"snippet_id": 72297, "code": ".debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name, text, placeholder_self.name) if 'source' in kwargs: del kwargs['source'] irc.reply(text, source=irc.pseudoclient.uid, **kwargs", "label": 0}, {"snippet_id": 83052, "code": "\t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(\"Found", "label": 0}, {"snippet_id": 23125, "code": " But I will log that we do not support this for future reference. :param chk_err: Whether or not to check for errors raised by the eject command \"\"\" logger.warn(\"Eject is not supported on this platform", "label": 0}, {"snippet_id": 15678, "code": " debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler", "label": 0}, {"snippet_id": 87807, "code": " to zinc should be in working directory or ' 'part of the JDK.{} is not.'.format(path)) if path !=os.path.normpath(path): raise TaskError('Classpath entries provided to zinc should be normalized ' '(i.e", "label": 0}, {"snippet_id": 24399, "code": ".warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def", "label": 0}, {"snippet_id": 31347, "code": " restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set()", "label": 0}, {"snippet_id": 83055, "code": "\t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(\"Found the following entry points: \") print", "label": 0}, {"snippet_id": 46505, "code": "=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if", "label": 0}, {"snippet_id": 80959, "code": "\t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName \t\tself.uploadsFolder=uploadsFolder \t\tself.size=size \t", "label": 0}, {"snippet_id": 47244, "code": " requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_", "label": 0}, {"snippet_id": 533, "code": "\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all()", "label": 0}, {"snippet_id": 31895, "code": " def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item", "label": 0}, {"snippet_id": 72320, "code": ") old_reply=remoteirc.reply with remoteirc.reply_lock: try: log.debug('(%s) networks.remote: overriding reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc", "label": 1}, {"snippet_id": 13609, "code": "( 0,7))\r \r def talk(myText):\r if( myText.find( \"twitter\") >=0):\r myText +=\"0\"\r myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please", "label": 0}, {"snippet_id": 44820, "code": "[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule", "label": 0}, {"snippet_id": 72993, "code": ".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"\" Recursive", "label": 0}, {"snippet_id": 3083, "code": ".get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out", "label": 0}, {"snippet_id": 52271, "code": " else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={", "label": 0}, {"snippet_id": 22444, "code": " 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err=False) def stop_agent_service(self): return shellutil.run(\"/sbin/service waagent stop\"", "label": 0}, {"snippet_id": 38974, "code": "\"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n", "label": 0}, {"snippet_id": 89625, "code": " @property def system_properties(self): \"\"\"Returns a dict containing the system properties of this java distribution.\"\"\" return dict(self._get_system_properties(self.java)) @property def version(self):", "label": 0}, {"snippet_id": 58584, "code": " case_run_pk in(self.case_run_1.pk, self.case_run_2.pk): comments=Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self.assertEqual(new_comment, comments[0].comment) self.assertEqual", "label": 0}, {"snippet_id": 34355, "code": " _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None", "label": 0}, {"snippet_id": 6120, "code": ".error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log", "label": 1}, {"snippet_id": 85164, "code": ".version=='custom': suffix=self.get_options().suffix_version if suffix: return '{0}_{1}'.format(name, suffix) else: raise RuntimeError('Suffix version must be specified if using a custom scala version. ' ", "label": 0}, {"snippet_id": 89870, "code": " this distribution against its configured constraints. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" if self._validated_binaries: return with self", "label": 0}, {"snippet_id": 76848, "code": ".rp_timeout d=DataLoader(noproxy_rp, c.only_cache) c.router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b", "label": 0}, {"snippet_id": 3681, "code": " check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not", "label": 0}, {"snippet_id": 95980, "code": " log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr]", "label": 0}, {"snippet_id": 33930, "code": " self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath", "label": 0}, {"snippet_id": 78351, "code": " self.w.sleep(self.errortimeout) except exc.PermanentError as e: try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception", "label": 0}, {"snippet_id": 9488, "code": " single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('</record><", "label": 0}, {"snippet_id": 84103, "code": ".get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution", "label": 1}, {"snippet_id": 17474, "code": "{} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None)", "label": 0}, {"snippet_id": 32602, "code": "-a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if", "label": 0}, {"snippet_id": 78671, "code": " overridden by sub classes\"\"\" pass def run(self): try: if self.options is not None and self.options.daemon: log.logger.debug('Executing remotely') return self.executer(*sys.argv) log.logger.debug('Executing", "label": 1}, {"snippet_id": 69629, "code": ": Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not", "label": 0}, {"snippet_id": 29969, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{", "label": 0}, {"snippet_id": 23946, "code": " port_id > 3: return None g0=\"00000000\" if port_id > 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=", "label": 0}, {"snippet_id": 93823, "code": " % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window", "label": 0}, {"snippet_id": 83005, "code": "\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]", "label": 0}, {"snippet_id": 66383, "code": " * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler", "label": 0}, {"snippet_id": 9184, "code": " skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,..", "label": 0}, {"snippet_id": 76426, "code": ") if socks.get(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg(self, frames): try: for nfr in self.wz.parse_router_msg(frames): self.wz_sock", "label": 0}, {"snippet_id": 55857, "code": " output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params", "label": 0}, {"snippet_id": 18078, "code": ") return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy", "label": 0}, {"snippet_id": 86381, "code": "._scheduler) output_files=tuple( os.path.relpath(f.path.replace('.java', '.class'), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest", "label": 0}, {"snippet_id": 14418, "code": ".join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR", "label": 0}, {"snippet_id": 24597, "code": "': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full", "label": 0}, {"snippet_id": 64637, "code": "\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import", "label": 0}, {"snippet_id": 24884, "code": "': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0", "label": 0}, {"snippet_id": 93209, "code": " class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self", "label": 0}, {"snippet_id": 3119, "code": " else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self", "label": 0}, {"snippet_id": 25540, "code": " if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1", "label": 0}, {"snippet_id": 93739, "code": " sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING)", "label": 0}, {"snippet_id": 70368, "code": "'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr", "label": 0}, {"snippet_id": 32547, "code": " producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement", "label": 0}, {"snippet_id": 90418, "code": ".from_home(home) class _UnknownEnvironment(_DistributionEnvironment): def __init__(self, *possible_environments): super(_DistributionEnvironment, self).__init__() if len(possible_environments) < 2: raise", "label": 0}, {"snippet_id": 77107, "code": " self.log.info( 'Initializing intraprocess signal socket %s', self.th_sa) self.th_sock=self.p.ctx.socket(zmq.PUB) self.th_sock.bind(self.th_sa) def init_th_back_sock(self): self.log.info( 'Initializing", "label": 0}, {"snippet_id": 87971, "code": " we have to provide these entries separately, in the -Xplugin: flag). Note that we don't currently support external plugins with dependencies, as we can't know which external classpath elements are required", "label": 0}, {"snippet_id": 62987, "code": "=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL", "label": 0}, {"snippet_id": 21886, "code": " dciclient.v1 import helper as dci_helper from dciagent.plugins import plugin import jinja2 import os import subprocess display=Display() class Options(object): def __init__(self, verbosity=None, inventory", "label": 1}, {"snippet_id": 929, "code": ".POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 50919, "code": " path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise", "label": 0}, {"snippet_id": 19956, "code": " not running') if self._session is not None: raise RuntimeError('already attached') if addr is None: addr=adapter.address self._attach(addr, **kwargs) return self._session def detach(self, adapter=None", "label": 0}, {"snippet_id": 59287, "code": "): Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator", "label": 0}, {"snippet_id": 57089, "code": "\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value", "label": 0}, {"snippet_id": 84201, "code": " are broken in different ways for same reason -datatypes may not match. One can push the local datatypes config to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively", "label": 0}, {"snippet_id": 43201, "code": " ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete", "label": 0}, {"snippet_id": 85084, "code": "=JarDependency('missing spec', ' //:{}'.format(key)) cls.register_jvm_tool(register, cls._key_for_tool_version(key, 'custom'), classpath=[dummy_jardep]) register_custom_tool('scalac') register_custom_tool", "label": 1}, {"snippet_id": 8824, "code": " process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url", "label": 1}, {"snippet_id": 77322, "code": "'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try", "label": 0}, {"snippet_id": 48210, "code": ".wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items", "label": 0}, {"snippet_id": 15351, "code": "=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'", "label": 0}, {"snippet_id": 22053, "code": " self.syntax=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def", "label": 0}, {"snippet_id": 19144, "code": " is not None: validate_response( response=response, request_method=request_method, schema=schema ) def validate_api_call(schema, raw_request, raw_response): \"\"\" Validate the request/response cycle of an", "label": 0}, {"snippet_id": 56284, "code": " TestCaseRunStatus, TestRunTag from tcms.core.helpers.comments import add_comment from tcms.core.utils.validations import validate_bug_id def check_permission(request, ctype): perm='%s.change_%s' % tuple(ctype.split", "label": 0}, {"snippet_id": 70914, "code": " t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING", "label": 0}, {"snippet_id": 36748, "code": " __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"", "label": 0}, {"snippet_id": 46870, "code": ".benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources", "label": 0}, {"snippet_id": 52968, "code": " False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self", "label": 0}, {"snippet_id": 9478, "code": "'<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords", "label": 0}, {"snippet_id": 35516, "code": ": \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr", "label": 0}, {"snippet_id": 50956, "code": ") if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod", "label": 0}, {"snippet_id": 47442, "code": "(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name", "label": 0}, {"snippet_id": 41050, "code": " get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names ", "label": 0}, {"snippet_id": 11806, "code": " http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key,{}", "label": 1}, {"snippet_id": 4779, "code": " composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style", "label": 0}, {"snippet_id": 50358, "code": ".\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo", "label": 0}, {"snippet_id": 36855, "code": " s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join", "label": 0}, {"snippet_id": 52491, "code": " None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self", "label": 0}, {"snippet_id": 41628, "code": " None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self", "label": 0}, {"snippet_id": 19940, "code": " adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError('already using managed adapter') if adapter is None: raise RuntimeError('debugger not running') if self._session is", "label": 0}, {"snippet_id": 71979, "code": " for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer))", "label": 1}, {"snippet_id": 25439, "code": "=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id']", "label": 0}, {"snippet_id": 12292, "code": " error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/", "label": 0}, {"snippet_id": 46348, "code": " to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone -", "label": 0}, {"snippet_id": 18150, "code": " from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm", "label": 0}, {"snippet_id": 65005, "code": " verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs)", "label": 0}, {"snippet_id": 44436, "code": ".summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag", "label": 0}, {"snippet_id": 50238, "code": "): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input", "label": 0}, {"snippet_id": 24460, "code": " self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property", "label": 0}, {"snippet_id": 94346, "code": ".error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if", "label": 0}, {"snippet_id": 70856, "code": ".CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device", "label": 0}, {"snippet_id": 94598, "code": " window=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log", "label": 0}, {"snippet_id": 38527, "code": " resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1,", "label": 0}, {"snippet_id": 93313, "code": " window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger", "label": 0}, {"snippet_id": 75912, "code": ", request[1][3]) msg.insert(0, b'') msgdict[rs]=msg s.send_multipart(msg) while self.running.is_set(): flag=0 for rs in rslist: if rs.finished: if not rs.retry: del msgdict[rs] continue s.send_multipart", "label": 0}, {"snippet_id": 40645, "code": "\"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic", "label": 1}, {"snippet_id": 3499, "code": "(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self):", "label": 0}, {"snippet_id": 59243, "code": ": SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend", "label": 0}, {"snippet_id": 9044, "code": ") if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms", "label": 0}, {"snippet_id": 58274, "code": " BaseCaseRun from tcms.tests import BasePlanCase from tcms.tests import remove_perm_from_user from tcms.tests import user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories", "label": 0}, {"snippet_id": 95906, "code": " convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the", "label": 1}, {"snippet_id": 68224, "code": " target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state", "label": 0}, {"snippet_id": 6472, "code": "\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache", "label": 0}, {"snippet_id": 70506, "code": " ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self,", "label": 0}, {"snippet_id": 76802, "code": "-errortimeout', type=float, default=3, help='Error timeout') parser.add_argument('--stop-on-closed', action='store_true', default=False, help='Forget about closed topics') parser.add_argument('--die-on-neterror'", "label": 0}, {"snippet_id": 41263, "code": ". Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError", "label": 0}, {"snippet_id": 66038, "code": " AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict", "label": 0}, {"snippet_id": 39960, "code": " times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks", "label": 0}, {"snippet_id": 49806, "code": " cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for", "label": 0}, {"snippet_id": 33341, "code": ", targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete", "label": 0}, {"snippet_id": 23263, "code": " iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name(self, sock, offset): return sock[offset:offset+16].split(b'\\0', 1)[0] def", "label": 0}, {"snippet_id": 93416, "code": ".addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '%s'!", "label": 0}, {"snippet_id": 95594, "code": " file_list_total, file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url", "label": 0}, {"snippet_id": 66923, "code": "\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list", "label": 0}, {"snippet_id": 5993, "code": "): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.", "label": 1}, {"snippet_id": 27297, "code": " None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional", "label": 1}, {"snippet_id": 40324, "code": " get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait", "label": 0}, {"snippet_id": 82811, "code": ".legitExtensions) > 0: \t\tn=up.detectValidExtensions(extensions,args.n,args.legitExtensions) \telse: \t\tn=up.detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions", "label": 0}, {"snippet_id": 37430, "code": "=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 63308, "code": ": client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds", "label": 0}, {"snippet_id": 20801, "code": "']=msg return msg.type=='event' and msg.event==event and condition(msg) handlername='event{!r}'.format(event) evt=self._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result", "label": 0}, {"snippet_id": 10524, "code": ".url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks", "label": 1}, {"snippet_id": 89858, "code": " self.validate() return self._validated_executable(name) def validate(self): \"\"\"Validates this distribution against its configured constraints. Raises Distribution.Error if this distribution is not valid", "label": 0}, {"snippet_id": 5118, "code": "=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output)", "label": 0}, {"snippet_id": 73745, "code": " found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for", "label": 0}, {"snippet_id": 33380, "code": " cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory", "label": 0}, {"snippet_id": 33797, "code": " if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if", "label": 0}, {"snippet_id": 32703, "code": "() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher", "label": 0}, {"snippet_id": 56577, "code": "()) def tags(request): \"\"\" Get tags for TestPlan, TestCase or TestRun \"\"\" tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a", "label": 1}, {"snippet_id": 36886, "code": " import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand", "label": 0}, {"snippet_id": 82134, "code": ",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser", "label": 0}, {"snippet_id": 70329, "code": " def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler", "label": 0}, {"snippet_id": 36166, "code": ".b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize", "label": 0}, {"snippet_id": 17094, "code": " SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy(", "label": 1}, {"snippet_id": 10678, "code": "'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file", "label": 1}, {"snippet_id": 5003, "code": " True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would", "label": 0}, {"snippet_id": 66210, "code": " if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev", "label": 0}, {"snippet_id": 42793, "code": " same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput", "label": 0}, {"snippet_id": 41287, "code": "{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config", "label": 0}, {"snippet_id": 67183, "code": ".Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import", "label": 0}, {"snippet_id": 66873, "code": " nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError", "label": 0}, {"snippet_id": 6297, "code": " None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has", "label": 1}, {"snippet_id": 11175, "code": " parse(file_name): etag, mtime=None, 0 def extract(comment, current_value): value=None if line.startswith(comment): value=line.rstrip()[len(comment):] return value or current_value try: with open(file_name", "label": 0}, {"snippet_id": 87578, "code": "-Xbootclasspath/p:{}'.format(':'.join(self.javac_classpath()))]) jvm_options.extend(self._jvm_options) zinc_args.extend(ctx.sources) self.log_zinc_file(ctx.analysis_file) with open(ctx.zinc_args_file, ", "label": 0}, {"snippet_id": 17307, "code": "), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format", "label": 0}, {"snippet_id": 71890, "code": "(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): ", "label": 0}, {"snippet_id": 18888, "code": " flex.validation.request import validate_request from flex.validation.response import validate_response def load_source(source): \"\"\" Common entry point for loading some form of raw swagger schema. Supports", "label": 0}, {"snippet_id": 22143, "code": "\" self.variable_manager.extra_vars={'job_id': job_id} self.pbex.run() return self.pbex._tqm._stats class AnsiblePlugin(plugin.Plugin): def __init__(self, conf): super(AnsiblePlugin, self).__init__(conf", "label": 0}, {"snippet_id": 79761, "code": " files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45", "label": 0}, {"snippet_id": 76165, "code": ", retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self", "label": 0}, {"snippet_id": 28371, "code": ".get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning", "label": 0}, {"snippet_id": 66375, "code": " from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine", "label": 0}, {"snippet_id": 33176, "code": " force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait", "label": 0}, {"snippet_id": 5633, "code": " category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info", "label": 0}, {"snippet_id": 72672, "code": "] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled. Skipping FTP download", "label": 1}, {"snippet_id": 91477, "code": " os import sys from builtins import str from future.utils import text_type from pants.backend.python.rules.inject_init import InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest", "label": 0}, {"snippet_id": 4709, "code": "<keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v", "label": 0}, {"snippet_id": 25179, "code": "'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy", "label": 0}, {"snippet_id": 78187, "code": "(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets", "label": 0}, {"snippet_id": 18640, "code": " return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest())", "label": 0}, {"snippet_id": 92108, "code": "(dedent(\"\"\"\\ Pants doesn't currently support cross-compiling native code. The following targets set platforms arguments other than['current'], which is unsupported for this reason. Please either remove the", "label": 0}, {"snippet_id": 31741, "code": "(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output", "label": 0}, {"snippet_id": 24776, "code": " self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240:", "label": 0}, {"snippet_id": 89964, "code": "}'.format(e)) raise def execute_java(self, *args, **kwargs): return execute_java(*args, distribution=self, **kwargs) def execute_java_async(self, *args, **kwargs): return execute_java_async(*args, distribution", "label": 0}, {"snippet_id": 80616, "code": "=\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex", "label": 0}, {"snippet_id": 87577, "code": " jvm_options.extend(['-Xbootclasspath/p:{}'.format(':'.join(self.javac_classpath()))]) jvm_options.extend(self._jvm_options) zinc_args.extend(ctx.sources) self.log_zinc_file(ctx.analysis_file) with open(ctx", "label": 0}, {"snippet_id": 14692, "code": " self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at", "label": 0}, {"snippet_id": 76638, "code": "/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]') msg.append('\u041a\u0430\u0436\u0434\u044b\u0439 \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random.randint(0, 9999999999))) return '\\n'.join(msg) def sbjfun(): return sup.randstr", "label": 0}, {"snippet_id": 73411, "code": ".VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir) create_directory_tree(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path", "label": 0}, {"snippet_id": 30825, "code": " Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError", "label": 0}, {"snippet_id": 31035, "code": " in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add", "label": 0}, {"snippet_id": 62305, "code": ") if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented", "label": 0}, {"snippet_id": 33089, "code": " only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule", "label": 0}, {"snippet_id": 7209, "code": "</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms", "label": 0}, {"snippet_id": 69093, "code": "=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support", "label": 0}, {"snippet_id": 67051, "code": " from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF", "label": 0}, {"snippet_id": 92600, "code": ".realpath(f.name).startswith(os.path.realpath(path)), 'file should be created in root_dir if specified.') def test_temporary_dir_no_args(self): with temporary_dir() as path: self.assertTrue(os.path.exists", "label": 0}, {"snippet_id": 87707, "code": ", ) res=self.context.execute_process_synchronously(req, self.name(),[WorkUnitLabel.COMPILER]) self.context._scheduler.materialize_directories(( DirectoryToMaterialize(get_buildroot(), res.output_directory_digest", "label": 1}, {"snippet_id": 28271, "code": "'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl'", "label": 1}, {"snippet_id": 63309, "code": " client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if", "label": 0}, {"snippet_id": 57588, "code": " import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context) except Exception: pass def _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if", "label": 0}, {"snippet_id": 68449, "code": " t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status", "label": 0}, {"snippet_id": 89867, "code": ": \"\"\"Validates this distribution against its configured constraints. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" if self._validated_binaries", "label": 0}, {"snippet_id": 47334, "code": ".check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present", "label": 0}, {"snippet_id": 39702, "code": " decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return", "label": 0}, {"snippet_id": 73987, "code": "\\\" or integer value\") if \"chunk_length\" in runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str", "label": 0}, {"snippet_id": 15498, "code": " SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest", "label": 0}, {"snippet_id": 34868, "code": ".dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(", "label": 0}, {"snippet_id": 32188, "code": ": try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as", "label": 0}, {"snippet_id": 59538, "code": " this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires", "label": 0}, {"snippet_id": 47896, "code": "._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other", "label": 0}, {"snippet_id": 8140, "code": ": tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return", "label": 0}, {"snippet_id": 10884, "code": " requests.exceptions import RequestException, ConnectionError, Timeout import requests import yaml from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, HostUnreachableException", "label": 0}, {"snippet_id": 72662, "code": "[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp", "label": 1}, {"snippet_id": 39315, "code": "(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func)", "label": 0}, {"snippet_id": 25502, "code": " this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get", "label": 0}, {"snippet_id": 37243, "code": " return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput)", "label": 0}, {"snippet_id": 80230, "code": "\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x", "label": 0}, {"snippet_id": 60881, "code": " exc_type, exc_value, tb): if self._observe is None: raise DeviceError('A qfunc must always conclude with a classical expectation value.') Device._current_context=None self.execute() @property def gates(self", "label": 0}, {"snippet_id": 81722, "code": "\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file\"}) \t\t\t\tif len(fileInputs) > 0: \t\t\t\t\treturnForms.append((f,fileInputs))", "label": 0}, {"snippet_id": 80901, "code": "\t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests", "label": 0}, {"snippet_id": 67092, "code": ".__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m:", "label": 0}, {"snippet_id": 35294, "code": " filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the", "label": 0}, {"snippet_id": 33620, "code": ".summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes", "label": 0}, {"snippet_id": 78060, "code": "'Appending %s:%s to forums[%s]', user, forum, domain) forums[domain].add((user, forum)) def rffu(urls): for user, domain, forum in r_udf.findall(urls): if len(forum) > 0: get_forum_id(forum) logger.info(", "label": 0}, {"snippet_id": 14124, "code": ": return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'", "label": 0}, {"snippet_id": 75433, "code": "(make_rep_msg(reqid, seqnum, status, answer)) return msg def get_iden(self, reqid): return self.iden_reqid_map.get_key(reqid) def get_reqids(self, iden): return self.iden_reqid_map.get_values(iden) def", "label": 0}, {"snippet_id": 43561, "code": " for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2", "label": 0}, {"snippet_id": 91701, "code": "(output_pytest_requirements_pex_filename,), ) requirements_pex_response=yield Get( ExecuteProcessResult, ExecuteProcessRequest, requirements_pex_request) source_roots=source_root_config.get_source_roots(", "label": 0}, {"snippet_id": 71941, "code": "\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf)", "label": 0}, {"snippet_id": 28998, "code": ">=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self", "label": 0}, {"snippet_id": 36455, "code": ".wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self", "label": 0}, {"snippet_id": 85587, "code": ".Products` :returns: A Zinc instance with access to relevant Zinc compiler wrapper jars and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self, products) def __init__(self, zinc_factory, products): self", "label": 0}, {"snippet_id": 1563, "code": " return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request", "label": 0}, {"snippet_id": 27603, "code": " self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium", "label": 0}, {"snippet_id": 17789, "code": ") def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data", "label": 0}, {"snippet_id": 82574, "code": ".proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print(\"[*] starting", "label": 0}, {"snippet_id": 61169, "code": " r\"\"\"Arbitrary one-qubit rotation using three Euler angles. Args: a,b,c(float): rotation angles Returns: array: unitary 2x2 rotation matrix rz(c) @ ry(b) @ rz(a) \"\"\" return frz(c) @(fry(b) @ frz(a)) def", "label": 0}, {"snippet_id": 49551, "code": " rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger", "label": 0}, {"snippet_id": 92478, "code": "(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd", "label": 0}, {"snippet_id": 94235, "code": " self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else", "label": 0}, {"snippet_id": 43285, "code": " wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards):", "label": 0}, {"snippet_id": 19602, "code": " nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget=True else: supported.append(arg", "label": 1}, {"snippet_id": 88591, "code": "\"Returns the output stream to write console messages to. :API: public \"\"\" return self._console_outstream @property def scm(self): \"\"\"Returns the current workspace's scm, if any. :API: public \"\"\" return", "label": 0}, {"snippet_id": 61181, "code": ") @ rz(a) \"\"\" return frz(c) @(fry(b) @ frz(a)) def ket(*args): r\"\"\"Input validation for an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised array. \"\"\" state=np.asarray(args", "label": 0}, {"snippet_id": 983, "code": " username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess", "label": 0}, {"snippet_id": 1682, "code": " output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username", "label": 0}, {"snippet_id": 8491, "code": " text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split", "label": 1}, {"snippet_id": 29632, "code": "\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic", "label": 0}, {"snippet_id": 59268, "code": " Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed", "label": 0}, {"snippet_id": 18783, "code": " extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for", "label": 0}, {"snippet_id": 66744, "code": " ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e:", "label": 1}, {"snippet_id": 66104, "code": " target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status", "label": 0}, {"snippet_id": 62407, "code": " to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend", "label": 0}, {"snippet_id": 79700, "code": " data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example:", "label": 0}, {"snippet_id": 66406, "code": " GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on ", "label": 0}, {"snippet_id": 14073, "code": " future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return", "label": 0}, {"snippet_id": 53267, "code": ") self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other", "label": 0}, {"snippet_id": 11883, "code": "(403) return True def check_pythonic_pr(data): \"\"\" Return True if the PR contains at least one Python file \"\"\" files=list(get_files_involved_in_pr(data).keys()) pythonic=False for file in files: if file", "label": 0}, {"snippet_id": 3417, "code": ") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif", "label": 0}, {"snippet_id": 31534, "code": "=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self", "label": 0}, {"snippet_id": 5377, "code": " spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), ", "label": 0}, {"snippet_id": 24042, "code": "=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*(//'| sed -e 's/).*//'\".format(output) err, output=shellutil.run_get_output(cmd_search_dev) if err==0: for", "label": 0}, {"snippet_id": 32453, "code": " params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies=", "label": 0}, {"snippet_id": 81710, "code": " \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor", "label": 0}, {"snippet_id": 52632, "code": ".benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return", "label": 0}, {"snippet_id": 28585, "code": " elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'", "label": 0}, {"snippet_id": 94854, "code": " args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center", "label": 0}, {"snippet_id": 47171, "code": "(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f", "label": 0}, {"snippet_id": 83138, "code": " with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information", "label": 0}, {"snippet_id": 52245, "code": " targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict)", "label": 0}, {"snippet_id": 86944, "code": " ' 'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if after ' 'running clean-all.') register('--incremental", "label": 0}, {"snippet_id": 15567, "code": "=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( ", "label": 0}, {"snippet_id": 66213, "code": "(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev", "label": 0}, {"snippet_id": 91235, "code": " IsortPrep from pants.backend.python.tasks.isort_run import IsortRun from pants.backend.python.tasks.local_python_distribution_artifact import \\ LocalPythonDistributionArtifact from pants.backend.python.tasks", "label": 0}, {"snippet_id": 78282, "code": "(exc.Closed, exc.UserDeny) as e: try: self.targets.remove(t) except ValueError: pass self.w.sleep(self.comment_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA')", "label": 0}, {"snippet_id": 6061, "code": " text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list", "label": 1}, {"snippet_id": 62170, "code": " in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del", "label": 0}, {"snippet_id": 75208, "code": ".response_handlers={} self.sig_handlers={} self.iden_reqid_map=BijectiveSetMap() def set_req_handler(self, interface, method, fun): self.req_handlers[(interface, method)]=fun def set_response_handler(self", "label": 0}, {"snippet_id": 39429, "code": " rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1])", "label": 0}, {"snippet_id": 69261, "code": " error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s", "label": 1}, {"snippet_id": 58260, "code": ".models import TestPlan from tcms.testruns.models import TestCaseRun from tcms.testruns.models import TestCaseRunStatus from tcms.tests import BaseCaseRun from tcms.tests import BasePlanCase from tcms.tests", "label": 0}, {"snippet_id": 37443, "code": ".temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output", "label": 0}, {"snippet_id": 63202, "code": " unstructured_path_rewrites={} if compute_environment: unstructured_path_rewrites=compute_environment.unstructured_path_rewrites client_job_description=ClientJobDescription( command_line=command_line, input_files=self", "label": 0}, {"snippet_id": 28318, "code": " setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION,", "label": 0}, {"snippet_id": 52779, "code": "*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for", "label": 0}, {"snippet_id": 16477, "code": "{} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None)", "label": 0}, {"snippet_id": 63772, "code": "\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode", "label": 0}, {"snippet_id": 37165, "code": ".temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch", "label": 0}, {"snippet_id": 52622, "code": " in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"", "label": 0}, {"snippet_id": 50311, "code": ".resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources", "label": 0}, {"snippet_id": 28512, "code": "\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=", "label": 0}, {"snippet_id": 7851, "code": " for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: set of formatted core keywords \"", "label": 0}, {"snippet_id": 37503, "code": ".subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\")", "label": 0}, {"snippet_id": 81605, "code": " uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog", "label": 0}, {"snippet_id": 53723, "code": " self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"", "label": 0}, {"snippet_id": 24845, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self", "label": 0}, {"snippet_id": 41586, "code": "\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input", "label": 0}, {"snippet_id": 42301, "code": " import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles", "label": 0}, {"snippet_id": 56698, "code": " Used for getting the chosen object(TestPlan, TestCase or TestRun) from the database \"\"\" def __init__(self, request): \"\"\" :param request: An HTTP GET request, containing the primary key and the type of", "label": 0}, {"snippet_id": 13376, "code": " params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file.encode()).decode(\"utf-8\") request_json={ \"path\": file, \"message\": \"Fix", "label": 0}, {"snippet_id": 47901, "code": "=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input", "label": 0}, {"snippet_id": 24935, "code": " elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" ", "label": 0}, {"snippet_id": 1918, "code": ".Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem,", "label": 0}, {"snippet_id": 85345, "code": " import Shader from pants.backend.jvm.targets.scala_jar_dependency import ScalaJarDependency from pants.backend.jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util", "label": 0}, {"snippet_id": 5237, "code": "=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}", "label": 0}, {"snippet_id": 8421, "code": " and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line", "label": 1}, {"snippet_id": 18462, "code": ".CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic:", "label": 0}, {"snippet_id": 57607, "code": "=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets().update(**{str(self.target_field): self.new_value})", "label": 0}, {"snippet_id": 16521, "code": " self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable(", "label": 0}, {"snippet_id": 31885, "code": " @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive", "label": 0}, {"snippet_id": 46107, "code": "): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional", "label": 0}, {"snippet_id": 62227, "code": "\"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map", "label": 1}, {"snippet_id": 82773, "code": " string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName) else: \tup=UploadForm", "label": 0}, {"snippet_id": 42745, "code": "._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output:", "label": 0}, {"snippet_id": 92557, "code": " test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the context.') self.assertTrue(os.path", "label": 0}, {"snippet_id": 973, "code": "': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess", "label": 0}, {"snippet_id": 14055, "code": ", 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future", "label": 0}, {"snippet_id": 56740, "code": " def get(self): func=getattr(self, self.object) return func() def plan(self): return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk) def case(self): return 'management/get_tag.html',", "label": 0}, {"snippet_id": 68053, "code": " <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return", "label": 0}, {"snippet_id": 3732, "code": "\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for p in r.stdout", "label": 0}, {"snippet_id": 33282, "code": "(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain", "label": 0}, {"snippet_id": 42809, "code": " be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance", "label": 0}, {"snippet_id": 78208, "code": "(targets) or targets) super().__init__(*args, **kvargs) def on_caprate_limit(self, rate): if not self.logined: self._capdata=(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now')", "label": 0}, {"snippet_id": 6310, "code": "(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\"", "label": 1}, {"snippet_id": 11876, "code": ") if not hmac.compare_digest(str(mac.hexdigest()), str(signature)): abort(403) return True def check_pythonic_pr(data): \"\"\" Return True if the PR contains at least one Python file \"\"\" files=list(get_files_involved_in_pr", "label": 0}, {"snippet_id": 1695, "code": "\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first(", "label": 0}, {"snippet_id": 35183, "code": " be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias", "label": 0}, {"snippet_id": 57765, "code": ") if sortkey < 0 or sortkey > 32300: return say_no('New sortkey is out of range[0, 32300].') except ValueError: return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request", "label": 0}, {"snippet_id": 83142, "code": " NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information. Defaulting to datatypes_conf", "label": 0}, {"snippet_id": 12559, "code": ", comment_body, comment_footer, ERROR def comment_permission_check(data, comment): \"\"\"Check for quite and resume status or duplicate comments\"\"\" PERMITTED_TO_COMMENT=True repository=data[\"repository\"] headers", "label": 0}, {"snippet_id": 80243, "code": "\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args", "label": 0}, {"snippet_id": 52253, "code": " self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None", "label": 0}, {"snippet_id": 20441, "code": ") with socket_timeout(server, timeout): client, _=server.accept() return Connection(client, server) return cls._create(connect, addr, **kwargs) @classmethod def _create(cls, connect, addr, timeout=None", "label": 0}, {"snippet_id": 8616, "code": " first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer)", "label": 0}, {"snippet_id": 74526, "code": "=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"", "label": 0}, {"snippet_id": 62357, "code": "=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because", "label": 0}, {"snippet_id": 88433, "code": ".build_file_parser=build_file_parser self.address_mapper=address_mapper self.run_tracker=run_tracker self._log=self.Log(run_tracker) self._target_base=target_base or Target self._products=Products() self", "label": 0}, {"snippet_id": 53514, "code": " input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def", "label": 0}, {"snippet_id": 89360, "code": " from pants.util.osutil import OS_ALIASES, normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version): if isinstance(version", "label": 0}, {"snippet_id": 24651, "code": " and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 56498, "code": " versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters=['app_form', 'format", "label": 1}, {"snippet_id": 79255, "code": ".append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the", "label": 0}, {"snippet_id": 33983, "code": " workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self,", "label": 0}, {"snippet_id": 43393, "code": "(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards", "label": 0}, {"snippet_id": 30792, "code": " try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 42367, "code": "._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input", "label": 0}, {"snippet_id": 71281, "code": ".has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet", "label": 0}, {"snippet_id": 75610, "code": ".running is cleared''' def __init__(self): super().__init__('Worker was interrupted at runtime') class Suspend(Exception): '''Exception to raise on suspend signal''' def __init__(self, interval, *args,", "label": 0}, {"snippet_id": 12904, "code": ".decode(r.encoding) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{", "label": 0}, {"snippet_id": 8220, "code": " a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2", "label": 1}, {"snippet_id": 16720, "code": " logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self", "label": 0}, {"snippet_id": 90202, "code": "(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable.", "label": 0}, {"snippet_id": 1159, "code": ": queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class=RegisteredServicesSerializer", "label": 0}, {"snippet_id": 96058, "code": "\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path", "label": 1}, {"snippet_id": 72724, "code": ".read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def", "label": 0}, {"snippet_id": 94359, "code": "=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell=True)==0: return True else: return False def check_component", "label": 0}, {"snippet_id": 53924, "code": " TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"", "label": 0}, {"snippet_id": 42940, "code": "(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError:", "label": 0}, {"snippet_id": 94620, "code": " cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\"", "label": 0}, {"snippet_id": 87247, "code": "(target, ScalacPlugin): self._write_scalac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target) elif", "label": 0}, {"snippet_id": 87833, "code": ".{} is not.'.format(path)) def log_zinc_file(self, analysis_file): self.context.log.debug('Calling zinc on:{}({})' .format(analysis_file, hash_file(analysis_file).upper() if os.path.exists(analysis_file", "label": 0}, {"snippet_id": 31722, "code": "(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp", "label": 1}, {"snippet_id": 45191, "code": "=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None", "label": 0}, {"snippet_id": 44379, "code": " missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn", "label": 0}, {"snippet_id": 77799, "code": "(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self.log=parent.log self.inter_sleep=parent.inter_sleep self.running=parent.running self.p.sig_sock.setsockopt(zmq.SUBSCRIBE", "label": 0}, {"snippet_id": 88698, "code": "(target_count) return target_count def submit_background_work_chain(self, work_chain, parent_workunit_name=None): \"\"\" :API: public \"\"\" background_root_workunit=self.run_tracker.get_background_root_workunit(", "label": 0}, {"snippet_id": 75036, "code": " EvaluatorProxy: def __init__(self, ev_init, *args, **kvargs): super().__init__() self.ev_init=ev_init self.bind_kt_ticker=Ticker() self.bind_kt=5 def handle_evaluate(self, reqid, interface, method, data): domain,", "label": 0}, {"snippet_id": 66878, "code": " worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker)", "label": 0}, {"snippet_id": 51218, "code": "(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start", "label": 0}, {"snippet_id": 90611, "code": " required to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" def _get_stricter_version(a, b,", "label": 0}, {"snippet_id": 76331, "code": " send_error_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.error, data) def send_wz_error(self, reqid, data, seqid=0): msg=self.wz.make_dealer_rep_msg( reqid, seqid, wzrpc.status.error, data) self", "label": 0}, {"snippet_id": 71438, "code": "\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import", "label": 0}, {"snippet_id": 58843, "code": ", {'app_form': 'testcases.CaseAutomatedForm'}) form=CaseAutomatedForm() self.assertHTMLEqual(str(response.content, encoding=settings.DEFAULT_CHARSET), form.as_p()) class TestUpdateCasePriority(BasePlanCase", "label": 1}, {"snippet_id": 3829, "code": "-a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if", "label": 0}, {"snippet_id": 20227, "code": " waiting for connection') if self._session is None: message='unable to connect after{} secs'.format( self._connecttimeout) if self._run_server_ex is None: raise Exception(message) else: message=message +os", "label": 0}, {"snippet_id": 294, "code": "): \"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name", "label": 0}, {"snippet_id": 35099, "code": " fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable", "label": 0}, {"snippet_id": 23133, "code": ". :param chk_err: Whether or not to check for errors raised by the eject command \"\"\" logger.warn(\"Eject is not supported on this platform\") def get_first_if(self): \"\"\"Return the interface name, and ip addr", "label": 0}, {"snippet_id": 53626, "code": " _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the", "label": 0}, {"snippet_id": 72889, "code": " str \"\"\" if ftp_config.enabled: create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP", "label": 0}, {"snippet_id": 65818, "code": ", fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=", "label": 0}, {"snippet_id": 31782, "code": ".clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch", "label": 0}, {"snippet_id": 4798, "code": ":keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style", "label": 0}, {"snippet_id": 24241, "code": "], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle'", "label": 0}, {"snippet_id": 32856, "code": " overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir", "label": 0}, {"snippet_id": 4411, "code": " -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext", "label": 0}, {"snippet_id": 23597, "code": " net, mask, gateway): cmd='route add{0}{1}{2}'.format(net, gateway, mask) return shellutil.run(cmd, chk_err=False) def is_missing_default_route(self): \"\"\" For FreeBSD, the default broadcast goes to current", "label": 0}, {"snippet_id": 70255, "code": " target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(),", "label": 0}, {"snippet_id": 20961, "code": " _receive_message(self, msg): for i, handler in enumerate(list(self._handlers)): handle_message, _, _=handler handled=handle_message(msg) try: msg, handled=handled except TypeError: pass if handled: self", "label": 0}, {"snippet_id": 4496, "code": "\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={", "label": 0}, {"snippet_id": 47127, "code": " expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set(", "label": 1}, {"snippet_id": 85131, "code": "'scalac', products) def style_classpath(self, products): return self._tool_classpath('scalastyle', products) @property def version(self): return self.get_options().version def suffix_version(self, name", "label": 0}, {"snippet_id": 11028, "code": " response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime.strptime(mtime, '%a", "label": 1}, {"snippet_id": 69754, "code": " Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client)", "label": 0}, {"snippet_id": 67645, "code": "(node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self", "label": 0}, {"snippet_id": 15192, "code": " SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False", "label": 0}, {"snippet_id": 59875, "code": ",val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires,", "label": 0}, {"snippet_id": 19467, "code": ".executable)) else: prog=argv[0] argv=argv[1:] supported, pydevd, script=_group_args(argv) args=_parse_args(prog, supported) extra=pydevd +['--'] if script: extra +=script return args, extra def _group_args(argv", "label": 0}, {"snippet_id": 32265, "code": " name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards", "label": 0}, {"snippet_id": 36866, "code": "}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or", "label": 0}, {"snippet_id": 94698, "code": "=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help", "label": 0}, {"snippet_id": 36632, "code": "=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule", "label": 0}, {"snippet_id": 92016, "code": " type_constraint, target_predicate in self._native_target_matchers.items(): if type_constraint.satisfied_by(tgt) and target_predicate(tgt): return True return False def check_build_for_current_platform_only(self", "label": 0}, {"snippet_id": 8162, "code": ") return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field)", "label": 0}, {"snippet_id": 60786, "code": "\"Exception raised by a:class:`Device` when it encounters an illegal operation in the quantum circuit. \"\"\" pass class Device(abc.ABC): \"\"\"Abstract base class for devices.\"\"\" _current_context=None name=''", "label": 0}, {"snippet_id": 94430, "code": " child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process", "label": 1}, {"snippet_id": 6064, "code": "=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read", "label": 1}, {"snippet_id": 45228, "code": ".name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs", "label": 0}, {"snippet_id": 33727, "code": " nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources", "label": 0}, {"snippet_id": 12708, "code": " in comments: if old_comment[\"user\"][\"id\"]==24736507: last_comment_id=old_comment[\"id\"] break if last_comment_id is None: response=requests.post(query, json={\"body\": comment}, headers=headers, auth=auth)", "label": 0}, {"snippet_id": 60357, "code": " operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](", "label": 0}, {"snippet_id": 90064, "code": "} for line in stdout.decode('utf-8').split(os.linesep): key, _, val=line.partition('=') props[key]=val self._system_properties=props return self._system_properties def _validate_executable(self, name):", "label": 0}, {"snippet_id": 15690, "code": ": if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0", "label": 0}, {"snippet_id": 9854, "code": ": str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace", "label": 0}, {"snippet_id": 29222, "code": "(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken", "label": 0}, {"snippet_id": 62601, "code": " expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator", "label": 0}, {"snippet_id": 94144, "code": "-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting", "label": 0}, {"snippet_id": 86825, "code": ": return('-C-encoding', '-CUTF-8', '-S-encoding', '-SUTF-8', '-S-g:vars') @classmethod def get_warning_args_default(cls): return('-C-deprecation', '-C-Xlint:all', '-C-Xlint:-serial', '-C-Xlint:-path', ", "label": 0}, {"snippet_id": 62984, "code": " directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information. Defaulting to datatypes_conf", "label": 0}, {"snippet_id": 30093, "code": " getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider", "label": 0}, {"snippet_id": 90002, "code": " _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open(os.path.join(classpath, 'SystemProperties.class'), 'w+b') as fp: fp.write(pkgutil.get_data(__name__, ", "label": 0}, {"snippet_id": 20611, "code": ") def __init__(self, conn, seq=1000, handlers=(), timeout=None, owned=False): super(DebugSession, self).__init__() self._conn=conn self._seq=seq self._timeout=timeout self._owned=owned self._handlers=[", "label": 0}, {"snippet_id": 89128, "code": "=defaultdict(set) for target in self.targets(from_predicate): for dependency in target.dependencies: if dependency in core: dependees[target].add(dependency) return dependees def resolve(self, spec): \"\"", "label": 0}, {"snippet_id": 16318, "code": "'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join(", "label": 0}, {"snippet_id": 83733, "code": ") completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper", "label": 0}, {"snippet_id": 7171, "code": " author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left", "label": 0}, {"snippet_id": 58248, "code": ".testcases.forms import CaseAutomatedForm from tcms.testcases.forms import TestCase from tcms.testplans.models import TestPlan from tcms.testruns.models import TestCaseRun from tcms.testruns.models import", "label": 1}, {"snippet_id": 8367, "code": "(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream", "label": 0}, {"snippet_id": 93219, "code": " DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[]", "label": 0}, {"snippet_id": 75671, "code": ").__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests=[] self.wz_bind_methods=[] self", "label": 1}, {"snippet_id": 45130, "code": " return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs,", "label": 0}, {"snippet_id": 86808, "code": " get_jvm_options_default(cls, bootstrap_option_values): return('-Dfile.encoding=UTF-8', '-Dzinc.analysis.cache.limit=1000', '-Djava.awt.headless=true', '-Xmx2g') @classmethod def get_args_default(cls, bootstrap_option_values", "label": 0}, {"snippet_id": 79816, "code": "\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\")", "label": 0}, {"snippet_id": 72247, "code": " world.services: irc.error('Unknown service %r.' % args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply", "label": 0}, {"snippet_id": 90333, "code": " plist_results: home=distribution['JVMHomePath'] yield self.Location.from_home(home) except subprocess.CalledProcessError: pass class _LinuxEnvironment(_DistributionEnvironment): _STANDARD_JAVA_DIST_DIRS", "label": 0}, {"snippet_id": 55543, "code": "(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\")", "label": 0}, {"snippet_id": 2654, "code": "\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference", "label": 0}, {"snippet_id": 84351, "code": ".integrated_datatypes_configs job_wrapper.extra_filenames.append(integrates_datatypes_config) metadata_kwds['datatypes_config']=os.path.join(configs_directory, os.path.basename(integrates_datatypes_config)) return", "label": 0}, {"snippet_id": 23652, "code": " allow_dhcp_broadcast(self): pass def set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def remove_route_for_dhcp_broadcast", "label": 0}, {"snippet_id": 32381, "code": "(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start", "label": 0}, {"snippet_id": 60767, "code": " first parameter, along with any additional parameters.\"\"\" return cls(name, *args, **kwargs) return new_object class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an", "label": 0}, {"snippet_id": 26600, "code": "'battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif", "label": 0}, {"snippet_id": 22518, "code": " Normally, tmsh is used to set the hostname for the system. For our purposes at this time though, I would hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM", "label": 0}, {"snippet_id": 80820, "code": "=templatesData[a[\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex", "label": 1}, {"snippet_id": 55835, "code": ": ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, ", "label": 0}, {"snippet_id": 19529, "code": " +1] except IndexError: nextarg=None if gottarget: script=argv[i:] +script break if arg=='--client': arg='--host' elif arg=='--file': if nextarg is None: pydevd.append(arg) continue if nextarg.endswith", "label": 0}, {"snippet_id": 3059, "code": " comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list", "label": 1}, {"snippet_id": 80228, "code": ".template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates", "label": 0}, {"snippet_id": 11893, "code": " Python file \"\"\" files=list(get_files_involved_in_pr(data).keys()) pythonic=False for file in files: if file[-3:]=='.py': pythonic=True break return pythonic def get_config(data): \"\"\" Get.pep8speaks.yml", "label": 0}, {"snippet_id": 53673, "code": " if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected", "label": 0}, {"snippet_id": 52669, "code": " is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output", "label": 0}, {"snippet_id": 5352, "code": " keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches:", "label": 0}, {"snippet_id": 75605, "code": "(Exception): '''Exception to raise when self.running is cleared''' def __init__(self): super().__init__('Worker was interrupted at runtime') class Suspend(Exception): '''Exception to raise on suspend signal''", "label": 0}, {"snippet_id": 75083, "code": " def send_keepalive(self): msg=self.p.wz.make_req_msg(b'Router', b'bind-keepalive',[], self.handle_keepalive_reply) msg.insert(0, b'') self.p.wz_sock.send_multipart(msg) def handle_keepalive_reply(self,", "label": 0}, {"snippet_id": 93167, "code": " time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M", "label": 0}, {"snippet_id": 21540, "code": " Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt: That was: %s\" % link) if x==0: seen_links.append(link) save_links.remove(link) elif x==1024:", "label": 1}, {"snippet_id": 63513, "code": " job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key", "label": 0}, {"snippet_id": 59835, "code": " -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value", "label": 0}, {"snippet_id": 5908, "code": " raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error", "label": 0}, {"snippet_id": 18422, "code": ") def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self", "label": 0}, {"snippet_id": 50642, "code": "._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile", "label": 0}, {"snippet_id": 76542, "code": ".Thread.start(self, *args, **kvargs) class WZWorkerProcess(WZWorkerBase, multiprocessing.Process): def start(self, sig_addr, *args, **kvargs): self.sig_addr=sig_addr multiprocessing.Process.start(self, ", "label": 0}, {"snippet_id": 79610, "code": " coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates", "label": 0}, {"snippet_id": 81958, "code": "\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the", "label": 0}, {"snippet_id": 24123, "code": " timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN)", "label": 1}, {"snippet_id": 93026, "code": " stdin_fd=-1): self.assertEqual('', sys.stdin.read()) print('garbage', file=sys.stdout) print('garbage', file=sys.stderr) def test_signal_handler_as(self): mock_initial_handler=1 mock_new_handler=2 with", "label": 0}, {"snippet_id": 65902, "code": " len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0:", "label": 0}, {"snippet_id": 81276, "code": ".name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:(filename,fd,mime)},data=self.postData) \t", "label": 1}, {"snippet_id": 34183, "code": ": ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, ", "label": 0}, {"snippet_id": 87544, "code": " option_set, disabled_args in self.get_options().compiler_option_sets_disabled_args.items(): if option_set not in compiler_option_sets: if option_set=='fatal_warnings': disabled_args=self.get_options()", "label": 0}, {"snippet_id": 61562, "code": " representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)) if not callable(operator_map[A.name]): return operator_map[A.name] p=[x.val", "label": 0}, {"snippet_id": 65622, "code": "(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15", "label": 0}, {"snippet_id": 75385, "code": ", args, reqid) self.set_response_handler(reqid, fun) return msg def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface", "label": 0}, {"snippet_id": 62332, "code": "\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"", "label": 0}, {"snippet_id": 59144, "code": " classical operations. -projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI", "label": 0}, {"snippet_id": 86446, "code": " from hashlib import sha1 from xml.etree import ElementTree from future.utils import PY3, text_type from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import", "label": 1}, {"snippet_id": 39274, "code": ", snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack", "label": 0}, {"snippet_id": 19415, "code": "--save-asyncio', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT -m MODULE[arg...] {0}[-h][-V][--nodebug][--host HOST | --server-host HOST", "label": 0}, {"snippet_id": 22796, "code": " we can't rely on this value. :param username: The username whose password to change :param password: The unencrypted password to set for the user :param crypt_id: If encrypting the password, the crypt_id", "label": 0}, {"snippet_id": 49921, "code": ", cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet,", "label": 0}, {"snippet_id": 92586, "code": "(fp.name) def test_temporary_file_within_other_dir(self): with temporary_dir() as path: with temporary_file(root_dir=path) as f: self.assertTrue(os.path.realpath(f.name).startswith(os.path.realpath(path", "label": 0}, {"snippet_id": 10485, "code": " text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import", "label": 1}, {"snippet_id": 30115, "code": " the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict", "label": 0}, {"snippet_id": 63768, "code": " already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID", "label": 0}, {"snippet_id": 15674, "code": "'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive", "label": 0}, {"snippet_id": 38310, "code": ".abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows", "label": 0}, {"snippet_id": 74218, "code": " benchmark_data_input_temp=runtime_config.benchmark[\"benchmark_data_input\"] if benchmark_data_input_temp in benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in", "label": 0}, {"snippet_id": 16908, "code": " timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC)", "label": 0}, {"snippet_id": 35073, "code": " format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return", "label": 0}, {"snippet_id": 22289, "code": " import DefaultOSUtil except ImportError: import azurelinuxagent.logger as logger import azurelinuxagent.utils.shellutil as shellutil from azurelinuxagent.exception import OSUtilError from azurelinuxagent", "label": 0}, {"snippet_id": 59607, "code": ".reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend=", "label": 0}, {"snippet_id": 53834, "code": ".append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError", "label": 0}, {"snippet_id": 6598, "code": " api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file)", "label": 1}, {"snippet_id": 18786, "code": ") def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data", "label": 0}, {"snippet_id": 54607, "code": "(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard", "label": 0}, {"snippet_id": 45019, "code": " *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths", "label": 0}, {"snippet_id": 77508, "code": ".evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount, (ev_init,)) def load_users(self): if not os.path.isfile(self.usersfile): return with", "label": 0}, {"snippet_id": 5308, "code": ": str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace", "label": 0}, {"snippet_id": 86347, "code": " plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin:{}{", "label": 0}, {"snippet_id": 19474, "code": " script=_group_args(argv) args=_parse_args(prog, supported) extra=pydevd +['--'] if script: extra +=script return args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index(", "label": 0}, {"snippet_id": 29920, "code": "): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value)", "label": 0}, {"snippet_id": 64542, "code": ": \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self", "label": 0}, {"snippet_id": 75510, "code": " method, reqid, key)] return(b'Router', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface", "label": 0}, {"snippet_id": 48996, "code": " __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain", "label": 0}, {"snippet_id": 21761, "code": ") X=dataset.iloc[:, 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X[:, 1]=labelencoder_X_1.fit_transform(X[:, 1", "label": 1}, {"snippet_id": 90966, "code": ") register('--paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables", "label": 0}, {"snippet_id": 5729, "code": " lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) ", "label": 0}, {"snippet_id": 45079, "code": "(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, ", "label": 0}, {"snippet_id": 31162, "code": ". \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))", "label": 0}, {"snippet_id": 12928, "code": "]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON[\"public\"]=True REQUEST_JSON", "label": 0}, {"snippet_id": 49463, "code": " None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files:", "label": 0}, {"snippet_id": 20825, "code": ") def _get_awaiter_for_request(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req[", "label": 0}, {"snippet_id": 20210, "code": "=new_hidden_thread( target=run, name='test.client', ) t.start() def wait(): t.join(timeout=self._connecttimeout) if t.is_alive(): warnings.warn('timed out waiting for connection') if self._session is None", "label": 0}, {"snippet_id": 37985, "code": "=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary", "label": 0}, {"snippet_id": 61914, "code": " IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions -----", "label": 0}, {"snippet_id": 36889, "code": " import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards", "label": 0}, {"snippet_id": 41141, "code": " item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name", "label": 0}, {"snippet_id": 63186, "code": " remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if not command_line: return try: dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper", "label": 0}, {"snippet_id": 42351, "code": "(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict", "label": 0}, {"snippet_id": 83660, "code": "=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app", "label": 0}, {"snippet_id": 913, "code": ":userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout", "label": 0}, {"snippet_id": 77370, "code": " self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}): wname", "label": 0}, {"snippet_id": 74818, "code": " isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types: self.blosc_shuffle_mode=blosc_shuffle_mode_int else: raise", "label": 0}, {"snippet_id": 77468, "code": "}'.format(i)))) self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads(self): return self.spawn_nworkers", "label": 0}, {"snippet_id": 50100, "code": ", snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack", "label": 0}, {"snippet_id": 39065, "code": " list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed", "label": 0}, {"snippet_id": 58522, "code": "'comment': 'new comment', 'run': '99999998,1009900'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No caserun found.'}) def test_add_comment_to_case_runs", "label": 0}, {"snippet_id": 46005, "code": " or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary", "label": 0}, {"snippet_id": 2516, "code": " with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp", "label": 0}, {"snippet_id": 20555, "code": ") def _close(self): if self._ownsock: close(self._sock) class DebugSession(Closeable): VERBOSE=False HOST='localhost' PORT=8888 TIMEOUT=None @classmethod def create_client(cls, addr=None, **kwargs): if", "label": 0}, {"snippet_id": 51361, "code": "(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value", "label": 0}, {"snippet_id": 21323, "code": "--depth', metavar='d', type=int, default=0, help='How many pages into the subreddit you want to go.') parser.add_argument('subreddit', type=str, help='The subreddit you want to play.') parser.add_argument", "label": 0}, {"snippet_id": 56354, "code": " if request.GET.get('format')=='ulli': field=request.GET.get('field', default='name') response_str='<ul>' for obj_value in info_type().values(field): response_str +='<li>' +obj_value.get(field, None) +", "label": 0}, {"snippet_id": 42930, "code": " output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item", "label": 0}, {"snippet_id": 42023, "code": " _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources", "label": 0}, {"snippet_id": 73203, "code": ". Additionally moves *.vcf files to output_dir Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing", "label": 0}, {"snippet_id": 70053, "code": " from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine", "label": 0}, {"snippet_id": 74691, "code": ".vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise", "label": 0}, {"snippet_id": 11030, "code": " else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y", "label": 1}, {"snippet_id": 3100, "code": "): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost", "label": 0}, {"snippet_id": 36186, "code": " need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return", "label": 0}, {"snippet_id": 30933, "code": " for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f", "label": 0}, {"snippet_id": 17800, "code": " expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript", "label": 0}, {"snippet_id": 58646, "code": " remove_perm_from_user(self.tester, self.permission) post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False', 'value_type': 'bool' } response=self.client.post", "label": 0}, {"snippet_id": 91045, "code": "._normalized_jdk_paths @memoized_method def _locator(self): return self._create_locator() @memoized_property def _normalized_jdk_paths(self): normalized={} jdk_paths=self.get_options().paths or{} for name, paths in", "label": 0}, {"snippet_id": 66350, "code": "\n \"\"\" Shine `umount' command classes. The umount command aims to stop Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals", "label": 0}, {"snippet_id": 19264, "code": ".NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.file.seek(0) with open(tmp_file.name) as json_file: result=load_source(json_file) assert result==native def test_json_file_path(): native={'foo': 'bar'}", "label": 0}, {"snippet_id": 24786, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self", "label": 0}, {"snippet_id": 55182, "code": " workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)]", "label": 0}, {"snippet_id": 75119, "code": "=wzrpc.status.e_req_denied: self.p.log.warn('Keepalive status{0}, reauthentificating and rebinding'. format(wzrpc.name_status(status))) self.p.auth_requests() self.p.bind_methods() elif status==wzrpc.status", "label": 0}, {"snippet_id": 82766, "code": "\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args", "label": 0}, {"snippet_id": 64436, "code": "\"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==", "label": 0}, {"snippet_id": 24061, "code": ".run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible cmd_search_storvsc=\"camcontrol devlist -b | grep storvsc{0} | awk '", "label": 0}, {"snippet_id": 43040, "code": "(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item,", "label": 0}, {"snippet_id": 21413, "code": " open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt", "label": 0}, {"snippet_id": 64789, "code": " RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for", "label": 0}, {"snippet_id": 64479, "code": " args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif", "label": 0}, {"snippet_id": 48403, "code": ".items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else", "label": 0}, {"snippet_id": 25546, "code": "['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type", "label": 0}, {"snippet_id": 29353, "code": ".\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file", "label": 0}, {"snippet_id": 47044, "code": " ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd", "label": 0}, {"snippet_id": 18326, "code": "=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port", "label": 0}, {"snippet_id": 47357, "code": ".rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove", "label": 0}, {"snippet_id": 89546, "code": " \"\"\" if home_path and not os.path.isdir(home_path): raise ValueError('The specified java home path is invalid:{}'.format(home_path)) if bin_path and not os.path.isdir(bin_path): raise ValueError('The specified", "label": 0}, {"snippet_id": 34566, "code": ") def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file", "label": 0}, {"snippet_id": 60074, "code": ".ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities", "label": 0}, {"snippet_id": 36532, "code": " unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for", "label": 0}, {"snippet_id": 76036, "code": ", wzauth_data.request[i, m])) def bind_route(self, i, m, f): self.log.debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler", "label": 0}, {"snippet_id": 5447, "code": "=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires", "label": 0}, {"snippet_id": 41391, "code": " listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type)", "label": 0}, {"snippet_id": 56767, "code": ".get(pk=self.object_pk) def run(self): return 'run/get_tag.html', TestRun.objects.get(pk=self.object_pk) class _TagActions(object): \"\"\" Used for performing the 'add' and 'remove' actions on a given tag ", "label": 0}, {"snippet_id": 61014, "code": "\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian projectors such that:math:`A=\\sum_k", "label": 0}, {"snippet_id": 71540, "code": " else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\"", "label": 0}, {"snippet_id": 66095, "code": "(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif", "label": 0}, {"snippet_id": 9793, "code": "\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output", "label": 0}, {"snippet_id": 72152, "code": " return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument('network') remote_parser.add_argument('--service', type=str, default='pylink", "label": 0}, {"snippet_id": 83349, "code": ": return try: dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters( client) unstructured_path_rewrites={} if compute_environment", "label": 0}, {"snippet_id": 43713, "code": "=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self", "label": 0}, {"snippet_id": 82620, "code": " args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions", "label": 0}, {"snippet_id": 59028, "code": ".property_django) def test_get_env_properties(self): response=self.client.get(self.get_info_url,{'info_type': 'env_properties'}) expected_json=json.loads( serializers.serialize( 'json', EnvProperty.objects.all(", "label": 0}, {"snippet_id": 64493, "code": " new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException", "label": 0}, {"snippet_id": 25480, "code": " device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement", "label": 0}, {"snippet_id": 5262, "code": "(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches:", "label": 0}, {"snippet_id": 5330, "code": ".replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"", "label": 0}, {"snippet_id": 30228, "code": " defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name", "label": 0}, {"snippet_id": 3275, "code": " color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode", "label": 0}, {"snippet_id": 1603, "code": "(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username", "label": 0}, {"snippet_id": 64265, "code": ".remote_version_path_rewrite(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path def output_paths( self): local_output_paths=self._wrapper_output_paths results=[]", "label": 0}, {"snippet_id": 60685, "code": " self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self._observe.params) elif self._observe.name=", "label": 0}, {"snippet_id": 69314, "code": " Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action,", "label": 0}, {"snippet_id": 45957, "code": ", flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value", "label": 0}, {"snippet_id": 60595, "code": ".state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng", "label": 1}, {"snippet_id": 94051, "code": " color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and ", "label": 0}, {"snippet_id": 47271, "code": " requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f", "label": 0}, {"snippet_id": 5473, "code": " else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict", "label": 0}, {"snippet_id": 15338, "code": " utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr'", "label": 0}, {"snippet_id": 49834, "code": "() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary", "label": 0}, {"snippet_id": 2691, "code": "): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile", "label": 0}, {"snippet_id": 29618, "code": "})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 11132, "code": "(self.mtime, other.mtime) > 0 else: return False def serialize(self): lines=[] time_string=strftime(\"%Y-%m-%d %H:%M:%S\", localtime()) lines.append(\"%s on %s\" %(Header.MON_CONF_GEN_COMMENT, time_string)) if", "label": 0}, {"snippet_id": 40375, "code": ")) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os", "label": 0}, {"snippet_id": 64163, "code": "', default_config_file) metadata_kwds['dataset_files_path']=remote_system_properties.get('galaxy_dataset_files_path', None) if LwrJobRunner.__use_remote_datatypes_conf( client): remote_datatypes_config", "label": 0}, {"snippet_id": 46093, "code": " for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand", "label": 0}, {"snippet_id": 63903, "code": ") job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown()", "label": 0}, {"snippet_id": 76464, "code": ": self.log.warn(e) def run(self): self.__sinit__() if self.start_timer: self.inter_sleep(self.start_timer) if self.running: self.log.info('Starting') try: self.child=self.call[0](*self.call[1], **self.call", "label": 0}, {"snippet_id": 35978, "code": " listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type)", "label": 0}, {"snippet_id": 42846, "code": " \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be", "label": 0}, {"snippet_id": 47030, "code": "\"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 32387, "code": " in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None", "label": 0}, {"snippet_id": 91875, "code": " PythonDistribution from pants.base.exceptions import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util", "label": 0}, {"snippet_id": 59642, "code": "\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend", "label": 0}, {"snippet_id": 73058, "code": " local folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp", "label": 0}, {"snippet_id": 18702, "code": " BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format(", "label": 0}, {"snippet_id": 39086, "code": " print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync", "label": 0}, {"snippet_id": 7238, "code": ", categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches", "label": 0}, {"snippet_id": 44748, "code": ") def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir", "label": 0}, {"snippet_id": 62716, "code": " Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate", "label": 0}, {"snippet_id": 75837, "code": ".insert(0, b'') s.send_multipart(msg) t.tick() while self.running.is_set(): p(timeout*1000) if rs.finished: if rs.retry: msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0,", "label": 0}, {"snippet_id": 23926, "code": ")[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if port_id > 3", "label": 0}, {"snippet_id": 34286, "code": " return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 75469, "code": " return reqid def make_auth_req_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router", "label": 0}, {"snippet_id": 2021, "code": ")) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False", "label": 0}, {"snippet_id": 29874, "code": "*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values", "label": 0}, {"snippet_id": 1610, "code": ",wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output=", "label": 0}, {"snippet_id": 9238, "code": " declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,", "label": 0}, {"snippet_id": 28142, "code": " homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600)", "label": 1}, {"snippet_id": 94826, "code": "'validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger", "label": 0}, {"snippet_id": 3292, "code": " kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if", "label": 0}, {"snippet_id": 44495, "code": "(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster,", "label": 0}, {"snippet_id": 47932, "code": " input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try:", "label": 0}, {"snippet_id": 28778, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self", "label": 0}, {"snippet_id": 3803, "code": "(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" ", "label": 0}, {"snippet_id": 94396, "code": "' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children", "label": 0}, {"snippet_id": 12151, "code": " return files def get_python_files_involved_in_pr(data): files=get_files_involved_in_pr(data) for file in list(files.keys()): if file[-3:] !=\".py\": del files[file] return files def run_pycodestyle(data,", "label": 0}, {"snippet_id": 68399, "code": ") elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target", "label": 0}, {"snippet_id": 17095, "code": " _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except", "label": 1}, {"snippet_id": 79747, "code": "=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies", "label": 0}, {"snippet_id": 4450, "code": " only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader", "label": 0}, {"snippet_id": 15201, "code": " import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT", "label": 0}, {"snippet_id": 43226, "code": "( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException(", "label": 0}, {"snippet_id": 78344, "code": ".errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t, msg)) self.w.sleep(self.errortimeout) except exc.PermanentError as e: try: self.targets.remove(t) except ValueError as e: pass self", "label": 0}, {"snippet_id": 41793, "code": ".mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime", "label": 0}, {"snippet_id": 36034, "code": "=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule", "label": 0}, {"snippet_id": 89464, "code": "\"\" class Error(Exception): \"\"\"Indicates an invalid java distribution.\"\"\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None", "label": 0}, {"snippet_id": 2987, "code": "\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window:", "label": 0}, {"snippet_id": 22580, "code": " running though, tmsh will reject that value because it is not a fully qualified domain name. The proper value should have been bigip.xxx.yyy WAAgent will not fail if this command fails, but the hostname will", "label": 0}, {"snippet_id": 2116, "code": ".split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}]", "label": 0}, {"snippet_id": 31193, "code": " the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self", "label": 0}, {"snippet_id": 90543, "code": " and dist.version > maximum_version: continue if jdk and not dist.jdk: continue return dist def locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets", "label": 0}, {"snippet_id": 14722, "code": "._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes", "label": 0}, {"snippet_id": 58230, "code": " import Comment from tcms.management.models import Priority from tcms.management.models import EnvGroup from tcms.management.models import EnvProperty from tcms.testcases.forms import CaseAutomatedForm", "label": 1}, {"snippet_id": 43318, "code": " _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log", "label": 0}, {"snippet_id": 69872, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None,", "label": 0}, {"snippet_id": 64988, "code": " Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1", "label": 0}, {"snippet_id": 74946, "code": ") if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config", "label": 1}, {"snippet_id": 19186, "code": " except ValidationError as err: errors['request'].add_error(err.messages or getattr(err, 'detail')) return response=normalize_response(raw_response, raw_request) try: validate_response( response=response,", "label": 0}, {"snippet_id": 37608, "code": "._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log", "label": 0}, {"snippet_id": 22441, "code": " sys config on 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err=False) def stop_agent_service(self): return shellutil.run(\"/sbin/service", "label": 0}, {"snippet_id": 4676, "code": " extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw", "label": 0}, {"snippet_id": 65334, "code": ".get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) if hasattr(eh, 'post'): eh", "label": 0}, {"snippet_id": 39381, "code": ".overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows", "label": 0}, {"snippet_id": 74068, "code": ".blosc_compression_algorithm=blosc_compression_algorithm_temp if \"blosc_compression_level\" in runtime_config.vcf_to_zarr: blosc_compression_level_str=runtime_config.vcf_to_zarr[\"blosc_compression_level\"", "label": 0}, {"snippet_id": 49282, "code": ".first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by", "label": 0}, {"snippet_id": 16766, "code": "( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path", "label": 0}, {"snippet_id": 712, "code": " row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append", "label": 0}, {"snippet_id": 83159, "code": " datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None,", "label": 0}, {"snippet_id": 22494, "code": "/chkconfig --del waagent\", chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"/sbin/pidof dhclient\") return ret[1] if ret[0]==0 else None def set_hostname(self, hostname): \"\"\"Set the static", "label": 0}, {"snippet_id": 21984, "code": " self.inventory=inventory self.listhosts=listhosts self.subset=subset self.module_paths=module_paths self.extra_vars=extra_vars self.forks=forks self.ask_vault_pass=ask_vault_pass self.vault_password_files", "label": 0}, {"snippet_id": 84585, "code": " super(CountLinesOfCode, cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register): super(CountLinesOfCode, cls).register_options(register) register('--transitive', type", "label": 0}, {"snippet_id": 7017, "code": " output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also strip", "label": 0}, {"snippet_id": 86685, "code": "\".format(arg)) return 1 arg_index=0 while arg_index < len(args): arg_index +=validate(arg_index) @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the", "label": 0}, {"snippet_id": 29425, "code": " return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return", "label": 0}, {"snippet_id": 4497, "code": ".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={}", "label": 0}, {"snippet_id": 65662, "code": " self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print ", "label": 1}, {"snippet_id": 13784, "code": "[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01", "label": 0}, {"snippet_id": 15873, "code": "': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True", "label": 0}, {"snippet_id": 10823, "code": "=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file", "label": 1}, {"snippet_id": 55856, "code": " decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 29564, "code": ".path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re", "label": 0}, {"snippet_id": 85712, "code": "): '/dev/null/remapped_by_pants/buildroot/', self._zinc_factory.get_options().pants_workdir: '/dev/null/remapped_by_pants/workdir/', } return( '-rebase-map', ','.join('{}:{}'.format(src, dst) for src, dst", "label": 0}, {"snippet_id": 41240, "code": " try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been", "label": 0}, {"snippet_id": 42827, "code": " output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 71368, "code": ".set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 19344, "code": ".NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_url(httpbin): native={ 'origin': '127.0.0.1', 'args':", "label": 0}, {"snippet_id": 8841, "code": " text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file", "label": 1}, {"snippet_id": 63987, "code": " dependency_resolution not in[\"none\", \"local\", \"remote\"]: raise Exception(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata", "label": 0}, {"snippet_id": 66168, "code": "% target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append", "label": 0}, {"snippet_id": 39852, "code": ".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable", "label": 0}, {"snippet_id": 30204, "code": " index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as", "label": 0}, {"snippet_id": 87014, "code": " @property def incremental(self): \"\"\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for", "label": 0}, {"snippet_id": 96001, "code": " number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}", "label": 0}, {"snippet_id": 6817, "code": " taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of", "label": 1}, {"snippet_id": 32642, "code": " of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp", "label": 0}, {"snippet_id": 24690, "code": " and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 32619, "code": "(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len", "label": 0}, {"snippet_id": 31579, "code": "=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message", "label": 0}, {"snippet_id": 12464, "code": "=data[file +\"_link\"] +\" error_string_list[1]=\"[{0}:{1}]({2}):\".format(line, col, line_url) error_string=\" \".join(error_string_list) error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append", "label": 0}, {"snippet_id": 47830, "code": " self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params", "label": 0}, {"snippet_id": 96073, "code": "..\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length, chunk_width=chunk_width) print(\"[VCF-Zarr", "label": 1}, {"snippet_id": 3113, "code": " is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!", "label": 0}, {"snippet_id": 9766, "code": " categories): \"\"\"Output the results obtained in text format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted", "label": 0}, {"snippet_id": 18105, "code": ") if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__", "label": 0}, {"snippet_id": 70761, "code": " fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets", "label": 0}, {"snippet_id": 56983, "code": " 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid literal for int() with base 10: 'string'\") \"\"\" value=error=None def get_time(time): date_time=datetime.datetime", "label": 0}, {"snippet_id": 27947, "code": "'GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state", "label": 0}, {"snippet_id": 45950, "code": " value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString", "label": 0}, {"snippet_id": 66926, "code": " with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): ", "label": 0}, {"snippet_id": 52519, "code": "\"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield", "label": 0}, {"snippet_id": 43130, "code": " fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems", "label": 0}, {"snippet_id": 4784, "code": " taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int", "label": 0}, {"snippet_id": 83162, "code": "/localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL", "label": 0}, {"snippet_id": 75850, "code": "=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) rs.finished=False rs.retry=False continue return elapsed=t.elapsed(False) if elapsed >=timeout: t", "label": 0}, {"snippet_id": 70141, "code": "%s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update", "label": 0}, {"snippet_id": 35313, "code": "*wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str", "label": 0}, {"snippet_id": 51263, "code": " first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group", "label": 0}, {"snippet_id": 79823, "code": "\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar", "label": 0}, {"snippet_id": 35904, "code": " or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"", "label": 0}, {"snippet_id": 2209, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action", "label": 0}, {"snippet_id": 70029, "code": " from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler", "label": 0}, {"snippet_id": 72048, "code": ") try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1: network name(case sensitive)).') return except KeyError: irc.error('No such network", "label": 0}, {"snippet_id": 6375, "code": " unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the", "label": 0}, {"snippet_id": 83232, "code": "(self.client_manager, 'ensure_has_status_update_callback'): self.client_manager.ensure_has_status_update_callback(self.__async_update) return job_state status=client.get_status() except Exception: self", "label": 0}, {"snippet_id": 66563, "code": " filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK", "label": 0}, {"snippet_id": 6859, "code": " extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects", "label": 0}, {"snippet_id": 21942, "code": " become_method=None, become_user=None, become_ask_pass=None, ask_pass=None, private_key_file=None, remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None", "label": 0}, {"snippet_id": 64924, "code": " to start Lustre filesystem servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration", "label": 0}, {"snippet_id": 56668, "code": " tag in all_tags: tag.num_plans=plan_counter.calculate_tag_count(tag) tag.num_cases=case_counter.calculate_tag_count(tag) tag.num_runs=run_counter.calculate_tag_count(tag) context_data={ 'tags': all_tags", "label": 0}, {"snippet_id": 91185, "code": " PythonDistribution from pants.backend.python.targets.python_library import PythonLibrary from pants.backend.python.targets.python_requirement_library import PythonRequirementLibrary from pants.backend.python.targets", "label": 0}, {"snippet_id": 29470, "code": " def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"", "label": 0}, {"snippet_id": 46829, "code": "(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict", "label": 0}, {"snippet_id": 82968, "code": "\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t", "label": 1}, {"snippet_id": 75991, "code": "'Cannot authentificate for({0},{1}),{2}:{3}'.\\ format(i, m, wzrpc.name_status(status), repr(data))) elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else:", "label": 0}, {"snippet_id": 95409, "code": "}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath", "label": 0}, {"snippet_id": 74770, "code": "=blosc_compression_algorithm_temp if \"blosc_compression_level\" in runtime_config.vcf_to_zarr: blosc_compression_level_str=runtime_config.vcf_to_zarr[\"blosc_compression_level\"] if isint(blosc_compression_level_str)", "label": 0}, {"snippet_id": 59675, "code": "))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device", "label": 0}, {"snippet_id": 4254, "code": "(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename", "label": 0}, {"snippet_id": 12184, "code": ".environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository\"] after_commit_hash=data[\"after_commit_hash\"] author=data[\"author\"] py_files=get_python_files_involved_in_pr(data) for file in", "label": 0}, {"snippet_id": 31758, "code": ".update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output", "label": 0}, {"snippet_id": 24752, "code": "\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=", "label": 0}, {"snippet_id": 64248, "code": "=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path(", "label": 0}, {"snippet_id": 27510, "code": " from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self", "label": 0}, {"snippet_id": 18511, "code": " self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in", "label": 0}, {"snippet_id": 76046, "code": ".debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i, m)", "label": 0}, {"snippet_id": 37362, "code": "\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else", "label": 0}, {"snippet_id": 76197, "code": " return self.log.debug('Unbinding route %s,%s', i, m) self.wz.del_req_handler(i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Route unbinded for(%s", "label": 0}, {"snippet_id": 37285, "code": ".items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark)", "label": 0}, {"snippet_id": 10879, "code": " import socket from time import localtime, strftime, time from requests.exceptions import RequestException, ConnectionError, Timeout import requests import yaml from monitoring_config_generator.exceptions", "label": 0}, {"snippet_id": 72308, "code": "'source' in kwargs: del kwargs['source'] irc.reply(text, source=irc.pseudoclient.uid, **kwargs) old_reply=remoteirc.reply with remoteirc.reply_lock: try: log.debug('(%s) networks.remote: overriding reply", "label": 1}, {"snippet_id": 61471, "code": ", operation.wires) elif len(operation.wires)==2: U=self.expand_two(U, operation.wires) else: raise ValueError('This plugin supports only one-and two-qubit gates.') self._state=U @ self._state A=DefaultQubit", "label": 0}, {"snippet_id": 6400, "code": " import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer", "label": 0}, {"snippet_id": 8428, "code": " the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote", "label": 1}, {"snippet_id": 91496, "code": ".python.subsystems.pytest import PyTest from pants.backend.python.subsystems.python_setup import PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot", "label": 0}, {"snippet_id": 52485, "code": ".shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell", "label": 0}, {"snippet_id": 55646, "code": "[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule", "label": 0}, {"snippet_id": 1001, "code": " configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False", "label": 0}, {"snippet_id": 39451, "code": ".output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an", "label": 0}, {"snippet_id": 63129, "code": " __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep( 2) job_state=self.__find_watched_job( job_id) if not job_state: log.warn(", "label": 0}, {"snippet_id": 1778, "code": ".Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action", "label": 0}, {"snippet_id": 79163, "code": "\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t", "label": 1}, {"snippet_id": 64772, "code": "(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR", "label": 0}, {"snippet_id": 79787, "code": "\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote server where uploads are put. Example: '/tmp/uploads/'\") parser", "label": 0}, {"snippet_id": 58608, "code": ": \"\"\"Test case for update\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateObject, cls).setUpTestData() cls.permission='testplans.change_testplan' cls.update_url=reverse('ajax-update') def setUp", "label": 0}, {"snippet_id": 43298, "code": ".output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log", "label": 0}, {"snippet_id": 77328, "code": " if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: w=wclass(*args, name='.'.join(", "label": 0}, {"snippet_id": 33098, "code": "(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger", "label": 0}, {"snippet_id": 79768, "code": "--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"-", "label": 0}, {"snippet_id": 4859, "code": " if s !=\"raw\": my_styles[s]=functions[s](complete_output, categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords", "label": 0}, {"snippet_id": 47507, "code": "{name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads", "label": 0}, {"snippet_id": 34436, "code": " workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self", "label": 0}, {"snippet_id": 24534, "code": "\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'", "label": 0}, {"snippet_id": 62807, "code": " engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend", "label": 0}, {"snippet_id": 73774, "code": "=\"\" password=\"\" use_tls=False directory=\"\" files=[] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config", "label": 0}, {"snippet_id": 10475, "code": " text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine", "label": 0}, {"snippet_id": 25374, "code": ") else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable", "label": 1}, {"snippet_id": 50186, "code": ".chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config", "label": 0}, {"snippet_id": 38696, "code": ")) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets", "label": 0}, {"snippet_id": 22541, "code": " or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example", "label": 0}, {"snippet_id": 72046, "code": ".disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1: network name(case sensitive)).') return except KeyError: irc.error('No", "label": 0}, {"snippet_id": 43048, "code": " for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self", "label": 0}, {"snippet_id": 48130, "code": ".append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item", "label": 0}, {"snippet_id": 40011, "code": "=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists", "label": 0}, {"snippet_id": 78111, "code": " def send_to_wm(frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) sig_sock.send_multipart(msg) def send_passthrough(frames): msg=[b'WipeManager'] msg.extend(wzrpc", "label": 0}, {"snippet_id": 9468, "code": " historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag", "label": 0}, {"snippet_id": 37718, "code": " in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems", "label": 0}, {"snippet_id": 5268, "code": " categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary", "label": 0}, {"snippet_id": 91258, "code": " pants.backend.python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import PythonBinaryCreate from pants.backend.python.tasks.python_bundle import PythonBundle from", "label": 0}, {"snippet_id": 81657, "code": ".uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t", "label": 1}, {"snippet_id": 53862, "code": " strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name", "label": 0}, {"snippet_id": 86965, "code": "'--incremental-caching', advanced=True, type=bool, help='When set, the results of incremental compiles will be written to the cache. ' 'This is unset by default, because it is generally a good precaution", "label": 0}, {"snippet_id": 12049, "code": "(arguments)) config[\"pycodestyle\"][\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return a list of file names modified/added in the PR", "label": 0}, {"snippet_id": 76634, "code": "/simg4.gelbooru.com/' +'/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]') msg.append('\u041a\u0430\u0436\u0434\u044b\u0439 \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random.randint(0, 9999999999))) return '\\n'.join(msg) def", "label": 0}, {"snippet_id": 49437, "code": " wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0", "label": 0}, {"snippet_id": 86745, "code": " settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator", "label": 0}, {"snippet_id": 62173, "code": "(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self", "label": 0}, {"snippet_id": 85862, "code": ".backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm", "label": 0}, {"snippet_id": 14121, "code": ") return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']", "label": 0}, {"snippet_id": 74952, "code": ".benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config=runtime_config) def read_configuration(location): \"", "label": 1}, {"snippet_id": 63152, "code": "%s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self", "label": 1}, {"snippet_id": 14893, "code": " self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET',", "label": 0}, {"snippet_id": 67879, "code": " command classes. The status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand", "label": 0}, {"snippet_id": 85483, "code": ".register_jvm_tool(register, 'compiler-bridge', classpath=[ ScalaJarDependency(org='org.scala-sbt', name='compiler-bridge', rev=zinc_rev, classifier='sources', intransitive=True), ]) cls.register_jvm_tool", "label": 0}, {"snippet_id": 79387, "code": "%s...\",url) \t\t \t\tr=self.session.get(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +", "label": 0}, {"snippet_id": 44574, "code": ".resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources", "label": 0}, {"snippet_id": 46145, "code": "\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values", "label": 0}, {"snippet_id": 10018, "code": "=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches", "label": 0}, {"snippet_id": 39558, "code": " rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self", "label": 0}, {"snippet_id": 70309, "code": " target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status", "label": 0}, {"snippet_id": 62966, "code": " __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home", "label": 0}, {"snippet_id": 26432, "code": " self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data", "label": 0}, {"snippet_id": 80471, "code": "\tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with", "label": 0}, {"snippet_id": 85623, "code": "._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list of str \"\"\" return self._zinc_factory.dist @memoized_property def compiler_bridge(self): \"\"", "label": 0}, {"snippet_id": 7350, "code": " in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw],", "label": 0}, {"snippet_id": 56502, "code": "(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters=['app_form', 'format'] parameters=strip_parameters(request.GET,", "label": 1}, {"snippet_id": 20192, "code": " self._run_server_ex=None def run(): try: self._session=self.SESSION.create_server(addr, **kwargs) except Exception as ex: self._run_server_ex=traceback.format_exc() t=new_hidden_thread( target=run, name", "label": 0}, {"snippet_id": 56416, "code": "'is_active', default='False')) except(ValueError, TypeError): is_active=False return Build.objects.filter(product_id=self.product_id, is_active=is_active) def categories(self): return Category.objects.filter", "label": 0}, {"snippet_id": 35826, "code": " a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has", "label": 0}, {"snippet_id": 54840, "code": " list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None,", "label": 0}, {"snippet_id": 63430, "code": "%s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths=job_wrapper.get_output_fnames() return[ str( o) for o in output_paths] def get_input_files(self", "label": 0}, {"snippet_id": 8977, "code": " is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags", "label": 0}, {"snippet_id": 55268, "code": " detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n", "label": 0}, {"snippet_id": 13888, "code": "): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture", "label": 0}, {"snippet_id": 69263, "code": "% e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message", "label": 1}, {"snippet_id": 73223, "code": " files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir", "label": 0}, {"snippet_id": 73121, "code": ".cwd(remote_path_absolute) except error_perm: temp=ftp.nlst() if not os.path.isfile(file_path_local): with open(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write", "label": 0}, {"snippet_id": 25332, "code": " up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config:", "label": 1}, {"snippet_id": 21156, "code": "=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message='Timeout waiting for ' if isinstance(self, AwaitableEvent): message +='Event{}'", "label": 0}, {"snippet_id": 69359, "code": ".targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath]", "label": 0}, {"snippet_id": 11415, "code": ".target_dir, file_name) def write_output(self, file_name, yaml_icinga): lines=yaml_icinga.icinga_lines output_writer=OutputWriter(self.output_path(file_name)) output_writer.write_lines(lines) @staticmethod", "label": 0}, {"snippet_id": 83906, "code": "\"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job", "label": 0}, {"snippet_id": 84742, "code": ".output_directory_digest] )[0].dependencies files_content={fc.path: fc.content.decode('utf-8') for fc in files_content_tuple} for line in files_content['report'].split('\\n'): yield line if self.get_options().ignored: yield ", "label": 0}, {"snippet_id": 51239, "code": "])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be", "label": 0}, {"snippet_id": 39226, "code": " and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule", "label": 0}, {"snippet_id": 30527, "code": " __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools", "label": 0}, {"snippet_id": 10447, "code": " indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_',", "label": 0}, {"snippet_id": 52131, "code": "=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__", "label": 0}, {"snippet_id": 26314, "code": ".Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\"", "label": 0}, {"snippet_id": 3670, "code": " succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check", "label": 0}, {"snippet_id": 7988, "code": "\"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1", "label": 0}, {"snippet_id": 17725, "code": " return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([", "label": 0}, {"snippet_id": 45024, "code": ".input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params", "label": 0}, {"snippet_id": 45716, "code": "<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if", "label": 0}, {"snippet_id": 39553, "code": ".message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__", "label": 0}, {"snippet_id": 42642, "code": " True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark", "label": 0}, {"snippet_id": 47712, "code": " import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand", "label": 0}, {"snippet_id": 51610, "code": " in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards ", "label": 0}, {"snippet_id": 93438, "code": "!\" %(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in", "label": 0}, {"snippet_id": 3580, "code": "'name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs", "label": 0}, {"snippet_id": 19370, "code": " __version__, __author__ \"\"\" For the PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger", "label": 0}, {"snippet_id": 93774, "code": ") return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name", "label": 0}, {"snippet_id": 86968, "code": "-caching', advanced=True, type=bool, help='When set, the results of incremental compiles will be written to the cache. ' 'This is unset by default, because it is generally a good precaution to cache ' 'only", "label": 0}, {"snippet_id": 66443, "code": ".status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else:", "label": 1}, {"snippet_id": 70578, "code": ", message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][", "label": 0}, {"snippet_id": 35218, "code": " after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that", "label": 0}, {"snippet_id": 64677, "code": " from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client", "label": 0}, {"snippet_id": 90783, "code": " Distribution.Error) as e: logger.debug('{} is not a valid distribution because:{}' .format(location.home_path, str(e))) pass if(minimum_version is not None and maximum_version is not None and maximum_version ", "label": 0}, {"snippet_id": 34630, "code": ".access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self):", "label": 1}, {"snippet_id": 86089, "code": " isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, AnnotationProcessor) and target.processors: processor_info_file=os.path.join", "label": 0}, {"snippet_id": 36659, "code": "+str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value", "label": 0}, {"snippet_id": 91793, "code": "='Run pytest for{}'.format(test_target.address.reference()), ) result=yield Get(FallibleExecuteProcessResult, ExecuteProcessRequest, request) status=Status.SUCCESS if result.exit_code==0 else Status.FAILURE", "label": 0}, {"snippet_id": 72767, "code": " the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks", "label": 0}, {"snippet_id": 94787, "code": "\"store_true\") remote_mutex.add_argument('-c', '--check', help=\"Run a component check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode", "label": 0}, {"snippet_id": 95787, "code": " path_head(path): head, tail=os.path.split(path) return head def path_leaf(path): head, tail=os.path.split(path) return tail or os.path.basename(head) def read_file_contents(local_filepath): if os.path", "label": 0}, {"snippet_id": 4118, "code": " pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import", "label": 0}, {"snippet_id": 5280, "code": " single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags", "label": 0}, {"snippet_id": 30940, "code": " wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self", "label": 0}, {"snippet_id": 53218, "code": ".priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)=", "label": 0}, {"snippet_id": 89764, "code": ".path.join(jdk_dir, 'bin', 'javac')): home=jdk_dir self._home=home return self._home @property def real_home(self): \"\"\"Real path to the distribution java.home(resolving links).\"\"\" return os.path.realpath", "label": 1}, {"snippet_id": 23340, "code": ".common.utils.shellutil as shellutil import azurelinuxagent.common.utils.textutil as textutil import azurelinuxagent.common.logger as logger from azurelinuxagent.common.exception import OSUtilError from", "label": 0}, {"snippet_id": 22578, "code": " gets around to running though, tmsh will reject that value because it is not a fully qualified domain name. The proper value should have been bigip.xxx.yyy WAAgent will not fail if this command fails,", "label": 0}, {"snippet_id": 65074, "code": " \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc", "label": 0}, {"snippet_id": 23223, "code": " expected*struct_size, buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno(), 0x8912, param) retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned", "label": 0}, {"snippet_id": 66346, "code": ".set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict", "label": 0}, {"snippet_id": 63305, "code": " compute_environment=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters", "label": 0}, {"snippet_id": 9474, "code": " acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items", "label": 0}, {"snippet_id": 67156, "code": "\"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f %s' to initialize", "label": 0}, {"snippet_id": 59193, "code": " numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate", "label": 0}, {"snippet_id": 67069, "code": " import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__", "label": 0}, {"snippet_id": 30146, "code": " self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items", "label": 0}, {"snippet_id": 63876, "code": ".job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still", "label": 0}, {"snippet_id": 63256, "code": ", job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return", "label": 0}, {"snippet_id": 81461, "code": ".ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext", "label": 0}, {"snippet_id": 26410, "code": " of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data", "label": 0}, {"snippet_id": 16095, "code": " _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True", "label": 1}, {"snippet_id": 49959, "code": " len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules", "label": 0}, {"snippet_id": 80824, "code": "[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent", "label": 1}, {"snippet_id": 74965, "code": "=runtime_config) def read_configuration(location): \"\"\" Args: location of the configuration file, existing configuration dictionary Returns: a dictionary of the form <dict>.<section>[<option>] and the corresponding", "label": 0}, {"snippet_id": 81668, "code": " in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: ", "label": 0}, {"snippet_id": 54880, "code": "\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule", "label": 0}, {"snippet_id": 60269, "code": " before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields", "label": 0}, {"snippet_id": 2428, "code": " self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile", "label": 0}, {"snippet_id": 85139, "code": "._tool_classpath('scalastyle', products) @property def version(self): return self.get_options().version def suffix_version(self, name): \"\"\"Appends the platform version to the given artifact name. Also validates that", "label": 0}, {"snippet_id": 36612, "code": "(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log,", "label": 0}, {"snippet_id": 41918, "code": "\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of", "label": 0}, {"snippet_id": 2557, "code": " comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def", "label": 0}, {"snippet_id": 10925, "code": " uri_parsed=urlparse.urlparse(uri) if is_file(uri_parsed): return read_config_from_file(uri_parsed.path) elif is_host(uri_parsed): return read_config_from_host(uri) else: raise ValueError('Given url was", "label": 0}, {"snippet_id": 69530, "code": " if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]", "label": 0}, {"snippet_id": 14921, "code": ", timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync", "label": 0}, {"snippet_id": 10845, "code": "=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d", "label": 1}, {"snippet_id": 68558, "code": ") layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes", "label": 0}, {"snippet_id": 74864, "code": " configuration. \"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_aggregations=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\"", "label": 1}, {"snippet_id": 2659, "code": ".comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex", "label": 0}, {"snippet_id": 74471, "code": " server=\"\" username=\"\" password=\"\" use_tls=False directory=\"\" files=[] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config", "label": 0}, {"snippet_id": 12675, "code": ".environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/{}/issues/{}/comments\" query=query.format(data[\"repository\"], str(data[\"pr_number\"", "label": 0}, {"snippet_id": 58609, "code": "\"\"Test case for update\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateObject, cls).setUpTestData() cls.permission='testplans.change_testplan' cls.update_url=reverse('ajax-update') def setUp(self", "label": 0}, {"snippet_id": 417, "code": "\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password", "label": 0}, {"snippet_id": 21115, "code": "()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'.format(awaitable.name)) else: messages.append('Response{}'.format(awaitable.name)) if len(messages)==0", "label": 0}, {"snippet_id": 73421, "code": "(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(\"**/*.vcf\") for path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str", "label": 0}, {"snippet_id": 43757, "code": ": None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows", "label": 0}, {"snippet_id": 66464, "code": " else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\"", "label": 0}, {"snippet_id": 1955, "code": "', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return", "label": 0}, {"snippet_id": 22812, "code": " for the user :param crypt_id: If encrypting the password, the crypt_id that was used :param salt_len: If encrypting the password, the length of the salt value used to do it. \"\"\" cmd=\"/usr/bin/tmsh modify", "label": 0}, {"snippet_id": 38971, "code": " disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:", "label": 0}, {"snippet_id": 60857, "code": " ' +self.author +'\\n' def __enter__(self): if Device._current_context is None: Device._current_context=self self.reset() else: raise DeviceError('Only one device can be active at a time.') return self def", "label": 0}, {"snippet_id": 53308, "code": "._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self", "label": 0}, {"snippet_id": 6983, "code": " object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return", "label": 0}, {"snippet_id": 67768, "code": "\"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 28326, "code": " up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config:", "label": 1}, {"snippet_id": 11725, "code": " integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: query=r\"INSERT INTO Users(repository, created_at) VALUES('{}', now());\" \\ \"\".format(repository) try: cursor.execute(query", "label": 0}, {"snippet_id": 92814, "code": "(self): falsey=(None, '', False) for invalid in falsey: with self.assertRaises(InvalidZipPath): next(open_zip(invalid).gen) def test_open_zip_returns_realpath_on_badzipfile(self): with temporary_file() as", "label": 0}, {"snippet_id": 15006, "code": " _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http:/", "label": 0}, {"snippet_id": 82983, "code": ".submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads", "label": 1}, {"snippet_id": 66534, "code": "(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes", "label": 0}, {"snippet_id": 65393, "code": ".CommandRCDefs import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs", "label": 0}, {"snippet_id": 37922, "code": " else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined", "label": 0}, {"snippet_id": 40711, "code": ": filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their", "label": 0}, {"snippet_id": 15437, "code": "._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage", "label": 0}, {"snippet_id": 26863, "code": "] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=", "label": 0}, {"snippet_id": 26628, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'", "label": 0}, {"snippet_id": 48814, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output", "label": 0}, {"snippet_id": 22555, "code": " specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly valid name. When WAAgent gets around", "label": 0}, {"snippet_id": 32112, "code": " inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)", "label": 0}, {"snippet_id": 79520, "code": "(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t", "label": 0}, {"snippet_id": 33964, "code": " update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow", "label": 0}, {"snippet_id": 81808, "code": " based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following(name -description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t[\"templateName\"]+\"' -", "label": 0}, {"snippet_id": 31987, "code": " --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies", "label": 0}, {"snippet_id": 81506, "code": ".shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: ", "label": 0}, {"snippet_id": 17785, "code": " return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr))", "label": 0}, {"snippet_id": 10569, "code": " False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please", "label": 1}, {"snippet_id": 18858, "code": ", ) from flex.loading.schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request", "label": 0}, {"snippet_id": 4617, "code": " in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder", "label": 0}, {"snippet_id": 77879, "code": ".exception(e) self.terminate() self.join_threads() if self.c.tcount > 0: self.save_users() self.save_targets() wm=workers.WZWorkerThread(c.router_addr, WipeManager,(c,), name='SpaghettiMonster') wm.start", "label": 0}, {"snippet_id": 51619, "code": "\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(*", "label": 0}, {"snippet_id": 26644, "code": " self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium", "label": 0}, {"snippet_id": 75855, "code": " method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) rs.finished=False rs.retry=False continue return elapsed=t.elapsed(False) if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,", "label": 0}, {"snippet_id": 69922, "code": " fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print", "label": 1}, {"snippet_id": 81027, "code": " 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical", "label": 0}, {"snippet_id": 9779, "code": " for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result", "label": 0}, {"snippet_id": 79808, "code": " parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete", "label": 0}, {"snippet_id": 15187, "code": " OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager", "label": 0}, {"snippet_id": 65990, "code": "> 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers", "label": 0}, {"snippet_id": 11828, "code": "), value) else: base[key]=head[key] else: base={key: head[key]} return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is", "label": 1}, {"snippet_id": 69818, "code": " else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self", "label": 0}, {"snippet_id": 45408, "code": " def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function", "label": 0}, {"snippet_id": 4965, "code": ", categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches", "label": 0}, {"snippet_id": 83630, "code": ".copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env=getattr( job_wrapper.job_destination, \"env\",[]) return self", "label": 0}, {"snippet_id": 68914, "code": ".FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre", "label": 0}, {"snippet_id": 75408, "code": " args, fun, reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer): iden=self.iden_reqid_map.get_key(reqid) if seqnum==0: self.iden_reqid_map.del_value(iden, reqid) msg=list(iden)", "label": 0}, {"snippet_id": 79597, "code": " import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level", "label": 0}, {"snippet_id": 35572, "code": "(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item.", "label": 0}, {"snippet_id": 76444, "code": ".parse_router_msg(frames): self.wz_sock.send_multipart(nfr) except wzrpc.WZErrorRep as e: self.log.info(e) self.wz_sock.send_multipart(e.rep_msg) except wzrpc.WZError as e: self.log.warn(e) def run(self", "label": 0}, {"snippet_id": 5086, "code": ".append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw], encode_for_xml(categories[kw]))) for field, keywords in((auth_field, output_complete[\"Author keywords\"])", "label": 0}, {"snippet_id": 79301, "code": "(extensions,e))) \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t", "label": 0}, {"snippet_id": 59754, "code": "'Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is", "label": 0}, {"snippet_id": 59329, "code": " end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True", "label": 0}, {"snippet_id": 85347, "code": ".backend.jvm.targets.scala_jar_dependency import ScalaJarDependency from pants.backend.jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil", "label": 0}, {"snippet_id": 84880, "code": ".replace('.', '_')) @classmethod def register_options(cls, register): def register_scala_compiler_tool(version): cls.register_jvm_tool(register, cls._key_for_tool_version('scalac', version), classpath=", "label": 1}, {"snippet_id": 14016, "code": " handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None,", "label": 0}, {"snippet_id": 84057, "code": " %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner, self).shutdown() self.client_manager", "label": 0}, {"snippet_id": 51534, "code": "*args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments", "label": 0}, {"snippet_id": 81419, "code": ".logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\"", "label": 0}, {"snippet_id": 84676, "code": "(input_file) list_file_out.write('\\n') list_file_snapshot=self.context._scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs(('input_files_list',)), text_type(tmpdir), ), ))[0] cloc_path, cloc_snapshot", "label": 0}, {"snippet_id": 27480, "code": " of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement", "label": 0}, {"snippet_id": 7606, "code": " _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword", "label": 0}, {"snippet_id": 35624, "code": "(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for", "label": 0}, {"snippet_id": 9851, "code": ", number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format(", "label": 0}, {"snippet_id": 81801, "code": " server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following(name -description): \" for t in templates: \ttemplatesSection", "label": 0}, {"snippet_id": 29285, "code": " except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os", "label": 0}, {"snippet_id": 21403, "code": " files.\" % work_dir) os.mkdir(work_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file", "label": 0}, {"snippet_id": 4640, "code": "{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or", "label": 0}, {"snippet_id": 25904, "code": " data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 57775, "code": "') except ValueError: return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets", "label": 0}, {"snippet_id": 75199, "code": " import WZBase class WZHandler(WZBase): def __init__(self): self.req_handlers={} self.response_handlers={} self.sig_handlers={} self.iden_reqid_map=BijectiveSetMap() def set_req_handler(self, interface", "label": 0}, {"snippet_id": 14087, "code": ".text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY", "label": 0}, {"snippet_id": 10254, "code": " return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares", "label": 0}, {"snippet_id": 32290, "code": " concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output", "label": 0}, {"snippet_id": 76580, "code": " dataloader import DataLoader from uniwipe import UniWipe from wipeskel import * import wzrpc from beon import regexp import pickle from logging import config from logconfig import logging_config config", "label": 0}, {"snippet_id": 95032, "code": "=\"Label for the benchmark run.\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration", "label": 0}, {"snippet_id": 41124, "code": " for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len", "label": 0}, {"snippet_id": 22272, "code": ".logger as logger import azurelinuxagent.common.utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except", "label": 0}, {"snippet_id": 32239, "code": " if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self", "label": 0}, {"snippet_id": 41688, "code": " Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 80154, "code": " for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=", "label": 0}, {"snippet_id": 52244, "code": " targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict", "label": 0}, {"snippet_id": 73365, "code": " as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output", "label": 0}, {"snippet_id": 10660, "code": "=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close", "label": 0}, {"snippet_id": 6604, "code": " as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines", "label": 1}, {"snippet_id": 86138, "code": " return super(JavacCompile, self).execute() def compile(self, ctx, args, dependency_classpath, upstream_analysis, settings, fatal_warnings, zinc_file_manager, javac_plugin_map, scalac_plugin_map): classpath=", "label": 0}, {"snippet_id": 29138, "code": " follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile", "label": 0}, {"snippet_id": 53919, "code": ", start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested", "label": 0}, {"snippet_id": 44547, "code": "(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules", "label": 0}, {"snippet_id": 31385, "code": "): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run", "label": 0}, {"snippet_id": 59355, "code": " retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" name='ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin", "label": 0}, {"snippet_id": 26973, "code": ": self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self", "label": 0}, {"snippet_id": 89645, "code": "\"Returns the distribution version. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" return self._get_version(self.java) def find_libs(self, names", "label": 0}, {"snippet_id": 13828, "code": "(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr", "label": 0}, {"snippet_id": 91834, "code": " logging from textwrap import dedent from pants.backend.native.subsystems.native_toolchain import NativeToolchain from pants.backend.native.targets.native_library import NativeLibrary from pants.backend", "label": 0}, {"snippet_id": 22042, "code": "=sftp_extra_args self.scp_extra_args=scp_extra_args self.ssh_extra_args=ssh_extra_args self.poll_interval=poll_interval self.seconds=seconds self.check=check self.syntax=syntax self.diff=diff self.force_handlers", "label": 0}, {"snippet_id": 93802, "code": "], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window", "label": 0}, {"snippet_id": 87428, "code": " analysis_cache=relative_to_exec_root(analysis_cache) classes_dir=relative_to_exec_root(classes_dir) relative_classpath=tuple(relative_to_exec_root(c) for c in absolute_classpath) zinc_args=[] zinc_args.extend([", "label": 0}, {"snippet_id": 58819, "code": " {'rc': 0, 'response': 'ok'}) self.assertEqual( 'PAUSED', TestCaseRun.objects.get(pk=self.case_run_1.pk).case_run_status.name) class TestGetForm(test.TestCase): \"\"\"Test case for form\"\"\" def test_get_form", "label": 1}, {"snippet_id": 42249, "code": ".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input", "label": 0}, {"snippet_id": 78021, "code": " remove_target(domain, id_, user) def get_forum_id(name): id_=d.bm_id_forum.get_key(name) int(id_, 10) return id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls", "label": 0}, {"snippet_id": 12729, "code": ": comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B %d, %Y at %H:%M Hours UTC\") comment +=\"\\n\\n comment", "label": 0}, {"snippet_id": 13211, "code": "\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) sha=None r=requests.get(url, headers=headers, auth=auth) for ref in", "label": 0}, {"snippet_id": 53197, "code": ".dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1,", "label": 0}, {"snippet_id": 1112, "code": "(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate(", "label": 0}, {"snippet_id": 21554, "code": "\"Reddytt: That was: %s\" % link) if x==0: seen_links.append(link) save_links.remove(link) elif x==1024: print(\"Reddytt: Forced exit detected. Saving and exiting.\") with open(seen_file, 'wb') as f: pickle", "label": 1}, {"snippet_id": 95726, "code": " file_output_str)) print(\"[Setup][Data] Decompressing file:{}\".format(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip(path_str, path_temp_output) pathlist_vcf_temp=pathlib.Path", "label": 0}, {"snippet_id": 36758, "code": "(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input", "label": 0}, {"snippet_id": 62894, "code": ".items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the", "label": 0}, {"snippet_id": 2876, "code": " state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name", "label": 0}, {"snippet_id": 95300, "code": ": \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors", "label": 0}, {"snippet_id": 48250, "code": "]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"", "label": 0}, {"snippet_id": 85065, "code": " register_style_tool('2.10') register_scala_compiler_tool('2.11') register_scala_repl_tool('2.11') register_style_tool('2.11') register_scala_compiler_tool('2.12') register_scala_repl_tool('2.12') register_style_tool", "label": 0}, {"snippet_id": 12127, "code": "=r.encoding) files={} for patchset in patch: file=patchset.target_file[1:] files[file]=[] for hunk in patchset: for line in hunk.target_lines(): if line.is_added: files[file].append(line.target_line_no)", "label": 0}, {"snippet_id": 10430, "code": " abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise", "label": 0}, {"snippet_id": 90430, "code": " if len(possible_environments) < 2: raise ValueError('At least two possible environments must be supplied.') self._possible_environments=possible_environments @property def jvm_locations(self): return itertools", "label": 0}, {"snippet_id": 27827, "code": "=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 65908, "code": ") for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime))", "label": 0}, {"snippet_id": 31930, "code": "=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards", "label": 0}, {"snippet_id": 67725, "code": " if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\"", "label": 0}, {"snippet_id": 59019, "code": " EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_python) EnvGroupPropertyMapFactory(group=cls.group_new, property=cls.property_django) def test_get_env_properties(self): response=self.client.get(self", "label": 0}, {"snippet_id": 76999, "code": "[domain] else: tlist=list() targets[domain]=tlist if domain in forums: fset=forums[domain] else: fset=set() forums[domain]=fset net=make_net(proxy, proxytype) net.cookiefname=(proxy if proxy else 'noproxy')", "label": 0}, {"snippet_id": 79068, "code": " or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern", "label": 0}, {"snippet_id": 49111, "code": ".first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0", "label": 0}, {"snippet_id": 12721, "code": ": response=requests.post(query, json={\"body\": comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B %d,", "label": 0}, {"snippet_id": 1272, "code": " wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli", "label": 0}, {"snippet_id": 12003, "code": "(config, new_config) except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key, value in confs.items(): if value: if isinstance(value, int): if isinstance(value, bool): arguments.append(\"", "label": 0}, {"snippet_id": 16069, "code": ".result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler", "label": 0}, {"snippet_id": 57720, "code": " found.') confirm_status_name='CONFIRMED' plan.run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan", "label": 0}, {"snippet_id": 31063, "code": ".expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self)", "label": 0}, {"snippet_id": 79190, "code": " \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: ", "label": 0}, {"snippet_id": 37756, "code": " not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_", "label": 0}, {"snippet_id": 12254, "code": " data[\"extra_results\"][filename]=stdout.decode(r.encoding).splitlines() data[\"results\"][filename]=[] for error in list(data[\"extra_results\"][filename]): if re.search(\"^file_to_check.py:\\d+:\\d+:\\s[WE]\\d+", "label": 0}, {"snippet_id": 63083, "code": ".ensure_has_status_update_callback(self.__async_update) return job_state status=client.get_status() except Exception: self.mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state", "label": 0}, {"snippet_id": 19936, "code": " client closed') if adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError('already using managed adapter') if adapter is None: raise RuntimeError('debugger not running'", "label": 0}, {"snippet_id": 33225, "code": " resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items)", "label": 0}, {"snippet_id": 91628, "code": " maybe_python_req_lib in all_targets: if hasattr(maybe_python_req_lib, 'requirement'): all_target_requirements.append(str(maybe_python_req_lib.requirement)) if hasattr(maybe_python_req_lib, 'requirements", "label": 0}, {"snippet_id": 43425, "code": " concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match", "label": 0}, {"snippet_id": 84031, "code": ".job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/", "label": 0}, {"snippet_id": 90295, "code": " _OSX_JAVA_HOME_EXE='/usr/libexec/java_home' @classmethod def standard(cls): return cls(cls._OSX_JAVA_HOME_EXE) def __init__(self, osx_java_home_exe): self._osx_java_home_exe=osx_java_home_exe @property", "label": 0}, {"snippet_id": 89123, "code": "(self.targets(on_predicate)) dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in target.dependencies: if dependency in core: dependees[target].add(dependency) return", "label": 0}, {"snippet_id": 7376, "code": " keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag,", "label": 0}, {"snippet_id": 71404, "code": "+=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 8493, "code": " string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text)", "label": 1}, {"snippet_id": 68544, "code": "% fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER)", "label": 0}, {"snippet_id": 25414, "code": " __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name", "label": 0}, {"snippet_id": 88714, "code": "( name=parent_workunit_name, labels=[WorkUnitLabel.MULTITOOL], parent=background_root_workunit) workunit_parent=workunit_parent_ctx.__enter__() done_hook=lambda: workunit_parent_ctx.__exit__(None, None", "label": 0}, {"snippet_id": 507, "code": "\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return", "label": 0}, {"snippet_id": 72165, "code": " remote_parser.add_argument('--service', type=str, default='pylink') remote_parser.add_argument('command', nargs=utils.IRCParser.REMAINDER) @utils.add_cmd def remote(irc, source, args): \"\"\"<network>[--service", "label": 0}, {"snippet_id": 55799, "code": "=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo", "label": 0}, {"snippet_id": 50250, "code": "=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo", "label": 0}, {"snippet_id": 20275, "code": ", **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ filename, ] +list", "label": 0}, {"snippet_id": 3414, "code": " component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config", "label": 0}, {"snippet_id": 8320, "code": ". Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext", "label": 1}, {"snippet_id": 79775, "code": "\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path", "label": 0}, {"snippet_id": 77488, "code": ", self.c.tcount, (self.pc, self.spawnqueue)) def spawn_evaluators(self): self.log.info('Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import", "label": 0}, {"snippet_id": 7004, "code": "'author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): ", "label": 0}, {"snippet_id": 69652, "code": " fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes:", "label": 0}, {"snippet_id": 73901, "code": "\"\"\" enabled=False fields=None alt_number=None chunk_length=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def", "label": 0}, {"snippet_id": 28761, "code": ".type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(", "label": 0}, {"snippet_id": 10408, "code": ".write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid", "label": 0}, {"snippet_id": 54457, "code": " WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected,", "label": 1}, {"snippet_id": 62980, "code": " properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with", "label": 0}, {"snippet_id": 67920, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import * from Base.Support", "label": 0}, {"snippet_id": 80084, "code": " while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent", "label": 0}, {"snippet_id": 50193, "code": " global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames):", "label": 0}, {"snippet_id": 35216, "code": " write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag", "label": 0}, {"snippet_id": 81131, "code": "[0][\"name\"] \t\tself.logger.debug(\"Found the following file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action", "label": 0}, {"snippet_id": 38581, "code": " ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False,", "label": 0}, {"snippet_id": 55421, "code": ".resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\"", "label": 0}, {"snippet_id": 92493, "code": " os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()", "label": 0}, {"snippet_id": 48774, "code": " str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if", "label": 0}, {"snippet_id": 27760, "code": "=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 69618, "code": ": \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self", "label": 0}, {"snippet_id": 47501, "code": " in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule", "label": 0}, {"snippet_id": 31944, "code": " not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain", "label": 0}, {"snippet_id": 57828, "code": " _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list('pk', flat=True) if not reviewers: err_msg='Reviewer %s is not found' % self.new_value raise ObjectDoesNotExist(err_msg)", "label": 0}, {"snippet_id": 21826, "code": ".models import Sequential from keras.layers import Dense classifier=Sequential() classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11)) classifier.add(Dense(units", "label": 1}, {"snippet_id": 77645, "code": " data: self.log.debug('Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug", "label": 0}, {"snippet_id": 59921, "code": ".filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number", "label": 0}, {"snippet_id": 64820, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of", "label": 0}, {"snippet_id": 75645, "code": " suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=(), kvargs={}, name=None, start_timer=None, poll_timeout=None, pargs=(), pkvargs={}): super().__init__(*pargs,", "label": 0}, {"snippet_id": 67856, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 74867, "code": "\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_aggregations=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\" Creates an", "label": 1}, {"snippet_id": 21814, "code": "=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) import keras from keras.models import Sequential from keras.layers import Dense classifier=Sequential() classifier.add(Dense(units=6", "label": 1}, {"snippet_id": 53761, "code": " be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name", "label": 0}, {"snippet_id": 28620, "code": "\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self", "label": 0}, {"snippet_id": 36307, "code": "(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output):", "label": 1}, {"snippet_id": 46734, "code": "\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value", "label": 0}, {"snippet_id": 27088, "code": " to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else:", "label": 1}, {"snippet_id": 70665, "code": ".get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None: view", "label": 0}, {"snippet_id": 66906, "code": ".iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt -=1", "label": 1}, {"snippet_id": 32768, "code": " import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger", "label": 0}, {"snippet_id": 87532, "code": "]) if option_set=='fatal_warnings': enabled_args=self.get_options().fatal_warnings_enabled_args zinc_args.extend(enabled_args) for option_set, disabled_args in self.get_options().compiler_option_sets_disabled_args", "label": 0}, {"snippet_id": 82543, "code": " fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are", "label": 0}, {"snippet_id": 56142, "code": ": \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow", "label": 0}, {"snippet_id": 77843, "code": ".load_bumplimit_set() self.load_targets() self.load_users() self.spawn_wipethreads() if self.c.ecount > 0: self.spawn_evaluators() try: while self.running.is_set(): if self.c.tcount==0: self.inter_sleep(5) continue", "label": 0}, {"snippet_id": 63057, "code": " url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try:", "label": 0}, {"snippet_id": 47263, "code": "(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value", "label": 0}, {"snippet_id": 80617, "code": " \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex", "label": 0}, {"snippet_id": 82017, "code": ".add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url", "label": 0}, {"snippet_id": 75370, "code": " method, args, fun, reqid=None): if not reqid: reqid=self.make_reqid() msg=make_req_msg(interface, method, args, reqid) self.set_response_handler(reqid, fun) return msg def make_router_req_msg(self, iden", "label": 0}, {"snippet_id": 35236, "code": "\"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 57109, "code": "('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field and", "label": 0}, {"snippet_id": 4771, "code": " keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords", "label": 0}, {"snippet_id": 79257, "code": ".shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s", "label": 0}, {"snippet_id": 12053, "code": "\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return a list of file names modified/added in the PR \"\"\" headers={\"Authorization\"", "label": 0}, {"snippet_id": 34147, "code": "=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo", "label": 0}, {"snippet_id": 72926, "code": "(ftp_config.directory) file_counter=1 file_list_total=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not", "label": 0}, {"snippet_id": 58942, "code": ".pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) for pk in(self.case_1", "label": 0}, {"snippet_id": 7327, "code": "' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in", "label": 0}, {"snippet_id": 56524, "code": "'app_form') q_format=request.GET.get('format') if not q_format: q_format='p' if not q_app_form: return HttpResponse('Unrecognizable app_form') q_app, q_form=q_app_form.split('.')[0], q_app_form.split('", "label": 1}, {"snippet_id": 21138, "code": "=0: return else: raise TimeoutError('Timeout waiting for{}'.format(','.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event", "label": 0}, {"snippet_id": 68107, "code": ".verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs", "label": 0}, {"snippet_id": 19462, "code": "-m ptvsd'.format(os.path.basename(sys.executable)) else: prog=argv[0] argv=argv[1:] supported, pydevd, script=_group_args(argv) args=_parse_args(prog, supported) extra=pydevd +['--'] if script: extra +", "label": 0}, {"snippet_id": 37078, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io", "label": 0}, {"snippet_id": 41838, "code": " files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested", "label": 0}, {"snippet_id": 85630, "code": " the distribution selected for Zinc. :rtype: list of str \"\"\" return self._zinc_factory.dist @memoized_property def compiler_bridge(self): \"\"\"Return the path to the Zinc compiler-bridge jar. :rtype: str \"\"", "label": 0}, {"snippet_id": 24649, "code": ".type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 75251, "code": ", method)] def del_response_handler(self, reqid): del self.response_handlers[reqid] def del_sig_handler(self, interface, method): del self.sig_handlers[(interface, method)] def _parse_req(self, iden, msg", "label": 0}, {"snippet_id": 92781, "code": "._allowZip64) def test_open_zipTrue(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=True) as zf: self.assertTrue(zf._allowZip64) def test_open_zipFalse(self", "label": 0}, {"snippet_id": 30357, "code": " plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \"", "label": 0}, {"snippet_id": 90153, "code": "!r}, maximum_version={!r} jdk={!r})'.format( self._bin_path, self._minimum_version, self._maximum_version, self._jdk)) class _DistributionEnvironment(AbstractClass): class Location(namedtuple('Location", "label": 0}, {"snippet_id": 63770, "code": " or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %(", "label": 0}, {"snippet_id": 33021, "code": " used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name", "label": 0}, {"snippet_id": 41193, "code": "(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist):", "label": 0}, {"snippet_id": 31164, "code": " f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f", "label": 0}, {"snippet_id": 15446, "code": " utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer", "label": 0}, {"snippet_id": 78363, "code": " e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception(e) self.w.sleep(self.errortimeout) def forumwipe_loop(self): for f in self.forums: self.counter_tick() try: self", "label": 1}, {"snippet_id": 14748, "code": " filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype", "label": 0}, {"snippet_id": 8996, "code": " only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader", "label": 0}, {"snippet_id": 32153, "code": ", *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance", "label": 0}, {"snippet_id": 70109, "code": " 1: print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1:", "label": 0}, {"snippet_id": 14331, "code": ".format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format", "label": 0}, {"snippet_id": 13137, "code": ") r=requests.get(url, headers=headers, auth=auth) ATTEMPT=0 while(r.status_code !=200): time.sleep(5) r=requests.get(url, headers=headers, auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking", "label": 0}, {"snippet_id": 88747, "code": ") def background_worker_pool(self): \"\"\"Returns the pool to which tasks can submit background work. :API: public \"\"\" return self.run_tracker.background_worker_pool() def subproc_map(self, f, items): \"\"\"Map", "label": 0}, {"snippet_id": 5198, "code": "=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output", "label": 0}, {"snippet_id": 36332, "code": "=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append", "label": 0}, {"snippet_id": 28194, "code": "'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None", "label": 0}, {"snippet_id": 27727, "code": "._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self", "label": 0}, {"snippet_id": 2225, "code": " wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout", "label": 0}, {"snippet_id": 82370, "code": ".template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): ", "label": 0}, {"snippet_id": 80095, "code": "\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection", "label": 0}, {"snippet_id": 22536, "code": " the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks", "label": 0}, {"snippet_id": 66039, "code": ".CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout", "label": 0}, {"snippet_id": 48574, "code": " BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function", "label": 0}, {"snippet_id": 84409, "code": "[ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path() new_version_path=self.path_mapper.remote_version_path_rewrite(version_path) if new_version_path", "label": 0}, {"snippet_id": 44044, "code": ".0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules", "label": 0}, {"snippet_id": 5459, "code": ")) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires", "label": 0}, {"snippet_id": 66418, "code": ".verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount:", "label": 1}, {"snippet_id": 13555, "code": "( audio.mouthValue==1):\r io.set( MOUTH_OPEN, 1)\r io.set( MOUTH_CLOSE, 0)\r else:\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 1)\r else:\r if( time.time() -lastMouthEventTime > 0.4):\r io.set( MOUTH_OPEN,", "label": 0}, {"snippet_id": 76403, "code": " except zmq.ZMQError as e: self.log.error(e) return if socks.get(self.sig_sock)==zmq.POLLIN: frames=self.sig_sock.recv_multipart() try: self.wz.parse_msg(frames[0], frames[1:]) except wzrpc.WZError as e:", "label": 0}, {"snippet_id": 12265, "code": "\"][filename]): if re.search(\"^file_to_check.py:\\d+:\\d+:\\s[WE]\\d+\\s.*\", error): data[\"results\"][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error", "label": 0}, {"snippet_id": 21531, "code": "(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(", "label": 1}, {"snippet_id": 5880, "code": " filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\"", "label": 0}, {"snippet_id": 62748, "code": " _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution", "label": 0}, {"snippet_id": 29724, "code": " AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value", "label": 0}, {"snippet_id": 58807, "code": ".objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) self.assertEqual( 'PAUSED', TestCaseRun", "label": 0}, {"snippet_id": 25788, "code": " data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" %", "label": 0}, {"snippet_id": 87885, "code": "'.join(args))) return ret def _scalac_plugin_args(self, scalac_plugin_map, classpath): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath", "label": 0}, {"snippet_id": 79525, "code": "\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode", "label": 0}, {"snippet_id": 79180, "code": "\t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex", "label": 0}, {"snippet_id": 82670, "code": "\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif", "label": 0}, {"snippet_id": 11547, "code": " section_data): self.write_line(\"\") self.write_line(\"define %s{\" % section_name) sorted_keys=section_data.keys() sorted_keys.sort() for key in sorted_keys: value=section_data[key] self.icinga_lines.append((", "label": 1}, {"snippet_id": 60803, "code": " version='' author='' _capabilities={} _gates={} _observables={} _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots self._out=None self._queue=[] self._observe=None def __repr__", "label": 0}, {"snippet_id": 94321, "code": " '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error", "label": 0}, {"snippet_id": 22446, "code": " return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err=False) def stop_agent_service(self): return shellutil.run(\"/sbin/service waagent stop\", chk_err=False", "label": 0}, {"snippet_id": 12912, "code": " filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(", "label": 0}, {"snippet_id": 91382, "code": "=SelectInterpreter).install('pyprep') task(name='build-local-dists', action=BuildLocalPythonDistributions).install('pyprep') task(name='requirements', action=ResolveRequirements).install('pyprep') task(name=", "label": 0}, {"snippet_id": 60993, "code": " numpy as np from scipy.linalg import expm, eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"", "label": 0}, {"snippet_id": 26398, "code": " for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name", "label": 0}, {"snippet_id": 29063, "code": ".station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the", "label": 1}, {"snippet_id": 71588, "code": " RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 76347, "code": "=self.wz.make_dealer_rep_msg( reqid, seqid, wzrpc.status.error, data) self.wz_sock.send_multipart(msg) def send_to_router(self, msg): msg.insert(0, b'') self.wz_sock.send_multipart(msg) def inter_sleep", "label": 0}, {"snippet_id": 68072, "code": " get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR", "label": 0}, {"snippet_id": 92495, "code": ".getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self", "label": 0}, {"snippet_id": 51661, "code": " values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{", "label": 0}, {"snippet_id": 94397, "code": "['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive", "label": 0}, {"snippet_id": 93466, "code": " node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" ", "label": 0}, {"snippet_id": 92603, "code": "(os.path.realpath(path)), 'file should be created in root_dir if specified.') def test_temporary_dir_no_args(self): with temporary_dir() as path: self.assertTrue(os.path.exists(path), 'Temporary dir should", "label": 0}, {"snippet_id": 89086, "code": "*kwargs)) return list(filter(predicate, target_set)) def _collect_targets(self, root_targets, **kwargs): return Target.closure_for_targets( target_roots=root_targets, **kwargs ) def dependents(self, on_predicate", "label": 0}, {"snippet_id": 69304, "code": " Shine.Configuration.Globals import Globals from Shine.Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction):", "label": 0}, {"snippet_id": 72469, "code": " the benchmark run), and config argument for where is the config file. \"\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.", "label": 0}, {"snippet_id": 32702, "code": " self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether", "label": 0}, {"snippet_id": 89217, "code": "\"\"\" build_graph=self.build_graph.clone_new() for address in self.address_mapper.scan_addresses(root): build_graph.inject_address_closure(address) return build_graph def execute_process_synchronously(self", "label": 1}, {"snippet_id": 30348, "code": "._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key", "label": 0}, {"snippet_id": 87346, "code": " hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self.get_options().pants_bootstrapdir, 'zinc', key) def compile(self, ctx, args", "label": 1}, {"snippet_id": 42851, "code": " may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item", "label": 0}, {"snippet_id": 19436, "code": " HOST | --server-host HOST] --port PORT FILENAME[arg...] \"\"\" def parse_args(argv=None): \"\"\"Return the parsed args to use in main().\"\"\" if argv is None: argv=sys.argv prog=argv[0] if prog==__file__: prog='{", "label": 0}, {"snippet_id": 70917, "code": " target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering", "label": 0}, {"snippet_id": 1637, "code": " to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s", "label": 0}, {"snippet_id": 2104, "code": ",'-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{", "label": 0}, {"snippet_id": 80809, "code": ".nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a[\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates", "label": 0}, {"snippet_id": 790, "code": " print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4", "label": 0}, {"snippet_id": 28645, "code": "='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state", "label": 0}, {"snippet_id": 81336, "code": " \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: ", "label": 0}, {"snippet_id": 85636, "code": ".dist @memoized_property def compiler_bridge(self): \"\"\"Return the path to the Zinc compiler-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property def", "label": 0}, {"snippet_id": 67793, "code": " result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler", "label": 0}, {"snippet_id": 89100, "code": "=root_targets, **kwargs ) def dependents(self, on_predicate=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate to targets they depend on that satisfy the on_predicate. :API", "label": 0}, {"snippet_id": 51612, "code": " as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments", "label": 0}, {"snippet_id": 21535, "code": "=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt: That was: %s\" % link) if x", "label": 1}, {"snippet_id": 6153, "code": " communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line)", "label": 1}, {"snippet_id": 58113, "code": " say_yes() def get_prod_related_objs(p_pks, target): \"\"\" Get Component, Version, Category, and Build\\n Return[(id, name),(id, name)] \"\"\" ctypes={ 'component':(Component, 'name'), 'version':(Version, 'value", "label": 0}, {"snippet_id": 24926, "code": " data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 58198, "code": "(objects, **kwargs): objects.update(**kwargs) kwargs['instances']=objects if objects.model.__name__==TestCaseRun.__name__ and kwargs.get( 'case_run_status', None): POST_UPDATE_SIGNAL.send(sender=None, *", "label": 0}, {"snippet_id": 439, "code": "\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action", "label": 0}, {"snippet_id": 87461, "code": "-color') zinc_args.extend(['-compiler-interface', compiler_interface]) zinc_args.extend(['-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend", "label": 1}, {"snippet_id": 71563, "code": " shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE", "label": 0}, {"snippet_id": 12266, "code": "]): if re.search(\"^file_to_check.py:\\d+:\\d+:\\s[WE]\\d+\\s.*\", error): data[\"results\"][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error", "label": 0}, {"snippet_id": 43502, "code": "(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self", "label": 0}, {"snippet_id": 10991, "code": " HostUnreachableException(msg) except Timeout as e: msg=\"Connect timed out for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except RequestException as e: msg=\"Could not get monitoring", "label": 0}, {"snippet_id": 11249, "code": "-h Show this message. --debug Print additional information. --targetdir=DIR The generated Icinga monitoring configuration is written into this directory. If no target directory is given its value is read", "label": 0}, {"snippet_id": 55874, "code": " **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return", "label": 0}, {"snippet_id": 15519, "code": " GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for", "label": 0}, {"snippet_id": 30593, "code": " targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict)", "label": 0}, {"snippet_id": 39082, "code": "(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster,", "label": 0}, {"snippet_id": 12298, "code": "][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(repository, after_commit_hash", "label": 0}, {"snippet_id": 88049, "code": "').get(name,[]) rel_classpath_elements=[ os.path.relpath(cpe, buildroot) for cpe in ClasspathUtil.internal_classpath(plugin_target_closure, cp_product, self._confs)] rel_classpath_elements=rel_classpath_elements", "label": 0}, {"snippet_id": 19160, "code": " Validate the request/response cycle of an api call against a swagger schema. Request/Response objects from the `requests` and `urllib` library are supported. \"\"\" request=normalize_request(raw_request)", "label": 0}, {"snippet_id": 34280, "code": "): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self", "label": 0}, {"snippet_id": 74817, "code": "\"blosc_shuffle_mode\"] if isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types: self.blosc_shuffle_mode=blosc_shuffle_mode_int", "label": 0}, {"snippet_id": 10726, "code": ".info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares", "label": 1}, {"snippet_id": 23843, "code": " SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We will sleep and retry as the network must be up. \"\"\" iface='' inet='' mac='' err", "label": 0}, {"snippet_id": 29007, "code": "\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 61473, "code": " len(operation.wires)==2: U=self.expand_two(U, operation.wires) else: raise ValueError('This plugin supports only one-and two-qubit gates.') self._state=U @ self._state A=DefaultQubit._get_operator_matrix", "label": 0}, {"snippet_id": 11931, "code": "\" } }, \"scanner\":{\"diff_only\": False}, \"pycodestyle\":{ \"ignore\":[], \"max-line-length\": 79, \"count\": False, \"first\": False, \"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show-source\": False", "label": 0}, {"snippet_id": 83911, "code": " unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os", "label": 0}, {"snippet_id": 45463, "code": " return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink.", "label": 0}, {"snippet_id": 66084, "code": " jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state", "label": 0}, {"snippet_id": 70372, "code": "[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre", "label": 0}, {"snippet_id": 61569, "code": " not supported by device{}\".format(A.name, cls.short_name)) if not callable(operator_map[A.name]): return operator_map[A.name] p=[x.val if isinstance(x, Variable) else x for x in A.params] return operator_map", "label": 0}, {"snippet_id": 69273, "code": ".print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration", "label": 1}, {"snippet_id": 61193, "code": "*args): r\"\"\"Input validation for an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised array. \"\"\" state=np.asarray(args) return state/np.linalg.norm(state) def unitary(*args", "label": 0}, {"snippet_id": 62785, "code": " keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend", "label": 0}, {"snippet_id": 65690, "code": " other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target", "label": 0}, {"snippet_id": 40137, "code": "(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch", "label": 1}, {"snippet_id": 35341, "code": " values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb", "label": 0}, {"snippet_id": 60935, "code": "[str->Circuit]: circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out @classmethod def capabilities(cls): \"\"\"Get the", "label": 0}, {"snippet_id": 48789, "code": " output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self", "label": 0}, {"snippet_id": 56306, "code": " return False def strip_parameters(request_dict, skip_parameters): parameters={} for key, value in request_dict.items(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters", "label": 0}, {"snippet_id": 24654, "code": "': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low", "label": 0}, {"snippet_id": 7208, "code": "%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms", "label": 0}, {"snippet_id": 36104, "code": ") if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input", "label": 0}, {"snippet_id": 68301, "code": "(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(", "label": 0}, {"snippet_id": 79865, "code": "=parser.add_argument_group('Required named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested", "label": 0}, {"snippet_id": 14904, "code": "._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout", "label": 0}, {"snippet_id": 20647, "code": " self._listenerthread=new_hidden_thread( target=self._listen, name='test.session', ) self._listenerthread.start() @property def is_client(self): return self._conn.is_client @property def received(self)", "label": 0}, {"snippet_id": 46711, "code": " YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys", "label": 0}, {"snippet_id": 78842, "code": ".codeExecUrlPattern=None \t\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host", "label": 0}, {"snippet_id": 51846, "code": "): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone", "label": 0}, {"snippet_id": 59108, "code": " simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler", "label": 0}, {"snippet_id": 85336, "code": ".backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.shader import Shader from pants.backend.jvm.targets.scala_jar_dependency import ScalaJarDependency from pants", "label": 0}, {"snippet_id": 13982, "code": ".5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests", "label": 0}, {"snippet_id": 70067, "code": ".Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self", "label": 0}, {"snippet_id": 29122, "code": " WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times,", "label": 1}, {"snippet_id": 35416, "code": " def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath", "label": 0}, {"snippet_id": 75146, "code": "('Keepalive timeout') else: self.p.log.warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self.p=parent self.p.wz_connect() self.p.wz_auth_requests=[ (b'Router',", "label": 0}, {"snippet_id": 81923, "code": "=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest", "label": 0}, {"snippet_id": 11256, "code": " --targetdir=DIR The generated Icinga monitoring configuration is written into this directory. If no target directory is given its value is read from /etc/monitoring_config_generator/config.yaml --skip", "label": 0}, {"snippet_id": 14409, "code": " self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines", "label": 0}, {"snippet_id": 41576, "code": " b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to", "label": 0}, {"snippet_id": 31474, "code": " import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles", "label": 0}, {"snippet_id": 39109, "code": " immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats,", "label": 0}, {"snippet_id": 62673, "code": " to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice)", "label": 0}, {"snippet_id": 36265, "code": "\"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output", "label": 0}, {"snippet_id": 43064, "code": " name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i", "label": 0}, {"snippet_id": 34825, "code": " contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file", "label": 0}, {"snippet_id": 11180, "code": " current_value): value=None if line.startswith(comment): value=line.rstrip()[len(comment):] return value or current_value try: with open(file_name, 'r') as config_file: for line in config_file.xreadlines", "label": 0}, {"snippet_id": 79029, "code": " folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using", "label": 0}, {"snippet_id": 3624, "code": "(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process terminated but check", "label": 1}, {"snippet_id": 53612, "code": " all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input", "label": 0}, {"snippet_id": 14282, "code": ") self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile", "label": 1}, {"snippet_id": 378, "code": "'loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs':", "label": 0}, {"snippet_id": 55327, "code": ", sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname", "label": 0}, {"snippet_id": 29602, "code": " wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards", "label": 0}, {"snippet_id": 90469, "code": "): self._cache={} self._distribution_environment=distribution_environment self._minimum_version=minimum_version self._maximum_version=maximum_version def _scan_constraint_match(self, minimum_version, maximum_version", "label": 0}, {"snippet_id": 32175, "code": " name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self", "label": 0}, {"snippet_id": 77745, "code": " add_target_exc(t['id'], t['user']) except ValueError: pass def terminate(self): msg=[b'GLOBAL'] msg.extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate',[])) if hasattr(self, 'th_sock'): self.th_sock.send_multipart", "label": 0}, {"snippet_id": 2032, "code": ": i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','", "label": 0}, {"snippet_id": 36932, "code": " name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self", "label": 0}, {"snippet_id": 25576, "code": "=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=", "label": 0}, {"snippet_id": 4681, "code": " out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw", "label": 0}, {"snippet_id": 83940, "code": "\"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(", "label": 0}, {"snippet_id": 86361, "code": " plugin)) ret.append('-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _execute_hermetic_compile(self, cmd, ctx): input_snapshot=ctx.target.sources_snapshot(scheduler=self.context._scheduler", "label": 0}, {"snippet_id": 14506, "code": "(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return", "label": 0}, {"snippet_id": 29156, "code": "=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls", "label": 0}, {"snippet_id": 13943, "code": " _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data", "label": 1}, {"snippet_id": 9006, "code": " acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild", "label": 0}, {"snippet_id": 66959, "code": " cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd", "label": 0}, {"snippet_id": 42494, "code": "=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule", "label": 0}, {"snippet_id": 2204, "code": ":')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name", "label": 0}, {"snippet_id": 75969, "code": " def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Successfull auth for(%s, %s)', i, m) elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError", "label": 1}, {"snippet_id": 57974, "code": ": return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id']=int(request.GET.get('bug_system_id',", "label": 0}, {"snippet_id": 43929, "code": " list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return", "label": 0}, {"snippet_id": 39746, "code": ": ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod", "label": 0}, {"snippet_id": 85358, "code": " ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.base.build_environment import get_buildroot from pants.engine.fs import PathGlobs, PathGlobsAndRoot from pants.java", "label": 1}, {"snippet_id": 3172, "code": ") def start_remote_clone_session(self, comp_name, session_name, hostname): remote_cmd=(\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\"ssh %s 'bash -s' < %s\" %(hostname, remote_cmd) send_main_session_command", "label": 0}, {"snippet_id": 15912, "code": ": return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync", "label": 0}, {"snippet_id": 2941, "code": "])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']", "label": 0}, {"snippet_id": 7290, "code": " for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return:", "label": 0}, {"snippet_id": 61045, "code": "(2): temp=v[:, k] P.append(np.outer(temp.conj(), temp)) return d, P I=np.eye(2) X=np.array([[0, 1],[1, 0]]) Y=np.array([[0, -1j],[1j, 0]]) Z=np.array([[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1", "label": 0}, {"snippet_id": 4243, "code": " input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path", "label": 0}, {"snippet_id": 5677, "code": "'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={", "label": 0}, {"snippet_id": 31108, "code": " the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic,", "label": 0}, {"snippet_id": 85377, "code": ".jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem from pants.util.dirutil import fast_relpath from pants.util.memo import memoized_method, memoized_property class Zinc(object", "label": 1}, {"snippet_id": 55605, "code": " the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames", "label": 0}, {"snippet_id": 65299, "code": "(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options,", "label": 0}, {"snippet_id": 44957, "code": " **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func", "label": 0}, {"snippet_id": 81055, "code": "%s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet", "label": 0}, {"snippet_id": 54718, "code": " of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules", "label": 0}, {"snippet_id": 53397, "code": " input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old)", "label": 0}, {"snippet_id": 45541, "code": " ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode", "label": 0}, {"snippet_id": 16027, "code": "=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num", "label": 0}, {"snippet_id": 94216, "code": " ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader)", "label": 0}, {"snippet_id": 47806, "code": "=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1:", "label": 0}, {"snippet_id": 17773, "code": " current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files'", "label": 0}, {"snippet_id": 90483, "code": " _scan_constraint_match(self, minimum_version, maximum_version, jdk): \"\"\"Finds a cached version matching the specified constraints :param Revision minimum_version: minimum jvm version to look for(eg, 1.7). :param", "label": 0}, {"snippet_id": 13368, "code": "\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file.encode()).decode(\"utf-8", "label": 0}, {"snippet_id": 36772, "code": ", omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False", "label": 0}, {"snippet_id": 54184, "code": " files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for", "label": 0}, {"snippet_id": 8492, "code": " text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W", "label": 1}, {"snippet_id": 21522, "code": " new_links=list(set(new_links)) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x", "label": 1}, {"snippet_id": 80190, "code": "[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0", "label": 0}, {"snippet_id": 35931, "code": "{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search", "label": 0}, {"snippet_id": 9983, "code": " list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches", "label": 0}, {"snippet_id": 31340, "code": ".rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern,", "label": 0}, {"snippet_id": 44561, "code": ":{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources", "label": 0}, {"snippet_id": 77629, "code": "=self.targetsfile if not os.path.isfile(fname): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list was loaded') targets.update(data['targets", "label": 0}, {"snippet_id": 26757, "code": "'min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(", "label": 0}, {"snippet_id": 49966, "code": " nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources", "label": 0}, {"snippet_id": 12833, "code": "(config[\"pycodestyle\"][\"ignore\"]) arg_to_ignore=\"\" if len(to_ignore) > 0: arg_to_ignore=\"--ignore \" +to_ignore for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url", "label": 0}, {"snippet_id": 42234, "code": " s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self", "label": 0}, {"snippet_id": 93705, "code": ".comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component", "label": 0}, {"snippet_id": 65322, "code": " result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes", "label": 0}, {"snippet_id": 23799, "code": " self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout={0}'.format(timeout)) if ret: raise OSUtilError(\"Failed set SCSI disks timeout:{0}\".format", "label": 0}, {"snippet_id": 81445, "code": "(extensions,e))) \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures", "label": 0}, {"snippet_id": 46609, "code": " return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist):", "label": 0}, {"snippet_id": 38289, "code": ".overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile", "label": 0}, {"snippet_id": 51054, "code": " rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re", "label": 1}, {"snippet_id": 43140, "code": ", wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception,", "label": 0}, {"snippet_id": 81318, "code": "[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult", "label": 1}, {"snippet_id": 11530, "code": " for service in yaml_config.services: self.write_section('service', service) def write_line(self, line): self.icinga_lines.append(line) def write_section(self, section_name, section_data): self.write_line", "label": 0}, {"snippet_id": 55975, "code": ", kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True", "label": 0}, {"snippet_id": 671, "code": "], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3", "label": 0}, {"snippet_id": 25105, "code": " more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from", "label": 1}, {"snippet_id": 79508, "code": ".schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif", "label": 1}, {"snippet_id": 56604, "code": "(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_plans=Count('tag", "label": 0}, {"snippet_id": 74456, "code": "(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\"", "label": 0}, {"snippet_id": 31908, "code": " flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True,", "label": 0}, {"snippet_id": 35370, "code": " filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: *", "label": 0}, {"snippet_id": 64255, "code": " self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path() new_version_path=self.path_mapper.remote_version_path_rewrite(version_path) if new_version_path:", "label": 0}, {"snippet_id": 1511, "code": "({\"version_info\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer", "label": 0}, {"snippet_id": 87623, "code": ".sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests) !=len(dependency_classpath):", "label": 1}, {"snippet_id": 83014, "code": "'%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints", "label": 0}, {"snippet_id": 1229, "code": " \"\"\" PRETTY_NAME of your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi", "label": 0}, {"snippet_id": 95170, "code": "=config.read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...", "label": 0}, {"snippet_id": 3694, "code": "\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(", "label": 0}, {"snippet_id": 6208, "code": " an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55", "label": 1}, {"snippet_id": 43410, "code": " get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards", "label": 0}, {"snippet_id": 21997, "code": " self.vault_password_files=vault_password_files self.new_vault_password_file=new_vault_password_file self.output_file=output_file self.tags=tags self.skip_tags=skip_tags self.one_line=one_line self.tree", "label": 0}, {"snippet_id": 8351, "code": " @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is", "label": 0}, {"snippet_id": 40604, "code": "\"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"", "label": 0}, {"snippet_id": 11107, "code": "==other.etag and self.mtime==other.mtime def __repr__(self): return \"Header(%s, %d)\" %(self.etag, self.mtime) def is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self", "label": 0}, {"snippet_id": 11148, "code": " on %s\" %(Header.MON_CONF_GEN_COMMENT, time_string)) if self.etag: lines.append(\"%s%s\" %(Header.ETAG_COMMENT, self.etag)) if self.mtime: lines.append(\"%s%d\" %(Header.MTIME_COMMMENT, self.mtime)) return", "label": 0}, {"snippet_id": 54869, "code": " greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map", "label": 0}, {"snippet_id": 89754, "code": ".home'] if os.path.basename(home)=='jre': jdk_dir=os.path.dirname(home) if self._is_executable(os.path.join(jdk_dir, 'bin', 'javac')): home=jdk_dir self._home=home return self._home @property def real_home", "label": 1}, {"snippet_id": 77377, "code": " self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_", "label": 0}, {"snippet_id": 31058, "code": ": return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException", "label": 0}, {"snippet_id": 73973, "code": " self.alt_number=None elif isint(alt_number_str): self.alt_number=int(alt_number_str) else: raise TypeError(\"Invalid value provided for alt_number in configuration.\\n\" \"Expected: \\\"auto\\\" or integer value", "label": 0}, {"snippet_id": 10057, "code": " fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode", "label": 0}, {"snippet_id": 88051, "code": " rel_classpath_elements=[ os.path.relpath(cpe, buildroot) for cpe in ClasspathUtil.internal_classpath(plugin_target_closure, cp_product, self._confs)] rel_classpath_elements=rel_classpath_elements or[classpath_element", "label": 0}, {"snippet_id": 48282, "code": " self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic", "label": 0}, {"snippet_id": 47799, "code": "=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func", "label": 0}, {"snippet_id": 59583, "code": ": https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq", "label": 0}, {"snippet_id": 43375, "code": " output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile", "label": 0}, {"snippet_id": 66457, "code": " ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr)", "label": 0}, {"snippet_id": 12010, "code": " arguments=[] confs=config[\"pycodestyle\"] for key, value in confs.items(): if value: if isinstance(value, int): if isinstance(value, bool): arguments.append(\"--{}\".format(key)) else: arguments.append(\"--{}={}\"", "label": 0}, {"snippet_id": 36012, "code": "=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards", "label": 0}, {"snippet_id": 45365, "code": "(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod", "label": 0}, {"snippet_id": 71917, "code": " command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self", "label": 0}, {"snippet_id": 34052, "code": " ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args,", "label": 0}, {"snippet_id": 17255, "code": " user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self", "label": 0}, {"snippet_id": 75800, "code": ".running.set() def wz_connect(self): self.wz_sock.connect(self.wz_addr) def wz_wait_reply(self, fun, interface, method, data, reqid=None, timeout=None): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker,", "label": 1}, {"snippet_id": 5918, "code": " module provides method to extract the fulltext from local or remote documents. Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide the functionality of the module", "label": 0}, {"snippet_id": 55121, "code": " return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list", "label": 0}, {"snippet_id": 78614, "code": " import logging import pdb import urllib2 import json import ijson from dbnav.writer import Writer from dbnav import logger as log from dbnav.jsonable import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec'", "label": 0}, {"snippet_id": 15316, "code": ", '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options", "label": 0}, {"snippet_id": 90970, "code": "', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating", "label": 0}, {"snippet_id": 59484, "code": "._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation", "label": 0}, {"snippet_id": 59339, "code": " IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running", "label": 0}, {"snippet_id": 16862, "code": ".server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object", "label": 0}, {"snippet_id": 64076, "code": " the datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def", "label": 0}, {"snippet_id": 91819, "code": ", stdout=result.stdout.decode('utf-8'), stderr=result.stderr.decode('utf-8'), ) def rules(): return[ run_python_test, UnionRule(TestTarget, PythonTestsAdaptor), optionable_rule(PyTest), optionable_rule", "label": 0}, {"snippet_id": 7035, "code": " routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite", "label": 0}, {"snippet_id": 15208, "code": "=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart", "label": 0}, {"snippet_id": 83731, "code": ".from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs", "label": 0}, {"snippet_id": 69405, "code": "% self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs", "label": 0}, {"snippet_id": 70720, "code": "(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs)", "label": 1}, {"snippet_id": 56402, "code": " try: self.product_id=int(product_id) except(ValueError, TypeError): self.product_id=0 def builds(self): try: is_active=strtobool(self.request.GET.get('is_active', default='False')) except(ValueError, TypeError", "label": 0}, {"snippet_id": 55523, "code": " include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile,", "label": 0}, {"snippet_id": 70002, "code": " servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import", "label": 0}, {"snippet_id": 34025, "code": ".set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params", "label": 0}, {"snippet_id": 71950, "code": ".nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError,", "label": 0}, {"snippet_id": 12606, "code": ".get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body\"] break \"\"\" text1=''.join(BeautifulSoup", "label": 0}, {"snippet_id": 44915, "code": " RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)):", "label": 0}, {"snippet_id": 60123, "code": " expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2", "label": 0}, {"snippet_id": 4175, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): ", "label": 0}, {"snippet_id": 33806, "code": ".stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile", "label": 0}, {"snippet_id": 95989, "code": ": print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH", "label": 0}, {"snippet_id": 15425, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self):", "label": 0}, {"snippet_id": 92058, "code": " boolean value indicating whether the current target closure has native sources. :raises::class:`pants.base.exceptions.IncompatiblePlatformsError` \"\"\" if not self._any_targets_have_native_sources(targets)", "label": 0}, {"snippet_id": 20642, "code": " else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread( target=self._listen, name='test.session', ) self._listenerthread.start() @property def is_client(self): return", "label": 0}, {"snippet_id": 81204, "code": " use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern", "label": 0}, {"snippet_id": 42163, "code": ", other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list", "label": 0}, {"snippet_id": 63182, "code": "): job_destination=job_wrapper.job_destination command_line, client, remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if not command_line: return try: dependencies_description", "label": 0}, {"snippet_id": 94999, "code": " file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of", "label": 0}, {"snippet_id": 5312, "code": "\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n'", "label": 0}, {"snippet_id": 61108, "code": "-1j * theta/2 * X) def fry(theta): r\"\"\"One-qubit rotation about the y axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm", "label": 0}, {"snippet_id": 27991, "code": "['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status", "label": 0}, {"snippet_id": 65462, "code": " def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target", "label": 0}, {"snippet_id": 70786, "code": ".state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else", "label": 0}, {"snippet_id": 17555, "code": "._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file", "label": 0}, {"snippet_id": 89663, "code": "\"Looks for jars in the distribution lib folder(s). If the distribution is a JDK, both the `lib` and `jre/lib` dirs will be scanned. The endorsed and extension dirs are not checked. :param list names: jar", "label": 0}, {"snippet_id": 53968, "code": " concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e:", "label": 0}, {"snippet_id": 52979, "code": ", other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None", "label": 0}, {"snippet_id": 25465, "code": " the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor", "label": 0}, {"snippet_id": 91719, "code": ", 'sources'): tgt_snapshot=maybe_source_target.sources.snapshot tgt_source_root=source_roots.find_by_path(maybe_source_target.address.spec_path) sources_snapshots_and_source_roots.append((tgt_snapshot,", "label": 0}, {"snippet_id": 33663, "code": "*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag", "label": 0}, {"snippet_id": 54551, "code": "(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict()", "label": 0}, {"snippet_id": 28734, "code": "'battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp", "label": 0}, {"snippet_id": 62370, "code": " _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend=='Simulator'", "label": 0}, {"snippet_id": 8798, "code": " text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines", "label": 0}, {"snippet_id": 36295, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all", "label": 1}, {"snippet_id": 37742, "code": "(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance", "label": 0}, {"snippet_id": 66170, "code": " if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\"", "label": 0}, {"snippet_id": 86579, "code": ".getLogger(__name__) class BaseZincCompile(JvmCompile): \"\"\"An abstract base class for zinc compilation tasks.\"\"\" _name='zinc' @staticmethod def _write_scalac_plugin_info(resources_dir, scalac_plugin_target)", "label": 1}, {"snippet_id": 88171, "code": " closing(jarfile.open(_SCALAC_PLUGIN_INFO_FILE, 'r')) as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile", "label": 0}, {"snippet_id": 42892, "code": "\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self", "label": 0}, {"snippet_id": 18849, "code": ".context_managers import ErrorDict from flex.exceptions import ValidationError from flex.loading.definitions import( definitions_validator, ) from flex.loading.schema import( swagger_schema_validator, )", "label": 0}, {"snippet_id": 50124, "code": " workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self", "label": 0}, {"snippet_id": 28424, "code": ") self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement", "label": 0}, {"snippet_id": 95849, "code": " Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation", "label": 0}, {"snippet_id": 65397, "code": ".Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable", "label": 0}, {"snippet_id": 41544, "code": ".dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output", "label": 0}, {"snippet_id": 16744, "code": " _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self", "label": 0}, {"snippet_id": 69584, "code": " new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError(opt) command.parse(new_args", "label": 0}, {"snippet_id": 37004, "code": " self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params", "label": 0}, {"snippet_id": 26755, "code": "'min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state", "label": 0}, {"snippet_id": 1791, "code": "'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute", "label": 0}, {"snippet_id": 66111, "code": " target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target", "label": 0}, {"snippet_id": 21166, "code": ": message='Timeout waiting for ' if isinstance(self, AwaitableEvent): message +='Event{}'.format(self.name) else: message +='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse", "label": 0}, {"snippet_id": 44793, "code": "(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir)", "label": 0}, {"snippet_id": 45998, "code": " value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags", "label": 1}, {"snippet_id": 33887, "code": " first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]", "label": 0}, {"snippet_id": 68722, "code": " target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag()", "label": 0}, {"snippet_id": 18756, "code": ".add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory", "label": 0}, {"snippet_id": 47371, "code": " omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark", "label": 0}, {"snippet_id": 5422, "code": " acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out", "label": 0}, {"snippet_id": 22187, "code": "=template.render( data) return outputText def run(self, state, data=None, context=None): \"\"\"Run ansible-playbook on the specified playbook. \"\"\" playbook=None log_file=None template=None if state in self", "label": 0}, {"snippet_id": 59896, "code": "]='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum", "label": 0}, {"snippet_id": 94508, "code": ".debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return", "label": 0}, {"snippet_id": 92354, "code": " output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**{}): self.assertNotIn('USER', os.environ) def test_hermetic_environment_subprocesses", "label": 1}, {"snippet_id": 10010, "code": " matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the", "label": 0}, {"snippet_id": 76770, "code": ".add_argument('--caprate_limit', type=float, default=0.8, help='Captcha rate limit') parser.add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser.add_argument", "label": 0}, {"snippet_id": 57226, "code": " object_pk=object_pk, ) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun", "label": 0}, {"snippet_id": 87320, "code": " lazily computed by zinc if the appropriate version does not exist. Eventually it would be great to just fetch this rather than compiling it. \"\"\" hasher=sha1() for cp_entry in[self._zinc.zinc, self._zinc", "label": 1}, {"snippet_id": 28107, "code": ".io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS", "label": 1}, {"snippet_id": 88091, "code": " return active_plugins unresolved_plugins=plugin_names -set(active_plugins.keys()) raise TaskError('Could not find requested plugins:{}'.format(list(unresolved_plugins))) @classmethod @memoized_method def", "label": 0}, {"snippet_id": 32943, "code": ".overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return(", "label": 0}, {"snippet_id": 94646, "code": " clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main", "label": 0}, {"snippet_id": 28385, "code": "(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"", "label": 0}, {"snippet_id": 78913, "code": ") \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself", "label": 0}, {"snippet_id": 40482, "code": "=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError", "label": 0}, {"snippet_id": 58501, "code": " 'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url", "label": 0}, {"snippet_id": 95869, "code": "(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(\"**/*.vcf\") for path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str", "label": 0}, {"snippet_id": 9341, "code": " dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen", "label": 0}, {"snippet_id": 68948, "code": " def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def", "label": 0}, {"snippet_id": 44486, "code": ")) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler", "label": 0}, {"snippet_id": 27763, "code": ".type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(", "label": 0}, {"snippet_id": 15343, "code": "'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'", "label": 0}, {"snippet_id": 28844, "code": "=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value", "label": 0}, {"snippet_id": 93177, "code": "%(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components", "label": 0}, {"snippet_id": 35609, "code": " the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self", "label": 0}, {"snippet_id": 80788, "code": ",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor", "label": 1}, {"snippet_id": 79618, "code": ")s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()", "label": 0}, {"snippet_id": 14077, "code": ".status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler): return urlparse", "label": 0}, {"snippet_id": 42812, "code": " item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item", "label": 0}, {"snippet_id": 85217, "code": " elif name.endswith(self.version): raise ValueError('The name \"{0}\" should not be suffixed with the scala platform version ' '({1}): it will be added automatically.'.format(name, self.version)) return ", "label": 0}, {"snippet_id": 53628, "code": " item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput", "label": 0}, {"snippet_id": 92888, "code": ": return '{} stdin_data=u('stdio') stdout_data=u('stdout') stderr_data=u('stderr') with temporary_file(binary_mode=False) as tmp_stdin,\\ temporary_file(binary_mode=False) as tmp_stdout,\\ temporary_file", "label": 0}, {"snippet_id": 35917, "code": ": \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat", "label": 0}, {"snippet_id": 18103, "code": " return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']", "label": 0}, {"snippet_id": 74184, "code": " object representation of the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\"", "label": 0}, {"snippet_id": 79152, "code": ".postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") ", "label": 0}, {"snippet_id": 93368, "code": ".run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for", "label": 0}, {"snippet_id": 89524, "code": " modified semantic version string or else a Revision object :param maximum_version: a modified semantic version string or else a Revision object :param bool jdk: ``True`` to require the distribution be", "label": 0}, {"snippet_id": 45132, "code": "(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return", "label": 0}, {"snippet_id": 80318, "code": " known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided", "label": 0}, {"snippet_id": 59295, "code": " IBMBackend backend: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose", "label": 0}, {"snippet_id": 65176, "code": "%(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" ", "label": 0}, {"snippet_id": 84535, "code": ", print_function, unicode_literals import os from builtins import open from future.utils import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants.base.workunit", "label": 0}, {"snippet_id": 91624, "code": ".adaptor for t in transitive_hydrated_targets.closure] all_target_requirements=[] for maybe_python_req_lib in all_targets: if hasattr(maybe_python_req_lib, 'requirement'): all_target_requirements.append(str", "label": 0}, {"snippet_id": 38484, "code": ": raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse", "label": 0}, {"snippet_id": 92036, "code": "\"\" Performs a check of whether the current target closure has native sources and if so, ensures that Pants is only targeting the current platform. :param tgts: a list of:class:`Target` objects. :return", "label": 0}, {"snippet_id": 35942, "code": ", Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import", "label": 0}, {"snippet_id": 32844, "code": " def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False", "label": 0}, {"snippet_id": 62517, "code": " super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its", "label": 0}, {"snippet_id": 31247, "code": ", rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name", "label": 0}, {"snippet_id": 53144, "code": ", Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__", "label": 0}, {"snippet_id": 93753, "code": ") if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp", "label": 0}, {"snippet_id": 20769, "code": "'event' and msg.event==event handlername='event{!r}'.format(event) with self._wait_for_message(match, handlername, **kwargs): yield result def get_awaiter_for_event(self, event, condition=lambda msg: True, ", "label": 0}, {"snippet_id": 60626, "code": ".name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map", "label": 0}, {"snippet_id": 24389, "code": " in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices", "label": 0}, {"snippet_id": 69129, "code": ".ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs", "label": 0}, {"snippet_id": 79460, "code": " uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t", "label": 0}, {"snippet_id": 71142, "code": " View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False", "label": 0}, {"snippet_id": 23750, "code": ".format(output)) try: return int(output)/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(", "label": 0}, {"snippet_id": 74091, "code": "=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for", "label": 0}, {"snippet_id": 46249, "code": " values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]", "label": 0}, {"snippet_id": 50011, "code": " resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule", "label": 0}, {"snippet_id": 71844, "code": ".Globals import Globals from Shine.Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file", "label": 0}, {"snippet_id": 57422, "code": ")) class ModelUpdateActions(object): \"\"\"Abstract class defining interfaces to update a model properties\"\"\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each possible proprety of", "label": 0}, {"snippet_id": 17362, "code": "._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost", "label": 0}, {"snippet_id": 20576, "code": " addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_client( addr, timeout=kwargs.get('timeout'), ) return cls(conn, owned=True, **kwargs) @classmethod def create_server(cls, addr=None, **kwargs):", "label": 0}, {"snippet_id": 58184, "code": " for k in p_pks.split(sep) if k] res=get_prod_related_objs(p_pks, target) else: res=[] return HttpResponse(json.dumps(res)) def objects_update(objects, **kwargs): objects.update(**kwargs) kwargs['instances", "label": 0}, {"snippet_id": 631, "code": "} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW", "label": 0}, {"snippet_id": 25845, "code": "'WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state", "label": 0}, {"snippet_id": 47467, "code": " return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule", "label": 0}, {"snippet_id": 58339, "code": "=self.client.get(reverse('iframe-navigation')) self.assertContains(response, urlencode({'people': self.user.email})) self.assertContains(response, urlencode({'author__email__startswith': self.user.email}", "label": 0}, {"snippet_id": 90631, "code": "): version_a=_parse_java_version(name, a) version_b=_parse_java_version(name, b) if version_a is None: return version_b if version_b is None: return version_a return stricter(version_a, version_b) minimum_version", "label": 0}, {"snippet_id": 89202, "code": " returned build graph. :API: public :param string root: The path to scan; by default, the build root. :returns: A new build graph encapsulating the targets found. \"\"\" build_graph=self.build_graph.clone_new", "label": 0}, {"snippet_id": 18250, "code": "=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None", "label": 0}, {"snippet_id": 94897, "code": " import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the", "label": 1}, {"snippet_id": 50934, "code": "(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file):", "label": 0}, {"snippet_id": 42473, "code": ".resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile", "label": 0}, {"snippet_id": 30376, "code": "): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class", "label": 0}, {"snippet_id": 94734, "code": " the --config argument\") subparser_remote=subparsers.add_parser('slave', help=\"Run a component locally without controlling it. The \" \"control is taken care of the remote master invoking \" \"this command", "label": 0}, {"snippet_id": 20237, "code": "'.format( self._connecttimeout) if self._run_server_ex is None: raise Exception(message) else: message=message +os.linesep +self._run_server_ex raise Exception(message) self._launch( argv, script=script", "label": 0}, {"snippet_id": 82024, "code": " dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\",", "label": 0}, {"snippet_id": 33744, "code": "\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job", "label": 0}, {"snippet_id": 2708, "code": " ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh ", "label": 0}, {"snippet_id": 52172, "code": ")$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None:", "label": 0}, {"snippet_id": 80290, "code": "-%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s", "label": 0}, {"snippet_id": 26504, "code": "\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data", "label": 0}, {"snippet_id": 54067, "code": ")) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict(", "label": 0}, {"snippet_id": 63447, "code": "): input_paths=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"", "label": 0}, {"snippet_id": 93699, "code": " '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name", "label": 0}, {"snippet_id": 80532, "code": ": \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds[\"username", "label": 0}, {"snippet_id": 41101, "code": ", getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self", "label": 0}, {"snippet_id": 61011, "code": " spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian projectors such", "label": 0}, {"snippet_id": 68340, "code": " AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True)", "label": 0}, {"snippet_id": 90147, "code": "._validated_binaries[name]=exe def __repr__(self): return('Distribution({!r}, minimum_version={!r}, maximum_version={!r} jdk={!r})'.format( self._bin_path, self._minimum_version, self._maximum_version,", "label": 0}, {"snippet_id": 22252, "code": "'log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template(template, data) ) runner=Runner(playbook=playbook, verbosity=0) stats", "label": 0}, {"snippet_id": 93725, "code": ") if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting", "label": 0}, {"snippet_id": 62691, "code": " ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM", "label": 0}, {"snippet_id": 76231, "code": " return self.wz_wait_reply(accept, *self.wz.make_auth_unbind_route_data(i, m, wzauth_data.bind_route[i, m])) def clear_auth(self): self.log.debug('Clearing our auth records') def accept(that, reqid, seqnum,", "label": 0}, {"snippet_id": 50990, "code": ", None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile", "label": 1}, {"snippet_id": 36930, "code": " Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output", "label": 0}, {"snippet_id": 93224, "code": " def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile", "label": 0}, {"snippet_id": 68911, "code": ".Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils", "label": 0}, {"snippet_id": 58967, "code": "('P3', TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view method\"\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData", "label": 0}, {"snippet_id": 86197, "code": ", ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format(distribution.home))", "label": 0}, {"snippet_id": 43820, "code": "\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException", "label": 0}, {"snippet_id": 10185, "code": " ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={}", "label": 0}, {"snippet_id": 19521, "code": " range(len(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except IndexError: nextarg=None if gottarget: script=argv[i:] +script break if arg=='--client': arg='--host' elif arg==", "label": 0}, {"snippet_id": 2214, "code": "':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name)", "label": 0}, {"snippet_id": 26128, "code": " import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers", "label": 1}, {"snippet_id": 41245, "code": ": try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML", "label": 0}, {"snippet_id": 74340, "code": " import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str", "label": 0}, {"snippet_id": 83006, "code": ": \t\t\t\t\tfoundEntryPoint=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound", "label": 0}, {"snippet_id": 92860, "code": ".name)): next(open_zip(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness to replace `sys.std*` with tempfiles. Validates that all files are read/written/flushed correctly, and", "label": 0}, {"snippet_id": 46159, "code": "): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value)", "label": 0}, {"snippet_id": 43354, "code": " be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the", "label": 0}, {"snippet_id": 86722, "code": ":param settings: The jvm platform settings from which to extract the arguments. :type settings::class:`JvmPlatformSettings` \"\"\" zinc_args=[ '-C-source', '-C{}'.format(settings.source_level), '-C-target", "label": 0}, {"snippet_id": 28682, "code": " and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 5724, "code": " many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite", "label": 0}, {"snippet_id": 83894, "code": ") if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid", "label": 0}, {"snippet_id": 82630, "code": "\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor", "label": 0}, {"snippet_id": 67133, "code": " install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:", "label": 0}, {"snippet_id": 49490, "code": "(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list(", "label": 0}, {"snippet_id": 70182, "code": " (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1):", "label": 0}, {"snippet_id": 85461, "code": ".exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-compiler_2.11', '0.0.7'),", "label": 1}, {"snippet_id": 95056, "code": "\"./data/input/\" download_directory=input_directory +\"download/\" temp_directory=\"./data/temp/\" vcf_directory=\"./data/vcf/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark", "label": 1}, {"snippet_id": 57418, "code": " 0, 'response': 'ok'})) class ModelUpdateActions(object): \"\"\"Abstract class defining interfaces to update a model properties\"\"\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each", "label": 0}, {"snippet_id": 43765, "code": " config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values", "label": 0}, {"snippet_id": 90994, "code": " same OS can be specified via several different ' 'aliases, according to this map:{}'.format(human_readable_os_aliases)) register('--minimum-version', advanced=True, help='Minimum version of the JVM pants", "label": 0}, {"snippet_id": 8110, "code": "(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir", "label": 0}, {"snippet_id": 72680, "code": " local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled. Skipping FTP download...\") data_service.process_data_files(input_dir=input_directory, temp_dir=temp_directory, output_dir", "label": 1}, {"snippet_id": 69976, "code": ") self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals", "label": 0}, {"snippet_id": 55519, "code": " logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code", "label": 0}, {"snippet_id": 86185, "code": "=['{}/bin/javac'.format(distribution.real_home)] javac_cmd.extend([ '-classpath', ':'.join(classpath), ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args):", "label": 0}, {"snippet_id": 76290, "code": " f) def unbind_methods(self): for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid", "label": 0}, {"snippet_id": 14358, "code": "=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles", "label": 0}, {"snippet_id": 71766, "code": "): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self", "label": 0}, {"snippet_id": 21582, "code": " 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove(link) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle", "label": 0}, {"snippet_id": 44593, "code": ")) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger", "label": 0}, {"snippet_id": 77828, "code": ".tcount > 0: self.pc=ProcessContext(self.p.name, self.p.ctx, self.c.router_addr, noproxy_rp) self.spawnqueue=Queue() self.load_bumplimit_set() self.load_targets() self.load_users() self.spawn_wipethreads", "label": 0}, {"snippet_id": 26939, "code": " data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state", "label": 0}, {"snippet_id": 43937, "code": " rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False", "label": 0}, {"snippet_id": 66020, "code": ") layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes", "label": 0}, {"snippet_id": 47713, "code": " import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles", "label": 0}, {"snippet_id": 73211, "code": " subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files,", "label": 0}, {"snippet_id": 68525, "code": " c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes", "label": 0}, {"snippet_id": 30675, "code": ".touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f", "label": 0}, {"snippet_id": 78092, "code": "]', user, forum, domain) forums[domain].remove((user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login': login, 'passwd': passwd}, False) def send_to_wm(frames): msg", "label": 0}, {"snippet_id": 14532, "code": " FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 53879, "code": " kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str", "label": 0}, {"snippet_id": 73549, "code": "\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr", "label": 0}, {"snippet_id": 38557, "code": " forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None,", "label": 0}, {"snippet_id": 20492, "code": "=sock self._ownsock=ownsock @property def is_client(self): try: return self._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError('connection", "label": 0}, {"snippet_id": 70019, "code": " from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine", "label": 0}, {"snippet_id": 29171, "code": " file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self", "label": 0}, {"snippet_id": 91110, "code": " .format(os_name)) return self._normalized_jdk_paths.get(os_name,()) def _create_locator(self): homes=self._get_explicit_jdk_paths() environment=_UnknownEnvironment( _ExplicitEnvironment(*homes), _UnknownEnvironment", "label": 0}, {"snippet_id": 48664, "code": ".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards", "label": 0}, {"snippet_id": 91788, "code": ".interpreter_search_paths))}, input_files=merged_input_files, description='Run pytest for{}'.format(test_target.address.reference()), ) result=yield Get(FallibleExecuteProcessResult, ExecuteProcessRequest, request", "label": 0}, {"snippet_id": 67697, "code": "\"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed", "label": 0}, {"snippet_id": 11493, "code": " header_source) self.write_output(file_name, yaml_icinga) if file_name: LOG.info(\"Icinga config file '%s' created.\" % file_name) return file_name class YamlToIcinga(object): def __init__(self, yaml_config, header", "label": 0}, {"snippet_id": 70251, "code": " succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s):", "label": 0}, {"snippet_id": 63470, "code": ".task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env=getattr(", "label": 0}, {"snippet_id": 71228, "code": "%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev", "label": 0}, {"snippet_id": 87321, "code": " zinc if the appropriate version does not exist. Eventually it would be great to just fetch this rather than compiling it. \"\"\" hasher=sha1() for cp_entry in[self._zinc.zinc, self._zinc.compiler_interface", "label": 1}, {"snippet_id": 12592, "code": ".com/repos/{}/issues/{}/comments\" url=url.format(repository, str(data[\"pr_number\"])) comments=requests.get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments):", "label": 0}, {"snippet_id": 65187, "code": " if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\"", "label": 0}, {"snippet_id": 24140, "code": ") from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules'", "label": 1}, {"snippet_id": 94004, "code": " def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[]", "label": 0}, {"snippet_id": 81319, "code": "\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True", "label": 1}, {"snippet_id": 13805, "code": "-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals", "label": 0}, {"snippet_id": 86866, "code": "-S-Xfatal-warnings', '-C-Werror') @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super(BaseZincCompile, cls).register_options", "label": 0}, {"snippet_id": 51871, "code": " name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names):", "label": 0}, {"snippet_id": 2600, "code": "'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep])", "label": 0}, {"snippet_id": 38591, "code": " ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats", "label": 0}, {"snippet_id": 20855, "code": " result['msg']=msg return msg.request_seq==seq handlername='response(cmd:{} seq:{})'.format(command, seq) evt=self._get_message_handle(match, handlername) return AwaitableResponse(req, lambda: result[\"msg\"],", "label": 0}, {"snippet_id": 6319, "code": " %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists", "label": 1}, {"snippet_id": 67556, "code": ".target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s", "label": 0}, {"snippet_id": 86695, "code": " @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform settings. This is responsible for the symbol substitution which replaces $JAVA_HOME with the", "label": 0}, {"snippet_id": 64166, "code": "=remote_system_properties.get('galaxy_dataset_files_path', None) if LwrJobRunner.__use_remote_datatypes_conf( client): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file", "label": 0}, {"snippet_id": 9723, "code": "=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results", "label": 0}, {"snippet_id": 47460, "code": ".version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError", "label": 0}, {"snippet_id": 41132, "code": ", getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i ", "label": 0}, {"snippet_id": 89512, "code": " string bin_path: the path to the java distribution's bin dir :param minimum_version: a modified semantic version string or else a Revision object :param maximum_version: a modified semantic version string", "label": 0}, {"snippet_id": 49767, "code": "\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and", "label": 0}, {"snippet_id": 35407, "code": "\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with", "label": 0}, {"snippet_id": 25408, "code": " add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'", "label": 0}, {"snippet_id": 71806, "code": " self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print", "label": 1}, {"snippet_id": 2058, "code": "\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False", "label": 0}, {"snippet_id": 3847, "code": "(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser", "label": 0}, {"snippet_id": 6574, "code": " source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode", "label": 0}, {"snippet_id": 39268, "code": ".dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile", "label": 0}, {"snippet_id": 68885, "code": "\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict", "label": 0}, {"snippet_id": 79303, "code": " \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t", "label": 0}, {"snippet_id": 15091, "code": " handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get(", "label": 1}, {"snippet_id": 43291, "code": " o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_", "label": 0}, {"snippet_id": 3871, "code": "\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser", "label": 0}, {"snippet_id": 27540, "code": ": self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1", "label": 0}, {"snippet_id": 68654, "code": ".state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\"", "label": 0}, {"snippet_id": 9444, "code": " author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left", "label": 0}, {"snippet_id": 48982, "code": " comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def", "label": 0}, {"snippet_id": 73480, "code": ":param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion :type input_vcf_path: str :type", "label": 0}, {"snippet_id": 93828, "code": " start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd", "label": 0}, {"snippet_id": 54147, "code": " wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies", "label": 0}, {"snippet_id": 37980, "code": "(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards", "label": 0}, {"snippet_id": 46092, "code": ")) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand", "label": 0}, {"snippet_id": 55415, "code": ".resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to", "label": 0}, {"snippet_id": 44995, "code": ".func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, ", "label": 0}, {"snippet_id": 54243, "code": "\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 66960, "code": " in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self", "label": 0}, {"snippet_id": 9651, "code": "(acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2,", "label": 0}, {"snippet_id": 11740, "code": ", now());\" \\ \"\".format(repository) try: cursor.execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def follow_user(user): \"\"\"Follow the user of the service\"\"\" headers={ \"Authorization", "label": 0}, {"snippet_id": 39199, "code": " dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler", "label": 0}, {"snippet_id": 66047, "code": " AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View", "label": 0}, {"snippet_id": 69138, "code": " ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import", "label": 0}, {"snippet_id": 80622, "code": " and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath", "label": 0}, {"snippet_id": 18866, "code": " from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request, normalize_response, ) from flex.validation.common import", "label": 0}, {"snippet_id": 30193, "code": " end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist", "label": 0}, {"snippet_id": 58416, "code": "(TestCommentCaseRuns, cls).setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs') def test_refuse_if_missing_comment(self): self.client.login( username=self.tester.username, password='password", "label": 0}, {"snippet_id": 44976, "code": "=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func", "label": 0}, {"snippet_id": 62528, "code": " backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend", "label": 0}, {"snippet_id": 75094, "code": ".handle_keepalive_reply) msg.insert(0, b'') self.p.wz_sock.send_multipart(msg) def handle_keepalive_reply(self, reqid, seqnum, status, data): if status==wzrpc.status.success: self.p.log.debug('Keepalive was successfull", "label": 0}, {"snippet_id": 29766, "code": " or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary", "label": 0}, {"snippet_id": 16628, "code": " qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList", "label": 0}, {"snippet_id": 63380, "code": "=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '',", "label": 0}, {"snippet_id": 16156, "code": " from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm", "label": 0}, {"snippet_id": 86429, "code": ", unicode_literals import errno import logging import os import re import textwrap from builtins import open from collections import defaultdict from contextlib import closing from hashlib import sha1 from", "label": 1}, {"snippet_id": 83908, "code": " no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return", "label": 0}, {"snippet_id": 26325, "code": " discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try", "label": 1}, {"snippet_id": 8765, "code": ", with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms ) if api: return output else: if isinstance(output, dict): for", "label": 0}, {"snippet_id": 67317, "code": " MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self", "label": 0}, {"snippet_id": 45749, "code": ".info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format", "label": 0}, {"snippet_id": 32697, "code": ".name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare", "label": 0}, {"snippet_id": 26603, "code": "'battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self", "label": 0}, {"snippet_id": 48554, "code": ", concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException)", "label": 0}, {"snippet_id": 27020, "code": "='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state", "label": 0}, {"snippet_id": 37028, "code": ") self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other", "label": 0}, {"snippet_id": 37404, "code": " output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile", "label": 0}, {"snippet_id": 63637, "code": "(\"failure finishing job %d\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish", "label": 0}, {"snippet_id": 19699, "code": "'server_host', None) clienthost=ns.pop('host', None) if serverhost: args.address=Address.as_server(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost", "label": 0}, {"snippet_id": 22282, "code": " azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger as logger import azurelinuxagent.utils.shellutil", "label": 0}, {"snippet_id": 36363, "code": " \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output", "label": 0}, {"snippet_id": 24879, "code": "=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data[", "label": 0}, {"snippet_id": 42166, "code": ".rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern,", "label": 0}, {"snippet_id": 68574, "code": " AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable()", "label": 0}, {"snippet_id": 75988, "code": " beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3}'.\\ format(i, m, wzrpc.name_status(status), repr(data))) elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])", "label": 1}, {"snippet_id": 2928, "code": " break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState", "label": 0}, {"snippet_id": 68124, "code": " nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view()", "label": 0}, {"snippet_id": 582, "code": "(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor", "label": 0}, {"snippet_id": 17047, "code": " filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response", "label": 0}, {"snippet_id": 34683, "code": ", self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self", "label": 0}, {"snippet_id": 34408, "code": " def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow", "label": 0}, {"snippet_id": 57250, "code": "='case_run_status': for t in targets: field='close_date' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), now ) ) if t.tested_by !=request.user: field", "label": 0}, {"snippet_id": 6903, "code": " or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return:", "label": 0}, {"snippet_id": 598, "code": "=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART", "label": 0}, {"snippet_id": 19673, "code": ".add_argument('filename', nargs='?') parser.add_argument('--single-session', action='store_true') parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns", "label": 0}, {"snippet_id": 22748, "code": " crypt_id=6, salt_len=10): \"\"\"Change a user's password with tmsh Since we are creating the user specified account and additionally changing the password of the built-in 'admin' account, both must be modified", "label": 0}, {"snippet_id": 240, "code": ", wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev", "label": 0}, {"snippet_id": 34197, "code": " ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params", "label": 0}, {"snippet_id": 86107, "code": ", _PROCESSOR_INFO_FILE) self._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f", "label": 0}, {"snippet_id": 4879, "code": ", output_limit))) else: my_styles[\"raw\"]=(single_keywords_p, composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords", "label": 0}, {"snippet_id": 30844, "code": " RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\"", "label": 0}, {"snippet_id": 86738, "code": "-C-target', '-C{}'.format(settings.target_level), ] if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): try: distribution=JvmPlatform.preferred_jvm_distribution", "label": 0}, {"snippet_id": 65805, "code": ".set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS", "label": 0}, {"snippet_id": 51899, "code": " given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name", "label": 0}, {"snippet_id": 7205, "code": "'<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords", "label": 0}, {"snippet_id": 86004, "code": " register_options(cls, register): super(JavacCompile, cls).register_options(register) @classmethod def subsystem_dependencies(cls): return super(JavacCompile, cls).subsystem_dependencies() +(JvmPlatform,)", "label": 0}, {"snippet_id": 70829, "code": " target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 87425, "code": "(compiler_bridge) analysis_cache=relative_to_exec_root(analysis_cache) classes_dir=relative_to_exec_root(classes_dir) relative_classpath=tuple(relative_to_exec_root(c) for c in absolute_classpath) zinc_args", "label": 1}, {"snippet_id": 17802, "code": " extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os", "label": 0}, {"snippet_id": 34088, "code": " RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority", "label": 0}, {"snippet_id": 76895, "code": ".signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net=sup.net.RequestPerformer() net.proxy=proxy if proxytype=='HTTP' or proxytype=='HTTPS': net.proxy_type=sup.proxytype.http elif", "label": 0}, {"snippet_id": 3582, "code": " check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for", "label": 0}, {"snippet_id": 75810, "code": " reqid=None, timeout=None): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=timeout if timeout else self.wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface", "label": 1}, {"snippet_id": 72777, "code": " static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import", "label": 0}, {"snippet_id": 57053, "code": "=pipe(val) except Exception as e: error=str(e) return value, error def say_no(error_msg): ajax_response={'rc': 1, 'response': error_msg} return HttpResponse(json.dumps(ajax_response)) def say_yes(): return", "label": 0}, {"snippet_id": 74516, "code": " runtime_config.ftp: self.server=runtime_config.ftp[\"server\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config", "label": 0}, {"snippet_id": 44946, "code": " rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo", "label": 0}, {"snippet_id": 68045, "code": " %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__", "label": 0}, {"snippet_id": 18115, "code": " _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'", "label": 0}, {"snippet_id": 91789, "code": ".interpreter_search_paths))}, input_files=merged_input_files, description='Run pytest for{}'.format(test_target.address.reference()), ) result=yield Get(FallibleExecuteProcessResult, ExecuteProcessRequest, request) status", "label": 0}, {"snippet_id": 18454, "code": " force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest", "label": 0}, {"snippet_id": 59102, "code": " and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends", "label": 0}, {"snippet_id": 73472, "code": " original data(VCF) to a Zarr format. Only converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config", "label": 0}, {"snippet_id": 21702, "code": " j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt.title('Classifier(Training set)') plt.xlabel('Age') plt.ylabel", "label": 0}, {"snippet_id": 38090, "code": ", rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self", "label": 0}, {"snippet_id": 81764, "code": ")s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()", "label": 0}, {"snippet_id": 30885, "code": ".dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output", "label": 1}, {"snippet_id": 82997, "code": ".result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint", "label": 0}, {"snippet_id": 63779, "code": " os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2", "label": 0}, {"snippet_id": 14273, "code": "=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer", "label": 1}, {"snippet_id": 66790, "code": " action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes", "label": 0}, {"snippet_id": 55488, "code": " overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack", "label": 0}, {"snippet_id": 72032, "code": " a network disconnected using this command, use REHASH to reload the networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects", "label": 0}, {"snippet_id": 37200, "code": " values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards", "label": 0}, {"snippet_id": 1766, "code": ".execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data=", "label": 0}, {"snippet_id": 67141, "code": "%s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"", "label": 0}, {"snippet_id": 50685, "code": " os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths", "label": 0}, {"snippet_id": 7696, "code": " acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={}", "label": 0}, {"snippet_id": 71921, "code": "\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self", "label": 0}, {"snippet_id": 65910, "code": "(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0:", "label": 0}, {"snippet_id": 56438, "code": ".objects.filter(product__id=self.product_id) def components(self): return Component.objects.filter(product__id=self.product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties(self)", "label": 0}, {"snippet_id": 38240, "code": ", expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath", "label": 1}, {"snippet_id": 61743, "code": "!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any", "label": 0}, {"snippet_id": 40898, "code": "(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append", "label": 0}, {"snippet_id": 372, "code": ", safe=False) elif action=='loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe", "label": 0}, {"snippet_id": 70634, "code": " status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in", "label": 1}, {"snippet_id": 5197, "code": " codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output", "label": 0}, {"snippet_id": 54133, "code": ".dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self", "label": 0}, {"snippet_id": 26037, "code": " elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station)", "label": 0}, {"snippet_id": 92123, "code": " platforms arguments other than['current'], which is unsupported for this reason. Please either remove the platforms argument from these targets, or set them to exactly['current']. Bad targets: {} \"\"\".format(", "label": 0}, {"snippet_id": 23515, "code": "(username): raise OSUtilError((\"User{0} is a system user, \" \"will not set password.\").format(username)) passwd_hash=textutil.gen_password_hash(password, crypt_id, salt_len) cmd=\"echo '{0}'|pw usermod{1} ", "label": 0}, {"snippet_id": 14059, "code": "[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests", "label": 0}, {"snippet_id": 50411, "code": ", rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate", "label": 0}, {"snippet_id": 27238, "code": "'Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass", "label": 0}, {"snippet_id": 19052, "code": " raw_schema=load_source(target) return parse(raw_schema) def validate(raw_schema, target=None, **kwargs): \"\"\" Given the python representation of a JSONschema as defined in the swagger spec, validate that the", "label": 0}, {"snippet_id": 43323, "code": ", concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as", "label": 0}, {"snippet_id": 78458, "code": " found_count=0 for user, forum in self.forums: targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format", "label": 0}, {"snippet_id": 16217, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( ", "label": 0}, {"snippet_id": 5041, "code": ": string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' '", "label": 0}, {"snippet_id": 75520, "code": " make_auth_unbind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b", "label": 0}, {"snippet_id": 72626, "code": "[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite", "label": 0}, {"snippet_id": 55113, "code": " \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets", "label": 0}, {"snippet_id": 89936, "code": " self._bin_path=os.path.join(self.home, 'bin') try: self._validated_executable('javac') self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please", "label": 0}, {"snippet_id": 30021, "code": "\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname:", "label": 0}, {"snippet_id": 34476, "code": " targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation", "label": 0}, {"snippet_id": 71564, "code": "\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING", "label": 0}, {"snippet_id": 86358, "code": "(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _execute_hermetic_compile(self, cmd, ctx): input_snapshot=ctx.target.sources_snapshot", "label": 0}, {"snippet_id": 73389, "code": " configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data", "label": 0}, {"snippet_id": 45565, "code": " mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of", "label": 1}, {"snippet_id": 61246, "code": "\") if not np.allclose(U @ U.conj().T, np.identity(U.shape[0]), atol=tolerance): raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian", "label": 0}, {"snippet_id": 60316, "code": ", hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and", "label": 1}, {"snippet_id": 95548, "code": "\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory", "label": 0}, {"snippet_id": 72036, "code": " reload the networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments", "label": 0}, {"snippet_id": 87739, "code": "=zinc_args, workunit_name=self.name(), workunit_labels=[WorkUnitLabel.COMPILER], dist=self._zinc.dist): raise TaskError('Zinc compile failed.') def _verify_zinc_classpath(self, classpath, allow_dist=True): def", "label": 0}, {"snippet_id": 69973, "code": "(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute", "label": 0}, {"snippet_id": 72093, "code": " the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"\"\" permissions.checkPermissions(irc, source,['networks.autoconnect'])", "label": 0}, {"snippet_id": 22165, "code": " template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template", "label": 0}, {"snippet_id": 64197, "code": "(integrates_datatypes_config) metadata_kwds['datatypes_config']=os.path.join(configs_directory, os.path.basename(integrates_datatypes_config)) return metadata_kwds class LwrComputeEnvironment( ComputeEnvironment)", "label": 0}, {"snippet_id": 52693, "code": "=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists", "label": 0}, {"snippet_id": 69985, "code": " get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs", "label": 0}, {"snippet_id": 16115, "code": ") return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']", "label": 0}, {"snippet_id": 699, "code": "\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io", "label": 0}, {"snippet_id": 85042, "code": ", help='Scala suffix to be used in `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool", "label": 0}, {"snippet_id": 40824, "code": " in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard", "label": 0}, {"snippet_id": 28894, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self", "label": 0}, {"snippet_id": 50070, "code": "(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile", "label": 0}, {"snippet_id": 33896, "code": " print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule", "label": 0}, {"snippet_id": 65452, "code": "(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message):", "label": 0}, {"snippet_id": 2158, "code": ":')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username", "label": 0}, {"snippet_id": 8350, "code": " read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext", "label": 0}, {"snippet_id": 43804, "code": "(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None,", "label": 0}, {"snippet_id": 6180, "code": ".info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares", "label": 1}, {"snippet_id": 67601, "code": " of %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target", "label": 0}, {"snippet_id": 82665, "code": " if args.proxy: \tif args.proxy[\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided", "label": 0}, {"snippet_id": 38567, "code": ", printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None", "label": 0}, {"snippet_id": 17085, "code": " handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get(", "label": 1}, {"snippet_id": 40440, "code": " be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\"))", "label": 0}, {"snippet_id": 84189, "code": " use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason -datatypes may not match. One can", "label": 0}, {"snippet_id": 28116, "code": " import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from", "label": 0}, {"snippet_id": 51509, "code": " if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards):", "label": 0}, {"snippet_id": 16946, "code": " if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler),", "label": 1}, {"snippet_id": 25455, "code": ".moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if", "label": 0}, {"snippet_id": 54744, "code": ".has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources", "label": 0}, {"snippet_id": 26335, "code": ".netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items", "label": 1}, {"snippet_id": 55968, "code": "*logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate", "label": 0}, {"snippet_id": 70942, "code": "=RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline)", "label": 0}, {"snippet_id": 15633, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics", "label": 0}, {"snippet_id": 16764, "code": "'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd", "label": 0}, {"snippet_id": 94088, "code": ", color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger", "label": 0}, {"snippet_id": 33638, "code": " list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed", "label": 0}, {"snippet_id": 73182, "code": " file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir", "label": 0}, {"snippet_id": 56392, "code": " _InfoObjects(object): def __init__(self, request, product_id=None): self.request=request try: self.product_id=int(product_id) except(ValueError, TypeError): self.product_id=0 def builds(self): try: is_active", "label": 0}, {"snippet_id": 2353, "code": " from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t", "label": 0}, {"snippet_id": 12405, "code": "\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8 issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}", "label": 0}, {"snippet_id": 9716, "code": " spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[", "label": 0}, {"snippet_id": 84777, "code": " pants.backend.jvm.targets.jar_library import JarLibrary from pants.build_graph.address import Address from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java.jar.jar_dependency", "label": 0}, {"snippet_id": 7936, "code": " keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches):", "label": 0}, {"snippet_id": 12042, "code": "'.join(value))) config[\"pycodestyle_cmd_config\"]='{arguments}'.format(arguments=' '.join(arguments)) config[\"pycodestyle\"][\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"])] return config", "label": 0}, {"snippet_id": 65862, "code": " elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target)", "label": 0}, {"snippet_id": 73716, "code": " config. file. \"\"\" def __init__(self, file_name): \"\"\" Initializes the configuration representation with a supplied file. \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if", "label": 0}, {"snippet_id": 27442, "code": " self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the", "label": 0}, {"snippet_id": 23623, "code": " not a all-ones broadcast address, need to specify the route manually to get it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service", "label": 0}, {"snippet_id": 11784, "code": "/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict(base, head): \"\"\" Recursively merge or update dict-like objects. >>> update({'k1': 1},{'k1':{'k2':{'k3': 3", "label": 0}, {"snippet_id": 79013, "code": " following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not", "label": 0}, {"snippet_id": 67335, "code": " execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel", "label": 0}, {"snippet_id": 54441, "code": " format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError", "label": 0}, {"snippet_id": 31797, "code": " branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): ", "label": 0}, {"snippet_id": 69312, "code": ".Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. ", "label": 0}, {"snippet_id": 62686, "code": ".MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool", "label": 0}, {"snippet_id": 2436, "code": "=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug", "label": 0}, {"snippet_id": 47415, "code": ":\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables", "label": 0}, {"snippet_id": 18645, "code": " if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive", "label": 0}, {"snippet_id": 70455, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs", "label": 0}, {"snippet_id": 83474, "code": " rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters: compute_environment=LwrComputeEnvironment( client, job_wrapper, remote_job_config) prepare_kwds[ 'compute_environment", "label": 0}, {"snippet_id": 36333, "code": ".wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value", "label": 0}, {"snippet_id": 14237, "code": " SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self", "label": 0}, {"snippet_id": 28567, "code": "'sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure", "label": 0}, {"snippet_id": 38503, "code": ": rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules", "label": 0}, {"snippet_id": 44723, "code": " print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule", "label": 0}, {"snippet_id": 35872, "code": " WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if", "label": 0}, {"snippet_id": 54249, "code": " files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None", "label": 0}, {"snippet_id": 47084, "code": ".rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files", "label": 0}, {"snippet_id": 53664, "code": "=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\")", "label": 0}, {"snippet_id": 13897, "code": ": return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout", "label": 0}, {"snippet_id": 17559, "code": " self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive():", "label": 0}, {"snippet_id": 12730, "code": " comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B %d, %Y at %H:%M Hours UTC\") comment +=\"\\n\\n comment", "label": 0}, {"snippet_id": 6322, "code": " word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory,", "label": 1}, {"snippet_id": 3793, "code": " \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name", "label": 0}, {"snippet_id": 54526, "code": "=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path", "label": 0}, {"snippet_id": 78549, "code": "==0: c=self.get_targets() if c==0: self.log.info('No targets found at all, sleeping for 30 seconds') self.long_sleep(30) self.schedule(self.comment_loop) if len(self.forums)==0: self.schedule(self.wait_loop", "label": 0}, {"snippet_id": 88871, "code": ".acquired: self._lock.acquire() def release_lock(self): \"\"\"Release the global lock if it's held. Returns True if the lock was held before this call. :API: public \"\"\" if not self._lock.acquired: return False", "label": 0}, {"snippet_id": 82173, "code": " and filtered by the server. Needs -l switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first", "label": 0}, {"snippet_id": 57821, "code": ", case__in=case_pks).update(**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list('pk', flat=True) if not reviewers: err_msg='Reviewer", "label": 0}, {"snippet_id": 17339, "code": "}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self", "label": 0}, {"snippet_id": 19008, "code": ": pass except NameError: pass raise ValueError( \"Unable to parse `{0}`. Tried yaml and json.\".format(source), ) def parse(raw_schema): context={ 'deferred_references': set(), } swagger_definitions=definitions_validator", "label": 0}, {"snippet_id": 76930, "code": " TypeError('Invalid proxytype %s' % proxytype) net.useragent=random.choice(d.ua_list) net.timeout=c.rp_timeout return net def upload_avatar(self, ud): if('avatar_uploaded' in ud[0] and ud[0]['avatar_uploaded", "label": 0}, {"snippet_id": 79411, "code": "+=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse", "label": 0}, {"snippet_id": 69715, "code": " os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand", "label": 0}, {"snippet_id": 66488, "code": "\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING", "label": 0}, {"snippet_id": 51048, "code": ", fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self", "label": 1}, {"snippet_id": 86820, "code": "') @classmethod def get_args_default(cls, bootstrap_option_values): return('-C-encoding', '-CUTF-8', '-S-encoding', '-SUTF-8', '-S-g:vars') @classmethod def get_warning_args_default(cls): return('-C-deprecation", "label": 0}, {"snippet_id": 77708, "code": ") def save_targets(self): data={ 'targets': targets, 'forums': forums, 'domains': domains, 'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL", "label": 0}, {"snippet_id": 36275, "code": " Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 49649, "code": " Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process", "label": 0}, {"snippet_id": 53523, "code": ".items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark", "label": 0}, {"snippet_id": 14517, "code": "'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 77115, "code": " self.th_sock=self.p.ctx.socket(zmq.PUB) self.th_sock.bind(self.th_sa) def init_th_back_sock(self): self.log.info( 'Initializing intraprocess backward socket %s', self.th_ba) self.th_back_sock=self.p.ctx", "label": 0}, {"snippet_id": 50179, "code": " None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config", "label": 0}, {"snippet_id": 446, "code": "> 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request", "label": 0}, {"snippet_id": 56295, "code": ": perm='%s.change_%s' % tuple(ctype.split('.')) if request.user.has_perm(perm): return True return False def strip_parameters(request_dict, skip_parameters): parameters={} for key, value in request_dict", "label": 0}, {"snippet_id": 59948, "code": " \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend", "label": 0}, {"snippet_id": 48597, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item", "label": 0}, {"snippet_id": 40189, "code": ".snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic", "label": 0}, {"snippet_id": 42508, "code": ", input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion", "label": 0}, {"snippet_id": 79463, "code": "\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"", "label": 0}, {"snippet_id": 64534, "code": " Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support", "label": 0}, {"snippet_id": 11091, "code": ".etag=etag self.mtime=int(mtime) def __nonzero__(self): return self.etag is None and self.mtime is 0 def __eq__(self, other): return self.etag==other.etag and self.mtime==other.mtime def __repr__(self):", "label": 0}, {"snippet_id": 32802, "code": " print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake", "label": 1}, {"snippet_id": 26805, "code": " elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" ", "label": 0}, {"snippet_id": 82267, "code": "-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in", "label": 0}, {"snippet_id": 3999, "code": " args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger", "label": 0}, {"snippet_id": 25185, "code": "'Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy", "label": 0}, {"snippet_id": 77321, "code": "(self, 'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break", "label": 0}, {"snippet_id": 39067, "code": "*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 44107, "code": ")) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles", "label": 0}, {"snippet_id": 16830, "code": "') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger,", "label": 0}, {"snippet_id": 55232, "code": "\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True", "label": 0}, {"snippet_id": 50925, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode &", "label": 0}, {"snippet_id": 51084, "code": ".file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self", "label": 0}, {"snippet_id": 30632, "code": " self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items()", "label": 0}, {"snippet_id": 76711, "code": "--upload-avatar', action='store_true', default=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default='randav', help='Directory with avatars') parser.add_argument", "label": 0}, {"snippet_id": 92150, "code": " BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires-pex' @classmethod def register_options(cls, register): super(BuildSetupRequiresPex, cls).register_options(register) register('--setuptools", "label": 0}, {"snippet_id": 77653, "code": ".update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data['domains']", "label": 0}, {"snippet_id": 78774, "code": ".parse import urljoin,urlparse from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t", "label": 0}, {"snippet_id": 57492, "code": " enough permission to update TestCases.\") action=self.get_update_action() if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception", "label": 0}, {"snippet_id": 93022, "code": "._stdio_as_tempfiles(): with stdio_as(stdout_fd=-1, stderr_fd=-1, stdin_fd=-1): self.assertEqual('', sys.stdin.read()) print('garbage', file=sys.stdout) print('garbage', file=sys.stderr) def test_signal_handler_as(self", "label": 0}, {"snippet_id": 41462, "code": ".expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"", "label": 0}, {"snippet_id": 45829, "code": ".group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the", "label": 0}, {"snippet_id": 34445, "code": " if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir,", "label": 0}, {"snippet_id": 58140, "code": " results=ctypes[target][0]._default_manager.filter(product__in=p_pks) attr=ctypes[target][1] results=[(r.pk, getattr(r, attr)) for r in results] return results def get_prod_related_obj_json(request): \"\"\" View", "label": 0}, {"snippet_id": 35680, "code": " def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end", "label": 0}, {"snippet_id": 5535, "code": " set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set", "label": 0}, {"snippet_id": 91055, "code": "{} jdk_paths=self.get_options().paths or{} for name, paths in sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to \"{}\"; combining", "label": 0}, {"snippet_id": 25073, "code": " get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data", "label": 1}, {"snippet_id": 94599, "code": "=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window", "label": 0}, {"snippet_id": 41709, "code": " omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined", "label": 1}, {"snippet_id": 72023, "code": " <network>. When all networks are disconnected, PyLink will automatically exit. To reconnect a network disconnected using this command, use REHASH to reload the networks list.\"\"\" permissions.checkPermissions", "label": 0}, {"snippet_id": 43300, "code": "{ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log,", "label": 0}, {"snippet_id": 45185, "code": " RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources", "label": 0}, {"snippet_id": 49114, "code": " self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname", "label": 0}, {"snippet_id": 80504, "code": ".cookies: \tfor key in args.cookies.keys(): \t\ts.cookies[key]=args.cookies[key] s.headers={'User-Agent':args.userAgent} s.trust_env=False if args.proxy: \tif args.proxy[\"username\"] and args.proxy[\"password", "label": 0}, {"snippet_id": 43892, "code": " of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules", "label": 0}, {"snippet_id": 78538, "code": " self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c==0: self.log.info('No", "label": 0}, {"snippet_id": 23987, "code": " cmd_search_ide=\"sysctl dev.storvsc | grep pnpinfo | grep deviceid={0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk -F. '{print", "label": 0}, {"snippet_id": 14612, "code": " OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady", "label": 0}, {"snippet_id": 13482, "code": " YOUR ACCESS TOKEN SECRET HERE FROM TWITTER'\r \r import sys\r import time\r import subprocess\r import os\r from random import randint\r from threading import Thread\r from chippyRuxpin_audioPlayer import AudioPlayer\r", "label": 0}, {"snippet_id": 69769, "code": " node, client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info:", "label": 0}, {"snippet_id": 911, "code": "([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username", "label": 0}, {"snippet_id": 15145, "code": " ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import", "label": 0}, {"snippet_id": 62546, "code": "**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or", "label": 0}, {"snippet_id": 37875, "code": ".apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items", "label": 0}, {"snippet_id": 83372, "code": ", client_outputs=self.__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description=dependencies_description", "label": 0}, {"snippet_id": 31919, "code": "._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output:", "label": 0}, {"snippet_id": 44749, "code": " onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir", "label": 0}, {"snippet_id": 42324, "code": " apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile", "label": 0}, {"snippet_id": 9685, "code": "=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw", "label": 0}, {"snippet_id": 36427, "code": " if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or", "label": 0}, {"snippet_id": 80952, "code": ".formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName", "label": 0}, {"snippet_id": 92046, "code": " ensures that Pants is only targeting the current platform. :param tgts: a list of:class:`Target` objects. :return: a boolean value indicating whether the current target closure has native sources. :raises", "label": 0}, {"snippet_id": 45586, "code": " of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch()", "label": 0}, {"snippet_id": 47589, "code": "): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self", "label": 0}, {"snippet_id": 85801, "code": ".defaulted_property(target, lambda x: x.strict_deps): dependencies=target.strict_dependencies(DependencyContext.global_instance()) else: dependencies=DependencyContext.global_instance().all_dependencies", "label": 0}, {"snippet_id": 10843, "code": " None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has", "label": 1}, {"snippet_id": 64115, "code": "\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory=remote_job_config['outputs_directory'] configs_directory", "label": 0}, {"snippet_id": 62163, "code": "(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs", "label": 0}, {"snippet_id": 3585, "code": "> 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process", "label": 0}, {"snippet_id": 82159, "code": "\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by the server. Needs -l switch.\"", "label": 0}, {"snippet_id": 22390, "code": " logger.info(\"Checking to see if mcpd is up\") rc=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!", "label": 0}, {"snippet_id": 76563, "code": ", signal, logging, threading, re, traceback, time import random import zmq from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import UniWipe from", "label": 0}, {"snippet_id": 81507, "code": ".shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t", "label": 0}, {"snippet_id": 9161, "code": " string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty", "label": 0}, {"snippet_id": 2558, "code": "\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies", "label": 0}, {"snippet_id": 43302, "code": " None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards", "label": 0}, {"snippet_id": 84076, "code": " __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) if not remote_work_dir_copy: work_dir_outputs=self.get_work_dir_outputs( job_wrapper) else", "label": 1}, {"snippet_id": 9115, "code": " matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): ", "label": 0}, {"snippet_id": 70122, "code": ".upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % ", "label": 0}, {"snippet_id": 7711, "code": " author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str", "label": 0}, {"snippet_id": 53654, "code": " else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only", "label": 0}, {"snippet_id": 44350, "code": " subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag", "label": 0}, {"snippet_id": 44216, "code": ".check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you", "label": 0}, {"snippet_id": 75674, "code": " self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests=[] self.wz_bind_methods=[] self.wz_poll_timeout=30 def __sinit__(self", "label": 1}, {"snippet_id": 52876, "code": ",)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException", "label": 0}, {"snippet_id": 16357, "code": "-stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils", "label": 0}, {"snippet_id": 62677, "code": "\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend", "label": 0}, {"snippet_id": 94789, "code": " remote_mutex.add_argument('-c', '--check', help=\"Run a component check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd", "label": 0}, {"snippet_id": 94185, "code": "(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self", "label": 0}, {"snippet_id": 45380, "code": " os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f", "label": 0}, {"snippet_id": 57568, "code": " pk_enough) except Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils", "label": 0}, {"snippet_id": 64046, "code": " in different ways for same reason -datatypes may not match. One can push the local datatypes config to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively", "label": 0}, {"snippet_id": 61755, "code": " matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires < 0) or np.any(wires >=self.wires) or wires[0]==wires[1]: raise ValueError(", "label": 0}, {"snippet_id": 84860, "code": "-library', version) @classmethod def _create_compiler_jardep(cls, version): return cls._create_jardep('scala-compiler', version) @classmethod def _key_for_tool_version(cls, tool, version): if version==", "label": 1}, {"snippet_id": 26428, "code": ") self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement", "label": 0}, {"snippet_id": 71353, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal", "label": 0}, {"snippet_id": 33497, "code": " subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else", "label": 0}, {"snippet_id": 66118, "code": ": status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size", "label": 0}, {"snippet_id": 34070, "code": "]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())", "label": 0}, {"snippet_id": 17294, "code": " as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '", "label": 1}, {"snippet_id": 84756, "code": " division, print_function, unicode_literals from collections import namedtuple from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.zinc_language_mixin", "label": 0}, {"snippet_id": 71025, "code": " len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(", "label": 0}, {"snippet_id": 76263, "code": " records on router were cleared') else: self.log.warn('Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_clear_data()) def bind_methods(self): for i, m, f, t", "label": 0}, {"snippet_id": 16393, "code": "._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr", "label": 0}, {"snippet_id": 47210, "code": ".expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest", "label": 0}, {"snippet_id": 85956, "code": ": javac_plugin_info_file=os.path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod def get_args_default(cls", "label": 0}, {"snippet_id": 86486, "code": ".backend.jvm.targets.javac_plugin import JavacPlugin from pants.backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend.jvm.tasks", "label": 0}, {"snippet_id": 74796, "code": " configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to", "label": 0}, {"snippet_id": 24861, "code": "._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if", "label": 0}, {"snippet_id": 17905, "code": " timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC)", "label": 0}, {"snippet_id": 1025, "code": " wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e'", "label": 0}, {"snippet_id": 59866, "code": " qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set([ key for(key,val) in operator_map.items", "label": 0}, {"snippet_id": 77902, "code": " sig_addr) def add_target(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Appending %s to targets", "label": 0}, {"snippet_id": 48979, "code": " j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return", "label": 0}, {"snippet_id": 57898, "code": " run_ids=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun", "label": 0}, {"snippet_id": 36448, "code": " in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add", "label": 0}, {"snippet_id": 42243, "code": " self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output)", "label": 0}, {"snippet_id": 43849, "code": " another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule", "label": 0}, {"snippet_id": 10396, "code": " xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s", "label": 0}, {"snippet_id": 69207, "code": ") > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >", "label": 0}, {"snippet_id": 39422, "code": "=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output", "label": 0}, {"snippet_id": 27271, "code": "'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi'", "label": 0}, {"snippet_id": 39856, "code": " None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os", "label": 0}, {"snippet_id": 87904, "code": ") ret=[] for name, cp_entries in plugin_jar_map.items(): ret.append('-S-Xplugin:{}'.format(':'.join(cp_entries))) for arg in scalac_plugin_map[name]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret", "label": 0}, {"snippet_id": 62648, "code": " if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the", "label": 0}, {"snippet_id": 18488, "code": "._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive():", "label": 0}, {"snippet_id": 50910, "code": " is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists", "label": 0}, {"snippet_id": 48071, "code": " self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\"", "label": 0}, {"snippet_id": 53318, "code": " self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule)", "label": 0}, {"snippet_id": 45221, "code": " name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path", "label": 0}, {"snippet_id": 73166, "code": "(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file): with open(local_file, 'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil", "label": 0}, {"snippet_id": 87606, "code": "(b'\\n') if self.execution_strategy==self.HERMETIC: zinc_relpath=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context._scheduler), ctx.target.sources_snapshot(self", "label": 0}, {"snippet_id": 52841, "code": " Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards", "label": 0}, {"snippet_id": 67282, "code": " print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand", "label": 0}, {"snippet_id": 71520, "code": " else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr", "label": 0}, {"snippet_id": 1621, "code": "(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason", "label": 0}, {"snippet_id": 27289, "code": " None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend", "label": 1}, {"snippet_id": 44739, "code": " if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir)", "label": 0}, {"snippet_id": 77622, "code": ") self.userqueues[domain]=uq return uq def load_targets(self): fname=self.targetsfile if not os.path.isfile(fname): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data:", "label": 0}, {"snippet_id": 64525, "code": " Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path", "label": 0}, {"snippet_id": 86164, "code": ".target, ctx.classes_dir) try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings],", "label": 0}, {"snippet_id": 37650, "code": ", name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for", "label": 0}, {"snippet_id": 8323, "code": " raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath", "label": 1}, {"snippet_id": 26004, "code": ">=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self", "label": 0}, {"snippet_id": 13771, "code": "} _safe_locals={} for k in[]: _safe_locals[k]=eval(k) for k, v in np.__dict__.iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace", "label": 1}, {"snippet_id": 49893, "code": "*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 18160, "code": " ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request", "label": 0}, {"snippet_id": 12021, "code": " if isinstance(value, bool): arguments.append(\"--{}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments.append(\"--{}={}\".format(key, ','.join(value", "label": 0}, {"snippet_id": 50600, "code": "(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority", "label": 0}, {"snippet_id": 53086, "code": "\".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 455, "code": "}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if", "label": 0}, {"snippet_id": 89171, "code": " files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets parsed in the root tree's BUILD files will be followed and this may lead", "label": 0}, {"snippet_id": 93329, "code": "(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking", "label": 0}, {"snippet_id": 84505, "code": " self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[", "label": 0}, {"snippet_id": 57119, "code": " not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field and value.') field=str(field) value, error=get_value_by_type(value", "label": 0}, {"snippet_id": 17752, "code": "] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def", "label": 0}, {"snippet_id": 19367, "code": ".socket import Address from ptvsd.version import __version__, __author__ \"\"\" For the PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling", "label": 0}, {"snippet_id": 65741, "code": ")], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header", "label": 0}, {"snippet_id": 72653, "code": ") data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config", "label": 1}, {"snippet_id": 58505, "code": " selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment'", "label": 0}, {"snippet_id": 3233, "code": ": if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException", "label": 0}, {"snippet_id": 58695, "code": "'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) plan=TestPlan", "label": 0}, {"snippet_id": 6514, "code": "(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.')", "label": 0}, {"snippet_id": 27170, "code": "', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain", "label": 0}, {"snippet_id": 30235, "code": " name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self", "label": 0}, {"snippet_id": 88246, "code": " contextlib import contextmanager from twitter.common.collections import OrderedSet from pants.base.build_environment import get_buildroot, get_scm from pants.base.worker_pool import SubprocPool from pants.base", "label": 0}, {"snippet_id": 57838, "code": "=True) if not reviewers: err_msg='Reviewer %s is not found' % self.new_value raise ObjectDoesNotExist(err_msg) self.get_update_targets().update(**{str(self.target_field): reviewers[0]}) @require_POST def", "label": 0}, {"snippet_id": 67644, "code": " (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1):", "label": 0}, {"snippet_id": 54521, "code": "=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps", "label": 0}, {"snippet_id": 61420, "code": " self._state=np.zeros(2**self.wires, dtype=complex) self._state[0]=1 self._out=np.full(self.wires, np.nan) for operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation", "label": 0}, {"snippet_id": 69598, "code": ".Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): ", "label": 0}, {"snippet_id": 16451, "code": " server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and", "label": 0}, {"snippet_id": 5634, "code": "[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i ", "label": 0}, {"snippet_id": 25685, "code": " self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium", "label": 0}, {"snippet_id": 77085, "code": ".sock' self.pr_ba='ipc://wm-back.sock' self.userqueues={} self.usersfile='wm_users.pickle' self.targetsfile='wm_targets.pickle' self.bumplimitfile='wm_bumplimit.pickle' def init_th_sock(self): self.log", "label": 0}, {"snippet_id": 72257, "code": "% args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text, **kwargs): \"", "label": 0}, {"snippet_id": 65739, "code": ".append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort", "label": 0}, {"snippet_id": 53694, "code": " protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item", "label": 0}, {"snippet_id": 88570, "code": " invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots @property def console_outstream(self):", "label": 0}, {"snippet_id": 58779, "code": "='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission Dinied.'}) def test_change_case_run_status(self", "label": 0}, {"snippet_id": 73573, "code": "\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width", "label": 0}, {"snippet_id": 67931, "code": ".CommandRCDefs import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs", "label": 0}, {"snippet_id": 39324, "code": "), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir", "label": 0}, {"snippet_id": 32129, "code": ": inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return", "label": 0}, {"snippet_id": 5374, "code": "{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={", "label": 0}, {"snippet_id": 9022, "code": ", reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines", "label": 0}, {"snippet_id": 39048, "code": "=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self", "label": 0}, {"snippet_id": 76769, "code": " parser.add_argument('--caprate_limit', type=float, default=0.8, help='Captcha rate limit') parser.add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser", "label": 0}, {"snippet_id": 58556, "code": ".many_comments_url, {'comment': new_comment, 'run': ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, ", "label": 0}, {"snippet_id": 29059, "code": ".auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle", "label": 1}, {"snippet_id": 62589, "code": "),[qubit]) for qubit in self.reg] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\"", "label": 0}, {"snippet_id": 56565, "code": ".forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags", "label": 1}, {"snippet_id": 95842, "code": " directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type", "label": 0}, {"snippet_id": 7395, "code": " %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords", "label": 0}, {"snippet_id": 8912, "code": " output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs", "label": 0}, {"snippet_id": 74947, "code": " \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config", "label": 1}, {"snippet_id": 65982, "code": " > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],", "label": 0}, {"snippet_id": 14969, "code": " BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests", "label": 1}, {"snippet_id": 86733, "code": "-C-source', '-C{}'.format(settings.source_level), '-C-target', '-C{}'.format(settings.target_level), ] if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): try", "label": 0}, {"snippet_id": 16754, "code": ")[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer())", "label": 0}, {"snippet_id": 34710, "code": " & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod", "label": 0}, {"snippet_id": 87115, "code": ".pants_workdir, get_buildroot(), ) ) if self.get_options().use_classpath_jars: raise TaskError(\"Hermetic zinc execution currently doesn't work with classpath jars\") def select(self, target): raise NotImplementedError", "label": 0}, {"snippet_id": 20034, "code": "(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start(*args, **kwargs): return DebugAdapter.start_wrapper_script( script, *args, ", "label": 0}, {"snippet_id": 38257, "code": " def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False", "label": 0}, {"snippet_id": 29169, "code": " def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function", "label": 0}, {"snippet_id": 58980, "code": " @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData() cls.get_info_url=reverse('ajax-info') cls.group_nitrate=EnvGroupFactory(name='nitrate') cls.group_new=EnvGroupFactory", "label": 0}, {"snippet_id": 88645, "code": " engine execution.\"\"\" self._set_target_root_count_in_runtracker() yield self.run_tracker.pantsd_stats.set_scheduler_metrics(self._scheduler.metrics()) self._set_affected_target_count_in_runtracker() def", "label": 0}, {"snippet_id": 67496, "code": ".Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from", "label": 0}, {"snippet_id": 2958, "code": ". Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp", "label": 0}, {"snippet_id": 5644, "code": "(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw", "label": 0}, {"snippet_id": 91148, "code": ".backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements from pants.backend.python.rules import inject_init, python_test_runner from", "label": 0}, {"snippet_id": 20031, "code": " self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start(*args, **kwargs", "label": 0}, {"snippet_id": 86169, "code": " distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) javac_cmd=['", "label": 0}, {"snippet_id": 38456, "code": ".first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by", "label": 0}, {"snippet_id": 60995, "code": ".linalg import expm, eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition", "label": 0}, {"snippet_id": 55315, "code": "*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag", "label": 0}, {"snippet_id": 71632, "code": " not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug", "label": 0}, {"snippet_id": 2332, "code": " Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import", "label": 0}, {"snippet_id": 5009, "code": " here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string", "label": 0}, {"snippet_id": 44174, "code": ", priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp", "label": 0}, {"snippet_id": 90853, "code": " listed for this operating system in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely locations on the file system such as `/usr/lib/jvm` on Linux machines. :API: public \"\"\"", "label": 0}, {"snippet_id": 31874, "code": "._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products", "label": 0}, {"snippet_id": 8710, "code": "\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords", "label": 0}, {"snippet_id": 34946, "code": "(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None", "label": 0}, {"snippet_id": 95899, "code": "(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path", "label": 1}, {"snippet_id": 78192, "code": " msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets) super().__init__(", "label": 0}, {"snippet_id": 13287, "code": "\" def autopep8ify(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(data[\"diff_url\"], headers=headers", "label": 0}, {"snippet_id": 66568, "code": "-fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount", "label": 1}, {"snippet_id": 25085, "code": ") def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData", "label": 1}, {"snippet_id": 32433, "code": " ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params", "label": 0}, {"snippet_id": 38602, "code": ", summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake", "label": 0}, {"snippet_id": 90832, "code": " maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions are searched for in the following order by default: 1. Paths listed for", "label": 0}, {"snippet_id": 83430, "code": " lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self", "label": 0}, {"snippet_id": 30762, "code": ".decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return", "label": 0}, {"snippet_id": 69352, "code": "(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): ", "label": 0}, {"snippet_id": 66001, "code": "\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout", "label": 0}, {"snippet_id": 47265, "code": " f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill", "label": 0}, {"snippet_id": 83323, "code": " async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination", "label": 0}, {"snippet_id": 27722, "code": "='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 42118, "code": ", \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return", "label": 0}, {"snippet_id": 59612, "code": " proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend'", "label": 0}, {"snippet_id": 84594, "code": " register): super(CountLinesOfCode, cls).register_options(register) register('--transitive', type=bool, fingerprint=True, default=True, help='Operate on the transitive dependencies of the specified targets", "label": 0}, {"snippet_id": 49530, "code": ".has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update", "label": 0}, {"snippet_id": 3366, "code": ".session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self", "label": 0}, {"snippet_id": 56786, "code": "\"\"\" def __init__(self, obj, tag_name): \"\"\" :param obj: the object for which the tag actions would be performed :type obj: either a:class:`tcms.testplans.models.TestPlan`, a:class:`tcms.testcases.models", "label": 0}, {"snippet_id": 8170, "code": " marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_", "label": 0}, {"snippet_id": 47247, "code": "\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 93651, "code": " name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component", "label": 0}, {"snippet_id": 26363, "code": " continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions", "label": 1}, {"snippet_id": 47163, "code": " combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"", "label": 0}, {"snippet_id": 88233, "code": ", unicode_literals import os import sys from builtins import filter, object from collections import defaultdict from contextlib import contextmanager from twitter.common.collections import OrderedSet from", "label": 0}, {"snippet_id": 39101, "code": "=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason", "label": 0}, {"snippet_id": 5190, "code": "\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def", "label": 0}, {"snippet_id": 42242, "code": "\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output", "label": 0}, {"snippet_id": 85181, "code": " RuntimeError('Suffix version must be specified if using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not specified, then the version specified in ' '", "label": 0}, {"snippet_id": 90364, "code": "(java_dist_dirs)==0: raise ValueError('Expected at least 1 java dist dir.') self._java_dist_dirs=java_dist_dirs @property def jvm_locations(self): for java_dist_dir in self._java_dist_dirs: if os.path.isdir", "label": 0}, {"snippet_id": 71880, "code": ".__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print", "label": 0}, {"snippet_id": 63672, "code": ", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id", "label": 0}, {"snippet_id": 5000, "code": ":var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken", "label": 0}, {"snippet_id": 13559, "code": ")\r io.set( MOUTH_CLOSE, 0)\r else:\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 1)\r else:\r if( time.time() -lastMouthEventTime > 0.4):\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 0)\r \r def updateEyes", "label": 0}, {"snippet_id": 59337, "code": " user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve", "label": 0}, {"snippet_id": 19410, "code": "-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT -m MODULE[arg...]", "label": 0}, {"snippet_id": 41927, "code": ".intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output", "label": 0}, {"snippet_id": 60741, "code": " undefined methods. The dynamic methods pass their arguments directly to __init__ of the inheriting class.\"\"\" def __getattr__(cls, name): \"\"\"Get the attribute call via name\"\"\" def new_object(*args, **kwargs", "label": 0}, {"snippet_id": 74301, "code": " if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified", "label": 0}, {"snippet_id": 70442, "code": " global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import", "label": 0}, {"snippet_id": 915, "code": ":configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 1914, "code": " range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io'", "label": 0}, {"snippet_id": 68957, "code": " > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node", "label": 1}, {"snippet_id": 54347, "code": ": return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list", "label": 0}, {"snippet_id": 93919, "code": ".logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update", "label": 0}, {"snippet_id": 49353, "code": " resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1,", "label": 0}, {"snippet_id": 78320, "code": ".Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except", "label": 1}, {"snippet_id": 79532, "code": "\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec", "label": 0}, {"snippet_id": 22675, "code": " admin account that is, or should be, built in to the system. :param username: The username that you want to add to the system :param expiration: The expiration date to use. We do not use this value. \"\"\" if", "label": 0}, {"snippet_id": 10943, "code": " acceptable %s' % uri) def read_config_from_file(path): yaml_config=merge_yaml_files(path) etag=None mtime=os.path.getmtime(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url", "label": 0}, {"snippet_id": 46740, "code": " __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format", "label": 0}, {"snippet_id": 77713, "code": " targets, 'forums': forums, 'domains': domains, 'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in", "label": 0}, {"snippet_id": 92657, "code": ": self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self.assertTrue(os.path.exists(path), 'Temporary dir should exist outside of context if cleanup=False.') shutil", "label": 0}, {"snippet_id": 89014, "code": " dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of the run. See Target.closure_for_targets for remaining parameters", "label": 0}, {"snippet_id": 79539, "code": " \t\t\t\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex", "label": 0}, {"snippet_id": 66666, "code": " cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc())", "label": 0}, {"snippet_id": 12471, "code": "{1}]({2}):\".format(line, col, line_url) error_string=\" \".join(error_string_list) error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append", "label": 0}, {"snippet_id": 12668, "code": " comment): comment_mode=None headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/{}/issues/", "label": 0}, {"snippet_id": 88269, "code": ".target import Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products import Products from pants.goal.workspace import ScmWorkspace from pants.process.lock", "label": 1}, {"snippet_id": 29782, "code": " exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\"", "label": 0}, {"snippet_id": 45566, "code": " else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule", "label": 1}, {"snippet_id": 48200, "code": " output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or", "label": 0}, {"snippet_id": 6695, "code": " codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords", "label": 0}, {"snippet_id": 34323, "code": ", kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True", "label": 0}, {"snippet_id": 2757, "code": ": self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name", "label": 0}, {"snippet_id": 75928, "code": " if rs.finished: if not rs.retry: del msgdict[rs] continue s.send_multipart(msgdict[rs]) rs.finished=False rs.retry=False flag=1 if not flag: return t.tick() p(timeout*1000) if t.elapsed(False) >=timeout", "label": 0}, {"snippet_id": 32748, "code": "-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order", "label": 0}, {"snippet_id": 27531, "code": " for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=", "label": 0}, {"snippet_id": 38882, "code": " return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list", "label": 0}, {"snippet_id": 28736, "code": ": self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type", "label": 0}, {"snippet_id": 87172, "code": ".classes_dir, compile_context.jar_file, compile_context.analysis_file) if zinc_args is not None: for compile_context in compile_contexts: with open(compile_context.zinc_args_file, 'r') as fp: args=fp.read", "label": 0}, {"snippet_id": 61445, "code": ") if state.ndim==1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError('State vector must be of length 2**wires.') continue U=DefaultQubit._get_operator_matrix(operation) if len", "label": 0}, {"snippet_id": 75463, "code": "*64)-1) if not reqid in self.response_handlers: return reqid def make_auth_req_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash", "label": 1}, {"snippet_id": 46448, "code": "[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"", "label": 0}, {"snippet_id": 75350, "code": " method)] except KeyError: raise WZENoHandler(iden, 'No handler for sig %s,%s'%(interface, method)) handler(interface, method, msg[1:]) return() def make_req_msg(self, interface, method, args, fun, reqid", "label": 0}, {"snippet_id": 43554, "code": "\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0:", "label": 0}, {"snippet_id": 1096, "code": "'deletewifi', 'endpoint': wifi_name}], safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name", "label": 0}, {"snippet_id": 23230, "code": " 0x8912, param) retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned more than{0} up ' 'network interfaces.'), expected) sock=buff.tostring() for i", "label": 0}, {"snippet_id": 48657, "code": "\"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards", "label": 0}, {"snippet_id": 34137, "code": ": rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd", "label": 0}, {"snippet_id": 71759, "code": ", cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(", "label": 0}, {"snippet_id": 35614, "code": " --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"", "label": 0}, {"snippet_id": 88716, "code": "=parent_workunit_name, labels=[WorkUnitLabel.MULTITOOL], parent=background_root_workunit) workunit_parent=workunit_parent_ctx.__enter__() done_hook=lambda: workunit_parent_ctx.__exit__(None, None, None", "label": 0}, {"snippet_id": 42797, "code": ".wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items", "label": 0}, {"snippet_id": 93338, "code": ".logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'],", "label": 0}, {"snippet_id": 37591, "code": " str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start,", "label": 0}, {"snippet_id": 35489, "code": ": if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist", "label": 0}, {"snippet_id": 34965, "code": " return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern", "label": 0}, {"snippet_id": 53943, "code": " concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output)", "label": 0}, {"snippet_id": 95083, "code": "] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\": print(\"[Setup] Setting up benchmark data", "label": 0}, {"snippet_id": 64310, "code": ".append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"", "label": 0}, {"snippet_id": 25124, "code": " from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity", "label": 0}, {"snippet_id": 21092, "code": "(object): @classmethod def wait_all(cls, *awaitables): timeout=3.0 messages=[] for _ in range(int(timeout * 10)): time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and", "label": 0}, {"snippet_id": 66925, "code": " with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self)", "label": 0}, {"snippet_id": 64911, "code": "\"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs(conf_dir_path, 0755) except", "label": 0}, {"snippet_id": 26589, "code": " elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'", "label": 0}, {"snippet_id": 52, "code": " crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase).", "label": 1}, {"snippet_id": 65746, "code": " NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0", "label": 0}, {"snippet_id": 25276, "code": "'Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], ", "label": 1}, {"snippet_id": 12827, "code": ".is_added: py_files[py_file].append(line.target_line_no) to_ignore=\",\".join(config[\"pycodestyle\"][\"ignore\"]) arg_to_ignore=\"\" if len(to_ignore) > 0: arg_to_ignore=\"--ignore \" +to_ignore for file in py_files", "label": 0}, {"snippet_id": 79974, "code": ",required=False,dest=\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument", "label": 0}, {"snippet_id": 52522, "code": ".output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion", "label": 0}, {"snippet_id": 35568, "code": " plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"", "label": 0}, {"snippet_id": 2724, "code": "\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self", "label": 0}, {"snippet_id": 3001, "code": "/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start", "label": 0}, {"snippet_id": 92464, "code": ".assertEqual(os.path.realpath(tempdir), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_nested_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir1", "label": 0}, {"snippet_id": 55075, "code": " except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are", "label": 0}, {"snippet_id": 39864, "code": ".abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target", "label": 0}, {"snippet_id": 78079, "code": ": if len(forum) > 0: get_forum_id(forum) logger.info('Removing %s:%s from forums[%s]', user, forum, domain) forums[domain].remove((user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue", "label": 0}, {"snippet_id": 52308, "code": ".resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self", "label": 0}, {"snippet_id": 59510, "code": " operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise", "label": 0}, {"snippet_id": 60179, "code": " Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock,", "label": 0}, {"snippet_id": 33707, "code": "=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa", "label": 0}, {"snippet_id": 30714, "code": " if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not", "label": 0}, {"snippet_id": 70358, "code": "=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type)", "label": 0}, {"snippet_id": 15607, "code": " self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished", "label": 0}, {"snippet_id": 80072, "code": " exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]", "label": 0}, {"snippet_id": 24533, "code": "(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity", "label": 0}, {"snippet_id": 88754, "code": " background work. :API: public \"\"\" return self.run_tracker.background_worker_pool() def subproc_map(self, f, items): \"\"\"Map function `f` over `items` in subprocesses and return the result. :API: public ", "label": 0}, {"snippet_id": 52160, "code": " the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): ", "label": 0}, {"snippet_id": 21116, "code": ")) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'.format(awaitable.name)) else: messages.append('Response{}'.format(awaitable.name)) if len(messages)==0", "label": 0}, {"snippet_id": 20687, "code": "} def send_request(self, command, **args): if self.closed: raise RuntimeError('session closed') wait=args.pop('wait', False) req=self._create_request(command, **args) if self.VERBOSE: msg=parse_message", "label": 0}, {"snippet_id": 52875, "code": " rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex:", "label": 0}, {"snippet_id": 28726, "code": "=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state", "label": 0}, {"snippet_id": 40971, "code": ") self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items", "label": 0}, {"snippet_id": 87334, "code": " hasher=sha1() for cp_entry in[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[", "label": 1}, {"snippet_id": 92555, "code": ".') def test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the context.') self.assertTrue(os", "label": 0}, {"snippet_id": 80419, "code": " are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password", "label": 0}, {"snippet_id": 51139, "code": " wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing:", "label": 0}, {"snippet_id": 57686, "code": "=self.request.user, action='Field %s changed from %s to %s.' %( self.target_field, testcase.case_status, new_status.name ) ) update_object.update(**{str(self.target_field): self.new_value}) try: plan=plan_from_request_or_none", "label": 0}, {"snippet_id": 33798, "code": " not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not", "label": 0}, {"snippet_id": 90235, "code": "\"\"Return the jvm locations discovered in this environment. :returns: An iterator over all discovered jvm locations. :rtype: iterator of:class:`DistributionEnvironment.Location` \"\"\" class _EnvVarEnvironment", "label": 0}, {"snippet_id": 40928, "code": " Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None,", "label": 0}, {"snippet_id": 37423, "code": ".dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, ", "label": 0}, {"snippet_id": 13115, "code": ": url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests", "label": 0}, {"snippet_id": 11697, "code": " import datetime import hmac import json import os import re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository)", "label": 0}, {"snippet_id": 55001, "code": " priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp", "label": 0}, {"snippet_id": 45908, "code": " value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return", "label": 0}, {"snippet_id": 63798, "code": " sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job():", "label": 0}, {"snippet_id": 7938, "code": ".items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a", "label": 0}, {"snippet_id": 77402, "code": "'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif type_==1: if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock", "label": 0}, {"snippet_id": 8713, "code": "(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache", "label": 0}, {"snippet_id": 34009, "code": "=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output", "label": 0}, {"snippet_id": 79885, "code": " file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\",", "label": 0}, {"snippet_id": 90001, "code": " _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open(os.path.join(classpath, 'SystemProperties.class'), 'w+b') as fp: fp.write(pkgutil.get_data", "label": 0}, {"snippet_id": 29034, "code": "'wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize", "label": 0}, {"snippet_id": 53912, "code": ": self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards", "label": 0}, {"snippet_id": 49257, "code": "\"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule", "label": 0}, {"snippet_id": 19665, "code": ".add_mutually_exclusive_group(required=True) target.add_argument('-m', dest='module') target.add_argument('filename', nargs='?') parser.add_argument('--single-session', action='store_true') parser.add_argument", "label": 0}, {"snippet_id": 91921, "code": "', '.cpp', '.cc'] class PythonNativeCodeError(Exception): pass @classmethod def register_options(cls, register): super(PythonNativeCode, cls).register_options(register) register('--native-source-extensions", "label": 0}, {"snippet_id": 74222, "code": " benchmark_data_input_temp in benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark", "label": 0}, {"snippet_id": 36005, "code": " targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict", "label": 0}, {"snippet_id": 9039, "code": ".normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext", "label": 0}, {"snippet_id": 84261, "code": ", remote_job_config): metadata_kwds={} if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if", "label": 0}, {"snippet_id": 1698, "code": " safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username", "label": 0}, {"snippet_id": 30643, "code": "), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input", "label": 0}, {"snippet_id": 76209, "code": "(i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Route unbinded for(%s, %s)', i, m) else: self.log.warn('Status %s, passing', wzrpc.name_status(status", "label": 0}, {"snippet_id": 25152, "code": "=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS,", "label": 1}, {"snippet_id": 23877, "code": " interface:{0}\".format(output)) ifaces=output.split() if not ifaces: raise OSUtilError(\"Can't find ether interface.\") iface=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False)", "label": 0}, {"snippet_id": 16200, "code": " UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 12, "code": ".csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response import Response from rest_framework import viewsets", "label": 0}, {"snippet_id": 18571, "code": " { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit'", "label": 0}, {"snippet_id": 57658, "code": ") except TestCaseStatus.DoesNotExist: raise ObjectDoesNotExist('The status you choose does not exist.') update_object=self.get_update_targets() if not update_object: return say_no('No record(s) found')", "label": 0}, {"snippet_id": 51353, "code": "): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value", "label": 0}, {"snippet_id": 6145, "code": " seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+", "label": 1}, {"snippet_id": 46746, "code": " maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic", "label": 0}, {"snippet_id": 80363, "code": ".manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _|", "label": 0}, {"snippet_id": 48725, "code": " zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else", "label": 0}, {"snippet_id": 29305, "code": " os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self", "label": 0}, {"snippet_id": 69109, "code": ".set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR", "label": 1}, {"snippet_id": 73188, "code": ", temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir. Additionally moves *.vcf files to output_dir Note: This method searches", "label": 0}, {"snippet_id": 85914, "code": " from pants.java.distribution.distribution import DistributionLocator from pants.util.dirutil import safe_open from pants.util.process_handler import subprocess _JAVAC_PLUGIN_INFO_FILE='META-INF/services", "label": 0}, {"snippet_id": 57939, "code": "(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data={} try: data['bugs']=request.GET.get('bug_id', '').split(',') data['runs'", "label": 0}, {"snippet_id": 11075, "code": " Header(etag=etag, mtime=mtime) class Header(object): MON_CONF_GEN_COMMENT=' ETAG_COMMENT=' MTIME_COMMMENT=' def __init__(self, etag=None, mtime=0): self.etag=etag self.mtime=int(mtime) def __nonzero__(self)", "label": 0}, {"snippet_id": 56991, "code": "') (None, \"invalid literal for int() with base 10: 'string'\") \"\"\" value=error=None def get_time(time): date_time=datetime.datetime if time=='NOW': return date_time.now() return date_time.strptime(time,", "label": 0}, {"snippet_id": 60054, "code": " importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm", "label": 0}, {"snippet_id": 45340, "code": "=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException,", "label": 1}, {"snippet_id": 67431, "code": "<filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden", "label": 0}, {"snippet_id": 39916, "code": "\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]), path)", "label": 0}, {"snippet_id": 24673, "code": "._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640:", "label": 0}, {"snippet_id": 60266, "code": " Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry", "label": 0}, {"snippet_id": 75453, "code": ".get_values(iden) def make_reqid(self): while True: reqid=random.randint(1,(2**64)-1) if not reqid in self.response_handlers: return reqid def make_auth_req_data(self, interface, method, key, reqid=None):", "label": 1}, {"snippet_id": 90813, "code": "}, maximum_version{}') else: error_format=('Failed to locate a{} distribution with minimum_version{}, ' 'maximum_version{}') raise self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version", "label": 0}, {"snippet_id": 92696, "code": "(os.path.realpath(path2).startswith(os.path.realpath(path1)), 'Nested temporary dir should be created within outer dir.') def test_timer(self): class FakeClock(object): def __init__(self): self._time=0", "label": 0}, {"snippet_id": 43017, "code": "(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property", "label": 0}, {"snippet_id": 81737, "code": ",json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger", "label": 0}, {"snippet_id": 61984, "code": ", Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP", "label": 0}, {"snippet_id": 32191, "code": "(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property", "label": 0}, {"snippet_id": 48878, "code": " get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self", "label": 0}, {"snippet_id": 71690, "code": " Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w", "label": 1}, {"snippet_id": 9942, "code": "]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str", "label": 0}, {"snippet_id": 94206, "code": ") self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open", "label": 0}, {"snippet_id": 25336, "code": ".components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES]", "label": 1}, {"snippet_id": 24250, "code": "['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba", "label": 0}, {"snippet_id": 44453, "code": "(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items", "label": 0}, {"snippet_id": 14434, "code": ") def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self", "label": 0}, {"snippet_id": 81855, "code": "=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(", "label": 0}, {"snippet_id": 28708, "code": "=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp", "label": 0}, {"snippet_id": 1038, "code": ": add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(", "label": 0}, {"snippet_id": 45300, "code": " path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed", "label": 0}, {"snippet_id": 20548, "code": ".dumps(req) write_message(write, body, stop=stop) def _close(self): if self._ownsock: close(self._sock) class DebugSession(Closeable): VERBOSE=False HOST='localhost' PORT=8888 TIMEOUT=None @classmethod", "label": 0}, {"snippet_id": 48599, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item]", "label": 0}, {"snippet_id": 3175, "code": " session_name, hostname): remote_cmd=(\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\"ssh %s 'bash -s' < %s\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph", "label": 0}, {"snippet_id": 55053, "code": "\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( ", "label": 0}, {"snippet_id": 94028, "code": " dep_resolve(current, res, unres) for node in res: if \"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep", "label": 0}, {"snippet_id": 58480, "code": ", {'rc': 1, 'response': 'No runs selected.'}) response=self.client.post(self.many_comments_url, {'comment': 'new comment'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET", "label": 0}, {"snippet_id": 25199, "code": "'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery", "label": 0}, {"snippet_id": 68777, "code": "\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header", "label": 0}, {"snippet_id": 39561, "code": ".benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__", "label": 0}, {"snippet_id": 33254, "code": ".relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None:", "label": 0}, {"snippet_id": 31809, "code": ") return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self", "label": 0}, {"snippet_id": 50155, "code": " self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is", "label": 0}, {"snippet_id": 77494, "code": ") def spawn_evaluators(self): self.log.info('Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self", "label": 0}, {"snippet_id": 30586, "code": " class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards", "label": 0}, {"snippet_id": 83276, "code": ": job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job", "label": 0}, {"snippet_id": 63158, "code": ".__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job", "label": 0}, {"snippet_id": 4577, "code": " } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of", "label": 0}, {"snippet_id": 41310, "code": " raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len", "label": 0}, {"snippet_id": 74265, "code": "=runtime_config) def read_configuration(location): \"\"\" Args: location of the configuration file, existing configuration dictionary Returns: a dictionary of the form <dict>.<section>[<option>] and the corresponding", "label": 0}, {"snippet_id": 68447, "code": "(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown", "label": 0}, {"snippet_id": 18034, "code": "'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData", "label": 0}, {"snippet_id": 73923, "code": " object representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation", "label": 0}, {"snippet_id": 73264, "code": ") for path in pathlist_gz: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)", "label": 0}, {"snippet_id": 82595, "code": "(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in", "label": 0}, {"snippet_id": 80209, "code": "(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args", "label": 0}, {"snippet_id": 19735, "code": ".as_client(clienthost, ns.pop('port')) module=ns.pop('module') filename=ns.pop('filename') if module is None: args.name=filename args.kind='script' else: args.name=module args.kind='module' return args def", "label": 0}, {"snippet_id": 8415, "code": "): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb ", "label": 1}, {"snippet_id": 38958, "code": " f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster", "label": 0}, {"snippet_id": 776, "code": "'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n'", "label": 0}, {"snippet_id": 54681, "code": " lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the", "label": 0}, {"snippet_id": 34598, "code": "=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists", "label": 0}, {"snippet_id": 995, "code": "=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser", "label": 0}, {"snippet_id": 15063, "code": ": request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response", "label": 0}, {"snippet_id": 10739, "code": " if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to", "label": 1}, {"snippet_id": 49323, "code": " only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self", "label": 0}, {"snippet_id": 66504, "code": ", RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map", "label": 0}, {"snippet_id": 60900, "code": " @property def gates(self): \"\"\"Get the supported gate set. Returns: dict[str->GateSpec]: \"\"\" return self._gates @property def observables(self): \"\"\"Get the supported observables. Returns: dict[str->GateSpec]: \"", "label": 0}, {"snippet_id": 34026, "code": ".input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo", "label": 0}, {"snippet_id": 93173, "code": " hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=", "label": 0}, {"snippet_id": 26073, "code": "): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import", "label": 1}, {"snippet_id": 63433, "code": ".prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths=job_wrapper.get_output_fnames() return[ str( o) for o in output_paths] def get_input_files(self, job_wrapper): input_paths", "label": 0}, {"snippet_id": 64170, "code": " if LwrJobRunner.__use_remote_datatypes_conf( client): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file', None) if not remote_datatypes_config: log.warn(NO_REMOTE_DATATYPES_CONFIG", "label": 0}, {"snippet_id": 8198, "code": " of documents are supported: PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf'", "label": 0}, {"snippet_id": 3809, "code": ") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1", "label": 0}, {"snippet_id": 88537, "code": ".source_root.SourceRoots` instance for the current run. :API: public \"\"\" return self._source_roots @property def target_roots(self): \"\"\"Returns the targets specified on the command line. This set is strictly a", "label": 0}, {"snippet_id": 85552, "code": "(cls, products): return cls.tool_jar_from_products(products, 'compiler-interface', cls.options_scope) def create(self, products): \"\"\"Create a Zinc instance from products active in the current Pants run", "label": 0}, {"snippet_id": 70579, "code": " message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv", "label": 0}, {"snippet_id": 20461, "code": ", timeout=None): if timeout is None: timeout=cls.TIMEOUT sock=connect(addr, timeout) if cls.VERBOSE: print('connected') self=cls(sock, ownsock=True) self._addr=addr return self def __init__(self, sock,", "label": 0}, {"snippet_id": 9232, "code": " Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return", "label": 0}, {"snippet_id": 20151, "code": " already running') assert self._session is None self._adapter=DebugAdapter.start(argv, port=self._port) return self._adapter def host_local_debugger(self, argv, script=None, env=None, cwd=None, **kwargs):", "label": 0}, {"snippet_id": 41201, "code": "(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass", "label": 0}, {"snippet_id": 50707, "code": "\"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"", "label": 0}, {"snippet_id": 69533, "code": "=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self,", "label": 0}, {"snippet_id": 81571, "code": "[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t", "label": 1}, {"snippet_id": 31308, "code": ".rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self", "label": 0}, {"snippet_id": 18472, "code": "._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return", "label": 0}, {"snippet_id": 33172, "code": "=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False,", "label": 0}, {"snippet_id": 10287, "code": " list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1,", "label": 0}, {"snippet_id": 37698, "code": " depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards,", "label": 0}, {"snippet_id": 93170, "code": " QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components", "label": 0}, {"snippet_id": 7955, "code": " clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches)", "label": 0}, {"snippet_id": 95955, "code": ": output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf", "label": 0}, {"snippet_id": 89237, "code": " execute_process_request, name, labels=None): \"\"\"Executes a process(possibly remotely), and returns information about its output. :param execute_process_request: The ExecuteProcessRequest to run. :param name: A descriptive", "label": 1}, {"snippet_id": 41723, "code": " @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for", "label": 0}, {"snippet_id": 41844, "code": " self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output", "label": 0}, {"snippet_id": 39121, "code": " printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger", "label": 0}, {"snippet_id": 93488, "code": "(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml'", "label": 0}, {"snippet_id": 49721, "code": " subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 62889, "code": "[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation", "label": 0}, {"snippet_id": 66465, "code": "=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__", "label": 0}, {"snippet_id": 10683, "code": ") if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines", "label": 1}, {"snippet_id": 40840, "code": " filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard", "label": 0}, {"snippet_id": 79464, "code": "\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m", "label": 0}, {"snippet_id": 19472, "code": " supported, pydevd, script=_group_args(argv) args=_parse_args(prog, supported) extra=pydevd +['--'] if script: extra +=script return args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try:", "label": 0}, {"snippet_id": 54813, "code": " cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False", "label": 0}, {"snippet_id": 78958, "code": ") \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName", "label": 0}, {"snippet_id": 92553, "code": " outside of the context.') def test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the context.')", "label": 0}, {"snippet_id": 90032, "code": "=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self.Error('Failed to determine java system properties for{} with", "label": 0}, {"snippet_id": 20758, "code": " closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event handlername='event{!r}'.format(event) with self._wait_for_message(match, handlername, **kwargs", "label": 0}, {"snippet_id": 55032, "code": " cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory", "label": 0}, {"snippet_id": 63721, "code": "(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if", "label": 0}, {"snippet_id": 47183, "code": " missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. ", "label": 0}, {"snippet_id": 82746, "code": ":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified", "label": 0}, {"snippet_id": 92712, "code": " FakeClock(object): def __init__(self): self._time=0.0 def time(self): ret=self._time self._time +=0.0001 return ret def sleep(self, duration): self._time +=duration clock=FakeClock() with Timer(clock=clock) as", "label": 0}, {"snippet_id": 59229, "code": " Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz", "label": 0}, {"snippet_id": 36336, "code": " combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self", "label": 0}, {"snippet_id": 19128, "code": " None: request=normalize_request(raw_request) response=None if raw_response is not None: response=normalize_response(raw_response, request=request) if response is not None: validate_response( response=response", "label": 0}, {"snippet_id": 29971, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}", "label": 0}, {"snippet_id": 57351, "code": " changed from{} to{}.'.format( field, getattr(t, field), TestCaseRunStatus.id_to_string(value), ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model", "label": 0}, {"snippet_id": 43179, "code": " str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_", "label": 0}, {"snippet_id": 13679, "code": " CREDENTIALS. Please read README.md for instructions.\") \r else:\r twitter=ChippyTwitter(consumerKey,consumerSecret,accessTokenKey,accessTokenSecret)\r \r web=WebFramework(talk)\r isRunning=False\r io.cleanup()\r", "label": 0}, {"snippet_id": 57373, "code": " if hasattr(model, 'mail_scene'): from tcms.core.utils.mailto import mailto mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context:", "label": 0}, {"snippet_id": 11237, "code": "/monitoring_config_generator/config.yaml' Usage: monconfgenerator[--debug][--targetdir=<directory>][--skip-checks][URL] monconfgenerator -h Options: -h Show this message. --debug Print additional information. --targetdir", "label": 0}, {"snippet_id": 40050, "code": " return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink.", "label": 0}, {"snippet_id": 78763, "code": " 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not available: %s', e) except BaseException as e: log.logger", "label": 0}, {"snippet_id": 89160, "code": "(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets parsed", "label": 0}, {"snippet_id": 34165, "code": ".globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo", "label": 0}, {"snippet_id": 65424, "code": ".EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776)", "label": 0}, {"snippet_id": 34633, "code": ") @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError", "label": 1}, {"snippet_id": 14410, "code": "._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ :", "label": 0}, {"snippet_id": 21840, "code": ") classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu')) classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) classifier.compile(optimizer='adam',", "label": 1}, {"snippet_id": 40036, "code": " @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return", "label": 1}, {"snippet_id": 28505, "code": " \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\",", "label": 0}, {"snippet_id": 32214, "code": "(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item,", "label": 0}, {"snippet_id": 86010, "code": ") @classmethod def subsystem_dependencies(cls): return super(JavacCompile, cls).subsystem_dependencies() +(JvmPlatform,) @classmethod def prepare(cls, options, round_manager): super(JavacCompile, cls).prepare", "label": 0}, {"snippet_id": 28850, "code": ">=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle", "label": 0}, {"snippet_id": 55891, "code": " def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def", "label": 0}, {"snippet_id": 92998, "code": "), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin", "label": 0}, {"snippet_id": 75772, "code": " self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method, data))) raise Resume() self", "label": 1}, {"snippet_id": 25366, "code": " variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name):", "label": 1}, {"snippet_id": 58702, "code": " post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) plan=TestPlan.objects.get(pk=self.plan.pk) self.assertFalse(plan.is_active) class", "label": 0}, {"snippet_id": 71872, "code": ", debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type", "label": 0}, {"snippet_id": 61156, "code": " return expm(-1j * theta/2 * Z) def fr3(a, b, c): r\"\"\"Arbitrary one-qubit rotation using three Euler angles. Args: a,b,c(float): rotation angles Returns: array: unitary 2x2 rotation matrix rz(c) @ ry(b", "label": 0}, {"snippet_id": 12247, "code": " shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"extra_results\"][filename]=stdout.decode(r.encoding).splitlines() data[\"results\"][filename]=[] for error in list(data[\"extra_results\"]", "label": 0}, {"snippet_id": 14949, "code": ", method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get(", "label": 1}, {"snippet_id": 26220, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', ", "label": 0}, {"snippet_id": 89617, "code": "._validated_binaries={} @property def jdk(self): self.validate() return self._is_jdk @property def system_properties(self): \"\"\"Returns a dict containing the system properties of this java distribution.", "label": 0}, {"snippet_id": 72289, "code": " same \" \\ \"network, as this would cause a recursive loop\" log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name, text, placeholder_self.name) if 'source' in kwargs: del kwargs", "label": 0}, {"snippet_id": 94008, "code": "\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres", "label": 0}, {"snippet_id": 55985, "code": ": ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod", "label": 0}, {"snippet_id": 57302, "code": " getattr(t, field), request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status", "label": 0}, {"snippet_id": 11171, "code": " self.mtime)) return lines @staticmethod def parse(file_name): etag, mtime=None, 0 def extract(comment, current_value): value=None if line.startswith(comment): value=line.rstrip()[len(comment):] return", "label": 0}, {"snippet_id": 93915, "code": " hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '", "label": 0}, {"snippet_id": 7388, "code": " ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return", "label": 0}, {"snippet_id": 62060, "code": "(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are", "label": 0}, {"snippet_id": 81527, "code": " self.logger.verbosity > 0: \t\t\t\tself.logger.debug(\"Requesting %s...\",url) \t\t \t\tr=self.session.get(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned", "label": 0}, {"snippet_id": 70046, "code": " FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine", "label": 0}, {"snippet_id": 86838, "code": "('-C-deprecation', '-C-Xlint:all', '-C-Xlint:-serial', '-C-Xlint:-path', '-S-deprecation', '-S-unchecked', '-S-Xlint') @classmethod def get_no_warning_args_default(cls): return('-C-nowarn', '-C-Xlint:none", "label": 0}, {"snippet_id": 46771, "code": "=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator", "label": 0}, {"snippet_id": 35367, "code": "(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit", "label": 0}, {"snippet_id": 44091, "code": " list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun", "label": 0}, {"snippet_id": 65236, "code": ", RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map", "label": 0}, {"snippet_id": 27178, "code": "'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1", "label": 0}, {"snippet_id": 55735, "code": " isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority,", "label": 0}, {"snippet_id": 3149, "code": ": cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name", "label": 0}, {"snippet_id": 7100, "code": " single_keywords_p: categories[w[0].concept]=w[0].type for w in single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords", "label": 0}, {"snippet_id": 58723, "code": "\"Test case for update_case_run_status\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateCaseRunStatus, cls).setUpTestData() cls.permission='testruns.change_testcaserun' cls.update_url=reverse('ajax", "label": 0}, {"snippet_id": 1257, "code": "-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split", "label": 0}, {"snippet_id": 47990, "code": " branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in", "label": 0}, {"snippet_id": 56181, "code": " django.contrib.auth.models import User from django.core import serializers from django.core.exceptions import ObjectDoesNotExist from django.apps import apps from django.forms import ValidationError from", "label": 0}, {"snippet_id": 46713, "code": " dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return", "label": 0}, {"snippet_id": 86616, "code": ")) @staticmethod def _write_javac_plugin_info(resources_dir, javac_plugin_target): javac_plugin_info_file=os.path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w'", "label": 0}, {"snippet_id": 92486, "code": " pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd", "label": 0}, {"snippet_id": 55515, "code": ".path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global", "label": 0}, {"snippet_id": 12538, "code": "\"opened\": comment_footer.append(config[\"message\"][\"opened\"][\"footer\"]) elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: comment_footer.append(config[\"message\"][\"updated\"][\"footer\"]) comment_footer", "label": 0}, {"snippet_id": 67326, "code": " RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 51969, "code": " insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name", "label": 0}, {"snippet_id": 32590, "code": "\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 20352, "code": " Closeable, ClosedError from.message import( raw_read_all as read_messages, raw_write_one as write_message ) from.socket import( Connection, create_server, create_client, close, recv_as_read, send_as_write,", "label": 0}, {"snippet_id": 76068, "code": " m) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}", "label": 0}, {"snippet_id": 3387, "code": "(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else:", "label": 0}, {"snippet_id": 53775, "code": " item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or", "label": 0}, {"snippet_id": 52149, "code": " config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P", "label": 0}, {"snippet_id": 13542, "code": " time.sleep( 0.1)\r \r while isRunning:\r if( audio.mouthValue !=lastMouthEvent):\r lastMouthEvent=audio.mouthValue\r lastMouthEventTime=time.time()\r \r if( audio.mouthValue==1):\r io.set( MOUTH_OPEN, 1)\r io.set", "label": 0}, {"snippet_id": 10212, "code": "): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean", "label": 0}, {"snippet_id": 72419, "code": " It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records", "label": 0}, {"snippet_id": 24846, "code": "% data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self", "label": 0}, {"snippet_id": 89682, "code": " checked. :param list names: jar file names :return: list of paths to requested libraries :raises: `Distribution.Error` if any of the jars could not be found. \"\"\" def collect_existing_libs(): def lib_paths(", "label": 0}, {"snippet_id": 34129, "code": "*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring", "label": 0}, {"snippet_id": 61554, "code": "(openqml.Operation or openqml.Expectation): operation/observable. Returns: array: matrix representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls", "label": 0}, {"snippet_id": 54096, "code": ".input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards)", "label": 0}, {"snippet_id": 57515, "code": " say_no('Update failed. Please try again or request ' 'support from your organization.') else: if resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets", "label": 0}, {"snippet_id": 61534, "code": " ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A(openqml.Operation or openqml.Expectation", "label": 0}, {"snippet_id": 45233, "code": "=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path", "label": 0}, {"snippet_id": 13101, "code": " data[\"fork_fullname\"]=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"])", "label": 0}, {"snippet_id": 84436, "code": " wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite( wrapper_path) results.append( self._dataset_path( local_output_path, remote_path)) return results def input_paths", "label": 0}, {"snippet_id": 74794, "code": " blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level", "label": 0}, {"snippet_id": 72325, "code": "%s) networks.remote: overriding reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient", "label": 1}, {"snippet_id": 50496, "code": ".benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def", "label": 0}, {"snippet_id": 61479, "code": ".expand_two(U, operation.wires) else: raise ValueError('This plugin supports only one-and two-qubit gates.') self._state=U @ self._state A=DefaultQubit._get_operator_matrix(self._observe) if self.shots", "label": 0}, {"snippet_id": 39610, "code": " ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params", "label": 0}, {"snippet_id": 23898, "code": "('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0}\".format(iface)) for line in output.split('\\n'): if line.find('inet ') !=-1: inet=line.split()[1] elif line", "label": 0}, {"snippet_id": 85, "code": "\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 89155, "code": "\"\"\" return self.build_graph.resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but", "label": 0}, {"snippet_id": 50478, "code": " def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def", "label": 0}, {"snippet_id": 3132, "code": "' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill", "label": 0}, {"snippet_id": 20765, "code": "]=msg return msg.type=='event' and msg.event==event handlername='event{!r}'.format(event) with self._wait_for_message(match, handlername, **kwargs): yield result def get_awaiter_for_event(self, event, condition", "label": 0}, {"snippet_id": 26840, "code": "%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength", "label": 0}, {"snippet_id": 93419, "code": " if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '%s'!\" %(dep, node", "label": 0}, {"snippet_id": 8212, "code": " text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import", "label": 1}, {"snippet_id": 90340, "code": "'JVMHomePath'] yield self.Location.from_home(home) except subprocess.CalledProcessError: pass class _LinuxEnvironment(_DistributionEnvironment): _STANDARD_JAVA_DIST_DIRS=('/usr/lib/jvm', '/usr/lib64/jvm", "label": 0}, {"snippet_id": 84244, "code": ")) return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration", "label": 0}, {"snippet_id": 38767, "code": " ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag,", "label": 0}, {"snippet_id": 36478, "code": " check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job", "label": 0}, {"snippet_id": 89067, "code": " in self.build_graph.synthetic_addresses: if self.build_graph.get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target(synthetic_address)) target_set.update", "label": 0}, {"snippet_id": 67957, "code": " import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576,", "label": 0}, {"snippet_id": 77462, "code": " args, kvargs, name='.'.join((wname, 'pr{0}'.format(i)))) self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads", "label": 0}, {"snippet_id": 20714, "code": " self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter=self._get_awaiter_for_request(req, **args) self._conn.send(req) return resp_awaiter def add_handler(self", "label": 0}, {"snippet_id": 69933, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) return", "label": 1}, {"snippet_id": 1051, "code": " JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(", "label": 0}, {"snippet_id": 23631, "code": " environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run(\"/etc/rc.d/dhclient start{0}\".format(self.get_if_name()", "label": 0}, {"snippet_id": 66255, "code": " ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 52406, "code": "(self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is", "label": 0}, {"snippet_id": 49071, "code": " flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None,", "label": 1}, {"snippet_id": 18725, "code": "): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 26801, "code": ")\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120:", "label": 0}, {"snippet_id": 15564, "code": " extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive", "label": 0}, {"snippet_id": 67217, "code": ".Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self", "label": 0}, {"snippet_id": 14352, "code": "=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append", "label": 0}, {"snippet_id": 13593, "code": " time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText):\r if( myText.find( \"twitter", "label": 0}, {"snippet_id": 17831, "code": ": if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description': x.description } for x in rawsnips", "label": 0}, {"snippet_id": 2811, "code": " --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=", "label": 0}, {"snippet_id": 61053, "code": "=np.eye(2) X=np.array([[0, 1],[1, 0]]) Y=np.array([[0, -1j],[1j, 0]]) Z=np.array([[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0]]) SWAP=np.array([[1, 0, 0, 0],[0, 0", "label": 0}, {"snippet_id": 26415, "code": "\"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None", "label": 0}, {"snippet_id": 59857, "code": "(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map", "label": 0}, {"snippet_id": 61819, "code": "(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1.6,[0]) qm", "label": 0}, {"snippet_id": 65771, "code": " AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(", "label": 0}, {"snippet_id": 42992, "code": "._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len", "label": 0}, {"snippet_id": 60632, "code": " device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q", "label": 0}, {"snippet_id": 4562, "code": " fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{}", "label": 1}, {"snippet_id": 24717, "code": " self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 12309, "code": "(error) url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(repository, after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct", "label": 0}, {"snippet_id": 95462, "code": " including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list \"\"\" if(remote_subdirs_list is not None) and(len(remote_subdirs_list", "label": 0}, {"snippet_id": 68902, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from", "label": 0}, {"snippet_id": 90609, "code": " distribution is required to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" def _get_stricter_version", "label": 0}, {"snippet_id": 58809, "code": "(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) self.assertEqual( 'PAUSED', TestCaseRun.objects", "label": 0}, {"snippet_id": 77527, "code": "(self.usersfile): return with open(self.usersfile, 'rb') as f: users=pickle.loads(f.read()) try: for domain in users.keys(): uq=Queue() for ud in users[domain]: self.log.debug('Loaded user %s:%s', domain,", "label": 0}, {"snippet_id": 45518, "code": " and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os", "label": 0}, {"snippet_id": 80529, "code": "] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args", "label": 0}, {"snippet_id": 38612, "code": "=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0,", "label": 0}, {"snippet_id": 56733, "code": ".GET.get(obj): self.object=obj self.object_pk=request.GET.get(obj) break def get(self): func=getattr(self, self.object) return func() def plan(self): return 'management/get_tag.html', TestPlan.objects.get", "label": 0}, {"snippet_id": 90896, "code": " meets the given constraints and returns it. :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg", "label": 0}, {"snippet_id": 37691, "code": " strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile", "label": 0}, {"snippet_id": 39607, "code": ", **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return", "label": 0}, {"snippet_id": 75332, "code": " handler for reqid') handler(reqid, seqnum, status, msg[1:]) return() def _parse_sig(self, iden, msg, interface, method): try: handler=self.sig_handlers[(interface, method)] except KeyError: raise WZENoHandler", "label": 0}, {"snippet_id": 31488, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError", "label": 0}, {"snippet_id": 55057, "code": "\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make", "label": 0}, {"snippet_id": 413, "code": "\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save()", "label": 0}, {"snippet_id": 40051, "code": "(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not", "label": 1}, {"snippet_id": 22694, "code": " use this value. \"\"\" if self.get_userentry(username): logger.info(\"User{0} already exists, skip useradd\", username) return None cmd=\"/usr/bin/tmsh create auth user %s partition-access add{ all-partitions", "label": 0}, {"snippet_id": 18235, "code": "') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface", "label": 0}, {"snippet_id": 65514, "code": "\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc", "label": 0}, {"snippet_id": 39298, "code": " workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self", "label": 0}, {"snippet_id": 89491, "code": " jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param string home_path: the path to the java distribution", "label": 0}, {"snippet_id": 24292, "code": "'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), })", "label": 1}, {"snippet_id": 18329, "code": " utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr'", "label": 0}, {"snippet_id": 84209, "code": " match. One can push the local datatypes config to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is", "label": 0}, {"snippet_id": 82617, "code": "\tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with", "label": 0}, {"snippet_id": 72029, "code": " PyLink will automatically exit. To reconnect a network disconnected using this command, use REHASH to reload the networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try", "label": 0}, {"snippet_id": 48302, "code": " if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer", "label": 0}, {"snippet_id": 15057, "code": "'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests", "label": 0}, {"snippet_id": 17124, "code": " import os import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from", "label": 0}, {"snippet_id": 77638, "code": " f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data", "label": 0}, {"snippet_id": 90901, "code": ". :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg, 1.7). The stricter of this and `--jvm-distributions", "label": 0}, {"snippet_id": 85368, "code": " from pants.engine.fs import PathGlobs, PathGlobsAndRoot from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem from pants.util.dirutil import fast_relpath", "label": 1}, {"snippet_id": 27393, "code": ".warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def", "label": 0}, {"snippet_id": 61515, "code": "._observe.wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self.shots)) else: a, P=spectral_decomposition_qubit(A) p0=self.ev(P[0], self._observe.wires) n0=np.random.binomial(self.shots, p0) ev=(n0*a", "label": 0}, {"snippet_id": 35754, "code": " end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key)", "label": 0}, {"snippet_id": 68586, "code": ") print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks", "label": 0}, {"snippet_id": 39955, "code": " follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod", "label": 0}, {"snippet_id": 21649, "code": ".colors import ListedColormap X_set, y_set=X_train, y_train X1, X2=np.meshgrid(np.arange(start=X_set[:, 0].min() -1, stop=X_set[:, 0].max() +1, step=0.01), np.arange(start=X_set[:, 1].min() -1, stop=X_set[:,", "label": 0}, {"snippet_id": 61874, "code": " different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C+", "label": 0}, {"snippet_id": 13703, "code": "[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01", "label": 0}, {"snippet_id": 6546, "code": ".text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename", "label": 0}, {"snippet_id": 2096, "code": " username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':'", "label": 0}, {"snippet_id": 43443, "code": " self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod", "label": 0}, {"snippet_id": 60193, "code": ", Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CatState:': Catstate, 'CoherentState': Coherent", "label": 0}, {"snippet_id": 4066, "code": " methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text", "label": 0}, {"snippet_id": 4095, "code": " of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode", "label": 0}, {"snippet_id": 36806, "code": " else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\"", "label": 0}, {"snippet_id": 74748, "code": ") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types: self.compressor=compressor_temp if \"blosc_compression_algorithm", "label": 0}, {"snippet_id": 88577, "code": " the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots @property def console_outstream(self): \"\"\"Returns the output stream to write console messages to. :API: public ", "label": 0}, {"snippet_id": 22881, "code": ") ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin':{0}\".format(output) ) self._save_sys_config() return ret def del_account", "label": 0}, {"snippet_id": 95124, "code": "..\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled. Skipping FTP download...\") data_service.process_data_files", "label": 1}, {"snippet_id": 5988, "code": ".compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system.", "label": 1}, {"snippet_id": 77633, "code": "): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum", "label": 0}, {"snippet_id": 27578, "code": "=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type", "label": 0}, {"snippet_id": 41949, "code": " self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 57019, "code": "%Y%m%d %H%M%S') pipes={ 'bool': lambda x: x=='True' and 1 or 0, 'datetime': get_time, 'int': lambda x: str(int(x)), 'str': lambda x: str(x), 'None': lambda x: None, } pipe=pipes.get(v_type, None) if pipe", "label": 0}, {"snippet_id": 11862, "code": " if sha_name !='sha1': abort(501) mac=hmac.new(os.environ[\"GITHUB_PAYLOAD_SECRET\"].encode(), msg=request.data, digestmod=\"sha1\") if not hmac.compare_digest(str(mac.hexdigest()), str(signature)): abort(403", "label": 0}, {"snippet_id": 90713, "code": ", 1.7). :param maximum_version: maximum jvm version to look for(eg, 1.7.9999). :param bool jdk: whether the found java distribution is required to have a jdk. :return: the located Distribution. :rtype:", "label": 0}, {"snippet_id": 79948, "code": " exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group", "label": 0}, {"snippet_id": 4930, "code": " output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords", "label": 0}, {"snippet_id": 22456, "code": " chk_err=False) def stop_agent_service(self): return shellutil.run(\"/sbin/service waagent stop\", chk_err=False) def start_agent_service(self): return shellutil.run(\"/sbin/service waagent start\", chk_err=False", "label": 0}, {"snippet_id": 42889, "code": " if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer", "label": 0}, {"snippet_id": 30921, "code": " omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards", "label": 0}, {"snippet_id": 67195, "code": ".CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine", "label": 0}, {"snippet_id": 62259, "code": " par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate", "label": 0}, {"snippet_id": 47479, "code": ") except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources", "label": 0}, {"snippet_id": 47681, "code": " s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join", "label": 0}, {"snippet_id": 62689, "code": "().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code", "label": 0}, {"snippet_id": 67819, "code": "), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type", "label": 0}, {"snippet_id": 49438, "code": "=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0,", "label": 0}, {"snippet_id": 58091, "code": ".objects.filter(bug_id__in=bug_ids) for run in runs: for bug in bugs: if bug.case_run_id==run.pk: run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs", "label": 0}, {"snippet_id": 67667, "code": " __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def", "label": 0}, {"snippet_id": 2073, "code": "'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username],", "label": 0}, {"snippet_id": 67211, "code": " open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose", "label": 0}, {"snippet_id": 4920, "code": " use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n'", "label": 0}, {"snippet_id": 90603, "code": "-maximum-version` is used. :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if", "label": 0}, {"snippet_id": 86099, "code": " and target.processors: processor_info_file=os.path.join(compile_context.classes_dir, _PROCESSOR_INFO_FILE) self._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self", "label": 0}, {"snippet_id": 63204, "code": " if compute_environment: unstructured_path_rewrites=compute_environment.unstructured_path_rewrites client_job_description=ClientJobDescription( command_line=command_line, input_files=self.get_input_files", "label": 0}, {"snippet_id": 13577, "code": " def updateEyes():\r while isRunning:\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN", "label": 0}, {"snippet_id": 83568, "code": "(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command: ", "label": 0}, {"snippet_id": 49125, "code": "._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[", "label": 0}, {"snippet_id": 36498, "code": " and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger", "label": 0}, {"snippet_id": 79557, "code": ".detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\"", "label": 0}, {"snippet_id": 59942, "code": " the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024)", "label": 0}, {"snippet_id": 95754, "code": "(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\") for", "label": 0}, {"snippet_id": 69596, "code": " Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install", "label": 0}, {"snippet_id": 92665, "code": " context.') self.assertTrue(os.path.exists(path), 'Temporary dir should exist outside of context if cleanup=False.') shutil.rmtree(path) def test_temporary_dir_with_root_dir(self): with temporary_dir()", "label": 0}, {"snippet_id": 30458, "code": " raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath", "label": 0}, {"snippet_id": 15676, "code": " 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest", "label": 0}, {"snippet_id": 78990, "code": " file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action)", "label": 0}, {"snippet_id": 78592, "code": ".sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError as", "label": 0}, {"snippet_id": 67704, "code": "(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr", "label": 0}, {"snippet_id": 85854, "code": " future.utils import text_type from pants.backend.jvm import argfile from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend", "label": 0}, {"snippet_id": 27157, "code": " MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure", "label": 1}, {"snippet_id": 60568, "code": " api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock', 'X', 'P', 'Homodyne', 'Heterodyne'} _circuits={} def __init__(self, wires, *, shots=0, hbar=2):", "label": 0}, {"snippet_id": 13077, "code": ".format(data[\"target_repo_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.post(url, headers=headers, auth", "label": 0}, {"snippet_id": 70508, "code": " NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose", "label": 0}, {"snippet_id": 87236, "code": " write_extra_resources to produce plugin and annotation processor files.\"\"\" target=compile_context.target if isinstance(target, ScalacPlugin): self._write_scalac_plugin_info(compile_context.classes_dir", "label": 0}, {"snippet_id": 51207, "code": "(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set(", "label": 0}, {"snippet_id": 51768, "code": " hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict -", "label": 0}, {"snippet_id": 82032, "code": " upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type", "label": 0}, {"snippet_id": 43745, "code": "=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug", "label": 0}, {"snippet_id": 61495, "code": "._state A=DefaultQubit._get_operator_matrix(self._observe) if self.shots==0: ev=self.ev(A,[self._observe.wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self._observe.wires) -ev", "label": 0}, {"snippet_id": 12193, "code": "\"repository\"] after_commit_hash=data[\"after_commit_hash\"] author=data[\"author\"] py_files=get_python_files_involved_in_pr(data) for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{", "label": 0}, {"snippet_id": 9442, "code": " composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires:", "label": 0}, {"snippet_id": 48504, "code": " name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards", "label": 0}, {"snippet_id": 15399, "code": " return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open(", "label": 0}, {"snippet_id": 87414, "code": "(relative_to_exec_root(c) for c in scala_path) compiler_interface=relative_to_exec_root(compiler_interface) compiler_bridge=relative_to_exec_root(compiler_bridge) analysis_cache=relative_to_exec_root(analysis_cache", "label": 1}, {"snippet_id": 76640, "code": ") msg.append('\u041a\u0430\u0436\u0434\u044b\u0439 \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random.randint(0, 9999999999))) return '\\n'.join(msg) def sbjfun(): return sup.randstr(1, 30) import argparse parser=argparse.ArgumentParser", "label": 0}, {"snippet_id": 15944, "code": " def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return", "label": 1}, {"snippet_id": 50943, "code": " protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join", "label": 0}, {"snippet_id": 12635, "code": "=True)) if text1==text2.replace(\"submitting\", \"updating\"): PERMITTED_TO_COMMENT=False \"\"\" for old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body", "label": 0}, {"snippet_id": 59221, "code": " SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT,", "label": 0}, {"snippet_id": 71704, "code": " s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry(", "label": 0}, {"snippet_id": 13734, "code": " def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals", "label": 0}, {"snippet_id": 55297, "code": "))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes", "label": 0}, {"snippet_id": 46727, "code": " must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the", "label": 0}, {"snippet_id": 14430, "code": " vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(", "label": 0}, {"snippet_id": 85259, "code": "._create_compiler_jardep), ('scala-library', self._create_runtime_jardep) ] for spec_key, create_jardep_func in specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec", "label": 0}, {"snippet_id": 76884, "code": " terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler) signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net=sup.net.RequestPerformer", "label": 0}, {"snippet_id": 70628, "code": " CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self", "label": 1}, {"snippet_id": 50261, "code": " ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params", "label": 0}, {"snippet_id": 72786, "code": " timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib import allel import sys import functools import", "label": 0}, {"snippet_id": 26251, "code": "':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength'", "label": 0}, {"snippet_id": 90132, "code": ") self._validated_binaries[name]=exe return exe @contextmanager def _valid_executable(self, name): exe=self._validate_executable(name) yield exe self._validated_binaries[name]=exe def __repr__(self): return", "label": 0}, {"snippet_id": 62020, "code": ". Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only", "label": 0}, {"snippet_id": 91889, "code": ".subsystem.subsystem import Subsystem from pants.util.memo import memoized_property from pants.util.objects import SubclassesOf logger=logging.getLogger(__name__) class PythonNativeCode(Subsystem): \"\"\"A", "label": 1}, {"snippet_id": 3864, "code": ") logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml", "label": 0}, {"snippet_id": 53162, "code": ", InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name", "label": 0}, {"snippet_id": 95428, "code": " file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter ", "label": 0}, {"snippet_id": 44753, "code": " def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def", "label": 0}, {"snippet_id": 95666, "code": " output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed", "label": 0}, {"snippet_id": 34213, "code": "(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message", "label": 0}, {"snippet_id": 93203, "code": "=(\"%s/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile", "label": 0}, {"snippet_id": 44419, "code": " job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))", "label": 0}, {"snippet_id": 19489, "code": " def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index('--') except ValueError: script=[] else: script=argv[pos +1:] argv=argv[:pos] for arg in argv: if arg=='-h' or arg=='--help':", "label": 0}, {"snippet_id": 54808, "code": "=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None", "label": 0}, {"snippet_id": 36108, "code": " self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self", "label": 0}, {"snippet_id": 54977, "code": ".io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules,", "label": 0}, {"snippet_id": 1902, "code": ".Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall(", "label": 0}, {"snippet_id": 20261, "code": ", wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script(self, filename, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed", "label": 0}, {"snippet_id": 62694, "code": " \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the", "label": 0}, {"snippet_id": 82529, "code": " \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey", "label": 0}, {"snippet_id": 3071, "code": ".session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res", "label": 1}, {"snippet_id": 50895, "code": ". \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard", "label": 1}, {"snippet_id": 10066, "code": ".output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for", "label": 0}, {"snippet_id": 58683, "code": " test_update_plan_is_active(self): self.client.login( username=self.tester.username, password='password') post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False',", "label": 0}, {"snippet_id": 88320, "code": " as well as information about the targets involved in the run. Advanced uses of the context include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal", "label": 0}, {"snippet_id": 65213, "code": ">][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map=", "label": 0}, {"snippet_id": 86818, "code": ".headless=true', '-Xmx2g') @classmethod def get_args_default(cls, bootstrap_option_values): return('-C-encoding', '-CUTF-8', '-S-encoding', '-SUTF-8', '-S-g:vars') @classmethod def get_warning_args_default", "label": 0}, {"snippet_id": 29996, "code": " wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for", "label": 0}, {"snippet_id": 83287, "code": " full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep( 2) job_state=self.__find_watched_job( job_id) if not job_state: log.warn( \"Failed to find", "label": 0}, {"snippet_id": 15570, "code": ") self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file", "label": 0}, {"snippet_id": 47216, "code": " self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in", "label": 0}, {"snippet_id": 35345, "code": "(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards", "label": 0}, {"snippet_id": 20650, "code": "=self._listen, name='test.session', ) self._listenerthread.start() @property def is_client(self): return self._conn.is_client @property def received(self): return list(self._received) def _create_request", "label": 0}, {"snippet_id": 71415, "code": "(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\"", "label": 0}, {"snippet_id": 87060, "code": "(self, *args, **kwargs): super(BaseZincCompile, self).__init__(*args, **kwargs) self._processor_info_dir=os.path.join(self.workdir, 'apt-processor-info') ZincCompile.validate_arguments(self.context.log", "label": 0}, {"snippet_id": 9301, "code": " keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of", "label": 0}, {"snippet_id": 87824, "code": " to zinc should be normalized ' '(i.e. without \"..\" and \".\").{} is not.'.format(path)) def log_zinc_file(self, analysis_file): self.context.log.debug('Calling zinc on:{}({})' .format(analysis_file, hash_file", "label": 0}, {"snippet_id": 90572, "code": " version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg, 1.7). The stricter of this and `--jvm-distributions-minimum-version` is used. ", "label": 0}, {"snippet_id": 49488, "code": ") else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None:", "label": 0}, {"snippet_id": 565, "code": ".username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows)", "label": 0}, {"snippet_id": 2083, "code": " action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc", "label": 0}, {"snippet_id": 33831, "code": "(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile", "label": 0}, {"snippet_id": 31004, "code": ", requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f", "label": 0}, {"snippet_id": 79935, "code": ",metavar=\"listOfExtensions\",dest=\"legitExtensions\",nargs=1,help=\"Legit extensions expected, for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar", "label": 0}, {"snippet_id": 1222, "code": " d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n", "label": 0}, {"snippet_id": 51369, "code": " flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value", "label": 0}, {"snippet_id": 60235, "code": "'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML. wires(int)", "label": 0}, {"snippet_id": 23581, "code": "._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper() return None def get_first_if(self): return self._get_net_info()[:2] def route_add(self, net, mask, gateway): cmd='route add{0}{1", "label": 0}, {"snippet_id": 76079, "code": " reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warn('Status{0}", "label": 0}, {"snippet_id": 78000, "code": " atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target(domain, id_, user) def rtfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 remove_target(domain", "label": 0}, {"snippet_id": 51440, "code": ": \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected", "label": 0}, {"snippet_id": 25025, "code": "'wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full", "label": 0}, {"snippet_id": 72637, "code": "[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\": print(\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree", "label": 1}, {"snippet_id": 15849, "code": " requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses", "label": 0}, {"snippet_id": 36574, "code": " files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove", "label": 0}, {"snippet_id": 21094, "code": " def wait_all(cls, *awaitables): timeout=3.0 messages=[] for _ in range(int(timeout * 10)): time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()", "label": 0}, {"snippet_id": 75144, "code": " self.p.log.warn('Keepalive timeout') else: self.p.log.warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self.p=parent self.p.wz_connect() self.p.wz_auth_requests=", "label": 0}, {"snippet_id": 6244, "code": " > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\"", "label": 1}, {"snippet_id": 32774, "code": " from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules", "label": 0}, {"snippet_id": 25208, "code": ":weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':[", "label": 0}, {"snippet_id": 81775, "code": "\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the", "label": 0}, {"snippet_id": 61498, "code": "(self._observe) if self.shots==0: ev=self.ev(A,[self._observe.wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self._observe.wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self", "label": 0}, {"snippet_id": 61623, "code": "}=\\bra{\\psi}A\\ket{\\psi}` \"\"\" if A.shape !=(2, 2): raise ValueError('2x2 matrix required.') A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance", "label": 0}, {"snippet_id": 90201, "code": "(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable", "label": 0}, {"snippet_id": 21314, "code": "-arguments]]', description='Play the youtube links from your favourite subreddit.') parser.add_argument('--depth', metavar='d', type=int, default=0, help='How many pages into the subreddit you want to go.')", "label": 0}, {"snippet_id": 46133, "code": " to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif", "label": 0}, {"snippet_id": 48846, "code": " filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not", "label": 0}, {"snippet_id": 23912, "code": "'\\n'): if line.find('inet ') !=-1: inet=line.split()[1] elif line.find('ether ') !=-1: mac=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port", "label": 0}, {"snippet_id": 59198, "code": " openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate,", "label": 0}, {"snippet_id": 11704, "code": " import os import re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository): \"\"\"Update users of the integration in", "label": 0}, {"snippet_id": 37032, "code": " self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set", "label": 0}, {"snippet_id": 16853, "code": ".unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': ", "label": 0}, {"snippet_id": 49426, "code": ", list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata", "label": 0}, {"snippet_id": 78902, "code": ".status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable", "label": 0}, {"snippet_id": 85714, "code": "/remapped_by_pants/buildroot/', self._zinc_factory.get_options().pants_workdir: '/dev/null/remapped_by_pants/workdir/', } return( '-rebase-map', ','.join('{}:{}'.format(src, dst) for src, dst in rebases.items", "label": 0}, {"snippet_id": 12456, "code": " error_string_list[2]=\"[{0}]({1})\".format(code, code_url) line, col=error_string_list[1][:-1].split(\":\") line_url=data[file +\"_link\"] +\" error_string_list[1]=\"[{0}:{1}]({2}):\".format(line, col, line_url", "label": 0}, {"snippet_id": 77108, "code": ".info( 'Initializing intraprocess signal socket %s', self.th_sa) self.th_sock=self.p.ctx.socket(zmq.PUB) self.th_sock.bind(self.th_sa) def init_th_back_sock(self): self.log.info( 'Initializing intraprocess", "label": 0}, {"snippet_id": 32274, "code": " have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if", "label": 0}, {"snippet_id": 44131, "code": " forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None", "label": 0}, {"snippet_id": 94807, "code": " args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger", "label": 0}, {"snippet_id": 8393, "code": ".error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log", "label": 1}, {"snippet_id": 51431, "code": " raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag", "label": 0}, {"snippet_id": 21304, "code": "'__main__': parser=ap.ArgumentParser(usage='%(prog)s[options] <subreddit>[--[mpv-arguments]]', description='Play the youtube links from your favourite subreddit.') parser.add_argument('--depth', metavar='d',", "label": 0}, {"snippet_id": 43116, "code": " concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output", "label": 0}, {"snippet_id": 94756, "code": " \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required", "label": 0}, {"snippet_id": 87777, "code": " classpath: if not os.path.isabs(path): raise TaskError('Classpath entries provided to zinc should be absolute. ' '{} is not.'.format(path)) if is_outside(path, self.get_options().pants_workdir) and(not", "label": 0}, {"snippet_id": 92920, "code": " stdio_as(stdout_fd=tmp_stdout.fileno(), stderr_fd=tmp_stderr.fileno(), stdin_fd=tmp_stdin.fileno()): self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys", "label": 0}, {"snippet_id": 61945, "code": "\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq", "label": 0}, {"snippet_id": 15951, "code": "': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS", "label": 1}, {"snippet_id": 91291, "code": " from pants.backend.python.tasks.resolve_requirements import ResolveRequirements from pants.backend.python.tasks.select_interpreter import SelectInterpreter from pants.backend.python.tasks.setup_py import", "label": 0}, {"snippet_id": 37786, "code": " ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None", "label": 0}, {"snippet_id": 7445, "code": " not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords", "label": 0}, {"snippet_id": 66663, "code": " cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(", "label": 0}, {"snippet_id": 19236, "code": "=load_source(source) assert result==native def test_yaml_string(): native={'foo': 'bar'} source=yaml.dump(native) result=load_source(source) assert result==native def test_json_file_object(): native={'foo': ", "label": 0}, {"snippet_id": 62672, "code": " state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice", "label": 0}, {"snippet_id": 89446, "code": ": public TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception", "label": 0}, {"snippet_id": 52095, "code": " files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath", "label": 0}, {"snippet_id": 37470, "code": " for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output", "label": 0}, {"snippet_id": 18170, "code": " from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification", "label": 0}, {"snippet_id": 92401, "code": ".assertIn('USER', os.environ) self.assertNotIn('AAA', os.environ) def test_hermetic_environment_unicode(self): UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output=UNICODE_CHAR if PY3", "label": 1}, {"snippet_id": 82906, "code": ",nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t", "label": 1}, {"snippet_id": 90956, "code": ".join('{}:[{}]'.format(str(key), ', '.join(sorted(val))) for key, val in OS_ALIASES.items()) register('--paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will", "label": 0}, {"snippet_id": 26103, "code": " more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from", "label": 1}, {"snippet_id": 26255, "code": ":weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy", "label": 0}, {"snippet_id": 73268, "code": "(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)) print(\"[Setup][Data] Decompressing file:", "label": 0}, {"snippet_id": 62842, "code": " observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in", "label": 0}, {"snippet_id": 50932, "code": " not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path", "label": 0}, {"snippet_id": 22243, "code": " self.conf: template=self.conf['template'] if log_file is None: if 'log_file' in self.conf: log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self", "label": 0}, {"snippet_id": 37163, "code": " in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old", "label": 0}, {"snippet_id": 79883, "code": " containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an", "label": 0}, {"snippet_id": 91795, "code": "'.format(test_target.address.reference()), ) result=yield Get(FallibleExecuteProcessResult, ExecuteProcessRequest, request) status=Status.SUCCESS if result.exit_code==0 else Status.FAILURE yield TestResult", "label": 0}, {"snippet_id": 54130, "code": " rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile", "label": 0}, {"snippet_id": 43764, "code": " global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules", "label": 0}, {"snippet_id": 65065, "code": "%s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update", "label": 0}, {"snippet_id": 84154, "code": " %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\"", "label": 0}, {"snippet_id": 92675, "code": "=False.') shutil.rmtree(path) def test_temporary_dir_with_root_dir(self): with temporary_dir() as path1: with temporary_dir(root_dir=path1) as path2: self.assertTrue(os.path.realpath(path2).startswith(os", "label": 0}, {"snippet_id": 41732, "code": " combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations", "label": 0}, {"snippet_id": 40644, "code": "(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value", "label": 1}, {"snippet_id": 54644, "code": " raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules", "label": 0}, {"snippet_id": 90972, "code": "=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm", "label": 0}, {"snippet_id": 65726, "code": " status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes", "label": 0}, {"snippet_id": 18641, "code": " UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic", "label": 0}, {"snippet_id": 63503, "code": ".params job_id=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id)", "label": 0}, {"snippet_id": 45476, "code": "\"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time):", "label": 1}, {"snippet_id": 93579, "code": ".stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting", "label": 0}, {"snippet_id": 27187, "code": "'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm'", "label": 0}, {"snippet_id": 52007, "code": " plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return ", "label": 0}, {"snippet_id": 47237, "code": "] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested", "label": 0}, {"snippet_id": 25717, "code": "\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state", "label": 0}, {"snippet_id": 28018, "code": "='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state", "label": 0}, {"snippet_id": 84021, "code": ")) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state=job", "label": 0}, {"snippet_id": 25723, "code": " Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=", "label": 0}, {"snippet_id": 18999, "code": " try: return yaml.load(raw_source) except(yaml.scanner.ScannerError, yaml.parser.ParserError): pass except NameError: pass raise ValueError( \"Unable to parse `{0}`. Tried yaml and json.\".format(source), ", "label": 1}, {"snippet_id": 38096, "code": ": return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames)", "label": 0}, {"snippet_id": 29055, "code": "\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 85231, "code": " be added automatically.'.format(name, self.version)) return '{0}_{1}'.format(name, self.version) @property def repl(self): \"\"\"Return the repl tool key.\"\"\" return self._key_for_tool_version('scala-repl',", "label": 1}, {"snippet_id": 89832, "code": " distribution has no valid command of the given name raises Distribution.Error. If this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if not isinstance(name, str): raise ValueError", "label": 0}, {"snippet_id": 11789, "code": " headers=headers, auth=auth) def update_dict(base, head): \"\"\" Recursively merge or update dict-like objects. >>> update({'k1': 1},{'k1':{'k2':{'k3': 3}}}) Source: http://stackoverflow.com/a/32357112/4698026", "label": 0}, {"snippet_id": 88287, "code": " pants.process.lock import OwnerPrintingInterProcessFileLock from pants.reporting.report import Report from pants.source.source_root import SourceRootConfig class Context(object): \"\"\"Contains the context", "label": 0}, {"snippet_id": 64714, "code": " > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self", "label": 1}, {"snippet_id": 93314, "code": "\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config", "label": 0}, {"snippet_id": 3264, "code": " dependency reference between %s and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def", "label": 0}, {"snippet_id": 58465, "code": ".username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run':[]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1", "label": 0}, {"snippet_id": 44580, "code": ") ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored", "label": 0}, {"snippet_id": 59425, "code": "(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def", "label": 0}, {"snippet_id": 86459, "code": ".java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.zinc import Zinc", "label": 0}, {"snippet_id": 67901, "code": " back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration", "label": 0}, {"snippet_id": 57192, "code": "%s changed from %s to %s.' %( field, getattr(t, field), value ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model, 'mail_scene'): mail_context", "label": 0}, {"snippet_id": 60411, "code": " ex, var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg", "label": 0}, {"snippet_id": 9522, "code": ": \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var", "label": 0}, {"snippet_id": 11571, "code": "(value)))) self.write_line(\"}\") @staticmethod def value_to_icinga(value): \"\"\"Convert a scalar or list to Icinga value format. Lists are concatenated by, and empty(None) values produce an empty string\"\"", "label": 1}, {"snippet_id": 55949, "code": " ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def", "label": 0}, {"snippet_id": 57585, "code": " mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context) except Exception: pass def _update_priority(self): exists=Priority.objects", "label": 0}, {"snippet_id": 90674, "code": "=self._scan_constraint_match(minimum_version, maximum_version, jdk) if not dist: dist=self._locate(minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) self._cache[key]=dist return", "label": 0}, {"snippet_id": 3565, "code": "'check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and ", "label": 0}, {"snippet_id": 64640, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from", "label": 0}, {"snippet_id": 28935, "code": " data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state", "label": 0}, {"snippet_id": 89638, "code": ".java)) @property def version(self): \"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" return self._get_version", "label": 0}, {"snippet_id": 27340, "code": ") dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name:", "label": 1}, {"snippet_id": 12640, "code": "\"submitting\", \"updating\"): PERMITTED_TO_COMMENT=False \"\"\" for old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body'].lower(): break elif 'quiet' in", "label": 0}, {"snippet_id": 78726, "code": " remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s", "label": 0}, {"snippet_id": 2412, "code": "=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list", "label": 0}, {"snippet_id": 13331, "code": " commit(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) fullname=data.get(\"fork_fullname\") for file, new_file in data", "label": 0}, {"snippet_id": 8789, "code": " input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path", "label": 0}, {"snippet_id": 48049, "code": " branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark", "label": 0}, {"snippet_id": 6238, "code": ".split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"", "label": 1}, {"snippet_id": 78353, "code": ".sleep(self.errortimeout) except exc.PermanentError as e: try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception(e) self", "label": 0}, {"snippet_id": 18673, "code": " except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info", "label": 0}, {"snippet_id": 29715, "code": " flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type", "label": 0}, {"snippet_id": 57730, "code": "=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case.count() review_case_count=plan.review_case.count", "label": 0}, {"snippet_id": 3608, "code": " procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(", "label": 1}, {"snippet_id": 60491, "code": " Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CoherentState': Coherent, 'DisplacedSqueezed': DisplacedSqueezed", "label": 0}, {"snippet_id": 87989, "code": " can't know which external classpath elements are required, and we'd have to put the entire external classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published", "label": 0}, {"snippet_id": 91433, "code": "'repl') task(name='setup-py', action=SetupPy).install() task(name='py', action=PythonBinaryCreate).install('binary') task(name='py-wheels', action=LocalPythonDistributionArtifact).install('binary') task", "label": 0}, {"snippet_id": 34200, "code": "(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, ", "label": 0}, {"snippet_id": 94062, "code": "\"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex", "label": 0}, {"snippet_id": 27985, "code": " if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self", "label": 0}, {"snippet_id": 43356, "code": " from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"", "label": 0}, {"snippet_id": 26649, "code": "='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state", "label": 0}, {"snippet_id": 63665, "code": "\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job", "label": 0}, {"snippet_id": 87650, "code": ", so won't be present for hermetic \" \"execution\".format(dep) ) if scala_path: snapshots.append( self.context._scheduler.capture_snapshots((PathGlobsAndRoot( PathGlobs(scala_path), get_buildroot(), ),))", "label": 0}, {"snippet_id": 63765, "code": "( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when", "label": 0}, {"snippet_id": 63681, "code": " the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid", "label": 0}, {"snippet_id": 93185, "code": ", datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts", "label": 0}, {"snippet_id": 7587, "code": " <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches", "label": 0}, {"snippet_id": 61010, "code": " spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian", "label": 0}, {"snippet_id": 35467, "code": " Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames,", "label": 0}, {"snippet_id": 21232, "code": " item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get", "label": 0}, {"snippet_id": 59343, "code": "(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed", "label": 0}, {"snippet_id": 68330, "code": ".LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout", "label": 0}, {"snippet_id": 51652, "code": ".items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern", "label": 0}, {"snippet_id": 62745, "code": ", Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password'", "label": 0}, {"snippet_id": 81842, "code": "\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=", "label": 0}, {"snippet_id": 68593, "code": ").print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict", "label": 0}, {"snippet_id": 65678, "code": "\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets", "label": 0}, {"snippet_id": 57331, "code": " not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field{} changed", "label": 0}, {"snippet_id": 60276, "code": " commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates", "label": 0}, {"snippet_id": 44297, "code": " and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger", "label": 0}, {"snippet_id": 58985, "code": "(TestGetObjectInfo, cls).setUpTestData() cls.get_info_url=reverse('ajax-info') cls.group_nitrate=EnvGroupFactory(name='nitrate') cls.group_new=EnvGroupFactory(name='NewGroup') cls.property_os=EnvPropertyFactory(name=", "label": 0}, {"snippet_id": 95645, "code": ".gz files to *.vcf, placed in output_dir. Additionally moves *.vcf files to output_dir Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir", "label": 0}, {"snippet_id": 27841, "code": "'WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state", "label": 0}, {"snippet_id": 20172, "code": ": if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None addr=('localhost', self._addr.port)", "label": 0}, {"snippet_id": 63658, "code": " stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out", "label": 0}, {"snippet_id": 38063, "code": "\"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self", "label": 0}, {"snippet_id": 54656, "code": " rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno", "label": 0}, {"snippet_id": 78229, "code": ", calling dologin() for now') self.dologin() def comment_loop(self): for t in self.targets: self.schedule(self.add_comment,(t, self.msgfun())) if len(self.targets)==0: self.schedule(self.scan_targets_loop", "label": 0}, {"snippet_id": 29333, "code": ".file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file", "label": 1}, {"snippet_id": 14436, "code": " not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def", "label": 0}, {"snippet_id": 51728, "code": ": if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist", "label": 0}, {"snippet_id": 747, "code": "() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id", "label": 0}, {"snippet_id": 13710, "code": " count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__", "label": 0}, {"snippet_id": 31926, "code": " self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any", "label": 0}, {"snippet_id": 84709, "code": "--ignored=ignored', '--list-file=input_files_list', '--report-file=report', ) req=ExecuteProcessRequest( argv=cmd, input_files=directory_digest, output_files=('ignored', 'report'), description='cloc', ", "label": 0}, {"snippet_id": 82403, "code": "\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity", "label": 0}, {"snippet_id": 61453, "code": "._state=state else: raise ValueError('State vector must be of length 2**wires.') continue U=DefaultQubit._get_operator_matrix(operation) if len(operation.wires)==1: U=self.expand_one(U, operation.wires) elif", "label": 0}, {"snippet_id": 68490, "code": "\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" %", "label": 0}, {"snippet_id": 59141, "code": " that only permits classical operations. -projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the", "label": 0}, {"snippet_id": 91983, "code": " return PythonSetup.global_instance() def pydist_has_native_sources(self, target): return target.has_sources(extension=tuple(self._native_source_extensions)) @memoized_property def _native_target_matchers", "label": 0}, {"snippet_id": 14509, "code": ", completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest(", "label": 0}, {"snippet_id": 44734, "code": "(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func):", "label": 0}, {"snippet_id": 12990, "code": " os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def", "label": 0}, {"snippet_id": 54222, "code": " snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"", "label": 0}, {"snippet_id": 43245, "code": " rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards", "label": 0}, {"snippet_id": 30506, "code": "(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def", "label": 0}, {"snippet_id": 55666, "code": ", lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0],", "label": 0}, {"snippet_id": 52904, "code": " omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ ", "label": 0}, {"snippet_id": 87103, "code": " zinc execution currently requires the workdir to be a child of the buildroot \" \"but workdir was{} and buildroot was{}\".format( self.get_options().pants_workdir, get_buildroot(), ) ) if self.get_options", "label": 0}, {"snippet_id": 62237, "code": " queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name,", "label": 0}, {"snippet_id": 20195, "code": "._run_server_ex=None def run(): try: self._session=self.SESSION.create_server(addr, **kwargs) except Exception as ex: self._run_server_ex=traceback.format_exc() t=new_hidden_thread( target=run, name='test.client', )", "label": 0}, {"snippet_id": 64597, "code": "\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on", "label": 0}, {"snippet_id": 91064, "code": " sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to \"{}\"; combining results.'.format(rename)) normalized[rename].extend(paths)", "label": 0}, {"snippet_id": 62094, "code": "). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4", "label": 0}, {"snippet_id": 82982, "code": ".submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not", "label": 1}, {"snippet_id": 42327, "code": " is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create", "label": 0}, {"snippet_id": 21747, "code": "(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt.title('Classifier(Test set)') plt.xlabel('Age') plt.ylabel('Estimated Salary')", "label": 0}, {"snippet_id": 74455, "code": ".items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username", "label": 0}, {"snippet_id": 85572, "code": " Pants run. :param products: The active Pants run products to pluck classpaths from. :type products::class:`pants.goal.products.Products` :returns: A Zinc instance with access to relevant Zinc compiler", "label": 0}, {"snippet_id": 68440, "code": " len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0:", "label": 0}, {"snippet_id": 77411, "code": " elif type_==1: if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if", "label": 0}, {"snippet_id": 12336, "code": " header, body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request.json[\"action\"]==\"opened\": if config[\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting", "label": 0}, {"snippet_id": 52567, "code": " for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name", "label": 0}, {"snippet_id": 4244, "code": ": log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry", "label": 0}, {"snippet_id": 49510, "code": " forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain", "label": 0}, {"snippet_id": 64289, "code": "._dataset_path( local_output_path, remote_path)) return results def input_paths( self): local_input_paths=self._wrapper_input_paths results=[] for local_input_path in local_input_paths: wrapper_path=str(", "label": 0}, {"snippet_id": 4527, "code": "(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords", "label": 0}, {"snippet_id": 89505, "code": " supplied. :param string home_path: the path to the java distribution's home dir :param string bin_path: the path to the java distribution's bin dir :param minimum_version: a modified semantic version string", "label": 0}, {"snippet_id": 95930, "code": " The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion :type input_vcf_path: str :type output_zarr_path: str", "label": 0}, {"snippet_id": 77231, "code": ".exception('Line %s raised exception %s', line, e) return newproxies.difference(self.proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try: proxypair=proxypairs.pop() except", "label": 0}, {"snippet_id": 80509, "code": ".keys(): \t\ts.cookies[key]=args.cookies[key] s.headers={'User-Agent':args.userAgent} s.trust_env=False if args.proxy: \tif args.proxy[\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging", "label": 0}, {"snippet_id": 28584, "code": "['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp", "label": 0}, {"snippet_id": 39588, "code": " return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 93448, "code": ".nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res: if node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(", "label": 0}, {"snippet_id": 63169, "code": " in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client", "label": 0}, {"snippet_id": 36248, "code": " self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format", "label": 0}, {"snippet_id": 75721, "code": ".IPV6, True) s.connect(self.sig_addr) s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL') s.setsockopt(zmq.SUBSCRIBE, b'WZWorker') s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8')) self.sig_sock=s s=self.ctx.socket", "label": 0}, {"snippet_id": 81588, "code": "=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog", "label": 1}, {"snippet_id": 55748, "code": ") rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric", "label": 0}, {"snippet_id": 81846, "code": " data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example:", "label": 0}, {"snippet_id": 64578, "code": "=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\"", "label": 0}, {"snippet_id": 2964, "code": ".start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s", "label": 0}, {"snippet_id": 2201, "code": "(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi", "label": 0}, {"snippet_id": 71489, "code": " def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose", "label": 0}, {"snippet_id": 14107, "code": " _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData", "label": 1}, {"snippet_id": 22279, "code": " as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger as logger import", "label": 0}, {"snippet_id": 36590, "code": "}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables", "label": 0}, {"snippet_id": 8239, "code": " config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify", "label": 1}, {"snippet_id": 90286, "code": " search_path.strip().split(os.pathsep): yield self.Location.from_bin(bin_path) class _OSXEnvironment(_DistributionEnvironment): _OSX_JAVA_HOME_EXE='/usr/libexec/java_home' @classmethod def standard(cls): return", "label": 0}, {"snippet_id": 43753, "code": ".config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def", "label": 0}, {"snippet_id": 21635, "code": "(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors import ListedColormap X_set, y_set=X_train, y_train X1, X2=np.meshgrid(np.arange(start=X_set[", "label": 0}, {"snippet_id": 65305, "code": "(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc=", "label": 0}, {"snippet_id": 53525, "code": " self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return", "label": 0}, {"snippet_id": 21564, "code": " elif x==1024: print(\"Reddytt: Forced exit detected. Saving and exiting.\") with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit", "label": 1}, {"snippet_id": 68292, "code": "], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column", "label": 0}, {"snippet_id": 16676, "code": ".EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), ", "label": 0}, {"snippet_id": 63506, "code": " job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\"", "label": 0}, {"snippet_id": 26173, "code": "'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', ", "label": 0}, {"snippet_id": 69791, "code": " client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node", "label": 1}, {"snippet_id": 49748, "code": ".updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main", "label": 0}, {"snippet_id": 70900, "code": "\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target", "label": 0}, {"snippet_id": 23015, "code": " which to look for devices \"\"\" patten=r'(sr[0-9]|hd[c-z]|cdrom[0-9]?)' for dvd in[re.match(patten, dev) for dev in os.listdir(dev_dir)]: if dvd is not None: return \"/dev/{0}\".format(dvd.group(0)) raise", "label": 0}, {"snippet_id": 18713, "code": "\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable", "label": 0}, {"snippet_id": 6618, "code": ".text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache,", "label": 0}, {"snippet_id": 27938, "code": "'GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)", "label": 0}, {"snippet_id": 29049, "code": " __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the", "label": 0}, {"snippet_id": 43788, "code": " concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder", "label": 0}, {"snippet_id": 94552, "code": "'list-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd", "label": 0}, {"snippet_id": 77927, "code": " targets[%s]', repr(t), domain) tlist.append(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Removing %s from targets[%s]", "label": 0}, {"snippet_id": 72747, "code": "; if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location", "label": 1}, {"snippet_id": 59539, "code": " backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise", "label": 0}, {"snippet_id": 59166, "code": " PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log", "label": 0}, {"snippet_id": 76705, "code": " help='EvaluatorProxy count') parser.add_argument('--upload-avatar', action='store_true', default=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default='randav',", "label": 0}, {"snippet_id": 26132, "code": ", DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger", "label": 1}, {"snippet_id": 49449, "code": " subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[", "label": 0}, {"snippet_id": 26983, "code": ".type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state", "label": 0}, {"snippet_id": 8856, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords", "label": 1}, {"snippet_id": 62884, "code": " expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2", "label": 0}, {"snippet_id": 46099, "code": "\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given", "label": 0}, {"snippet_id": 68291, "code": " target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 63344, "code": ".__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config", "label": 0}, {"snippet_id": 65720, "code": "\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type", "label": 0}, {"snippet_id": 66460, "code": ", rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount", "label": 0}, {"snippet_id": 62943, "code": " import url_to_destination_params from.lwr_client import finish_job as lwr_finish_job from.lwr_client import submit_job as lwr_submit_job from.lwr_client import ClientJobDescription from.lwr_client import", "label": 0}, {"snippet_id": 21278, "code": " videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label:', lk) continue new_links.append('https://www.youtube.com/watch?v=' +videolabel) return", "label": 0}, {"snippet_id": 83959, "code": " self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM", "label": 0}, {"snippet_id": 79366, "code": "\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t\t\t\tself.logger", "label": 0}, {"snippet_id": 87292, "code": "'.format(processor.strip())) @memoized_property def _zinc_cache_dir(self): \"\"\"A directory where zinc can store compiled copies of the `compiler-bridge`. The compiler-bridge is specific to each scala version", "label": 1}, {"snippet_id": 11732, "code": " INTO Users(repository, created_at) VALUES('{}', now());\" \\ \"\".format(repository) try: cursor.execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def follow_user(user): \"\"\"Follow", "label": 0}, {"snippet_id": 29918, "code": " isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values", "label": 0}, {"snippet_id": 4916, "code": ":keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['", "label": 0}, {"snippet_id": 20501, "code": "._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed read=recv_as_read(self._sock) for", "label": 0}, {"snippet_id": 4136, "code": " invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer", "label": 0}, {"snippet_id": 60928, "code": " the predefined circuit templates. .. todo:: rename to circuits? Returns: dict[str->Circuit]: circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns:", "label": 0}, {"snippet_id": 15990, "code": " headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method", "label": 0}, {"snippet_id": 89689, "code": " paths to requested libraries :raises: `Distribution.Error` if any of the jars could not be found. \"\"\" def collect_existing_libs(): def lib_paths(): yield os.path.join(self.home, 'lib') if self.jdk: yield", "label": 0}, {"snippet_id": 20251, "code": "+os.linesep +self._run_server_ex raise Exception(message) self._launch( argv, script=script, wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script", "label": 0}, {"snippet_id": 27704, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'", "label": 0}, {"snippet_id": 10413, "code": ": tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return", "label": 0}, {"snippet_id": 69272, "code": ": self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration", "label": 1}, {"snippet_id": 41016, "code": ") def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index", "label": 0}, {"snippet_id": 8902, "code": "=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig", "label": 0}, {"snippet_id": 92470, "code": " os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_nested_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1)", "label": 0}, {"snippet_id": 14099, "code": ") SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json", "label": 1}, {"snippet_id": 52941, "code": "\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if", "label": 0}, {"snippet_id": 81417, "code": " !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None):", "label": 0}, {"snippet_id": 31748, "code": " replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output", "label": 0}, {"snippet_id": 93406, "code": ": 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self", "label": 0}, {"snippet_id": 41664, "code": " else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule", "label": 0}, {"snippet_id": 19281, "code": " native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.json') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native", "label": 0}, {"snippet_id": 77659, "code": ".debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data['domains']) if 'sets' in data: self.log.debug('Other sets were", "label": 0}, {"snippet_id": 86457, "code": ".backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems", "label": 0}, {"snippet_id": 4693, "code": " the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or", "label": 0}, {"snippet_id": 66742, "code": " e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e", "label": 1}, {"snippet_id": 34322, "code": " ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo):", "label": 0}, {"snippet_id": 68122, "code": " fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY", "label": 0}, {"snippet_id": 58588, "code": ", self.case_run_2.pk): comments=Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self.assertEqual(new_comment, comments[0].comment) self.assertEqual(self.tester, comments[0].user", "label": 0}, {"snippet_id": 27981, "code": ".type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state", "label": 0}, {"snippet_id": 10484, "code": " text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import", "label": 0}, {"snippet_id": 4144, "code": " extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import", "label": 1}, {"snippet_id": 17195, "code": " import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT", "label": 0}, {"snippet_id": 3504, "code": "]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self", "label": 0}, {"snippet_id": 75472, "code": "(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-request', args, reqid)", "label": 0}, {"snippet_id": 815, "code": ") return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall", "label": 0}, {"snippet_id": 45454, "code": " os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink", "label": 1}, {"snippet_id": 79602, "code": ".basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests", "label": 0}, {"snippet_id": 18274, "code": ") self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename", "label": 1}, {"snippet_id": 39903, "code": ": \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow", "label": 0}, {"snippet_id": 79204, "code": " moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept:", "label": 0}, {"snippet_id": 36677, "code": " if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output", "label": 0}, {"snippet_id": 83185, "code": " runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport,", "label": 0}, {"snippet_id": 61236, "code": ".asarray(args[0]) if U.shape[0] !=U.shape[1]: raise ValueError(\"Operator must be a square matrix.\") if not np.allclose(U @ U.conj().T, np.identity(U.shape[0]), atol=tolerance): raise ValueError(\"Operator", "label": 0}, {"snippet_id": 64073, "code": " config -but there is no guarentee that it will contain all the datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\",", "label": 0}, {"snippet_id": 84684, "code": " ), ))[0] cloc_path, cloc_snapshot=ClocBinary.global_instance().hackily_snapshot(self.context) directory_digest=self.context._scheduler.merge_directories(tuple(s.directory_digest for s in input_snapshots", "label": 0}, {"snippet_id": 39937, "code": " import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f)", "label": 1}, {"snippet_id": 92347, "code": "], stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**{}): self.assertNotIn", "label": 1}, {"snippet_id": 81474, "code": ".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f) \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future", "label": 0}, {"snippet_id": 63034, "code": " app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url", "label": 0}, {"snippet_id": 36303, "code": " in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self", "label": 1}, {"snippet_id": 5689, "code": " the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches", "label": 0}, {"snippet_id": 58867, "code": "(cls): super(TestUpdateCasePriority, cls).setUpTestData() cls.permission='testcases.change_testcase' cls.case_update_url=reverse('ajax-update_cases_default_tester') def setUp(self): user_should_have_perm", "label": 0}, {"snippet_id": 30410, "code": " as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not", "label": 0}, {"snippet_id": 40552, "code": " value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v", "label": 0}, {"snippet_id": 27231, "code": " Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather", "label": 0}, {"snippet_id": 10021, "code": "[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword", "label": 0}, {"snippet_id": 88559, "code": " all targets in play for the run as returned by self.targets(). Note that for a command line invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target", "label": 0}, {"snippet_id": 84979, "code": " that plugin.') cls.register_jvm_tool(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True", "label": 0}, {"snippet_id": 43306, "code": " self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark", "label": 0}, {"snippet_id": 82676, "code": " args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds", "label": 0}, {"snippet_id": 21053, "code": " self._add_handler(handler, handlername) try: yield finally: wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event() def handler", "label": 0}, {"snippet_id": 56843, "code": " remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter(object): \"\"\" Used for counting the number of times a tag is assigned to TestRun/TestCase/TestPlan \"\"\" def", "label": 0}, {"snippet_id": 25303, "code": " vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }", "label": 0}, {"snippet_id": 6187, "code": " lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5", "label": 1}, {"snippet_id": 57202, "code": " User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model, 'mail_scene'): mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk", "label": 0}, {"snippet_id": 5651, "code": " output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"", "label": 0}, {"snippet_id": 69022, "code": "(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map=", "label": 0}, {"snippet_id": 57392, "code": " ) if mail_context: mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=='case_run_status': for t in targets: field", "label": 0}, {"snippet_id": 44563, "code": "(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources", "label": 0}, {"snippet_id": 20977, "code": "(msg) try: msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self", "label": 0}, {"snippet_id": 11355, "code": ".target_dir or not os.path.isdir(self.target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL:", "label": 0}, {"snippet_id": 655, "code": ".execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], ", "label": 0}, {"snippet_id": 66929, "code": " __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available", "label": 0}, {"snippet_id": 84858, "code": "._create_jardep('scala-library', version) @classmethod def _create_compiler_jardep(cls, version): return cls._create_jardep('scala-compiler', version) @classmethod def _key_for_tool_version(cls, tool, version):", "label": 1}, {"snippet_id": 79669, "code": "=\"\\n\\t * '\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\",", "label": 0}, {"snippet_id": 66512, "code": " RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 62487, "code": " default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={", "label": 0}, {"snippet_id": 40833, "code": "\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re", "label": 0}, {"snippet_id": 45129, "code": " ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=", "label": 0}, {"snippet_id": 73689, "code": " isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\"", "label": 0}, {"snippet_id": 59393, "code": ".__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs", "label": 0}, {"snippet_id": 89229, "code": ": build_graph.inject_address_closure(address) return build_graph def execute_process_synchronously(self, execute_process_request, name, labels=None): \"\"\"Executes a process(possibly remotely), and returns", "label": 1}, {"snippet_id": 32598, "code": " to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o", "label": 0}, {"snippet_id": 61971, "code": " import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map", "label": 0}, {"snippet_id": 90726, "code": " distribution is required to have a jdk. :return: the located Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" for location in", "label": 0}, {"snippet_id": 5434, "code": " keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw", "label": 0}, {"snippet_id": 58976, "code": "\"Test case for info view method\"\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData() cls.get_info_url=reverse('ajax-info') cls.group_nitrate=EnvGroupFactory(name='nitrate", "label": 0}, {"snippet_id": 73779, "code": " __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config", "label": 0}, {"snippet_id": 29915, "code": " combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable", "label": 0}, {"snippet_id": 95685, "code": " *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir=str(temp_dir) output_dir=str(output_dir) create_directory_tree(input_dir) create_directory_tree", "label": 0}, {"snippet_id": 72331, "code": " reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command", "label": 1}, {"snippet_id": 8011, "code": " len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1", "label": 0}, {"snippet_id": 80100, "code": ",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection arguments') manualFormArgs.add_argument", "label": 0}, {"snippet_id": 44460, "code": "(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list", "label": 0}, {"snippet_id": 23530, "code": "(password, crypt_id, salt_len) cmd=\"echo '{0}'|pw usermod{1} -H 0 \".format(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret !=0: raise OSUtilError((\"Failed to set password", "label": 0}, {"snippet_id": 73057, "code": "] Created local folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list", "label": 0}, {"snippet_id": 47403, "code": " f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f", "label": 0}, {"snippet_id": 71913, "code": " command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\"", "label": 0}, {"snippet_id": 52104, "code": " file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict", "label": 0}, {"snippet_id": 2826, "code": " def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name", "label": 0}, {"snippet_id": 86661, "code": " whitelisted_args.items()} def validate(idx): arg=args[idx] for pattern, has_argument in valid_patterns.items(): if pattern.match(arg): return 2 if has_argument else 1 log.warn(\"Zinc argument '{}' is not supported,", "label": 0}, {"snippet_id": 33592, "code": " in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False", "label": 0}, {"snippet_id": 8131, "code": ".mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os", "label": 0}, {"snippet_id": 31507, "code": " import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"", "label": 0}, {"snippet_id": 92502, "code": " self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os", "label": 0}, {"snippet_id": 64826, "code": ", None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf", "label": 0}, {"snippet_id": 73378, "code": " all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir", "label": 0}, {"snippet_id": 46669, "code": " WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(", "label": 0}, {"snippet_id": 46497, "code": ",(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda", "label": 0}, {"snippet_id": 87876, "code": "} for plugin{})'.format(arg, plugin)) ret.append('-C-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _scalac_plugin_args(self, scalac_plugin_map, classpath): if not scalac_plugin_map: return", "label": 0}, {"snippet_id": 78203, "code": ", targets)] or type(targets)==tuple and list(targets) or targets) super().__init__(*args, **kvargs) def on_caprate_limit(self, rate): if not self.logined: self._capdata=(0, 0) return self.log.warning('Caprate", "label": 0}, {"snippet_id": 50229, "code": "._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name", "label": 0}, {"snippet_id": 79317, "code": "=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback", "label": 0}, {"snippet_id": 80706, "code": "?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques", "label": 0}, {"snippet_id": 72376, "code": "): \"\"\"<protocol module name> Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for changes to apply.\"\"\" permissions.checkPermissions", "label": 0}, {"snippet_id": 93389, "code": " set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes:", "label": 0}, {"snippet_id": 70284, "code": " Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self):", "label": 0}, {"snippet_id": 40829, "code": " def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath", "label": 0}, {"snippet_id": 37119, "code": "(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return", "label": 1}, {"snippet_id": 60102, "code": "-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum", "label": 0}, {"snippet_id": 14129, "code": " data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data[ 'message'", "label": 0}, {"snippet_id": 13192, "code": " r.status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format(data[\"fork_fullname\"]) headers", "label": 0}, {"snippet_id": 51882, "code": " as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs", "label": 0}, {"snippet_id": 31422, "code": "\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run", "label": 0}, {"snippet_id": 83275, "code": " job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state", "label": 0}, {"snippet_id": 90044, "code": " if process.returncode !=0: raise self.Error('Failed to determine java system properties for{} with{} -exit code' '{}:{}'.format(java, ' '.join(cmd), process.returncode, stderr.decode('utf-8'))) props=", "label": 0}, {"snippet_id": 57543, "code": "\"\"\" case_ids=map(int, self.request.POST.getlist('case')) self._update_objects=TestCase.objects.filter(pk__in=case_ids) return self._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none", "label": 0}, {"snippet_id": 19652, "code": "('--server-host') parser.add_argument('--port', type=int, required=True) target=parser.add_mutually_exclusive_group(required=True) target.add_argument('-m', dest='module') target.add_argument('filename", "label": 0}, {"snippet_id": 26782, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self", "label": 0}, {"snippet_id": 39839, "code": " return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs", "label": 0}, {"snippet_id": 76823, "code": "'--die-on-neterror', action='store_true', default=False, help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net.RequestPerformer() noproxy_rp.proxy='' noproxy_rp", "label": 0}, {"snippet_id": 58268, "code": ".models import TestCaseRunStatus from tcms.tests import BaseCaseRun from tcms.tests import BasePlanCase from tcms.tests import remove_perm_from_user from tcms.tests import user_should_have_perm from tcms", "label": 0}, {"snippet_id": 13520, "code": ".setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def updateMouth():\r lastMouthEvent=0\r lastMouthEventTime=0\r \r while( audio==None):\r", "label": 0}, {"snippet_id": 38618, "code": "=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict()", "label": 0}, {"snippet_id": 17412, "code": " : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self", "label": 0}, {"snippet_id": 82755, "code": " if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set", "label": 0}, {"snippet_id": 70738, "code": " self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print ", "label": 1}, {"snippet_id": 75947, "code": ") >=timeout: for rs in rslist: if not rs.finished: rs.accept(None, 0, 255,[]) rs.finished=True raise WorkerInterrupt() def auth_requests(self): for i, m in self.wz_auth_requests: def accept(that, reqid", "label": 0}, {"snippet_id": 87142, "code": " register_extra_products_from_contexts(self, targets, compile_contexts): compile_contexts=[self.select_runtime_context(compile_contexts[t]) for t in targets] zinc_analysis=self.context.products.get_data('zinc_analysis') zinc_args", "label": 0}, {"snippet_id": 90109, "code": " locate the{} executable,{} does not appear to be a' ' valid{} distribution'.format(name, self, 'JDK' if self._jdk else 'JRE')) def _validated_executable(self, name): exe=self._validated_binaries.get(name", "label": 0}, {"snippet_id": 29696, "code": ", format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value", "label": 0}, {"snippet_id": 30650, "code": "() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output", "label": 0}, {"snippet_id": 4231, "code": " ) if api: return output else: if isinstance(output, dict): for i in output: print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os", "label": 0}, {"snippet_id": 41112, "code": " item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None,", "label": 0}, {"snippet_id": 65512, "code": " % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def", "label": 0}, {"snippet_id": 51203, "code": " contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex", "label": 0}, {"snippet_id": 66046, "code": " AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"", "label": 0}, {"snippet_id": 25622, "code": " data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\"", "label": 0}, {"snippet_id": 90325, "code": "-xml']) plist_results=plistlib.loads(plist) if PY3 else plistlib.readPlistFromString(plist) for distribution in plist_results: home=distribution['JVMHomePath'] yield self.Location.from_home(home) except", "label": 0}, {"snippet_id": 44056, "code": " self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items)", "label": 0}, {"snippet_id": 50282, "code": ": rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources", "label": 0}, {"snippet_id": 34555, "code": ".supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str", "label": 0}, {"snippet_id": 94202, "code": "/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename", "label": 0}, {"snippet_id": 13831, "code": " def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr,", "label": 0}, {"snippet_id": 48536, "code": " IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 68, "code": " \"\"\" PRETTY_NAME of your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi", "label": 0}, {"snippet_id": 91684, "code": " requirements_pex_request=ExecuteProcessRequest( argv=tuple(requirements_pex_argv), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=pex_snapshot.directory_digest,", "label": 1}, {"snippet_id": 55831, "code": " decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths,", "label": 0}, {"snippet_id": 43191, "code": ", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete", "label": 0}, {"snippet_id": 51093, "code": ".file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other,", "label": 0}, {"snippet_id": 33149, "code": " quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False", "label": 0}, {"snippet_id": 9629, "code": "\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw], encode_for_xml(categories[kw]))) for field, keywords in", "label": 0}, {"snippet_id": 43933, "code": "( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule", "label": 0}, {"snippet_id": 46219, "code": "*wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items", "label": 0}, {"snippet_id": 44840, "code": ", lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0],", "label": 0}, {"snippet_id": 3759, "code": " session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(", "label": 0}, {"snippet_id": 38230, "code": " from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import", "label": 1}, {"snippet_id": 24621, "code": "._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self", "label": 0}, {"snippet_id": 18925, "code": " string. \"\"\" if isinstance(source, collections.Mapping): return source elif hasattr(source, 'read') and callable(source.read): raw_source=source.read() elif os.path.exists(os.path.expanduser(str(source))):", "label": 0}, {"snippet_id": 81948, "code": " where uploads are put. Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default", "label": 0}, {"snippet_id": 82540, "code": "] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers", "label": 0}, {"snippet_id": 557, "code": ".username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor(", "label": 0}, {"snippet_id": 19821, "code": ", defaultport=port) self._connecttimeout=connecttimeout self._adapter=None self._session=None self._breakpoints=breakpoints @property def adapter(self): return self._adapter @property def session(self)", "label": 0}, {"snippet_id": 55105, "code": ", \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and", "label": 0}, {"snippet_id": 20607, "code": "(conn, owned=True, **kwargs) def __init__(self, conn, seq=1000, handlers=(), timeout=None, owned=False): super(DebugSession, self).__init__() self._conn=conn self._seq=seq self._timeout=timeout self._owned", "label": 0}, {"snippet_id": 84177, "code": " lwr_client) @staticmethod def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the", "label": 0}, {"snippet_id": 60505, "code": "'SqueezedState': Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'QuadraticPhase': Pgate, ", "label": 0}, {"snippet_id": 48390, "code": "._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item,", "label": 0}, {"snippet_id": 87190, "code": ") zinc_args[compile_context.target]=args def create_empty_extra_products(self): if self.context.products.is_required_data('zinc_analysis'): self.context.products.safe_create_data('zinc_analysis', dict)", "label": 0}, {"snippet_id": 41899, "code": ": raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output", "label": 0}, {"snippet_id": 40319, "code": " be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files", "label": 0}, {"snippet_id": 22433, "code": " config\" rc=shellutil.run(cmd) if rc !=0: logger.error(\"WARNING: Cannot save sys config on 1st boot.\") return rc def restart_ssh_service(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err", "label": 0}, {"snippet_id": 88461, "code": ".join(self._buildroot, '.pants.workdir.file_lock')) self._java_sysprops=None self.requested_goals=requested_goals or[] self._console_outstream=console_outstream or sys.stdout self._scm=scm or get_scm()", "label": 0}, {"snippet_id": 37311, "code": " *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name", "label": 0}, {"snippet_id": 51930, "code": ": next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield", "label": 0}, {"snippet_id": 11064, "code": " handle that.\" %(url, response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime=mtime) class Header(object): MON_CONF_GEN_COMMENT=' ETAG_COMMENT=' MTIME_COMMMENT", "label": 0}, {"snippet_id": 175, "code": " add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={", "label": 0}, {"snippet_id": 85544, "code": ", 'compiler-bridge', cls.options_scope) @classmethod def _compiler_interface(cls, products): return cls.tool_jar_from_products(products, 'compiler-interface', cls.options_scope) def create(self, products", "label": 0}, {"snippet_id": 72248, "code": ".services: irc.error('Unknown service %r.' % args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply", "label": 0}, {"snippet_id": 63643, "code": ") return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log", "label": 0}, {"snippet_id": 7923, "code": " c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature", "label": 0}, {"snippet_id": 93321, "code": "\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups", "label": 0}, {"snippet_id": 15551, "code": "._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification", "label": 0}, {"snippet_id": 17566, "code": ".Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self", "label": 0}, {"snippet_id": 65969, "code": ": status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE", "label": 0}, {"snippet_id": 33606, "code": " True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain", "label": 0}, {"snippet_id": 56543, "code": "'.')[0], q_app_form.split('.')[1] exec('from tcms.%s.forms import %s as form' %(q_app, q_form)) __import__('tcms.%s.forms' % q_app) q_app_module=sys.modules['tcms.%s.forms' % q_app] form_class=getattr(q_app_module", "label": 1}, {"snippet_id": 64060, "code": " server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is no guarentee that it will contain all the datatypes available", "label": 0}, {"snippet_id": 79904, "code": " matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\"", "label": 0}, {"snippet_id": 12340, "code": " comment_header=\"\" if request.json[\"action\"]==\"opened\": if config[\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message", "label": 0}, {"snippet_id": 24173, "code": " None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%'", "label": 0}, {"snippet_id": 73528, "code": "(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config", "label": 0}, {"snippet_id": 61567, "code": ": raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)) if not callable(operator_map[A.name]): return operator_map[A.name] p=[x.val if isinstance(x, Variable) else x for x in", "label": 0}, {"snippet_id": 76292, "code": " unbind_methods(self): for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status,", "label": 0}, {"snippet_id": 26208, "code": "':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi", "label": 0}, {"snippet_id": 31197, "code": " _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources", "label": 0}, {"snippet_id": 11710, "code": " psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is", "label": 0}, {"snippet_id": 86405, "code": ".directory_digest, output_files=output_files, description='Compiling{} with javac'.format(ctx.target.address.spec), ) exec_result=self.context.execute_process_synchronously( exec_process_request, 'javac", "label": 1}, {"snippet_id": 62789, "code": " required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, ", "label": 0}, {"snippet_id": 28001, "code": "._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state", "label": 0}, {"snippet_id": 4682, "code": " defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects ", "label": 0}, {"snippet_id": 50746, "code": " __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections", "label": 0}, {"snippet_id": 84049, "code": ") is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self)", "label": 0}, {"snippet_id": 68120, "code": "(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags", "label": 0}, {"snippet_id": 38029, "code": " bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l", "label": 0}, {"snippet_id": 23350, "code": " azurelinuxagent.common.logger as logger from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil from azurelinuxagent.common.future import ustr", "label": 0}, {"snippet_id": 85249, "code": "'scala-repl', self.version) def injectables(self, build_graph): if self.version=='custom': return specs_to_create=[ ('scalac', self._create_compiler_jardep), ('scala-library', self._create_runtime_jardep)", "label": 1}, {"snippet_id": 75016, "code": " file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location", "label": 0}, {"snippet_id": 34037, "code": " **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has", "label": 0}, {"snippet_id": 67602, "code": "%s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 57717, "code": " say_no('No plan record found.') confirm_status_name='CONFIRMED' plan.run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name", "label": 0}, {"snippet_id": 49198, "code": "._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self):", "label": 0}, {"snippet_id": 59752, "code": ", **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly", "label": 0}, {"snippet_id": 78576, "code": ".schedule(self.comment_loop) return if len(self.forums)==0: with cstate(self, WipeState.waiting_for_targets): while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop", "label": 0}, {"snippet_id": 14179, "code": ".command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification", "label": 0}, {"snippet_id": 24163, "code": " MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure", "label": 1}, {"snippet_id": 48001, "code": ".protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear(", "label": 0}, {"snippet_id": 81470, "code": " ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f) \t\t\t\tfor", "label": 0}, {"snippet_id": 92885, "code": " uuid_str=str(uuid.uuid4()) def u(string): return '{} stdin_data=u('stdio') stdout_data=u('stdout') stderr_data=u('stderr') with temporary_file(binary_mode=False) as tmp_stdin,\\ temporary_file(binary_mode", "label": 0}, {"snippet_id": 11666, "code": " yaml config!\".format(arg['URL'])) exit_code=EXIT_CODE_NOT_WRITTEN except ConfigurationContainsUndefinedVariables: LOG.error(\"Configuration contained undefined variables!\") exit_code=EXIT_CODE_ERROR except", "label": 0}, {"snippet_id": 85328, "code": " Java from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.shader import Shader from", "label": 0}, {"snippet_id": 37671, "code": " start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def", "label": 0}, {"snippet_id": 92222, "code": ", object, range, str from contextlib import contextmanager import mock from future.utils import PY3 from pants.util.contextutil import(InvalidZipPath, Timer, environment_as, exception_logging, hermetic_environment_as", "label": 0}, {"snippet_id": 21781, "code": " 2]=labelencoder_X_2.fit_transform(X[:, 2]) onehotencoder=OneHotEncoder(categorical_features=[1]) X=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn.model_selection import train_test_split", "label": 1}, {"snippet_id": 80327, "code": "]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not-regex or with --true-regex.\") if args.legitExtensions", "label": 0}, {"snippet_id": 43247, "code": "\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input", "label": 0}, {"snippet_id": 95907, "code": "(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data", "label": 1}, {"snippet_id": 87619, "code": ".context._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests", "label": 1}, {"snippet_id": 75910, "code": "[2], rs.accept, request[1][3]) msg.insert(0, b'') msgdict[rs]=msg s.send_multipart(msg) while self.running.is_set(): flag=0 for rs in rslist: if rs.finished: if not rs.retry: del msgdict[rs] continue s", "label": 0}, {"snippet_id": 5754, "code": "[1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn", "label": 0}, {"snippet_id": 35141, "code": "[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def", "label": 0}, {"snippet_id": 14728, "code": "}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[", "label": 0}, {"snippet_id": 15763, "code": "._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( ", "label": 0}, {"snippet_id": 57064, "code": "={'rc': 1, 'response': error_msg} return HttpResponse(json.dumps(ajax_response)) def say_yes(): return HttpResponse(json.dumps({'rc': 0, 'response': 'ok'})) @require_POST def update(request): \"\"\" Generic", "label": 0}, {"snippet_id": 93004, "code": "(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self): with self._stdio_as_tempfiles", "label": 0}, {"snippet_id": 67900, "code": " either stand back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine", "label": 0}, {"snippet_id": 62283, "code": " result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires", "label": 0}, {"snippet_id": 46153, "code": " combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values,", "label": 0}, {"snippet_id": 23801, "code": " return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout={0}'.format(timeout)) if ret: raise OSUtilError(\"Failed set SCSI disks timeout:{0}\".format(output)) self._scsi_disks_timeout_set", "label": 0}, {"snippet_id": 66146, "code": ".1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size", "label": 0}, {"snippet_id": 90796, "code": " pass if(minimum_version is not None and maximum_version is not None and maximum_version < minimum_version): error_format=('Pants configuration/options led to impossible constraints for{} ' 'distribution:", "label": 0}, {"snippet_id": 70302, "code": " get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR", "label": 0}, {"snippet_id": 47335, "code": " unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG", "label": 0}, {"snippet_id": 39584, "code": "(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths", "label": 0}, {"snippet_id": 16654, "code": "): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler", "label": 0}, {"snippet_id": 60245, "code": "} class StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified", "label": 0}, {"snippet_id": 81711, "code": "[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms", "label": 0}, {"snippet_id": 25865, "code": "] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=", "label": 0}, {"snippet_id": 12344, "code": "\"opened\": if config[\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request", "label": 0}, {"snippet_id": 39910, "code": ". \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow", "label": 0}, {"snippet_id": 68964, "code": "%(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s:", "label": 1}, {"snippet_id": 40802, "code": " Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join", "label": 0}, {"snippet_id": 83883, "code": " errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0]", "label": 0}, {"snippet_id": 43903, "code": ": raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger", "label": 0}, {"snippet_id": 40627, "code": " shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): ", "label": 0}, {"snippet_id": 4785, "code": " name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number", "label": 0}, {"snippet_id": 95662, "code": ", and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir", "label": 0}, {"snippet_id": 42751, "code": ": self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define", "label": 0}, {"snippet_id": 734, "code": " for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS", "label": 0}, {"snippet_id": 36874, "code": "\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake", "label": 0}, {"snippet_id": 46, "code": " import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(", "label": 1}, {"snippet_id": 12669, "code": "): comment_mode=None headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/{}/issues/{}/comments", "label": 0}, {"snippet_id": 88500, "code": " the new-style options. :API: public \"\"\" return self._options @property def log(self): \"\"\"Returns the preferred logger for goals to use. :API: public \"\"\" return self._log @property def products(self): \"\"", "label": 0}, {"snippet_id": 95758, "code": " filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path", "label": 0}, {"snippet_id": 75388, "code": ".set_response_handler(reqid, fun) return msg def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface, method, args", "label": 0}, {"snippet_id": 83119, "code": " import PathMapper log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR", "label": 0}, {"snippet_id": 73038, "code": " remote_subdirs_list=[] remote_path_relative=\"\" remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP] Created local folder:", "label": 0}, {"snippet_id": 4494, "code": "(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms", "label": 0}, {"snippet_id": 22130, "code": " loader=self.loader, options=self.options, passwords={}) def run(self, job_id): \"\"\"Run the playbook and returns the playbook's stats.\"\"\" self.variable_manager.extra_vars={'job_id': job_id} self.pbex.run(", "label": 0}, {"snippet_id": 26824, "code": "] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0", "label": 0}, {"snippet_id": 16142, "code": " ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import", "label": 0}, {"snippet_id": 55475, "code": " dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile", "label": 0}, {"snippet_id": 19781, "code": " ptvsd.socket import Address from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.debugadapter import DebugAdapter, wait_for_socket_server from.debugsession import DebugSession class _LifecycleClient", "label": 0}, {"snippet_id": 8449, "code": " not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words", "label": 1}, {"snippet_id": 69602, "code": " from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model", "label": 0}, {"snippet_id": 52144, "code": " YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self", "label": 0}, {"snippet_id": 22599, "code": " command fails, but the hostname will not be what the user set either. Currently we do not set the hostname when WAAgent starts up, so I am passing on setting it here too. :param hostname: The hostname", "label": 0}, {"snippet_id": 87356, "code": ".pants_bootstrapdir, 'zinc', key) def compile(self, ctx, args, dependency_classpath, upstream_analysis, settings, compiler_option_sets, zinc_file_manager, javac_plugin_map, scalac_plugin_map): absolute_classpath", "label": 1}, {"snippet_id": 67176, "code": "\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import", "label": 0}, {"snippet_id": 5755, "code": " / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn", "label": 0}, {"snippet_id": 6880, "code": " are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position", "label": 0}, {"snippet_id": 96052, "code": " shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print(\"[VCF-Zarr", "label": 1}, {"snippet_id": 5014, "code": " should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents", "label": 0}, {"snippet_id": 19027, "code": "(raw_schema, context=context) swagger_schema=swagger_schema_validator( raw_schema, context=swagger_definitions, ) return swagger_schema def load(target): \"\"\" Given one of the supported target formats, load", "label": 0}, {"snippet_id": 53278, "code": ") self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources", "label": 0}, {"snippet_id": 8794, "code": " read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path", "label": 0}, {"snippet_id": 87150, "code": " for t in targets] zinc_analysis=self.context.products.get_data('zinc_analysis') zinc_args=self.context.products.get_data('zinc_args') if zinc_analysis is not None: for compile_context in compile_contexts", "label": 0}, {"snippet_id": 65128, "code": ": def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 122, "code": "[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps", "label": 0}, {"snippet_id": 18156, "code": ".client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request", "label": 0}, {"snippet_id": 23749, "code": ".format(output)) try: return int(output)/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output", "label": 0}, {"snippet_id": 79677, "code": "]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData", "label": 0}, {"snippet_id": 14420, "code": ".readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def", "label": 0}, {"snippet_id": 81345, "code": ".search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult", "label": 0}, {"snippet_id": 91806, "code": "(FallibleExecuteProcessResult, ExecuteProcessRequest, request) status=Status.SUCCESS if result.exit_code==0 else Status.FAILURE yield TestResult( status=status, stdout=result.stdout.decode('utf-8'), stderr=result.stderr", "label": 0}, {"snippet_id": 93289, "code": " session by name \"%s\" on server' % self.session_name) else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name", "label": 0}, {"snippet_id": 12384, "code": " PR.\\n\\n\" else: comment_header=config[\"message\"][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors", "label": 0}, {"snippet_id": 89463, "code": " \"\"\" class Error(Exception): \"\"\"Indicates an invalid java distribution.\"\"\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None", "label": 0}, {"snippet_id": 43593, "code": " import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging", "label": 0}, {"snippet_id": 38155, "code": ") comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def", "label": 0}, {"snippet_id": 46016, "code": "\"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): ", "label": 0}, {"snippet_id": 26369, "code": " module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data", "label": 1}, {"snippet_id": 53078, "code": ".incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{", "label": 0}, {"snippet_id": 19772, "code": " debug_main(addr, name, kind, *extra, **kwargs) if __name__=='__main__': args, extra=parse_args() main(args.address, args.name, args.kind, extra, nodebug=args.nodebug, singlesession=args.single_session", "label": 1}, {"snippet_id": 61196, "code": " an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised array. \"\"\" state=np.asarray(args) return state/np.linalg.norm(state) def unitary(*args): r\"\"\"Input validation for an", "label": 0}, {"snippet_id": 79476, "code": ": \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or", "label": 0}, {"snippet_id": 96012, "code": "=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config", "label": 0}, {"snippet_id": 59455, "code": "+'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to", "label": 1}, {"snippet_id": 66731, "code": ".message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s", "label": 1}, {"snippet_id": 39036, "code": " elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence", "label": 0}, {"snippet_id": 80383, "code": " \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey", "label": 0}, {"snippet_id": 44801, "code": ".add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, ", "label": 0}, {"snippet_id": 28095, "code": "\" Support for the NetAtmo Weather Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime", "label": 1}, {"snippet_id": 50727, "code": " class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.", "label": 0}, {"snippet_id": 6784, "code": " acronyms={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords", "label": 0}, {"snippet_id": 11645, "code": "], arg['--debug'], arg['--targetdir'], arg['--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN if file_name else EXIT_CODE_NOT_WRITTEN except HostUnreachableException: LOG.warn(\"Target url{0", "label": 0}, {"snippet_id": 13824, "code": "=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del", "label": 0}, {"snippet_id": 28141, "code": " Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta", "label": 1}, {"snippet_id": 15523, "code": "._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def", "label": 0}, {"snippet_id": 70376, "code": "[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths", "label": 0}, {"snippet_id": 80553, "code": "\"password\"] \telse: \t\tproxyUser=args.proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" ", "label": 0}, {"snippet_id": 30612, "code": ".wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio,", "label": 0}, {"snippet_id": 6847, "code": ", position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound", "label": 0}, {"snippet_id": 18146, "code": ".completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import", "label": 0}, {"snippet_id": 17001, "code": ": return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666", "label": 0}, {"snippet_id": 80423, "code": " damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \")", "label": 0}, {"snippet_id": 77725, "code": " with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru' and t['forum']=='anonymous'", "label": 0}, {"snippet_id": 78825, "code": "\tself.notRegex=notRegex \t\tself.inputName=inputName \t\tself.uploadsFolder=uploadsFolder \t\tself.size=size \t\tself.validExtensions=[] \t\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None \t\tself.logLock=Lock()", "label": 0}, {"snippet_id": 27605, "code": "='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 93408, "code": "'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep])", "label": 0}, {"snippet_id": 67419, "code": ".RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__", "label": 0}, {"snippet_id": 22862, "code": " if userentry is None: raise OSUtilError(\"The 'admin' user account was not found!\") cmd=\"/usr/bin/tmsh modify auth user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd,", "label": 0}, {"snippet_id": 78125, "code": ") def send_passthrough(frames): msg=[b'WipeManager'] msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames)) sig_sock.send_multipart(msg) def drop_users(): send_passthrough([b'WipeSkel',", "label": 0}, {"snippet_id": 58316, "code": "() cls.user=UserFactory(email='user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses(self): self.client.login( username=self.user.username, password", "label": 0}, {"snippet_id": 86254, "code": ") javac_cmd.extend(args) if fatal_warnings: javac_cmd.extend(self.get_options().fatal_warnings_enabled_args) else: javac_cmd.extend(self.get_options().fatal_warnings_disabled_args) with argfile.safe_args", "label": 0}, {"snippet_id": 76405, "code": " as e: self.log.error(e) return if socks.get(self.sig_sock)==zmq.POLLIN: frames=self.sig_sock.recv_multipart() try: self.wz.parse_msg(frames[0], frames[1:]) except wzrpc.WZError as e: self.log.warn(e) if", "label": 0}, {"snippet_id": 86129, "code": ")) def execute(self): if JvmPlatform.global_instance().get_options().compiler=='javac': return super(JavacCompile, self).execute() def compile(self, ctx, args, dependency_classpath, upstream_analysis, settings", "label": 0}, {"snippet_id": 93276, "code": ".session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self.logger.info('starting", "label": 0}, {"snippet_id": 78479, "code": "'1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page))) for t in found: if(t in self.pc.sets['closed'] or t", "label": 1}, {"snippet_id": 18055, "code": "=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status", "label": 0}, {"snippet_id": 8759, "code": " spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms ) if api", "label": 0}, {"snippet_id": 34607, "code": " ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os", "label": 1}, {"snippet_id": 62263, "code": " Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self,", "label": 0}, {"snippet_id": 32483, "code": ".update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards", "label": 0}, {"snippet_id": 34601, "code": " file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists", "label": 0}, {"snippet_id": 23955, "code": " port_id > 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=\"000\" +ustr(port_id) g0g1=\"{0}-{1}\".format", "label": 0}, {"snippet_id": 77650, "code": "') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update", "label": 0}, {"snippet_id": 31743, "code": " not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard", "label": 0}, {"snippet_id": 62335, "code": "(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None", "label": 0}, {"snippet_id": 9456, "code": " composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms", "label": 0}, {"snippet_id": 3376, "code": ".logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" ", "label": 0}, {"snippet_id": 51067, "code": " regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self", "label": 0}, {"snippet_id": 27795, "code": "'WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 63444, "code": " get_input_files(self, job_wrapper): input_paths=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr", "label": 0}, {"snippet_id": 19219, "code": ": source={'foo': 'bar'} result=load_source(source) assert result==source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source(source) assert result==native def test_yaml_string", "label": 1}, {"snippet_id": 8216, "code": "'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import", "label": 1}, {"snippet_id": 90982, "code": " before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS can be specified via several different ' 'aliases, according to this map", "label": 0}, {"snippet_id": 5396, "code": "]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str", "label": 0}, {"snippet_id": 16599, "code": " SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self", "label": 0}, {"snippet_id": 82847, "code": "(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads", "label": 0}, {"snippet_id": 3248, "code": " node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex", "label": 0}, {"snippet_id": 89632, "code": " of this java distribution.\"\"\" return dict(self._get_system_properties(self.java)) @property def version(self): \"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is not", "label": 0}, {"snippet_id": 78322, "code": " self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except ValueError as e:", "label": 1}, {"snippet_id": 54017, "code": ", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete", "label": 0}, {"snippet_id": 34101, "code": ".priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if", "label": 0}, {"snippet_id": 2895, "code": "'%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self", "label": 0}, {"snippet_id": 52718, "code": " check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This", "label": 0}, {"snippet_id": 22618, "code": " hostname to set on the device \"\"\" return None def set_dhcp_hostname(self, hostname): \"\"\"Sets the DHCP hostname See `set_hostname` for an explanation of why I pass here :param hostname: The hostname to", "label": 0}, {"snippet_id": 34682, "code": "(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self", "label": 0}, {"snippet_id": 24768, "code": " self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state", "label": 0}, {"snippet_id": 60141, "code": "\n \"\"\"This module contains the device class and context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields", "label": 0}, {"snippet_id": 53871, "code": " **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable", "label": 0}, {"snippet_id": 94121, "code": "=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave", "label": 0}, {"snippet_id": 20915, "code": " if self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings", "label": 0}, {"snippet_id": 87175, "code": ", compile_context.analysis_file) if zinc_args is not None: for compile_context in compile_contexts: with open(compile_context.zinc_args_file, 'r') as fp: args=fp.read().split() zinc_args[compile_context", "label": 0}, {"snippet_id": 14103, "code": " SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy(", "label": 1}, {"snippet_id": 69683, "code": " installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs", "label": 0}, {"snippet_id": 71209, "code": "\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target", "label": 0}, {"snippet_id": 20671, "code": " _create_request(self, command, **args): seq=self._seq self._seq +=1 return{ 'type': 'request', 'seq': seq, 'command': command, 'arguments': args, } def send_request(self, command, **args): if self.closed: raise", "label": 0}, {"snippet_id": 86427, "code": " division, print_function, unicode_literals import errno import logging import os import re import textwrap from builtins import open from collections import defaultdict from contextlib import closing from", "label": 1}, {"snippet_id": 74095, "code": " configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted", "label": 0}, {"snippet_id": 89703, "code": ": yield os.path.join(self.home, 'lib') if self.jdk: yield os.path.join(self.home, 'jre', 'lib') for name in names: for path in lib_paths(): lib_path=os.path.join(path, name) if os.path.exists(lib_path)", "label": 0}, {"snippet_id": 30386, "code": " pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries", "label": 0}, {"snippet_id": 4029, "code": ".set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check()", "label": 0}, {"snippet_id": 56449, "code": ".product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties(self): if self.request.GET.get('env_group_id'): return EnvGroup.objects.get(id=self.request.GET['env_group_id']).property.all", "label": 0}, {"snippet_id": 57272, "code": "'tested_by' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), request.user ) ) field='assignee' try: assignee=t.assginee if assignee !=request.user: t", "label": 0}, {"snippet_id": 80203, "code": "\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames", "label": 0}, {"snippet_id": 59280, "code": " has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend: use_hardware(bool): If True, the", "label": 0}, {"snippet_id": 71238, "code": ".1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags", "label": 0}, {"snippet_id": 55369, "code": " if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores", "label": 0}, {"snippet_id": 13732, "code": " safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self", "label": 0}, {"snippet_id": 11296, "code": " NoSuchHostname, HostUnreachableException from monitoring_config_generator import set_log_level_to_debug from monitoring_config_generator.yaml_tools.readers import Header, read_config from monitoring_config_generator", "label": 0}, {"snippet_id": 58975, "code": ": \"\"\"Test case for info view method\"\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData() cls.get_info_url=reverse('ajax-info') cls.group_nitrate=EnvGroupFactory(name='nitrate", "label": 0}, {"snippet_id": 41887, "code": ".exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def", "label": 0}, {"snippet_id": 89429, "code": " minimum version can be specified if you know need to compile source code or run bytecode that exercise features only available in that version forward. :API: public TODO(John Sirois): This class has a broken", "label": 0}, {"snippet_id": 40988, "code": " self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name", "label": 0}, {"snippet_id": 11791, "code": ") def update_dict(base, head): \"\"\" Recursively merge or update dict-like objects. >>> update({'k1': 1},{'k1':{'k2':{'k3': 3}}}) Source: http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in", "label": 0}, {"snippet_id": 36968, "code": ") self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno", "label": 0}, {"snippet_id": 227, "code": "=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname", "label": 0}, {"snippet_id": 35778, "code": " except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist", "label": 0}, {"snippet_id": 67366, "code": " indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(),", "label": 0}, {"snippet_id": 17407, "code": "') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else", "label": 0}, {"snippet_id": 49379, "code": " local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None,", "label": 0}, {"snippet_id": 44949, "code": ".version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo", "label": 0}, {"snippet_id": 18074, "code": " response.text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global", "label": 0}, {"snippet_id": 19007, "code": ".ParserError): pass except NameError: pass raise ValueError( \"Unable to parse `{0}`. Tried yaml and json.\".format(source), ) def parse(raw_schema): context={ 'deferred_references': set(), } swagger_definitions", "label": 0}, {"snippet_id": 33926, "code": "._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir", "label": 0}, {"snippet_id": 94654, "code": " ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser", "label": 0}, {"snippet_id": 93635, "code": " start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name", "label": 0}, {"snippet_id": 44694, "code": " logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code,", "label": 0}, {"snippet_id": 13870, "code": " ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object", "label": 0}, {"snippet_id": 89271, "code": " this is an unstable, experimental API, which is subject to change with no notice. \"\"\" with self.new_workunit( name=name, labels=labels, cmd=' '.join(execute_process_request.argv), ) as workunit: result", "label": 0}, {"snippet_id": 52889, "code": " +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name", "label": 0}, {"snippet_id": 54590, "code": " global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules", "label": 0}, {"snippet_id": 54212, "code": " return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException", "label": 0}, {"snippet_id": 76206, "code": " m) self.wz.del_req_handler(i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Route unbinded for(%s, %s)', i, m) else: self.log.warn('Status %s, passing", "label": 0}, {"snippet_id": 15277, "code": "._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort()", "label": 1}, {"snippet_id": 17881, "code": " pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( ''", "label": 0}, {"snippet_id": 94920, "code": " for where is the config file. \"\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title", "label": 0}, {"snippet_id": 62952, "code": " submit_job as lwr_submit_job from.lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__", "label": 0}, {"snippet_id": 32110, "code": " specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start", "label": 0}, {"snippet_id": 3326, "code": " check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" })", "label": 0}, {"snippet_id": 29970, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{", "label": 0}, {"snippet_id": 48202, "code": " rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments", "label": 0}, {"snippet_id": 45123, "code": " ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def", "label": 0}, {"snippet_id": 4305, "code": " process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False", "label": 0}, {"snippet_id": 76162, "code": " self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m", "label": 0}, {"snippet_id": 28835, "code": "._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type==", "label": 0}, {"snippet_id": 50769, "code": " Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in", "label": 1}, {"snippet_id": 28008, "code": "._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=", "label": 0}, {"snippet_id": 46356, "code": " consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall", "label": 0}, {"snippet_id": 57904, "code": "').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun found.') add_comment(runs, comment", "label": 0}, {"snippet_id": 15231, "code": ".format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800", "label": 0}, {"snippet_id": 6958, "code": " string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string", "label": 0}, {"snippet_id": 27677, "code": " self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 28114, "code": " datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE,", "label": 1}, {"snippet_id": 69176, "code": "%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage", "label": 0}, {"snippet_id": 22703, "code": " exists, skip useradd\", username) return None cmd=\"/usr/bin/tmsh create auth user %s partition-access add{ all-partitions{ role admin}} shell bash\" %(username) retcode, out=shellutil.run_get_output(cmd", "label": 0}, {"snippet_id": 95435, "code": "({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory", "label": 0}, {"snippet_id": 42404, "code": ".snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message", "label": 0}, {"snippet_id": 43010, "code": " if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 87206, "code": "'zinc_analysis', dict) if self.context.products.is_required_data('zinc_args'): self.context.products.safe_create_data('zinc_args', lambda: defaultdict(list)) def javac_classpath(self): return Java.global_javac_classpath", "label": 0}, {"snippet_id": 49110, "code": ".first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count", "label": 0}, {"snippet_id": 777, "code": "': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'],", "label": 0}, {"snippet_id": 85749, "code": "() def cp(instance, toolname): scope=instance.options_scope return instance.tool_classpath_from_products(self._products, toolname, scope=scope) classpaths=(cp(java_options_src, 'javac-plugin-dep') + cp", "label": 0}, {"snippet_id": 57106, "code": "') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk", "label": 0}, {"snippet_id": 81274, "code": "\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:(filename,fd", "label": 1}, {"snippet_id": 5913, "code": "\n \"\"\" BibClassify text extractor. This module provides method to extract the fulltext from local or remote documents. Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide", "label": 1}, {"snippet_id": 94068, "code": ": self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red", "label": 0}, {"snippet_id": 21493, "code": "(subreddit_link) if depth > 0: for d in range(depth): link=\"\" for l in links: if re.search(\"after=\", l): link=l if link==\"\": print(\"Reddytt: Could not identify 'after'-variable to progress deeper.\") else:", "label": 0}, {"snippet_id": 866, "code": " data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep", "label": 0}, {"snippet_id": 50952, "code": "& ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self", "label": 0}, {"snippet_id": 57899, "code": "=[i for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun found", "label": 0}, {"snippet_id": 77293, "code": ".info('Starting %s(s)', wname) if issubclass(wclass, workers.WZWorkerThread): type_=0 if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock()", "label": 0}, {"snippet_id": 76416, "code": ".parse_msg(frames[0], frames[1:]) except wzrpc.WZError as e: self.log.warn(e) if socks.get(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg(self", "label": 0}, {"snippet_id": 81758, "code": " coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\")", "label": 0}, {"snippet_id": 19081, "code": " the provided schema. \"\"\" schema=schema_validator(raw_schema, **kwargs) if target is not None: validate_object(target, schema=schema, **kwargs) def validate_api_request(schema, raw_request): request=normalize_request", "label": 0}, {"snippet_id": 70876, "code": "\"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs", "label": 0}, {"snippet_id": 90833, "code": ")) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions are searched for in the following order by default: 1. Paths listed for this operating", "label": 0}, {"snippet_id": 81375, "code": "(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: ", "label": 0}, {"snippet_id": 55765, "code": " RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo", "label": 0}, {"snippet_id": 84595, "code": " register): super(CountLinesOfCode, cls).register_options(register) register('--transitive', type=bool, fingerprint=True, default=True, help='Operate on the transitive dependencies of the specified targets. ' ", "label": 0}, {"snippet_id": 42100, "code": "} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 69965, "code": " \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall", "label": 0}, {"snippet_id": 9786, "code": "=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output ", "label": 0}, {"snippet_id": 85385, "code": " Subsystem from pants.util.dirutil import fast_relpath from pants.util.memo import memoized_method, memoized_property class Zinc(object): \"\"\"Configuration for Pants' zinc wrapper tool.\"\"\" ZINC_COMPILE_MAIN", "label": 1}, {"snippet_id": 54022, "code": ".append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete", "label": 0}, {"snippet_id": 82881, "code": " nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[\"templateName\"]]=templatefd.read() \ttemplatefd", "label": 0}, {"snippet_id": 51479, "code": " shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else", "label": 1}, {"snippet_id": 46085, "code": " annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\"", "label": 0}, {"snippet_id": 69271, "code": " except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException", "label": 1}, {"snippet_id": 90106, "code": " exe raise self.Error('Failed to locate the{} executable,{} does not appear to be a' ' valid{} distribution'.format(name, self, 'JDK' if self._jdk else 'JRE')) def _validated_executable(self, name): exe", "label": 0}, {"snippet_id": 81662, "code": " \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes", "label": 0}, {"snippet_id": 78961, "code": "\t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms", "label": 0}, {"snippet_id": 51460, "code": "(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity", "label": 0}, {"snippet_id": 1850, "code": " elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io", "label": 0}, {"snippet_id": 42500, "code": " self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output", "label": 0}, {"snippet_id": 49779, "code": ": missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input", "label": 0}, {"snippet_id": 43399, "code": ") except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching", "label": 0}, {"snippet_id": 14447, "code": "._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self", "label": 0}, {"snippet_id": 64813, "code": "(None, GlobalMountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf", "label": 0}, {"snippet_id": 79711, "code": "\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials", "label": 0}, {"snippet_id": 1672, "code": " expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\"", "label": 0}, {"snippet_id": 33441, "code": "\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the", "label": 0}, {"snippet_id": 64555, "code": "(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print", "label": 1}, {"snippet_id": 36292, "code": ".expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self):", "label": 1}, {"snippet_id": 43577, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib", "label": 0}, {"snippet_id": 45251, "code": ": return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path", "label": 0}, {"snippet_id": 77558, "code": " self.userqueues[domain]=uq except Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users(self): users={} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds=[]", "label": 0}, {"snippet_id": 86761, "code": "[settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform", "label": 0}, {"snippet_id": 28331, "code": ".netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items", "label": 1}, {"snippet_id": 27584, "code": " self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id==", "label": 0}, {"snippet_id": 88071, "code": "!=rel_classpath_elements: raise TaskError('Plugin{} defined in{} and in{}'.format(name, active_plugins[name], classpath_element)) active_plugins[name]=rel_classpath_elements if len(active_plugins)==len", "label": 0}, {"snippet_id": 56301, "code": ".split('.')) if request.user.has_perm(perm): return True return False def strip_parameters(request_dict, skip_parameters): parameters={} for key, value in request_dict.items(): if key not in skip_parameters", "label": 0}, {"snippet_id": 9335, "code": " of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to", "label": 0}, {"snippet_id": 68155, "code": "\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print", "label": 0}, {"snippet_id": 55242, "code": " dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag", "label": 0}, {"snippet_id": 3772, "code": ".kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name): window=session.find_where({ ", "label": 0}, {"snippet_id": 4098, "code": " MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used.", "label": 0}, {"snippet_id": 89306, "code": " unicode_literals import itertools import logging import os import pkgutil import plistlib from abc import abstractproperty from builtins import object, open, str from collections import namedtuple from", "label": 0}, {"snippet_id": 68095, "code": "(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname", "label": 1}, {"snippet_id": 55393, "code": " will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names(", "label": 0}, {"snippet_id": 10872, "code": " executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory, executable)): return True return", "label": 1}, {"snippet_id": 19945, "code": " not None: raise RuntimeError('already using managed adapter') if adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') if addr", "label": 0}, {"snippet_id": 80849, "code": "(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s'", "label": 0}, {"snippet_id": 16784, "code": "._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(", "label": 0}, {"snippet_id": 89574, "code": " not bool(home_path) ^ bool(bin_path): raise ValueError('Exactly one of home path or bin path should be supplied, given: ' 'home_path={} bin_path={}'.format(home_path, bin_path)) self._home=home_path self", "label": 0}, {"snippet_id": 63656, "code": " job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"", "label": 0}, {"snippet_id": 69781, "code": "%(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s:", "label": 1}, {"snippet_id": 62203, "code": "=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend:", "label": 0}, {"snippet_id": 17975, "code": ", handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS)", "label": 0}, {"snippet_id": 93008, "code": " self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self): with self._stdio_as_tempfiles(): with stdio_as", "label": 0}, {"snippet_id": 49478, "code": " filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not", "label": 0}, {"snippet_id": 32337, "code": " e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return", "label": 0}, {"snippet_id": 8955, "code": " output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of", "label": 0}, {"snippet_id": 60479, "code": ", CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__", "label": 0}, {"snippet_id": 89687, "code": " names :return: list of paths to requested libraries :raises: `Distribution.Error` if any of the jars could not be found. \"\"\" def collect_existing_libs(): def lib_paths(): yield os.path.join(self.home,", "label": 0}, {"snippet_id": 82508, "code": ".manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |.", "label": 0}, {"snippet_id": 58089, "code": "=bz_external_track) else: bugs=Bug.objects.filter(bug_id__in=bug_ids) for run in runs: for bug in bugs: if bug.case_run_id==run.pk: run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)", "label": 0}, {"snippet_id": 85476, "code": ".0.7'), ], main=Zinc.ZINC_COMPILE_MAIN, custom_rules=shader_rules) cls.register_jvm_tool(register, 'compiler-bridge', classpath=[ ScalaJarDependency(org='org.scala-sbt', name='compiler-bridge', rev=zinc_rev", "label": 1}, {"snippet_id": 67646, "code": ".type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose", "label": 0}, {"snippet_id": 48849, "code": " requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen ", "label": 0}, {"snippet_id": 40027, "code": "\"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self):", "label": 1}, {"snippet_id": 51178, "code": " seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path", "label": 0}, {"snippet_id": 1827, "code": "': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=", "label": 0}, {"snippet_id": 54310, "code": ") def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return", "label": 0}, {"snippet_id": 57937, "code": " clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data={} try: data['bugs']=request.GET.get('bug_id', '').split(", "label": 0}, {"snippet_id": 87720, "code": "(get_buildroot(), res.output_directory_digest), )) return res.output_directory_digest else: if self.runjava(classpath=[self._zinc.zinc], main=Zinc.ZINC_COMPILE_MAIN, jvm_options=jvm_options, args=zinc_args,", "label": 0}, {"snippet_id": 17686, "code": "._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format", "label": 0}, {"snippet_id": 76384, "code": ".poll(timeout * 1000) except Resume as e: return def poll(self, timeout=None): try: socks=dict(self.poller.poll(timeout if timeout !=None else self.poll_timeout)) except zmq.ZMQError as e: self.log.error", "label": 1}, {"snippet_id": 43227, "code": " name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( ", "label": 0}, {"snippet_id": 93250, "code": "[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session", "label": 0}, {"snippet_id": 24056, "code": ".*//'\".format(output) err, output=shellutil.run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible cmd_search_storvsc=", "label": 0}, {"snippet_id": 40729, "code": " arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def", "label": 0}, {"snippet_id": 34232, "code": " return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 5656, "code": " return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return", "label": 0}, {"snippet_id": 36673, "code": ", res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self", "label": 0}, {"snippet_id": 34466, "code": ", paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class", "label": 0}, {"snippet_id": 56437, "code": " Category.objects.filter(product__id=self.product_id) def components(self): return Component.objects.filter(product__id=self.product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties", "label": 0}, {"snippet_id": 47835, "code": ".workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict", "label": 0}, {"snippet_id": 88032, "code": " active_plugins={} buildroot=get_buildroot() cp_product=self.context.products.get_data('runtime_classpath') for classpath_element in classpath: name=self._maybe_get_plugin_name(classpath_element) if name", "label": 0}, {"snippet_id": 93458, "code": " node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error", "label": 0}, {"snippet_id": 9453, "code": " single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords ", "label": 0}, {"snippet_id": 47645, "code": " self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output", "label": 0}, {"snippet_id": 73732, "code": " parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section=", "label": 0}, {"snippet_id": 57567, "code": ".request, pk_enough) except Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms", "label": 0}, {"snippet_id": 60001, "code": "'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is", "label": 0}, {"snippet_id": 69166, "code": " s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry(", "label": 0}, {"snippet_id": 29901, "code": " keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns", "label": 0}, {"snippet_id": 20204, "code": "*kwargs) except Exception as ex: self._run_server_ex=traceback.format_exc() t=new_hidden_thread( target=run, name='test.client', ) t.start() def wait(): t.join(timeout=self._connecttimeout) if t.is_alive", "label": 0}, {"snippet_id": 38942, "code": " main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path", "label": 0}, {"snippet_id": 83022, "code": "\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown", "label": 0}, {"snippet_id": 25753, "code": " self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle':", "label": 0}, {"snippet_id": 59204, "code": " import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT", "label": 0}, {"snippet_id": 78910, "code": ",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) ", "label": 0}, {"snippet_id": 3528, "code": "\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self", "label": 0}, {"snippet_id": 93758, "code": " CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp)", "label": 0}, {"snippet_id": 86985, "code": " to cache ' 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies() +(Zinc.Factory, JvmPlatform,) @classmethod def prepare(cls", "label": 0}, {"snippet_id": 66612, "code": " from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(", "label": 1}, {"snippet_id": 83907, "code": "): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid", "label": 0}, {"snippet_id": 72751, "code": ", runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files", "label": 1}, {"snippet_id": 31439, "code": ".updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self", "label": 0}, {"snippet_id": 39928, "code": "\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError", "label": 1}, {"snippet_id": 35555, "code": " names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict", "label": 0}, {"snippet_id": 12323, "code": ".remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request.json[\"action", "label": 0}, {"snippet_id": 33117, "code": "\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1,", "label": 0}, {"snippet_id": 62493, "code": "(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed'] def __init__(self,", "label": 0}, {"snippet_id": 14288, "code": "() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file", "label": 1}, {"snippet_id": 12594, "code": "{}/issues/{}/comments\" url=url.format(repository, str(data[\"pr_number\"])) comments=requests.get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments): if old_comment", "label": 0}, {"snippet_id": 77507, "code": " from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount, (ev_init,)) def load_users(self): if not os.path.isfile(self.usersfile", "label": 0}, {"snippet_id": 31532, "code": ".workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set", "label": 0}, {"snippet_id": 29537, "code": " get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os", "label": 0}, {"snippet_id": 72638, "code": ".generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\": print(\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree(vcf_directory", "label": 1}, {"snippet_id": 8757, "code": "=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms", "label": 0}, {"snippet_id": 26229, "code": " TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None]", "label": 0}, {"snippet_id": 18023, "code": "=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line,", "label": 0}, {"snippet_id": 77438, "code": ".router_addr, fun, args, kvargs, name='.'.join((wname, 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args,", "label": 0}, {"snippet_id": 3866, "code": " parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers", "label": 0}, {"snippet_id": 69118, "code": "\n from Configuration.Globals import Globals from Commands.CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError", "label": 0}, {"snippet_id": 70319, "code": ": RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 70688, "code": "\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets", "label": 0}, {"snippet_id": 15348, "code": "._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)", "label": 0}, {"snippet_id": 50511, "code": " decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 54146, "code": " self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio,", "label": 0}, {"snippet_id": 47458, "code": "=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule", "label": 0}, {"snippet_id": 52116, "code": ".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise", "label": 0}, {"snippet_id": 8877, "code": " as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines", "label": 1}, {"snippet_id": 56539, "code": " app_form') q_app, q_form=q_app_form.split('.')[0], q_app_form.split('.')[1] exec('from tcms.%s.forms import %s as form' %(q_app, q_form)) __import__('tcms.%s.forms' % q_app) q_app_module=sys.modules['tcms.", "label": 1}, {"snippet_id": 7678, "code": " a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym", "label": 0}, {"snippet_id": 81214, "code": " or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern", "label": 0}, {"snippet_id": 34194, "code": ", **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return", "label": 0}, {"snippet_id": 45710, "code": " return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to", "label": 0}, {"snippet_id": 23467, "code": " create user account:{0}, \" \"retcode:{1}, \" \"output:{2}\").format(username, retcode, out)) def del_account(self, username): if self.is_sys_user(username): logger.error(\"{0} is a system user. Will not delete", "label": 0}, {"snippet_id": 85072, "code": " register_style_tool('2.11') register_scala_compiler_tool('2.12') register_scala_repl_tool('2.12') register_style_tool('2.12') def register_custom_tool(key): dummy_jardep=JarDependency('missing spec', ' //", "label": 0}, {"snippet_id": 68092, "code": " RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level()", "label": 1}, {"snippet_id": 19227, "code": " result==source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source(source) assert result==native def test_yaml_string(): native={'foo': 'bar'} source=yaml.dump(native", "label": 1}, {"snippet_id": 34357, "code": " return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads", "label": 0}, {"snippet_id": 44164, "code": " dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity", "label": 0}, {"snippet_id": 64703, "code": " %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print", "label": 1}, {"snippet_id": 53205, "code": "=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self", "label": 0}, {"snippet_id": 49407, "code": " ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False,", "label": 0}, {"snippet_id": 62892, "code": " for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values", "label": 0}, {"snippet_id": 10851, "code": "=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"", "label": 1}, {"snippet_id": 46084, "code": " annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained", "label": 0}, {"snippet_id": 44217, "code": ") if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have", "label": 0}, {"snippet_id": 22115, "code": "(pb_dir, playbook) display.verbosity=self.options.verbosity self.pbex=playbook_executor.PlaybookExecutor( playbooks=[playbook], inventory=self.inventory, variable_manager=self.variable_manager, loader=self", "label": 1}, {"snippet_id": 69927, "code": ") status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for", "label": 1}, {"snippet_id": 22859, "code": ") ) userentry=self.get_userentry('admin') if userentry is None: raise OSUtilError(\"The 'admin' user account was not found!\") cmd=\"/usr/bin/tmsh modify auth user 'admin' password '{0}'\".format(password)", "label": 0}, {"snippet_id": 20475, "code": "(sock, ownsock=True) self._addr=addr return self def __init__(self, sock, ownsock=False): super(DebugSessionConnection, self).__init__() self._sock=sock self._ownsock=ownsock @property def is_client(self):", "label": 0}, {"snippet_id": 13007, "code": " data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"", "label": 0}, {"snippet_id": 20278, "code": " if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ filename, ] +list(argv) if kwargs", "label": 0}, {"snippet_id": 73419, "code": " output_zarr_dir=str(output_zarr_dir) create_directory_tree(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(\"**/*.vcf\") for path in pathlist_vcf: path_str", "label": 0}, {"snippet_id": 92520, "code": "(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_temporary_file_no_args(self): with temporary_file() as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within", "label": 0}, {"snippet_id": 83780, "code": ".\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing job %d\" % job_wrapper.job_id) return", "label": 0}, {"snippet_id": 84775, "code": " ZincLanguageMixin from pants.backend.jvm.targets.jar_library import JarLibrary from pants.build_graph.address import Address from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java", "label": 0}, {"snippet_id": 6793, "code": "=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords)", "label": 0}, {"snippet_id": 43303, "code": ".apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 81512, "code": "\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t\t\t\tself.logger", "label": 0}, {"snippet_id": 55091, "code": " the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can", "label": 0}, {"snippet_id": 71758, "code": "%s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" ", "label": 0}, {"snippet_id": 86187, "code": "(distribution.real_home)] javac_cmd.extend([ '-classpath', ':'.join(classpath), ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting ", "label": 0}, {"snippet_id": 72433, "code": " runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments()", "label": 1}, {"snippet_id": 55133, "code": ": subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 64891, "code": " preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file", "label": 0}, {"snippet_id": 65737, "code": " ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]]))", "label": 0}, {"snippet_id": 91880, "code": " IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import memoized_property from pants.util", "label": 1}, {"snippet_id": 89476, "code": "(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping", "label": 0}, {"snippet_id": 34919, "code": " missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError", "label": 0}, {"snippet_id": 94212, "code": "/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config", "label": 0}, {"snippet_id": 46591, "code": ".__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__", "label": 0}, {"snippet_id": 67239, "code": "%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info", "label": 1}, {"snippet_id": 94503, "code": ": returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component", "label": 0}, {"snippet_id": 39493, "code": " not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance", "label": 0}, {"snippet_id": 70644, "code": "=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf", "label": 0}, {"snippet_id": 34411, "code": " is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self", "label": 0}, {"snippet_id": 55149, "code": " subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else", "label": 0}, {"snippet_id": 28537, "code": "='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state", "label": 0}, {"snippet_id": 87612, "code": "=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry.directory_digest", "label": 1}, {"snippet_id": 62915, "code": " galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch", "label": 0}, {"snippet_id": 71867, "code": " class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes", "label": 0}, {"snippet_id": 12271, "code": ".py:\\d+:\\d+:\\s[WE]\\d+\\s.*\", error): data[\"results\"][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error in list(data[\"results\"][filename]", "label": 0}, {"snippet_id": 23422, "code": " \"\"\" Create user account with 'username' \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None", "label": 0}, {"snippet_id": 79490, "code": " %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"", "label": 1}, {"snippet_id": 36666, "code": "=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\":", "label": 0}, {"snippet_id": 53140, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError", "label": 0}, {"snippet_id": 60812, "code": "} _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots self._out=None self._queue=[] self._observe=None def __repr__(self): \"\"\"String representation.\"\"\" return self.__module__ ", "label": 0}, {"snippet_id": 56368, "code": "'<li>' +obj_value.get(field, None) +'</li>' response_str +='</ul>' return HttpResponse(response_str) return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value'))) class _InfoObjects", "label": 0}, {"snippet_id": 8352, "code": " remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not", "label": 0}, {"snippet_id": 44932, "code": ") and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version", "label": 0}, {"snippet_id": 62161, "code": "'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval", "label": 0}, {"snippet_id": 55859, "code": "(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params,", "label": 0}, {"snippet_id": 8048, "code": "\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords", "label": 0}, {"snippet_id": 66600, "code": " ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import", "label": 0}, {"snippet_id": 71181, "code": "==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE", "label": 0}, {"snippet_id": 18982, "code": "-8') else: raw_source=response.content else: raw_source=source try: try: return json.loads(raw_source) except ValueError: pass try: return yaml.load(raw_source) except(yaml.scanner.ScannerError, yaml.parser", "label": 1}, {"snippet_id": 13475, "code": " accessTokenKey='INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR ACCESS TOKEN SECRET HERE FROM TWITTER'\r \r import sys\r import time\r import subprocess\r import os\r from random import", "label": 0}, {"snippet_id": 36950, "code": ".message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output", "label": 0}, {"snippet_id": 81043, "code": "\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as", "label": 0}, {"snippet_id": 64456, "code": " has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute", "label": 0}, {"snippet_id": 91734, "code": "(tgt_snapshot, tgt_source_root)) all_sources_digests=yield[ Get( Digest, DirectoryWithPrefixToStrip( directory_digest=snapshot.directory_digest, prefix=source_root.path ) ) for snapshot, source_root in", "label": 0}, {"snippet_id": 62971, "code": " NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is", "label": 0}, {"snippet_id": 1982, "code": " action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={", "label": 0}, {"snippet_id": 67605, "code": "(node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def", "label": 0}, {"snippet_id": 977, "code": " elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc", "label": 0}, {"snippet_id": 89614, "code": " self._system_properties=None self._validated_binaries={} @property def jdk(self): self.validate() return self._is_jdk @property def system_properties(self): \"\"\"Returns a dict containing the system properties", "label": 0}, {"snippet_id": 56588, "code": " tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions", "label": 0}, {"snippet_id": 13944, "code": ", handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers", "label": 1}, {"snippet_id": 66764, "code": "\n from Shine.Configuration.Globals import Globals from Shine.Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction", "label": 0}, {"snippet_id": 38798, "code": ") return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory", "label": 0}, {"snippet_id": 30175, "code": " def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments", "label": 0}, {"snippet_id": 10677, "code": " 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file", "label": 1}, {"snippet_id": 65316, "code": "(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune", "label": 0}, {"snippet_id": 80675, "code": "\tn=up.detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit()", "label": 0}, {"snippet_id": 42213, "code": "() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell", "label": 0}, {"snippet_id": 2624, "code": ".error(\"Unmet dependency: '%s' for component '%s'!\" %(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve", "label": 0}, {"snippet_id": 9038, "code": "=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords", "label": 0}, {"snippet_id": 61633, "code": " A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation value.'.format(expectation", "label": 0}, {"snippet_id": 10694, "code": " and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line", "label": 1}, {"snippet_id": 7705, "code": " output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str", "label": 0}, {"snippet_id": 36443, "code": ".rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\"", "label": 0}, {"snippet_id": 13591, "code": "( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 0)\r time.sleep( randint( 0,7))\r \r def talk(myText):\r if( myText", "label": 0}, {"snippet_id": 36101, "code": ".dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f", "label": 0}, {"snippet_id": 85224, "code": "}\" should not be suffixed with the scala platform version ' '({1}): it will be added automatically.'.format(name, self.version)) return '{0}_{1}'.format(name, self.version) @property def repl(self): \"\"", "label": 0}, {"snippet_id": 72894, "code": " create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config", "label": 0}, {"snippet_id": 5301, "code": " boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} <", "label": 0}, {"snippet_id": 86145, "code": " dependency_classpath, upstream_analysis, settings, fatal_warnings, zinc_file_manager, javac_plugin_map, scalac_plugin_map): classpath=(ctx.classes_dir,) +tuple(ce.path for ce in dependency_classpath) if", "label": 0}, {"snippet_id": 54641, "code": ".is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str", "label": 0}, {"snippet_id": 49428, "code": ", summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake", "label": 0}, {"snippet_id": 75870, "code": ") if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self", "label": 0}, {"snippet_id": 67850, "code": " 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.", "label": 0}, {"snippet_id": 7399, "code": " encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags", "label": 0}, {"snippet_id": 92479, "code": " pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2", "label": 0}, {"snippet_id": 60578, "code": "'Homodyne', 'Heterodyne'} _circuits={} def __init__(self, wires, *, shots=0, hbar=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self):", "label": 1}, {"snippet_id": 61792, "code": "(U, np.eye(between)) if wires[0] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp", "label": 0}, {"snippet_id": 11546, "code": " section_data): self.write_line(\"\") self.write_line(\"define %s{\" % section_name) sorted_keys=section_data.keys() sorted_keys.sort() for key in sorted_keys: value=section_data[key] self.icinga_lines.append", "label": 1}, {"snippet_id": 34947, "code": "))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove", "label": 0}, {"snippet_id": 40568, "code": " return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag", "label": 1}, {"snippet_id": 46413, "code": "(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments", "label": 0}, {"snippet_id": 59366, "code": " name='ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend", "label": 0}, {"snippet_id": 66397, "code": ".EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node", "label": 0}, {"snippet_id": 67457, "code": " command classes. The start command aims to start Lustre filesystem servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and", "label": 0}, {"snippet_id": 13916, "code": " handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 13046, "code": "\"description\"]: if data[\"target_repo_fullname\"] in repo[\"description\"]: FORKED=True r=requests.delete(\"https://api.github.com/repos/\" \"{}\".format(repo[\"full_name\"]), headers=headers, auth=auth) return FORKED def", "label": 0}, {"snippet_id": 17011, "code": " handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column", "label": 0}, {"snippet_id": 2354, "code": " subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message", "label": 0}, {"snippet_id": 50817, "code": " a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return", "label": 0}, {"snippet_id": 18216, "code": " with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check", "label": 0}, {"snippet_id": 94573, "code": " window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window", "label": 0}, {"snippet_id": 7824, "code": "(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches,", "label": 0}, {"snippet_id": 68176, "code": " 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets", "label": 1}, {"snippet_id": 34305, "code": " decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs)", "label": 0}, {"snippet_id": 92415, "code": " expected_output=UNICODE_CHAR if PY3 else ENCODED_CHAR with environment_as(**dict(XXX=UNICODE_CHAR)): self.assertEqual(os.environ['XXX'], expected_output) with hermetic_environment_as(**dict(AAA=UNICODE_CHAR", "label": 1}, {"snippet_id": 39116, "code": "=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag", "label": 0}, {"snippet_id": 2755, "code": " not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window", "label": 0}, {"snippet_id": 58686, "code": "( username=self.tester.username, password='password') post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False', 'value_type': 'bool' } response", "label": 0}, {"snippet_id": 60796, "code": "\"Abstract base class for devices.\"\"\" _current_context=None name='' short_name='' api_version='' version='' author='' _capabilities={} _gates={} _observables={} _circuits={} def __init__(self, name, shots", "label": 0}, {"snippet_id": 89914, "code": ") if self._maximum_version: version=self._get_version(java) if version > self._maximum_version: raise self.Error('The java distribution at{} is too new; expecting no older than' '{} and got{}'.format(java", "label": 0}, {"snippet_id": 70195, "code": " self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1:", "label": 0}, {"snippet_id": 74498, "code": " ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"ftp\"): if \"enabled\" in runtime_config.ftp: self.enabled=config_str_to_bool(runtime_config.ftp[\"enabled\"]) if ", "label": 0}, {"snippet_id": 47545, "code": " return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other", "label": 0}, {"snippet_id": 95302, "code": " Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors", "label": 0}, {"snippet_id": 89434, "code": " compile source code or run bytecode that exercise features only available in that version forward. :API: public TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods", "label": 0}, {"snippet_id": 37333, "code": " output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError", "label": 0}, {"snippet_id": 21569, "code": " exiting.\") with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove(link) with", "label": 0}, {"snippet_id": 61206, "code": "\"\" state=np.asarray(args) return state/np.linalg.norm(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square", "label": 0}, {"snippet_id": 9720, "code": ": results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw", "label": 0}, {"snippet_id": 87325, "code": " be great to just fetch this rather than compiling it. \"\"\" hasher=sha1() for cp_entry in[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry", "label": 1}, {"snippet_id": 70162, "code": ".get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(", "label": 0}, {"snippet_id": 16184, "code": " OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager", "label": 0}, {"snippet_id": 2154, "code": "\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi", "label": 0}, {"snippet_id": 41739, "code": " in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination", "label": 0}, {"snippet_id": 17912, "code": ", timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync", "label": 0}, {"snippet_id": 37477, "code": ", \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow", "label": 0}, {"snippet_id": 20301, "code": " False): argv.insert(0, '--nodebug') self._launch(argv, **kwargs) return self._adapter, self._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed", "label": 0}, {"snippet_id": 55827, "code": " return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 81577, "code": "\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text)", "label": 1}, {"snippet_id": 89717, "code": " in lib_paths(): lib_path=os.path.join(path, name) if os.path.exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate{} library'.format(name)) return list(collect_existing_libs", "label": 0}, {"snippet_id": 42285, "code": " K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import", "label": 0}, {"snippet_id": 28785, "code": "\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 231, "code": "'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps)", "label": 0}, {"snippet_id": 71578, "code": "{ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return", "label": 0}, {"snippet_id": 59856, "code": " ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val", "label": 0}, {"snippet_id": 52102, "code": " raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON", "label": 0}, {"snippet_id": 18715, "code": "{0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options", "label": 0}, {"snippet_id": 65863, "code": " target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[", "label": 0}, {"snippet_id": 32344, "code": "(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards", "label": 0}, {"snippet_id": 32267, "code": ", start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested", "label": 0}, {"snippet_id": 69196, "code": " print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden", "label": 0}, {"snippet_id": 43450, "code": ".groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values", "label": 0}, {"snippet_id": 17997, "code": " _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http:/", "label": 0}, {"snippet_id": 58404, "code": " TestCommentCaseRuns(BaseCaseRun): \"\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls).setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs", "label": 0}, {"snippet_id": 52603, "code": "\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output", "label": 0}, {"snippet_id": 90392, "code": "(java_dist_dir, path) if os.path.isdir(home): yield self.Location.from_home(home) class _ExplicitEnvironment(_DistributionEnvironment): def __init__(self, *homes): self._homes=homes @property def jvm_locations", "label": 0}, {"snippet_id": 19579, "code": " not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in('--host', '--server-host', '--port', '-m'): if arg=='-m':", "label": 0}, {"snippet_id": 74296, "code": "=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could", "label": 0}, {"snippet_id": 78034, "code": " id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not in forums: forums[domain]=set() if len(forum) > 0: get_forum_id(forum) logger.info(", "label": 0}, {"snippet_id": 84155, "code": " dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False", "label": 0}, {"snippet_id": 87839, "code": ".log.debug('Calling zinc on:{}({})' .format(analysis_file, hash_file(analysis_file).upper() if os.path.exists(analysis_file) else 'nonexistent')) @classmethod def _javac_plugin_args(cls, javac_plugin_map", "label": 0}, {"snippet_id": 44110, "code": " forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets)", "label": 0}, {"snippet_id": 53655, "code": " self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 10968, "code": " except socket.error as e: msg=\"Could not open socket for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error", "label": 0}, {"snippet_id": 86380, "code": ".sources_snapshot(scheduler=self.context._scheduler) output_files=tuple( os.path.relpath(f.path.replace('.java', '.class'), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java')", "label": 0}, {"snippet_id": 38161, "code": "-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order", "label": 0}, {"snippet_id": 91580, "code": "--interpreter-constraint\", text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor, PyTest, PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest, python_setup", "label": 1}, {"snippet_id": 30123, "code": " toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"", "label": 0}, {"snippet_id": 46106, "code": " annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern", "label": 0}, {"snippet_id": 14989, "code": " _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit", "label": 0}, {"snippet_id": 14599, "code": " OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup()", "label": 0}, {"snippet_id": 86080, "code": " write_extra_resources to produce plugin and annotation processor files.\"\"\" target=compile_context.target if isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target", "label": 0}, {"snippet_id": 46623, "code": "(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath", "label": 0}, {"snippet_id": 87794, "code": " self.get_options().pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath entries provided to zinc should be in working directory or ' 'part of the JDK.{} is not.'", "label": 0}, {"snippet_id": 34356, "code": "): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads", "label": 0}, {"snippet_id": 66841, "code": " command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self", "label": 0}, {"snippet_id": 82725, "code": "+=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={", "label": 0}, {"snippet_id": 5047, "code": "\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output", "label": 0}, {"snippet_id": 56829, "code": " self.obj=obj self.tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag", "label": 0}, {"snippet_id": 32401, "code": " name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( ", "label": 0}, {"snippet_id": 77855, "code": ": while self.running.is_set(): if self.c.tcount==0: self.inter_sleep(5) continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except WorkerInterrupt", "label": 0}, {"snippet_id": 73079, "code": "(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP", "label": 0}, {"snippet_id": 55978, "code": " return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return", "label": 0}, {"snippet_id": 61062, "code": "[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0]]) SWAP=np.array([[1, 0, 0, 0],[0, 0, 1, 0],[0, 1, 0, 0],[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the", "label": 0}, {"snippet_id": 18676, "code": " vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info", "label": 0}, {"snippet_id": 41175, "code": "(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self):", "label": 0}, {"snippet_id": 8817, "code": "=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os", "label": 0}, {"snippet_id": 75407, "code": " method, args, fun, reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer): iden=self.iden_reqid_map.get_key(reqid) if seqnum==0: self.iden_reqid_map.del_value(iden, reqid) msg", "label": 0}, {"snippet_id": 10300, "code": "[1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn", "label": 0}, {"snippet_id": 65425, "code": ".Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler", "label": 0}, {"snippet_id": 87886, "code": "(args))) return ret def _scalac_plugin_args(self, scalac_plugin_map, classpath): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret", "label": 0}, {"snippet_id": 22504, "code": " ret[1] if ret[0]==0 else None def set_hostname(self, hostname): \"\"\"Set the static hostname of the device Normally, tmsh is used to set the hostname for the system. For our purposes at this time though", "label": 0}, {"snippet_id": 7651, "code": ": bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details", "label": 0}, {"snippet_id": 34376, "code": " self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name,", "label": 0}, {"snippet_id": 14357, "code": "._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[", "label": 0}, {"snippet_id": 87905, "code": " name, cp_entries in plugin_jar_map.items(): ret.append('-S-Xplugin:{}'.format(':'.join(cp_entries))) for arg in scalac_plugin_map[name]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret def _find_scalac_plugins", "label": 0}, {"snippet_id": 75934, "code": " msgdict[rs] continue s.send_multipart(msgdict[rs]) rs.finished=False rs.retry=False flag=1 if not flag: return t.tick() p(timeout*1000) if t.elapsed(False) >=timeout: for rs in rslist: if not rs.finished", "label": 0}, {"snippet_id": 11085, "code": " def __init__(self, etag=None, mtime=0): self.etag=etag self.mtime=int(mtime) def __nonzero__(self): return self.etag is None and self.mtime is 0 def __eq__(self, other): return self.etag==other.etag and", "label": 0}, {"snippet_id": 16335, "code": " utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr'", "label": 0}, {"snippet_id": 80759, "code": ",nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt", "label": 1}, {"snippet_id": 16262, "code": ") self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename", "label": 1}, {"snippet_id": 71753, "code": ".is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg", "label": 0}, {"snippet_id": 15226, "code": "). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs", "label": 0}, {"snippet_id": 78248, "code": " self.schedule(self.scan_targets_loop) else: self.schedule(self.comment_loop) def add_comment(self, t, msg): if True: try: self.postmsg(t[1], msg, t[0]) except exc.Success as e: self.counters['comments", "label": 0}, {"snippet_id": 76392, "code": "=None): try: socks=dict(self.poller.poll(timeout if timeout !=None else self.poll_timeout)) except zmq.ZMQError as e: self.log.error(e) return if socks.get(self.sig_sock)==zmq.POLLIN: frames=self.sig_sock", "label": 1}, {"snippet_id": 65544, "code": ": RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return", "label": 0}, {"snippet_id": 13937, "code": "( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return", "label": 1}, {"snippet_id": 67107, "code": " execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf", "label": 1}, {"snippet_id": 69340, "code": ": ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self", "label": 0}, {"snippet_id": 35150, "code": " value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value", "label": 1}, {"snippet_id": 17282, "code": ".Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict", "label": 1}, {"snippet_id": 26134, "code": " STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES", "label": 1}, {"snippet_id": 81395, "code": ".isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself", "label": 0}, {"snippet_id": 71072, "code": " if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout", "label": 0}, {"snippet_id": 9541, "code": " author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for", "label": 0}, {"snippet_id": 34353, "code": ") @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message", "label": 0}, {"snippet_id": 40112, "code": " OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk", "label": 0}, {"snippet_id": 47692, "code": "}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or", "label": 0}, {"snippet_id": 63807, "code": " log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid))", "label": 0}, {"snippet_id": 25027, "code": " data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class", "label": 0}, {"snippet_id": 89643, "code": "(self): \"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" return self._get_version(self.java) def find_libs(self,", "label": 0}, {"snippet_id": 75286, "code": ")] except KeyError: raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value(tuple(iden), reqid) handler(reqid, interface, method, msg[1", "label": 0}, {"snippet_id": 43689, "code": " Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder(", "label": 0}, {"snippet_id": 56611, "code": "() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_plans=Count('tag')).order_by('tag') test_case_tags=TestCaseTag.objects.filter", "label": 0}, {"snippet_id": 92552, "code": " exist outside of the context.') def test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist within the", "label": 0}, {"snippet_id": 45503, "code": " def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError", "label": 0}, {"snippet_id": 72486, "code": " benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default", "label": 0}, {"snippet_id": 32810, "code": " shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic", "label": 1}, {"snippet_id": 78746, "code": ":]) log.logger.debug('Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json", "label": 0}, {"snippet_id": 68631, "code": " fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status", "label": 0}, {"snippet_id": 1593, "code": "(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS", "label": 0}, {"snippet_id": 33029, "code": " lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the", "label": 0}, {"snippet_id": 67824, "code": " target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support", "label": 0}, {"snippet_id": 95802, "code": ".path.basename(head) def read_file_contents(local_filepath): if os.path.isfile(local_filepath): with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir", "label": 0}, {"snippet_id": 61352, "code": "(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name=", "label": 0}, {"snippet_id": 90073, "code": ".partition('=') props[key]=val self._system_properties=props return self._system_properties def _validate_executable(self, name): def bin_paths(): yield self._bin_path if self._is_jdk: yield os.path.join(self", "label": 0}, {"snippet_id": 93786, "code": " self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\"", "label": 0}, {"snippet_id": 15325, "code": "), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log'", "label": 0}, {"snippet_id": 31324, "code": ".wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod", "label": 0}, {"snippet_id": 54743, "code": "=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource", "label": 0}, {"snippet_id": 61225, "code": " unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape[0] !=U.shape[1]: raise ValueError(\"Operator must be a square matrix.\")", "label": 0}, {"snippet_id": 7305, "code": ":keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield", "label": 0}, {"snippet_id": 51302, "code": "(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value", "label": 0}, {"snippet_id": 6436, "code": "\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False,", "label": 0}, {"snippet_id": 78596, "code": ".scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError as e: self.log.error(e) except", "label": 0}, {"snippet_id": 89006, "code": " in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of", "label": 0}, {"snippet_id": 17595, "code": " return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not", "label": 0}, {"snippet_id": 80242, "code": "): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if", "label": 0}, {"snippet_id": 61036, "code": " that:math:`A=\\sum_k a_k P_k`. \"\"\" d, v=eigh(A) P=[] for k in range(2): temp=v[:, k] P.append(np.outer(temp.conj(), temp)) return d, P I=np.eye(2) X=np.array([[0, 1],[1, 0]]) Y=np.array([[0, -1j],[1j, 0]])", "label": 0}, {"snippet_id": 95398, "code": "\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print", "label": 0}, {"snippet_id": 60705, "code": ".params) elif self._observe.name=='Displacement': ex=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device", "label": 0}, {"snippet_id": 13535, "code": " lastMouthEventTime=0\r \r while( audio==None):\r time.sleep( 0.1)\r \r while isRunning:\r if( audio.mouthValue !=lastMouthEvent):\r lastMouthEvent=audio.mouthValue\r lastMouthEventTime=time.time()\r \r if( audio", "label": 0}, {"snippet_id": 83895, "code": " job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid)", "label": 0}, {"snippet_id": 15661, "code": "()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport", "label": 0}, {"snippet_id": 74325, "code": "(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been generated successfully.\") else: print(\"[Config", "label": 0}, {"snippet_id": 42582, "code": " branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old)", "label": 0}, {"snippet_id": 13968, "code": " timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method", "label": 1}, {"snippet_id": 36052, "code": ": min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict", "label": 0}, {"snippet_id": 5605, "code": " _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info", "label": 0}, {"snippet_id": 82443, "code": ": \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point", "label": 0}, {"snippet_id": 76510, "code": "() self.unbind_methods() self.running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx, sig_addr", "label": 0}, {"snippet_id": 80410, "code": " to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds", "label": 0}, {"snippet_id": 83641, "code": " job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params job_id=job_state", "label": 0}, {"snippet_id": 16251, "code": "=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request", "label": 0}, {"snippet_id": 59350, "code": " use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" name='ProjectQ OpenQML plugin' short_name", "label": 0}, {"snippet_id": 87231, "code": ".products) def write_extra_resources(self, compile_context): \"\"\"Override write_extra_resources to produce plugin and annotation processor files.\"\"\" target=compile_context.target if isinstance(target, ScalacPlugin", "label": 0}, {"snippet_id": 81333, "code": ".search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self", "label": 0}, {"snippet_id": 41302, "code": " checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class", "label": 0}, {"snippet_id": 61673, "code": ", wires): \"\"\"Expand a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(2, 2): raise ValueError", "label": 0}, {"snippet_id": 86530, "code": ".engine.fs import DirectoryToMaterialize, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator from", "label": 0}, {"snippet_id": 30700, "code": ".protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_", "label": 0}, {"snippet_id": 32077, "code": "): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif", "label": 0}, {"snippet_id": 41315, "code": " be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic", "label": 0}, {"snippet_id": 79214, "code": "\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads", "label": 0}, {"snippet_id": 41787, "code": "\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing", "label": 0}, {"snippet_id": 36167, "code": "(self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is", "label": 0}, {"snippet_id": 87892, "code": " classpath): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret=[] for name, cp_entries in plugin_jar_map.items(): ret.append('-S", "label": 0}, {"snippet_id": 31246, "code": "+str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value", "label": 0}, {"snippet_id": 6616, "code": " text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode", "label": 0}, {"snippet_id": 4186, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" %", "label": 0}, {"snippet_id": 67860, "code": " result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes", "label": 0}, {"snippet_id": 85064, "code": " with_jline=True) register_style_tool('2.10') register_scala_compiler_tool('2.11') register_scala_repl_tool('2.11') register_style_tool('2.11') register_scala_compiler_tool('2.12') register_scala_repl_tool(", "label": 0}, {"snippet_id": 5773, "code": " into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches", "label": 0}, {"snippet_id": 50078, "code": " Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path", "label": 0}, {"snippet_id": 16056, "code": "=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error", "label": 0}, {"snippet_id": 95846, "code": ":param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config", "label": 0}, {"snippet_id": 22180, "code": ".Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template.render( data) return outputText def run(self, state, data=None, context=None): \"\"\"Run ansible-playbook on", "label": 0}, {"snippet_id": 46398, "code": "(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item.", "label": 0}, {"snippet_id": 30267, "code": " def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end", "label": 0}, {"snippet_id": 73148, "code": " file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file)", "label": 0}, {"snippet_id": 8478, "code": " number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"", "label": 1}, {"snippet_id": 9536, "code": ":var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility,", "label": 0}, {"snippet_id": 55260, "code": "(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed", "label": 0}, {"snippet_id": 82673, "code": "\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser", "label": 0}, {"snippet_id": 34528, "code": " import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os", "label": 1}, {"snippet_id": 63153, "code": "\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched", "label": 1}, {"snippet_id": 43468, "code": " of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp", "label": 0}, {"snippet_id": 12051, "code": "\"pycodestyle\"][\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return a list of file names modified/added in the PR \"\"\" headers={", "label": 0}, {"snippet_id": 48985, "code": " comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self)", "label": 0}, {"snippet_id": 91169, "code": ".targets.python_app import PythonApp from pants.backend.python.targets.python_binary import PythonBinary from pants.backend.python.targets.python_distribution import PythonDistribution from pants.backend", "label": 0}, {"snippet_id": 78898, "code": " initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t", "label": 0}, {"snippet_id": 73548, "code": " print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF", "label": 0}, {"snippet_id": 53718, "code": "\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self", "label": 0}, {"snippet_id": 45913, "code": " str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern", "label": 0}, {"snippet_id": 10830, "code": ".close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in", "label": 1}, {"snippet_id": 73353, "code": " tail or os.path.basename(head) def read_file_contents(local_filepath): if os.path.isfile(local_filepath): with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr", "label": 0}, {"snippet_id": 32264, "code": " if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards", "label": 0}, {"snippet_id": 21418, "code": " os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working directory found, but no subreddit directory.", "label": 0}, {"snippet_id": 71889, "code": " isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self", "label": 0}, {"snippet_id": 71984, "code": " rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt -=1 if self.fs.action_refcnt", "label": 1}, {"snippet_id": 17733, "code": "._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax", "label": 0}, {"snippet_id": 27907, "code": " data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self", "label": 0}, {"snippet_id": 81017, "code": "=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint", "label": 0}, {"snippet_id": 59377, "code": "' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']", "label": 0}, {"snippet_id": 70811, "code": " status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\",", "label": 0}, {"snippet_id": 14897, "code": "): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler", "label": 0}, {"snippet_id": 31059, "code": " filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self", "label": 0}, {"snippet_id": 75151, "code": ".p.log.warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self.p=parent self.p.wz_connect() self.p.wz_auth_requests=[ (b'Router', b'auth-bind-route'), (b'Router'", "label": 0}, {"snippet_id": 64459, "code": "-1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute", "label": 0}, {"snippet_id": 66442, "code": ".status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc", "label": 1}, {"snippet_id": 88963, "code": ": os.makedirs(abs_target_base) if not self.source_roots.find_by_path(rel_target_base): self.source_roots.add_source_root(rel_target_base) if dependencies: dependencies=[dep.address for dep in dependencies", "label": 0}, {"snippet_id": 34605, "code": " self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self):", "label": 1}, {"snippet_id": 4758, "code": " the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords ", "label": 0}, {"snippet_id": 527, "code": " if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print", "label": 0}, {"snippet_id": 52043, "code": " class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then", "label": 0}, {"snippet_id": 66577, "code": " rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes,", "label": 1}, {"snippet_id": 19863, "code": " self._session is None raise NotImplementedError def stop_debugging(self): if self.closed: raise RuntimeError('debug client closed') if self._adapter is None: raise RuntimeError('debugger not running') if", "label": 0}, {"snippet_id": 14172, "code": " ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request", "label": 0}, {"snippet_id": 9938, "code": "[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym,", "label": 0}, {"snippet_id": 9936, "code": " output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms", "label": 0}, {"snippet_id": 44263, "code": " same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power", "label": 0}, {"snippet_id": 84712, "code": "-list-file=input_files_list', '--report-file=report', ) req=ExecuteProcessRequest( argv=cmd, input_files=directory_digest, output_files=('ignored', 'report'), description='cloc', ) exec_result=self.context", "label": 1}, {"snippet_id": 57554, "code": ".filter(pk__in=case_ids) return self._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none(self.request, pk_enough) except Http404: return None def _sendmail(self): mail_context", "label": 0}, {"snippet_id": 93642, "code": "'name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger", "label": 0}, {"snippet_id": 18211, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( ", "label": 0}, {"snippet_id": 45951, "code": "): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value", "label": 0}, {"snippet_id": 78837, "code": "\t\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None \t\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl)", "label": 0}, {"snippet_id": 76835, "code": "() noproxy_rp=sup.net.RequestPerformer() noproxy_rp.proxy='' noproxy_rp.timeout=c.noproxy_timeout noproxy_rp.timeout=c.rp_timeout d=DataLoader(noproxy_rp, c.only_cache) c.router_addr=d.addrs['rpcrouter", "label": 0}, {"snippet_id": 14372, "code": "._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:'", "label": 0}, {"snippet_id": 83872, "code": "\"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job", "label": 0}, {"snippet_id": 296, "code": "\" List all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address", "label": 0}, {"snippet_id": 85654, "code": "\"Return the path to the Zinc compiler-interface jar. :rtype: str \"\"\" return self._zinc_factory._compiler_interface(self._products) @memoized_method def snapshot(self, scheduler): buildroot=get_buildroot(", "label": 0}, {"snippet_id": 74986, "code": "=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None", "label": 0}, {"snippet_id": 63485, "code": " job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params job_id=job_state", "label": 0}, {"snippet_id": 36004, "code": ", dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict", "label": 0}, {"snippet_id": 6637, "code": " get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False,", "label": 0}, {"snippet_id": 95380, "code": "(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\"", "label": 0}, {"snippet_id": 36579, "code": " if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards", "label": 0}, {"snippet_id": 75020, "code": " overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been", "label": 0}, {"snippet_id": 1531, "code": "(serializer.data, safe=False) elif action=='loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer", "label": 0}, {"snippet_id": 49670, "code": "\" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, ", "label": 0}, {"snippet_id": 32425, "code": ".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards", "label": 0}, {"snippet_id": 75491, "code": "-request', args, reqid) def make_auth_bind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key", "label": 0}, {"snippet_id": 2244, "code": ",') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe", "label": 0}, {"snippet_id": 77350, "code": "'pr{0}' if type_ else 'th{0}').format(i))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as", "label": 0}, {"snippet_id": 37341, "code": ", output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files", "label": 0}, {"snippet_id": 13269, "code": "]), \"sha\": sha, } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not create new branch in the fork\" def autopep8ify(data, config): headers", "label": 0}, {"snippet_id": 89739, "code": "()) @property def home(self): \"\"\"Returns the distribution JAVA_HOME.\"\"\" if not self._home: home=self._get_system_properties(self.java)['java.home'] if os.path.basename(home)=='jre': jdk_dir=os.path.dirname", "label": 0}, {"snippet_id": 88410, "code": " target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser=None, address_mapper=None, console_outstream=None, scm=None, workspace=None, invalidation_report=None, scheduler", "label": 0}, {"snippet_id": 20057, "code": ", **kwargs) else: start=DebugAdapter.start new_addr=Address.as_server if detachable else Address.as_client addr=new_addr(None, self._addr.port) self._adapter=start(argv, addr=addr, env=env, cwd=cwd) if", "label": 0}, {"snippet_id": 86504, "code": ".jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants.base.build_environment import get_buildroot from pants.base.exceptions import", "label": 0}, {"snippet_id": 64776, "code": " target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc", "label": 0}, {"snippet_id": 73830, "code": " runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp:", "label": 0}, {"snippet_id": 7496, "code": " format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result", "label": 0}, {"snippet_id": 2211, "code": "=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name", "label": 0}, {"snippet_id": 7631, "code": " single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]}", "label": 0}, {"snippet_id": 7718, "code": " author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items():", "label": 0}, {"snippet_id": 5062, "code": "<subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in", "label": 0}, {"snippet_id": 70529, "code": " verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print ", "label": 0}, {"snippet_id": 73646, "code": " numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', ", "label": 0}, {"snippet_id": 73902, "code": " enabled=False fields=None alt_number=None chunk_length=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__", "label": 0}, {"snippet_id": 53104, "code": " another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or", "label": 0}, {"snippet_id": 11428, "code": "=OutputWriter(self.output_path(file_name)) output_writer.write_lines(lines) @staticmethod def create_filename(hostname): name='%s.cfg' % hostname if name !=os.path.basename(name): msg=\"Directory traversal", "label": 0}, {"snippet_id": 44275, "code": " of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False", "label": 0}, {"snippet_id": 29296, "code": ").st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files", "label": 0}, {"snippet_id": 24034, "code": "{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*", "label": 0}, {"snippet_id": 72219, "code": "=args.network if netname==irc.name: irc.error(\"Cannot remote-send a command to the local network; use a normal command!\") return try: remoteirc=world.networkobjects[netname] except KeyError: irc.error(", "label": 0}, {"snippet_id": 94929, "code": " parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser", "label": 0}, {"snippet_id": 16668, "code": "=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def", "label": 0}, {"snippet_id": 29477, "code": "<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if", "label": 0}, {"snippet_id": 68663, "code": "\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" ", "label": 0}, {"snippet_id": 63007, "code": ":8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"", "label": 0}, {"snippet_id": 298, "code": " or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST", "label": 0}, {"snippet_id": 25956, "code": "=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl", "label": 0}, {"snippet_id": 34333, "code": ": ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod", "label": 0}, {"snippet_id": 56193, "code": " from django.apps import apps from django.forms import ValidationError from django.http import Http404 from django.http import HttpResponse from django.shortcuts import render from django.views.decorators", "label": 0}, {"snippet_id": 38992, "code": " input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag)", "label": 0}, {"snippet_id": 59645, "code": " for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or", "label": 0}, {"snippet_id": 43597, "code": " from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names", "label": 0}, {"snippet_id": 86949, "code": " while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if after ' 'running clean-all.') register('--incremental-caching', advanced=True, type=bool,", "label": 0}, {"snippet_id": 95070, "code": "\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"]", "label": 1}, {"snippet_id": 7757, "code": " the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes", "label": 0}, {"snippet_id": 26084, "code": " def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData(", "label": 1}, {"snippet_id": 79834, "code": " TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution", "label": 0}, {"snippet_id": 75895, "code": ".wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0]) rslist.append(rs) msg=self.wz.make_req_msg(request[1][0], request[1][1], request[1][2], rs.accept, request[1][3])", "label": 0}, {"snippet_id": 50808, "code": "=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls", "label": 0}, {"snippet_id": 38676, "code": " not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules", "label": 0}, {"snippet_id": 16664, "code": "(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport", "label": 0}, {"snippet_id": 47802, "code": "=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun", "label": 0}, {"snippet_id": 32223, "code": ": self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile", "label": 0}, {"snippet_id": 47485, "code": "+str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value", "label": 0}, {"snippet_id": 28181, "code": "'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24", "label": 0}, {"snippet_id": 93521, "code": "(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/", "label": 0}, {"snippet_id": 60198, "code": "(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CatState:': Catstate, 'CoherentState': Coherent, 'FockDensityMatrix': DensityMatrix, 'DisplacedSqueezed':", "label": 0}, {"snippet_id": 86747, "code": " if any('$JAVA_HOME' in a for a in settings.args): try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution", "label": 0}, {"snippet_id": 31084, "code": " creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if", "label": 0}, {"snippet_id": 49364, "code": "): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets", "label": 0}, {"snippet_id": 2189, "code": ".POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess", "label": 0}, {"snippet_id": 1840, "code": " row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor()", "label": 0}, {"snippet_id": 20232, "code": " message='unable to connect after{} secs'.format( self._connecttimeout) if self._run_server_ex is None: raise Exception(message) else: message=message +os.linesep +self._run_server_ex raise Exception(message", "label": 0}, {"snippet_id": 73096, "code": "{}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory", "label": 0}, {"snippet_id": 68643, "code": "==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE", "label": 0}, {"snippet_id": 71651, "code": ".umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\"", "label": 1}, {"snippet_id": 82394, "code": "\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs", "label": 0}, {"snippet_id": 4137, "code": ".legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from", "label": 1}, {"snippet_id": 87019, "code": "\"\"\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. \"\"\" return self.get_options", "label": 0}, {"snippet_id": 13413, "code": "=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github", "label": 0}, {"snippet_id": 61950, "code": " numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate,", "label": 0}, {"snippet_id": 44659, "code": " print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path", "label": 0}, {"snippet_id": 75551, "code": ", method, type_, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, struct.pack('!B', type_), make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-set-route", "label": 0}, {"snippet_id": 53500, "code": ", *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput", "label": 0}, {"snippet_id": 39500, "code": ": raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority", "label": 0}, {"snippet_id": 57784, "code": "(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets=self.get_update_targets() offset=0 step_length=500 queryset_filter=TestCasePlan.objects.filter data", "label": 0}, {"snippet_id": 61013, "code": " r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian projectors such that:math:`A=", "label": 0}, {"snippet_id": 9384, "code": ".type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc", "label": 0}, {"snippet_id": 56376, "code": " +='</ul>' return HttpResponse(response_str) return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value'))) class _InfoObjects(object): def __init__(self, request, product_id", "label": 0}, {"snippet_id": 5275, "code": " HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary", "label": 0}, {"snippet_id": 73469, "code": " conversion_config): \"\"\" Converts the original data(VCF) to a Zarr format. Only converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output", "label": 1}, {"snippet_id": 36261, "code": " RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded.", "label": 0}, {"snippet_id": 83471, "code": "=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters: compute_environment=LwrComputeEnvironment( client, job_wrapper,", "label": 0}, {"snippet_id": 33735, "code": ":{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources", "label": 0}, {"snippet_id": 47159, "code": ".wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value", "label": 0}, {"snippet_id": 13455, "code": "], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code==201: data[\"pr_url\"]=r.json()[\"html_url\"] else: data[\"error\"]=", "label": 0}, {"snippet_id": 18693, "code": " crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr", "label": 0}, {"snippet_id": 46902, "code": "=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio", "label": 0}, {"snippet_id": 63200, "code": ") unstructured_path_rewrites={} if compute_environment: unstructured_path_rewrites=compute_environment.unstructured_path_rewrites client_job_description=ClientJobDescription( command_line=command_line,", "label": 0}, {"snippet_id": 37996, "code": ") def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards", "label": 0}, {"snippet_id": 24552, "code": " elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self", "label": 0}, {"snippet_id": 58891, "code": ".username, password='password') response=self.client.post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self.plan.pk, 'case':[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects", "label": 0}, {"snippet_id": 92969, "code": ".assertEqual(stderr_data, tmp_stderr.read().strip()) def test_stdio_as(self): self.assertTrue(sys.stderr.fileno() > 2, \"Expected a pseudofile as stderr, got:{}\".format(sys.stderr)) old_stdout, old_stderr", "label": 0}, {"snippet_id": 83693, "code": " get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds) def finish_job( self, job_state): stderr=stdout=", "label": 0}, {"snippet_id": 93952, "code": ") def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name", "label": 0}, {"snippet_id": 57381, "code": ".utils.mailto import mailto mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: mail_context['context']['user']=request.user try", "label": 0}, {"snippet_id": 538, "code": ": return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username", "label": 0}, {"snippet_id": 70502, "code": "* from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre", "label": 0}, {"snippet_id": 44229, "code": " IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot", "label": 0}, {"snippet_id": 46436, "code": " of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end", "label": 0}, {"snippet_id": 89988, "code": " _get_version(self, java): return _parse_java_version('java.version', self._get_system_properties(java)['java.version']) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir", "label": 0}, {"snippet_id": 21910, "code": "=None, subset=None, module_paths=None, extra_vars=None, forks=None, ask_vault_pass=None, vault_password_files=None, new_vault_password_file=None, output_file=None, tags=None, skip_tags=None, one_line=None", "label": 0}, {"snippet_id": 663, "code": " row[0], 'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse", "label": 0}, {"snippet_id": 23440, "code": " useradd\", username) return if expiration is not None: cmd=\"pw useradd{0} -e{1} -m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd)", "label": 0}, {"snippet_id": 24398, "code": " _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"", "label": 0}, {"snippet_id": 56349, "code": " info_type: return HttpResponse('Unrecognizable info-type') if request.GET.get('format')=='ulli': field=request.GET.get('field', default='name') response_str='<ul>' for obj_value in info_type().values(field)", "label": 0}, {"snippet_id": 30006, "code": "\"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard", "label": 0}, {"snippet_id": 24894, "code": "] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0", "label": 0}, {"snippet_id": 13185, "code": "=json.dumps(request_json), headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}", "label": 0}, {"snippet_id": 25345, "code": " dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s", "label": 1}, {"snippet_id": 3163, "code": "'%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name) send_main_session_command(self.session, cmd) def start_remote_clone_session(self, comp_name, session_name, hostname): remote_cmd=(\"%s '%s' '%s'\"", "label": 0}, {"snippet_id": 2711, "code": " with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp", "label": 0}, {"snippet_id": 13333, "code": " headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) fullname=data.get(\"fork_fullname\") for file, new_file in data[\"results\"].items(", "label": 0}, {"snippet_id": 2466, "code": ".has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self", "label": 0}, {"snippet_id": 45555, "code": ".join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except", "label": 1}, {"snippet_id": 87873, "code": " must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-C-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _scalac_plugin_args(self, scalac_plugin_map, classpath", "label": 0}, {"snippet_id": 50807, "code": " rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__", "label": 0}, {"snippet_id": 71037, "code": "(c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if", "label": 0}, {"snippet_id": 39748, "code": " return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator", "label": 0}, {"snippet_id": 38222, "code": " import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand,", "label": 1}, {"snippet_id": 22773, "code": " must be modified in this method. Note that the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0.", "label": 0}, {"snippet_id": 8638, "code": " This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and", "label": 0}, {"snippet_id": 52327, "code": ".touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f", "label": 0}, {"snippet_id": 90997, "code": " different ' 'aliases, according to this map:{}'.format(human_readable_os_aliases)) register('--minimum-version', advanced=True, help='Minimum version of the JVM pants will use') register('--maximum-version", "label": 0}, {"snippet_id": 32615, "code": " bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen", "label": 0}, {"snippet_id": 27783, "code": " elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" ", "label": 0}, {"snippet_id": 34073, "code": ", resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have", "label": 0}, {"snippet_id": 45573, "code": ".file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file,", "label": 1}, {"snippet_id": 34266, "code": "(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate", "label": 0}, {"snippet_id": 80292, "code": ",level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs", "label": 0}, {"snippet_id": 57284, "code": " getattr(t, field), request.user ) ) field='assignee' try: assignee=t.assginee if assignee !=request.user: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field", "label": 0}, {"snippet_id": 73941, "code": " is not None: if hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config", "label": 0}, {"snippet_id": 93548, "code": " self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote", "label": 0}, {"snippet_id": 92581, "code": " of context if cleanup=False.') os.unlink(fp.name) def test_temporary_file_within_other_dir(self): with temporary_dir() as path: with temporary_file(root_dir=path) as f: self.assertTrue(os.path.realpath", "label": 0}, {"snippet_id": 95424, "code": ") Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter", "label": 0}, {"snippet_id": 28165, "code": " None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%'", "label": 0}, {"snippet_id": 18256, "code": ") self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename", "label": 1}, {"snippet_id": 91014, "code": " of the JVM pants will use') register('--maximum-version', advanced=True, help='Maximum version of the JVM pants will use') def all_jdk_paths(self): \"\"\"Get all explicitly configured JDK paths. :return:", "label": 0}, {"snippet_id": 73600, "code": ".blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{", "label": 1}, {"snippet_id": 62172, "code": " isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']", "label": 0}, {"snippet_id": 5816, "code": " version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index", "label": 0}, {"snippet_id": 79822, "code": "=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override", "label": 0}, {"snippet_id": 35782, "code": "(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist", "label": 0}, {"snippet_id": 8857, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a", "label": 1}, {"snippet_id": 66482, "code": " message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system", "label": 0}, {"snippet_id": 88041, "code": " for classpath_element in classpath: name=self._maybe_get_plugin_name(classpath_element) if name in plugin_names: plugin_target_closure=self._plugin_targets('scalac').get(name,[]) rel_classpath_elements=", "label": 0}, {"snippet_id": 69067, "code": ".get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None", "label": 0}, {"snippet_id": 81782, "code": "=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected", "label": 0}, {"snippet_id": 19952, "code": ") if adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') if addr is None: addr=adapter.address self._attach(addr, **kwargs) return", "label": 0}, {"snippet_id": 10015, "code": " if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of", "label": 0}, {"snippet_id": 38633, "code": ".global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self", "label": 0}, {"snippet_id": 5531, "code": " fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)", "label": 0}, {"snippet_id": 49337, "code": "(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger", "label": 0}, {"snippet_id": 11229, "code": " given it reads it's default configuration from file system. The configuration file is: /etc/monitoring_config_generator/config.yaml' Usage: monconfgenerator[--debug][--targetdir=<directory>][--skip-checks", "label": 0}, {"snippet_id": 29783, "code": ") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged", "label": 0}, {"snippet_id": 88040, "code": "') for classpath_element in classpath: name=self._maybe_get_plugin_name(classpath_element) if name in plugin_names: plugin_target_closure=self._plugin_targets('scalac').get(name,[]) rel_classpath_elements", "label": 0}, {"snippet_id": 14154, "code": " import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from", "label": 0}, {"snippet_id": 83640, "code": " env=getattr( job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params job_id", "label": 0}, {"snippet_id": 63533, "code": ".galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds)", "label": 0}, {"snippet_id": 79764, "code": ").\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData", "label": 0}, {"snippet_id": 93674, "code": " if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp", "label": 0}, {"snippet_id": 92776, "code": "'test'), 'w') as zf: self.assertTrue(zf._allowZip64) def test_open_zipTrue(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=True) as zf: self.assertTrue", "label": 0}, {"snippet_id": 96007, "code": ".vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read", "label": 0}, {"snippet_id": 46311, "code": "(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append", "label": 0}, {"snippet_id": 1380, "code": ": \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess", "label": 0}, {"snippet_id": 18276, "code": "() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file", "label": 1}, {"snippet_id": 28310, "code": ".Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\"", "label": 0}, {"snippet_id": 43614, "code": " format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception,", "label": 0}, {"snippet_id": 64209, "code": " class LwrComputeEnvironment( ComputeEnvironment): def __init__( self, lwr_client, job_wrapper, remote_job_config): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper", "label": 0}, {"snippet_id": 3621, "code": "%s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process", "label": 1}, {"snippet_id": 42585, "code": ") if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp", "label": 0}, {"snippet_id": 91458, "code": "-prep', action=IsortPrep).install('fmt') task(name='isort', action=IsortRun).install('fmt') task(name='py', action=PythonBundle).install('bundle') task(name='unpack-wheels', action=UnpackWheels).install", "label": 0}, {"snippet_id": 17759, "code": ".add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory", "label": 0}, {"snippet_id": 17248, "code": "=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request", "label": 0}, {"snippet_id": 84240, "code": ".get( \"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters", "label": 0}, {"snippet_id": 75153, "code": ".warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self.p=parent self.p.wz_connect() self.p.wz_auth_requests=[ (b'Router', b'auth-bind-route'), (b'Router', b'auth", "label": 0}, {"snippet_id": 29883, "code": "-first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with", "label": 0}, {"snippet_id": 29291, "code": " protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join", "label": 0}, {"snippet_id": 89380, "code": " isinstance(version, string_types): version=Revision.lenient(version) if version and not isinstance(version, Revision): raise ValueError('{} must be a string or a Revision object, given:{}'.format(name,", "label": 0}, {"snippet_id": 32263, "code": "._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"", "label": 0}, {"snippet_id": 25571, "code": " elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state", "label": 0}, {"snippet_id": 65953, "code": " nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign", "label": 0}, {"snippet_id": 59654, "code": " given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self", "label": 0}, {"snippet_id": 30497, "code": " config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P", "label": 0}, {"snippet_id": 93583, "code": "'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window", "label": 0}, {"snippet_id": 71302, "code": "\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", '", "label": 0}, {"snippet_id": 35258, "code": " annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained", "label": 0}, {"snippet_id": 15431, "code": ") def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self", "label": 0}, {"snippet_id": 61595, "code": "(self, A, wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem Returns", "label": 0}, {"snippet_id": 12681, "code": ".environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/{}/issues/{}/comments\" query=query.format(data[\"repository\"], str(data[\"pr_number\"])) comments=requests.get(query, headers=headers, auth=auth", "label": 0}, {"snippet_id": 3733, "code": " check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name", "label": 0}, {"snippet_id": 44148, "code": " is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles", "label": 0}, {"snippet_id": 48489, "code": " item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 56348, "code": " not info_type: return HttpResponse('Unrecognizable info-type') if request.GET.get('format')=='ulli': field=request.GET.get('field', default='name') response_str='<ul>' for obj_value in info_type().values", "label": 0}, {"snippet_id": 70061, "code": " open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__", "label": 0}, {"snippet_id": 34223, "code": "*kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return", "label": 0}, {"snippet_id": 78459, "code": ", forum in self.forums: targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain", "label": 0}, {"snippet_id": 43847, "code": " used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name", "label": 0}, {"snippet_id": 5566, "code": ", '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches", "label": 0}, {"snippet_id": 44286, "code": " removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows", "label": 0}, {"snippet_id": 12347, "code": "\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[", "label": 0}, {"snippet_id": 44099, "code": "=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse", "label": 0}, {"snippet_id": 58204, "code": " HTTPStatus from urllib.parse import urlencode from django import test from django.conf import settings from django.contrib.contenttypes.models import ContentType from django.core import serializers from", "label": 0}, {"snippet_id": 15695, "code": ".PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info ", "label": 0}, {"snippet_id": 93365, "code": " comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def", "label": 0}, {"snippet_id": 80282, "code": ": \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\")", "label": 0}, {"snippet_id": 54703, "code": " of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException()", "label": 0}, {"snippet_id": 3980, "code": " remote_mutex.add_argument('-c', '--check', help=\"Run a component check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif", "label": 0}, {"snippet_id": 86165, "code": " ctx.classes_dir) try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict", "label": 0}, {"snippet_id": 22846, "code": ") if ret !=0: raise OSUtilError( \"Failed to set password for{0}:{1}\".format(username, output) ) userentry=self.get_userentry('admin') if userentry is None: raise OSUtilError(\"The 'admin' user account was", "label": 0}, {"snippet_id": 33223, "code": " is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files", "label": 0}, {"snippet_id": 27420, "code": "'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self", "label": 0}, {"snippet_id": 9692, "code": " only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results", "label": 0}, {"snippet_id": 29075, "code": ".data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is", "label": 1}, {"snippet_id": 46720, "code": " isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat", "label": 0}, {"snippet_id": 51754, "code": " Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None,", "label": 0}, {"snippet_id": 86989, "code": ") @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies() +(Zinc.Factory, JvmPlatform,) @classmethod def prepare(cls, options, round_manager): super(BaseZincCompile", "label": 0}, {"snippet_id": 5572, "code": " output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]}", "label": 0}, {"snippet_id": 54915, "code": " not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules", "label": 0}, {"snippet_id": 52170, "code": "{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search", "label": 0}, {"snippet_id": 75731, "code": ") s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8')) self.sig_sock=s s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) self.wz_sock=s self.wz=WZHandler(", "label": 0}, {"snippet_id": 94490, "code": " specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running", "label": 0}, {"snippet_id": 60921, "code": "\"\"\" return self._observables @property def templates(self): \"\"\"Get the predefined circuit templates. .. todo:: rename to circuits? Returns: dict[str->Circuit]: circuit templates \"\"\" return self._circuits", "label": 0}, {"snippet_id": 47757, "code": " Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles", "label": 0}, {"snippet_id": 40403, "code": "] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint", "label": 0}, {"snippet_id": 43022, "code": "(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log", "label": 0}, {"snippet_id": 66591, "code": ".ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs", "label": 0}, {"snippet_id": 48500, "code": " self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None", "label": 0}, {"snippet_id": 4724, "code": ", fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit", "label": 0}, {"snippet_id": 23531, "code": " crypt_id, salt_len) cmd=\"echo '{0}'|pw usermod{1} -H 0 \".format(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret !=0: raise OSUtilError((\"Failed to set password for", "label": 0}, {"snippet_id": 63278, "code": ".job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job", "label": 0}, {"snippet_id": 55781, "code": "*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring", "label": 0}, {"snippet_id": 47868, "code": "(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority", "label": 0}, {"snippet_id": 14744, "code": "'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return", "label": 0}, {"snippet_id": 5386, "code": " \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted", "label": 0}, {"snippet_id": 93950, "code": ".is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session", "label": 0}, {"snippet_id": 36028, "code": "=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards", "label": 0}, {"snippet_id": 42254, "code": ".append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \"", "label": 0}, {"snippet_id": 66458, "code": "(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print", "label": 0}, {"snippet_id": 88697, "code": " self.run_tracker.pantsd_stats.set_affected_targets_size(target_count) return target_count def submit_background_work_chain(self, work_chain, parent_workunit_name=None): \"\"\" :API: public \"\"\" background_root_workunit", "label": 0}, {"snippet_id": 633, "code": " return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows", "label": 0}, {"snippet_id": 19308, "code": " 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.flush() with open(tmp_file.name) as yaml_file: result=load_source(yaml_file) assert result", "label": 0}, {"snippet_id": 14871, "code": " ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass", "label": 0}, {"snippet_id": 26117, "code": " datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE", "label": 1}, {"snippet_id": 84107, "code": " @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution==\"remote\" if", "label": 1}, {"snippet_id": 76239, "code": " wzauth_data.bind_route[i, m])) def clear_auth(self): self.log.debug('Clearing our auth records') def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Auth records", "label": 0}, {"snippet_id": 57268, "code": ", now ) ) if t.tested_by !=request.user: field='tested_by' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), request.user ) ) field='assignee' try: assignee", "label": 0}, {"snippet_id": 27509, "code": " the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name", "label": 0}, {"snippet_id": 49744, "code": "=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)", "label": 0}, {"snippet_id": 94335, "code": ".error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component", "label": 0}, {"snippet_id": 8734, "code": "=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines", "label": 0}, {"snippet_id": 78716, "code": ".post_mortem(sys.exc_info()[2]) else: log.log_error(e) def executer(self, *args): \"\"\"Execute remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port,", "label": 1}, {"snippet_id": 57787, "code": " is None: return say_no('No plan record found.') update_targets=self.get_update_targets() offset=0 step_length=500 queryset_filter=TestCasePlan.objects.filter data={self.target_field: sortkey} while 1:", "label": 0}, {"snippet_id": 85689, "code": " ), ))[0] @memoized_property def rebase_map_args(self): \"\"\"We rebase known stable paths in zinc analysis to make it portable across machines.\"\"\" rebases={ self.dist.real_home: '/dev/null/remapped_by_pants", "label": 0}, {"snippet_id": 22892, "code": "\"Failed to set password for 'admin':{0}\".format(output) ) self._save_sys_config() return ret def del_account(self, username): \"\"\"Deletes a user account. Note that the default method also checks for a \"system", "label": 0}, {"snippet_id": 93710, "code": " tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState", "label": 0}, {"snippet_id": 85919, "code": " DistributionLocator from pants.util.dirutil import safe_open from pants.util.process_handler import subprocess _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE=", "label": 0}, {"snippet_id": 11407, "code": ") return header_source.is_newer_than(old_header) def output_path(self, file_name): return os.path.join(self.target_dir, file_name) def write_output(self, file_name, yaml_icinga): lines=yaml_icinga.icinga_lines", "label": 0}, {"snippet_id": 88677, "code": ".set_target_root_size(target_count) return target_count def _set_affected_target_count_in_runtracker(self): \"\"\"Sets the realized target count in the run tracker's daemon stats object.\"\"\" target_count=len(self.build_graph", "label": 0}, {"snippet_id": 6423, "code": " keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources", "label": 1}, {"snippet_id": 14326, "code": "._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), ", "label": 0}, {"snippet_id": 20307, "code": "(argv, **kwargs) return self._adapter, self._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError", "label": 0}, {"snippet_id": 62717, "code": " to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate", "label": 0}, {"snippet_id": 71308, "code": ".dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status", "label": 0}, {"snippet_id": 8409, "code": ".close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb", "label": 1}, {"snippet_id": 36788, "code": " self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(", "label": 0}, {"snippet_id": 59563, "code": " not yet implemented for this backend\") def shutdown(self): \"\"\"Shutdown. \"\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ", "label": 0}, {"snippet_id": 18859, "code": ") from flex.loading.schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request", "label": 0}, {"snippet_id": 84251, "code": "( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration(self, client, job_wrapper, remote_metadata, remote_job_config): metadata_kwds={} if remote_metadata", "label": 0}, {"snippet_id": 94356, "code": " exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell=True)==0", "label": 0}, {"snippet_id": 56844, "code": " tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter(object): \"\"\" Used for counting the number of times a tag is assigned to TestRun/TestCase/TestPlan \"\"\" def __init__(self", "label": 0}, {"snippet_id": 75177, "code": "-type')] self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init() self.bind_kt_ticker.tick(", "label": 0}, {"snippet_id": 10544, "code": " file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf", "label": 1}, {"snippet_id": 8003, "code": " their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0", "label": 0}, {"snippet_id": 42806, "code": "\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input", "label": 0}, {"snippet_id": 84286, "code": "=remote_job_config['configs_directory'] working_directory=remote_job_config['working_directory'] outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path) for path", "label": 0}, {"snippet_id": 50204, "code": ", c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile", "label": 0}, {"snippet_id": 20909, "code": " handlername, **kwargs): yield result def _close(self): if self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1", "label": 0}, {"snippet_id": 24718, "code": "._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000", "label": 0}, {"snippet_id": 38409, "code": ") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already", "label": 0}, {"snippet_id": 8055, "code": " _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and", "label": 0}, {"snippet_id": 93084, "code": " with temporary_file(permissions=0o700) as f: self.assertEqual(0o700, os.stat(f.name)[0] & 0o777) with temporary_dir(permissions=0o644) as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging", "label": 0}, {"snippet_id": 15637, "code": " diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[", "label": 0}, {"snippet_id": 37530, "code": "(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and", "label": 0}, {"snippet_id": 3459, "code": ".window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\"", "label": 0}, {"snippet_id": 70564, "code": " ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client", "label": 0}, {"snippet_id": 27199, "code": "'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl'", "label": 0}, {"snippet_id": 31147, "code": " in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(", "label": 0}, {"snippet_id": 58494, "code": " self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username", "label": 0}, {"snippet_id": 91178, "code": " PythonBinary from pants.backend.python.targets.python_distribution import PythonDistribution from pants.backend.python.targets.python_library import PythonLibrary from pants.backend.python.targets.python_requirement_library", "label": 0}, {"snippet_id": 34910, "code": "=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range", "label": 0}, {"snippet_id": 7331, "code": "\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"]", "label": 0}, {"snippet_id": 65439, "code": "(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node", "label": 0}, {"snippet_id": 28480, "code": " return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if", "label": 0}, {"snippet_id": 12583, "code": "\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/issues/{}/comments\" url=url.format(repository, str(data[\"pr_number\"])) comments=requests", "label": 0}, {"snippet_id": 39343, "code": " self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath", "label": 0}, {"snippet_id": 8618, "code": " for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes", "label": 0}, {"snippet_id": 23828, "code": " -p{0}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None' if", "label": 0}, {"snippet_id": 74871, "code": "\"vcf\" benchmark_dataset=\"\" benchmark_aggregations=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\" Creates an object representation of the Benchmark module", "label": 1}, {"snippet_id": 83807, "code": ", resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True", "label": 0}, {"snippet_id": 92492, "code": "), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd", "label": 0}, {"snippet_id": 83860, "code": ", pid): try: os.kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check", "label": 0}, {"snippet_id": 95805, "code": "(local_filepath): if os.path.isfile(local_filepath): with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): ", "label": 0}, {"snippet_id": 90184, "code": " from_home(cls, home): \"\"\"Creates a location given the JAVA_HOME directory. :param string home: The path of the JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home", "label": 0}, {"snippet_id": 75071, "code": ".solve_capage(domain, page) self.p.log.info('Done, sending answer: %s', res) self.p.send_success_rep(reqid,[v.encode('utf-8') for v in res]) def send_keepalive(self): msg=self.p.wz.make_req_msg(b'Router', b", "label": 0}, {"snippet_id": 19127, "code": " not None: request=normalize_request(raw_request) response=None if raw_response is not None: response=normalize_response(raw_response, request=request) if response is not None: validate_response( response", "label": 0}, {"snippet_id": 89256, "code": " representing the process being executed. :param labels: A tuple of WorkUnitLabels. :return: An ExecuteProcessResult with information about the execution. Note that this is an unstable, experimental API, which is", "label": 0}, {"snippet_id": 7990, "code": " single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len", "label": 0}, {"snippet_id": 78496, "code": " found: if(t in self.pc.sets['closed'] or t in self.pc.sets['bumplimit'] or t in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in", "label": 1}, {"snippet_id": 70948, "code": " elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\"", "label": 0}, {"snippet_id": 86898, "code": ": True, '-msg-filter': True, }, help='A dict of option regexes that make up pants\\' supported API for zinc. ' 'Options not listed here are subject to change/removal. The value of the dict ' 'indicates that", "label": 0}, {"snippet_id": 37128, "code": " try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))]", "label": 1}, {"snippet_id": 86819, "code": "', '-Xmx2g') @classmethod def get_args_default(cls, bootstrap_option_values): return('-C-encoding', '-CUTF-8', '-S-encoding', '-SUTF-8', '-S-g:vars') @classmethod def get_warning_args_default(cls): return", "label": 0}, {"snippet_id": 58913, "code": " Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': \"You don't have enough permission to \" \"update TestCases.\"})", "label": 0}, {"snippet_id": 8240, "code": " if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor", "label": 1}, {"snippet_id": 34560, "code": ".chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output", "label": 0}, {"snippet_id": 7778, "code": "\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes):", "label": 0}, {"snippet_id": 87411, "code": "=ctx.classes_dir analysis_cache=ctx.analysis_file scala_path=tuple(relative_to_exec_root(c) for c in scala_path) compiler_interface=relative_to_exec_root(compiler_interface) compiler_bridge=relative_to_exec_root", "label": 1}, {"snippet_id": 53997, "code": "=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems", "label": 0}, {"snippet_id": 40379, "code": " return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern):", "label": 0}, {"snippet_id": 62747, "code": ", CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device',", "label": 0}, {"snippet_id": 11220, "code": " transformed into a valid Icinga configuration file. If no URL is given it reads it's default configuration from file system. The configuration file is: /etc/monitoring_config_generator/config.yaml' Usage", "label": 0}, {"snippet_id": 23049, "code": " containing the provisioningiso.iso file This is the _first_ hook that WAAgent provides for us, so this is the point where we should wait for mcpd to load. I am just overloading this method to add the mcpd", "label": 0}, {"snippet_id": 81625, "code": ".shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): ", "label": 0}, {"snippet_id": 30572, "code": ", ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job", "label": 0}, {"snippet_id": 63978, "code": "=installed_tool_dependencies, ) @staticmethod def __dependency_resolution( lwr_client): dependency_resolution=lwr_client.destination_params.get( \"dependency_resolution\", \"local\") if dependency_resolution not in", "label": 0}, {"snippet_id": 52129, "code": "'s a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector", "label": 0}, {"snippet_id": 37674, "code": " self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None", "label": 0}, {"snippet_id": 72203, "code": " due to protocol limitations.\"\"\" permissions.checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args(args) netname=args.network if netname==irc.name: irc.error(\"Cannot remote-send", "label": 0}, {"snippet_id": 82446, "code": "--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int", "label": 0}, {"snippet_id": 44844, "code": " def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule", "label": 0}, {"snippet_id": 66234, "code": " dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic", "label": 0}, {"snippet_id": 17937, "code": "): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET'", "label": 1}, {"snippet_id": 64025, "code": " __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different", "label": 0}, {"snippet_id": 78390, "code": ".counters['topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min exc caught, topic_successtimeout", "label": 0}, {"snippet_id": 81379, "code": "\tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t", "label": 0}, {"snippet_id": 67129, "code": "=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr)", "label": 0}, {"snippet_id": 53212, "code": "=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func", "label": 0}, {"snippet_id": 91434, "code": " task(name='setup-py', action=SetupPy).install() task(name='py', action=PythonBinaryCreate).install('binary') task(name='py-wheels', action=LocalPythonDistributionArtifact).install('binary') task(name=", "label": 0}, {"snippet_id": 11838, "code": "\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get('X-Hub-Signature') if header_signature is None: abort(403) sha_name", "label": 0}, {"snippet_id": 60583, "code": "} def __init__(self, wires, *, shots=0, hbar=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations", "label": 1}, {"snippet_id": 1127, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse", "label": 0}, {"snippet_id": 82088, "code": "=\"Legit extensions expected, for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions", "label": 0}, {"snippet_id": 58314, "code": "(TestNavigation, cls).setUpTestData() cls.user=UserFactory(email='user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses(self): self.client.login( username", "label": 0}, {"snippet_id": 34149, "code": ".benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]", "label": 0}, {"snippet_id": 67731, "code": " print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>", "label": 0}, {"snippet_id": 62134, "code": " plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0)", "label": 0}, {"snippet_id": 68028, "code": " client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> ", "label": 0}, {"snippet_id": 68002, "code": " ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">>", "label": 0}, {"snippet_id": 29114, "code": " collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks", "label": 1}, {"snippet_id": 25069, "code": " self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES)", "label": 1}, {"snippet_id": 84768, "code": " import JvmToolMixin from pants.backend.jvm.subsystems.zinc_language_mixin import ZincLanguageMixin from pants.backend.jvm.targets.jar_library import JarLibrary from pants.build_graph.address import Address", "label": 0}, {"snippet_id": 41253, "code": ": import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except", "label": 0}, {"snippet_id": 82054, "code": "\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group()", "label": 0}, {"snippet_id": 4157, "code": " invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER", "label": 0}, {"snippet_id": 43408, "code": "=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary", "label": 0}, {"snippet_id": 20342, "code": " json import socket import sys import time import threading import warnings from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.message import( raw_read_all as read_messages, raw_write_one", "label": 0}, {"snippet_id": 18463, "code": " and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data", "label": 0}, {"snippet_id": 23324, "code": " port 'n'. Include a wait in here because BIG-IP may not have yet initialized this list of devices. :param port_id: :return: \"\"\" for retries in range(1, 100): if os.path.exists(\"/sys/bus/vmbus/devices/\")", "label": 0}, {"snippet_id": 134, "code": "=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append", "label": 0}, {"snippet_id": 9668, "code": " %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords", "label": 0}, {"snippet_id": 78761, "code": "(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not available: %s', e) except BaseException as e", "label": 0}, {"snippet_id": 87737, "code": "=jvm_options, args=zinc_args, workunit_name=self.name(), workunit_labels=[WorkUnitLabel.COMPILER], dist=self._zinc.dist): raise TaskError('Zinc compile failed.') def _verify_zinc_classpath(self, classpath,", "label": 0}, {"snippet_id": 88973, "code": " dependencies: dependencies=[dep.address for dep in dependencies] self.build_graph.inject_synthetic_target(address=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from,", "label": 0}, {"snippet_id": 8712, "code": " output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False,", "label": 0}, {"snippet_id": 47229, "code": " newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files", "label": 0}, {"snippet_id": 93246, "code": ".load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful", "label": 0}, {"snippet_id": 29299, "code": ".S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path", "label": 0}, {"snippet_id": 18515, "code": " self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable(", "label": 0}, {"snippet_id": 35540, "code": "): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict", "label": 0}, {"snippet_id": 17325, "code": " self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout'", "label": 0}, {"snippet_id": 83128, "code": "\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use", "label": 0}, {"snippet_id": 74618, "code": ", runtime_config=None): \"\"\" Creates an object representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type", "label": 0}, {"snippet_id": 48391, "code": " set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None)", "label": 0}, {"snippet_id": 29194, "code": " ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os", "label": 1}, {"snippet_id": 64505, "code": " else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError", "label": 0}, {"snippet_id": 17321, "code": "}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format", "label": 0}, {"snippet_id": 40035, "code": ") @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink", "label": 1}, {"snippet_id": 64349, "code": " self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[", "label": 0}, {"snippet_id": 53327, "code": ".shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output", "label": 0}, {"snippet_id": 77938, "code": ": tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Removing %s from targets[%s]', repr(t), domain) tlist.remove(t) def add_target_exc(domain, id_, tuser=None): if domain", "label": 0}, {"snippet_id": 59494, "code": ".name, self.short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe", "label": 0}, {"snippet_id": 83206, "code": ": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination", "label": 0}, {"snippet_id": 47867, "code": "=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self", "label": 0}, {"snippet_id": 76054, "code": " status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i, m) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0", "label": 0}, {"snippet_id": 71506, "code": " def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node,", "label": 1}, {"snippet_id": 19964, "code": "'already attached') if addr is None: addr=adapter.address self._attach(addr, **kwargs) return self._session def detach(self, adapter=None): if self.closed: raise RuntimeError('debug client closed') if self", "label": 0}, {"snippet_id": 1328, "code": "\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap", "label": 1}, {"snippet_id": 90065, "code": ".decode('utf-8').split(os.linesep): key, _, val=line.partition('=') props[key]=val self._system_properties=props return self._system_properties def _validate_executable(self, name): def bin_paths(): yield", "label": 0}, {"snippet_id": 80344, "code": " args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is", "label": 0}, {"snippet_id": 74277, "code": "[<option>] and the corresponding values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string", "label": 0}, {"snippet_id": 83858, "code": ".fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got", "label": 0}, {"snippet_id": 35541, "code": "\"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if", "label": 0}, {"snippet_id": 19426, "code": " HOST | --server-host HOST] --port PORT -m MODULE[arg...] {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT FILENAME[arg...] \"\"\" def parse_args(argv=None): \"\"\"Return the parsed args to", "label": 0}, {"snippet_id": 11785, "code": "/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict(base, head): \"\"\" Recursively merge or update dict-like objects. >>> update({'k1': 1},{'k1':{'k2':{'k3': 3}}})", "label": 0}, {"snippet_id": 42326, "code": " apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): ", "label": 0}, {"snippet_id": 64729, "code": " %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s:", "label": 0}, {"snippet_id": 67603, "code": "%s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update", "label": 0}, {"snippet_id": 18110, "code": " except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0", "label": 0}, {"snippet_id": 9823, "code": " :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms", "label": 0}, {"snippet_id": 62380, "code": " Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': for qubit in self.reg: self.eng.deallocate_qubit(qubit) def _deallocate3(self): \"", "label": 0}, {"snippet_id": 81304, "code": " self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html):", "label": 1}, {"snippet_id": 61662, "code": "\"\"\" self._state =None self._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem Returns", "label": 0}, {"snippet_id": 22277, "code": ".utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger as", "label": 0}, {"snippet_id": 54680, "code": " self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name", "label": 0}, {"snippet_id": 85111, "code": " proper classpath based on products and scala version.\"\"\" return self.tool_classpath_from_products(products, self._key_for_tool_version(tool, self.version), scope=self.options_scope) def compiler_classpath", "label": 1}, {"snippet_id": 43532, "code": "): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"", "label": 0}, {"snippet_id": 40860, "code": ".start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names", "label": 0}, {"snippet_id": 8632, "code": "(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in", "label": 0}, {"snippet_id": 22713, "code": " partition-access add{ all-partitions{ role admin}} shell bash\" %(username) retcode, out=shellutil.run_get_output(cmd, log_cmd=True, chk_err=True) if retcode !=0: raise OSUtilError( \"Failed to create user", "label": 0}, {"snippet_id": 46757, "code": "{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search", "label": 0}, {"snippet_id": 35943, "code": " K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial", "label": 0}, {"snippet_id": 50381, "code": " ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__", "label": 0}, {"snippet_id": 55796, "code": ".benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name", "label": 0}, {"snippet_id": 58578, "code": " case_run_ct=ContentType.objects.get_for_model(TestCaseRun) for case_run_pk in(self.case_run_1.pk, self.case_run_2.pk): comments=Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self", "label": 0}, {"snippet_id": 27201, "code": ":['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi", "label": 0}, {"snippet_id": 51405, "code": " isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected", "label": 1}, {"snippet_id": 29880, "code": " given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards", "label": 0}, {"snippet_id": 61204, "code": " array: normalised array. \"\"\" state=np.asarray(args) return state/np.linalg.norm(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix.", "label": 0}, {"snippet_id": 21924, "code": " output_file=None, tags=None, skip_tags=None, one_line=None, tree=None, ask_sudo_pass=None, ask_su_pass=None, sudo=None, sudo_user=None, become=None, become_method=None, become_user=None, become_ask_pass", "label": 0}, {"snippet_id": 67767, "code": ": return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 51488, "code": "\"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group", "label": 1}, {"snippet_id": 53695, "code": " self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic", "label": 0}, {"snippet_id": 27214, "code": ":battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None", "label": 0}, {"snippet_id": 22526, "code": " our purposes at this time though, I would hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method", "label": 0}, {"snippet_id": 50527, "code": " return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version", "label": 0}, {"snippet_id": 13432, "code": "\"https://api.github.com/repos/{}/pulls\" url=url.format(data[\"target_repo_fullname\"]) request_json={ \"title\": \"Fix pep8 errors\", \"head\": \"pep8speaks:{}\".format(data[\"new_branch\"]), \"base\": data[\"target_repo_branch", "label": 0}, {"snippet_id": 23706, "code": ".format(dvd)) if chk_err and retcode !=0: raise OSUtilError(\"Failed to eject dvd: ret={0}\".format(retcode)) def restart_if(self, ifname): shellutil.run(\"/etc/rc.d/dhclient restart{0}\".format(ifname), chk_err", "label": 0}, {"snippet_id": 66752, "code": "\"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e:", "label": 1}, {"snippet_id": 76072, "code": ".status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])", "label": 0}, {"snippet_id": 54602, "code": " return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output", "label": 0}, {"snippet_id": 68830, "code": ".set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 56033, "code": ".resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self", "label": 0}, {"snippet_id": 25342, "code": "(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error", "label": 1}, {"snippet_id": 84898, "code": "._create_compiler_jardep(version)]) def register_scala_repl_tool(version, with_jline=False): classpath=[cls._create_compiler_jardep(version)] if with_jline: jline_dep=JarDependency( org='org.scala-lang'", "label": 0}, {"snippet_id": 88659, "code": " _set_target_root_count_in_runtracker(self): \"\"\"Sets the target root count in the run tracker's daemon stats object.\"\"\" target_count=len(self._target_roots) self.run_tracker.pantsd_stats.set_target_root_size(target_count", "label": 0}, {"snippet_id": 85676, "code": "(( PathGlobsAndRoot( PathGlobs( tuple( fast_relpath(a, buildroot) for a in(self.zinc, self.compiler_bridge, self.compiler_interface) ) ), buildroot, ), ))[0] @memoized_property def rebase_map_args(self", "label": 1}, {"snippet_id": 59421, "code": "=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self", "label": 0}, {"snippet_id": 58402, "code": " target_status_code=HTTPStatus.OK) class TestCommentCaseRuns(BaseCaseRun): \"\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls).setUpTestData(", "label": 0}, {"snippet_id": 94875, "code": " vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil", "label": 0}, {"snippet_id": 33655, "code": "(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(", "label": 0}, {"snippet_id": 30074, "code": " f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return", "label": 0}, {"snippet_id": 53251, "code": "=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self", "label": 0}, {"snippet_id": 27580, "code": "'Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type==", "label": 0}, {"snippet_id": 65470, "code": ": print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done", "label": 0}, {"snippet_id": 15848, "code": " retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server", "label": 0}, {"snippet_id": 32591, "code": "\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 74644, "code": " hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr:", "label": 0}, {"snippet_id": 86692, "code": "+=validate(arg_index) @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform settings. This is responsible for the symbol substitution which", "label": 0}, {"snippet_id": 44144, "code": ".name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self,", "label": 0}, {"snippet_id": 86705, "code": " arguments given in the jvm platform settings. This is responsible for the symbol substitution which replaces $JAVA_HOME with the path to an appropriate jvm distribution. :param settings: The jvm platform", "label": 0}, {"snippet_id": 62655, "code": " **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed", "label": 0}, {"snippet_id": 48377, "code": " SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params:", "label": 0}, {"snippet_id": 85408, "code": "=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope='zinc' @classmethod def subsystem_dependencies(cls): return super", "label": 0}, {"snippet_id": 45490, "code": "} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname", "label": 0}, {"snippet_id": 50053, "code": " no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False", "label": 0}, {"snippet_id": 48987, "code": "-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order", "label": 0}, {"snippet_id": 674, "code": ": row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor", "label": 0}, {"snippet_id": 80313, "code": ".error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex", "label": 0}, {"snippet_id": 34314, "code": "(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return", "label": 0}, {"snippet_id": 57130, "code": ", field and value.') field=str(field) value, error=get_value_by_type(value, vtype) if error: return say_no(error) has_perms=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied", "label": 0}, {"snippet_id": 49544, "code": " forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None", "label": 0}, {"snippet_id": 66204, "code": ") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [", "label": 0}, {"snippet_id": 7742, "code": " if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of", "label": 0}, {"snippet_id": 79244, "code": "=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\",", "label": 0}, {"snippet_id": 40457, "code": "\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False", "label": 0}, {"snippet_id": 6227, "code": " \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number", "label": 1}, {"snippet_id": 49930, "code": " cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds", "label": 0}, {"snippet_id": 81269, "code": "() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self", "label": 1}, {"snippet_id": 8094, "code": " in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT", "label": 0}, {"snippet_id": 79773, "code": "=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar", "label": 0}, {"snippet_id": 22990, "code": " correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists on all platforms that are supported on Azure(Stack) :param dev_dir: The root directory from", "label": 0}, {"snippet_id": 11291, "code": ".exceptions import MonitoringConfigGeneratorException, \\ ConfigurationContainsUndefinedVariables, NoSuchHostname, HostUnreachableException from monitoring_config_generator import set_log_level_to_debug from", "label": 0}, {"snippet_id": 53302, "code": ".priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func", "label": 0}, {"snippet_id": 20045, "code": "(*args, **kwargs): return DebugAdapter.start_wrapper_script( script, *args, **kwargs) else: start=DebugAdapter.start new_addr=Address.as_server if detachable else Address.as_client addr=new_addr(None, self", "label": 0}, {"snippet_id": 95619, "code": "(local_file_gz, local_file): with open(local_file, 'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir):", "label": 0}, {"snippet_id": 9565, "code": " we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted", "label": 0}, {"snippet_id": 68148, "code": "(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR", "label": 0}, {"snippet_id": 81298, "code": ".postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") ", "label": 0}, {"snippet_id": 82678, "code": ": \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds[\"username", "label": 0}, {"snippet_id": 74162, "code": " module's configuration. \"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_allele_count=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config", "label": 1}, {"snippet_id": 79636, "code": "=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected", "label": 0}, {"snippet_id": 36813, "code": "\" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output", "label": 0}, {"snippet_id": 43851, "code": "(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): ", "label": 0}, {"snippet_id": 73803, "code": ": if hasattr(runtime_config, \"ftp\"): if \"enabled\" in runtime_config.ftp: self.enabled=config_str_to_bool(runtime_config.ftp[\"enabled\"]) if \"server\" in runtime_config.ftp: self.server=runtime_config.ftp", "label": 0}, {"snippet_id": 74136, "code": " in configuration.\\n\" \"blosc_shuffle_mode must be a valid integer.\") else: raise TypeError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode could not be converted to integer", "label": 0}, {"snippet_id": 36596, "code": ".remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input", "label": 0}, {"snippet_id": 70969, "code": "(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) ", "label": 0}, {"snippet_id": 44189, "code": " notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes", "label": 0}, {"snippet_id": 95679, "code": " unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir", "label": 0}, {"snippet_id": 67598, "code": ": print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target", "label": 0}, {"snippet_id": 70815, "code": ".append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort", "label": 0}, {"snippet_id": 15918, "code": ", timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync", "label": 0}, {"snippet_id": 77412, "code": ": self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: if type_", "label": 0}, {"snippet_id": 76567, "code": " threading, re, traceback, time import random import zmq from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import UniWipe from wipeskel import *", "label": 0}, {"snippet_id": 30732, "code": " True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule", "label": 0}, {"snippet_id": 46242, "code": " def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath", "label": 0}, {"snippet_id": 3606, "code": "%s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3", "label": 1}, {"snippet_id": 25552, "code": "': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24", "label": 0}, {"snippet_id": 24446, "code": ".type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"", "label": 0}, {"snippet_id": 66179, "code": "=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append", "label": 0}, {"snippet_id": 50483, "code": " return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo):", "label": 0}, {"snippet_id": 40948, "code": " toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names)", "label": 0}, {"snippet_id": 47682, "code": ".append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s", "label": 0}, {"snippet_id": 8722, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the", "label": 0}, {"snippet_id": 41382, "code": ", Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException", "label": 1}, {"snippet_id": 73651, "code": ":param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation", "label": 0}, {"snippet_id": 40042, "code": ".access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self", "label": 1}, {"snippet_id": 46531, "code": " None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items)", "label": 0}, {"snippet_id": 82098, "code": "=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument", "label": 0}, {"snippet_id": 59123, "code": "..])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()\t A simple introspective simulator that only permits classical operations", "label": 0}, {"snippet_id": 28952, "code": " data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data", "label": 0}, {"snippet_id": 56575, "code": "+q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan, TestCase or TestRun \"\"\" tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get(", "label": 1}, {"snippet_id": 4939, "code": "% recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append(", "label": 0}, {"snippet_id": 28080, "code": " def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData(", "label": 1}, {"snippet_id": 74088, "code": "(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\")", "label": 0}, {"snippet_id": 34093, "code": " integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values", "label": 0}, {"snippet_id": 17950, "code": " handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff", "label": 1}, {"snippet_id": 63730, "code": ".strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[", "label": 0}, {"snippet_id": 83621, "code": " job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper", "label": 0}, {"snippet_id": 67574, "code": "%s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print", "label": 0}, {"snippet_id": 70693, "code": "\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print", "label": 0}, {"snippet_id": 70034, "code": ".Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from", "label": 0}, {"snippet_id": 25836, "code": "'WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)", "label": 0}, {"snippet_id": 17951, "code": "), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1", "label": 1}, {"snippet_id": 61219, "code": " unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape[0] !=U.shape[1]", "label": 0}, {"snippet_id": 40872, "code": " names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for", "label": 0}, {"snippet_id": 91324, "code": " BuildFileAliases from pants.build_graph.resources import Resources from pants.goal.task_registrar import TaskRegistrar as task def build_file_aliases(): return BuildFileAliases( targets={ PythonApp.alias", "label": 0}, {"snippet_id": 42077, "code": "(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()}", "label": 0}, {"snippet_id": 64399, "code": " self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for", "label": 0}, {"snippet_id": 24287, "code": "'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol", "label": 1}, {"snippet_id": 39389, "code": "*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames", "label": 0}, {"snippet_id": 30230, "code": " as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs", "label": 0}, {"snippet_id": 91269, "code": " import PythonBinaryCreate from pants.backend.python.tasks.python_bundle import PythonBundle from pants.backend.python.tasks.python_repl import PythonRepl from pants.backend.python.tasks.python_run import", "label": 0}, {"snippet_id": 66725, "code": "% e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message", "label": 1}, {"snippet_id": 44758, "code": " def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the", "label": 0}, {"snippet_id": 28866, "code": " self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state", "label": 0}, {"snippet_id": 58545, "code": "(self): self.client.login( username=self.tester.username, password='password') new_comment='new comment' response=self.client.post( self.many_comments_url, {'comment': new_comment, 'run': ','.join([str", "label": 0}, {"snippet_id": 16191, "code": ", EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy'", "label": 0}, {"snippet_id": 11384, "code": " % (self.source, self.target_dir)) def _is_newer(self, header_source, hostname): if not hostname: raise NoSuchHostname('hostname not found') output_path=self.output_path(self.create_filename(hostname))", "label": 0}, {"snippet_id": 23106, "code": " chk_err=True): \"\"\"Runs the eject command to eject the provisioning DVD BIG-IP does not include an eject command. It is sufficient to just umount the DVD disk. But I will log that we do not support this for", "label": 0}, {"snippet_id": 21230, "code": " sublist in l for item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml", "label": 0}, {"snippet_id": 50567, "code": " decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def", "label": 0}, {"snippet_id": 18418, "code": " vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(", "label": 0}, {"snippet_id": 48601, "code": " list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_", "label": 0}, {"snippet_id": 39426, "code": "(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0]", "label": 0}, {"snippet_id": 34979, "code": "(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start", "label": 0}, {"snippet_id": 42287, "code": "\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake", "label": 0}, {"snippet_id": 20816, "code": "._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result[\"msg\"], evt) def _get_awaiter_for_request(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try", "label": 0}, {"snippet_id": 67481, "code": " from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine", "label": 0}, {"snippet_id": 19687, "code": "-version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None) clienthost=ns.pop('host', None) if serverhost: args.address=Address", "label": 0}, {"snippet_id": 3996, "code": " logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args", "label": 0}, {"snippet_id": 55480, "code": "._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse", "label": 0}, {"snippet_id": 36921, "code": " IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow", "label": 0}, {"snippet_id": 46297, "code": "\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\"", "label": 0}, {"snippet_id": 2227, "code": " safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 22240, "code": " and template in self.conf: template=self.conf['template'] if log_file is None: if 'log_file' in self.conf: log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook", "label": 0}, {"snippet_id": 8843, "code": ".text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\"", "label": 1}, {"snippet_id": 72911, "code": ".username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=ftp_config.directory) else: ftp.cwd(ftp_config.directory)", "label": 0}, {"snippet_id": 15340, "code": ".PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append(", "label": 0}, {"snippet_id": 58085, "code": " bug_system_id=bug_system_id, bz_external_track=bz_external_track) else: bugs=Bug.objects.filter(bug_id__in=bug_ids) for run in runs: for bug in bugs: if bug.case_run_id==run.pk: run.remove_bug(bug.bug_id", "label": 0}, {"snippet_id": 86335, "code": "'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args", "label": 0}, {"snippet_id": 74782, "code": " if(compression_level_int >=0) and(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" ", "label": 0}, {"snippet_id": 9545, "code": " acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the", "label": 0}, {"snippet_id": 51609, "code": " filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: *", "label": 0}, {"snippet_id": 37187, "code": ".touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values)", "label": 0}, {"snippet_id": 62473, "code": "-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys", "label": 0}, {"snippet_id": 34310, "code": " ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def", "label": 0}, {"snippet_id": 51058, "code": "(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self", "label": 0}, {"snippet_id": 78252, "code": ") def add_comment(self, t, msg): if True: try: self.postmsg(t[1], msg, t[0]) except exc.Success as e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self", "label": 0}, {"snippet_id": 79318, "code": " as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension", "label": 0}, {"snippet_id": 245, "code": "'nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname:", "label": 0}, {"snippet_id": 55892, "code": "): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads", "label": 0}, {"snippet_id": 34365, "code": "=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None", "label": 0}, {"snippet_id": 85578, "code": " products to pluck classpaths from. :type products::class:`pants.goal.products.Products` :returns: A Zinc instance with access to relevant Zinc compiler wrapper jars and classpaths. :rtype::class:`Zinc` ", "label": 0}, {"snippet_id": 263, "code": " wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\":", "label": 0}, {"snippet_id": 46762, "code": "=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m.group(\"value", "label": 0}, {"snippet_id": 93360, "code": "['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self", "label": 0}, {"snippet_id": 26521, "code": ".data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature']", "label": 0}, {"snippet_id": 71284, "code": ".append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], ", "label": 0}, {"snippet_id": 83165, "code": "( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the job runner", "label": 0}, {"snippet_id": 28841, "code": "'WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self", "label": 0}, {"snippet_id": 37259, "code": " set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name", "label": 0}, {"snippet_id": 18347, "code": ".format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args", "label": 0}, {"snippet_id": 58767, "code": "': 'testruns.testcaserun', 'object_pk': self.case_run_1.pk, 'field': 'case_run_status', 'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response", "label": 0}, {"snippet_id": 56088, "code": " workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self", "label": 0}, {"snippet_id": 75956, "code": ", 255,[]) rs.finished=True raise WorkerInterrupt() def auth_requests(self): for i, m in self.wz_auth_requests: def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug", "label": 0}, {"snippet_id": 18639, "code": " else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest", "label": 0}, {"snippet_id": 85091, "code": "(register, cls._key_for_tool_version(key, 'custom'), classpath=[dummy_jardep]) register_custom_tool('scalac') register_custom_tool('scala-repl') register_custom_tool('scalastyle') def _tool_classpath(self,", "label": 1}, {"snippet_id": 20675, "code": "._seq +=1 return{ 'type': 'request', 'seq': seq, 'command': command, 'arguments': args, } def send_request(self, command, **args): if self.closed: raise RuntimeError('session closed') wait=args.pop('wait", "label": 0}, {"snippet_id": 17729, "code": "=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 12352, "code": ": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: if", "label": 0}, {"snippet_id": 70751, "code": " status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for", "label": 0}, {"snippet_id": 34719, "code": ".path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file", "label": 0}, {"snippet_id": 14539, "code": "( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive", "label": 0}, {"snippet_id": 42192, "code": ".updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self", "label": 0}, {"snippet_id": 42483, "code": "._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other", "label": 0}, {"snippet_id": 74132, "code": " raise ValueError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode must be a valid integer.\") else: raise TypeError(\"Invalid value for blosc_shuffle_mode in configuration.", "label": 0}, {"snippet_id": 72489, "code": "\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It", "label": 0}, {"snippet_id": 62003, "code": "'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator", "label": 0}, {"snippet_id": 12609, "code": " last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body\"] break \"\"\" text1=''.join(BeautifulSoup(markdown(comment)).findAll(text=True", "label": 0}, {"snippet_id": 46716, "code": "'s a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector", "label": 0}, {"snippet_id": 71914, "code": " command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" %", "label": 0}, {"snippet_id": 94625, "code": ": clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",('echo \" def", "label": 0}, {"snippet_id": 7960, "code": " structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info", "label": 0}, {"snippet_id": 37829, "code": ") if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict()", "label": 0}, {"snippet_id": 62799, "code": "\"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it", "label": 0}, {"snippet_id": 4982, "code": " skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean,", "label": 0}, {"snippet_id": 67841, "code": ".set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result", "label": 0}, {"snippet_id": 2604, "code": " node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet", "label": 0}, {"snippet_id": 36910, "code": " import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None", "label": 0}, {"snippet_id": 36995, "code": "=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self", "label": 0}, {"snippet_id": 21349, "code": "='Arguments to pass to `mpv`.') args=parser.parse_args() subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ['HOME'] +", "label": 1}, {"snippet_id": 42481, "code": "=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd", "label": 0}, {"snippet_id": 95896, "code": "{}\".format(path_str)) print(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path", "label": 1}, {"snippet_id": 272, "code": "\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config", "label": 0}, {"snippet_id": 56261, "code": " import TestCaseStatus, TestCaseTag from tcms.testcases.views import plan_from_request_or_none from tcms.testplans.models import TestPlan, TestCasePlan, TestPlanTag from tcms.testruns.models import TestRun", "label": 0}, {"snippet_id": 69509, "code": " register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd", "label": 0}, {"snippet_id": 13057, "code": "//api.github.com/repos/\" \"{}\".format(repo[\"full_name\"]), headers=headers, auth=auth) return FORKED def fork_for_pr(data): FORKED=False url=\"https://api.github.com/repos/{}/forks\" url=url.format(data[\"target_repo_fullname", "label": 0}, {"snippet_id": 28704, "code": "._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500:", "label": 0}, {"snippet_id": 20924, "code": "=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still running') self._check_handlers() def _listen(self): try: for", "label": 0}, {"snippet_id": 16647, "code": " UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic", "label": 0}, {"snippet_id": 81892, "code": ",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(", "label": 0}, {"snippet_id": 73580, "code": ".DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)) if conversion_config.compressor==\"Blosc\": compressor", "label": 0}, {"snippet_id": 46025, "code": "\"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise", "label": 0}, {"snippet_id": 50447, "code": " *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams", "label": 0}, {"snippet_id": 54011, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=", "label": 0}, {"snippet_id": 52121, "code": "\"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or", "label": 0}, {"snippet_id": 36842, "code": " output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input", "label": 0}, {"snippet_id": 42317, "code": " Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule", "label": 0}, {"snippet_id": 18116, "code": " data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data", "label": 0}, {"snippet_id": 50407, "code": "=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self", "label": 0}, {"snippet_id": 17459, "code": "( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else", "label": 0}, {"snippet_id": 22867, "code": " 'admin' user account was not found!\") cmd=\"/usr/bin/tmsh modify auth user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise", "label": 0}, {"snippet_id": 23260, "code": " i) if b'lo' in iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name(self, sock, offset): return sock[offset:offset+16].split(b", "label": 0}, {"snippet_id": 47003, "code": "(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message", "label": 0}, {"snippet_id": 19927, "code": " adapter=None, **kwargs): if self.closed: raise RuntimeError('debug client closed') if adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError('already using managed adapter", "label": 0}, {"snippet_id": 75335, "code": " seqnum, status, msg[1:]) return() def _parse_sig(self, iden, msg, interface, method): try: handler=self.sig_handlers[(interface, method)] except KeyError: raise WZENoHandler(iden, 'No handler for sig %s", "label": 0}, {"snippet_id": 7750, "code": " return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,..", "label": 0}, {"snippet_id": 5763, "code": " component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0", "label": 0}, {"snippet_id": 26512, "code": " from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self", "label": 0}, {"snippet_id": 39171, "code": " for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n", "label": 0}, {"snippet_id": 91799, "code": "()), ) result=yield Get(FallibleExecuteProcessResult, ExecuteProcessRequest, request) status=Status.SUCCESS if result.exit_code==0 else Status.FAILURE yield TestResult( status=status, stdout=result.stdout", "label": 0}, {"snippet_id": 15610, "code": " self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self)", "label": 0}, {"snippet_id": 9937, "code": " output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms:", "label": 0}, {"snippet_id": 47905, "code": " self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule)", "label": 0}, {"snippet_id": 23684, "code": " ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device() retcode=shellutil.run(\"cdcontrol -f{0}", "label": 0}, {"snippet_id": 64151, "code": " metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home default_config_file=os.path.join(remote_galaxy_home, 'universe_wsgi.ini') metadata_kwds['config_file']", "label": 0}, {"snippet_id": 10795, "code": "\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile", "label": 1}, {"snippet_id": 45253, "code": ".abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir):", "label": 0}, {"snippet_id": 68623, "code": " jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state=", "label": 0}, {"snippet_id": 30925, "code": "(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return", "label": 0}, {"snippet_id": 90096, "code": "'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{} executable,{} does not appear to be a' ' valid{} distribution", "label": 0}, {"snippet_id": 7683, "code": "(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"", "label": 0}, {"snippet_id": 66403, "code": " * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s", "label": 0}, {"snippet_id": 41260, "code": " and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\")", "label": 0}, {"snippet_id": 22669, "code": " instance creation. The second one is the admin account that is, or should be, built in to the system. :param username: The username that you want to add to the system :param expiration: The expiration", "label": 0}, {"snippet_id": 39531, "code": " to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule", "label": 0}, {"snippet_id": 92102, "code": " bad_targets.update(targets) raise IncompatiblePlatformsError(dedent(\"\"\"\\ Pants doesn't currently support cross-compiling native code. The following targets set platforms arguments other than['current']", "label": 0}, {"snippet_id": 29876, "code": " \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per", "label": 0}, {"snippet_id": 81508, "code": "(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self", "label": 0}, {"snippet_id": 60572, "code": "(operator_map.keys()) _observables={'Fock', 'X', 'P', 'Homodyne', 'Heterodyne'} _circuits={} def __init__(self, wires, *, shots=0, hbar=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super()", "label": 0}, {"snippet_id": 53468, "code": " True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark", "label": 0}, {"snippet_id": 80925, "code": " import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t\tself.logger=logging.getLogger(\"fuxploider\") \t", "label": 0}, {"snippet_id": 75609, "code": " self.running is cleared''' def __init__(self): super().__init__('Worker was interrupted at runtime') class Suspend(Exception): '''Exception to raise on suspend signal''' def __init__(self, interval, *args", "label": 0}, {"snippet_id": 42833, "code": ": if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output", "label": 0}, {"snippet_id": 6935, "code": " K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined", "label": 0}, {"snippet_id": 53236, "code": "=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles", "label": 0}, {"snippet_id": 47421, "code": " f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input", "label": 0}, {"snippet_id": 15766, "code": " extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory", "label": 0}, {"snippet_id": 87244, "code": " target=compile_context.target if isinstance(target, ScalacPlugin): self._write_scalac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, JavacPlugin): self._write_javac_plugin_info", "label": 0}, {"snippet_id": 94117, "code": " self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self", "label": 0}, {"snippet_id": 22296, "code": " logger import azurelinuxagent.utils.shellutil as shellutil from azurelinuxagent.exception import OSUtilError from azurelinuxagent.distro.default.osutil import DefaultOSUtil class BigIpOSUtil(DefaultOSUtil", "label": 0}, {"snippet_id": 43058, "code": " name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name", "label": 0}, {"snippet_id": 6642, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract", "label": 1}, {"snippet_id": 32247, "code": " rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self", "label": 0}, {"snippet_id": 60894, "code": " expectation value.') Device._current_context=None self.execute() @property def gates(self): \"\"\"Get the supported gate set. Returns: dict[str->GateSpec]: \"\"\" return self._gates @property def observables(self", "label": 0}, {"snippet_id": 43218, "code": " wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict()", "label": 0}, {"snippet_id": 16087, "code": " _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests", "label": 1}, {"snippet_id": 80311, "code": "=None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and", "label": 0}, {"snippet_id": 9063, "code": " single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors", "label": 0}, {"snippet_id": 37228, "code": " Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile", "label": 0}, {"snippet_id": 77447, "code": ", 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'pr{0}'.format(i)))) self", "label": 0}, {"snippet_id": 62045, "code": "+simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead", "label": 0}, {"snippet_id": 45889, "code": "(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value", "label": 0}, {"snippet_id": 46828, "code": " def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards", "label": 0}, {"snippet_id": 52410, "code": ".encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in", "label": 0}, {"snippet_id": 79692, "code": ".add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"--proxy\",", "label": 0}, {"snippet_id": 62113, "code": " Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" name='ProjectQ OpenQML plugin' short_name='projectq' api_version='0", "label": 0}, {"snippet_id": 77210, "code": " has too few spaces', line) continue if len(proxypair) > 2: self.log.debug('Line %s has too much spaces', line) proxypair=(proxypair[0], proxypair[1]) newproxies.add(proxypair) except Exception as e: self", "label": 0}, {"snippet_id": 41172, "code": ": return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr", "label": 0}, {"snippet_id": 763, "code": ": row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads", "label": 0}, {"snippet_id": 38259, "code": ", snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the", "label": 0}, {"snippet_id": 31279, "code": " self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps", "label": 0}, {"snippet_id": 30667, "code": "), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output", "label": 0}, {"snippet_id": 2313, "code": "(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset", "label": 0}, {"snippet_id": 2998, "code": " log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd']", "label": 0}, {"snippet_id": 51636, "code": " lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards", "label": 0}, {"snippet_id": 78941, "code": "\t\texit() \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0]", "label": 0}, {"snippet_id": 64929, "code": " the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from", "label": 0}, {"snippet_id": 11441, "code": "!=os.path.basename(name): msg=\"Directory traversal attempt detected for host name %r\" raise Exception(msg % hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config", "label": 0}, {"snippet_id": 65291, "code": "', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr", "label": 0}, {"snippet_id": 24862, "code": "%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle", "label": 0}, {"snippet_id": 79553, "code": " secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser'", "label": 0}, {"snippet_id": 31847, "code": "(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in", "label": 0}, {"snippet_id": 65463, "code": " ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev)", "label": 0}, {"snippet_id": 33695, "code": "=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats", "label": 0}, {"snippet_id": 3901, "code": " new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser('validate', help=\"Validate the", "label": 0}, {"snippet_id": 36041, "code": ".params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for", "label": 0}, {"snippet_id": 47887, "code": " self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other", "label": 0}, {"snippet_id": 29695, "code": "(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict(", "label": 0}, {"snippet_id": 93205, "code": "/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None):", "label": 0}, {"snippet_id": 55490, "code": " \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os", "label": 0}, {"snippet_id": 60842, "code": " return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ' +self.author +'\\n' def __enter__(self): if Device._current_context", "label": 0}, {"snippet_id": 48422, "code": "(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise", "label": 0}, {"snippet_id": 48729, "code": " log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output,", "label": 0}, {"snippet_id": 88870, "code": "._lock.acquired: self._lock.acquire() def release_lock(self): \"\"\"Release the global lock if it's held. Returns True if the lock was held before this call. :API: public \"\"\" if not self._lock.acquired: return", "label": 0}, {"snippet_id": 20448, "code": " return Connection(client, server) return cls._create(connect, addr, **kwargs) @classmethod def _create(cls, connect, addr, timeout=None): if timeout is None: timeout=cls.TIMEOUT sock=connect(addr, timeout)", "label": 0}, {"snippet_id": 63913, "code": "): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) if not remote_work_dir_copy", "label": 1}, {"snippet_id": 10097, "code": "(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches,", "label": 0}, {"snippet_id": 42885, "code": "\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError", "label": 0}, {"snippet_id": 85974, "code": ", 'UTF-8') @classmethod def get_warning_args_default(cls): return('-deprecation', '-Xlint:all', '-Xlint:-serial', '-Xlint:-path') @classmethod def get_no_warning_args_default(cls): return('-nowarn', '-Xlint", "label": 0}, {"snippet_id": 4621, "code": " format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"", "label": 0}, {"snippet_id": 87514, "code": ".items())]) zinc_args.extend(self._zinc.rebase_map_args) zinc_args.extend(args) zinc_args.extend(self._get_zinc_arguments(settings)) zinc_args.append('-transactional') for option_set in compiler_option_sets", "label": 0}, {"snippet_id": 78195, "code": " self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets) super().__init__(*args, **kvargs) def on_caprate_limit(self", "label": 0}, {"snippet_id": 10339, "code": ".items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the", "label": 0}, {"snippet_id": 6731, "code": " author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name", "label": 0}, {"snippet_id": 24823, "code": "=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 38771, "code": "=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag", "label": 0}, {"snippet_id": 33627, "code": "(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items", "label": 0}, {"snippet_id": 87273, "code": ", _PROCESSOR_INFO_FILE) self._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f", "label": 0}, {"snippet_id": 64336, "code": " return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self._sep def version_path( self", "label": 0}, {"snippet_id": 67155, "code": "\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f ", "label": 0}, {"snippet_id": 32922, "code": "=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update", "label": 0}, {"snippet_id": 40300, "code": "?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing", "label": 0}, {"snippet_id": 47907, "code": "=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule", "label": 0}, {"snippet_id": 17626, "code": "=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList", "label": 0}, {"snippet_id": 31480, "code": " from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards,", "label": 0}, {"snippet_id": 75493, "code": " args, reqid) def make_auth_bind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return", "label": 0}, {"snippet_id": 22988, "code": " is NOT the correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists on all platforms that are supported on Azure(Stack) :param dev_dir: The root", "label": 0}, {"snippet_id": 11688, "code": " SystemExit as e: exit_code=e.code except BaseException as e: LOG.error(e) exit_code=EXIT_CODE_ERROR finally: stop_time=datetime.now() LOG.info(\"finished in %s\" %(stop_time -start_time)) sys.exit(exit_code)", "label": 0}, {"snippet_id": 54903, "code": "(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list(", "label": 0}, {"snippet_id": 43636, "code": " shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic", "label": 1}, {"snippet_id": 35996, "code": " chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile", "label": 0}, {"snippet_id": 91751, "code": " Get( Digest, DirectoriesToMerge(directories=tuple(all_sources_digests)), ) inits_digest=yield Get(InjectedInitDigest, Digest, sources_digest) all_input_digests=[ sources_digest, inits_digest.directory_digest", "label": 0}, {"snippet_id": 5906, "code": " len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__", "label": 0}, {"snippet_id": 74742, "code": "\\n\" \"Expected: \\\"default\\\" or integer value\") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types:", "label": 0}, {"snippet_id": 11580, "code": " value_to_icinga(value): \"\"\"Convert a scalar or list to Icinga value format. Lists are concatenated by, and empty(None) values produce an empty string\"\"\" if isinstance(value, list): return \",\".join([str", "label": 0}, {"snippet_id": 7724, "code": "] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]", "label": 0}, {"snippet_id": 41355, "code": ", Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import", "label": 0}, {"snippet_id": 28801, "code": " elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" ", "label": 0}, {"snippet_id": 30835, "code": " self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format", "label": 0}, {"snippet_id": 38802, "code": "() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe", "label": 0}, {"snippet_id": 45506, "code": " path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise", "label": 0}, {"snippet_id": 65766, "code": ", AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT,", "label": 0}, {"snippet_id": 23304, "code": "{0}/{1} gw{2}\").format(net, mask, gateway) return shellutil.run(cmd, chk_err=False) def device_for_ide_port(self, port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in here because", "label": 0}, {"snippet_id": 30209, "code": "[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"", "label": 0}, {"snippet_id": 29087, "code": "\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self.station_data", "label": 1}, {"snippet_id": 86520, "code": ".exceptions import TaskError from pants.base.hash_utils import hash_file from pants.base.workunit import WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize, PathGlobs, PathGlobsAndRoot from", "label": 0}, {"snippet_id": 84980, "code": " plugin.') cls.register_jvm_tool(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default", "label": 0}, {"snippet_id": 70144, "code": "), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self", "label": 0}, {"snippet_id": 93657, "code": " comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL", "label": 0}, {"snippet_id": 16527, "code": " FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def", "label": 0}, {"snippet_id": 47541, "code": ")) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def", "label": 0}, {"snippet_id": 8704, "code": ".text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER", "label": 0}, {"snippet_id": 86093, "code": "._write_javac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, AnnotationProcessor) and target.processors: processor_info_file=os.path.join(compile_context.classes_dir, _PROCESSOR_INFO_FILE) self", "label": 0}, {"snippet_id": 69972, "code": " def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return", "label": 0}, {"snippet_id": 70461, "code": ".Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import * from Base.Support.View import View from Base", "label": 0}, {"snippet_id": 22307, "code": " OSUtilError from azurelinuxagent.distro.default.osutil import DefaultOSUtil class BigIpOSUtil(DefaultOSUtil): def __init__(self): super(BigIpOSUtil, self).__init__() def _wait_until_mcpd_is_initialized", "label": 0}, {"snippet_id": 5429, "code": "(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches", "label": 0}, {"snippet_id": 13440, "code": ": \"Fix pep8 errors\", \"head\": \"pep8speaks:{}\".format(data[\"new_branch\"]), \"base\": data[\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers", "label": 0}, {"snippet_id": 84373, "code": " remote_job_config): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths", "label": 0}, {"snippet_id": 60301, "code": "()) _observables={'Fock', 'X', 'P', 'Homodyne'} _circuits={} def __init__(self, wires, *, shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None", "label": 0}, {"snippet_id": 61953, "code": " from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate", "label": 0}, {"snippet_id": 27661, "code": "\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self", "label": 0}, {"snippet_id": 52094, "code": " YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found", "label": 0}, {"snippet_id": 40603, "code": "\"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): ", "label": 0}, {"snippet_id": 89888, "code": "._valid_executable('java') as java: if self._minimum_version: version=self._get_version(java) if version < self._minimum_version: raise self.Error('The java distribution at{} is too old; expecting at least{} and", "label": 0}, {"snippet_id": 44260, "code": " trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by", "label": 0}, {"snippet_id": 10624, "code": " @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is", "label": 0}, {"snippet_id": 33258, "code": " not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets", "label": 0}, {"snippet_id": 43197, "code": "(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio", "label": 0}, {"snippet_id": 62307, "code": "): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def", "label": 0}, {"snippet_id": 37419, "code": "): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self", "label": 0}, {"snippet_id": 45456, "code": ".access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self):", "label": 1}, {"snippet_id": 5650, "code": " c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature", "label": 0}, {"snippet_id": 69053, "code": " def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support", "label": 0}, {"snippet_id": 47658, "code": "\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input", "label": 0}, {"snippet_id": 61969, "code": " import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian", "label": 0}, {"snippet_id": 33900, "code": ", os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def", "label": 0}, {"snippet_id": 88178, "code": " as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile): \"\"\"Compile Scala and Java code to classfiles using", "label": 0}, {"snippet_id": 83829, "code": " exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)", "label": 0}, {"snippet_id": 15627, "code": " and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response", "label": 0}, {"snippet_id": 60072, "code": ".MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if", "label": 0}, {"snippet_id": 83245, "code": " except Exception: self.mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self, job_state", "label": 0}, {"snippet_id": 71137, "code": "=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other", "label": 0}, {"snippet_id": 68575, "code": ", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict", "label": 0}, {"snippet_id": 85269, "code": " specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address): jars=[create_jardep_func(self.version)] build_graph", "label": 0}, {"snippet_id": 80735, "code": " nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[\"templateName\"]]=templatefd.read() \ttemplatefd", "label": 0}, {"snippet_id": 32413, "code": ".wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile", "label": 0}, {"snippet_id": 32026, "code": " temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch", "label": 0}, {"snippet_id": 3472, "code": " down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name)", "label": 0}, {"snippet_id": 68366, "code": "): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target)", "label": 0}, {"snippet_id": 67893, "code": " of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"", "label": 0}, {"snippet_id": 56907, "code": "(self, tag): \"\"\" :param tag: the tag you do the counting for :type tag::class:`tcms.management.models.Tag` :return: the number of times a tag is assigned to object :rtype: int \"\"\" if self.counter['tag'", "label": 0}, {"snippet_id": 55097, "code": " are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument", "label": 0}, {"snippet_id": 7326, "code": ">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field", "label": 0}, {"snippet_id": 11031, "code": " None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime.strptime(mtime, '%a, %d %b %Y %H:", "label": 1}, {"snippet_id": 12914, "code": "=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist", "label": 0}, {"snippet_id": 71148, "code": " fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type", "label": 0}, {"snippet_id": 40593, "code": " output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary", "label": 0}, {"snippet_id": 61269, "code": "*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args(array): square hermitian matrix. Returns: array: square hermitian matrix. \"\"\" A=np.asarray(args[0]) if A.shape[0] !=A.shape", "label": 0}, {"snippet_id": 22410, "code": " logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys", "label": 0}, {"snippet_id": 54483, "code": ", flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None", "label": 1}, {"snippet_id": 47997, "code": ".update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output", "label": 0}, {"snippet_id": 77342, "code": ": if not self.running.is_set(): break try: w=wclass(*args, name='.'.join( (wname,('pr{0}' if type_ else 'th{0}').format(i))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa", "label": 0}, {"snippet_id": 89828, "code": "/bin/jar' >>> If this distribution has no valid command of the given name raises Distribution.Error. If this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if not isinstance(name", "label": 0}, {"snippet_id": 44476, "code": "\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map", "label": 0}, {"snippet_id": 87504, "code": ":{}'.format( relative_to_exec_root(k), relative_to_exec_root(v) ) for k, v in upstream_analysis.items())]) zinc_args.extend(self._zinc.rebase_map_args) zinc_args.extend(args) zinc_args.extend(self._get_zinc_arguments", "label": 0}, {"snippet_id": 21030, "code": " _wait_for_message(self, match, handlername, timeout=None): if timeout is None: timeout=self.TIMEOUT lock, wait=get_locked_and_waiter() def handler(msg): if not match(msg): return msg, False lock.release()", "label": 0}, {"snippet_id": 23995, "code": "{0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk -F. '{print $3}'\" err, output=shellutil.run_get_output(cmd_extract_id) \"\"\"", "label": 0}, {"snippet_id": 87981, "code": " that we don't currently support external plugins with dependencies, as we can't know which external classpath elements are required, and we'd have to put the entire external classpath on each -Xplugin", "label": 0}, {"snippet_id": 44649, "code": " dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile", "label": 0}, {"snippet_id": 51813, "code": ": self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a", "label": 0}, {"snippet_id": 8474, "code": " the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is", "label": 1}, {"snippet_id": 47703, "code": " __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile,", "label": 0}, {"snippet_id": 52459, "code": " RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"", "label": 0}, {"snippet_id": 16031, "code": ", column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column", "label": 0}, {"snippet_id": 18990, "code": " return json.loads(raw_source) except ValueError: pass try: return yaml.load(raw_source) except(yaml.scanner.ScannerError, yaml.parser.ParserError): pass except NameError: pass raise ValueError( \"Unable", "label": 1}, {"snippet_id": 80843, "code": " \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a", "label": 0}, {"snippet_id": 82700, "code": " \telse: \t\tproxyUser=args.proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol", "label": 0}, {"snippet_id": 95765, "code": "\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str", "label": 0}, {"snippet_id": 359, "code": "'getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='loadDependencies':", "label": 0}, {"snippet_id": 90383, "code": "(java_dist_dir): for path in os.listdir(java_dist_dir): home=os.path.join(java_dist_dir, path) if os.path.isdir(home): yield self.Location.from_home(home) class _ExplicitEnvironment(_DistributionEnvironment", "label": 0}, {"snippet_id": 63359, "code": "'working_directory'], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs", "label": 1}, {"snippet_id": 85531, "code": " products): return cls.tool_jar_from_products(products, Zinc.ZINC_COMPILER_TOOL_NAME, cls.options_scope) @classmethod def _compiler_bridge(cls, products): return cls.tool_jar_from_products(products, 'compiler", "label": 0}, {"snippet_id": 27730, "code": "'battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp", "label": 0}, {"snippet_id": 79651, "code": " meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following(name -description", "label": 0}, {"snippet_id": 94708, "code": " or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser('validate', help=", "label": 0}, {"snippet_id": 64685, "code": " GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print \"%s: Mounting %s on ", "label": 0}, {"snippet_id": 21084, "code": ") return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object): @classmethod def wait_all(cls, *awaitables): timeout=3.0 messages=[] for _ in range(int(timeout *", "label": 0}, {"snippet_id": 84568, "code": ".isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask from pants.util.contextutil import temporary_dir class CountLinesOfCode(ConsoleTask): \"\"\"Print counts of lines of code.\"\"", "label": 0}, {"snippet_id": 18857, "code": " definitions_validator, ) from flex.loading.schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import", "label": 0}, {"snippet_id": 60280, "code": " hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()", "label": 0}, {"snippet_id": 32356, "code": " RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable", "label": 0}, {"snippet_id": 86438, "code": " textwrap from builtins import open from collections import defaultdict from contextlib import closing from hashlib import sha1 from xml.etree import ElementTree from future.utils import PY3, text_type from", "label": 1}, {"snippet_id": 87246, "code": " isinstance(target, ScalacPlugin): self._write_scalac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target", "label": 0}, {"snippet_id": 95436, "code": "/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory,", "label": 0}, {"snippet_id": 50036, "code": " if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if", "label": 0}, {"snippet_id": 40433, "code": " string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})", "label": 0}, {"snippet_id": 3401, "code": "/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file", "label": 0}, {"snippet_id": 71272, "code": ": flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\"", "label": 0}, {"snippet_id": 46483, "code": ", names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield", "label": 0}, {"snippet_id": 84487, "code": " remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory", "label": 0}, {"snippet_id": 33458, "code": "\" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow", "label": 0}, {"snippet_id": 60117, "code": " probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state", "label": 0}, {"snippet_id": 82155, "code": ".add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by the server.", "label": 0}, {"snippet_id": 30746, "code": " priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): ", "label": 0}, {"snippet_id": 84650, "code": " for target in targets ) input_files={f.path for snapshot in input_snapshots for f in snapshot.files} with temporary_dir() as tmpdir: list_file=os.path.join(tmpdir, 'input_files_list') with open(list_file", "label": 0}, {"snippet_id": 3186, "code": "%s 'bash -s' < %s\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes", "label": 0}, {"snippet_id": 93485, "code": " and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=", "label": 0}, {"snippet_id": 20704, "code": " self.VERBOSE: msg=parse_message(req) print(' <-', msg) if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter", "label": 0}, {"snippet_id": 25969, "code": "'GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self", "label": 0}, {"snippet_id": 50398, "code": " ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo", "label": 0}, {"snippet_id": 92261, "code": ": def test_empty_environment(self): with environment_as(): pass def test_override_single_variable(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): subprocess.Popen", "label": 0}, {"snippet_id": 29572, "code": ".remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if", "label": 0}, {"snippet_id": 46916, "code": ") self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self", "label": 0}, {"snippet_id": 5628, "code": "[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core", "label": 0}, {"snippet_id": 78545, "code": ".scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if c==0: self.log.info('No targets found at all, sleeping for 30 seconds') self.long_sleep(30) self.schedule(self.comment_loop) if len(self.forums)=", "label": 0}, {"snippet_id": 19443, "code": "\" def parse_args(argv=None): \"\"\"Return the parsed args to use in main().\"\"\" if argv is None: argv=sys.argv prog=argv[0] if prog==__file__: prog='{} -m ptvsd'.format(os.path.basename(sys.executable)) else", "label": 0}, {"snippet_id": 77918, "code": " or '' t=(tuser, id_) logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser", "label": 0}, {"snippet_id": 9329, "code": ", taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit:", "label": 0}, {"snippet_id": 58288, "code": ".factories import UserFactory from tcms.tests.factories import EnvGroupFactory from tcms.tests.factories import EnvGroupPropertyMapFactory from tcms.tests.factories import EnvPropertyFactory class TestNavigation", "label": 0}, {"snippet_id": 85135, "code": " style_classpath(self, products): return self._tool_classpath('scalastyle', products) @property def version(self): return self.get_options().version def suffix_version(self, name): \"\"\"Appends the platform version to", "label": 0}, {"snippet_id": 44726, "code": ", os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def", "label": 0}, {"snippet_id": 68475, "code": "(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if", "label": 0}, {"snippet_id": 40667, "code": "\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError(", "label": 1}, {"snippet_id": 39611, "code": ".input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params", "label": 0}, {"snippet_id": 30468, "code": " \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or", "label": 0}, {"snippet_id": 65231, "code": " system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc", "label": 0}, {"snippet_id": 31365, "code": ".updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list()", "label": 0}, {"snippet_id": 53838, "code": ".add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have", "label": 0}, {"snippet_id": 86940, "code": " compilation, which dramatically ' 'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if after ' 'running clean-all.", "label": 0}, {"snippet_id": 70313, "code": " RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status]", "label": 0}, {"snippet_id": 14426, "code": ".PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self", "label": 0}, {"snippet_id": 17744, "code": ": if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded", "label": 0}, {"snippet_id": 42041, "code": "=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError", "label": 0}, {"snippet_id": 25996, "code": "'rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'", "label": 0}, {"snippet_id": 35517, "code": "\"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False", "label": 0}, {"snippet_id": 54846, "code": ", benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False", "label": 0}, {"snippet_id": 3146, "code": " kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'", "label": 0}, {"snippet_id": 37458, "code": ".protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"):", "label": 0}, {"snippet_id": 18553, "code": "._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if", "label": 0}, {"snippet_id": 76147, "code": ")) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() else: self.log.warn('Status{0}, retrying'.format(wzrpc", "label": 0}, {"snippet_id": 13798, "code": ", count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self", "label": 0}, {"snippet_id": 38729, "code": " if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag", "label": 0}, {"snippet_id": 52734, "code": " Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output", "label": 0}, {"snippet_id": 26016, "code": "'wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56:", "label": 0}, {"snippet_id": 16398, "code": " _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r')", "label": 0}, {"snippet_id": 84587, "code": " cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register): super(CountLinesOfCode, cls).register_options(register) register('--transitive', type=bool, fingerprint=True", "label": 0}, {"snippet_id": 4899, "code": "=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical", "label": 0}, {"snippet_id": 85895, "code": " import JvmCompile from pants.base.exceptions import TaskError from pants.base.workunit import WorkUnit, WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize from pants.engine.isolated_process", "label": 0}, {"snippet_id": 12473, "code": ".format(line, col, line_url) error_string=\" \".join(error_string_list) error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append(\"\\n\\n\")", "label": 0}, {"snippet_id": 50276, "code": " **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has", "label": 0}, {"snippet_id": 88580, "code": ":API: public \"\"\" return self._target_roots @property def console_outstream(self): \"\"\"Returns the output stream to write console messages to. :API: public \"\"\" return self._console_outstream @property def", "label": 0}, {"snippet_id": 54760, "code": " in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute", "label": 0}, {"snippet_id": 34423, "code": "._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if", "label": 0}, {"snippet_id": 78084, "code": " get_forum_id(forum) logger.info('Removing %s:%s from forums[%s]', user, forum, domain) forums[domain].remove((user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login'", "label": 0}, {"snippet_id": 93573, "code": "(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp", "label": 0}, {"snippet_id": 21468, "code": ") else: print(\"Reddytt: Working directory found. Loading variables.\") with open(seen_file, 'rb') as f: seen_links=pickle.load(f) with open(unseen_file, 'rb') as f: unseen_links=pickle.load(f) new_links", "label": 0}, {"snippet_id": 12655, "code": ": break elif 'quiet' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False return PERMITTED_TO_COMMENT def create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token", "label": 0}, {"snippet_id": 12221, "code": " with open(\"file_to_check.py\", 'w+', encoding=r.encoding) as file_to_check: file_to_check.write(r.text) cmd='pycodestyle{config[pycodestyle_cmd_config]} file_to_check.py'.format( config=config) proc=subprocess", "label": 0}, {"snippet_id": 17037, "code": "'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData", "label": 0}, {"snippet_id": 2779, "code": "=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!", "label": 0}, {"snippet_id": 43025, "code": " self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, ", "label": 0}, {"snippet_id": 68206, "code": ".get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other", "label": 1}, {"snippet_id": 63679, "code": " we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid", "label": 0}, {"snippet_id": 64247, "code": "\"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"]", "label": 0}, {"snippet_id": 82736, "code": " proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif", "label": 0}, {"snippet_id": 15583, "code": ") def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if", "label": 0}, {"snippet_id": 58125, "code": "(Component, 'name'), 'version':(Version, 'value'), 'build':(Build, 'name'), 'category':(Category, 'name'), } results=ctypes[target][0]._default_manager.filter(product__in=p_pks) attr=ctypes[target][1] results", "label": 0}, {"snippet_id": 37983, "code": " snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"", "label": 0}, {"snippet_id": 24094, "code": " -e 's/).*//'\".format(output) err, output=shellutil.run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible return None", "label": 0}, {"snippet_id": 43939, "code": " resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores", "label": 0}, {"snippet_id": 77787, "code": " frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) self.th_sock.send_multipart(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self", "label": 0}, {"snippet_id": 18401, "code": " open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE", "label": 0}, {"snippet_id": 69056, "code": ": return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler", "label": 0}, {"snippet_id": 70964, "code": " if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len", "label": 0}, {"snippet_id": 90874, "code": " Error(Distribution.Error): \"\"\"Error locating a java distribution. :API: public \"\"\" @classmethod def cached(cls, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that", "label": 0}, {"snippet_id": 64240, "code": " remote_job_config, self.local_path_config.working_directory()) self._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config", "label": 0}, {"snippet_id": 42411, "code": " elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles", "label": 0}, {"snippet_id": 77560, "code": " Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users(self): users={} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds=[] for i in range(uqsize): uds.append", "label": 0}, {"snippet_id": 1293, "code": "-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':", "label": 0}, {"snippet_id": 23330, "code": " devices. :param port_id: :return: \"\"\" for retries in range(1, 100): if os.path.exists(\"/sys/bus/vmbus/devices/\"): break else: time.sleep(10) return super(BigIpOSUtil, self).device_for_ide_port(port_id", "label": 0}, {"snippet_id": 14039, "code": ".CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value':", "label": 0}, {"snippet_id": 82111, "code": " exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv", "label": 0}, {"snippet_id": 8870, "code": " extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" %", "label": 1}, {"snippet_id": 2379, "code": "'%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts/start_named_clone_session", "label": 0}, {"snippet_id": 81011, "code": "=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject", "label": 0}, {"snippet_id": 44430, "code": "()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list", "label": 0}, {"snippet_id": 32833, "code": ", not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd", "label": 1}, {"snippet_id": 54799, "code": " prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False,", "label": 0}, {"snippet_id": 10168, "code": " for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0", "label": 0}, {"snippet_id": 47031, "code": " try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 3755, "code": ": session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name", "label": 0}, {"snippet_id": 26565, "code": " self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self", "label": 0}, {"snippet_id": 80947, "code": "\t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself", "label": 0}, {"snippet_id": 40648, "code": "): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if", "label": 1}, {"snippet_id": 21904, "code": ", verbosity=None, inventory=None, listhosts=None, subset=None, module_paths=None, extra_vars=None, forks=None, ask_vault_pass=None, vault_password_files=None, new_vault_password_file=None, output_file=None", "label": 0}, {"snippet_id": 726, "code": ".Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall(", "label": 0}, {"snippet_id": 81138, "code": ".inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using", "label": 0}, {"snippet_id": 13036, "code": "=requests.get(url, headers=headers, auth=auth) for repo in r.json(): if repo[\"description\"]: if data[\"target_repo_fullname\"] in repo[\"description\"]: FORKED=True r=requests.delete(\"https://api.github.com/repos/", "label": 0}, {"snippet_id": 38280, "code": " self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 95495, "code": " try: local_path=local_directory +\"/\" +remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP] Created local folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP", "label": 0}, {"snippet_id": 41313, "code": " WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum", "label": 0}, {"snippet_id": 94957, "code": " creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser", "label": 0}, {"snippet_id": 69638, "code": "(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(", "label": 1}, {"snippet_id": 66743, "code": " except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except", "label": 1}, {"snippet_id": 36672, "code": " res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local", "label": 0}, {"snippet_id": 43115, "code": ". \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output", "label": 0}, {"snippet_id": 84306, "code": "=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home default_config_file=os.path.join(remote_galaxy_home, 'universe_wsgi.ini') metadata_kwds['config_file", "label": 0}, {"snippet_id": 16284, "code": "._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump(", "label": 1}, {"snippet_id": 71652, "code": ") rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes", "label": 1}, {"snippet_id": 2307, "code": "(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer", "label": 0}, {"snippet_id": 28502, "code": " def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data", "label": 0}, {"snippet_id": 47167, "code": " wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files", "label": 0}, {"snippet_id": 2426, "code": "(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w')", "label": 0}, {"snippet_id": 56761, "code": " 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk) def run(self): return 'run/get_tag.html', TestRun.objects.get(pk=self.object_pk) class _TagActions(object): \"\"\" Used for performing the", "label": 0}, {"snippet_id": 12871, "code": " as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout,", "label": 0}, {"snippet_id": 61222, "code": "\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape[0] !=U.shape[1]: raise ValueError", "label": 0}, {"snippet_id": 33317, "code": ".name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self", "label": 0}, {"snippet_id": 7167, "code": " single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary", "label": 0}, {"snippet_id": 87749, "code": ".dist): raise TaskError('Zinc compile failed.') def _verify_zinc_classpath(self, classpath, allow_dist=True): def is_outside(path, putative_parent): return os.path.relpath(path, putative_parent).startswith", "label": 0}, {"snippet_id": 46764, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import", "label": 0}, {"snippet_id": 19902, "code": " self.closed: raise RuntimeError('debug client closed') if self._adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') raise NotImplementedError", "label": 0}, {"snippet_id": 95809, "code": "(local_filepath): with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input", "label": 0}, {"snippet_id": 73372, "code": ", output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input", "label": 0}, {"snippet_id": 31240, "code": ") except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources", "label": 0}, {"snippet_id": 75874, "code": "() rs.accept(None, 0, 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict", "label": 0}, {"snippet_id": 89447, "code": " TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception)", "label": 0}, {"snippet_id": 42385, "code": ".subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile", "label": 0}, {"snippet_id": 9697, "code": " if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches,", "label": 0}, {"snippet_id": 66008, "code": ")],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count", "label": 0}, {"snippet_id": 84489, "code": ") def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return", "label": 0}, {"snippet_id": 65944, "code": "\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status", "label": 0}, {"snippet_id": 78730, "code": " try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request) response", "label": 0}, {"snippet_id": 78269, "code": ".w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment,(t, msg)) except(exc.Closed, exc.UserDeny) as e: try: self.targets", "label": 0}, {"snippet_id": 19600, "code": "=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget", "label": 1}, {"snippet_id": 87463, "code": ".extend(['-compiler-interface', compiler_interface]) zinc_args.extend(['-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala-path',", "label": 1}, {"snippet_id": 3835, "code": "\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs", "label": 0}, {"snippet_id": 74934, "code": ".benchmark[\"benchmark_dataset\"] if \"benchmark_aggregations\" in runtime_config.benchmark: self.benchmark_aggregations=config_str_to_bool(runtime_config.benchmark[\"benchmark_aggregations\"]) if \"benchmark_PCA", "label": 1}, {"snippet_id": 40642, "code": " exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"", "label": 0}, {"snippet_id": 27337, "code": " config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names():", "label": 1}, {"snippet_id": 50827, "code": "._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile", "label": 0}, {"snippet_id": 20894, "code": " result['msg']=msg return msg.request_seq==seq handlername='response(cmd:{} seq:{})'.format(command, seq) with self._wait_for_message(match, handlername, **kwargs): yield result def _close(self): if self", "label": 0}, {"snippet_id": 51654, "code": "}) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath", "label": 0}, {"snippet_id": 74740, "code": " value provided for chunk_width in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if", "label": 0}, {"snippet_id": 35578, "code": ".get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name,", "label": 0}, {"snippet_id": 3194, "code": " send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node') for current in node.depends_on: deps.node", "label": 0}, {"snippet_id": 69677, "code": " file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers", "label": 0}, {"snippet_id": 70011, "code": " previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import", "label": 0}, {"snippet_id": 18856, "code": " definitions_validator, ) from flex.loading.schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http", "label": 0}, {"snippet_id": 38164, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib", "label": 0}, {"snippet_id": 33043, "code": ".first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by", "label": 0}, {"snippet_id": 6991, "code": "\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords", "label": 0}, {"snippet_id": 87080, "code": "(self.context.log, self.get_options().whitelisted_args, self._args) if self.execution_strategy==self.HERMETIC: try: fast_relpath(self.get_options().pants_workdir, get_buildroot()) except ValueError: raise", "label": 0}, {"snippet_id": 71832, "code": " RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e", "label": 1}, {"snippet_id": 23529, "code": ".gen_password_hash(password, crypt_id, salt_len) cmd=\"echo '{0}'|pw usermod{1} -H 0 \".format(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret !=0: raise OSUtilError((", "label": 0}, {"snippet_id": 20517, "code": " read=recv_as_read(self._sock) for msg, _, _ in read_messages(read, stop=stop): if self.VERBOSE: print(repr(msg)) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection", "label": 0}, {"snippet_id": 3024, "code": "], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name'", "label": 0}, {"snippet_id": 34571, "code": "(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function", "label": 0}, {"snippet_id": 72143, "code": " ValueError: irc.error('Invalid argument \"%s\" for <seconds>.' % seconds) return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument('network", "label": 0}, {"snippet_id": 32741, "code": "(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return", "label": 0}, {"snippet_id": 36554, "code": " in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self", "label": 0}, {"snippet_id": 73009, "code": " function that automatically downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list ", "label": 0}, {"snippet_id": 83098, "code": ".lwr_client import url_to_destination_params from.lwr_client import finish_job as lwr_finish_job from.lwr_client import submit_job as lwr_submit_job from.lwr_client import ClientJobDescription from.lwr_client", "label": 0}, {"snippet_id": 17754, "code": "._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data):", "label": 0}, {"snippet_id": 81158, "code": ".debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection", "label": 0}, {"snippet_id": 74878, "code": " __init__(self, runtime_config=None): \"\"\" Creates an object representation of the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type", "label": 0}, {"snippet_id": 75632, "code": ": self.interval=interval super().__init__(*args, **kvargs) class Resume(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=", "label": 0}, {"snippet_id": 74841, "code": " valid integer.\") else: raise TypeError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode could not be converted to integer.\") benchmark_data_input_types=[\"vcf\", \"zarr\"] class", "label": 0}, {"snippet_id": 61059, "code": "([[0, -1j],[1j, 0]]) Z=np.array([[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0]]) SWAP=np.array([[1, 0, 0, 0],[0, 0, 1, 0],[0, 1, 0, 0],[0, 0, 0, 1]]) def frx(theta", "label": 0}, {"snippet_id": 49706, "code": "())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated", "label": 0}, {"snippet_id": 23670, "code": "(self, ifname): shellutil.run(\"route delete 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret", "label": 0}, {"snippet_id": 35651, "code": "._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end", "label": 0}, {"snippet_id": 9905, "code": " single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword", "label": 0}, {"snippet_id": 24479, "code": "\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self", "label": 0}, {"snippet_id": 71028, "code": "\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" %", "label": 0}, {"snippet_id": 68164, "code": "(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc", "label": 0}, {"snippet_id": 60288, "code": "\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock', 'X', 'P', ", "label": 0}, {"snippet_id": 80865, "code": "[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint", "label": 0}, {"snippet_id": 57049, "code": " value type.' else: try: value=pipe(val) except Exception as e: error=str(e) return value, error def say_no(error_msg): ajax_response={'rc': 1, 'response': error_msg} return HttpResponse(json.dumps(ajax_response", "label": 0}, {"snippet_id": 33966, "code": "(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir", "label": 0}, {"snippet_id": 76818, "code": "'Forget about closed topics') parser.add_argument('--die-on-neterror', action='store_true', default=False, help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net", "label": 0}, {"snippet_id": 42387, "code": ".resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd", "label": 0}, {"snippet_id": 9282, "code": " composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according", "label": 0}, {"snippet_id": 35856, "code": " files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath", "label": 0}, {"snippet_id": 60230, "code": "'ControlledPhase': CZgate, 'Displacement': Dgate, 'Kerr': Kgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device):", "label": 0}, {"snippet_id": 42865, "code": "\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output", "label": 0}, {"snippet_id": 93186, "code": " datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts", "label": 0}, {"snippet_id": 7431, "code": "=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords", "label": 0}, {"snippet_id": 72551, "code": " file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of", "label": 0}, {"snippet_id": 45859, "code": "(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:", "label": 0}, {"snippet_id": 78524, "code": " self.log.debug('Found no new targets in forum %s:%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while", "label": 0}, {"snippet_id": 55132, "code": " in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow", "label": 0}, {"snippet_id": 52824, "code": "\" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job", "label": 0}, {"snippet_id": 77996, "code": ") r_di=re.compile(regexp.f_udi) def atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target(domain, id_, user) def rtfu(urls): for user, domain, id1, id2 in r_di.findall(urls", "label": 0}, {"snippet_id": 54338, "code": ".name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the", "label": 0}, {"snippet_id": 33760, "code": " in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag", "label": 0}, {"snippet_id": 8878, "code": " for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines", "label": 1}, {"snippet_id": 75697, "code": " thread-local interface on startup''' self.log=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker=Ticker() self.poller=zmq.Poller() s=self.ctx.socket(zmq.SUB) self.poller.register", "label": 0}, {"snippet_id": 13980, "code": " delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return", "label": 0}, {"snippet_id": 47154, "code": " for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name", "label": 0}, {"snippet_id": 61912, "code": "\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions ", "label": 0}, {"snippet_id": 11311, "code": " monitoring_config_generator.yaml_tools.config import YamlConfig from monitoring_config_generator.settings import CONFIG EXIT_CODE_CONFIG_WRITTEN=0 EXIT_CODE_ERROR=1 EXIT_CODE_NOT_WRITTEN=2 LOG=logging.getLogger(", "label": 0}, {"snippet_id": 88984, "code": "=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from, **kwargs) new_target=self.build_graph.get_target(address) return new_target def targets(self, predicate=None, **kwargs)", "label": 0}, {"snippet_id": 29105, "code": " stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from", "label": 1}, {"snippet_id": 88949, "code": " source root. :API: public \"\"\" rel_target_base=target_base or address.spec_path abs_target_base=os.path.join(get_buildroot(), rel_target_base) if not os.path.exists(abs_target_base): os.makedirs(abs_target_base", "label": 0}, {"snippet_id": 8954, "code": " output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning", "label": 0}, {"snippet_id": 12968, "code": "(diffs) !=0: REQUEST_JSON[\"files\"][file.split(\"/\")[-1] +\".diff\"]={ \"content\": diffs } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD", "label": 0}, {"snippet_id": 73659, "code": " input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data", "label": 0}, {"snippet_id": 11351, "code": " set_log_level_to_debug() if not self.target_dir or not os.path.isdir(self.target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\"", "label": 0}, {"snippet_id": 35290, "code": "\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per", "label": 0}, {"snippet_id": 31410, "code": " run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append", "label": 0}, {"snippet_id": 39361, "code": "(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config", "label": 0}, {"snippet_id": 83240, "code": "(self.__async_update) return job_state status=client.get_status() except Exception: self.mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return", "label": 0}, {"snippet_id": 92468, "code": ") self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_nested_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual", "label": 0}, {"snippet_id": 63499, "code": " job_state): job_destination_params=job_state.job_destination.params job_id=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env", "label": 0}, {"snippet_id": 16417, "code": "-NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not", "label": 0}, {"snippet_id": 41225, "code": " Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json", "label": 0}, {"snippet_id": 46845, "code": ".get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input", "label": 0}, {"snippet_id": 54653, "code": " snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule", "label": 0}, {"snippet_id": 58251, "code": " CaseAutomatedForm from tcms.testcases.forms import TestCase from tcms.testplans.models import TestPlan from tcms.testruns.models import TestCaseRun from tcms.testruns.models import TestCaseRunStatus from tcms", "label": 1}, {"snippet_id": 48571, "code": "=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str", "label": 0}, {"snippet_id": 63668, "code": " job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job", "label": 0}, {"snippet_id": 55471, "code": " return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None):", "label": 0}, {"snippet_id": 68839, "code": " layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +", "label": 0}, {"snippet_id": 93910, "code": "=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname)", "label": 0}, {"snippet_id": 55529, "code": " self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if", "label": 0}, {"snippet_id": 34374, "code": ".params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow", "label": 0}, {"snippet_id": 8215, "code": " provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio", "label": 1}, {"snippet_id": 89079, "code": ".build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter(predicate, target_set)) def _collect_targets(self, root_targets, **kwargs): return", "label": 0}, {"snippet_id": 54534, "code": "=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included", "label": 0}, {"snippet_id": 48709, "code": ".output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output)", "label": 0}, {"snippet_id": 2601, "code": " for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else", "label": 0}, {"snippet_id": 8984, "code": " definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return", "label": 0}, {"snippet_id": 6385, "code": " and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six", "label": 0}, {"snippet_id": 80112, "code": " Form Detection arguments') manualFormArgs.add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection", "label": 0}, {"snippet_id": 67391, "code": "=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors:", "label": 1}, {"snippet_id": 60475, "code": " Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock,", "label": 0}, {"snippet_id": 64315, "code": " local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"%s_files\" % remote_path[ 0:-len( \".dat\")", "label": 0}, {"snippet_id": 91902, "code": ".getLogger(__name__) class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope='python-native-code' default_native_source_extensions", "label": 0}, {"snippet_id": 14274, "code": " self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive", "label": 1}, {"snippet_id": 89898, "code": " raise self.Error('The java distribution at{} is too old; expecting at least{} and' ' got{}'.format(java, self._minimum_version, version)) if self._maximum_version: version=self._get_version(java) if version", "label": 0}, {"snippet_id": 26386, "code": " SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices", "label": 0}, {"snippet_id": 78582, "code": "(self, WipeState.waiting_for_targets): while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self", "label": 0}, {"snippet_id": 78731, "code": ": url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request) response", "label": 0}, {"snippet_id": 41098, "code": "._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next", "label": 0}, {"snippet_id": 57526, "code": " if resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids=map(int, self.request.POST", "label": 0}, {"snippet_id": 69296, "code": ".print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except KeyError: print", "label": 1}, {"snippet_id": 86162, "code": "._record_compile_classpath(classpath, ctx.target, ctx.classes_dir) try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform", "label": 0}, {"snippet_id": 43431, "code": " --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict", "label": 0}, {"snippet_id": 12305, "code": "[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(repository, after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment", "label": 0}, {"snippet_id": 64298, "code": " for local_input_path in local_input_paths: wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path", "label": 0}, {"snippet_id": 40252, "code": "._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex(", "label": 0}, {"snippet_id": 39005, "code": " in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False", "label": 0}, {"snippet_id": 52575, "code": " combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self", "label": 0}, {"snippet_id": 71727, "code": "\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen", "label": 0}, {"snippet_id": 51761, "code": " to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone -", "label": 0}, {"snippet_id": 91204, "code": ".python_tests import PythonTests from pants.backend.python.targets.unpacked_whls import UnpackedWheels from pants.backend.python.tasks.build_local_python_distributions import \\ BuildLocalPythonDistributions", "label": 0}, {"snippet_id": 47490, "code": "(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()}", "label": 0}, {"snippet_id": 41149, "code": " add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def", "label": 0}, {"snippet_id": 43324, "code": " concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as", "label": 0}, {"snippet_id": 74074, "code": " blosc_compression_level_str=runtime_config.vcf_to_zarr[\"blosc_compression_level\"] if isint(blosc_compression_level_str): compression_level_int=int(blosc_compression_level_str) if(compression_level_int", "label": 0}, {"snippet_id": 21617, "code": ".preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix", "label": 0}, {"snippet_id": 82910, "code": "\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==", "label": 1}, {"snippet_id": 86194, "code": "', ':'.join(classpath), ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format", "label": 0}, {"snippet_id": 46911, "code": "=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output:", "label": 0}, {"snippet_id": 67502, "code": " Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from", "label": 0}, {"snippet_id": 3815, "code": ", comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",", "label": 0}, {"snippet_id": 53102, "code": " if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self", "label": 0}, {"snippet_id": 8937, "code": ":param text_lines: list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param", "label": 0}, {"snippet_id": 31230, "code": "*_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self", "label": 0}, {"snippet_id": 37133, "code": " expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old)", "label": 1}, {"snippet_id": 87634, "code": ".directory_digest ) if len(directory_digests) !=len(dependency_classpath): for dep in dependency_classpath: if dep.directory_digest is None: logger.warning( \"ClasspathEntry{} didn't have a DirectoryDigest, so won't", "label": 1}, {"snippet_id": 65872, "code": " elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\"", "label": 0}, {"snippet_id": 16835, "code": " not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description': x.description } for x in rawsnips]", "label": 0}, {"snippet_id": 1199, "code": ".models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd", "label": 1}, {"snippet_id": 68978, "code": "\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr", "label": 1}, {"snippet_id": 27141, "code": " Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'", "label": 1}, {"snippet_id": 47398, "code": " Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \",", "label": 0}, {"snippet_id": 80010, "code": "(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by the server. Needs -l switch", "label": 0}, {"snippet_id": 86911, "code": " zinc. ' 'Options not listed here are subject to change/removal. The value of the dict ' 'indicates that an option accepts an argument.') register('--incremental', advanced=True, type=bool, default=True", "label": 0}, {"snippet_id": 54995, "code": ", forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete", "label": 0}, {"snippet_id": 74051, "code": "=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types: self.compressor=compressor_temp if \"blosc_compression_algorithm\" in runtime_config.vcf_to_zarr: blosc_compression_algorithm_temp", "label": 0}, {"snippet_id": 6269, "code": " distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable", "label": 1}, {"snippet_id": 10850, "code": " line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable)", "label": 1}, {"snippet_id": 79342, "code": " \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads", "label": 0}, {"snippet_id": 26774, "code": "': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0", "label": 0}, {"snippet_id": 39427, "code": ", lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0],", "label": 0}, {"snippet_id": 78091, "code": " forums[%s]', user, forum, domain) forums[domain].remove((user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login': login, 'passwd': passwd}, False) def send_to_wm", "label": 0}, {"snippet_id": 23121, "code": " sufficient to just umount the DVD disk. But I will log that we do not support this for future reference. :param chk_err: Whether or not to check for errors raised by the eject command \"\"\" logger.warn(\"Eject", "label": 0}, {"snippet_id": 37545, "code": " start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params", "label": 0}, {"snippet_id": 88647, "code": " self._set_target_root_count_in_runtracker() yield self.run_tracker.pantsd_stats.set_scheduler_metrics(self._scheduler.metrics()) self._set_affected_target_count_in_runtracker() def _set_target_root_count_in_runtracker", "label": 0}, {"snippet_id": 4487, "code": "=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext", "label": 0}, {"snippet_id": 91823, "code": "=result.stderr.decode('utf-8'), ) def rules(): return[ run_python_test, UnionRule(TestTarget, PythonTestsAdaptor), optionable_rule(PyTest), optionable_rule(PythonSetup), optionable_rule(SourceRootConfig), ]", "label": 0}, {"snippet_id": 58347, "code": "})) self.assertContains(response, urlencode({'author__email__startswith': self.user.email})) class TestIndex(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self", "label": 0}, {"snippet_id": 82490, "code": " args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is", "label": 0}, {"snippet_id": 63189, "code": " job_wrapper, job_destination) if not command_line: return try: dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters(", "label": 0}, {"snippet_id": 83971, "code": " sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt", "label": 0}, {"snippet_id": 30106, "code": " list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False):", "label": 0}, {"snippet_id": 76574, "code": " from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import UniWipe from wipeskel import * import wzrpc from beon import regexp import pickle from", "label": 0}, {"snippet_id": 21004, "code": " def _check_handlers(self): unhandled=[] for handle_msg, name, required in self._handlers: if not required: continue unhandled.append(name or repr(handle_msg)) if unhandled: raise RuntimeError('unhandled", "label": 0}, {"snippet_id": 62715, "code": ". retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items", "label": 0}, {"snippet_id": 80323, "code": ".n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not-regex or with -", "label": 0}, {"snippet_id": 65764, "code": " layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index", "label": 0}, {"snippet_id": 57970, "code": ",')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id", "label": 0}, {"snippet_id": 16107, "code": ".raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ ", "label": 0}, {"snippet_id": 13097, "code": " auth=auth) if r.status_code==202: data[\"fork_fullname\"]=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos", "label": 0}, {"snippet_id": 61789, "code": ".wires-b-1) between=2**n_between U=np.kron(U, np.eye(between)) if wires[0] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim ", "label": 0}, {"snippet_id": 63137, "code": ".__find_watched_job( job_id) if not job_state: sleep( 2) job_state=self.__find_watched_job( job_id) if not job_state: log.warn( \"Failed to find job corresponding to final status %s in %s\" %( full_status,", "label": 0}, {"snippet_id": 18912, "code": " object(dictionary-like) -path to yaml file -path to json file -file object(json or yaml). -json string. -yaml string. \"\"\" if isinstance(source, collections.Mapping): return source elif hasattr(source,", "label": 0}, {"snippet_id": 74745, "code": "\" or integer value\") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types: self.compressor=compressor_temp", "label": 0}, {"snippet_id": 3479, "code": "\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self", "label": 0}, {"snippet_id": 30904, "code": " output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill)", "label": 0}, {"snippet_id": 6746, "code": " if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1]", "label": 0}, {"snippet_id": 80872, "code": "\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt", "label": 0}, {"snippet_id": 61402, "code": "=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self._state is None: self._state=np.zeros(2**self.wires", "label": 1}, {"snippet_id": 27498, "code": " this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get", "label": 0}, {"snippet_id": 55639, "code": " snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None)", "label": 0}, {"snippet_id": 69438, "code": " command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action", "label": 1}, {"snippet_id": 95203, "code": " results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files(ftp_server, ftp_directory, files=None", "label": 1}, {"snippet_id": 53075, "code": ".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input", "label": 0}, {"snippet_id": 91845, "code": " pants.backend.native.targets.native_library import NativeLibrary from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.subsystems import pex_build_util from pants", "label": 0}, {"snippet_id": 82878, "code": ".info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[", "label": 0}, {"snippet_id": 73632, "code": " configparser import ConfigParser from shutil import copyfile import os.path from pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The", "label": 0}, {"snippet_id": 54227, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output", "label": 0}, {"snippet_id": 1361, "code": "\"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli", "label": 0}, {"snippet_id": 23406, "code": "\"hostname{0}\".format(hostname), chk_err=False) def restart_ssh_service(self): return shellutil.run('service sshd restart', chk_err=False) def useradd(self, username, expiration=None): \"\"\" Create user account", "label": 1}, {"snippet_id": 44708, "code": ".included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert", "label": 0}, {"snippet_id": 35, "code": " import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt", "label": 1}, {"snippet_id": 11406, "code": ".parse(output_path) return header_source.is_newer_than(old_header) def output_path(self, file_name): return os.path.join(self.target_dir, file_name) def write_output(self, file_name, yaml_icinga): lines", "label": 0}, {"snippet_id": 90964, "code": " OS_ALIASES.items()) register('--paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME", "label": 0}, {"snippet_id": 14898, "code": " return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler", "label": 0}, {"snippet_id": 73547, "code": " print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"", "label": 0}, {"snippet_id": 60015, "code": ": raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified", "label": 0}, {"snippet_id": 39556, "code": ".benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format", "label": 0}, {"snippet_id": 71385, "code": " layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +", "label": 0}, {"snippet_id": 38710, "code": " targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 10540, "code": "\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if", "label": 1}, {"snippet_id": 9725, "code": "(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]", "label": 0}, {"snippet_id": 48247, "code": ", _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item", "label": 0}, {"snippet_id": 88326, "code": " run. Advanced uses of the context include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated with. ", "label": 0}, {"snippet_id": 12413, "code": "\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link\"])) for issue", "label": 0}, {"snippet_id": 58803, "code": "', 'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) self", "label": 0}, {"snippet_id": 87714, "code": "[WorkUnitLabel.COMPILER]) self.context._scheduler.materialize_directories(( DirectoryToMaterialize(get_buildroot(), res.output_directory_digest), )) return res.output_directory_digest else: if self.runjava", "label": 1}, {"snippet_id": 2962, "code": "]) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting", "label": 0}, {"snippet_id": 7318, "code": " kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' ", "label": 0}, {"snippet_id": 70459, "code": " Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import * from Base.Support.View import View", "label": 0}, {"snippet_id": 54129, "code": ".apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 86786, "code": ", distribution.home) for a in settings.args) zinc_args.extend(settings_args) return zinc_args @classmethod def implementation_version(cls): return super(BaseZincCompile, cls).implementation_version() +", "label": 0}, {"snippet_id": 17751, "code": ")[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer())", "label": 0}, {"snippet_id": 43050, "code": " self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile", "label": 0}, {"snippet_id": 39658, "code": " ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 18316, "code": "), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log'", "label": 0}, {"snippet_id": 16912, "code": " BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST", "label": 0}, {"snippet_id": 12411, "code": " PEP8 issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file ", "label": 0}, {"snippet_id": 77682, "code": ".debug('Other sets were loaded') self.pc.sets.update(data['sets']) def load_bumplimit_set(self): if not os.path.isfile(self.bumplimitfile): return with open(self.bumplimitfile, 'rb') as f: self.pc.sets", "label": 0}, {"snippet_id": 10618, "code": " @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not", "label": 0}, {"snippet_id": 7246, "code": ", provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted", "label": 0}, {"snippet_id": 10181, "code": ")]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output", "label": 0}, {"snippet_id": 20327, "code": "('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ '-m', module, ] +list(argv) if kwargs.pop('nodebug', False): argv", "label": 0}, {"snippet_id": 56406, "code": " except(ValueError, TypeError): self.product_id=0 def builds(self): try: is_active=strtobool(self.request.GET.get('is_active', default='False')) except(ValueError, TypeError): is_active=False return Build", "label": 0}, {"snippet_id": 8422, "code": "'t \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines", "label": 1}, {"snippet_id": 37626, "code": "(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item", "label": 0}, {"snippet_id": 94641, "code": "\"Enter\") window.cmd(\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists", "label": 0}, {"snippet_id": 456, "code": ", safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the", "label": 0}, {"snippet_id": 34816, "code": ".rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile", "label": 1}, {"snippet_id": 60480, "code": " CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map", "label": 0}, {"snippet_id": 44677, "code": ".included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple", "label": 0}, {"snippet_id": 71524, "code": "%s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed", "label": 0}, {"snippet_id": 32340, "code": " InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule", "label": 0}, {"snippet_id": 69651, "code": " fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes", "label": 0}, {"snippet_id": 32069, "code": "(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags", "label": 0}, {"snippet_id": 12168, "code": "[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os", "label": 0}, {"snippet_id": 84336, "code": ".warn(NO_REMOTE_DATATYPES_CONFIG) remote_datatypes_config=os.path.join(remote_galaxy_home, 'datatypes_conf.xml') metadata_kwds['datatypes_config']=remote_datatypes_config else: integrates_datatypes_config", "label": 0}, {"snippet_id": 50903, "code": "} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname", "label": 0}, {"snippet_id": 63357, "code": " remote_command_params=dict( working_directory=remote_job_config['working_directory'], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper,", "label": 0}, {"snippet_id": 48263, "code": " output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if", "label": 0}, {"snippet_id": 93697, "code": ".logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in", "label": 0}, {"snippet_id": 14777, "code": ": def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files", "label": 0}, {"snippet_id": 69372, "code": " Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type", "label": 0}, {"snippet_id": 40397, "code": " os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\"", "label": 0}, {"snippet_id": 29016, "code": "='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state", "label": 0}, {"snippet_id": 94881, "code": " runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments()", "label": 1}, {"snippet_id": 82381, "code": "\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t", "label": 0}, {"snippet_id": 14644, "code": ".Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not", "label": 0}, {"snippet_id": 9345, "code": " style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword", "label": 0}, {"snippet_id": 85493, "code": "'compiler-bridge', rev=zinc_rev, classifier='sources', intransitive=True), ]) cls.register_jvm_tool(register, 'compiler-interface', classpath=[ JarDependency(org='org.scala-sbt', name='compiler-interface", "label": 0}, {"snippet_id": 6336, "code": ". its two main methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the", "label": 0}, {"snippet_id": 8337, "code": "=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read", "label": 1}, {"snippet_id": 12157, "code": " for file in list(files.keys()): if file[-3:] !=\".py\": del files[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"\"\" headers", "label": 0}, {"snippet_id": 94109, "code": " self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\")", "label": 0}, {"snippet_id": 59008, "code": "') cls.property_django=EnvPropertyFactory(name='django') EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_os) EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_python", "label": 0}, {"snippet_id": 34704, "code": " protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join", "label": 0}, {"snippet_id": 21352, "code": ".') args=parser.parse_args() subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ['HOME'] +\"/.reddytt\" sr_dir=work_dir ", "label": 1}, {"snippet_id": 93761, "code": ".debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost", "label": 0}, {"snippet_id": 56576, "code": "+q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan, TestCase or TestRun \"\"\" tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags')", "label": 1}, {"snippet_id": 17801, "code": " extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(", "label": 0}, {"snippet_id": 70489, "code": " open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import", "label": 0}, {"snippet_id": 5296, "code": " dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically", "label": 0}, {"snippet_id": 34769, "code": "(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as", "label": 0}, {"snippet_id": 78625, "code": " from dbnav.jsonable import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec': 'executer', 'dbexport': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self,", "label": 0}, {"snippet_id": 76579, "code": " workers from dataloader import DataLoader from uniwipe import UniWipe from wipeskel import * import wzrpc from beon import regexp import pickle from logging import config from logconfig import logging_config", "label": 0}, {"snippet_id": 79047, "code": " provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\"", "label": 0}, {"snippet_id": 50844, "code": " self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self):", "label": 1}, {"snippet_id": 4168, "code": " taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags", "label": 0}, {"snippet_id": 9709, "code": "=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results", "label": 0}, {"snippet_id": 81505, "code": ".shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog", "label": 0}, {"snippet_id": 43053, "code": " kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str", "label": 0}, {"snippet_id": 86576, "code": ".processing.Processor' logger=logging.getLogger(__name__) class BaseZincCompile(JvmCompile): \"\"\"An abstract base class for zinc compilation tasks.\"\"\" _name='zinc' @staticmethod def _write_scalac_plugin_info", "label": 1}, {"snippet_id": 15477, "code": "=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data)", "label": 0}, {"snippet_id": 92189, "code": ".32.3', help='The wheel version to use when executing `setup.py` scripts.') @property def base_requirements(self): return[ PythonRequirement('setuptools=={}'.format(self.get_options().setuptools_version)", "label": 0}, {"snippet_id": 16433, "code": " return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport", "label": 0}, {"snippet_id": 18789, "code": "): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data", "label": 0}, {"snippet_id": 93644, "code": " res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(", "label": 0}, {"snippet_id": 55154, "code": " workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}:", "label": 0}, {"snippet_id": 34890, "code": "<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if", "label": 0}, {"snippet_id": 22771, "code": " account, both must be modified in this method. Note that the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have", "label": 0}, {"snippet_id": 53756, "code": " output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item", "label": 0}, {"snippet_id": 4777, "code": " composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted", "label": 0}, {"snippet_id": 30233, "code": " \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in", "label": 0}, {"snippet_id": 44465, "code": ": items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs)", "label": 0}, {"snippet_id": 21219, "code": " import urllib3 import certifi import re import sys import argparse as ap flatten=lambda l:[item for sublist in l for item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED", "label": 0}, {"snippet_id": 25376, "code": " data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning", "label": 0}, {"snippet_id": 57967, "code": "'case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e", "label": 0}, {"snippet_id": 68271, "code": "=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target", "label": 0}, {"snippet_id": 52113, "code": "{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config", "label": 0}, {"snippet_id": 487, "code": "(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt", "label": 0}, {"snippet_id": 58419, "code": ".setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs') def test_refuse_if_missing_comment(self): self.client.login( username=self.tester.username, password='password') response=self.client.post", "label": 0}, {"snippet_id": 86193, "code": "-classpath', ':'.join(classpath), ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args", "label": 0}, {"snippet_id": 66978, "code": " assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg", "label": 0}, {"snippet_id": 17134, "code": " ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse", "label": 0}, {"snippet_id": 10317, "code": " list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords", "label": 0}, {"snippet_id": 93266, "code": ".debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found", "label": 0}, {"snippet_id": 28154, "code": "['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure", "label": 1}, {"snippet_id": 87025, "code": " property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. \"\"\" return self.get_options().incremental @property def cache_incremental(self): ", "label": 0}, {"snippet_id": 83163, "code": ":8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"", "label": 0}, {"snippet_id": 85635, "code": "._zinc_factory.dist @memoized_property def compiler_bridge(self): \"\"\"Return the path to the Zinc compiler-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property", "label": 0}, {"snippet_id": 68905, "code": " import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import", "label": 0}, {"snippet_id": 94175, "code": ".server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name", "label": 0}, {"snippet_id": 72614, "code": "/data/temp/\" vcf_directory=\"./data/vcf/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command", "label": 1}, {"snippet_id": 51890, "code": "._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end", "label": 0}, {"snippet_id": 18122, "code": " import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers", "label": 0}, {"snippet_id": 29057, "code": ".\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle", "label": 1}, {"snippet_id": 50523, "code": " resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 23089, "code": " Whether to check for errors or not in the mounting commands \"\"\" self._wait_until_mcpd_is_initialized() return super(BigIpOSUtil, self).mount_dvd(**kwargs) def eject_dvd(self, chk_err=True): \"\"\"Runs the", "label": 0}, {"snippet_id": 42683, "code": " are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output", "label": 0}, {"snippet_id": 64613, "code": ") if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count", "label": 0}, {"snippet_id": 16662, "code": ": if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message'])", "label": 0}, {"snippet_id": 34244, "code": " return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo):", "label": 0}, {"snippet_id": 48435, "code": "(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log", "label": 0}, {"snippet_id": 18820, "code": "( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets", "label": 0}, {"snippet_id": 93040, "code": ": mock_initial_handler=1 mock_new_handler=2 with mock.patch('signal.signal', **PATCH_OPTS) as mock_signal: mock_signal.return_value=mock_initial_handler try: with signal_handler_as(signal.SIGUSR2, mock_new_handler", "label": 0}, {"snippet_id": 43274, "code": " concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output", "label": 0}, {"snippet_id": 4598, "code": " the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already", "label": 0}, {"snippet_id": 66133, "code": "\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target", "label": 0}, {"snippet_id": 92904, "code": "(binary_mode=False) as tmp_stdout,\\ temporary_file(binary_mode=False) as tmp_stderr: print(stdin_data, file=tmp_stdin) tmp_stdin.seek(0) with stdio_as(stdout_fd=tmp_stdout.fileno(), stderr_fd=tmp_stderr", "label": 0}, {"snippet_id": 80793, "code": "({\"suffix\":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[", "label": 1}, {"snippet_id": 21790, "code": ") X=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0) from sklearn", "label": 1}, {"snippet_id": 23387, "code": " rc_file_path='/etc/rc.conf' conf_file=fileutil.read_file(rc_file_path).split(\"\\n\") textutil.set_ini_config(conf_file, \"hostname\", hostname) fileutil.write_file(rc_file_path, \"\\n\".join(conf_file)) shellutil", "label": 0}, {"snippet_id": 76778, "code": " limit') parser.add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser.add_argument('--topic_successtimeout', type=float, default=0.1, help='Topic success", "label": 0}, {"snippet_id": 72567, "code": "=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\", metavar=\"RUN_LABEL\", help", "label": 1}, {"snippet_id": 74426, "code": " representation with a supplied file. \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for", "label": 0}, {"snippet_id": 56596, "code": ".get('tags') q_action=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag", "label": 0}, {"snippet_id": 52489, "code": ".shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex", "label": 0}, {"snippet_id": 40662, "code": "\"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group", "label": 1}, {"snippet_id": 80105, "code": "=\"Use a random user-agent while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection arguments') manualFormArgs.add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true", "label": 0}, {"snippet_id": 5021, "code": " marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"", "label": 0}, {"snippet_id": 65507, "code": " %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__", "label": 0}, {"snippet_id": 33652, "code": " list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed", "label": 0}, {"snippet_id": 6114, "code": "=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close", "label": 0}, {"snippet_id": 93373, "code": ".copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group", "label": 0}, {"snippet_id": 76031, "code": "(data)) self.wz_wait_reply(accept, *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m])) def bind_route(self, i, m, f): self.log.debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum", "label": 0}, {"snippet_id": 35123, "code": "): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value)", "label": 0}, {"snippet_id": 40086, "code": ": return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os", "label": 0}, {"snippet_id": 26675, "code": "._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280", "label": 0}, {"snippet_id": 23727, "code": "{0}\".format(ifname), chk_err=False) def get_total_mem(self): cmd=\"sysctl hw.physmem |awk '{print $2}'\" ret, output=shellutil.run_get_output(cmd) if ret: raise OSUtilError(\"Failed to get total memory:{0}", "label": 0}, {"snippet_id": 51279, "code": "{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern", "label": 0}, {"snippet_id": 85026, "code": " 'and must exist. Otherwise, defaults for the specified version will be used.') register('--suffix-version', advanced=True, default=None, help='Scala suffix to be used in `scala_jar` definitions. For example", "label": 0}, {"snippet_id": 7202, "code": " :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output", "label": 0}, {"snippet_id": 49253, "code": ".is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1", "label": 0}, {"snippet_id": 37005, "code": "=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other", "label": 0}, {"snippet_id": 80785, "code": "=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested", "label": 1}, {"snippet_id": 13144, "code": ".status_code !=200): time.sleep(5) r=requests.get(url, headers=headers, auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname", "label": 0}, {"snippet_id": 21109, "code": " awaitables if a._event is not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'.format(awaitable.name)) else: messages.append(", "label": 0}, {"snippet_id": 60252, "code": ". wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation", "label": 0}, {"snippet_id": 89136, "code": " dependency in target.dependencies: if dependency in core: dependees[target].add(dependency) return dependees def resolve(self, spec): \"\"\"Returns an iterator over the target(s) the given address points to. :API", "label": 0}, {"snippet_id": 53440, "code": " wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards)", "label": 0}, {"snippet_id": 73334, "code": " filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head(path): head, tail=os.path.split(path) return head def path_leaf(path): head, tail=os.path.split(path) return tail or os.path.basename(head", "label": 0}, {"snippet_id": 31273, "code": "()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 47393, "code": " cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n", "label": 0}, {"snippet_id": 34909, "code": ".\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait))", "label": 0}, {"snippet_id": 67990, "code": "(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message):", "label": 0}, {"snippet_id": 69447, "code": ": for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt -=1 if self.fs.action_refcnt==0", "label": 1}, {"snippet_id": 1477, "code": ".get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address", "label": 0}, {"snippet_id": 93541, "code": ".yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost", "label": 0}, {"snippet_id": 27267, "code": " Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None],", "label": 0}, {"snippet_id": 59758, "code": "(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. ", "label": 0}, {"snippet_id": 81335, "code": ") \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result:", "label": 0}, {"snippet_id": 46370, "code": " Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str", "label": 0}, {"snippet_id": 23580, "code": "=self._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper() return None def get_first_if(self): return self._get_net_info()[:2] def route_add(self, net, mask, gateway): cmd='route add", "label": 0}, {"snippet_id": 62159, "code": " k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'", "label": 0}, {"snippet_id": 38192, "code": " functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions", "label": 0}, {"snippet_id": 62511, "code": " __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just", "label": 0}, {"snippet_id": 7524, "code": " element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output", "label": 0}, {"snippet_id": 38918, "code": "=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)", "label": 0}, {"snippet_id": 72312, "code": " del kwargs['source'] irc.reply(text, source=irc.pseudoclient.uid, **kwargs) old_reply=remoteirc.reply with remoteirc.reply_lock: try: log.debug('(%s) networks.remote: overriding reply() of IRC object ", "label": 1}, {"snippet_id": 7183, "code": " composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms", "label": 0}, {"snippet_id": 66720, "code": " e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e", "label": 1}, {"snippet_id": 51181, "code": " latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex", "label": 0}, {"snippet_id": 56567, "code": " form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan, TestCase", "label": 1}, {"snippet_id": 28649, "code": "'battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data[", "label": 0}, {"snippet_id": 37504, "code": "[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append", "label": 0}, {"snippet_id": 85261, "code": "('scala-library', self._create_runtime_jardep) ] for spec_key, create_jardep_func in specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address", "label": 0}, {"snippet_id": 71943, "code": "% self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs", "label": 0}, {"snippet_id": 8083, "code": " short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float", "label": 0}, {"snippet_id": 10959, "code": "(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url): try: response=requests.get(url) except socket.error as e: msg=\"Could not open socket for '%s', error: %s\" %(url", "label": 0}, {"snippet_id": 58884, "code": ": remove_perm_from_user(self.tester, self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field': 'priority", "label": 0}, {"snippet_id": 72091, "code": "<seconds> Sets the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"\"\" permissions.checkPermissions(irc, source,['networks", "label": 0}, {"snippet_id": 91583, "code": " text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor, PyTest, PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest, python_setup, source_root_config): \"", "label": 1}, {"snippet_id": 31072, "code": " protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"", "label": 0}, {"snippet_id": 34064, "code": ".\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance", "label": 0}, {"snippet_id": 79890, "code": "/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument", "label": 0}, {"snippet_id": 79867, "code": "'Required named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test", "label": 0}, {"snippet_id": 65416, "code": ".Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA", "label": 0}, {"snippet_id": 63746, "code": ", '']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can", "label": 0}, {"snippet_id": 31263, "code": ".resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\":", "label": 0}, {"snippet_id": 70599, "code": "][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map", "label": 0}, {"snippet_id": 20454, "code": ", **kwargs) @classmethod def _create(cls, connect, addr, timeout=None): if timeout is None: timeout=cls.TIMEOUT sock=connect(addr, timeout) if cls.VERBOSE: print('connected') self=cls(sock, ownsock=True", "label": 0}, {"snippet_id": 49145, "code": "=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile", "label": 0}, {"snippet_id": 39572, "code": " ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo", "label": 0}, {"snippet_id": 5285, "code": " of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of", "label": 0}, {"snippet_id": 79160, "code": ".verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t", "label": 1}, {"snippet_id": 42920, "code": "] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name", "label": 0}, {"snippet_id": 16296, "code": "=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(),", "label": 1}, {"snippet_id": 22553, "code": " in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly valid name. When WAAgent", "label": 0}, {"snippet_id": 80978, "code": "=uploadsFolder \t\tself.size=size \t\tself.validExtensions=[] \t\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None \t\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself", "label": 0}, {"snippet_id": 24974, "code": " self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 86314, "code": "'stdout'), stderr=workunit.output('stderr')) return_code=p.wait() workunit.set_outcome(WorkUnit.FAILURE if return_code else WorkUnit.SUCCESS) if return_code: raise TaskError('javac exited with return code", "label": 0}, {"snippet_id": 76616, "code": " sig_sock.bind(sig_addr) domains=set() targets=dict() protected=set() forums=dict() def message(): msg=[] msg.append('[image-original-none-http://simg4.gelbooru.com/' +'/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98", "label": 0}, {"snippet_id": 60321, "code": "=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset(", "label": 1}, {"snippet_id": 25083, "code": ".data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is", "label": 1}, {"snippet_id": 7598, "code": " _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the", "label": 0}, {"snippet_id": 50722, "code": " for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute", "label": 0}, {"snippet_id": 38156, "code": " comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def", "label": 0}, {"snippet_id": 17689, "code": ".PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info ", "label": 0}, {"snippet_id": 38840, "code": " Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake", "label": 0}, {"snippet_id": 6065, "code": " \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an", "label": 1}, {"snippet_id": 18350, "code": ".append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen", "label": 0}, {"snippet_id": 36852, "code": ".updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self", "label": 0}, {"snippet_id": 1644, "code": " returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd=", "label": 0}, {"snippet_id": 23135, "code": " chk_err: Whether or not to check for errors raised by the eject command \"\"\" logger.warn(\"Eject is not supported on this platform\") def get_first_if(self): \"\"\"Return the interface name, and ip addr of the", "label": 0}, {"snippet_id": 48488, "code": ", str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise", "label": 0}, {"snippet_id": 52072, "code": " return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to", "label": 0}, {"snippet_id": 22064, "code": "=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self, playbook, options=None, verbosity=0): if options is None: self.options", "label": 0}, {"snippet_id": 54192, "code": ".snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False", "label": 0}, {"snippet_id": 71156, "code": "\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status", "label": 0}, {"snippet_id": 21744, "code": ".min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt.title('Classifier(Test set)') plt.xlabel(", "label": 0}, {"snippet_id": 37449, "code": " if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked", "label": 0}, {"snippet_id": 62136, "code": "'Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs", "label": 0}, {"snippet_id": 13995, "code": "( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler", "label": 0}, {"snippet_id": 10873, "code": " executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory, executable)): return True return False", "label": 1}, {"snippet_id": 57834, "code": ".values_list('pk', flat=True) if not reviewers: err_msg='Reviewer %s is not found' % self.new_value raise ObjectDoesNotExist(err_msg) self.get_update_targets().update(**{str(self.target_field): reviewers[0]}", "label": 0}, {"snippet_id": 78469, "code": " of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page", "label": 0}, {"snippet_id": 76896, "code": "(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net=sup.net.RequestPerformer() net.proxy=proxy if proxytype=='HTTP' or proxytype=='HTTPS': net.proxy_type=sup.proxytype.http elif proxytype", "label": 0}, {"snippet_id": 68870, "code": " AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 23243, "code": " 'network interfaces.'), expected) sock=buff.tostring() for i in range(0, struct_size * expected, struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else: break", "label": 0}, {"snippet_id": 92851, "code": ", os.path.realpath(not_zip.name)) with self.assertRaisesRegexp(zipfile.BadZipfile, r'{}'.format(not_zip.name)): next(open_zip(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness", "label": 0}, {"snippet_id": 61211, "code": "(args) return state/np.linalg.norm(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\"", "label": 0}, {"snippet_id": 14525, "code": "._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]", "label": 0}, {"snippet_id": 11324, "code": ".getLogger(\"monconfgenerator\") class MonitoringConfigGenerator(object): def __init__(self, url, debug_enabled=False, target_dir=None, skip_checks=False): self.skip_checks=skip_checks self.target_dir=target_dir", "label": 0}, {"snippet_id": 17893, "code": " BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync", "label": 0}, {"snippet_id": 87998, "code": " have to put the entire external classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published as \"fat jars\"(which appears to be the norm, since SBT doesn't support", "label": 0}, {"snippet_id": 92447, "code": " def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir) as path: self.assertEqual(tempdir, path) self.assertEqual(os.path.realpath(tempdir), os.getcwd()) self", "label": 0}, {"snippet_id": 77525, "code": ".path.isfile(self.usersfile): return with open(self.usersfile, 'rb') as f: users=pickle.loads(f.read()) try: for domain in users.keys(): uq=Queue() for ud in users[domain]: self.log.debug('Loaded user ", "label": 0}, {"snippet_id": 23242, "code": "} up ' 'network interfaces.'), expected) sock=buff.tostring() for i in range(0, struct_size * expected, struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else:", "label": 0}, {"snippet_id": 65188, "code": " strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine", "label": 0}, {"snippet_id": 84784, "code": ".address import Address from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem major_version_info", "label": 0}, {"snippet_id": 83216, "code": " a legacy URL to a job destination\"\"\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state", "label": 0}, {"snippet_id": 74710, "code": " value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"chunk_width\" in runtime_config.vcf_to_zarr: chunk_width_str=runtime_config.vcf_to_zarr[\"chunk_width\"] if", "label": 0}, {"snippet_id": 76180, "code": " wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug('Route %s,%s was not bound', i, m) return self.log.debug('Unbinding route %s,%s', i", "label": 0}, {"snippet_id": 93827, "code": " start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp", "label": 0}, {"snippet_id": 33368, "code": "=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata", "label": 0}, {"snippet_id": 51317, "code": " name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name", "label": 0}, {"snippet_id": 89230, "code": " build_graph.inject_address_closure(address) return build_graph def execute_process_synchronously(self, execute_process_request, name, labels=None): \"\"\"Executes a process(possibly remotely), and returns", "label": 1}, {"snippet_id": 66129, "code": "\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA", "label": 0}, {"snippet_id": 54081, "code": ", snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile,", "label": 0}, {"snippet_id": 92350, "code": ").wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**{}): self.assertNotIn('USER', os", "label": 1}, {"snippet_id": 45662, "code": ".file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target", "label": 0}, {"snippet_id": 55564, "code": " self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self", "label": 0}, {"snippet_id": 41484, "code": "(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input", "label": 0}, {"snippet_id": 64646, "code": " import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 90743, "code": " location in itertools.chain(self._distribution_environment.jvm_locations): try: dist=Distribution(home_path=location.home_path, bin_path=location.bin_path, minimum_version=minimum_version, maximum_version", "label": 0}, {"snippet_id": 75578, "code": "(self, reqid=None): if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return self.make_req_msg(d[0], d[1], d[2], fun, d[3]) def _parse_err", "label": 0}, {"snippet_id": 76590, "code": " import wzrpc from beon import regexp import pickle from logging import config from logconfig import logging_config config.dictConfig(logging_config) logger=logging.getLogger() ctx=zmq.Context() sig_addr", "label": 0}, {"snippet_id": 86871, "code": " get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super(BaseZincCompile, cls).register_options(register) register('--whitelisted-args', advanced", "label": 0}, {"snippet_id": 68442, "code": " status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE", "label": 0}, {"snippet_id": 124, "code": " wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n'", "label": 0}, {"snippet_id": 86501, "code": " from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants.base.build_environment import get_buildroot from pants", "label": 0}, {"snippet_id": 88244, "code": " defaultdict from contextlib import contextmanager from twitter.common.collections import OrderedSet from pants.base.build_environment import get_buildroot, get_scm from pants.base.worker_pool import SubprocPool", "label": 0}, {"snippet_id": 70845, "code": " id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER)", "label": 0}, {"snippet_id": 19824, "code": " self._connecttimeout=connecttimeout self._adapter=None self._session=None self._breakpoints=breakpoints @property def adapter(self): return self._adapter @property def session(self): return self._session", "label": 0}, {"snippet_id": 44830, "code": " def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], ", "label": 0}, {"snippet_id": 89113, "code": " from_predicate to targets they depend on that satisfy the on_predicate. :API: public \"\"\" core=set(self.targets(on_predicate)) dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in", "label": 0}, {"snippet_id": 66875, "code": " handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e:", "label": 0}, {"snippet_id": 4782, "code": " taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword", "label": 0}, {"snippet_id": 56973, "code": ", 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid", "label": 0}, {"snippet_id": 88125, "code": "() if plugin_info.tag !='plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return plugin_info.find('name').text if os.path.isdir", "label": 0}, {"snippet_id": 44961, "code": " if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule", "label": 0}, {"snippet_id": 2549, "code": " (comp['name'], group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self", "label": 0}, {"snippet_id": 85304, "code": " def injectables_spec_mapping(self): maybe_suffix='' if self.version=='custom' else '-synthetic' return{ 'scalac':['//:scalac{}'.format(maybe_suffix)], 'scala-library':['//:scala-library{}'.format(maybe_suffix", "label": 0}, {"snippet_id": 62877, "code": "'AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items", "label": 0}, {"snippet_id": 36620, "code": "=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format", "label": 0}, {"snippet_id": 87986, "code": " dependencies, as we can't know which external classpath elements are required, and we'd have to put the entire external classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins", "label": 0}, {"snippet_id": 40774, "code": ".format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern", "label": 0}, {"snippet_id": 76077, "code": "{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warn", "label": 0}, {"snippet_id": 39510, "code": " rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\"", "label": 0}, {"snippet_id": 91492, "code": " InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest from pants.backend.python.subsystems.python_setup import PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge", "label": 0}, {"snippet_id": 63592, "code": "=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed", "label": 0}, {"snippet_id": 17659, "code": ": if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message'])", "label": 0}, {"snippet_id": 17727, "code": " CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes", "label": 0}, {"snippet_id": 55957, "code": " decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs)", "label": 0}, {"snippet_id": 93820, "code": "\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window", "label": 0}, {"snippet_id": 3649, "code": " return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(", "label": 0}, {"snippet_id": 6584, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a", "label": 1}, {"snippet_id": 44682, "code": ".included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return", "label": 0}, {"snippet_id": 84285, "code": " configs_directory=remote_job_config['configs_directory'] working_directory=remote_job_config['working_directory'] outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path", "label": 0}, {"snippet_id": 92620, "code": ".assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self.assertTrue(os.path.isdir(path), 'Temporary dir should be a dir and not a file.') self.assertFalse(os.path.exists", "label": 0}, {"snippet_id": 43566, "code": " j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return", "label": 0}, {"snippet_id": 69409, "code": "'.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params", "label": 0}, {"snippet_id": 81900, "code": ",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help", "label": 0}, {"snippet_id": 25194, "code": ", DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None],", "label": 0}, {"snippet_id": 75821, "code": ", self.sleep_ticker, self.wz timeout=timeout if timeout else self.wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart", "label": 1}, {"snippet_id": 82758, "code": ".manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter", "label": 0}, {"snippet_id": 2321, "code": "=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class=RegisteredServicesSerializer", "label": 0}, {"snippet_id": 4312, "code": " spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file", "label": 1}, {"snippet_id": 57605, "code": " exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets().update(**{str(self", "label": 0}, {"snippet_id": 32565, "code": " IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self", "label": 0}, {"snippet_id": 5974, "code": " urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\"", "label": 1}, {"snippet_id": 31144, "code": ".rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists", "label": 0}, {"snippet_id": 68501, "code": " c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(", "label": 0}, {"snippet_id": 3948, "code": " \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required", "label": 0}, {"snippet_id": 788, "code": "'getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in", "label": 0}, {"snippet_id": 67518, "code": ".RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import *", "label": 0}, {"snippet_id": 9588, "code": " formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code", "label": 0}, {"snippet_id": 78864, "code": " \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject", "label": 0}, {"snippet_id": 22379, "code": " within roughly 50 minutes(100 * 30 seconds) \"\"\" for retries in range(1, 100): logger.info(\"Checking to see if mcpd is up\") rc=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null |", "label": 0}, {"snippet_id": 41981, "code": "(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format(", "label": 0}, {"snippet_id": 61911, "code": ")\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions", "label": 0}, {"snippet_id": 77965, "code": " targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending %s to targets", "label": 0}, {"snippet_id": 68835, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout", "label": 0}, {"snippet_id": 69778, "code": "%s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else", "label": 1}, {"snippet_id": 93138, "code": " setupParser import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call", "label": 0}, {"snippet_id": 24542, "code": " if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1", "label": 0}]