[{"snippet_id": 26009, "code": "'rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status", "label": 0}, {"snippet_id": 2082, "code": ") elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep'", "label": 0}, {"snippet_id": 14990, "code": "( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest", "label": 0}, {"snippet_id": 72809, "code": " import functools import numpy as np import zarr import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates", "label": 1}, {"snippet_id": 53799, "code": " def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name)", "label": 0}, {"snippet_id": 41179, "code": "(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self", "label": 0}, {"snippet_id": 27714, "code": "'battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif", "label": 0}, {"snippet_id": 50413, "code": " return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo", "label": 0}, {"snippet_id": 42190, "code": "): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self)", "label": 0}, {"snippet_id": 30539, "code": " import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile,", "label": 1}, {"snippet_id": 85390, "code": " import memoized_method, memoized_property class Zinc(object): \"\"\"Configuration for Pants' zinc wrapper tool.\"\"\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main' ZINC_EXTRACT_MAIN='org.pantsbuild.zinc", "label": 0}, {"snippet_id": 65254, "code": "): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler", "label": 0}, {"snippet_id": 63441, "code": " return[ str( o) for o in output_paths] def get_input_files(self, job_wrapper): input_paths=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper)", "label": 0}, {"snippet_id": 13103, "code": "\"]=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization", "label": 0}, {"snippet_id": 42553, "code": "=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in", "label": 0}, {"snippet_id": 52528, "code": " in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else:", "label": 1}, {"snippet_id": 59155, "code": " Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .", "label": 0}, {"snippet_id": 27409, "code": "\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self", "label": 0}, {"snippet_id": 67379, "code": "(nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc", "label": 0}, {"snippet_id": 29690, "code": " WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self", "label": 0}, {"snippet_id": 69052, "code": " RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname", "label": 0}, {"snippet_id": 65139, "code": " print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s", "label": 0}, {"snippet_id": 50537, "code": ".priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate", "label": 0}, {"snippet_id": 20027, "code": " is not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start", "label": 0}, {"snippet_id": 73157, "code": "(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz, local_file", "label": 0}, {"snippet_id": 58401, "code": ".tester.username]), target_status_code=HTTPStatus.OK) class TestCommentCaseRuns(BaseCaseRun): \"\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls)", "label": 0}, {"snippet_id": 74545, "code": " runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config", "label": 0}, {"snippet_id": 80877, "code": " +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor", "label": 0}, {"snippet_id": 62653, "code": "=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as", "label": 0}, {"snippet_id": 76608, "code": ".getLogger() ctx=zmq.Context() sig_addr='ipc://signals' sig_sock=ctx.socket(zmq.PUB) sig_sock.bind(sig_addr) domains=set() targets=dict() protected=set() forums=dict() def message(): msg=[] msg.append(", "label": 0}, {"snippet_id": 59838, "code": " NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator", "label": 0}, {"snippet_id": 47363, "code": " for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output", "label": 0}, {"snippet_id": 73301, "code": "=str(path) filename_str=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib", "label": 0}, {"snippet_id": 26305, "code": " vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass,", "label": 0}, {"snippet_id": 55203, "code": ".path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies", "label": 0}, {"snippet_id": 77526, "code": ".isfile(self.usersfile): return with open(self.usersfile, 'rb') as f: users=pickle.loads(f.read()) try: for domain in users.keys(): uq=Queue() for ud in users[domain]: self.log.debug('Loaded user %s:%s'", "label": 0}, {"snippet_id": 39008, "code": "() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary", "label": 0}, {"snippet_id": 45312, "code": " if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source", "label": 0}, {"snippet_id": 20735, "code": "(self, handler, **kwargs): if self.closed: raise RuntimeError('session closed') self._add_handler(handler, **kwargs) @contextlib.contextmanager def wait_for_event(self, event, **kwargs): if self.closed", "label": 0}, {"snippet_id": 76522, "code": "(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx, sig_addr, *args, **kvargs): self.ctx=ctx self.sig_addr=sig_addr threading.Thread.start(self, *args", "label": 0}, {"snippet_id": 25686, "code": ".type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 72086, "code": " source, args): \"\"\"<network> <seconds> Sets the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"\"\" permissions.checkPermissions", "label": 0}, {"snippet_id": 709, "code": "[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall", "label": 0}, {"snippet_id": 38388, "code": ".contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def", "label": 0}, {"snippet_id": 62861, "code": " expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg)", "label": 0}, {"snippet_id": 38873, "code": " removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows", "label": 0}, {"snippet_id": 21348, "code": ".REMAINDER, help='Arguments to pass to `mpv`.') args=parser.parse_args() subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ", "label": 1}, {"snippet_id": 74197, "code": ": ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config", "label": 0}, {"snippet_id": 41502, "code": "=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in", "label": 0}, {"snippet_id": 85887, "code": ".backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants.base.exceptions import TaskError from pants.base.workunit import WorkUnit,", "label": 0}, {"snippet_id": 14616, "code": " OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self", "label": 0}, {"snippet_id": 64123, "code": "]=remote_galaxy_home outputs_directory=remote_job_config['outputs_directory'] configs_directory=remote_job_config['configs_directory'] working_directory=remote_job_config['working_directory'] outputs=[Bunch", "label": 0}, {"snippet_id": 49399, "code": " cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete", "label": 0}, {"snippet_id": 64934, "code": " filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions", "label": 0}, {"snippet_id": 54319, "code": " rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__", "label": 0}, {"snippet_id": 73416, "code": " input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir) create_directory_tree(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(\"**/*.vcf\"", "label": 0}, {"snippet_id": 7918, "code": ": i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches", "label": 0}, {"snippet_id": 635, "code": "(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print", "label": 0}, {"snippet_id": 68834, "code": "\"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\"", "label": 0}, {"snippet_id": 12987, "code": ".environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"", "label": 0}, {"snippet_id": 2416, "code": " def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile", "label": 0}, {"snippet_id": 56222, "code": " tcms.signals import POST_UPDATE_SIGNAL from tcms.management.models import Component, Build, Version from tcms.management.models import Priority from tcms.management.models import Tag from tcms.management", "label": 0}, {"snippet_id": 53353, "code": "=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion", "label": 1}, {"snippet_id": 84918, "code": "[version].full_version ) classpath.append(jline_dep) cls.register_jvm_tool(register, cls._key_for_tool_version('scala-repl', version), classpath=classpath) def register_style_tool(version): cls.register_jvm_tool", "label": 1}, {"snippet_id": 6551, "code": " process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url", "label": 1}, {"snippet_id": 83397, "code": ", remote_job_config) log.info(\"lwr job submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception:", "label": 0}, {"snippet_id": 31535, "code": ".docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set()", "label": 0}, {"snippet_id": 95925, "code": " converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion ", "label": 0}, {"snippet_id": 75663, "code": ").__init__(*pargs, **pkvargs) self.name=name if name else type(self).__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr", "label": 0}, {"snippet_id": 64354, "code": " unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[ parameter_value] if parameter_value in unstructured_path_rewrites.itervalues", "label": 0}, {"snippet_id": 56175, "code": " import http from django.db.models import Q, Count from django.contrib.auth.models import User from django.core import serializers from django.core.exceptions import ObjectDoesNotExist from django.apps", "label": 0}, {"snippet_id": 53460, "code": "=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark", "label": 0}, {"snippet_id": 49741, "code": " workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}:", "label": 0}, {"snippet_id": 86899, "code": ", '-msg-filter': True, }, help='A dict of option regexes that make up pants\\' supported API for zinc. ' 'Options not listed here are subject to change/removal. The value of the dict ' 'indicates that an", "label": 0}, {"snippet_id": 94204, "code": " self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default", "label": 0}, {"snippet_id": 1270, "code": ".communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess", "label": 0}, {"snippet_id": 29957, "code": " filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: *", "label": 0}, {"snippet_id": 85677, "code": "( PathGlobsAndRoot( PathGlobs( tuple( fast_relpath(a, buildroot) for a in(self.zinc, self.compiler_bridge, self.compiler_interface) ) ), buildroot, ), ))[0] @memoized_property def rebase_map_args(self)", "label": 1}, {"snippet_id": 7737, "code": " matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the", "label": 0}, {"snippet_id": 13571, "code": ".4):\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 0)\r \r def updateEyes():\r while isRunning:\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1", "label": 0}, {"snippet_id": 41738, "code": " f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination", "label": 0}, {"snippet_id": 81205, "code": " code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing", "label": 0}, {"snippet_id": 86886, "code": "-whitelisted-args', advanced=True, type=dict, default={ '-S.*': False, '-C.*': False, '-file-filter': True, '-msg-filter': True, }, help='A dict of option regexes that make up pants\\' supported API for", "label": 0}, {"snippet_id": 48100, "code": " of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property", "label": 0}, {"snippet_id": 45368, "code": " follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod", "label": 0}, {"snippet_id": 54516, "code": " controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self", "label": 0}, {"snippet_id": 58607, "code": "(BasePlanCase): \"\"\"Test case for update\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateObject, cls).setUpTestData() cls.permission='testplans.change_testplan' cls.update_url=reverse('ajax-update'", "label": 0}, {"snippet_id": 64218, "code": "): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config", "label": 0}, {"snippet_id": 76650, "code": "))) return '\\n'.join(msg) def sbjfun(): return sup.randstr(1, 30) import argparse parser=argparse.ArgumentParser(add_help=True) parser.add_argument('--only-cache', '-C', action='store_true', help=\"Disables", "label": 0}, {"snippet_id": 30060, "code": " names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os", "label": 0}, {"snippet_id": 82464, "code": " known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided", "label": 0}, {"snippet_id": 64546, "code": " /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new", "label": 0}, {"snippet_id": 47400, "code": " files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove", "label": 0}, {"snippet_id": 42711, "code": " @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive", "label": 0}, {"snippet_id": 48998, "code": "\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools", "label": 0}, {"snippet_id": 58968, "code": ", TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view method\"\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData", "label": 0}, {"snippet_id": 75235, "code": " set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method)]=fun def del_req_handler(self, interface, method): del self.req_handlers[(interface, method)] def del_response_handler(self, reqid", "label": 0}, {"snippet_id": 17721, "code": ".format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable", "label": 0}, {"snippet_id": 9081, "code": " else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags", "label": 0}, {"snippet_id": 70772, "code": "[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target", "label": 0}, {"snippet_id": 93377, "code": ", comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes", "label": 0}, {"snippet_id": 88561, "code": " play for the run as returned by self.targets(). Note that for a command line invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API", "label": 0}, {"snippet_id": 72569, "code": ", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\", metavar=\"RUN_LABEL\", help=\"Label for the benchmark run", "label": 1}, {"snippet_id": 73631, "code": " configparser import ConfigParser from shutil import copyfile import os.path from pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str", "label": 0}, {"snippet_id": 69674, "code": " print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on", "label": 0}, {"snippet_id": 21148, "code": "(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message='Timeout waiting", "label": 0}, {"snippet_id": 91600, "code": " target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download/v1.6.6/pex' digest=Digest('61bb79384db0da8c844678440bd368bcbfac17bbdb865721ad3f9cb0ab29b629', 1826945) pex_snapshot=yield Get(Snapshot,", "label": 0}, {"snippet_id": 9782, "code": "=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output", "label": 0}, {"snippet_id": 9577, "code": " find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">", "label": 0}, {"snippet_id": 62728, "code": "\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables", "label": 0}, {"snippet_id": 18943, "code": ".expanduser(str(source))): with open(os.path.expanduser(str(source)), 'r') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts", "label": 0}, {"snippet_id": 35389, "code": " Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join", "label": 0}, {"snippet_id": 24973, "code": "] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low", "label": 0}, {"snippet_id": 81432, "code": "\t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e in extList: \t\t\t\ttmpExtList.append((e,getMime(extensions,e))) \t\telse: ", "label": 0}, {"snippet_id": 40864, "code": " else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list()", "label": 0}, {"snippet_id": 475, "code": " to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '", "label": 0}, {"snippet_id": 35362, "code": "(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern", "label": 0}, {"snippet_id": 82367, "code": "\targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower", "label": 0}, {"snippet_id": 45682, "code": ": return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return", "label": 0}, {"snippet_id": 66306, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag", "label": 0}, {"snippet_id": 92548, "code": ", 'Temporary file should not exist outside of the context.') def test_temporary_file_without_cleanup(self): with temporary_file(cleanup=False) as fp: self.assertTrue(os.path.exists(fp.name), 'Temporary", "label": 0}, {"snippet_id": 44698, "code": "{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd", "label": 0}, {"snippet_id": 39793, "code": ".threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow", "label": 0}, {"snippet_id": 42761, "code": ".dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names", "label": 0}, {"snippet_id": 49456, "code": " greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map", "label": 0}, {"snippet_id": 34809, "code": ", fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self", "label": 1}, {"snippet_id": 31778, "code": " branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output,", "label": 0}, {"snippet_id": 71650, "code": " status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print", "label": 1}, {"snippet_id": 67385, "code": " fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print ", "label": 1}, {"snippet_id": 92746, "code": " 0) clock.sleep(0.1) self.assertGreater(t.elapsed, 0.1) clock.sleep(0.1) self.assertTrue(t.finish is None) self.assertGreater(t.elapsed, 0.2) self.assertLess(t.finish, clock.time()) def test_open_zipDefault", "label": 0}, {"snippet_id": 52187, "code": "\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake", "label": 1}, {"snippet_id": 26663, "code": "\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self", "label": 0}, {"snippet_id": 32017, "code": "=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 63270, "code": " job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state", "label": 0}, {"snippet_id": 41510, "code": "[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self", "label": 0}, {"snippet_id": 16154, "code": " syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData", "label": 0}, {"snippet_id": 36053, "code": " min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict)", "label": 0}, {"snippet_id": 47946, "code": "=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=", "label": 1}, {"snippet_id": 69289, "code": " print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError", "label": 1}, {"snippet_id": 72362, "code": " %s', irc.name, netname) remoteirc.reply=old_reply remoteirc.pseudoclient.account='' @utils.add_cmd def reloadproto(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without", "label": 1}, {"snippet_id": 46129, "code": " second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)", "label": 0}, {"snippet_id": 47725, "code": " Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException,", "label": 0}, {"snippet_id": 70220, "code": "%(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target", "label": 0}, {"snippet_id": 56961, "code": " (datetime.datetime(1986, 6, 24, 12, 30, 59), None) 3. get_value_by_type('5', 'int') ('5', None) 4. get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None,", "label": 0}, {"snippet_id": 60395, "code": ".run('fock', cutoff_dim=self.cutoff) reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name=='X': ex, var=self.state.quad_expectation(reg, 0", "label": 0}, {"snippet_id": 72553, "code": " data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes.", "label": 0}, {"snippet_id": 64229, "code": "=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config.working_directory()", "label": 0}, {"snippet_id": 78317, "code": "(t, msg)) except exc.Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t) try: self.targets", "label": 1}, {"snippet_id": 59569, "code": "\"Shutdown. \"\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive", "label": 0}, {"snippet_id": 63847, "code": "() def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck in the queued/running state when Galaxy started\"\"\" job_state=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id(", "label": 0}, {"snippet_id": 66632, "code": ":(\\w+):\", s) if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug", "label": 0}, {"snippet_id": 53442, "code": " if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch,", "label": 0}, {"snippet_id": 30999, "code": " existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested", "label": 0}, {"snippet_id": 20142, "code": " if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None self._adapter=DebugAdapter.start(argv, port=self._port) return self._adapter def host_local_debugger", "label": 0}, {"snippet_id": 13032, "code": ".environ[\"BOT_PASSWORD\"]) r=requests.get(url, headers=headers, auth=auth) for repo in r.json(): if repo[\"description\"]: if data[\"target_repo_fullname\"] in repo[\"description\"]: FORKED=True r=requests.delete", "label": 0}, {"snippet_id": 36845, "code": ".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 28723, "code": "='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state", "label": 0}, {"snippet_id": 90222, "code": " executable. :returns: The java distribution location. \"\"\" return cls(home_path=None, bin_path=bin_path) @abstractproperty def jvm_locations(self): \"\"\"Return the jvm locations discovered in this environment.", "label": 0}, {"snippet_id": 83830, "code": ", job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state", "label": 0}, {"snippet_id": 77832, "code": "=ProcessContext(self.p.name, self.p.ctx, self.c.router_addr, noproxy_rp) self.spawnqueue=Queue() self.load_bumplimit_set() self.load_targets() self.load_users() self.spawn_wipethreads() if self.c.ecount", "label": 0}, {"snippet_id": 86369, "code": "(args))) return ret def _execute_hermetic_compile(self, cmd, ctx): input_snapshot=ctx.target.sources_snapshot(scheduler=self.context._scheduler) output_files=tuple( os.path.relpath(f.path.replace('.java", "label": 0}, {"snippet_id": 64790, "code": " RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname", "label": 0}, {"snippet_id": 81367, "code": "(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future", "label": 0}, {"snippet_id": 49467, "code": "\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule", "label": 0}, {"snippet_id": 22785, "code": " on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param username: The username whose password to change :param password: The unencrypted", "label": 0}, {"snippet_id": 42682, "code": " lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property", "label": 0}, {"snippet_id": 76879, "code": " interrupt_handler(signal, frame): pass def terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler) signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype", "label": 0}, {"snippet_id": 1512, "code": "\"version_info\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data,", "label": 0}, {"snippet_id": 26195, "code": "'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', ", "label": 0}, {"snippet_id": 17003, "code": "( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData", "label": 0}, {"snippet_id": 21100, "code": ")): time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append", "label": 0}, {"snippet_id": 96003, "code": ".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format", "label": 0}, {"snippet_id": 65892, "code": " % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len", "label": 0}, {"snippet_id": 84890, "code": " cls.register_jvm_tool(register, cls._key_for_tool_version('scalac', version), classpath=[cls._create_compiler_jardep(version)]) def register_scala_repl_tool(version, with_jline=False): classpath=[cls._create_compiler_jardep", "label": 1}, {"snippet_id": 42380, "code": ".protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set", "label": 0}, {"snippet_id": 33517, "code": "\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess(", "label": 0}, {"snippet_id": 82770, "code": " --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction", "label": 0}, {"snippet_id": 85754, "code": ".options_scope return instance.tool_classpath_from_products(self._products, toolname, scope=scope) classpaths=(cp(java_options_src, 'javac-plugin-dep') + cp(scala_options_src, 'scalac-plugin-dep')) return", "label": 0}, {"snippet_id": 43506, "code": " > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def", "label": 0}, {"snippet_id": 73097, "code": "}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory", "label": 0}, {"snippet_id": 87369, "code": " absolute_classpath=(ctx.classes_dir,) +tuple(ce.path for ce in dependency_classpath) if self.get_options().capture_classpath: self._record_compile_classpath(absolute_classpath, ctx.target, ctx.classes_dir", "label": 0}, {"snippet_id": 36501, "code": " previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning:", "label": 0}, {"snippet_id": 30383, "code": " InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile", "label": 0}, {"snippet_id": 76954, "code": "): return files=[] for sd in os.walk(c.av_dir): files.extend(sd[2]) av=os.path.join(sd[0], random.choice(files)) self.log.info('Uploading %s as new avatar', av) self.site.uploadavatar('0', av) ud[0]['avatar", "label": 0}, {"snippet_id": 56966, "code": ". get_value_by_type('5', 'int') ('5', None) 4. get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, ", "label": 0}, {"snippet_id": 10662, "code": " IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text", "label": 1}, {"snippet_id": 84922, "code": ".register_jvm_tool(register, cls._key_for_tool_version('scala-repl', version), classpath=classpath) def register_style_tool(version): cls.register_jvm_tool(register, cls._key_for_tool_version('scalastyle", "label": 1}, {"snippet_id": 65594, "code": ".indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None: view=\"fs\" else: view=view.lower() if view", "label": 1}, {"snippet_id": 13279, "code": " auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not create new branch in the fork\" def autopep8ify(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ", "label": 0}, {"snippet_id": 25775, "code": "=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state", "label": 0}, {"snippet_id": 81488, "code": " \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads", "label": 0}, {"snippet_id": 59526, "code": ", wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires", "label": 0}, {"snippet_id": 71189, "code": ".status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA", "label": 0}, {"snippet_id": 10722, "code": " not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words", "label": 1}, {"snippet_id": 60845, "code": ": ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ' +self.author +'\\n' def __enter__(self): if Device._current_context is None: Device._current_context", "label": 0}, {"snippet_id": 49465, "code": ".global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return", "label": 0}, {"snippet_id": 8863, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"", "label": 1}, {"snippet_id": 54410, "code": "=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools", "label": 0}, {"snippet_id": 78505, "code": "'] or t in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in forum %s:%s', lt, user, forum) else: self.log.debug('Found no new", "label": 1}, {"snippet_id": 42844, "code": " is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 51767, "code": " the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict", "label": 0}, {"snippet_id": 24341, "code": "=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not", "label": 1}, {"snippet_id": 38089, "code": "(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self", "label": 0}, {"snippet_id": 9700, "code": " resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires", "label": 0}, {"snippet_id": 88583, "code": "\"\"\" return self._target_roots @property def console_outstream(self): \"\"\"Returns the output stream to write console messages to. :API: public \"\"\" return self._console_outstream @property def scm(self): ", "label": 0}, {"snippet_id": 68713, "code": " jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if", "label": 0}, {"snippet_id": 43505, "code": " comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list(", "label": 0}, {"snippet_id": 50740, "code": " \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]),", "label": 0}, {"snippet_id": 89771, "code": " self._home=home return self._home @property def real_home(self): \"\"\"Real path to the distribution java.home(resolving links).\"\"\" return os.path.realpath(self.home) @property def java(self): \"\"\"Returns", "label": 1}, {"snippet_id": 71041, "code": ".get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime", "label": 0}, {"snippet_id": 44509, "code": ", local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing", "label": 0}, {"snippet_id": 32105, "code": " raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output", "label": 0}, {"snippet_id": 52823, "code": " job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from", "label": 0}, {"snippet_id": 534, "code": "\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first(", "label": 0}, {"snippet_id": 34293, "code": ": def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log", "label": 0}, {"snippet_id": 42839, "code": ".rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not", "label": 0}, {"snippet_id": 29214, "code": " self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def", "label": 1}, {"snippet_id": 64476, "code": " execute(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt", "label": 0}, {"snippet_id": 13, "code": " import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response import Response from rest_framework import viewsets from", "label": 0}, {"snippet_id": 61732, "code": "-qubit operator into a full system operator. Args: U(array): 4x4 matrix wires(Sequence[int]): two target subsystems(order matters!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError", "label": 0}, {"snippet_id": 6439, "code": " output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False,", "label": 0}, {"snippet_id": 35810, "code": " pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f:", "label": 0}, {"snippet_id": 26020, "code": " self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] ", "label": 0}, {"snippet_id": 54054, "code": ", end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve", "label": 0}, {"snippet_id": 13774, "code": "[]: _safe_locals[k]=eval(k) for k, v in np.__dict__.iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop", "label": 0}, {"snippet_id": 12630, "code": ")) text2=''.join(BeautifulSoup(markdown(last_comment)).findAll(text=True)) if text1==text2.replace(\"submitting\", \"updating\"): PERMITTED_TO_COMMENT=False \"\"\" for old_comment in reversed(comments): if '@pep8speaks", "label": 0}, {"snippet_id": 31506, "code": " import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule ", "label": 0}, {"snippet_id": 85191, "code": " bootstrapping jars. If a custom ' 'scala version is not specified, then the version specified in ' '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would use the suffix version \"2.10", "label": 0}, {"snippet_id": 37210, "code": " branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): ", "label": 0}, {"snippet_id": 47070, "code": ".format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable", "label": 0}, {"snippet_id": 13554, "code": "()\r \r if( audio.mouthValue==1):\r io.set( MOUTH_OPEN, 1)\r io.set( MOUTH_CLOSE, 0)\r else:\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 1)\r else:\r if( time.time() -lastMouthEventTime > 0.4):\r io.set( MOUTH_OPEN", "label": 0}, {"snippet_id": 19126, "code": " raw_request is not None: request=normalize_request(raw_request) response=None if raw_response is not None: response=normalize_response(raw_response, request=request) if response is not None: validate_response", "label": 0}, {"snippet_id": 8334, "code": " text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list", "label": 1}, {"snippet_id": 4728, "code": "[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags", "label": 0}, {"snippet_id": 87649, "code": " DirectoryDigest, so won't be present for hermetic \" \"execution\".format(dep) ) if scala_path: snapshots.append( self.context._scheduler.capture_snapshots((PathGlobsAndRoot( PathGlobs(scala_path), get_buildroot(), ),)", "label": 0}, {"snippet_id": 14137, "code": " json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter", "label": 0}, {"snippet_id": 56662, "code": "=_TagCounter('num_runs', test_run_tags) for tag in all_tags: tag.num_plans=plan_counter.calculate_tag_count(tag) tag.num_cases=case_counter.calculate_tag_count(tag) tag.num_runs=run_counter.calculate_tag_count", "label": 0}, {"snippet_id": 57650, "code": " def _update_case_status(self): try: new_status=TestCaseStatus.objects.get(pk=self.new_value) except TestCaseStatus.DoesNotExist: raise ObjectDoesNotExist('The status you choose does not exist.') update_object", "label": 0}, {"snippet_id": 52685, "code": " None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists:", "label": 0}, {"snippet_id": 60125, "code": "[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value", "label": 0}, {"snippet_id": 31166, "code": " if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards", "label": 0}, {"snippet_id": 59988, "code": "([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__", "label": 0}, {"snippet_id": 38951, "code": ".postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps", "label": 0}, {"snippet_id": 52844, "code": " from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads", "label": 0}, {"snippet_id": 60720, "code": "\" import abc import logging logging.getLogger() class MethodFactory(type): \"\"\"Metaclass that allows derived classes to dynamically instantiate new objects based on undefined methods. The dynamic methods", "label": 0}, {"snippet_id": 72238, "code": " irc.error('No such network \"%s\"(case sensitive).' % netname) return if args.service not in world.services: irc.error('Unknown service %r.' % args.service) return remoteirc.called_in=remoteirc.called_by", "label": 0}, {"snippet_id": 46595, "code": " plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \"", "label": 0}, {"snippet_id": 69276, "code": " RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR", "label": 1}, {"snippet_id": 90859, "code": "-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely locations on the file system such as `/usr/lib/jvm` on Linux machines. :API: public \"\"\" class Error(Distribution.Error): \"\"\"Error locating", "label": 0}, {"snippet_id": 46243, "code": " glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern)", "label": 0}, {"snippet_id": 55609, "code": " dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def", "label": 0}, {"snippet_id": 11717, "code": " def update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: query=r\"INSERT INTO Users(repository, created_at) VALUES('{}',", "label": 0}, {"snippet_id": 92302, "code": "(binary_mode=False) as new_output: subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\" in os.environ)'], stdout=new_output).wait() new_output.seek(0) self.assertEqual('False\\n', new_output.read())", "label": 0}, {"snippet_id": 28550, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise':", "label": 0}, {"snippet_id": 78877, "code": "\t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code <", "label": 0}, {"snippet_id": 77094, "code": ".usersfile='wm_users.pickle' self.targetsfile='wm_targets.pickle' self.bumplimitfile='wm_bumplimit.pickle' def init_th_sock(self): self.log.info( 'Initializing intraprocess signal socket %s', self.th_sa", "label": 0}, {"snippet_id": 69149, "code": " from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search", "label": 1}, {"snippet_id": 3249, "code": ".comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2", "label": 0}, {"snippet_id": 16030, "code": " include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column,", "label": 0}, {"snippet_id": 83803, "code": "): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper", "label": 0}, {"snippet_id": 52108, "code": "\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict", "label": 0}, {"snippet_id": 2308, "code": ") def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet", "label": 0}, {"snippet_id": 81574, "code": "\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload", "label": 1}, {"snippet_id": 52784, "code": " omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark", "label": 0}, {"snippet_id": 66079, "code": " return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state=", "label": 0}, {"snippet_id": 20108, "code": " return self._session=None try: session.close() except ClosedError: pass class DebugClient(_LifecycleClient): \"\"\"A high-level abstraction of a debug client(i.e. editor).\"\"\" class EasyDebugClient(DebugClient", "label": 0}, {"snippet_id": 58869, "code": "(TestUpdateCasePriority, cls).setUpTestData() cls.permission='testcases.change_testcase' cls.case_update_url=reverse('ajax-update_cases_default_tester') def setUp(self): user_should_have_perm(self.tester,", "label": 0}, {"snippet_id": 70905, "code": " t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state", "label": 0}, {"snippet_id": 81909, "code": " uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type", "label": 0}, {"snippet_id": 6739, "code": " string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache", "label": 0}, {"snippet_id": 6411, "code": ".bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils", "label": 1}, {"snippet_id": 17137, "code": " utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils", "label": 0}, {"snippet_id": 7351, "code": "(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw], encode_for_xml", "label": 0}, {"snippet_id": 25003, "code": " elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data[", "label": 0}, {"snippet_id": 51321, "code": " value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return", "label": 0}, {"snippet_id": 20674, "code": "=self._seq self._seq +=1 return{ 'type': 'request', 'seq': seq, 'command': command, 'arguments': args, } def send_request(self, command, **args): if self.closed: raise RuntimeError('session closed') wait", "label": 0}, {"snippet_id": 91494, "code": " pants.backend.python.subsystems.pytest import PyTest from pants.backend.python.subsystems.python_setup import PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip", "label": 0}, {"snippet_id": 25980, "code": "'rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self", "label": 0}, {"snippet_id": 28137, "code": " import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=", "label": 1}, {"snippet_id": 87787, "code": ".'.format(path)) if is_outside(path, self.get_options().pants_workdir) and(not allow_dist or is_outside(path, dist.home)): raise TaskError('Classpath entries provided to zinc should be in working directory", "label": 0}, {"snippet_id": 43924, "code": "(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger", "label": 0}, {"snippet_id": 84396, "code": " remote_job_config, self.local_path_config.working_directory()) self._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config", "label": 0}, {"snippet_id": 88177, "code": "')) as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile): \"\"\"Compile Scala and Java code to classfiles", "label": 0}, {"snippet_id": 85735, "code": "\"Any additional global compiletime classpath entries for compiler plugins.\"\"\" java_options_src=Java.global_instance() scala_options_src=ScalaPlatform.global_instance() def cp(instance, toolname): scope", "label": 0}, {"snippet_id": 68099, "code": ".target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname():", "label": 1}, {"snippet_id": 72895, "code": " create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username,", "label": 0}, {"snippet_id": 63911, "code": " def shutdown( self): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client", "label": 0}, {"snippet_id": 34677, "code": " def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError", "label": 0}, {"snippet_id": 83492, "code": ".__prepare_input_files_locally(job_wrapper) remote_metadata=LwrJobRunner.__remote_metadata( client) remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution", "label": 0}, {"snippet_id": 741, "code": ".Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall(", "label": 0}, {"snippet_id": 88161, "code": "(classpath_element, plugin_info_file) except IOError as e: if e.errno !=errno.ENOENT: raise else: with open_zip(classpath_element, 'r') as jarfile: try: with closing(jarfile.open(_SCALAC_PLUGIN_INFO_FILE, 'r'))", "label": 0}, {"snippet_id": 93453, "code": " res, unres) dep_string=\"\" for node in res: if node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException", "label": 0}, {"snippet_id": 91218, "code": ".build_local_python_distributions import \\ BuildLocalPythonDistributions from pants.backend.python.tasks.gather_sources import GatherSources from pants.backend.python.tasks.isort_prep import IsortPrep from pants.backend", "label": 0}, {"snippet_id": 79533, "code": "\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]", "label": 0}, {"snippet_id": 35727, "code": ": yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index", "label": 0}, {"snippet_id": 14209, "code": " ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd", "label": 0}, {"snippet_id": 9671, "code": ", encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags", "label": 0}, {"snippet_id": 6143, "code": " log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len", "label": 1}, {"snippet_id": 12288, "code": "][filename].remove(error) for error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url", "label": 0}, {"snippet_id": 82404, "code": "\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args", "label": 0}, {"snippet_id": 64241, "code": ".local_path_config.working_directory()) self._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties", "label": 0}, {"snippet_id": 91130, "code": " division, print_function, unicode_literals from pants.backend.python.pants_requirement import PantsRequirement from pants.backend.python.python_artifact import PythonArtifact from pants.backend.python", "label": 0}, {"snippet_id": 91419, "code": "'pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install('repl') task(name='setup-py', action=SetupPy).install() task", "label": 0}, {"snippet_id": 80182, "code": "\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt\",\"r\") as fd: \t\tnb", "label": 0}, {"snippet_id": 41147, "code": "[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self)", "label": 0}, {"snippet_id": 46702, "code": "\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise", "label": 0}, {"snippet_id": 85049, "code": " definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool('2.10') register_scala_repl_tool('2.10'", "label": 0}, {"snippet_id": 12724, "code": ".post(query, json={\"body\": comment}, headers=headers, auth=auth) data[\"comment_response\"]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B %d, %Y at %H:%M Hours UTC\"", "label": 0}, {"snippet_id": 71380, "code": " AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i", "label": 0}, {"snippet_id": 17320, "code": "-idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self", "label": 0}, {"snippet_id": 70059, "code": " Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler", "label": 0}, {"snippet_id": 72083, "code": "(network) @utils.add_cmd def autoconnect(irc, source, args): \"\"\"<network> <seconds> Sets the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to", "label": 0}, {"snippet_id": 60989, "code": " and context manager\"\"\" import numpy as np from scipy.linalg import expm, eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit", "label": 0}, {"snippet_id": 27793, "code": " elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" ", "label": 0}, {"snippet_id": 76113, "code": ", m, wzauth_data.bind_route[i, m])) def set_route_type(self, i, m, t): self.log.debug('Setting %s,%s type to %d', i, m, t) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success", "label": 0}, {"snippet_id": 90021, "code": "'SystemProperties.class')) cmd=[java, '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode ", "label": 0}, {"snippet_id": 93571, "code": " '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running", "label": 0}, {"snippet_id": 1546, "code": ") serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False)", "label": 0}, {"snippet_id": 88768, "code": " over `items` in subprocesses and return the result. :API: public :param f: A multiproc-friendly(importable) work function. :param items: A iterable of pickleable arguments to f. \"\"\" try: res=SubprocPool", "label": 0}, {"snippet_id": 31303, "code": " __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__", "label": 0}, {"snippet_id": 64537, "code": " from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self", "label": 0}, {"snippet_id": 83244, "code": ".get_status() except Exception: self.mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self", "label": 0}, {"snippet_id": 76045, "code": ".debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i,", "label": 0}, {"snippet_id": 38241, "code": " dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath", "label": 1}, {"snippet_id": 18668, "code": "'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest", "label": 0}, {"snippet_id": 27570, "code": "': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif", "label": 0}, {"snippet_id": 2631, "code": "(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res", "label": 0}, {"snippet_id": 21793, "code": "() X=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0) from sklearn.preprocessing import StandardScaler", "label": 1}, {"snippet_id": 81959, "code": "-template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the", "label": 0}, {"snippet_id": 86600, "code": " _SCALAC_PLUGIN_INFO_FILE) with safe_open(scalac_plugin_info_file, 'w') as f: f.write(textwrap.dedent(\"\"\" <plugin> <name>{}</name> <classname>{}</classname> </plugin> \"\"\".format(scalac_plugin_target.plugin", "label": 0}, {"snippet_id": 6756, "code": "=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode", "label": 0}, {"snippet_id": 1028, "code": ".POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess", "label": 0}, {"snippet_id": 18005, "code": " return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data", "label": 0}, {"snippet_id": 49766, "code": ".subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag", "label": 0}, {"snippet_id": 88172, "code": " closing(jarfile.open(_SCALAC_PLUGIN_INFO_FILE, 'r')) as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile):", "label": 0}, {"snippet_id": 36781, "code": " self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s", "label": 0}, {"snippet_id": 58732, "code": " cls).setUpTestData() cls.permission='testruns.change_testcaserun' cls.update_url=reverse('ajax-update_case_run_status') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission", "label": 0}, {"snippet_id": 27460, "code": "\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of", "label": 0}, {"snippet_id": 13544, "code": " \r while isRunning:\r if( audio.mouthValue !=lastMouthEvent):\r lastMouthEvent=audio.mouthValue\r lastMouthEventTime=time.time()\r \r if( audio.mouthValue==1):\r io.set( MOUTH_OPEN, 1)\r io.set( MOUTH_CLOSE, 0", "label": 0}, {"snippet_id": 3227, "code": "\"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not ", "label": 0}, {"snippet_id": 55829, "code": ".func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 3904, "code": "\"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser('validate', help=\"Validate the setup specified by the ", "label": 0}, {"snippet_id": 77316, "code": ", workers.WZWorkerProcess): type_=1 if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i", "label": 0}, {"snippet_id": 13337, "code": " \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) fullname=data.get(\"fork_fullname\") for file, new_file in data[\"results\"].items(): url=\"https://api.github.com", "label": 0}, {"snippet_id": 20993, "code": "(self, handle_msg, handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[] for handle_msg, name, required in self._handlers", "label": 0}, {"snippet_id": 54047, "code": " is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set", "label": 0}, {"snippet_id": 34283, "code": "=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate", "label": 0}, {"snippet_id": 68705, "code": "=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags", "label": 0}, {"snippet_id": 3581, "code": "']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[", "label": 0}, {"snippet_id": 67423, "code": ".FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return", "label": 0}, {"snippet_id": 89598, "code": "/usr/bin') self._minimum_version=_parse_java_version(\"minimum_version\", minimum_version) self._maximum_version=_parse_java_version(\"maximum_version\", maximum_version) self._jdk=jdk self._is_jdk=False self", "label": 0}, {"snippet_id": 16633, "code": "): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return", "label": 0}, {"snippet_id": 37577, "code": ".items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else", "label": 0}, {"snippet_id": 44843, "code": "=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if", "label": 0}, {"snippet_id": 48939, "code": " def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2", "label": 0}, {"snippet_id": 22266, "code": " import struct import time try: import azurelinuxagent.common.logger as logger import azurelinuxagent.common.utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent", "label": 0}, {"snippet_id": 64187, "code": "'datatypes_config']=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append(integrates_datatypes_config) metadata_kwds[", "label": 0}, {"snippet_id": 37931, "code": " except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno,", "label": 0}, {"snippet_id": 93722, "code": " state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self", "label": 0}, {"snippet_id": 82058, "code": "(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group() exclusiveArgs.add_argument(\"-l\",\"--legit", "label": 0}, {"snippet_id": 84667, "code": "') as list_file_out: for input_file in sorted(input_files): list_file_out.write(input_file) list_file_out.write('\\n') list_file_snapshot=self.context._scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs", "label": 0}, {"snippet_id": 71230, "code": " %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\"", "label": 0}, {"snippet_id": 41915, "code": " dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following", "label": 0}, {"snippet_id": 43589, "code": "\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter", "label": 0}, {"snippet_id": 35082, "code": " value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return", "label": 0}, {"snippet_id": 65734, "code": " else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index],", "label": 0}, {"snippet_id": 93949, "code": "(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd", "label": 0}, {"snippet_id": 6282, "code": ") local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb", "label": 1}, {"snippet_id": 41047, "code": "[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names", "label": 0}, {"snippet_id": 37739, "code": "(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable", "label": 0}, {"snippet_id": 26986, "code": ": if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self", "label": 0}, {"snippet_id": 41834, "code": "\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 79481, "code": ".logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t", "label": 0}, {"snippet_id": 56876, "code": " want count :type key: str :param test_tags: query set, containing the Tag->Object relationship, ordered by tag and annotated by key e.g. TestPlanTag, TestCaseTag ot TestRunTag :type test_tags: QuerySet ", "label": 0}, {"snippet_id": 45161, "code": " return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator", "label": 0}, {"snippet_id": 23560, "code": "(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed to delete root password: Failed to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info()", "label": 0}, {"snippet_id": 39153, "code": " claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names", "label": 0}, {"snippet_id": 76449, "code": ".send_multipart(nfr) except wzrpc.WZErrorRep as e: self.log.info(e) self.wz_sock.send_multipart(e.rep_msg) except wzrpc.WZError as e: self.log.warn(e) def run(self): self.__sinit__() if self.start_timer", "label": 0}, {"snippet_id": 34030, "code": "[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance", "label": 0}, {"snippet_id": 63414, "code": ", None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds", "label": 0}, {"snippet_id": 24321, "code": ".string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo", "label": 0}, {"snippet_id": 65212, "code": "[-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map", "label": 0}, {"snippet_id": 316, "code": ".get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address", "label": 0}, {"snippet_id": 41496, "code": ", self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in", "label": 0}, {"snippet_id": 51401, "code": " in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after", "label": 1}, {"snippet_id": 68424, "code": " status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" ", "label": 0}, {"snippet_id": 1584, "code": ".POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\"", "label": 0}, {"snippet_id": 89536, "code": " Revision object :param bool jdk: ``True`` to require the distribution be a JDK vs a JRE \"\"\" if home_path and not os.path.isdir(home_path): raise ValueError('The specified java home path is invalid:{}'", "label": 0}, {"snippet_id": 80391, "code": "}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal", "label": 0}, {"snippet_id": 57618, "code": "') self.get_update_targets().update(**{str(self.target_field): self.new_value}) def _update_default_tester(self): try: user=User.objects.get(Q(username=self.new_value) | Q(email=self.new_value)) except", "label": 0}, {"snippet_id": 49984, "code": "(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job", "label": 0}, {"snippet_id": 69902, "code": ", None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf", "label": 0}, {"snippet_id": 3223, "code": ") for node in res: if \"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif", "label": 0}, {"snippet_id": 82360, "code": "\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default", "label": 0}, {"snippet_id": 40901, "code": " dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class", "label": 0}, {"snippet_id": 93131, "code": " libtmux import Server from yaml import load, dump from setupParser import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse", "label": 0}, {"snippet_id": 68266, "code": ".status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers", "label": 0}, {"snippet_id": 72420, "code": " line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results", "label": 0}, {"snippet_id": 88153, "code": " _SCALAC_PLUGIN_INFO_FILE), 'r') as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except IOError as e: if e.errno !=errno.ENOENT: raise else: with open_zip(classpath_element", "label": 0}, {"snippet_id": 66910, "code": " worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt -=1 if self.fs.action_refcnt==0: worker.task.abort()", "label": 0}, {"snippet_id": 18054, "code": ": request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response", "label": 0}, {"snippet_id": 95509, "code": "(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp.nlst() file_counter=1 file_list_total", "label": 0}, {"snippet_id": 75240, "code": "(interface, method)]=fun def del_req_handler(self, interface, method): del self.req_handlers[(interface, method)] def del_response_handler(self, reqid): del self.response_handlers[reqid] def del_sig_handler", "label": 0}, {"snippet_id": 91578, "code": ".extend([\"--interpreter-constraint\", text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor, PyTest, PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest", "label": 1}, {"snippet_id": 82895, "code": "\"templateName\"]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in", "label": 1}, {"snippet_id": 42099, "code": "()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 8867, "code": "=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for", "label": 1}, {"snippet_id": 78684, "code": ".debug('Executing remotely') return self.executer(*sys.argv) log.logger.debug('Executing locally') return self.execute() except BaseException as e: log.logger.exception(e) if log.logger.getEffectiveLevel()", "label": 0}, {"snippet_id": 42498, "code": " self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else", "label": 0}, {"snippet_id": 20122, "code": " editor).\"\"\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter", "label": 0}, {"snippet_id": 26867, "code": "': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle']", "label": 0}, {"snippet_id": 63941, "code": " working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def", "label": 1}, {"snippet_id": 27590, "code": "=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self", "label": 0}, {"snippet_id": 67477, "code": ". \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import", "label": 0}, {"snippet_id": 67178, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from", "label": 0}, {"snippet_id": 56827, "code": " str \"\"\" self.obj=obj self.tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj", "label": 0}, {"snippet_id": 14224, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd", "label": 0}, {"snippet_id": 35184, "code": " removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp", "label": 0}, {"snippet_id": 92198, "code": "\n from __future__ import absolute_import, division, print_function, unicode_literals import os import pstats import shutil import signal import sys import unittest import uuid import zipfile from builtins", "label": 0}, {"snippet_id": 55914, "code": " decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources", "label": 0}, {"snippet_id": 25895, "code": "'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 33688, "code": "=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason", "label": 0}, {"snippet_id": 78369, "code": " UnicodeDecodeError as e: self.log.exception(e) self.w.sleep(self.errortimeout) def forumwipe_loop(self): for f in self.forums: self.counter_tick() try: self.addtopic(self.msgfun(), self.sbjfun(), f) except exc", "label": 1}, {"snippet_id": 43123, "code": " IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 32566, "code": " IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno", "label": 0}, {"snippet_id": 52527, "code": " f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else", "label": 1}, {"snippet_id": 95505, "code": "] Created local folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list", "label": 0}, {"snippet_id": 67565, "code": ": Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target", "label": 0}, {"snippet_id": 63715, "code": "( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self,", "label": 0}, {"snippet_id": 79958, "code": " common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest", "label": 0}, {"snippet_id": 11079, "code": "(object): MON_CONF_GEN_COMMENT=' ETAG_COMMENT=' MTIME_COMMMENT=' def __init__(self, etag=None, mtime=0): self.etag=etag self.mtime=int(mtime) def __nonzero__(self): return self.etag is None and self.mtime is", "label": 0}, {"snippet_id": 83765, "code": "=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to", "label": 0}, {"snippet_id": 4333, "code": " get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode", "label": 1}, {"snippet_id": 54989, "code": " self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules,", "label": 0}, {"snippet_id": 86086, "code": "\" target=compile_context.target if isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, AnnotationProcessor) and target.processors", "label": 0}, {"snippet_id": 56908, "code": ", tag): \"\"\" :param tag: the tag you do the counting for :type tag::class:`tcms.management.models.Tag` :return: the number of times a tag is assigned to object :rtype: int \"\"\" if self.counter['tag'] !=tag", "label": 0}, {"snippet_id": 63530, "code": "?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params", "label": 0}, {"snippet_id": 21373, "code": "% subreddit seen_file=sr_dir +\"/seen\" seen_links=[] unseen_file=sr_dir +\"/unseen\" unseen_links=[] print(\"Reddytt: Checking for reddytt working directory(%s).\" % work_dir) if not os.path.isdir(work_dir)", "label": 0}, {"snippet_id": 66812, "code": " assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes)", "label": 0}, {"snippet_id": 9342, "code": " extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning", "label": 0}, {"snippet_id": 53711, "code": "\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError", "label": 0}, {"snippet_id": 26112, "code": "/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS", "label": 1}, {"snippet_id": 49091, "code": " jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict(", "label": 0}, {"snippet_id": 93524, "code": " dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR,", "label": 0}, {"snippet_id": 6113, "code": "=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line", "label": 0}, {"snippet_id": 78873, "code": ",headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\")", "label": 0}, {"snippet_id": 22679, "code": " to the system. :param username: The username that you want to add to the system :param expiration: The expiration date to use. We do not use this value. \"\"\" if self.get_userentry(username): logger.info", "label": 0}, {"snippet_id": 44940, "code": " RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]", "label": 0}, {"snippet_id": 83064, "code": " AsynchronousJobState, AsynchronousJobRunner from galaxy.jobs import ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps", "label": 0}, {"snippet_id": 33529, "code": " main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path", "label": 0}, {"snippet_id": 26412, "code": " __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name", "label": 0}, {"snippet_id": 69453, "code": " from Shine.Commands import commandList from Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs", "label": 0}, {"snippet_id": 56497, "code": ".filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters=", "label": 1}, {"snippet_id": 38362, "code": "(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule", "label": 0}, {"snippet_id": 50643, "code": "._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile)", "label": 0}, {"snippet_id": 80961, "code": "=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName \t\tself.uploadsFolder=uploadsFolder \t\tself.size=size \t\tself.validExtensions", "label": 0}, {"snippet_id": 82556, "code": " to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds", "label": 0}, {"snippet_id": 21146, "code": ".format(','.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message", "label": 0}, {"snippet_id": 39773, "code": " def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None", "label": 0}, {"snippet_id": 89805, "code": " Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the path to the command of the given name for this distribution. For example::: >>> d=Distribution() >>> jar=d.binary('jar') >", "label": 0}, {"snippet_id": 92319, "code": ".assertEqual('False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as(HORK=None): subprocess", "label": 0}, {"snippet_id": 18481, "code": " CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest", "label": 0}, {"snippet_id": 60356, "code": ".name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map", "label": 0}, {"snippet_id": 55685, "code": ": rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int)", "label": 0}, {"snippet_id": 42399, "code": " self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self", "label": 0}, {"snippet_id": 38128, "code": ".. \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name", "label": 0}, {"snippet_id": 72209, "code": ".checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args(args) netname=args.network if netname==irc.name: irc.error(\"Cannot remote-send a command to the local network; use a normal", "label": 0}, {"snippet_id": 898, "code": "')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False)", "label": 0}, {"snippet_id": 59899, "code": "\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator", "label": 0}, {"snippet_id": 52013, "code": ": try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist", "label": 0}, {"snippet_id": 26391, "code": ")) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo", "label": 0}, {"snippet_id": 24024, "code": "\"camcontrol devlist -b | grep blkvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep", "label": 0}, {"snippet_id": 28543, "code": " 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24':", "label": 0}, {"snippet_id": 114, "code": ") wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device", "label": 0}, {"snippet_id": 61028, "code": "[array[complex]]):(a, P): eigenvalues and hermitian projectors such that:math:`A=\\sum_k a_k P_k`. \"\"\" d, v=eigh(A) P=[] for k in range(2): temp=v[:, k] P.append(np.outer(temp.conj(), temp)) return d, P", "label": 0}, {"snippet_id": 59723, "code": ".randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate,", "label": 0}, {"snippet_id": 27010, "code": "._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=", "label": 0}, {"snippet_id": 29035, "code": " self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object", "label": 0}, {"snippet_id": 15164, "code": " FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client", "label": 0}, {"snippet_id": 54439, "code": " format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception", "label": 0}, {"snippet_id": 22105, "code": ".variable_manager.set_inventory(self.inventory) pb_dir=os.path.abspath('.') playbook_path=\"%s/%s\" %(pb_dir, playbook) display.verbosity=self.options.verbosity self.pbex=playbook_executor.PlaybookExecutor", "label": 1}, {"snippet_id": 43384, "code": "(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex:", "label": 0}, {"snippet_id": 66679, "code": " \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage", "label": 0}, {"snippet_id": 17219, "code": " with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check", "label": 0}, {"snippet_id": 75129, "code": " rebinding'. format(wzrpc.name_status(status))) self.p.auth_requests() self.p.bind_methods() elif status==wzrpc.status.e_timeout: self.p.log.warn('Keepalive timeout') else: self.p.log.warn('Keepalive status{0}'", "label": 0}, {"snippet_id": 16957, "code": " headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data,", "label": 1}, {"snippet_id": 826, "code": " print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess", "label": 0}, {"snippet_id": 13297, "code": "'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess", "label": 0}, {"snippet_id": 60450, "code": " import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix, DisplacedSqueezed, Fock, Ket, Squeezed, Thermal", "label": 0}, {"snippet_id": 3341, "code": ".server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server", "label": 0}, {"snippet_id": 12489, "code": "(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file:\\n\\n\") comment_body.append(\"> \" +\"\".join(data[\"extra_results\"][file]", "label": 0}, {"snippet_id": 43498, "code": " rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other", "label": 0}, {"snippet_id": 48480, "code": " str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if", "label": 0}, {"snippet_id": 18870, "code": ".single.schema import( schema_validator, ) from flex.http import( normalize_request, normalize_response, ) from flex.validation.common import validate_object from flex.validation.request import validate_request", "label": 0}, {"snippet_id": 24244, "code": "'Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass", "label": 0}, {"snippet_id": 36349, "code": " value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in", "label": 0}, {"snippet_id": 78253, "code": " add_comment(self, t, msg): if True: try: self.postmsg(t[1], msg, t[0]) except exc.Success as e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w", "label": 0}, {"snippet_id": 44255, "code": " locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on", "label": 0}, {"snippet_id": 49159, "code": ".overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config", "label": 0}, {"snippet_id": 18470, "code": " extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive(", "label": 0}, {"snippet_id": 39155, "code": " will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set", "label": 0}, {"snippet_id": 41118, "code": " None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items)", "label": 0}, {"snippet_id": 95855, "code": " input_vcf_dir: str :type output_zarr_dir: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir) create_directory_tree", "label": 0}, {"snippet_id": 77021, "code": "+domain w=UniWipe(fset, tlist, sbjfun, message, pc, net, domain, Mailinator, uq(domain) if uq else None) w.stoponclose=c.stop_on_closed w.die_on_neterror=c.die_on_neterror w.caprate_minp=c.caprate_minp w", "label": 0}, {"snippet_id": 69191, "code": "=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd", "label": 0}, {"snippet_id": 80131, "code": " detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName", "label": 0}, {"snippet_id": 40815, "code": " wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the", "label": 0}, {"snippet_id": 83704, "code": " def finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state(job_state) run_results=client.full_status() stdout=run_results.get('stdout', ", "label": 0}, {"snippet_id": 88351, "code": "): \"\"\"A logger facade that logs into the pants reporting framework.\"\"\" def __init__(self, run_tracker): self._run_tracker=run_tracker def debug(self, *msg_elements): self._run_tracker.log(Report.DEBUG,", "label": 0}, {"snippet_id": 25023, "code": "=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self", "label": 0}, {"snippet_id": 78762, "code": "(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not available: %s', e) except BaseException as e: log", "label": 0}, {"snippet_id": 70229, "code": "): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target", "label": 0}, {"snippet_id": 25757, "code": "'min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state", "label": 0}, {"snippet_id": 36153, "code": ".output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\"", "label": 0}, {"snippet_id": 35644, "code": "(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"", "label": 0}, {"snippet_id": 19973, "code": " **kwargs) return self._session def detach(self, adapter=None): if self.closed: raise RuntimeError('debug client closed') if self._session is None: raise RuntimeError('not attached') if adapter is None", "label": 0}, {"snippet_id": 15360, "code": "-stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils", "label": 0}, {"snippet_id": 57705, "code": ": self.new_value}) try: plan=plan_from_request_or_none(self.request) except Http404: return say_no(\"No plan record found.\") else: if plan is None: return say_no('No plan record found.') confirm_status_name", "label": 0}, {"snippet_id": 48783, "code": " True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"", "label": 0}, {"snippet_id": 30172, "code": ".append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set", "label": 0}, {"snippet_id": 71094, "code": ".set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout", "label": 0}, {"snippet_id": 24099, "code": "=shellutil.run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible return None @staticmethod def get_total_cpu_ticks_since_boot", "label": 0}, {"snippet_id": 60823, "code": " self._observe=None def __repr__(self): \"\"\"String representation.\"\"\" return self.__module__ +'.' +self.__class__.__name__ +'\\nInstance: ' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\"", "label": 0}, {"snippet_id": 63022, "code": " url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads", "label": 0}, {"snippet_id": 74940, "code": ".benchmark: self.benchmark_aggregations=config_str_to_bool(runtime_config.benchmark[\"benchmark_aggregations\"]) if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config", "label": 1}, {"snippet_id": 81611, "code": ": \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched", "label": 0}, {"snippet_id": 76173, "code": " self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug('Route ", "label": 0}, {"snippet_id": 64748, "code": " on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self", "label": 0}, {"snippet_id": 21791, "code": "=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0) from sklearn", "label": 1}, {"snippet_id": 14851, "code": " retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server", "label": 0}, {"snippet_id": 65257, "code": "() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler", "label": 0}, {"snippet_id": 65109, "code": ", target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start", "label": 0}, {"snippet_id": 1046, "code": "',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe", "label": 0}, {"snippet_id": 79998, "code": "-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip", "label": 0}, {"snippet_id": 55138, "code": " subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return", "label": 0}, {"snippet_id": 73319, "code": "*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str", "label": 0}, {"snippet_id": 32578, "code": "), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete", "label": 0}, {"snippet_id": 69081, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client", "label": 0}, {"snippet_id": 53682, "code": ".temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output", "label": 0}, {"snippet_id": 20452, "code": "._create(connect, addr, **kwargs) @classmethod def _create(cls, connect, addr, timeout=None): if timeout is None: timeout=cls.TIMEOUT sock=connect(addr, timeout) if cls.VERBOSE: print('connected') self", "label": 0}, {"snippet_id": 15623, "code": " self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady():", "label": 0}, {"snippet_id": 59993, "code": ") _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError", "label": 0}, {"snippet_id": 80680, "code": ".info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: ", "label": 0}, {"snippet_id": 84399, "code": ".local_path_config.working_directory()) self._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][", "label": 0}, {"snippet_id": 19482, "code": "-'] if script: extra +=script return args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index('--') except ValueError: script=[] else: script=argv[pos +1:] argv=argv[:pos", "label": 0}, {"snippet_id": 1635, "code": "\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=", "label": 0}, {"snippet_id": 6342, "code": ". The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer", "label": 0}, {"snippet_id": 51902, "code": " Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self", "label": 0}, {"snippet_id": 63927, "code": ") if not remote_work_dir_copy: work_dir_outputs=self.get_work_dir_outputs( job_wrapper) else: work_dir_outputs=[] output_files=self.get_output_files( job_wrapper) client_outputs=ClientOutputs( working_directory", "label": 1}, {"snippet_id": 61800, "code": ", 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after", "label": 0}, {"snippet_id": 43953, "code": ".name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None", "label": 0}, {"snippet_id": 56704, "code": " the database \"\"\" def __init__(self, request): \"\"\" :param request: An HTTP GET request, containing the primary key and the type of object to be selected :type request: HttpRequest \"\"\" for obj in['plan'", "label": 0}, {"snippet_id": 73499, "code": ": config.VCFtoZarrConfigurationRepresentation \"\"\" if conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum", "label": 0}, {"snippet_id": 35392, "code": ". Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards", "label": 0}, {"snippet_id": 33433, "code": " process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely", "label": 0}, {"snippet_id": 62303, "code": "=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation()", "label": 0}, {"snippet_id": 95071, "code": "/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file", "label": 1}, {"snippet_id": 66262, "code": "=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 46157, "code": " isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values", "label": 0}, {"snippet_id": 47684, "code": "\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s", "label": 0}, {"snippet_id": 73258, "code": "=pathlib.Path(input_dir).glob(\"**/*.gz\") for path in pathlist_gz: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib", "label": 0}, {"snippet_id": 82125, "code": "=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\"", "label": 0}, {"snippet_id": 24354, "code": " in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor", "label": 0}, {"snippet_id": 24791, "code": "'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 69513, "code": "\"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':", "label": 0}, {"snippet_id": 48196, "code": " raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"", "label": 0}, {"snippet_id": 4427, "code": "; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs.", "label": 0}, {"snippet_id": 65605, "code": " view is None: view=\"fs\" else: view=view.lower() if view.startswith(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS", "label": 1}, {"snippet_id": 24423, "code": "'Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type", "label": 0}, {"snippet_id": 85205, "code": ". For example for Scala ' '2.10.7 you would use the suffix version \"2.10\".') elif name.endswith(self.version): raise ValueError('The name \"{0}\" should not be suffixed with the scala platform version ' ", "label": 0}, {"snippet_id": 80204, "code": "\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t", "label": 0}, {"snippet_id": 54685, "code": "=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments", "label": 0}, {"snippet_id": 4015, "code": "(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args", "label": 0}, {"snippet_id": 52636, "code": " @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested", "label": 0}, {"snippet_id": 65143, "code": ")...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target", "label": 0}, {"snippet_id": 2892, "code": " as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name", "label": 0}, {"snippet_id": 80682, "code": ": \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)", "label": 0}, {"snippet_id": 27771, "code": "=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state", "label": 0}, {"snippet_id": 73377, "code": " Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located", "label": 0}, {"snippet_id": 5317, "code": " generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): ", "label": 0}, {"snippet_id": 77381, "code": " spawn', e, wname) def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock", "label": 0}, {"snippet_id": 68562, "code": "\"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status", "label": 0}, {"snippet_id": 89035, "code": " :param predicate: If specified, the predicate will be used to narrow the scope of targets returned. :param bool postorder: `True` to gather transitive dependencies with a postorder traversal; `False` or", "label": 0}, {"snippet_id": 4146, "code": " as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger", "label": 1}, {"snippet_id": 30189, "code": " -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index", "label": 0}, {"snippet_id": 38322, "code": "=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 59959, "code": " of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate", "label": 0}, {"snippet_id": 85827, "code": ".compute_classpath_entries(iter(dependencies), classpath_product, all_extra_cp_entries, self.DEFAULT_CONFS, ) def compile_classpath(self, classpath_product_key, target, extra_cp_entries=None): \"\"\"Compute the compile", "label": 0}, {"snippet_id": 14796, "code": " 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data", "label": 0}, {"snippet_id": 46224, "code": "\"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching", "label": 0}, {"snippet_id": 2317, "code": " BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all(", "label": 0}, {"snippet_id": 15430, "code": " SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists", "label": 0}, {"snippet_id": 28970, "code": "['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium", "label": 0}, {"snippet_id": 10404, "code": ".mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os", "label": 0}, {"snippet_id": 41200, "code": " __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist)", "label": 0}, {"snippet_id": 95546, "code": "\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory,", "label": 0}, {"snippet_id": 86384, "code": "=tuple( os.path.relpath(f.path.replace('.java', '.class'), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd)", "label": 0}, {"snippet_id": 78033, "code": ", 10) return id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not in forums: forums[domain]=set() if len(forum) > 0: get_forum_id(forum)", "label": 0}, {"snippet_id": 64797, "code": " execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel", "label": 0}, {"snippet_id": 33732, "code": " logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources:", "label": 0}, {"snippet_id": 57096, "code": "=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not", "label": 0}, {"snippet_id": 921, "code": ") elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep'", "label": 0}, {"snippet_id": 28517, "code": ".data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature']", "label": 0}, {"snippet_id": 74708, "code": " raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"chunk_width\" in runtime_config.vcf_to_zarr: chunk_width_str=runtime_config.vcf_to_zarr", "label": 0}, {"snippet_id": 5349, "code": ":return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"", "label": 0}, {"snippet_id": 7009, "code": " composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according", "label": 0}, {"snippet_id": 78158, "code": ".no_shell: while True: time.sleep(1) else: try: import IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except KeyboardInterrupt: print(\"KeyboardInterrupt\") except SystemExit", "label": 1}, {"snippet_id": 24500, "code": " unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\"", "label": 0}, {"snippet_id": 34058, "code": "\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named", "label": 0}, {"snippet_id": 66728, "code": " e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e", "label": 1}, {"snippet_id": 83518, "code": " dependency_resolution=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params", "label": 1}, {"snippet_id": 25384, "code": "(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo", "label": 0}, {"snippet_id": 39212, "code": " quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun", "label": 0}, {"snippet_id": 12353, "code": "\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: if config[\"message\"", "label": 0}, {"snippet_id": 50526, "code": " ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version", "label": 0}, {"snippet_id": 45370, "code": " in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks", "label": 0}, {"snippet_id": 49736, "code": " subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else", "label": 0}, {"snippet_id": 56268, "code": " plan_from_request_or_none from tcms.testplans.models import TestPlan, TestCasePlan, TestPlanTag from tcms.testruns.models import TestRun, TestCaseRun, TestCaseRunStatus, TestRunTag from tcms.core.helpers.comments", "label": 0}, {"snippet_id": 47410, "code": " job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from", "label": 0}, {"snippet_id": 48316, "code": "): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif", "label": 0}, {"snippet_id": 33863, "code": ".path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global", "label": 0}, {"snippet_id": 86475, "code": ".zinc import Zinc from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin import JavacPlugin from pants.backend.jvm.targets.jvm_target", "label": 0}, {"snippet_id": 93831, "code": "]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp", "label": 0}, {"snippet_id": 60127, "code": " probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise", "label": 0}, {"snippet_id": 62341, "code": " make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or", "label": 0}, {"snippet_id": 29785, "code": "(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp", "label": 0}, {"snippet_id": 35245, "code": " after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for", "label": 1}, {"snippet_id": 29439, "code": ".start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file", "label": 0}, {"snippet_id": 44885, "code": " value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\")", "label": 0}, {"snippet_id": 3378, "code": " slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name", "label": 0}, {"snippet_id": 52995, "code": " self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class", "label": 0}, {"snippet_id": 43082, "code": ": try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings", "label": 0}, {"snippet_id": 88404, "code": "*msg_elements) def __init__(self, options, run_tracker, target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser=None, address_mapper=None, console_outstream=None, scm=None", "label": 0}, {"snippet_id": 58857, "code": ")) class TestUpdateCasePriority(BasePlanCase): \"\"\"Test case for update_cases_default_tester\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateCasePriority, cls).setUpTestData() cls.permission='testcases", "label": 1}, {"snippet_id": 77568, "code": "') def save_users(self): users={} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds=[] for i in range(uqsize): uds.append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write", "label": 0}, {"snippet_id": 69060, "code": " execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel))", "label": 0}, {"snippet_id": 12854, "code": "/{}\" url=url.format(data[\"repository\"], data[\"sha\"], file) r=requests.get(url, headers=headers, auth=auth) with open(\"file_to_fix.py\", 'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text", "label": 0}, {"snippet_id": 90195, "code": " JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable", "label": 0}, {"snippet_id": 17400, "code": " self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines", "label": 0}, {"snippet_id": 46652, "code": " a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has", "label": 0}, {"snippet_id": 33238, "code": ".__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items))", "label": 0}, {"snippet_id": 72142, "code": " except ValueError: irc.error('Invalid argument \"%s\" for <seconds>.' % seconds) return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument", "label": 0}, {"snippet_id": 82052, "code": "=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group", "label": 0}, {"snippet_id": 90493, "code": " specified constraints :param Revision minimum_version: minimum jvm version to look for(eg, 1.7). :param Revision maximum_version: maximum jvm version to look for(eg, 1.7.9999). :param bool jdk: whether", "label": 0}, {"snippet_id": 53097, "code": "\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s", "label": 0}, {"snippet_id": 46957, "code": ".dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output", "label": 0}, {"snippet_id": 78085, "code": "(forum) logger.info('Removing %s:%s from forums[%s]', user, forum, domain) forums[domain].remove((user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login': login, ", "label": 0}, {"snippet_id": 84577, "code": " \"\"\"Print counts of lines of code.\"\"\" @classmethod def subsystem_dependencies(cls): return super(CountLinesOfCode, cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register", "label": 0}, {"snippet_id": 39743, "code": "(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func", "label": 0}, {"snippet_id": 28118, "code": " from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity", "label": 0}, {"snippet_id": 53404, "code": ".temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch", "label": 0}, {"snippet_id": 17673, "code": ".EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), ", "label": 0}, {"snippet_id": 44971, "code": " rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self", "label": 0}, {"snippet_id": 18565, "code": " deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return", "label": 0}, {"snippet_id": 17174, "code": ".client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification", "label": 0}, {"snippet_id": 77208, "code": ".warning('Line %s has too few spaces', line) continue if len(proxypair) > 2: self.log.debug('Line %s has too much spaces', line) proxypair=(proxypair[0], proxypair[1]) newproxies.add(proxypair) except Exception", "label": 0}, {"snippet_id": 44179, "code": ", ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag", "label": 0}, {"snippet_id": 28319, "code": "(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None", "label": 0}, {"snippet_id": 51862, "code": "=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for", "label": 0}, {"snippet_id": 64753, "code": "\\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount", "label": 0}, {"snippet_id": 40046, "code": ") @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError", "label": 1}, {"snippet_id": 59176, "code": ".. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import", "label": 0}, {"snippet_id": 28481, "code": " self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"", "label": 0}, {"snippet_id": 37316, "code": " list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self", "label": 0}, {"snippet_id": 78967, "code": ": \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms[0][1][0][\"name\"] \t\tself.logger", "label": 0}, {"snippet_id": 66052, "code": " STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS", "label": 0}, {"snippet_id": 33642, "code": ".persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep", "label": 0}, {"snippet_id": 31481, "code": " snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged", "label": 0}, {"snippet_id": 95067, "code": "/data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config", "label": 1}, {"snippet_id": 1826, "code": "], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif", "label": 0}, {"snippet_id": 81295, "code": ":(filename,fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint", "label": 0}, {"snippet_id": 55512, "code": ".path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile)", "label": 0}, {"snippet_id": 58001, "code": ": return(None, 'Actions only allow \"add\" and \"remove\".') else: data['action']=request.GET.get('a') data['bz_external_track']=True if request.GET.get('bz_external_track', False) else False return(data, ", "label": 0}, {"snippet_id": 24343, "code": " config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names():", "label": 1}, {"snippet_id": 72265, "code": " remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text, **kwargs): \"\"\" reply() rerouter for the 'remote' command. \"\"\" assert irc.name !=placeholder_self.name,", "label": 0}, {"snippet_id": 25553, "code": "._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif", "label": 0}, {"snippet_id": 84638, "code": " not self.get_options().transitive: targets=self.context.target_roots input_snapshots=tuple( target.sources_snapshot(scheduler=self.context._scheduler) for target in targets ) input_files={f.path for snapshot", "label": 0}, {"snippet_id": 980, "code": "': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker']", "label": 0}, {"snippet_id": 59084, "code": " **Module name:**:mod:`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits", "label": 0}, {"snippet_id": 93585, "code": " else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window) self.logger", "label": 0}, {"snippet_id": 79572, "code": "'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file\"}) \t\t\t\tif len(fileInputs)", "label": 0}, {"snippet_id": 1709, "code": "\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards", "label": 0}, {"snippet_id": 42716, "code": " products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"", "label": 0}, {"snippet_id": 44375, "code": " and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle", "label": 0}, {"snippet_id": 54807, "code": " printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None", "label": 0}, {"snippet_id": 14291, "code": ".Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict", "label": 1}, {"snippet_id": 62844, "code": " self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value", "label": 0}, {"snippet_id": 2413, "code": " class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list", "label": 0}, {"snippet_id": 84538, "code": " unicode_literals import os from builtins import open from future.utils import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants.base.workunit import WorkUnitLabel from pants", "label": 0}, {"snippet_id": 60798, "code": " _current_context=None name='' short_name='' api_version='' version='' author='' _capabilities={} _gates={} _observables={} _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots", "label": 0}, {"snippet_id": 90196, "code": " JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent", "label": 0}, {"snippet_id": 1404, "code": ".Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid", "label": 0}, {"snippet_id": 80319, "code": " entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either", "label": 0}, {"snippet_id": 54684, "code": " snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule", "label": 0}, {"snippet_id": 89109, "code": ": \"\"\"Returns a map from targets that satisfy the from_predicate to targets they depend on that satisfy the on_predicate. :API: public \"\"\" core=set(self.targets(on_predicate)) dependees=defaultdict(set)", "label": 0}, {"snippet_id": 62609, "code": ".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of", "label": 0}, {"snippet_id": 38580, "code": ", ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes", "label": 0}, {"snippet_id": 89834, "code": " no valid command of the given name raises Distribution.Error. If this distribution is a JDK checks both `bin` and `jre/bin` for the binary. \"\"\" if not isinstance(name, str): raise ValueError('name must", "label": 0}, {"snippet_id": 38622, "code": " subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources", "label": 0}, {"snippet_id": 8494, "code": " @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if", "label": 1}, {"snippet_id": 85907, "code": " DirectoryToMaterialize from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator from pants.util.dirutil import safe_open from", "label": 0}, {"snippet_id": 21794, "code": "=X[:, 1:] from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0) from sklearn.preprocessing import StandardScaler sc", "label": 1}, {"snippet_id": 73442, "code": " -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr", "label": 0}, {"snippet_id": 72167, "code": ".add_argument('--service', type=str, default='pylink') remote_parser.add_argument('command', nargs=utils.IRCParser.REMAINDER) @utils.add_cmd def remote(irc, source, args): \"\"\"<network>[--service <service", "label": 0}, {"snippet_id": 17051, "code": "'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests", "label": 0}, {"snippet_id": 22063, "code": ".flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self, playbook, options=None, verbosity=0): if options is None: self", "label": 0}, {"snippet_id": 46865, "code": ".output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res", "label": 0}, {"snippet_id": 4346, "code": "(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords", "label": 0}, {"snippet_id": 58095, "code": " run in runs: for bug in bugs: if bug.case_run_id==run.pk: run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs(p_pks, target): \"\"\"", "label": 0}, {"snippet_id": 32504, "code": " wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file", "label": 0}, {"snippet_id": 15237, "code": " DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options", "label": 0}, {"snippet_id": 60223, "code": "'Beamsplitter': BSgate, 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'Kerr': Kgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing", "label": 0}, {"snippet_id": 54303, "code": "\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self,", "label": 0}, {"snippet_id": 94337, "code": " loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self", "label": 0}, {"snippet_id": 76428, "code": "(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg(self, frames): try: for nfr in self.wz.parse_router_msg(frames): self.wz_sock.send_multipart", "label": 0}, {"snippet_id": 67505, "code": " from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine", "label": 0}, {"snippet_id": 89036, "code": ": If specified, the predicate will be used to narrow the scope of targets returned. :param bool postorder: `True` to gather transitive dependencies with a postorder traversal; `False` or preorder by default", "label": 0}, {"snippet_id": 89732, "code": ".Error('Failed to locate{} library'.format(name)) return list(collect_existing_libs()) @property def home(self): \"\"\"Returns the distribution JAVA_HOME.\"\"\" if not self._home: home=self._get_system_properties", "label": 0}, {"snippet_id": 43691, "code": " \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules", "label": 0}, {"snippet_id": 35182, "code": " shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An", "label": 0}, {"snippet_id": 44667, "code": " snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path", "label": 0}, {"snippet_id": 10958, "code": ".getmtime(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url): try: response=requests.get(url) except socket.error as e: msg=\"Could not open socket for '%s', error: %s\" %", "label": 0}, {"snippet_id": 35109, "code": ", format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value", "label": 0}, {"snippet_id": 52135, "code": "(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\"", "label": 0}, {"snippet_id": 8271, "code": " file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf", "label": 1}, {"snippet_id": 41238, "code": ", into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML", "label": 0}, {"snippet_id": 65740, "code": " target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout", "label": 0}, {"snippet_id": 1375, "code": "=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap", "label": 0}, {"snippet_id": 2830, "code": ": node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name", "label": 0}, {"snippet_id": 66402, "code": " import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print ", "label": 0}, {"snippet_id": 85319, "code": ".jvm.subsystems.dependency_context import DependencyContext from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend.jvm", "label": 0}, {"snippet_id": 32948, "code": " def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain", "label": 0}, {"snippet_id": 55433, "code": " else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"", "label": 0}, {"snippet_id": 16763, "code": " extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory", "label": 0}, {"snippet_id": 94818, "code": " cc=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph", "label": 0}, {"snippet_id": 15481, "code": "._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return", "label": 0}, {"snippet_id": 75802, "code": " def wz_connect(self): self.wz_sock.connect(self.wz_addr) def wz_wait_reply(self, fun, interface, method, data, reqid=None, timeout=None): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz", "label": 1}, {"snippet_id": 58769, "code": "'testruns.testcaserun', 'object_pk': self.case_run_1.pk, 'field': 'case_run_status', 'value': str(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response", "label": 0}, {"snippet_id": 31134, "code": ".dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): ", "label": 0}, {"snippet_id": 69356, "code": ".debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=", "label": 0}, {"snippet_id": 8657, "code": ", and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six", "label": 0}, {"snippet_id": 27623, "code": " data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id", "label": 0}, {"snippet_id": 66251, "code": " target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +", "label": 0}, {"snippet_id": 53804, "code": " set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None)", "label": 0}, {"snippet_id": 31770, "code": ") if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards", "label": 0}, {"snippet_id": 21233, "code": " sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get('href", "label": 0}, {"snippet_id": 84464, "code": "( wrapper_path) results.append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path", "label": 0}, {"snippet_id": 46988, "code": ".priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files", "label": 0}, {"snippet_id": 15941, "code": "=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method", "label": 1}, {"snippet_id": 1948, "code": "=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row", "label": 0}, {"snippet_id": 47156, "code": " self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in", "label": 0}, {"snippet_id": 15635, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else:", "label": 0}, {"snippet_id": 3713, "code": "): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed", "label": 0}, {"snippet_id": 77926, "code": " to targets[%s]', repr(t), domain) tlist.append(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Removing %s from targets[", "label": 0}, {"snippet_id": 35280, "code": " annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern", "label": 0}, {"snippet_id": 28449, "code": ".moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if", "label": 0}, {"snippet_id": 58449, "code": ".DEFAULT_CHARSET), {'rc': 1, 'response': 'Comments needed'}) def test_refuse_if_missing_no_case_run_pk(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self", "label": 0}, {"snippet_id": 12301, "code": " if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(repository, after_commit_hash, file)", "label": 0}, {"snippet_id": 11768, "code": "\", } auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/user/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict(base", "label": 0}, {"snippet_id": 1750, "code": "(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows", "label": 0}, {"snippet_id": 736, "code": " range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS", "label": 0}, {"snippet_id": 45464, "code": "(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not", "label": 1}, {"snippet_id": 26699, "code": "'battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 10137, "code": "]} :keyword spires: bool, to get the spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit", "label": 0}, {"snippet_id": 90538, "code": " minimum_version: continue if maximum_version and dist.version > maximum_version: continue if jdk and not dist.jdk: continue return dist def locate(self, minimum_version=None, maximum_version=None, jdk", "label": 0}, {"snippet_id": 87867, "code": ".items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-C-Xplugin:{}{}'.format(plugin, ' '.join(args)", "label": 0}, {"snippet_id": 7512, "code": "=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output", "label": 0}, {"snippet_id": 66989, "code": " in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency", "label": 0}, {"snippet_id": 86781, "code": " settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings.args) zinc_args.extend(settings_args) return zinc_args @classmethod def implementation_version(cls): return super(BaseZincCompile, cls", "label": 0}, {"snippet_id": 14640, "code": " diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[", "label": 0}, {"snippet_id": 50984, "code": "(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.", "label": 1}, {"snippet_id": 48478, "code": " if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self", "label": 0}, {"snippet_id": 16381, "code": " stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None", "label": 0}, {"snippet_id": 15655, "code": ".DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try", "label": 0}, {"snippet_id": 36734, "code": ".dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self", "label": 0}, {"snippet_id": 1545, "code": "() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False", "label": 0}, {"snippet_id": 58051, "code": " bug_system_id=data['bug_system_id'] bug_ids=data['bugs'] try: validate_bug_id(bug_ids, bug_system_id) except ValidationError as e: return say_no(str(e)) bz_external_track=data['bz_external_track'] action=data", "label": 0}, {"snippet_id": 75820, "code": " self.poll, self.sleep_ticker, self.wz timeout=timeout if timeout else self.wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b''", "label": 1}, {"snippet_id": 40522, "code": ", format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value", "label": 0}, {"snippet_id": 17100, "code": "'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data", "label": 1}, {"snippet_id": 81066, "code": ".critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit()", "label": 0}, {"snippet_id": 76798, "code": " timeout') parser.add_argument('--errortimeout', type=float, default=3, help='Error timeout') parser.add_argument('--stop-on-closed', action='store_true', default=False, help='Forget about closed topics", "label": 0}, {"snippet_id": 7129, "code": " _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions[s](complete_output, categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit))", "label": 0}, {"snippet_id": 61339, "code": " for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical", "label": 0}, {"snippet_id": 95091, "code": " print(\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location", "label": 1}, {"snippet_id": 43373, "code": " producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement", "label": 0}, {"snippet_id": 6417, "code": " extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import", "label": 1}, {"snippet_id": 85214, "code": "\"2.10\".') elif name.endswith(self.version): raise ValueError('The name \"{0}\" should not be suffixed with the scala platform version ' '({1}): it will be added automatically.'.format(name, self.version)", "label": 0}, {"snippet_id": 10527, "code": "('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not", "label": 1}, {"snippet_id": 22087, "code": "=verbosity self.loader=dataloader.DataLoader() self.variable_manager=vars.VariableManager() self.inventory=inventory.Inventory( loader=self.loader, variable_manager=self.variable_manager, host_list='/etc", "label": 0}, {"snippet_id": 33122, "code": " def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False", "label": 0}, {"snippet_id": 45325, "code": " pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow", "label": 0}, {"snippet_id": 12608, "code": ".json() last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body\"] break \"\"\" text1=''.join(BeautifulSoup(markdown(comment)).findAll(text", "label": 0}, {"snippet_id": 82713, "code": "=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser", "label": 0}, {"snippet_id": 51808, "code": " else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add", "label": 0}, {"snippet_id": 46648, "code": " first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is", "label": 0}, {"snippet_id": 78172, "code": " WorkerInterrupt from wipeskel import WipeSkel, WipeState, cstate from beon import exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun", "label": 0}, {"snippet_id": 44626, "code": " and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and", "label": 0}, {"snippet_id": 1634, "code": "' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output", "label": 0}, {"snippet_id": 77485, "code": " return self.spawn_nworkers(0, WipeThread, self.c.tcount, (self.pc, self.spawnqueue)) def spawn_evaluators(self): self.log.info('Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init()", "label": 0}, {"snippet_id": 71303, "code": " NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '", "label": 0}, {"snippet_id": 65685, "code": " fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets", "label": 0}, {"snippet_id": 45881, "code": " f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\")", "label": 0}, {"snippet_id": 84744, "code": " files_content={fc.path: fc.content.decode('utf-8') for fc in files_content_tuple} for line in files_content['report'].split('\\n'): yield line if self.get_options().ignored: yield 'Ignored the following", "label": 0}, {"snippet_id": 50744, "code": "\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product", "label": 0}, {"snippet_id": 8818, "code": "=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path", "label": 0}, {"snippet_id": 31031, "code": " if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif", "label": 0}, {"snippet_id": 76408, "code": "(e) return if socks.get(self.sig_sock)==zmq.POLLIN: frames=self.sig_sock.recv_multipart() try: self.wz.parse_msg(frames[0], frames[1:]) except wzrpc.WZError as e: self.log.warn(e) if socks.get(self.wz_sock", "label": 0}, {"snippet_id": 78408, "code": " cur: %f', self.topic_successtimeout) self.w.sleep(self.topic_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10) except exc.UnknownAnswer as e", "label": 0}, {"snippet_id": 7672, "code": "[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)", "label": 0}, {"snippet_id": 88900, "code": " global lock object is actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots) def add_new_target(self", "label": 0}, {"snippet_id": 90455, "code": ") class _Locator(object): class Error(Distribution.Error): \"\"\"Error locating a java distribution.\"\"\" def __init__(self, distribution_environment, minimum_version=None, maximum_version=None): self._cache", "label": 0}, {"snippet_id": 9069, "code": " fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else: single_keywords", "label": 0}, {"snippet_id": 77222, "code": ") proxypair=(proxypair[0], proxypair[1]) newproxies.add(proxypair) except Exception as e: self.log.exception('Line %s raised exception %s', line, e) return newproxies.difference(self.proxylist) def add_spawns", "label": 0}, {"snippet_id": 27030, "code": "'wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo", "label": 0}, {"snippet_id": 37427, "code": " _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output", "label": 0}, {"snippet_id": 50500, "code": " ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 80941, "code": "=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction", "label": 0}, {"snippet_id": 71510, "code": " if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed", "label": 1}, {"snippet_id": 17617, "code": " self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady():", "label": 0}, {"snippet_id": 61746, "code": " matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires < 0) or np.any(wires ", "label": 0}, {"snippet_id": 56899, "code": " self.counter={'tag': 0} def calculate_tag_count(self, tag): \"\"\" :param tag: the tag you do the counting for :type tag::class:`tcms.management.models.Tag` :return: the number of times a tag is assigned", "label": 0}, {"snippet_id": 41330, "code": ": \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat", "label": 0}, {"snippet_id": 23236, "code": " if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned more than{0} up ' 'network interfaces.'), expected) sock=buff.tostring() for i in range(0, struct_size * expected, struct_size)", "label": 0}, {"snippet_id": 61016, "code": " decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian projectors such that:math:`A=\\sum_k a_k P_k`. \"", "label": 0}, {"snippet_id": 90937, "code": " java distribution:{}'.format(e)) options_scope='jvm-distributions' @classmethod def register_options(cls, register): super(DistributionLocator, cls).register_options(register) human_readable_os_aliases='", "label": 0}, {"snippet_id": 1208, "code": " common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion():", "label": 1}, {"snippet_id": 80882, "code": "\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues", "label": 0}, {"snippet_id": 61183, "code": "(a) \"\"\" return frz(c) @(fry(b) @ frz(a)) def ket(*args): r\"\"\"Input validation for an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised array. \"\"\" state=np.asarray(args) return", "label": 0}, {"snippet_id": 40513, "code": " else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString", "label": 0}, {"snippet_id": 71207, "code": " else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"", "label": 0}, {"snippet_id": 88562, "code": " play for the run as returned by self.targets(). Note that for a command line invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API:", "label": 0}, {"snippet_id": 1004, "code": "=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass", "label": 0}, {"snippet_id": 85055, "code": " `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool('2.10') register_scala_repl_tool('2.10', with_jline=True) register_style_tool('2.10') register_scala_compiler_tool('2.11", "label": 0}, {"snippet_id": 9781, "code": " list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted", "label": 0}, {"snippet_id": 20201, "code": "=self.SESSION.create_server(addr, **kwargs) except Exception as ex: self._run_server_ex=traceback.format_exc() t=new_hidden_thread( target=run, name='test.client', ) t.start() def wait(): t.join(timeout", "label": 0}, {"snippet_id": 66604, "code": " Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import", "label": 0}, {"snippet_id": 75038, "code": " __init__(self, ev_init, *args, **kvargs): super().__init__() self.ev_init=ev_init self.bind_kt_ticker=Ticker() self.bind_kt=5 def handle_evaluate(self, reqid, interface, method, data): domain, page=data self", "label": 0}, {"snippet_id": 88288, "code": ".process.lock import OwnerPrintingInterProcessFileLock from pants.reporting.report import Report from pants.source.source_root import SourceRootConfig class Context(object): \"\"\"Contains the context for", "label": 0}, {"snippet_id": 35993, "code": " jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag", "label": 0}, {"snippet_id": 8443, "code": " line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text):", "label": 1}, {"snippet_id": 39699, "code": " return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 68949, "code": ": self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node", "label": 0}, {"snippet_id": 89173, "code": ". Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets parsed in the root tree's BUILD files will be followed and this may lead to BUILD files outside", "label": 0}, {"snippet_id": 67721, "code": ") def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 90551, "code": " locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets the given constraints and returns it. First looks for a cached version that was previously located", "label": 0}, {"snippet_id": 59805, "code": " observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator(str(observable)[-1]+'0'), self.reg) variance=1 -expectation_value**2 elif observable", "label": 0}, {"snippet_id": 47046, "code": " RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"", "label": 0}, {"snippet_id": 10802, "code": " URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream", "label": 1}, {"snippet_id": 93637, "code": " comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name", "label": 0}, {"snippet_id": 58108, "code": " Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs(p_pks, target): \"\"\" Get Component, Version, Category, and Build\\n Return[(id, name),(id, name)] \"\"\" ctypes={ 'component", "label": 0}, {"snippet_id": 43896, "code": " not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets:", "label": 0}, {"snippet_id": 88477, "code": "() self._workspace=workspace or(ScmWorkspace(self._scm) if self._scm else None) self._replace_targets(target_roots) self._invalidation_report=invalidation_report self._scheduler=scheduler @property def", "label": 0}, {"snippet_id": 45074, "code": " def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return", "label": 0}, {"snippet_id": 22641, "code": " device \"\"\" return None def useradd(self, username, expiration=None): \"\"\"Create user account using tmsh Our policy is to create two accounts when booting a BIG-IP instance. The first account is the one", "label": 1}, {"snippet_id": 66326, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout", "label": 0}, {"snippet_id": 91215, "code": ".python.tasks.build_local_python_distributions import \\ BuildLocalPythonDistributions from pants.backend.python.tasks.gather_sources import GatherSources from pants.backend.python.tasks.isort_prep import", "label": 0}, {"snippet_id": 7306, "code": " provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s", "label": 0}, {"snippet_id": 38928, "code": " else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete()", "label": 0}, {"snippet_id": 80639, "code": ".uploadsPath,args.url,args.formAction,args.inputName) else: \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up", "label": 0}, {"snippet_id": 57455, "code": " def __init__(self, request): self.request=request self.target_field=request.POST.get('target_field') self.new_value=request.POST.get('new_value') def get_update_action(self): return getattr(self, '_update_", "label": 0}, {"snippet_id": 20311, "code": ", self._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert", "label": 0}, {"snippet_id": 46995, "code": ".output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size", "label": 0}, {"snippet_id": 205, "code": "{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess", "label": 0}, {"snippet_id": 44838, "code": ".add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo", "label": 0}, {"snippet_id": 31539, "code": "._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self", "label": 0}, {"snippet_id": 19333, "code": ": 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_url", "label": 0}, {"snippet_id": 87462, "code": ") zinc_args.extend(['-compiler-interface', compiler_interface]) zinc_args.extend(['-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala", "label": 1}, {"snippet_id": 60213, "code": "'FockState': Fock, 'FockStateVector': Ket, 'SqueezedState': Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase", "label": 0}, {"snippet_id": 38899, "code": " subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return", "label": 0}, {"snippet_id": 51575, "code": "[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try:", "label": 0}, {"snippet_id": 10764, "code": " text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split", "label": 1}, {"snippet_id": 43678, "code": " jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict(", "label": 0}, {"snippet_id": 22736, "code": " output:{2}\".format(username, retcode, out) ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id=6, salt_len=10): \"\"\"Change a user's password with tmsh Since we are creating", "label": 0}, {"snippet_id": 3774, "code": "(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name): window=session.find_where({ \"window_name\": window_name", "label": 0}, {"snippet_id": 82880, "code": ".datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[\"templateName\"]]=templatefd", "label": 0}, {"snippet_id": 28789, "code": " data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self", "label": 0}, {"snippet_id": 20944, "code": ": for msg in self._conn.iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message(self, msg): for i", "label": 1}, {"snippet_id": 7073, "code": " text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags:", "label": 0}, {"snippet_id": 69486, "code": "): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register", "label": 0}, {"snippet_id": 94532, "code": " return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window", "label": 0}, {"snippet_id": 8839, "code": " process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file", "label": 1}, {"snippet_id": 4426, "code": "-partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs", "label": 0}, {"snippet_id": 72930, "code": " file_list_total=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with", "label": 0}, {"snippet_id": 59409, "code": " in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del", "label": 0}, {"snippet_id": 75937, "code": ".send_multipart(msgdict[rs]) rs.finished=False rs.retry=False flag=1 if not flag: return t.tick() p(timeout*1000) if t.elapsed(False) >=timeout: for rs in rslist: if not rs.finished: rs.accept(None, 0, 255,[])", "label": 0}, {"snippet_id": 95199, "code": ", runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files", "label": 1}, {"snippet_id": 73042, "code": " remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP] Created local folder:{}\".format(local_path)) except OSError: pass except", "label": 0}, {"snippet_id": 54545, "code": " self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None", "label": 0}, {"snippet_id": 60597, "code": ".__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires", "label": 1}, {"snippet_id": 21440, "code": " subreddit directory. Creating %s, and files.\" % sr_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file", "label": 0}, {"snippet_id": 15344, "code": "{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format", "label": 0}, {"snippet_id": 35570, "code": " toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a", "label": 0}, {"snippet_id": 53621, "code": ".name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of", "label": 0}, {"snippet_id": 17374, "code": "._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode", "label": 0}, {"snippet_id": 2650, "code": " node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error", "label": 0}, {"snippet_id": 89940, "code": ", 'bin') try: self._validated_executable('javac') self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please check you have a JDK ' 'installed. Original", "label": 0}, {"snippet_id": 81337, "code": "=None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search", "label": 0}, {"snippet_id": 1213, "code": " crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase).", "label": 1}, {"snippet_id": 238, "code": "(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for", "label": 0}, {"snippet_id": 9949, "code": "(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions])", "label": 0}, {"snippet_id": 48032, "code": "=1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards", "label": 0}, {"snippet_id": 53091, "code": ".updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self", "label": 0}, {"snippet_id": 38773, "code": " ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 81489, "code": " future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t", "label": 0}, {"snippet_id": 67002, "code": "':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command", "label": 0}, {"snippet_id": 81169, "code": ".uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t", "label": 0}, {"snippet_id": 21414, "code": "(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working", "label": 0}, {"snippet_id": 47919, "code": " dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_,", "label": 0}, {"snippet_id": 56016, "code": ".func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version", "label": 0}, {"snippet_id": 21142, "code": "'Timeout waiting for{}'.format(','.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event", "label": 0}, {"snippet_id": 46935, "code": ".add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input", "label": 0}, {"snippet_id": 38583, "code": "=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False", "label": 0}, {"snippet_id": 64803, "code": "=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs", "label": 0}, {"snippet_id": 71507, "code": "(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client", "label": 1}, {"snippet_id": 95094, "code": " up benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments[\"config_file", "label": 1}, {"snippet_id": 46747, "code": " the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): ", "label": 0}, {"snippet_id": 30730, "code": "=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64", "label": 0}, {"snippet_id": 89733, "code": " library'.format(name)) return list(collect_existing_libs()) @property def home(self): \"\"\"Returns the distribution JAVA_HOME.\"\"\" if not self._home: home=self._get_system_properties(self.java)['java.home", "label": 0}, {"snippet_id": 6248, "code": "=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile", "label": 1}, {"snippet_id": 92744, "code": ".assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t.elapsed, 0.1) clock.sleep(0.1) self.assertTrue(t.finish is None) self.assertGreater(t.elapsed, 0.2) self.assertLess(t.finish, clock.time(", "label": 0}, {"snippet_id": 8020, "code": "[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str", "label": 0}, {"snippet_id": 86497, "code": ".backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants", "label": 0}, {"snippet_id": 48610, "code": "(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio", "label": 0}, {"snippet_id": 61638, "code": "(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation value.'.format(expectation.imag)) return expectation.real def reset(self):", "label": 0}, {"snippet_id": 48108, "code": ") for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark:", "label": 0}, {"snippet_id": 21137, "code": "==0: return else: raise TimeoutError('Timeout waiting for{}'.format(','.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event", "label": 0}, {"snippet_id": 88283, "code": " import ScmWorkspace from pants.process.lock import OwnerPrintingInterProcessFileLock from pants.reporting.report import Report from pants.source.source_root import SourceRootConfig class Context(object)", "label": 0}, {"snippet_id": 86575, "code": "/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class BaseZincCompile(JvmCompile): \"\"\"An abstract base class for zinc compilation tasks.\"\"\" _name='zinc' @staticmethod", "label": 1}, {"snippet_id": 50046, "code": "())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile(", "label": 0}, {"snippet_id": 42668, "code": " input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self", "label": 0}, {"snippet_id": 9840, "code": " :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> ", "label": 0}, {"snippet_id": 93044, "code": " mock.patch('signal.signal', **PATCH_OPTS) as mock_signal: mock_signal.return_value=mock_initial_handler try: with signal_handler_as(signal.SIGUSR2, mock_new_handler): raise NotImplementedError('blah')", "label": 0}, {"snippet_id": 26211, "code": ":weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':", "label": 0}, {"snippet_id": 63828, "code": ".id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id)) client=self.get_client(job.destination_params", "label": 0}, {"snippet_id": 34405, "code": "=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os", "label": 0}, {"snippet_id": 8764, "code": " no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms ) if api: return output else: if isinstance(output", "label": 0}, {"snippet_id": 31787, "code": " values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards", "label": 0}, {"snippet_id": 64570, "code": " if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename", "label": 1}, {"snippet_id": 86721, "code": " distribution. :param settings: The jvm platform settings from which to extract the arguments. :type settings::class:`JvmPlatformSettings` \"\"\" zinc_args=[ '-C-source', '-C{}'.format(settings.source_level", "label": 0}, {"snippet_id": 66500, "code": " target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc", "label": 0}, {"snippet_id": 50767, "code": " import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os", "label": 1}, {"snippet_id": 78285, "code": " try: self.targets.remove(t) except ValueError: pass self.w.sleep(self.comment_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.schedule(self.add_comment", "label": 0}, {"snippet_id": 15408, "code": "._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 38194, "code": " import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException", "label": 0}, {"snippet_id": 48967, "code": "\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0:", "label": 0}, {"snippet_id": 69862, "code": " RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel", "label": 0}, {"snippet_id": 83884, "code": "], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid", "label": 0}, {"snippet_id": 66481, "code": " print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file", "label": 0}, {"snippet_id": 56981, "code": ") 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid literal for int() with base 10: 'string'\") \"\"\" value=error=None def get_time", "label": 0}, {"snippet_id": 85148, "code": "().version def suffix_version(self, name): \"\"\"Appends the platform version to the given artifact name. Also validates that the name doesn't already end with the version. \"\"\" if self.version=='custom': suffix", "label": 0}, {"snippet_id": 10841, "code": " url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote", "label": 1}, {"snippet_id": 20235, "code": " connect after{} secs'.format( self._connecttimeout) if self._run_server_ex is None: raise Exception(message) else: message=message +os.linesep +self._run_server_ex raise Exception(message) self._launch(", "label": 0}, {"snippet_id": 5803, "code": " sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the", "label": 0}, {"snippet_id": 2114, "code": ":')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username", "label": 0}, {"snippet_id": 24370, "code": ": dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES", "label": 1}, {"snippet_id": 40650, "code": "\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 34983, "code": ": os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name", "label": 0}, {"snippet_id": 82421, "code": ".veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds", "label": 0}, {"snippet_id": 60866, "code": " is None: Device._current_context=self self.reset() else: raise DeviceError('Only one device can be active at a time.') return self def __exit__(self, exc_type, exc_value, tb): if self._observe is None", "label": 0}, {"snippet_id": 60791, "code": " in the quantum circuit. \"\"\" pass class Device(abc.ABC): \"\"\"Abstract base class for devices.\"\"\" _current_context=None name='' short_name='' api_version='' version='' author='' _capabilities={} _gates={", "label": 0}, {"snippet_id": 22340, "code": " before we go provisioning the system. I call this method at the first opportunity I have(during the DVD mounting call). This ensures that the rest of the provisioning does not need to wait for mcpd to", "label": 0}, {"snippet_id": 81707, "code": " executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms", "label": 0}, {"snippet_id": 21935, "code": " ask_su_pass=None, sudo=None, sudo_user=None, become=None, become_method=None, become_user=None, become_ask_pass=None, ask_pass=None, private_key_file=None, remote_user=None, connection=None, timeout=None,", "label": 0}, {"snippet_id": 3241, "code": "\"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between", "label": 0}, {"snippet_id": 17982, "code": "=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest,", "label": 0}, {"snippet_id": 37894, "code": ".dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self", "label": 0}, {"snippet_id": 71833, "code": " self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except KeyError:", "label": 0}, {"snippet_id": 81813, "code": "-description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse", "label": 0}, {"snippet_id": 47873, "code": ".protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log", "label": 0}, {"snippet_id": 70943, "code": " t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0", "label": 0}, {"snippet_id": 3475, "code": " kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window", "label": 0}, {"snippet_id": 68742, "code": ") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [", "label": 0}, {"snippet_id": 42079, "code": "=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\":", "label": 0}, {"snippet_id": 4079, "code": " text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML", "label": 0}, {"snippet_id": 87242, "code": "\"\"\" target=compile_context.target if isinstance(target, ScalacPlugin): self._write_scalac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, JavacPlugin): self._write_javac_plugin_info", "label": 0}, {"snippet_id": 50905, "code": " symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if", "label": 0}, {"snippet_id": 6942, "code": " type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations", "label": 0}, {"snippet_id": 11703, "code": " json import os import re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository): \"\"\"Update users of the integration", "label": 0}, {"snippet_id": 9882, "code": "): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword", "label": 0}, {"snippet_id": 66607, "code": ".CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug", "label": 1}, {"snippet_id": 65243, "code": ": RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 22221, "code": "]: log_file=self.conf[state]['log_file'] if 'template' in self.conf[state]: template=self.conf[state]['template'] if playbook is None: playbook=self.conf['playbook'] if template is None and template in", "label": 0}, {"snippet_id": 14360, "code": " port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append", "label": 0}, {"snippet_id": 4755, "code": " keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of", "label": 0}, {"snippet_id": 50015, "code": ".run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and", "label": 0}, {"snippet_id": 42489, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True)", "label": 0}, {"snippet_id": 66075, "code": "(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets:", "label": 0}, {"snippet_id": 66935, "code": ".cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load", "label": 0}, {"snippet_id": 74557, "code": ": delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc", "label": 0}, {"snippet_id": 12081, "code": "[\"Accept\"]=\"application/vnd.github.VERSION.diff\" auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository\"] after_commit_hash=data[\"after_commit_hash\"] author=data[\"author", "label": 0}, {"snippet_id": 52373, "code": " if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o", "label": 0}, {"snippet_id": 41760, "code": " combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in", "label": 0}, {"snippet_id": 61630, "code": " ValueError('2x2 matrix required.') A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation", "label": 0}, {"snippet_id": 15337, "code": ".path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std=", "label": 0}, {"snippet_id": 68376, "code": " t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING", "label": 0}, {"snippet_id": 43962, "code": " cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster", "label": 0}, {"snippet_id": 71738, "code": " cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen", "label": 0}, {"snippet_id": 74185, "code": " of the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config", "label": 0}, {"snippet_id": 63454, "code": " i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination", "label": 0}, {"snippet_id": 9143, "code": " bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary", "label": 0}, {"snippet_id": 43985, "code": " cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False", "label": 0}, {"snippet_id": 91502, "code": ".python_setup import PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch) from pants.engine.isolated_process import(ExecuteProcessRequest", "label": 0}, {"snippet_id": 46168, "code": " in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map", "label": 0}, {"snippet_id": 78260, "code": ") except exc.Success as e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment,(t,", "label": 0}, {"snippet_id": 78996, "code": "\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) ", "label": 0}, {"snippet_id": 95402, "code": " % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file", "label": 0}, {"snippet_id": 51097, "code": "(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__", "label": 0}, {"snippet_id": 22132, "code": " options=self.options, passwords={}) def run(self, job_id): \"\"\"Run the playbook and returns the playbook's stats.\"\"\" self.variable_manager.extra_vars={'job_id': job_id} self.pbex.run() return self.pbex", "label": 0}, {"snippet_id": 42540, "code": ": try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))", "label": 1}, {"snippet_id": 54877, "code": " resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items)", "label": 0}, {"snippet_id": 50886, "code": " check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file", "label": 1}, {"snippet_id": 35831, "code": " f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" ", "label": 0}, {"snippet_id": 11046, "code": ".datetime.strptime(mtime, '%a, %d %b %Y %H:%M:%S %Z').strftime('%s') if mtime else int(time()) else: msg=\"Request %s returned with status %s. I don't know how to handle that.\" %(url, response.status_code)", "label": 0}, {"snippet_id": 12280, "code": "].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split", "label": 0}, {"snippet_id": 11545, "code": " section_name, section_data): self.write_line(\"\") self.write_line(\"define %s{\" % section_name) sorted_keys=section_data.keys() sorted_keys.sort() for key in sorted_keys: value=section_data[key] self.icinga_lines", "label": 1}, {"snippet_id": 9288, "code": "=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also", "label": 0}, {"snippet_id": 62068, "code": " the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end", "label": 0}, {"snippet_id": 81045, "code": " or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(", "label": 0}, {"snippet_id": 94493, "code": " amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp", "label": 0}, {"snippet_id": 23161, "code": " struct_size check here because, curiously, our 64bit platform is identified by python in Azure(Stack) as 32 bit and without adjusting the struct_size, we can't get the information we need. I believe this may be", "label": 0}, {"snippet_id": 58010, "code": "=request.GET.get('a') data['bz_external_track']=True if request.GET.get('bz_external_track', False) else False return(data, '') def update_bugs_to_caseruns(request): \"\"\" Add one or more bugs to or remove", "label": 0}, {"snippet_id": 83452, "code": " Build command-line and LWR client for this job. \"\"\" command_line=None client=None remote_job_config=None compute_environment=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool", "label": 0}, {"snippet_id": 9566, "code": " read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"", "label": 0}, {"snippet_id": 60151, "code": " import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix, DisplacedSqueezed,", "label": 0}, {"snippet_id": 8189, "code": " text extractor. This module provides method to extract the fulltext from local or remote documents. Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide the functionality", "label": 1}, {"snippet_id": 81995, "code": " expression to detect code execution. Overrides the default code execution detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group('Required named", "label": 0}, {"snippet_id": 27678, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920:", "label": 0}, {"snippet_id": 79835, "code": ".\") parser.add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex", "label": 0}, {"snippet_id": 75102, "code": " handle_keepalive_reply(self, reqid, seqnum, status, data): if status==wzrpc.status.success: self.p.log.debug('Keepalive was successfull') elif status==wzrpc.status.e_req_denied: self.p.log.warn('Keepalive", "label": 0}, {"snippet_id": 81608, "code": "\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself", "label": 0}, {"snippet_id": 14812, "code": "._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os", "label": 0}, {"snippet_id": 71336, "code": ".set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i ", "label": 0}, {"snippet_id": 35582, "code": " fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index", "label": 0}, {"snippet_id": 72330, "code": " overriding reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join", "label": 1}, {"snippet_id": 8686, "code": " ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import", "label": 1}, {"snippet_id": 57657, "code": "(pk=self.new_value) except TestCaseStatus.DoesNotExist: raise ObjectDoesNotExist('The status you choose does not exist.') update_object=self.get_update_targets() if not update_object: return say_no('No", "label": 0}, {"snippet_id": 93602, "code": ".logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\" %(host", "label": 0}, {"snippet_id": 59454, "code": " +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued", "label": 1}, {"snippet_id": 22589, "code": " qualified domain name. The proper value should have been bigip.xxx.yyy WAAgent will not fail if this command fails, but the hostname will not be what the user set either. Currently we do not set the hostname", "label": 0}, {"snippet_id": 54968, "code": " if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag", "label": 0}, {"snippet_id": 23036, "code": " raise OSUtilError(\"Failed to get dvd device\") def mount_dvd(self, **kwargs): \"\"\"Mount the DVD containing the provisioningiso.iso file This is the _first_ hook that WAAgent provides for us, so this is the", "label": 0}, {"snippet_id": 29995, "code": ")) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values", "label": 0}, {"snippet_id": 71609, "code": ".fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None,", "label": 0}, {"snippet_id": 55885, "code": " ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark", "label": 0}, {"snippet_id": 57634, "code": "(email=self.new_value)) except User.DoesNotExist: raise ObjectDoesNotExist('Default tester not found!') self.get_update_targets().update(**{str(self.target_field): user.pk}) def _update_case_status(self", "label": 0}, {"snippet_id": 77942, "code": " '' t=(tuser, id_) logger.info('Removing %s from targets[%s]', repr(t), domain) tlist.remove(t) def add_target_exc(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain", "label": 0}, {"snippet_id": 66389, "code": " RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def", "label": 0}, {"snippet_id": 17101, "code": " response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if", "label": 0}, {"snippet_id": 22513, "code": ": \"\"\"Set the static hostname of the device Normally, tmsh is used to set the hostname for the system. For our purposes at this time though, I would hesitate to trust this function. Azure(Stack) uses the", "label": 0}, {"snippet_id": 17463, "code": " self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data", "label": 0}, {"snippet_id": 62076, "code": " is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit). user(string): IBM Quantum Experience user name password(string", "label": 0}, {"snippet_id": 8121, "code": " save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid)", "label": 0}, {"snippet_id": 95460, "code": " files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list \"\"\" if(remote_subdirs_list is not None", "label": 0}, {"snippet_id": 61795, "code": " if wires[0] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron", "label": 0}, {"snippet_id": 13866, "code": " from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor(", "label": 0}, {"snippet_id": 85555, "code": "(products, 'compiler-interface', cls.options_scope) def create(self, products): \"\"\"Create a Zinc instance from products active in the current Pants run. :param products: The active Pants run products to pluck", "label": 0}, {"snippet_id": 32627, "code": " bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards", "label": 0}, {"snippet_id": 69353, "code": ", NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch", "label": 0}, {"snippet_id": 29499, "code": " get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait)", "label": 0}, {"snippet_id": 27628, "code": "._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500:", "label": 0}, {"snippet_id": 60323, "code": "=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset(", "label": 1}, {"snippet_id": 47347, "code": " the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic,", "label": 0}, {"snippet_id": 4769, "code": " number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary", "label": 0}, {"snippet_id": 79896, "code": " requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex", "label": 0}, {"snippet_id": 2269, "code": " print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker']", "label": 0}, {"snippet_id": 85490, "code": " ScalaJarDependency(org='org.scala-sbt', name='compiler-bridge', rev=zinc_rev, classifier='sources', intransitive=True), ]) cls.register_jvm_tool(register, 'compiler-interface', classpath=[ JarDependency(org='org.scala", "label": 0}, {"snippet_id": 40671, "code": " annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained", "label": 0}, {"snippet_id": 73670, "code": "=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value", "label": 0}, {"snippet_id": 14553, "code": "): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request", "label": 0}, {"snippet_id": 37639, "code": ") for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance", "label": 0}, {"snippet_id": 20421, "code": " RuntimeError('could not connect') return sock return cls._create(connect, addr, **kwargs) @classmethod def create_server(cls, addr, **kwargs): def connect(addr, timeout): server=create_server(addr) with", "label": 0}, {"snippet_id": 13711, "code": ".exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals", "label": 0}, {"snippet_id": 47379, "code": " f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in", "label": 0}, {"snippet_id": 93322, "code": ".yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']:", "label": 0}, {"snippet_id": 89587, "code": "={}'.format(home_path, bin_path)) self._home=home_path self._bin_path=bin_path or(os.path.join(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version=_parse_java_version(\"minimum_version", "label": 0}, {"snippet_id": 1441, "code": "-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet. ", "label": 0}, {"snippet_id": 22978, "code": " found, but in my tests with 12.1.1 it will also find /dev/sr0 on occasion. This is NOT the correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists", "label": 0}, {"snippet_id": 70827, "code": " [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 92819, "code": ") for invalid in falsey: with self.assertRaises(InvalidZipPath): next(open_zip(invalid).gen) def test_open_zip_returns_realpath_on_badzipfile(self): with temporary_file() as not_zip: with temporary_dir", "label": 0}, {"snippet_id": 70457, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import ", "label": 0}, {"snippet_id": 82920, "code": ".validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t", "label": 1}, {"snippet_id": 31735, "code": ")] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output", "label": 0}, {"snippet_id": 43958, "code": ", dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False", "label": 0}, {"snippet_id": 73702, "code": "(value) return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name", "label": 0}, {"snippet_id": 60016, "code": " ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the ", "label": 0}, {"snippet_id": 23793, "code": ".format(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout={0}'.format(timeout)) if ret", "label": 0}, {"snippet_id": 20131, "code": "\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session", "label": 0}, {"snippet_id": 62073, "code": " statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit). user(string): IBM Quantum Experience user", "label": 0}, {"snippet_id": 85959, "code": "(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod def get_args_default(cls, bootstrap_option_values): return('-encoding',", "label": 0}, {"snippet_id": 61810, "code": "=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm", "label": 0}, {"snippet_id": 49491, "code": "): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list()", "label": 0}, {"snippet_id": 24563, "code": "['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2", "label": 0}, {"snippet_id": 91641, "code": "'requirements'): for py_req in maybe_python_req_lib.requirements: all_target_requirements.append(str(py_req.requirement)) all_requirements=sorted(all_target_requirements +list(pytest.get_requirement_strings()", "label": 0}, {"snippet_id": 55153, "code": " workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{", "label": 0}, {"snippet_id": 48218, "code": ": \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self", "label": 0}, {"snippet_id": 95016, "code": "=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\", metavar=\"RUN_LABEL\", help=\"Label", "label": 1}, {"snippet_id": 89147, "code": " \"\"\"Returns an iterator over the target(s) the given address points to. :API: public \"\"\" return self.build_graph.resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under", "label": 0}, {"snippet_id": 4957, "code": " return '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'):", "label": 0}, {"snippet_id": 59147, "code": ".backends.IBMBackend([use_hardware,...])\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for", "label": 0}, {"snippet_id": 94728, "code": "'validate', help=\"Validate the setup specified by the --config argument\") subparser_remote=subparsers.add_parser('slave', help=\"Run a component locally without controlling it. The \" \"control is taken care", "label": 0}, {"snippet_id": 48414, "code": " name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self", "label": 0}, {"snippet_id": 70003, "code": " just some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration", "label": 0}, {"snippet_id": 8692, "code": " as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger", "label": 1}, {"snippet_id": 5491, "code": "...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes", "label": 0}, {"snippet_id": 61919, "code": ", transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .. autosummary:: init_plugin Classes -", "label": 0}, {"snippet_id": 70185, "code": ", target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start", "label": 0}, {"snippet_id": 59788, "code": "(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable", "label": 0}, {"snippet_id": 81482, "code": "=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f) \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt:", "label": 0}, {"snippet_id": 11852, "code": ".get('X-Hub-Signature') if header_signature is None: abort(403) sha_name, signature=header_signature.split('=') if sha_name !='sha1': abort(501) mac=hmac.new(os.environ[\"GITHUB_PAYLOAD_SECRET\"].encode(", "label": 0}, {"snippet_id": 28233, "code": "], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle'", "label": 0}, {"snippet_id": 27885, "code": ")\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210:", "label": 0}, {"snippet_id": 64119, "code": " Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory=remote_job_config['outputs_directory'] configs_directory=remote_job_config['configs_directory'", "label": 0}, {"snippet_id": 71534, "code": "(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print", "label": 0}, {"snippet_id": 40373, "code": " in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs", "label": 0}, {"snippet_id": 80401, "code": " mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused", "label": 0}, {"snippet_id": 842, "code": " rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes", "label": 0}, {"snippet_id": 10499, "code": " is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio", "label": 1}, {"snippet_id": 41815, "code": " Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"", "label": 0}, {"snippet_id": 25592, "code": " self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] ", "label": 0}, {"snippet_id": 7921, "code": ".getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return", "label": 0}, {"snippet_id": 55890, "code": " message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate", "label": 0}, {"snippet_id": 34285, "code": ") return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 82704, "code": "\t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+", "label": 0}, {"snippet_id": 53072, "code": " files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run", "label": 0}, {"snippet_id": 90894, "code": " distribution that meets the given constraints and returns it. :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version", "label": 0}, {"snippet_id": 17012, "code": ") session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn", "label": 0}, {"snippet_id": 68305, "code": " AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, ", "label": 0}, {"snippet_id": 47642, "code": " always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( ", "label": 0}, {"snippet_id": 4981, "code": " :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean", "label": 0}, {"snippet_id": 79603, "code": ".basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\")", "label": 0}, {"snippet_id": 67728, "code": "(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>]", "label": 0}, {"snippet_id": 56029, "code": "=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir", "label": 0}, {"snippet_id": 58082, "code": " run.add_bug(bug_id=bug_id, bug_system_id=bug_system_id, bz_external_track=bz_external_track) else: bugs=Bug.objects.filter(bug_id__in=bug_ids) for run in runs: for bug in bugs: if bug.case_run_id==run", "label": 0}, {"snippet_id": 64768, "code": ".__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR", "label": 0}, {"snippet_id": 17701, "code": " running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n ", "label": 0}, {"snippet_id": 12443, "code": ", \"Line \") error_string_list=error_string.split(\" \") code=error_string_list[2] code_url=\"https://duckduckgo.com/?q=pep8%20{0}\".format(code) error_string_list[2]=\"[{0}]({1})\".format(code, code_url) line", "label": 0}, {"snippet_id": 23376, "code": ": super(FreeBSDOSUtil, self).__init__() self._scsi_disks_timeout_set=False def set_hostname(self, hostname): rc_file_path='/etc/rc.conf' conf_file=fileutil.read_file(rc_file_path).split(\"\\n\") textutil.set_ini_config", "label": 0}, {"snippet_id": 82798, "code": " \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not args.skipRecon: \tif len(args.legitExtensions) > 0: \t\tn=up.detectValidExtensions", "label": 0}, {"snippet_id": 78023, "code": ", user) def get_forum_id(name): id_=d.bm_id_forum.get_key(name) int(id_, 10) return id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not", "label": 0}, {"snippet_id": 26919, "code": " data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self", "label": 0}, {"snippet_id": 31332, "code": ".rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"", "label": 0}, {"snippet_id": 43080, "code": ".add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified", "label": 0}, {"snippet_id": 29161, "code": "\"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file", "label": 0}, {"snippet_id": 20372, "code": " as socket_timeout) from.threading import get_locked_and_waiter from.vsc import parse_message class DebugSessionConnection(Closeable): VERBOSE=False TIMEOUT=5.0 @classmethod def create_client(cls, addr", "label": 0}, {"snippet_id": 14882, "code": ") _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler", "label": 0}, {"snippet_id": 79389, "code": "\t \t\tr=self.session.get(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self", "label": 0}, {"snippet_id": 120, "code": ".append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0]", "label": 0}, {"snippet_id": 63945, "code": ", version_file=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution", "label": 1}, {"snippet_id": 88073, "code": ": raise TaskError('Plugin{} defined in{} and in{}'.format(name, active_plugins[name], classpath_element)) active_plugins[name]=rel_classpath_elements if len(active_plugins)==len(plugin_names): return active_plugins", "label": 0}, {"snippet_id": 65588, "code": ".nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None:", "label": 0}, {"snippet_id": 19427, "code": "-server-host HOST] --port PORT -m MODULE[arg...] {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT FILENAME[arg...] \"\"\" def parse_args(argv=None): \"\"\"Return the parsed args to use in main(", "label": 0}, {"snippet_id": 11455, "code": " hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config(self.source) if raw_yaml_config is None: raise SystemExit(\"Raw yaml config from source '%s' is 'None'.\" ", "label": 0}, {"snippet_id": 45222, "code": ", snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join", "label": 0}, {"snippet_id": 14852, "code": " requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses", "label": 0}, {"snippet_id": 48026, "code": " values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards", "label": 0}, {"snippet_id": 54274, "code": "=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the", "label": 0}, {"snippet_id": 89953, "code": " if self._jdk: logger.debug('Failed to validate javac executable. Please check you have a JDK ' 'installed. Original error:{}'.format(e)) raise def execute_java(self, *args, **kwargs): return execute_java", "label": 0}, {"snippet_id": 9023, "code": " reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines", "label": 0}, {"snippet_id": 22529, "code": " though, I would hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method. The problem is that", "label": 0}, {"snippet_id": 69578, "code": ") next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError", "label": 0}, {"snippet_id": 58214, "code": " from django.contrib.contenttypes.models import ContentType from django.core import serializers from django.urls import reverse from django_comments.models import Comment from tcms.management.models import", "label": 0}, {"snippet_id": 60342, "code": ".reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\"", "label": 0}, {"snippet_id": 29840, "code": "\"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError", "label": 1}, {"snippet_id": 13612, "code": " myText.find( \"twitter\") >=0):\r myText +=\"0\"\r myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions", "label": 0}, {"snippet_id": 37021, "code": "._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input", "label": 0}, {"snippet_id": 10421, "code": "(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default", "label": 0}, {"snippet_id": 84811, "code": ".6'), '2.11': major_version_info(full_version='2.11.12'), '2.12': major_version_info(full_version='2.12.4'), } scala_style_jar=JarDependency('org.scalastyle', 'scalastyle_2.11', '0.8.0') class ScalaPlatform", "label": 0}, {"snippet_id": 53852, "code": ".params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs)", "label": 0}, {"snippet_id": 17974, "code": "( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS", "label": 0}, {"snippet_id": 28623, "code": "'battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data", "label": 0}, {"snippet_id": 29922, "code": " filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in", "label": 0}, {"snippet_id": 2801, "code": " done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command", "label": 0}, {"snippet_id": 58649, "code": " 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response", "label": 0}, {"snippet_id": 68933, "code": " open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def", "label": 0}, {"snippet_id": 51586, "code": " or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern", "label": 0}, {"snippet_id": 77547, "code": ".debug('Loaded user %s:%s', domain, ud['login']) uq.put(ud) self.userqueues[domain]=uq except Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users(self): users={}", "label": 0}, {"snippet_id": 84217, "code": "-but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is no guarentee that it will contain all the datatypes available to this", "label": 0}, {"snippet_id": 10434, "code": "(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: ", "label": 0}, {"snippet_id": 40308, "code": "+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing", "label": 0}, {"snippet_id": 72256, "code": "' % args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text, **kwargs):", "label": 0}, {"snippet_id": 89103, "code": ") def dependents(self, on_predicate=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate to targets they depend on that satisfy the on_predicate. :API: public \"\"\" core", "label": 0}, {"snippet_id": 54567, "code": "=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self", "label": 0}, {"snippet_id": 61192, "code": " ket(*args): r\"\"\"Input validation for an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised array. \"\"\" state=np.asarray(args) return state/np.linalg.norm(state) def unitary", "label": 0}, {"snippet_id": 90895, "code": " that meets the given constraints and returns it. :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look", "label": 0}, {"snippet_id": 38678, "code": " list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun", "label": 0}, {"snippet_id": 52582, "code": "=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\"", "label": 0}, {"snippet_id": 30821, "code": " @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex),", "label": 0}, {"snippet_id": 31832, "code": " self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\"", "label": 0}, {"snippet_id": 46649, "code": " as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not", "label": 0}, {"snippet_id": 84558, "code": ".fs import FilesContent, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask from pants.util.contextutil import temporary_dir", "label": 0}, {"snippet_id": 42194, "code": " self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s", "label": 0}, {"snippet_id": 39885, "code": "(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can", "label": 0}, {"snippet_id": 59850, "code": "(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device.", "label": 0}, {"snippet_id": 45935, "code": ", format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value", "label": 0}, {"snippet_id": 68570, "code": "\" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS", "label": 0}, {"snippet_id": 58049, "code": "'runs']) bug_system_id=data['bug_system_id'] bug_ids=data['bugs'] try: validate_bug_id(bug_ids, bug_system_id) except ValidationError as e: return say_no(str(e)) bz_external_track=data['bz_external_track", "label": 0}, {"snippet_id": 12035, "code": " isinstance(value, list): arguments.append(\"--{}={}\".format(key, ','.join(value))) config[\"pycodestyle_cmd_config\"]='{arguments}'.format(arguments=' '.join(arguments)) config[\"pycodestyle\"][\"ignore\"]=[e.upper()", "label": 0}, {"snippet_id": 83400, "code": "(\"lwr job submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running", "label": 0}, {"snippet_id": 48233, "code": "-an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self)", "label": 0}, {"snippet_id": 31318, "code": "=other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule", "label": 0}, {"snippet_id": 85652, "code": " def compiler_interface(self): \"\"\"Return the path to the Zinc compiler-interface jar. :rtype: str \"\"\" return self._zinc_factory._compiler_interface(self._products) @memoized_method def snapshot(self, scheduler", "label": 0}, {"snippet_id": 38298, "code": " self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack", "label": 0}, {"snippet_id": 75973, "code": " if status==wzrpc.status.success: self.log.debug('Successfull auth for(%s, %s)', i, m) elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3", "label": 1}, {"snippet_id": 52000, "code": "._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key", "label": 0}, {"snippet_id": 92670, "code": "(path), 'Temporary dir should exist outside of context if cleanup=False.') shutil.rmtree(path) def test_temporary_dir_with_root_dir(self): with temporary_dir() as path1: with temporary_dir(root_dir=path1)", "label": 0}, {"snippet_id": 77245, "code": " while self.running.is_set(): try: try: proxypair=proxypairs.pop() except Exception: return self.proxylist.add(proxypair) for spawn in create_spawn(proxypair[0], proxypair[1], self.pc, self.get_userqueue", "label": 0}, {"snippet_id": 46412, "code": ".add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an", "label": 0}, {"snippet_id": 3760, "code": ".kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send", "label": 0}, {"snippet_id": 35548, "code": " cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance", "label": 0}, {"snippet_id": 83293, "code": ".__find_watched_job( job_id) if not job_state: sleep( 2) job_state=self.__find_watched_job( job_id) if not job_state: log.warn( \"Failed to find job corresponding to final status %s in %s\" %( full_status,", "label": 0}, {"snippet_id": 68981, "code": ".status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else:", "label": 1}, {"snippet_id": 5387, "code": "\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted", "label": 0}, {"snippet_id": 27093, "code": ".station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self.station_data.lastData(exclude", "label": 1}, {"snippet_id": 11018, "code": "(msg) def get_from_header(field): return response.headers[field] if field in response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag'", "label": 1}, {"snippet_id": 24720, "code": "'battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif", "label": 0}, {"snippet_id": 75884, "code": " p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0]) rslist.append(rs) msg=self.wz.make_req_msg", "label": 0}, {"snippet_id": 84820, "code": "'), } scala_style_jar=JarDependency('org.scalastyle', 'scalastyle_2.11', '0.8.0') class ScalaPlatform(JvmToolMixin, ZincLanguageMixin, InjectablesMixin, Subsystem): \"\"\"A scala platform. :API: public \"\"", "label": 0}, {"snippet_id": 67657, "code": " self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1:", "label": 0}, {"snippet_id": 55552, "code": ", os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def", "label": 0}, {"snippet_id": 60615, "code": ".eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name,", "label": 0}, {"snippet_id": 76669, "code": "'-C', action='store_true', help=\"Disables any requests in DataLoader(includes Witch)\") parser.add_argument('--no-shell', '-N', action='store_true', help=\"Sleep instead of starting the shell\") parser.add_argument", "label": 0}, {"snippet_id": 73510, "code": "(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=", "label": 0}, {"snippet_id": 91606, "code": "/v1.6.6/pex' digest=Digest('61bb79384db0da8c844678440bd368bcbfac17bbdb865721ad3f9cb0ab29b629', 1826945) pex_snapshot=yield Get(Snapshot, UrlToFetch(url, digest)) transitive_hydrated_targets=yield Get( TransitiveHydratedTargets", "label": 0}, {"snippet_id": 51919, "code": " def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end", "label": 0}, {"snippet_id": 56967, "code": ", 'int') ('5', None) 4. get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type", "label": 0}, {"snippet_id": 71786, "code": " print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help", "label": 0}, {"snippet_id": 8300, "code": ".escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\"", "label": 1}, {"snippet_id": 88397, "code": "(self, *msg_elements): self._run_tracker.log(Report.FATAL, *msg_elements) def __init__(self, options, run_tracker, target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser", "label": 0}, {"snippet_id": 20715, "code": ".send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter=self._get_awaiter_for_request(req, **args) self._conn.send(req) return resp_awaiter def add_handler(self, handler,", "label": 0}, {"snippet_id": 94034, "code": ": if \"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is", "label": 0}, {"snippet_id": 80488, "code": " found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies", "label": 0}, {"snippet_id": 88126, "code": ") if plugin_info.tag !='plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return plugin_info.find('name').text if os.path.isdir(classpath_element", "label": 0}, {"snippet_id": 7114, "code": "=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict", "label": 0}, {"snippet_id": 25618, "code": " self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360:", "label": 0}, {"snippet_id": 71851, "code": ".Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self", "label": 0}, {"snippet_id": 70095, "code": ", fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting", "label": 0}, {"snippet_id": 68960, "code": "%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info", "label": 1}, {"snippet_id": 46341, "code": " Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None,", "label": 0}, {"snippet_id": 32613, "code": " bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict", "label": 0}, {"snippet_id": 40685, "code": ".group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand", "label": 0}, {"snippet_id": 44576, "code": " resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources", "label": 0}, {"snippet_id": 14911, "code": " def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data,", "label": 0}, {"snippet_id": 69123, "code": ".CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from", "label": 0}, {"snippet_id": 88472, "code": "] self._console_outstream=console_outstream or sys.stdout self._scm=scm or get_scm() self._workspace=workspace or(ScmWorkspace(self._scm) if self._scm else None) self._replace_targets(target_roots) self", "label": 0}, {"snippet_id": 75824, "code": " self.wz timeout=timeout if timeout else self.wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) t.tick(", "label": 1}, {"snippet_id": 94898, "code": " config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the benchmark", "label": 1}, {"snippet_id": 8762, "code": " match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms ) if api: return output else:", "label": 0}, {"snippet_id": 82283, "code": " Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file", "label": 0}, {"snippet_id": 49826, "code": ".extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary", "label": 0}, {"snippet_id": 74560, "code": "=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz", "label": 0}, {"snippet_id": 75553, "code": "): if not reqid: reqid=self.make_reqid() args=[interface, method, struct.pack('!B', type_), make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-set-route-type', args, reqid) def make_auth_clear_data", "label": 0}, {"snippet_id": 69133, "code": " from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem", "label": 0}, {"snippet_id": 33816, "code": "._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation", "label": 0}, {"snippet_id": 14492, "code": "._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive():", "label": 0}, {"snippet_id": 50739, "code": " srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack", "label": 0}, {"snippet_id": 24179, "code": "', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 35291, "code": " wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default", "label": 0}, {"snippet_id": 84856, "code": ": return cls._create_jardep('scala-library', version) @classmethod def _create_compiler_jardep(cls, version): return cls._create_jardep('scala-compiler', version) @classmethod def _key_for_tool_version", "label": 1}, {"snippet_id": 43543, "code": "\"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name", "label": 0}, {"snippet_id": 37817, "code": " is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule", "label": 0}, {"snippet_id": 38136, "code": "(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0", "label": 0}, {"snippet_id": 76855, "code": "'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b'WZWorker', b'terminate']) for t in threading.enumerate(): if isinstance(t, threading", "label": 0}, {"snippet_id": 21597, "code": "[:,[2, 3]].values y=dataset.iloc[:, 4].values from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=0) from sklearn.preprocessing", "label": 0}, {"snippet_id": 41714, "code": " expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set(", "label": 1}, {"snippet_id": 50622, "code": ".priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile", "label": 0}, {"snippet_id": 42856, "code": ".temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output", "label": 0}, {"snippet_id": 54069, "code": " RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj", "label": 0}, {"snippet_id": 82303, "code": " type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php", "label": 0}, {"snippet_id": 8527, "code": " file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\"", "label": 1}, {"snippet_id": 78694, "code": "') return self.execute() except BaseException as e: log.logger.exception(e) if log.logger.getEffectiveLevel() <=logging.DEBUG: if os.getenv('UNITTEST', 'False')=='True': raise if self.options.trace: pdb", "label": 1}, {"snippet_id": 86302, "code": ".context.log.debug('Executing{}'.format(' '.join(javac_cmd))) p=subprocess.Popen(javac_cmd, stdout=workunit.output('stdout'), stderr=workunit.output('stderr')) return_code=p.wait() workunit.set_outcome", "label": 0}, {"snippet_id": 84019, "code": ".get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper", "label": 0}, {"snippet_id": 80935, "code": ",formUrl=None,formAction=None,inputName=None): \t\tself.logger=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself", "label": 0}, {"snippet_id": 2855, "code": "(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING", "label": 0}, {"snippet_id": 88043, "code": " in classpath: name=self._maybe_get_plugin_name(classpath_element) if name in plugin_names: plugin_target_closure=self._plugin_targets('scalac').get(name,[]) rel_classpath_elements=[ os.path.relpath(cpe,", "label": 0}, {"snippet_id": 77720, "code": "'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru' and", "label": 0}, {"snippet_id": 74086, "code": "(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between", "label": 0}, {"snippet_id": 71641, "code": "\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0:", "label": 0}, {"snippet_id": 10418, "code": " if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc", "label": 0}, {"snippet_id": 86422, "code": ", WorkUnitLabel.JVM), ) classes_directory=ctx.classes_dir self.context._scheduler.materialize_directories(( DirectoryToMaterialize(text_type(classes_directory), exec_result.output_directory_digest), ))", "label": 0}, {"snippet_id": 40985, "code": "(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item.", "label": 0}, {"snippet_id": 760, "code": " datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse", "label": 0}, {"snippet_id": 72811, "code": " import numpy as np import zarr import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for", "label": 1}, {"snippet_id": 7637, "code": "[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords", "label": 0}, {"snippet_id": 49148, "code": "=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 94800, "code": "\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug(\"Launching runner mode\") cc=ControlCenter(args.config", "label": 0}, {"snippet_id": 49815, "code": "-immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif", "label": 0}, {"snippet_id": 40582, "code": " AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError(", "label": 1}, {"snippet_id": 89077, "code": " synthetics.add(self.build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter(predicate, target_set)) def _collect_targets(self, root_targets", "label": 0}, {"snippet_id": 44538, "code": " benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes", "label": 0}, {"snippet_id": 31302, "code": ")) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def", "label": 0}, {"snippet_id": 68928, "code": " from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self", "label": 0}, {"snippet_id": 23501, "code": "'rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user(username): raise OSUtilError((\"User{0} is a system user", "label": 0}, {"snippet_id": 81403, "code": ".shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s", "label": 0}, {"snippet_id": 30101, "code": " class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict", "label": 0}, {"snippet_id": 78119, "code": " frames[2], frames[3:])) sig_sock.send_multipart(msg) def send_passthrough(frames): msg=[b'WipeManager'] msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames)) sig_sock.send_multipart(msg)", "label": 0}, {"snippet_id": 35438, "code": ".normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names", "label": 0}, {"snippet_id": 92791, "code": " 'test'), 'w', allowZip64=True) as zf: self.assertTrue(zf._allowZip64) def test_open_zipFalse(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=False)", "label": 0}, {"snippet_id": 20870, "code": "(match, handlername) return AwaitableResponse(req, lambda: result[\"msg\"], evt) @contextlib.contextmanager def wait_for_response(self, req, **kwargs): if self.closed: raise RuntimeError('session closed')", "label": 0}, {"snippet_id": 35405, "code": ".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns", "label": 0}, {"snippet_id": 35147, "code": "): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString", "label": 0}, {"snippet_id": 75710, "code": ".sleep_ticker=Ticker() self.poller=zmq.Poller() s=self.ctx.socket(zmq.SUB) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) s.connect(self.sig_addr) s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL')", "label": 0}, {"snippet_id": 81714, "code": "\t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren", "label": 0}, {"snippet_id": 70585, "code": ".fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support", "label": 0}, {"snippet_id": 16825, "code": ".path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data", "label": 0}, {"snippet_id": 50048, "code": ": scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False", "label": 0}, {"snippet_id": 80957, "code": "=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName \t\tself.uploadsFolder=uploadsFolder \t\tself", "label": 0}, {"snippet_id": 23095, "code": "\" self._wait_until_mcpd_is_initialized() return super(BigIpOSUtil, self).mount_dvd(**kwargs) def eject_dvd(self, chk_err=True): \"\"\"Runs the eject command to eject the provisioning DVD BIG-IP does not include", "label": 0}, {"snippet_id": 33518, "code": "\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess()", "label": 0}, {"snippet_id": 32124, "code": "._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of", "label": 0}, {"snippet_id": 19026, "code": "=definitions_validator(raw_schema, context=context) swagger_schema=swagger_schema_validator( raw_schema, context=swagger_definitions, ) return swagger_schema def load(target): \"\"\" Given one of the supported target formats", "label": 0}, {"snippet_id": 46920, "code": ".output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output", "label": 0}, {"snippet_id": 41472, "code": " res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set", "label": 0}, {"snippet_id": 12804, "code": "), encoding=r.encoding) py_files={} for patchset in patch: if patchset.target_file[-3:]=='.py': py_file=patchset.target_file[1:] py_files[py_file]=[] for hunk in patchset: for line in hunk.target_lines", "label": 0}, {"snippet_id": 48067, "code": "(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, *", "label": 0}, {"snippet_id": 60246, "code": " StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before", "label": 0}, {"snippet_id": 87611, "code": " zinc_relpath=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry", "label": 1}, {"snippet_id": 47241, "code": " None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files", "label": 0}, {"snippet_id": 94146, "code": ".session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave", "label": 0}, {"snippet_id": 87692, "code": " input_files=merged_input_digest, output_files=(analysis_cache,), output_directories=(classes_dir,), description=\"zinc compile for{}\".format(ctx.target.address.spec), jdk_home=text_type(self._zinc.dist.home),", "label": 0}, {"snippet_id": 5199, "code": "=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, ", "label": 0}, {"snippet_id": 40614, "code": ": \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected", "label": 0}, {"snippet_id": 38102, "code": " self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 ", "label": 0}, {"snippet_id": 45438, "code": " function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def", "label": 1}, {"snippet_id": 6331, "code": " This module is the main module of BibClassify. its two main methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs,", "label": 0}, {"snippet_id": 49962, "code": " cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will", "label": 0}, {"snippet_id": 52760, "code": " the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic,", "label": 0}, {"snippet_id": 85054, "code": "-RC1` would cause `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool('2.10') register_scala_repl_tool('2.10', with_jline=True) register_style_tool('2.10') register_scala_compiler_tool", "label": 0}, {"snippet_id": 72135, "code": " return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return except ValueError: irc.error('Invalid argument \"%s\" for <seconds>.' % seconds) return network.serverdata['autoconnect", "label": 0}, {"snippet_id": 65534, "code": " get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR", "label": 0}, {"snippet_id": 60932, "code": ": rename to circuits? Returns: dict[str->Circuit]: circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out @classmethod", "label": 0}, {"snippet_id": 81371, "code": "\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload", "label": 0}, {"snippet_id": 32975, "code": ".contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def", "label": 0}, {"snippet_id": 57695, "code": ".case_status, new_status.name ) ) update_object.update(**{str(self.target_field): self.new_value}) try: plan=plan_from_request_or_none(self.request) except Http404: return say_no(\"No plan record found.\") else:", "label": 0}, {"snippet_id": 82769, "code": " specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args", "label": 0}, {"snippet_id": 67607, "code": ".get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node,", "label": 0}, {"snippet_id": 62830, "code": ".kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self", "label": 0}, {"snippet_id": 33883, "code": ".append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os", "label": 0}, {"snippet_id": 51786, "code": " shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if", "label": 0}, {"snippet_id": 7187, "code": " kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\"", "label": 0}, {"snippet_id": 13724, "code": "-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals", "label": 0}, {"snippet_id": 36391, "code": ".append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing", "label": 0}, {"snippet_id": 10557, "code": " \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\"", "label": 1}, {"snippet_id": 27318, "code": " def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get", "label": 0}, {"snippet_id": 63452, "code": " return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params", "label": 0}, {"snippet_id": 6433, "code": " encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False", "label": 0}, {"snippet_id": 14689, "code": ".PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from", "label": 0}, {"snippet_id": 31914, "code": " \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output", "label": 0}, {"snippet_id": 12516, "code": " config[\"only_mention_files_with_errors\"] and not ERROR: comment_body.append(\"Cheers ! There are no PEP8 issues in this Pull Request.:beers: \") comment_body=''.join(comment_body) comment_footer=[] if request", "label": 0}, {"snippet_id": 78338, "code": " self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t, msg)) self.w.sleep(self.errortimeout) except exc.PermanentError", "label": 0}, {"snippet_id": 56100, "code": ".isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow", "label": 0}, {"snippet_id": 67557, "code": ", fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting", "label": 0}, {"snippet_id": 3625, "code": ")) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process terminated but check was", "label": 1}, {"snippet_id": 9340, "code": " acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires", "label": 0}, {"snippet_id": 29266, "code": " path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !", "label": 0}, {"snippet_id": 61238, "code": " if U.shape[0] !=U.shape[1]: raise ValueError(\"Operator must be a square matrix.\") if not np.allclose(U @ U.conj().T, np.identity(U.shape[0]), atol=tolerance): raise ValueError(\"Operator must be unitary", "label": 0}, {"snippet_id": 93817, "code": "['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'", "label": 0}, {"snippet_id": 90651, "code": "=_get_stricter_version(minimum_version, self._minimum_version, \"minimum_version\", max) maximum_version=_get_stricter_version(maximum_version, self._maximum_version, \"maximum_version\", min) key=(minimum_version", "label": 0}, {"snippet_id": 19663, "code": " required=True) target=parser.add_mutually_exclusive_group(required=True) target.add_argument('-m', dest='module') target.add_argument('filename', nargs='?') parser.add_argument('--single-session', action=", "label": 0}, {"snippet_id": 27974, "code": ".type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] ", "label": 0}, {"snippet_id": 31932, "code": " self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names(", "label": 0}, {"snippet_id": 95477, "code": "): remote_path_relative=\"/\".join(remote_subdirs_list) remote_path_absolute=\"/\" +remote_directory +\"/\" +remote_path_relative +\"/\" else: remote_subdirs_list=[] remote_path_relative=\"\" remote_path_absolute", "label": 0}, {"snippet_id": 27212, "code": " '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer", "label": 0}, {"snippet_id": 31123, "code": " self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 20117, "code": " \"\"\"A high-level abstraction of a debug client(i.e. editor).\"\"\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise", "label": 0}, {"snippet_id": 75957, "code": "]) rs.finished=True raise WorkerInterrupt() def auth_requests(self): for i, m in self.wz_auth_requests: def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Successfull", "label": 0}, {"snippet_id": 43865, "code": " if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule", "label": 0}, {"snippet_id": 63142, "code": "=self.__find_watched_job( job_id) if not job_state: log.warn( \"Failed to find job corresponding to final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state", "label": 1}, {"snippet_id": 28996, "code": "'rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status", "label": 0}, {"snippet_id": 63641, "code": " job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code)", "label": 0}, {"snippet_id": 35542, "code": " Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone", "label": 0}, {"snippet_id": 72538, "code": ".\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required", "label": 0}, {"snippet_id": 39485, "code": ".resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources", "label": 0}, {"snippet_id": 73841, "code": "(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else:", "label": 0}, {"snippet_id": 76369, "code": "(self, timeout): self.sleep_ticker.tick() self.poll(timeout * 1000) while self.sleep_ticker.elapsed(False) < timeout: try: self.poll(timeout * 1000) except Resume as e: return def poll(self, timeout=None):", "label": 1}, {"snippet_id": 93197, "code": "=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND", "label": 0}, {"snippet_id": 38475, "code": " rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules", "label": 0}, {"snippet_id": 95966, "code": " Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number", "label": 0}, {"snippet_id": 10521, "code": " else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf", "label": 1}, {"snippet_id": 30360, "code": " __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class", "label": 0}, {"snippet_id": 51000, "code": "{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException", "label": 0}, {"snippet_id": 29864, "code": " dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first", "label": 0}, {"snippet_id": 24813, "code": "\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 89600, "code": "._minimum_version=_parse_java_version(\"minimum_version\", minimum_version) self._maximum_version=_parse_java_version(\"maximum_version\", maximum_version) self._jdk=jdk self._is_jdk=False self._system_properties", "label": 0}, {"snippet_id": 34182, "code": " decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def", "label": 0}, {"snippet_id": 28572, "code": "'sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl':", "label": 0}, {"snippet_id": 65094, "code": " node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target", "label": 0}, {"snippet_id": 94458, "code": ".STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\"Check succeeded\")", "label": 0}, {"snippet_id": 38857, "code": "\"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock", "label": 0}, {"snippet_id": 36887, "code": " import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles", "label": 0}, {"snippet_id": 87690, "code": " input_files=merged_input_digest, output_files=(analysis_cache,), output_directories=(classes_dir,), description=\"zinc compile for{}\".format(ctx.target.address.spec), jdk_home=text_type(self._zinc.dist", "label": 0}, {"snippet_id": 35620, "code": " self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index)", "label": 0}, {"snippet_id": 52611, "code": "(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return", "label": 0}, {"snippet_id": 91874, "code": " PythonDistribution from pants.base.exceptions import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants", "label": 0}, {"snippet_id": 28153, "code": " DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None]", "label": 1}, {"snippet_id": 77388, "code": " kvargs={}): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock()", "label": 0}, {"snippet_id": 62128, "code": "='ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend", "label": 0}, {"snippet_id": 8375, "code": " the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\"", "label": 0}, {"snippet_id": 61706, "code": " subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U def expand_two(self, U, wires): \"\"\"Expand a two-qubit operator", "label": 0}, {"snippet_id": 17616, "code": " def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self", "label": 0}, {"snippet_id": 88468, "code": "=None self.requested_goals=requested_goals or[] self._console_outstream=console_outstream or sys.stdout self._scm=scm or get_scm() self._workspace=workspace or(ScmWorkspace(self._scm) if self._scm else", "label": 0}, {"snippet_id": 62713, "code": ". Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in", "label": 0}, {"snippet_id": 2570, "code": "'host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp[", "label": 0}, {"snippet_id": 16055, "code": "'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes", "label": 0}, {"snippet_id": 8233, "code": " import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener", "label": 1}, {"snippet_id": 60684, "code": " elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self._observe.params) elif self._observe.name", "label": 0}, {"snippet_id": 7170, "code": " spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don", "label": 0}, {"snippet_id": 57623, "code": ".target_field): self.new_value}) def _update_default_tester(self): try: user=User.objects.get(Q(username=self.new_value) | Q(email=self.new_value)) except User.DoesNotExist: raise ObjectDoesNotExist('Default", "label": 0}, {"snippet_id": 24624, "code": " data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\"", "label": 0}, {"snippet_id": 81024, "code": ".httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet", "label": 0}, {"snippet_id": 12602, "code": "\"pr_number\"])) comments=requests.get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body\"", "label": 0}, {"snippet_id": 93572, "code": "\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp", "label": 0}, {"snippet_id": 1739, "code": " cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect", "label": 0}, {"snippet_id": 51462, "code": ": raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and", "label": 0}, {"snippet_id": 54386, "code": ". \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp", "label": 0}, {"snippet_id": 48650, "code": "() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)", "label": 0}, {"snippet_id": 36151, "code": " in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode", "label": 0}, {"snippet_id": 40114, "code": " if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for", "label": 0}, {"snippet_id": 44118, "code": "), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self", "label": 0}, {"snippet_id": 34247, "code": " decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads", "label": 0}, {"snippet_id": 29421, "code": "._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self", "label": 0}, {"snippet_id": 69595, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class", "label": 0}, {"snippet_id": 25278, "code": "'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl", "label": 1}, {"snippet_id": 20817, "code": "._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result[\"msg\"], evt) def _get_awaiter_for_request(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq", "label": 0}, {"snippet_id": 49759, "code": " to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input", "label": 0}, {"snippet_id": 82452, "code": ") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args", "label": 0}, {"snippet_id": 17670, "code": " 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest", "label": 0}, {"snippet_id": 80805, "code": " stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t", "label": 0}, {"snippet_id": 14081, "code": " _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location,", "label": 0}, {"snippet_id": 53874, "code": " for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self", "label": 0}, {"snippet_id": 32423, "code": ".name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input", "label": 0}, {"snippet_id": 66723, "code": " error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s", "label": 1}, {"snippet_id": 65876, "code": ".append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) ", "label": 0}, {"snippet_id": 63050, "code": ": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination", "label": 0}, {"snippet_id": 15970, "code": ", headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data", "label": 1}, {"snippet_id": 50362, "code": ".version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo", "label": 0}, {"snippet_id": 30112, "code": " it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that", "label": 0}, {"snippet_id": 13442, "code": "\"head\": \"pep8speaks:{}\".format(data[\"new_branch\"]), \"base\": data[\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth", "label": 0}, {"snippet_id": 52577, "code": "(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return", "label": 0}, {"snippet_id": 69339, "code": " targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes", "label": 0}, {"snippet_id": 23111, "code": " command to eject the provisioning DVD BIG-IP does not include an eject command. It is sufficient to just umount the DVD disk. But I will log that we do not support this for future reference. :param chk_err:", "label": 0}, {"snippet_id": 57988, "code": ": %s)' % str(e)) data['bug_system_id']=int(request.GET.get('bug_system_id', 1)) if request.GET.get('a') not in('add', 'remove'): return(None, 'Actions only allow \"add\" and \"remove\".') else: data['action", "label": 0}, {"snippet_id": 22921, "code": " the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. We also don't use sudo, so we remove that method call as well. :param username: :return", "label": 0}, {"snippet_id": 26846, "code": "] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type", "label": 0}, {"snippet_id": 23287, "code": " 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using tmsh. :param net: :param mask: :param gateway: :return: \"\"\" cmd=(\"/usr/bin/tmsh create net route \" \"{0}/{1} gw{2}\").format(net", "label": 0}, {"snippet_id": 70774, "code": ",(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING", "label": 0}, {"snippet_id": 89422, "code": " ensuring basic constraints are met. For example a minimum version can be specified if you know need to compile source code or run bytecode that exercise features only available in that version forward", "label": 0}, {"snippet_id": 75380, "code": ".make_reqid() msg=make_req_msg(interface, method, args, reqid) self.set_response_handler(reqid, fun) return msg def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None): msg=iden[:]", "label": 0}, {"snippet_id": 22756, "code": " tmsh Since we are creating the user specified account and additionally changing the password of the built-in 'admin' account, both must be modified in this method. Note that the default method also checks", "label": 0}, {"snippet_id": 34542, "code": " follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod", "label": 0}, {"snippet_id": 947, "code": ".split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps", "label": 0}, {"snippet_id": 41940, "code": " the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill),", "label": 0}, {"snippet_id": 45822, "code": ": f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear", "label": 0}, {"snippet_id": 38099, "code": ".name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the", "label": 0}, {"snippet_id": 70209, "code": " node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info", "label": 0}, {"snippet_id": 35550, "code": " dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist", "label": 0}, {"snippet_id": 23241, "code": " returned more than{0} up ' 'network interfaces.'), expected) sock=buff.tostring() for i in range(0, struct_size * expected, struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface:", "label": 0}, {"snippet_id": 36876, "code": " K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile", "label": 0}, {"snippet_id": 28458, "code": "\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of", "label": 0}, {"snippet_id": 55405, "code": "+provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info(", "label": 0}, {"snippet_id": 71129, "code": " STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s", "label": 0}, {"snippet_id": 43, "code": " BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d,", "label": 1}, {"snippet_id": 43141, "code": ", concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException)", "label": 0}, {"snippet_id": 11088, "code": ", mtime=0): self.etag=etag self.mtime=int(mtime) def __nonzero__(self): return self.etag is None and self.mtime is 0 def __eq__(self, other): return self.etag==other.etag and self.mtime==other.mtime def", "label": 0}, {"snippet_id": 50346, "code": "(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule", "label": 0}, {"snippet_id": 54631, "code": ": for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno", "label": 0}, {"snippet_id": 43562, "code": " reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards", "label": 0}, {"snippet_id": 50488, "code": " benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo", "label": 0}, {"snippet_id": 78698, "code": " except BaseException as e: log.logger.exception(e) if log.logger.getEffectiveLevel() <=logging.DEBUG: if os.getenv('UNITTEST', 'False')=='True': raise if self.options.trace: pdb.post_mortem(sys.exc_info()[2", "label": 1}, {"snippet_id": 54163, "code": " output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:", "label": 0}, {"snippet_id": 63873, "code": ".job_destination=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states", "label": 0}, {"snippet_id": 95547, "code": "\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory", "label": 0}, {"snippet_id": 72746, "code": "); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic", "label": 1}, {"snippet_id": 47727, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError", "label": 0}, {"snippet_id": 5930, "code": " documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine", "label": 0}, {"snippet_id": 30984, "code": " @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested", "label": 0}, {"snippet_id": 8923, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined into", "label": 1}, {"snippet_id": 85460, "code": " Shader.exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-compiler_2.11', '0.0", "label": 1}, {"snippet_id": 95442, "code": "(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"\" Recursive function", "label": 0}, {"snippet_id": 84044, "code": ".Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states", "label": 0}, {"snippet_id": 78244, "code": " self.msgfun())) if len(self.targets)==0: self.schedule(self.scan_targets_loop) else: self.schedule(self.comment_loop) def add_comment(self, t, msg): if True: try: self.postmsg(t[1], msg, t[0]) except exc", "label": 0}, {"snippet_id": 48178, "code": ".dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise", "label": 0}, {"snippet_id": 67396, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) return result", "label": 1}, {"snippet_id": 78955, "code": ".\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit", "label": 0}, {"snippet_id": 87341, "code": "._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self.get_options().pants_bootstrapdir", "label": 1}, {"snippet_id": 45265, "code": ".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable", "label": 0}, {"snippet_id": 32886, "code": "._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[", "label": 0}, {"snippet_id": 9952, "code": "\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms", "label": 0}, {"snippet_id": 15026, "code": " def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes'", "label": 0}, {"snippet_id": 82458, "code": "\tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not", "label": 0}, {"snippet_id": 1315, "code": " entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn", "label": 1}, {"snippet_id": 39587, "code": " return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo", "label": 0}, {"snippet_id": 7692, "code": " expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return", "label": 0}, {"snippet_id": 94056, "code": " node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex", "label": 0}, {"snippet_id": 9682, "code": " def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw", "label": 0}, {"snippet_id": 90975, "code": " os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS can be", "label": 0}, {"snippet_id": 75865, "code": ".finished=False rs.retry=False continue return elapsed=t.elapsed(False) if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t", "label": 0}, {"snippet_id": 31236, "code": "\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name", "label": 0}, {"snippet_id": 95172, "code": ".read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def", "label": 0}, {"snippet_id": 34226, "code": "(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self", "label": 0}, {"snippet_id": 46082, "code": " if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic", "label": 0}, {"snippet_id": 93639, "code": " node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name", "label": 0}, {"snippet_id": 20521, "code": " for msg, _, _ in read_messages(read, stop=stop): if self.VERBOSE: print(repr(msg)) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection closed') def stop(): return", "label": 0}, {"snippet_id": 44234, "code": " the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no", "label": 0}, {"snippet_id": 51992, "code": " end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key", "label": 0}, {"snippet_id": 57580, "code": "._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context) except", "label": 0}, {"snippet_id": 64971, "code": " from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies", "label": 0}, {"snippet_id": 57160, "code": "*ctype.split(\".\", 1)) targets=model._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype", "label": 0}, {"snippet_id": 13109, "code": ": data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 69678, "code": " %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print ", "label": 0}, {"snippet_id": 66585, "code": ".CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from", "label": 0}, {"snippet_id": 50625, "code": "=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile", "label": 0}, {"snippet_id": 14300, "code": " tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter", "label": 1}, {"snippet_id": 59951, "code": " is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key", "label": 0}, {"snippet_id": 23535, "code": " cmd=\"echo '{0}'|pw usermod{1} -H 0 \".format(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret !=0: raise OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format", "label": 0}, {"snippet_id": 75604, "code": " WorkerInterrupt(Exception): '''Exception to raise when self.running is cleared''' def __init__(self): super().__init__('Worker was interrupted at runtime') class Suspend(Exception): '''Exception to raise", "label": 0}, {"snippet_id": 41369, "code": " import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from", "label": 1}, {"snippet_id": 14085, "code": ".raise_for_status() if response.text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(", "label": 0}, {"snippet_id": 19610, "code": "-session',): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv): parser", "label": 1}, {"snippet_id": 6972, "code": " list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\"", "label": 0}, {"snippet_id": 3086, "code": "(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1'", "label": 0}, {"snippet_id": 23539, "code": " 0 \".format(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret !=0: raise OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format(username, output)) def del_root_password", "label": 0}, {"snippet_id": 16870, "code": "': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True", "label": 0}, {"snippet_id": 1261, "code": "'nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append", "label": 0}, {"snippet_id": 52827, "code": " corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict(", "label": 0}, {"snippet_id": 23050, "code": " containing the provisioningiso.iso file This is the _first_ hook that WAAgent provides for us, so this is the point where we should wait for mcpd to load. I am just overloading this method to add the mcpd wait.", "label": 0}, {"snippet_id": 39804, "code": " def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None:", "label": 0}, {"snippet_id": 39917, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools", "label": 0}, {"snippet_id": 42697, "code": ".items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark", "label": 0}, {"snippet_id": 67375, "code": " filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if", "label": 0}, {"snippet_id": 14050, "code": ", 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data", "label": 0}, {"snippet_id": 17349, "code": "=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles", "label": 0}, {"snippet_id": 22884, "code": ".run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin':{0}\".format(output) ) self._save_sys_config() return ret def del_account(self, username): ", "label": 0}, {"snippet_id": 72228, "code": " a command to the local network; use a normal command!\") return try: remoteirc=world.networkobjects[netname] except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return if args", "label": 0}, {"snippet_id": 76393, "code": " try: socks=dict(self.poller.poll(timeout if timeout !=None else self.poll_timeout)) except zmq.ZMQError as e: self.log.error(e) return if socks.get(self.sig_sock)==zmq.POLLIN: frames=self.sig_sock.recv_multipart", "label": 1}, {"snippet_id": 35296, "code": "-first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with", "label": 0}, {"snippet_id": 62241, "code": " expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=[x.val if isinstance(x,", "label": 0}, {"snippet_id": 17382, "code": "/localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self", "label": 0}, {"snippet_id": 2677, "code": " and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=", "label": 0}, {"snippet_id": 80459, "code": "=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions", "label": 0}, {"snippet_id": 62066, "code": "(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered", "label": 0}, {"snippet_id": 37775, "code": " list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_", "label": 0}, {"snippet_id": 47842, "code": ".message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output", "label": 0}, {"snippet_id": 37969, "code": ".products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno", "label": 0}, {"snippet_id": 24191, "code": "], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24", "label": 0}, {"snippet_id": 21882, "code": ".display import Display from dciclient.v1 import helper as dci_helper from dciagent.plugins import plugin import jinja2 import os import subprocess display=Display() class Options(object): def __init__", "label": 1}, {"snippet_id": 31916, "code": " output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not", "label": 0}, {"snippet_id": 54470, "code": ".parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from", "label": 1}, {"snippet_id": 63063, "code": "\"\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager", "label": 0}, {"snippet_id": 65823, "code": " lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets", "label": 0}, {"snippet_id": 9619, "code": "=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience),", "label": 0}, {"snippet_id": 30742, "code": "._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf", "label": 0}, {"snippet_id": 94315, "code": " else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit", "label": 0}, {"snippet_id": 77761, "code": "',[])) if hasattr(self, 'th_sock'): self.th_sock.send_multipart(msg) if hasattr(self, 'pr_sock'): self.pr_sock.send_multipart(msg) def join_threads(self): for t in self.threads: t.join() def send_passthrough", "label": 0}, {"snippet_id": 54750, "code": "(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger", "label": 0}, {"snippet_id": 57164, "code": "=model._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0", "label": 0}, {"snippet_id": 78729, "code": ".options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request", "label": 0}, {"snippet_id": 91466, "code": "=IsortRun).install('fmt') task(name='py', action=PythonBundle).install('bundle') task(name='unpack-wheels', action=UnpackWheels).install() def rules(): return inject_init.rules() +python_test_runner.rules(", "label": 1}, {"snippet_id": 22471, "code": " shellutil.run(\"/sbin/service waagent start\", chk_err=False) def register_agent_service(self): return shellutil.run(\"/sbin/chkconfig --add waagent\", chk_err=False) def unregister_agent_service(self): return", "label": 0}, {"snippet_id": 70420, "code": " status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global", "label": 0}, {"snippet_id": 89095, "code": ", **kwargs): return Target.closure_for_targets( target_roots=root_targets, **kwargs ) def dependents(self, on_predicate=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate", "label": 0}, {"snippet_id": 19880, "code": " raise RuntimeError('debugger not running') if self._session is not None: self._detach() try: self._adapter.close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self", "label": 0}, {"snippet_id": 79862, "code": " template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group('Required named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help", "label": 0}, {"snippet_id": 74435, "code": ".optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))}", "label": 0}, {"snippet_id": 41359, "code": "\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import", "label": 0}, {"snippet_id": 59576, "code": ": \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and", "label": 0}, {"snippet_id": 5878, "code": "(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in", "label": 0}, {"snippet_id": 50912, "code": ": return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os", "label": 0}, {"snippet_id": 93423, "code": " dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '%s'!\" %(dep, node.comp_name)) if exit_on_fail: exit(1", "label": 0}, {"snippet_id": 47600, "code": " class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self", "label": 0}, {"snippet_id": 10550, "code": "'pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ", "label": 0}, {"snippet_id": 41939, "code": " when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill", "label": 0}, {"snippet_id": 63799, "code": " pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID", "label": 0}, {"snippet_id": 11871, "code": ".encode(), msg=request.data, digestmod=\"sha1\") if not hmac.compare_digest(str(mac.hexdigest()), str(signature)): abort(403) return True def check_pythonic_pr(data): \"\"\" Return True if the PR contains at", "label": 0}, {"snippet_id": 9117, "code": ">,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite", "label": 0}, {"snippet_id": 85199, "code": " then the version specified in ' '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would use the suffix version \"2.10\".') elif name.endswith(self.version): raise ValueError('The name \"{0", "label": 0}, {"snippet_id": 7320, "code": "\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output", "label": 0}, {"snippet_id": 85987, "code": "(cls): return('-nowarn', '-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-Werror',) @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod", "label": 0}, {"snippet_id": 33791, "code": "\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not", "label": 0}, {"snippet_id": 29001, "code": "=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 71073, "code": "(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header", "label": 0}, {"snippet_id": 18424, "code": " not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def", "label": 0}, {"snippet_id": 51385, "code": " not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance", "label": 0}, {"snippet_id": 12753, "code": "=comment.format(time_now) query=\"https://api.github.com/repos/{}/issues/comments/{}\" query=query.format(data[\"repository\"], str(last_comment_id)) response=requests.patch(query, json={\"body\": comment}, headers", "label": 0}, {"snippet_id": 27956, "code": "] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status']", "label": 0}, {"snippet_id": 56880, "code": " query set, containing the Tag->Object relationship, ordered by tag and annotated by key e.g. TestPlanTag, TestCaseTag ot TestRunTag :type test_tags: QuerySet \"\"\" self.key=key self.test_tags=iter(test_tags", "label": 0}, {"snippet_id": 12802, "code": " patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) py_files={} for patchset in patch: if patchset.target_file[-3:]=='.py': py_file=patchset.target_file[1:] py_files[py_file]=[] for hunk", "label": 0}, {"snippet_id": 65218, "code": "-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK,", "label": 0}, {"snippet_id": 28803, "code": "'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 78629, "code": "'dbexec': 'executer', 'dbexport': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try: sys.stdout", "label": 0}, {"snippet_id": 55777, "code": " ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule", "label": 0}, {"snippet_id": 22000, "code": " self.new_vault_password_file=new_vault_password_file self.output_file=output_file self.tags=tags self.skip_tags=skip_tags self.one_line=one_line self.tree=tree self.ask_sudo_pass=ask_sudo_pass self.ask_su_pass", "label": 0}, {"snippet_id": 33545, "code": " f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster", "label": 0}, {"snippet_id": 37384, "code": ".wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items", "label": 0}, {"snippet_id": 41725, "code": ": \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_", "label": 0}, {"snippet_id": 18420, "code": " SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate(", "label": 0}, {"snippet_id": 58394, "code": "-views-index')) self.assertRedirects( response, reverse('tcms-recent', args=[self.tester.username]), target_status_code=HTTPStatus.OK) class TestCommentCaseRuns(BaseCaseRun): \"\"\"Test case for ajax.comment_case_runs", "label": 0}, {"snippet_id": 93245, "code": "] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug", "label": 0}, {"snippet_id": 22045, "code": ".ssh_extra_args=ssh_extra_args self.poll_interval=poll_interval self.seconds=seconds self.check=check self.syntax=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache=flush_cache self", "label": 0}, {"snippet_id": 137, "code": " list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password", "label": 0}, {"snippet_id": 83710, "code": " stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state(job_state) run_results=client.full_status() stdout=run_results.get('stdout', '') stderr=run_results.get('stderr', '", "label": 0}, {"snippet_id": 35043, "code": "(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False", "label": 0}, {"snippet_id": 68698, "code": " dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag", "label": 0}, {"snippet_id": 83222, "code": "\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager, 'ensure_has_status_update_callback'", "label": 0}, {"snippet_id": 83796, "code": "\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code", "label": 0}, {"snippet_id": 77670, "code": ".log.debug('Domain set was loaded') domains.update(data['domains']) if 'sets' in data: self.log.debug('Other sets were loaded') self.pc.sets.update(data['sets']) def load_bumplimit_set(self): if not os", "label": 0}, {"snippet_id": 62496, "code": "([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend", "label": 0}, {"snippet_id": 16492, "code": ") return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self)", "label": 0}, {"snippet_id": 35408, "code": ")) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values", "label": 0}, {"snippet_id": 26599, "code": "=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\"", "label": 0}, {"snippet_id": 6791, "code": "=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords))", "label": 0}, {"snippet_id": 75281, "code": ")] except KeyError: try: handler=self.req_handlers[(interface, None)] except KeyError: raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value", "label": 0}, {"snippet_id": 90604, "code": " used. :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution", "label": 0}, {"snippet_id": 61588, "code": " A.params] return operator_map[A.name](*p) def ev(self, A, wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable", "label": 0}, {"snippet_id": 34536, "code": " WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks", "label": 1}, {"snippet_id": 10321, "code": "\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords", "label": 0}, {"snippet_id": 69048, "code": " RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel", "label": 0}, {"snippet_id": 36589, "code": ":\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables", "label": 0}, {"snippet_id": 30437, "code": ". Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError", "label": 0}, {"snippet_id": 19774, "code": "\nfrom __future__ import absolute_import import os import traceback import warnings from ptvsd.socket import Address from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.debugadapter import", "label": 0}, {"snippet_id": 87738, "code": " args=zinc_args, workunit_name=self.name(), workunit_labels=[WorkUnitLabel.COMPILER], dist=self._zinc.dist): raise TaskError('Zinc compile failed.') def _verify_zinc_classpath(self, classpath, allow_dist", "label": 0}, {"snippet_id": 65068, "code": "), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self", "label": 0}, {"snippet_id": 30447, "code": " except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath", "label": 0}, {"snippet_id": 19678, "code": " action='store_true') parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None) clienthost=ns", "label": 0}, {"snippet_id": 61814, "code": ".prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1])", "label": 0}, {"snippet_id": 35190, "code": "\"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): ", "label": 0}, {"snippet_id": 20000, "code": " is not None if not self._session.is_client: raise RuntimeError('detach not supported') self._detach() def _close(self): if self._session is not None: try: self._session.close() except ClosedError: pass", "label": 0}, {"snippet_id": 42193, "code": "() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced", "label": 0}, {"snippet_id": 90055, "code": "}:{}'.format(java, ' '.join(cmd), process.returncode, stderr.decode('utf-8'))) props={} for line in stdout.decode('utf-8').split(os.linesep): key, _, val=line.partition('=') props[key]=val self._system_properties", "label": 0}, {"snippet_id": 40741, "code": " combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable", "label": 0}, {"snippet_id": 20432, "code": "(cls, addr, **kwargs): def connect(addr, timeout): server=create_server(addr) with socket_timeout(server, timeout): client, _=server.accept() return Connection(client, server) return cls._create(connect", "label": 0}, {"snippet_id": 28942, "code": "%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength", "label": 0}, {"snippet_id": 91375, "code": " def register_goals(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local-dists', action=BuildLocalPythonDistributions).install('pyprep') task(name='requirements'", "label": 0}, {"snippet_id": 26301, "code": " vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }", "label": 0}, {"snippet_id": 58227, "code": " from django_comments.models import Comment from tcms.management.models import Priority from tcms.management.models import EnvGroup from tcms.management.models import EnvProperty from tcms.testcases.forms", "label": 1}, {"snippet_id": 10261, "code": "\"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1", "label": 0}, {"snippet_id": 28103, "code": " at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant", "label": 1}, {"snippet_id": 29259, "code": "(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir", "label": 0}, {"snippet_id": 45743, "code": ".path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep", "label": 0}, {"snippet_id": 22692, "code": ". We do not use this value. \"\"\" if self.get_userentry(username): logger.info(\"User{0} already exists, skip useradd\", username) return None cmd=\"/usr/bin/tmsh create auth user %s partition-access add{ all", "label": 0}, {"snippet_id": 5209, "code": "(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text format. :return: str", "label": 0}, {"snippet_id": 33472, "code": " not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info", "label": 0}, {"snippet_id": 46495, "code": " for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items", "label": 0}, {"snippet_id": 54117, "code": " o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_", "label": 0}, {"snippet_id": 84248, "code": "( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration(self, client, job_wrapper, remote_metadata, remote_job_config", "label": 0}, {"snippet_id": 63340, "code": ".__remote_metadata( client) remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client", "label": 0}, {"snippet_id": 70300, "code": " FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR", "label": 0}, {"snippet_id": 15818, "code": ") def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data):", "label": 0}, {"snippet_id": 95196, "code": " data from the server, runs the benchmarks, and records the timer results. \"\"\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static", "label": 1}, {"snippet_id": 31331, "code": ".rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): ", "label": 0}, {"snippet_id": 61731, "code": " a two-qubit operator into a full system operator. Args: U(array): 4x4 matrix wires(Sequence[int]): two target subsystems(order matters!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError", "label": 0}, {"snippet_id": 70150, "code": " \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc", "label": 0}, {"snippet_id": 80055, "code": "-threads\",metavar=\"Threads\",nargs=1,dest=\"nbThreads\",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs", "label": 0}, {"snippet_id": 32447, "code": " wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self", "label": 0}, {"snippet_id": 41424, "code": " self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards", "label": 0}, {"snippet_id": 34074, "code": "=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers", "label": 0}, {"snippet_id": 30130, "code": ". Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend", "label": 0}, {"snippet_id": 6750, "code": " reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines", "label": 0}, {"snippet_id": 78194, "code": "=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets) super().__init__(*args, **kvargs) def on_caprate_limit", "label": 0}, {"snippet_id": 69047, "code": " TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self", "label": 0}, {"snippet_id": 44578, "code": "\" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info", "label": 0}, {"snippet_id": 81679, "code": "\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]", "label": 0}, {"snippet_id": 45092, "code": "(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate", "label": 0}, {"snippet_id": 60956, "code": " of the plugin. Measurements, batching etc. Returns: dict[str->*]: results \"\"\" return cls._capabilities @abc.abstractmethod def execute(self): \"\"\"Apply the queued operations to the device, and measure the", "label": 1}, {"snippet_id": 34452, "code": ".path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for", "label": 0}, {"snippet_id": 26683, "code": " self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium", "label": 0}, {"snippet_id": 60536, "code": " device for OpenQML. wires(int): the number of modes to initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\"", "label": 0}, {"snippet_id": 9065, "code": " composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors", "label": 0}, {"snippet_id": 88542, "code": " \"\"\" return self._source_roots @property def target_roots(self): \"\"\"Returns the targets specified on the command line. This set is strictly a subset of all targets in play for the run as returned by self", "label": 0}, {"snippet_id": 64947, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand", "label": 0}, {"snippet_id": 11109, "code": ".mtime==other.mtime def __repr__(self): return \"Header(%s, %d)\" %(self.etag, self.mtime) def is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self.mtime, other.mtime) ", "label": 0}, {"snippet_id": 42727, "code": " \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput", "label": 0}, {"snippet_id": 95235, "code": " results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib import allel import sys import functools import numpy as np", "label": 0}, {"snippet_id": 1907, "code": "=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data", "label": 0}, {"snippet_id": 71348, "code": "\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column", "label": 0}, {"snippet_id": 13183, "code": "=requests.patch(url, data=json.dumps(request_json), headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https:", "label": 0}, {"snippet_id": 66273, "code": " AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\",", "label": 0}, {"snippet_id": 81162, "code": " upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not", "label": 0}, {"snippet_id": 85972, "code": " return('-encoding', 'UTF-8') @classmethod def get_warning_args_default(cls): return('-deprecation', '-Xlint:all', '-Xlint:-serial', '-Xlint:-path') @classmethod def get_no_warning_args_default(cls): return", "label": 0}, {"snippet_id": 11716, "code": " abort def update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: query=r\"INSERT INTO Users(repository, created_at) VALUES", "label": 0}, {"snippet_id": 16168, "code": " import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import", "label": 0}, {"snippet_id": 43693, "code": " self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 16516, "code": " GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for", "label": 0}, {"snippet_id": 47360, "code": ") if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self", "label": 0}, {"snippet_id": 80297, "code": ": \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point", "label": 0}, {"snippet_id": 6532, "code": " filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines", "label": 0}, {"snippet_id": 17062, "code": " def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return", "label": 0}, {"snippet_id": 70494, "code": ".Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=", "label": 0}, {"snippet_id": 33340, "code": " targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity,", "label": 0}, {"snippet_id": 56712, "code": " request): \"\"\" :param request: An HTTP GET request, containing the primary key and the type of object to be selected :type request: HttpRequest \"\"\" for obj in['plan', 'case', 'run']: if request.GET.get(obj):", "label": 0}, {"snippet_id": 58364, "code": ".get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-login'), target_status_code=HTTPStatus.OK) def test_when_logged_in_index_page_redirects_to_dashboard(self): self.client.login", "label": 0}, {"snippet_id": 38489, "code": " self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule", "label": 0}, {"snippet_id": 10013, "code": ".output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches", "label": 0}, {"snippet_id": 23442, "code": " username) return if expiration is not None: cmd=\"pw useradd{0} -e{1} -m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode", "label": 0}, {"snippet_id": 1689, "code": "(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username", "label": 0}, {"snippet_id": 51772, "code": " def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist", "label": 0}, {"snippet_id": 62619, "code": ": \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items", "label": 0}, {"snippet_id": 20710, "code": " if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter=self._get_awaiter_for_request(req, **args) self._conn", "label": 0}, {"snippet_id": 16139, "code": " ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers", "label": 0}, {"snippet_id": 73109, "code": " fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp=ftp", "label": 0}, {"snippet_id": 59692, "code": "): \"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has", "label": 0}, {"snippet_id": 226, "code": "\"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname", "label": 0}, {"snippet_id": 31102, "code": ".intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output))", "label": 0}, {"snippet_id": 17013, "code": "=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn(", "label": 0}, {"snippet_id": 91997, "code": "(self): return{ SubclassesOf(PythonDistribution): self.pydist_has_native_sources, SubclassesOf(NativeLibrary): NativeLibrary.produces_ctypes_native_library, } def _any_targets_have_native_sources(self,", "label": 0}, {"snippet_id": 36825, "code": " shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(", "label": 0}, {"snippet_id": 84567, "code": ".isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask from pants.util.contextutil import temporary_dir class CountLinesOfCode(ConsoleTask): \"\"\"Print counts of lines of code.", "label": 0}, {"snippet_id": 85437, "code": " cls).register_options(register) zinc_rev='1.0.3' shader_rules=[ Shader.exclude_package('scala', recursive=True), Shader.exclude_package('xsbt', recursive=True), Shader.exclude_package('xsbti', recursive", "label": 0}, {"snippet_id": 71325, "code": ", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i", "label": 0}, {"snippet_id": 92162, "code": "(BuildSetupRequiresPex, cls).register_options(register) register('--setuptools-version', advanced=True, fingerprint=True, default='40.6.3', help='The setuptools version to use when executing `setup.py`", "label": 0}, {"snippet_id": 38999, "code": " updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True", "label": 0}, {"snippet_id": 25701, "code": "'battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 91672, "code": "', 'pytest:main', '-o', output_pytest_requirements_pex_filename, ] +interpreter_constraint_args +[ text_type(req) for req in all_requirements ] requirements_pex_request=ExecuteProcessRequest( argv=tuple", "label": 0}, {"snippet_id": 12358, "code": " the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: if config[\"message\"][\"updated\"][\"header\"]==\"\": comment_header", "label": 0}, {"snippet_id": 43283, "code": ".params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards", "label": 0}, {"snippet_id": 19050, "code": "'s python representation. \"\"\" raw_schema=load_source(target) return parse(raw_schema) def validate(raw_schema, target=None, **kwargs): \"\"\" Given the python representation of a JSONschema as defined in the", "label": 0}, {"snippet_id": 60306, "code": "'} _circuits={} def __init__(self, wires, *, shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def", "label": 1}, {"snippet_id": 29019, "code": " data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class", "label": 0}, {"snippet_id": 73552, "code": " number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length", "label": 0}, {"snippet_id": 76847, "code": ".rp_timeout d=DataLoader(noproxy_rp, c.only_cache) c.router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL", "label": 0}, {"snippet_id": 56108, "code": ")) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag)", "label": 0}, {"snippet_id": 13162, "code": "=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json={ \"name\": name, \"description\": \"Forked from @{}'s{}\".format(author,", "label": 0}, {"snippet_id": 93339, "code": ".error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group", "label": 0}, {"snippet_id": 34970, "code": " None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match", "label": 0}, {"snippet_id": 48152, "code": " output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self", "label": 0}, {"snippet_id": 1488, "code": " print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({\"STATUS\":\"SUCCESS\"", "label": 0}, {"snippet_id": 61, "code": " d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n", "label": 0}, {"snippet_id": 46917, "code": ".subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule", "label": 0}, {"snippet_id": 86366, "code": ".format(plugin, ' '.join(args))) return ret def _execute_hermetic_compile(self, cmd, ctx): input_snapshot=ctx.target.sources_snapshot(scheduler=self.context._scheduler) output_files=tuple( os.path.relpath", "label": 0}, {"snippet_id": 25602, "code": "'battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif", "label": 0}, {"snippet_id": 931, "code": "\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split", "label": 0}, {"snippet_id": 16905, "code": " def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data,", "label": 0}, {"snippet_id": 12611, "code": "=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body\"] break \"\"\" text1=''.join(BeautifulSoup(markdown(comment)).findAll(text=True)) text2=''", "label": 0}, {"snippet_id": 24950, "code": "%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength", "label": 0}, {"snippet_id": 75514, "code": "', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method", "label": 0}, {"snippet_id": 79207, "code": "()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group", "label": 0}, {"snippet_id": 52901, "code": ") def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self", "label": 0}, {"snippet_id": 4323, "code": " extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.", "label": 1}, {"snippet_id": 14362, "code": ".append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen", "label": 0}, {"snippet_id": 85560, "code": ".options_scope) def create(self, products): \"\"\"Create a Zinc instance from products active in the current Pants run. :param products: The active Pants run products to pluck classpaths from. :type products", "label": 0}, {"snippet_id": 93501, "code": " self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style", "label": 0}, {"snippet_id": 40438, "code": " occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint", "label": 0}, {"snippet_id": 55775, "code": ".version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo", "label": 0}, {"snippet_id": 91351, "code": " 'python_requirement_library': PythonRequirementLibrary, Resources.alias(): Resources, UnpackedWheels.alias(): UnpackedWheels, }, objects={ 'python_requirement': PythonRequirement, 'python_artifact': PythonArtifact", "label": 0}, {"snippet_id": 71521, "code": "\"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print", "label": 0}, {"snippet_id": 66303, "code": " AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\",", "label": 0}, {"snippet_id": 71622, "code": ", fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem ", "label": 0}, {"snippet_id": 36402, "code": " Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"", "label": 0}, {"snippet_id": 82615, "code": ".lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be", "label": 0}, {"snippet_id": 11807, "code": "//stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key,{}), value", "label": 1}, {"snippet_id": 91826, "code": " import absolute_import, division, print_function, unicode_literals import logging from textwrap import dedent from pants.backend.native.subsystems.native_toolchain import NativeToolchain from pants.backend", "label": 0}, {"snippet_id": 5907, "code": " < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log", "label": 0}, {"snippet_id": 92137, "code": " Bad targets: {} \"\"\".format('\\n'.join(sorted(target.address.reference() for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires-pex' @classmethod", "label": 0}, {"snippet_id": 67757, "code": "][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING", "label": 0}, {"snippet_id": 62931, "code": " galaxy.util.bunch import Bunch import errno from time import sleep import os from.lwr_client import build_client_manager from.lwr_client import url_to_destination_params from.lwr_client import finish_job as", "label": 0}, {"snippet_id": 54266, "code": " bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict()", "label": 0}, {"snippet_id": 39994, "code": "\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self)", "label": 0}, {"snippet_id": 39514, "code": ".priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if", "label": 0}, {"snippet_id": 50585, "code": " ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self", "label": 0}, {"snippet_id": 43390, "code": " ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile,", "label": 0}, {"snippet_id": 7261, "code": " list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only", "label": 0}, {"snippet_id": 36713, "code": ": return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict", "label": 0}, {"snippet_id": 77489, "code": ".tcount, (self.pc, self.spawnqueue)) def spawn_evaluators(self): self.log.info('Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator", "label": 0}, {"snippet_id": 26133, "code": " DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__)", "label": 1}, {"snippet_id": 53062, "code": " run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append", "label": 0}, {"snippet_id": 67163, "code": " MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f %s' to initialize the file system.\" % \\ fs_conf.get_fs_name() return 0", "label": 1}, {"snippet_id": 7905, "code": "]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info", "label": 0}, {"snippet_id": 84097, "code": " working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def", "label": 1}, {"snippet_id": 31813, "code": "(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark", "label": 0}, {"snippet_id": 43118, "code": " wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards", "label": 0}, {"snippet_id": 9826, "code": " single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags", "label": 0}, {"snippet_id": 52255, "code": ".wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards", "label": 0}, {"snippet_id": 16387, "code": " server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash", "label": 0}, {"snippet_id": 89969, "code": "**kwargs): return execute_java(*args, distribution=self, **kwargs) def execute_java_async(self, *args, **kwargs): return execute_java_async(*args, distribution=self, **kwargs) @memoized_method def _get_version", "label": 0}, {"snippet_id": 69502, "code": " def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len", "label": 0}, {"snippet_id": 40211, "code": "._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill)", "label": 1}, {"snippet_id": 87520, "code": " zinc_args.extend(self._get_zinc_arguments(settings)) zinc_args.append('-transactional') for option_set in compiler_option_sets: enabled_args=self.get_options().compiler_option_sets_enabled_args.get(option_set,", "label": 0}, {"snippet_id": 68207, "code": ".get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other)", "label": 1}, {"snippet_id": 3125, "code": " % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name", "label": 0}, {"snippet_id": 6729, "code": " will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache", "label": 0}, {"snippet_id": 42757, "code": " for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names", "label": 0}, {"snippet_id": 58972, "code": ") class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view method\"\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData() cls.get_info_url=reverse('ajax-info') cls", "label": 0}, {"snippet_id": 48992, "code": "\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict", "label": 0}, {"snippet_id": 82723, "code": "://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==", "label": 0}, {"snippet_id": 89124, "code": ".targets(on_predicate)) dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in target.dependencies: if dependency in core: dependees[target].add(dependency) return dependees", "label": 0}, {"snippet_id": 20914, "code": " _close(self): if self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive()", "label": 0}, {"snippet_id": 82368, "code": "\targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower()", "label": 0}, {"snippet_id": 36158, "code": "() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def", "label": 0}, {"snippet_id": 73075, "code": "(remote_path_absolute) file_list=ftp.nlst() file_counter=1 file_list_total=len(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile", "label": 0}, {"snippet_id": 21528, "code": "+=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link", "label": 1}, {"snippet_id": 60263, "code": " cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"", "label": 0}, {"snippet_id": 66694, "code": " def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute", "label": 0}, {"snippet_id": 40143, "code": "(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError", "label": 1}, {"snippet_id": 54740, "code": ".rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource", "label": 0}, {"snippet_id": 91520, "code": " ExecuteProcessResult, FallibleExecuteProcessResult) from pants.engine.legacy.graph import BuildFileAddresses, TransitiveHydratedTargets from pants.engine.legacy.structs import PythonTestsAdaptor from pants.engine.rules", "label": 0}, {"snippet_id": 58956, "code": " {'rc': 0, 'response': 'ok'}) for pk in(self.case_1.pk, self.case_3.pk): self.assertEqual('P3', TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view", "label": 0}, {"snippet_id": 32360, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item]", "label": 0}, {"snippet_id": 26308, "code": ")]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None):", "label": 0}, {"snippet_id": 83825, "code": "(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state", "label": 0}, {"snippet_id": 41335, "code": " substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the", "label": 0}, {"snippet_id": 89879, "code": " according to the configured constraints. \"\"\" if self._validated_binaries: return with self._valid_executable('java') as java: if self._minimum_version: version=self._get_version(java) if version < self", "label": 0}, {"snippet_id": 74876, "code": " def __init__(self, runtime_config=None): \"\"\" Creates an object representation of the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration", "label": 0}, {"snippet_id": 67478, "code": " \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import", "label": 0}, {"snippet_id": 26961, "code": "=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status", "label": 0}, {"snippet_id": 95292, "code": "(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path", "label": 0}, {"snippet_id": 68384, "code": ".servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED:", "label": 0}, {"snippet_id": 47058, "code": ", rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise", "label": 0}, {"snippet_id": 24663, "code": " data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\"", "label": 0}, {"snippet_id": 53112, "code": " __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict", "label": 0}, {"snippet_id": 22421, "code": " \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys config\" rc=shellutil.run(cmd) if rc !=0: logger.error(\"WARNING: Cannot save sys config", "label": 0}, {"snippet_id": 21590, "code": " pandas as pd dataset=pd.read_csv('Social_Network_Ads.csv') X=dataset.iloc[:,[2, 3]].values y=dataset.iloc[:, 4].values from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test", "label": 1}, {"snippet_id": 22952, "code": "+username) def get_dvd_device(self, dev_dir='/dev'): \"\"\"Find BIG-IP's CD/DVD device This device is almost certainly /dev/cdrom so I added the ? to this pattern. Note that this method will return upon the", "label": 0}, {"snippet_id": 77339, "code": " wclass type') for i in range(count): if not self.running.is_set(): break try: w=wclass(*args, name='.'.join( (wname,('pr{0}' if type_ else 'th{0}').format(i))), **kvargs) if type_==0: self.threads.append(w", "label": 0}, {"snippet_id": 27975, "code": "=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60:", "label": 0}, {"snippet_id": 87722, "code": ".output_directory_digest), )) return res.output_directory_digest else: if self.runjava(classpath=[self._zinc.zinc], main=Zinc.ZINC_COMPILE_MAIN, jvm_options=jvm_options, args=zinc_args, workunit_name=self", "label": 0}, {"snippet_id": 86533, "code": ", PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator from pants.util.contextutil import open_zip", "label": 0}, {"snippet_id": 23784, "code": " return int(output) except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil", "label": 0}, {"snippet_id": 89363, "code": ".osutil import OS_ALIASES, normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version): if isinstance(version, string_types", "label": 0}, {"snippet_id": 50690, "code": ".abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target", "label": 0}, {"snippet_id": 15050, "code": "': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def", "label": 0}, {"snippet_id": 50720, "code": " for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"", "label": 0}, {"snippet_id": 10976, "code": ": %s\" %(url, e) raise HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except Timeout as", "label": 0}, {"snippet_id": 29117, "code": " Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in", "label": 1}, {"snippet_id": 43606, "code": " from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException", "label": 0}, {"snippet_id": 70675, "code": ".debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None: view=\"fs\" else: view=view.lower() if view.startswith(\"disk\") or view.startswith(\"target\"): status_flags &=", "label": 1}, {"snippet_id": 44348, "code": ".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job", "label": 0}, {"snippet_id": 95723, "code": "(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)) print(\"[Setup][Data] Decompressing file:{}\".format(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip", "label": 0}, {"snippet_id": 17401, "code": "._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ :", "label": 0}, {"snippet_id": 74561, "code": "=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", ", "label": 0}, {"snippet_id": 56885, "code": ">Object relationship, ordered by tag and annotated by key e.g. TestPlanTag, TestCaseTag ot TestRunTag :type test_tags: QuerySet \"\"\" self.key=key self.test_tags=iter(test_tags) self.counter={'tag': 0} def", "label": 0}, {"snippet_id": 17415, "code": "-NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen", "label": 0}, {"snippet_id": 72784, "code": ", and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib import allel import sys import", "label": 0}, {"snippet_id": 89516, "code": " to the java distribution's bin dir :param minimum_version: a modified semantic version string or else a Revision object :param maximum_version: a modified semantic version string or else a Revision object", "label": 0}, {"snippet_id": 70873, "code": "(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic", "label": 0}, {"snippet_id": 80557, "code": ".proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy ", "label": 0}, {"snippet_id": 81859, "code": " metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs=", "label": 0}, {"snippet_id": 69126, "code": " CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import", "label": 0}, {"snippet_id": 72769, "code": " line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results", "label": 0}, {"snippet_id": 67029, "code": ".startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else:", "label": 0}, {"snippet_id": 67123, "code": "() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ ", "label": 0}, {"snippet_id": 95287, "code": ": str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path", "label": 0}, {"snippet_id": 36216, "code": " except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule", "label": 0}, {"snippet_id": 11794, "code": "-like objects. >>> update({'k1': 1},{'k1':{'k2':{'k3': 3}}}) Source: http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance", "label": 1}, {"snippet_id": 35608, "code": " \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone", "label": 0}, {"snippet_id": 4463, "code": " it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache", "label": 0}, {"snippet_id": 36844, "code": " files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if", "label": 0}, {"snippet_id": 21019, "code": ") if unhandled: raise RuntimeError('unhandled:{}'.format(unhandled)) @contextlib.contextmanager def _wait_for_message(self, match, handlername, timeout=None): if timeout is None: timeout=self.TIMEOUT lock", "label": 0}, {"snippet_id": 16197, "code": ".responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal", "label": 0}, {"snippet_id": 48759, "code": " RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer", "label": 0}, {"snippet_id": 21852, "code": " activation='sigmoid')) classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) classifier.fit(X_train, y_train, batch_size=10, epochs=100) y_pred=classifier.predict(X_test)", "label": 1}, {"snippet_id": 73104, "code": ".copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd", "label": 0}, {"snippet_id": 27419, "code": "{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self", "label": 0}, {"snippet_id": 40859, "code": ".dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards", "label": 0}, {"snippet_id": 89719, "code": " lib_paths(): lib_path=os.path.join(path, name) if os.path.exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate{} library'.format(name)) return list(collect_existing_libs()", "label": 0}, {"snippet_id": 26984, "code": ".type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=", "label": 0}, {"snippet_id": 49614, "code": " list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock", "label": 0}, {"snippet_id": 72524, "code": ", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation", "label": 0}, {"snippet_id": 59057, "code": " response=self.client.get(self.get_info_url, {'info_type': 'env_properties', 'env_group_id': self.group_new.pk}) group=EnvGroup.objects.get(pk=self.group_new.pk) expected_json=json.loads( serializers.serialize", "label": 0}, {"snippet_id": 4480, "code": " rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\"", "label": 0}, {"snippet_id": 5007, "code": " NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience", "label": 0}, {"snippet_id": 28191, "code": "'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', ", "label": 0}, {"snippet_id": 42010, "code": " def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input", "label": 0}, {"snippet_id": 42597, "code": " if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards", "label": 0}, {"snippet_id": 13999, "code": "=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data", "label": 0}, {"snippet_id": 5264, "code": ")) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list", "label": 0}, {"snippet_id": 92212, "code": " shutil import signal import sys import unittest import uuid import zipfile from builtins import next, object, range, str from contextlib import contextmanager import mock from future.utils import PY3 from", "label": 0}, {"snippet_id": 68900, "code": "\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import", "label": 0}, {"snippet_id": 42657, "code": " return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"", "label": 0}, {"snippet_id": 87300, "code": "(self): \"\"\"A directory where zinc can store compiled copies of the `compiler-bridge`. The compiler-bridge is specific to each scala version, and is lazily computed by zinc if the appropriate version does", "label": 1}, {"snippet_id": 28222, "code": "'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value", "label": 0}, {"snippet_id": 14803, "code": " extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data", "label": 0}, {"snippet_id": 49443, "code": "=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict", "label": 0}, {"snippet_id": 42710, "code": "._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files", "label": 0}, {"snippet_id": 77498, "code": "'Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount", "label": 0}, {"snippet_id": 78578, "code": ".comment_loop) return if len(self.forums)==0: with cstate(self, WipeState.waiting_for_targets): while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self", "label": 0}, {"snippet_id": 41687, "code": " \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 22540, "code": " UI or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For", "label": 0}, {"snippet_id": 45299, "code": "(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be", "label": 0}, {"snippet_id": 66099, "code": ".state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif", "label": 0}, {"snippet_id": 11823, "code": ": base[key]=update_dict(base.get(key,{}), value) else: base[key]=head[key] else: base={key: head[key]} return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os", "label": 1}, {"snippet_id": 39882, "code": "\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace", "label": 0}, {"snippet_id": 35571, "code": "(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item", "label": 0}, {"snippet_id": 64294, "code": "): local_input_paths=self._wrapper_input_paths results=[] for local_input_path in local_input_paths: wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path", "label": 0}, {"snippet_id": 66896, "code": " worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s", "label": 1}, {"snippet_id": 85738, "code": " entries for compiler plugins.\"\"\" java_options_src=Java.global_instance() scala_options_src=ScalaPlatform.global_instance() def cp(instance, toolname): scope=instance.options_scope return instance.tool_classpath_from_products", "label": 0}, {"snippet_id": 78411, "code": ".topic_successtimeout) self.w.sleep(self.topic_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10) except exc.UnknownAnswer as e: self.log.warning(", "label": 0}, {"snippet_id": 78886, "code": ".logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s", "label": 0}, {"snippet_id": 66302, "code": "(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column", "label": 0}, {"snippet_id": 69790, "code": " > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self", "label": 1}, {"snippet_id": 52663, "code": "\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested", "label": 0}, {"snippet_id": 95393, "code": " os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter,", "label": 0}, {"snippet_id": 51249, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"", "label": 0}, {"snippet_id": 22269, "code": " try: import azurelinuxagent.common.logger as logger import azurelinuxagent.common.utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil", "label": 0}, {"snippet_id": 45895, "code": "=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError", "label": 0}, {"snippet_id": 34637, "code": " return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink.", "label": 0}, {"snippet_id": 24864, "code": "% data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >", "label": 0}, {"snippet_id": 11780, "code": "//api.github.com/user/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict(base, head): \"\"\" Recursively merge or update dict-like objects. >>> update({'k1'", "label": 0}, {"snippet_id": 64915, "code": " is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs(conf_dir_path, 0755) except OSError, ex: print \"OSError\" raise", "label": 1}, {"snippet_id": 30244, "code": ", names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield", "label": 0}, {"snippet_id": 70694, "code": " status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes", "label": 0}, {"snippet_id": 42113, "code": ".output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self", "label": 0}, {"snippet_id": 85266, "code": " for spec_key, create_jardep_func in specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address): jars=[create_jardep_func", "label": 0}, {"snippet_id": 93737, "code": " 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND", "label": 0}, {"snippet_id": 18099, "code": " response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data", "label": 0}, {"snippet_id": 26613, "code": " data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 18311, "code": " '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os", "label": 0}, {"snippet_id": 62645, "code": "(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs)", "label": 0}, {"snippet_id": 76315, "code": ", seqnum, status, data)) def send_success_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.success, data) def send_error_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.error, data", "label": 0}, {"snippet_id": 12225, "code": "'w+', encoding=r.encoding) as file_to_check: file_to_check.write(r.text) cmd='pycodestyle{config[pycodestyle_cmd_config]} file_to_check.py'.format( config=config) proc=subprocess.Popen(cmd, shell=True,", "label": 0}, {"snippet_id": 23685, "code": ".run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device() retcode=shellutil.run(\"cdcontrol -f{0} eject\".format", "label": 0}, {"snippet_id": 73208, "code": " searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory", "label": 0}, {"snippet_id": 58359, "code": "(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self.client.get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-login'), target_status_code", "label": 0}, {"snippet_id": 71581, "code": " RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status]", "label": 0}, {"snippet_id": 36851, "code": ".updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \"", "label": 0}, {"snippet_id": 295, "code": "\"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address", "label": 0}, {"snippet_id": 34496, "code": " notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname", "label": 0}, {"snippet_id": 44800, "code": "._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules", "label": 0}, {"snippet_id": 85174, "code": "{0}_{1}'.format(name, suffix) else: raise RuntimeError('Suffix version must be specified if using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is", "label": 0}, {"snippet_id": 15569, "code": "', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer", "label": 0}, {"snippet_id": 65438, "code": " TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self", "label": 0}, {"snippet_id": 75771, "code": "() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method, data))) raise Resume(", "label": 1}, {"snippet_id": 89064, "code": "=OrderedSet() for synthetic_address in self.build_graph.synthetic_addresses: if self.build_graph.get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target(synthetic_address", "label": 0}, {"snippet_id": 93631, "code": " send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs", "label": 0}, {"snippet_id": 93336, "code": " self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" ", "label": 0}, {"snippet_id": 17268, "code": " self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer", "label": 1}, {"snippet_id": 88975, "code": " dependencies: dependencies=[dep.address for dep in dependencies] self.build_graph.inject_synthetic_target(address=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from, **kwargs)", "label": 0}, {"snippet_id": 33007, "code": " name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile", "label": 0}, {"snippet_id": 9543, "code": ": dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc", "label": 0}, {"snippet_id": 79429, "code": " res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0", "label": 1}, {"snippet_id": 65931, "code": ")) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes", "label": 0}, {"snippet_id": 74778, "code": "(blosc_compression_level_str): compression_level_int=int(blosc_compression_level_str) if(compression_level_int >=0) and(compression_level_int <=9): self.blosc_compression_level=compression_level_int else", "label": 0}, {"snippet_id": 44175, "code": " priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp", "label": 0}, {"snippet_id": 95908, "code": "(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a", "label": 1}, {"snippet_id": 71505, "code": ".mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s", "label": 1}, {"snippet_id": 19145, "code": " None: validate_response( response=response, request_method=request_method, schema=schema ) def validate_api_call(schema, raw_request, raw_response): \"\"\" Validate the request/response cycle of an api call", "label": 0}, {"snippet_id": 1255, "code": " grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows", "label": 0}, {"snippet_id": 37082, "code": ".lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input,", "label": 0}, {"snippet_id": 71572, "code": "(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR", "label": 0}, {"snippet_id": 7130, "code": " my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions[s](complete_output, categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw", "label": 0}, {"snippet_id": 42916, "code": ".subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\")", "label": 0}, {"snippet_id": 57136, "code": "(field) value, error=get_value_by_type(value, vtype) if error: return say_no(error) has_perms=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied.') model=apps.get_model", "label": 0}, {"snippet_id": 81644, "code": ".uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t", "label": 1}, {"snippet_id": 91076, "code": "; combining results.'.format(rename)) normalized[rename].extend(paths) else: normalized[rename]=paths return normalized def _get_explicit_jdk_paths(self): if not self._normalized_jdk_paths: return() os_name", "label": 0}, {"snippet_id": 80884, "code": ".detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear(", "label": 0}, {"snippet_id": 77191, "code": ".newproxyfile, 'rt') as f: for line in f: try: line=line.rstrip('\\n') proxypair=tuple(line.split(' ')) if len(proxypair) < 2: self.log.warning('Line %s has too few spaces', line) continue if len(proxypair", "label": 1}, {"snippet_id": 8390, "code": " as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join", "label": 1}, {"snippet_id": 29051, "code": " auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list", "label": 0}, {"snippet_id": 24851, "code": "=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=", "label": 0}, {"snippet_id": 70553, "code": " target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client", "label": 0}, {"snippet_id": 6723, "code": " only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader", "label": 0}, {"snippet_id": 81036, "code": "\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason", "label": 0}, {"snippet_id": 50287, "code": "**ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo", "label": 0}, {"snippet_id": 86810, "code": " bootstrap_option_values): return('-Dfile.encoding=UTF-8', '-Dzinc.analysis.cache.limit=1000', '-Djava.awt.headless=true', '-Xmx2g') @classmethod def get_args_default(cls, bootstrap_option_values): return('-C-encoding', ", "label": 0}, {"snippet_id": 53807, "code": "*kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str", "label": 0}, {"snippet_id": 35097, "code": ".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not", "label": 0}, {"snippet_id": 6820, "code": ", output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will", "label": 1}, {"snippet_id": 76749, "code": " parser.add_argument('--noproxy-timeout', type=int, default=5, help='noproxy_rp timeout') parser.add_argument('--caprate_minp', type=int, default=5, help='Cap rate minimum possible count for limit check", "label": 0}, {"snippet_id": 95035, "code": " run.\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()", "label": 0}, {"snippet_id": 80732, "code": ".info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[", "label": 0}, {"snippet_id": 67611, "code": " print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if", "label": 0}, {"snippet_id": 79955, "code": "\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\"", "label": 0}, {"snippet_id": 1422, "code": " print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key", "label": 0}, {"snippet_id": 76218, "code": " for(%s, %s)', i, m) else: self.log.warn('Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_unbind_route_data(i, m, wzauth_data.bind_route[i, m])) def", "label": 0}, {"snippet_id": 20182, "code": " raise RuntimeError('debugger already running') assert self._session is None addr=('localhost', self._addr.port) self._run_server_ex=None def run(): try: self._session=self.SESSION.create_server(addr, ", "label": 0}, {"snippet_id": 54886, "code": "(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath", "label": 0}, {"snippet_id": 17429, "code": "-1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport", "label": 0}, {"snippet_id": 60097, "code": "([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities", "label": 0}, {"snippet_id": 28483, "code": " @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement", "label": 0}, {"snippet_id": 27945, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self", "label": 0}, {"snippet_id": 86599, "code": ".path.join(resources_dir, _SCALAC_PLUGIN_INFO_FILE) with safe_open(scalac_plugin_info_file, 'w') as f: f.write(textwrap.dedent(\"\"\" <plugin> <name>{}</name> <classname>{}</classname> </plugin> \"\"\".format", "label": 0}, {"snippet_id": 77959, "code": "(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError('%s is protected' % repr(t", "label": 0}, {"snippet_id": 11974, "code": "\"BOT_PASSWORD\"]) url=\"https://raw.githubusercontent.com/{}/{}/.pep8speaks.yml\" url=url.format(data[\"repository\"], data[\"after_commit_hash\"]) r=requests.get(url, headers=headers, auth=auth) if r.status_code", "label": 0}, {"snippet_id": 1747, "code": " return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor", "label": 0}, {"snippet_id": 42299, "code": " import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand", "label": 0}, {"snippet_id": 3497, "code": " start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def", "label": 0}, {"snippet_id": 85176, "code": "}'.format(name, suffix) else: raise RuntimeError('Suffix version must be specified if using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not", "label": 0}, {"snippet_id": 66272, "code": "\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column", "label": 0}, {"snippet_id": 32138, "code": " SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params:", "label": 0}, {"snippet_id": 30970, "code": " in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"", "label": 0}, {"snippet_id": 43093, "code": ", start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested", "label": 0}, {"snippet_id": 82401, "code": " templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity", "label": 0}, {"snippet_id": 18284, "code": ".GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file", "label": 1}, {"snippet_id": 23842, "code": " SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We will sleep and retry as the network must be up. \"\"\" iface='' inet=''", "label": 0}, {"snippet_id": 55579, "code": " def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def", "label": 0}, {"snippet_id": 52651, "code": " existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested", "label": 0}, {"snippet_id": 51152, "code": "=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not", "label": 0}, {"snippet_id": 70980, "code": " status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE", "label": 0}, {"snippet_id": 16000, "code": ") if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR", "label": 0}, {"snippet_id": 67299, "code": " Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={", "label": 0}, {"snippet_id": 10412, "code": " def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory", "label": 0}, {"snippet_id": 12834, "code": "\"pycodestyle\"][\"ignore\"]) arg_to_ignore=\"\" if len(to_ignore) > 0: arg_to_ignore=\"--ignore \" +to_ignore for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format", "label": 0}, {"snippet_id": 65132, "code": " ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if", "label": 0}, {"snippet_id": 46568, "code": "): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone", "label": 0}, {"snippet_id": 56317, "code": "(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters @require_GET def info(request): \"\"\"Ajax responder for misc information\"\"\" objects=_InfoObjects(request=request,", "label": 1}, {"snippet_id": 94130, "code": " slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name", "label": 0}, {"snippet_id": 11210, "code": " does it by querying an URL from which it receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is given it reads it's default configuration", "label": 0}, {"snippet_id": 18458, "code": "() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded", "label": 0}, {"snippet_id": 37025, "code": "._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output", "label": 0}, {"snippet_id": 15863, "code": ".utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 44660, "code": "=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self", "label": 0}, {"snippet_id": 38827, "code": " the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" ", "label": 0}, {"snippet_id": 23884, "code": " not ifaces: raise OSUtilError(\"Can't find ether interface.\") iface=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface", "label": 0}, {"snippet_id": 27224, "code": "'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value", "label": 0}, {"snippet_id": 2831, "code": " node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name", "label": 0}, {"snippet_id": 83746, "code": ".cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs", "label": 0}, {"snippet_id": 14292, "code": " def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self", "label": 1}, {"snippet_id": 58941, "code": ":[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) for pk", "label": 0}, {"snippet_id": 38614, "code": "=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False)", "label": 0}, {"snippet_id": 19228, "code": "=source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source(source) assert result==native def test_yaml_string(): native={'foo': 'bar'} source=yaml.dump(native) result", "label": 1}, {"snippet_id": 72707, "code": "=vcf_directory, output_zarr_dir=zarr_directory_setup, conversion_config=vcf_to_zarr_config) elif command==\"exec\": print(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location", "label": 1}, {"snippet_id": 19632, "code": "(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ) parser.add_argument('--nodebug', action='store_true') host=parser.add_mutually_exclusive_group() host.add_argument('", "label": 0}, {"snippet_id": 43526, "code": " def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2", "label": 0}, {"snippet_id": 80649, "code": ",postData,args.uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not args.skipRecon: \tif len(args.legitExtensions", "label": 0}, {"snippet_id": 22371, "code": " Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within roughly 50 minutes(100 * 30 seconds) \"\"\" for retries in range(1, 100): logger.info(\"Checking to see if mcpd is", "label": 0}, {"snippet_id": 23044, "code": " **kwargs): \"\"\"Mount the DVD containing the provisioningiso.iso file This is the _first_ hook that WAAgent provides for us, so this is the point where we should wait for mcpd to load. I am just overloading", "label": 0}, {"snippet_id": 41241, "code": " open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed", "label": 0}, {"snippet_id": 78150, "code": "'WipeThread', b'WipeThread', b'log-spawn-name']) if c.no_shell: while True: time.sleep(1) else: try: import IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except KeyboardInterrupt", "label": 1}, {"snippet_id": 9870, "code": ".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to", "label": 0}, {"snippet_id": 39049, "code": "\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self", "label": 0}, {"snippet_id": 16920, "code": ", handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 63307, "code": "=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds", "label": 0}, {"snippet_id": 3584, "code": "'cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend", "label": 0}, {"snippet_id": 2917, "code": ") if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting", "label": 0}, {"snippet_id": 75264, "code": ".sig_handlers[(interface, method)] def _parse_req(self, iden, msg, reqid, interface, method): try: handler=self.req_handlers[(interface, method)] except KeyError: try: handler=self.req_handlers[(interface,", "label": 0}, {"snippet_id": 72349, "code": "' '.join(args.command)) finally: log.debug('(%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname) remoteirc.reply=old_reply remoteirc.pseudoclient.account='' @utils.add_cmd def reloadproto", "label": 1}, {"snippet_id": 38404, "code": ": raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules", "label": 0}, {"snippet_id": 74700, "code": "\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default", "label": 0}, {"snippet_id": 12943, "code": " files\"\"\" REQUEST_JSON={} REQUEST_JSON[\"public\"]=True REQUEST_JSON[\"files\"]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs", "label": 0}, {"snippet_id": 24258, "code": "'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy", "label": 0}, {"snippet_id": 41499, "code": "), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self", "label": 0}, {"snippet_id": 68938, "code": ".Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self", "label": 0}, {"snippet_id": 58221, "code": ".core import serializers from django.urls import reverse from django_comments.models import Comment from tcms.management.models import Priority from tcms.management.models import EnvGroup from tcms.management", "label": 0}, {"snippet_id": 58011, "code": "=request.GET.get('a') data['bz_external_track']=True if request.GET.get('bz_external_track', False) else False return(data, '') def update_bugs_to_caseruns(request): \"\"\" Add one or more bugs to or remove that", "label": 0}, {"snippet_id": 14156, "code": " OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client", "label": 0}, {"snippet_id": 14374, "code": ") if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str", "label": 0}, {"snippet_id": 84476, "code": " if remote_path: remote_extra_files_path=\"%s_files\" % remote_path[ 0:-len( \".dat\")] return local_dataset_path.with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return", "label": 0}, {"snippet_id": 9891, "code": " to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws", "label": 0}, {"snippet_id": 27557, "code": "['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2", "label": 0}, {"snippet_id": 63624, "code": ".\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing job %d\" % job_wrapper.job_id) return", "label": 0}, {"snippet_id": 43703, "code": ".workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath", "label": 0}, {"snippet_id": 32930, "code": "=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self", "label": 0}, {"snippet_id": 45155, "code": " shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self", "label": 0}, {"snippet_id": 52054, "code": " Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError:", "label": 0}, {"snippet_id": 18214, "code": " SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer", "label": 0}, {"snippet_id": 25601, "code": "=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\"", "label": 0}, {"snippet_id": 72224, "code": ".error(\"Cannot remote-send a command to the local network; use a normal command!\") return try: remoteirc=world.networkobjects[netname] except KeyError: irc.error('No such network \"%s\"(case sensitive).' ", "label": 0}, {"snippet_id": 83583, "code": "('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths=job_wrapper.get_output_fnames() return[ str( o) for o in", "label": 0}, {"snippet_id": 81769, "code": ",level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName", "label": 0}, {"snippet_id": 68716, "code": " tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag()", "label": 0}, {"snippet_id": 23724, "code": "/rc.d/dhclient restart{0}\".format(ifname), chk_err=False) def get_total_mem(self): cmd=\"sysctl hw.physmem |awk '{print $2}'\" ret, output=shellutil.run_get_output(cmd) if ret: raise OSUtilError(\"Failed to", "label": 0}, {"snippet_id": 15704, "code": " debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info ", "label": 0}, {"snippet_id": 85622, "code": "._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list of str \"\"\" return self._zinc_factory.dist @memoized_property def compiler_bridge", "label": 0}, {"snippet_id": 63909, "code": " job_state) def shutdown( self): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy", "label": 0}, {"snippet_id": 53462, "code": " branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark", "label": 0}, {"snippet_id": 25022, "code": " self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] ", "label": 0}, {"snippet_id": 27831, "code": " data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state", "label": 0}, {"snippet_id": 84785, "code": " Address from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem major_version_info=namedtuple", "label": 0}, {"snippet_id": 38745, "code": "(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles", "label": 0}, {"snippet_id": 55161, "code": ".updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main", "label": 0}, {"snippet_id": 56722, "code": " request: HttpRequest \"\"\" for obj in['plan', 'case', 'run']: if request.GET.get(obj): self.object=obj self.object_pk=request.GET.get(obj) break def get(self): func=getattr(self, self.object) return func", "label": 0}, {"snippet_id": 58896, "code": ".post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self.plan.pk, 'case':[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual(", "label": 0}, {"snippet_id": 18868, "code": ".paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request, normalize_response, ) from flex.validation.common import validate_object from flex", "label": 0}, {"snippet_id": 7634, "code": "[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return", "label": 0}, {"snippet_id": 71386, "code": "(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 88922, "code": ", target_base=None, dependencies=None, derived_from=None, **kwargs): \"\"\"Creates a new target, adds it to the context and returns it. This method ensures the target resolves files against the given target_base", "label": 0}, {"snippet_id": 59081, "code": "============== **Module name:**:mod:`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize", "label": 0}, {"snippet_id": 28634, "code": "'battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif", "label": 0}, {"snippet_id": 34641, "code": "): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError", "label": 1}, {"snippet_id": 65611, "code": "\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict", "label": 0}, {"snippet_id": 4802, "code": ":keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean ", "label": 0}, {"snippet_id": 86696, "code": " _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform settings. This is responsible for the symbol substitution which replaces $JAVA_HOME with the path to", "label": 0}, {"snippet_id": 86489, "code": " JavacPlugin from pants.backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from", "label": 0}, {"snippet_id": 62576, "code": ", self.reg) variance=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg] variance", "label": 0}, {"snippet_id": 25319, "code": ".string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo", "label": 0}, {"snippet_id": 38295, "code": "=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included", "label": 0}, {"snippet_id": 37604, "code": "(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property", "label": 0}, {"snippet_id": 10297, "code": "(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords)", "label": 0}, {"snippet_id": 62199, "code": ") self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__", "label": 0}, {"snippet_id": 52932, "code": ".is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties(", "label": 0}, {"snippet_id": 25167, "code": "'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high", "label": 0}, {"snippet_id": 17025, "code": " query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num", "label": 0}, {"snippet_id": 64022, "code": " @staticmethod def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR.", "label": 0}, {"snippet_id": 27606, "code": " and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 62165, "code": " kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self", "label": 0}, {"snippet_id": 13114, "code": " update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[", "label": 0}, {"snippet_id": 48991, "code": "\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections", "label": 0}, {"snippet_id": 72154, "code": "['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument('network') remote_parser.add_argument('--service', type=str, default='pylink') remote_parser.add_argument", "label": 0}, {"snippet_id": 5975, "code": " else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf", "label": 1}, {"snippet_id": 61466, "code": " if len(operation.wires)==1: U=self.expand_one(U, operation.wires) elif len(operation.wires)==2: U=self.expand_two(U, operation.wires) else: raise ValueError('This plugin supports only one-and two-qubit", "label": 0}, {"snippet_id": 67148, "code": "(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers)", "label": 0}, {"snippet_id": 56644, "code": ") test_run_tags=TestRunTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_runs=Count('tag')).order_by('tag') plan_counter=_TagCounter('num_plans', test_plan_tags) case_counter=_TagCounter", "label": 0}, {"snippet_id": 94759, "code": "\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument", "label": 0}, {"snippet_id": 67546, "code": " FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status", "label": 0}, {"snippet_id": 25084, "code": ".keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None", "label": 1}, {"snippet_id": 1157, "code": "(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class", "label": 0}, {"snippet_id": 49739, "code": " workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow", "label": 0}, {"snippet_id": 89386, "code": "(version, Revision): raise ValueError('{} must be a string or a Revision object, given:{}'.format(name, version)) return version class Distribution(object): \"\"\"Represents a java distribution -either a JRE or", "label": 0}, {"snippet_id": 30876, "code": " in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else:", "label": 1}, {"snippet_id": 95781, "code": "(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head(path): head, tail=os.path.split(path) return head def path_leaf(path): head, tail=os.path.split(path) return tail or os.path", "label": 0}, {"snippet_id": 31647, "code": ".resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile", "label": 0}, {"snippet_id": 47651, "code": " shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(", "label": 0}, {"snippet_id": 33217, "code": " greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map", "label": 0}, {"snippet_id": 50044, "code": "(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile", "label": 0}, {"snippet_id": 9168, "code": " object>,[[position, position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms", "label": 0}, {"snippet_id": 18813, "code": "=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager", "label": 0}, {"snippet_id": 88974, "code": " dependencies: dependencies=[dep.address for dep in dependencies] self.build_graph.inject_synthetic_target(address=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from, *", "label": 0}, {"snippet_id": 84991, "code": "'Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default='2.12', choices=['2.10', '2.11', '2.12', 'custom'], fingerprint=True, help='The", "label": 0}, {"snippet_id": 49680, "code": "\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the", "label": 0}, {"snippet_id": 72977, "code": " downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter,", "label": 0}, {"snippet_id": 64005, "code": "): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False)) return remote_metadata @staticmethod def __remote_work_dir_copy( lwr_client): return LwrJobRunner", "label": 0}, {"snippet_id": 78710, "code": " 'False')=='True': raise if self.options.trace: pdb.post_mortem(sys.exc_info()[2]) else: log.log_error(e) def executer(self, *args): \"\"\"Execute remotely\"\"\" options=self.options try: url='http://{host}:", "label": 1}, {"snippet_id": 919, "code": " safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(", "label": 0}, {"snippet_id": 32589, "code": " \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 45171, "code": "): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func", "label": 0}, {"snippet_id": 10174, "code": "[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core", "label": 0}, {"snippet_id": 60847, "code": " version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ' +self.author +'\\n' def __enter__(self): if Device._current_context is None: Device._current_context=self self.reset() else", "label": 0}, {"snippet_id": 36096, "code": "=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_", "label": 0}, {"snippet_id": 23374, "code": " def __init__(self): super(FreeBSDOSUtil, self).__init__() self._scsi_disks_timeout_set=False def set_hostname(self, hostname): rc_file_path='/etc/rc.conf' conf_file=fileutil.read_file(rc_file_path).split", "label": 0}, {"snippet_id": 29984, "code": " lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards", "label": 0}, {"snippet_id": 47258, "code": ".benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if", "label": 0}, {"snippet_id": 45362, "code": " WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks", "label": 1}, {"snippet_id": 10894, "code": " monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, HostUnreachableException from monitoring_config_generator.yaml_tools.merger import merge_yaml_files def is_file(parsed_uri): return", "label": 0}, {"snippet_id": 62509, "code": ", 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be", "label": 0}, {"snippet_id": 49185, "code": "() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for", "label": 0}, {"snippet_id": 23096, "code": "._wait_until_mcpd_is_initialized() return super(BigIpOSUtil, self).mount_dvd(**kwargs) def eject_dvd(self, chk_err=True): \"\"\"Runs the eject command to eject the provisioning DVD BIG-IP does not include", "label": 0}, {"snippet_id": 3768, "code": ", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name):", "label": 0}, {"snippet_id": 55115, "code": "--unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets", "label": 0}, {"snippet_id": 86371, "code": ")) return ret def _execute_hermetic_compile(self, cmd, ctx): input_snapshot=ctx.target.sources_snapshot(scheduler=self.context._scheduler) output_files=tuple( os.path.relpath(f.path.replace('.java', '.class", "label": 0}, {"snippet_id": 74733, "code": ".chunk_width=None elif isint(chunk_width_str): self.chunk_width=int(chunk_width_str) else: raise TypeError(\"Invalid value provided for chunk_width in configuration.\\n\" \"Expected: \\\"default\\\" or integer", "label": 0}, {"snippet_id": 91103, "code": "('--jvm-distributions-paths was specified, but has no entry for \"{}\".' .format(os_name)) return self._normalized_jdk_paths.get(os_name,()) def _create_locator(self): homes=self._get_explicit_jdk_paths(", "label": 0}, {"snippet_id": 39913, "code": " srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack", "label": 0}, {"snippet_id": 17859, "code": ".server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object", "label": 0}, {"snippet_id": 9132, "code": " extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects", "label": 0}, {"snippet_id": 62544, "code": ".backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable", "label": 0}, {"snippet_id": 72892, "code": " ftp_config.enabled: create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server)", "label": 0}, {"snippet_id": 16843, "code": " retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json", "label": 0}, {"snippet_id": 87915, "code": " in scalac_plugin_map[name]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin classpath", "label": 0}, {"snippet_id": 26263, "code": "'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None", "label": 0}, {"snippet_id": 77502, "code": " Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount, (ev_init,))", "label": 0}, {"snippet_id": 5832, "code": "* length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path", "label": 0}, {"snippet_id": 42286, "code": " __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict", "label": 0}, {"snippet_id": 62559, "code": ".flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator(str(observable)[-1]+'0'", "label": 0}, {"snippet_id": 51941, "code": " end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items", "label": 0}, {"snippet_id": 61021, "code": ": A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian projectors such that:math:`A=\\sum_k a_k P_k`. \"\"\" d, v=eigh(A) P=[] for k in range(2): temp", "label": 0}, {"snippet_id": 58598, "code": " self.assertEqual(new_comment, comments[0].comment) self.assertEqual(self.tester, comments[0].user) class TestUpdateObject(BasePlanCase): \"\"\"Test case for update\"\"\" @classmethod def setUpTestData(cls):", "label": 0}, {"snippet_id": 51018, "code": " try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f", "label": 0}, {"snippet_id": 8633, "code": " are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone", "label": 0}, {"snippet_id": 30499, "code": " PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat", "label": 0}, {"snippet_id": 617, "code": ".Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action", "label": 0}, {"snippet_id": 45547, "code": " root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self)", "label": 0}, {"snippet_id": 4270, "code": " text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines", "label": 0}, {"snippet_id": 54936, "code": " forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets)", "label": 0}, {"snippet_id": 76007, "code": " wzrpc.status.e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warning('Recvd unknown reply for(%s, %s) %s: %s', i, m, wzrpc.name_status(status), repr(data)", "label": 0}, {"snippet_id": 89294, "code": "(FallibleExecuteProcessResult,[execute_process_request])[0] workunit.output(\"stdout\").write(result.stdout) workunit.output(\"stderr\").write(result.stderr) workunit.set_outcome(WorkUnit.FAILURE if result.exit_code else WorkUnit", "label": 0}, {"snippet_id": 1297, "code": " SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def", "label": 0}, {"snippet_id": 37561, "code": "): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item", "label": 0}, {"snippet_id": 61667, "code": "._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem Returns: array: 2^n*2^n matrix \"", "label": 0}, {"snippet_id": 64540, "code": " class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install", "label": 0}, {"snippet_id": 40101, "code": "(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP ", "label": 0}, {"snippet_id": 58906, "code": ":[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': \"You don't have", "label": 0}, {"snippet_id": 47986, "code": " exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output", "label": 0}, {"snippet_id": 35174, "code": " return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually", "label": 0}, {"snippet_id": 77095, "code": ".usersfile='wm_users.pickle' self.targetsfile='wm_targets.pickle' self.bumplimitfile='wm_bumplimit.pickle' def init_th_sock(self): self.log.info( 'Initializing intraprocess signal socket %s', self.th_sa)", "label": 0}, {"snippet_id": 68336, "code": " AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def", "label": 0}, {"snippet_id": 26062, "code": "\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 7716, "code": " keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in", "label": 0}, {"snippet_id": 22985, "code": "/dev/sr0 on occasion. This is NOT the correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists on all platforms that are supported on Azure(Stack", "label": 0}, {"snippet_id": 27710, "code": "=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp", "label": 0}, {"snippet_id": 24816, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self", "label": 0}, {"snippet_id": 2377, "code": ", datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts", "label": 0}, {"snippet_id": 26658, "code": " data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low", "label": 0}, {"snippet_id": 47844, "code": "._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self", "label": 0}, {"snippet_id": 44714, "code": " code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile", "label": 0}, {"snippet_id": 19374, "code": "\"\" For the PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py \"\"", "label": 0}, {"snippet_id": 73393, "code": " directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str", "label": 0}, {"snippet_id": 32658, "code": ") def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return", "label": 0}, {"snippet_id": 77177, "code": ".ROUTER) self.pr_back_sock.bind(self.pr_ba) def read_newproxies(self): if not os.path.isfile(self.newproxyfile): return newproxies=set() with open(self.newproxyfile, 'rt') as f: for line in f: try: line", "label": 1}, {"snippet_id": 82703, "code": ".proxy[\"username\"] \t\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy ", "label": 0}, {"snippet_id": 89038, "code": " the predicate will be used to narrow the scope of targets returned. :param bool postorder: `True` to gather transitive dependencies with a postorder traversal; `False` or preorder by default. :returns", "label": 0}, {"snippet_id": 50783, "code": " in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks", "label": 0}, {"snippet_id": 29885, "code": ": filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their", "label": 0}, {"snippet_id": 95074, "code": "[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite", "label": 0}, {"snippet_id": 61533, "code": ".shots, p0) ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A(openqml.Operation or openqml", "label": 0}, {"snippet_id": 64795, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None", "label": 0}, {"snippet_id": 68781, "code": " target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 36537, "code": " for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output", "label": 0}, {"snippet_id": 38595, "code": " list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False,", "label": 0}, {"snippet_id": 51146, "code": " be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.", "label": 0}, {"snippet_id": 82319, "code": ". Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent", "label": 0}, {"snippet_id": 87878, "code": ", plugin)) ret.append('-C-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _scalac_plugin_args(self, scalac_plugin_map, classpath): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins", "label": 0}, {"snippet_id": 78602, "code": " self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError as e: self.log.error(e) except WorkerInterrupt as e: self.log.warning(e) except Exception", "label": 0}, {"snippet_id": 61738, "code": " 4x4 matrix wires(Sequence[int]): two target subsystems(order matters!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError", "label": 0}, {"snippet_id": 72978, "code": ":{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath", "label": 0}, {"snippet_id": 53733, "code": " raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item):", "label": 0}, {"snippet_id": 28680, "code": ".type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 15205, "code": " except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=(", "label": 0}, {"snippet_id": 55830, "code": " return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input", "label": 0}, {"snippet_id": 15653, "code": "): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive", "label": 0}, {"snippet_id": 20344, "code": " import sys import time import threading import warnings from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.message import( raw_read_all as read_messages, raw_write_one as write_message", "label": 0}, {"snippet_id": 18690, "code": "'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self", "label": 0}, {"snippet_id": 13022, "code": " headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(url, headers=headers, auth=auth) for repo in r.json(): if repo[", "label": 0}, {"snippet_id": 71033, "code": "(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append", "label": 0}, {"snippet_id": 19947, "code": "('already using managed adapter') if adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') if addr is None: addr=adapter.address", "label": 0}, {"snippet_id": 63539, "code": ", files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds) def finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper", "label": 0}, {"snippet_id": 8172, "code": " return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2", "label": 0}, {"snippet_id": 66330, "code": ".set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname", "label": 0}, {"snippet_id": 44032, "code": "=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources", "label": 0}, {"snippet_id": 28069, "code": "): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import", "label": 1}, {"snippet_id": 91571, "code": ", None) ) } constraints_args=[] for constraint in sorted(constraints): constraints_args.extend([\"--interpreter-constraint\", text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor", "label": 1}, {"snippet_id": 23295, "code": " mask: :param gateway: :return: \"\"\" cmd=(\"/usr/bin/tmsh create net route \" \"{0}/{1} gw{2}\").format(net, mask, gateway) return shellutil.run(cmd, chk_err=False) def device_for_ide_port(self, port_id): \"", "label": 0}, {"snippet_id": 12741, "code": " time_now=utc_time.strftime(\"%B %d, %Y at %H:%M Hours UTC\") comment +=\"\\n\\n comment=comment.format(time_now) query=\"https://api.github.com/repos/{}/issues/comments/{}\" query=query.format(data[\"repository\"]", "label": 0}, {"snippet_id": 1604, "code": " if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password", "label": 0}, {"snippet_id": 34003, "code": " def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0", "label": 0}, {"snippet_id": 81790, "code": " templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=", "label": 0}, {"snippet_id": 75676, "code": ".poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests=[] self.wz_bind_methods=[] self.wz_poll_timeout=30 def __sinit__(self): ''", "label": 1}, {"snippet_id": 94242, "code": ": self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self", "label": 0}, {"snippet_id": 21102, "code": " time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event", "label": 0}, {"snippet_id": 10558, "code": "\"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")", "label": 1}, {"snippet_id": 55751, "code": ".resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule", "label": 0}, {"snippet_id": 13539, "code": "=None):\r time.sleep( 0.1)\r \r while isRunning:\r if( audio.mouthValue !=lastMouthEvent):\r lastMouthEvent=audio.mouthValue\r lastMouthEventTime=time.time()\r \r if( audio.mouthValue==1):\r io.set( MOUTH_OPEN,", "label": 0}, {"snippet_id": 51924, "code": "._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next", "label": 0}, {"snippet_id": 92274, "code": " temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): subprocess.Popen([sys.executable, '-c', 'import os; print(os.environ[\"HORK\"])'], stdout=output).wait() output.seek(0) self.assertEqual(", "label": 0}, {"snippet_id": 62029, "code": " Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed", "label": 0}, {"snippet_id": 60719, "code": " device class and context manager\"\"\" import abc import logging logging.getLogger() class MethodFactory(type): \"\"\"Metaclass that allows derived classes to dynamically instantiate new objects based on undefined", "label": 0}, {"snippet_id": 95958, "code": "(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=", "label": 0}, {"snippet_id": 12293, "code": "[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/{}{}\" data[filename", "label": 0}, {"snippet_id": 27591, "code": "': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full", "label": 0}, {"snippet_id": 28765, "code": "=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data[", "label": 0}, {"snippet_id": 86978, "code": " 'This is unset by default, because it is generally a good precaution to cache ' 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies", "label": 0}, {"snippet_id": 45281, "code": " workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self", "label": 0}, {"snippet_id": 82817, "code": ",args.n,args.legitExtensions) \telse: \t\tn=up.detectValidExtensions(extensions,args.n) \tlogger.info(\" else: \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error", "label": 0}, {"snippet_id": 10589, "code": " to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False", "label": 0}, {"snippet_id": 24887, "code": "'GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 77046, "code": "=0.2 if c.upload_avatar: w.hooks['post_login'].append(upload_avatar) yield w class WipeManager: def __init__(self, config, *args, **kvargs): super().__init__(*args, **kvargs) self.newproxyfile='newproxies", "label": 0}, {"snippet_id": 12099, "code": " author=data[\"author\"] diff_url=\"https://api.github.com/repos/{}/pulls/{}\" diff_url=diff_url.format(repository, str(data[\"pr_number\"])) r=requests.get(diff_url, headers=diff_headers, auth=auth) patch=unidiff", "label": 0}, {"snippet_id": 27060, "code": "\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 18378, "code": "'http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self):", "label": 0}, {"snippet_id": 70960, "code": ".append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering", "label": 0}, {"snippet_id": 41244, "code": " f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" ", "label": 0}, {"snippet_id": 55741, "code": " RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)):", "label": 0}, {"snippet_id": 62072, "code": " runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit). user(string): IBM Quantum", "label": 0}, {"snippet_id": 36739, "code": " __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction", "label": 0}, {"snippet_id": 6699, "code": "-partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs", "label": 0}, {"snippet_id": 89848, "code": " not isinstance(name, str): raise ValueError('name must be a binary name, given{} of type{}'.format(name, type(name))) self.validate() return self._validated_executable(name) def validate(self): \"\"\"Validates", "label": 0}, {"snippet_id": 27050, "code": " latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): ", "label": 0}, {"snippet_id": 65701, "code": " in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\"", "label": 0}, {"snippet_id": 4914, "code": " kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\"", "label": 0}, {"snippet_id": 79962, "code": "\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs", "label": 0}, {"snippet_id": 18448, "code": "._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled(", "label": 0}, {"snippet_id": 37344, "code": " for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names", "label": 0}, {"snippet_id": 9443, "code": " spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don", "label": 0}, {"snippet_id": 70076, "code": " import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting ", "label": 0}, {"snippet_id": 44276, "code": " snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False", "label": 0}, {"snippet_id": 87402, "code": "=self.scalac_classpath() compiler_interface=self._zinc.compiler_interface compiler_bridge=self._zinc.compiler_bridge classes_dir=ctx.classes_dir analysis_cache=ctx.analysis_file scala_path=tuple(relative_to_exec_root", "label": 1}, {"snippet_id": 1172, "code": ".decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response import Response from rest_framework import", "label": 0}, {"snippet_id": 40857, "code": " dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern", "label": 0}, {"snippet_id": 40424, "code": " raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P=", "label": 0}, {"snippet_id": 48172, "code": ".output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names()", "label": 0}, {"snippet_id": 6842, "code": " matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): ", "label": 0}, {"snippet_id": 21419, "code": "\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working directory found, but no subreddit directory. Creating %s", "label": 0}, {"snippet_id": 64966, "code": ".FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils", "label": 0}, {"snippet_id": 63662, "code": " Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads", "label": 0}, {"snippet_id": 89182, "code": ", but any dependencies of targets parsed in the root tree's BUILD files will be followed and this may lead to BUILD files outside of ``root`` being parsed and included in the returned build graph. :API", "label": 0}, {"snippet_id": 28896, "code": "] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0", "label": 0}, {"snippet_id": 58035, "code": " caserun at a time. \"\"\" data, error=clean_bug_form(request) if error: return say_no(error) runs=TestCaseRun.objects.filter(pk__in=data['runs']) bug_system_id=data['bug_system_id'] bug_ids=data['bugs'] try", "label": 0}, {"snippet_id": 33813, "code": " and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule", "label": 0}, {"snippet_id": 38735, "code": " is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles", "label": 0}, {"snippet_id": 45414, "code": "._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile", "label": 0}, {"snippet_id": 128, "code": " nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows", "label": 0}, {"snippet_id": 19765, "code": "=False, **kwargs): if nodebug: run_main(addr, name, kind, *extra, **kwargs) else: debug_main(addr, name, kind, *extra, **kwargs) if __name__=='__main__': args, extra=parse_args() main(args.address, args", "label": 0}, {"snippet_id": 12048, "code": " '.join(arguments)) config[\"pycodestyle\"][\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return a list of file names modified", "label": 0}, {"snippet_id": 83521, "code": " ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception", "label": 1}, {"snippet_id": 75489, "code": "'Router', b'auth-request', args, reqid) def make_auth_bind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface,", "label": 0}, {"snippet_id": 16073, "code": ".codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest", "label": 0}, {"snippet_id": 5196, "code": "\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\"", "label": 0}, {"snippet_id": 88156, "code": " as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except IOError as e: if e.errno !=errno.ENOENT: raise else: with open_zip(classpath_element, 'r') as jarfile: try: with", "label": 0}, {"snippet_id": 74920, "code": ".benchmark[\"benchmark_data_input\"] if benchmark_data_input_temp in benchmark_data_input_types: self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self", "label": 0}, {"snippet_id": 8520, "code": " user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file", "label": 1}, {"snippet_id": 69774, "code": " > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node", "label": 1}, {"snippet_id": 56465, "code": "['env_group_id']).property.all() return EnvProperty.objects.all() def env_values(self): return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id')) def users(self): query=strip_parameters", "label": 0}, {"snippet_id": 67643, "code": " \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1", "label": 0}, {"snippet_id": 45211, "code": " self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property", "label": 0}, {"snippet_id": 80341, "code": " either with --not-regex or with --true-regex.\") if args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if", "label": 0}, {"snippet_id": 10715, "code": "\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text", "label": 1}, {"snippet_id": 68788, "code": " target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i", "label": 0}, {"snippet_id": 42438, "code": "._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output", "label": 0}, {"snippet_id": 80720, "code": "] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData", "label": 0}, {"snippet_id": 50856, "code": ") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file)", "label": 1}, {"snippet_id": 21206, "code": " def resp(self): return self._result_getter() class AwaitableEvent(Awaitable): def __init__(self, name, result_getter, event=None): super(AwaitableEvent, self).__init__(name, event) self._result_getter", "label": 0}, {"snippet_id": 69582, "code": " command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError(opt", "label": 0}, {"snippet_id": 51673, "code": "\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname:", "label": 0}, {"snippet_id": 21764, "code": ", 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X[:, 1]=labelencoder_X_1.fit_transform(X[:, 1]) labelencoder_X_2", "label": 0}, {"snippet_id": 71676, "code": " ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import", "label": 0}, {"snippet_id": 90024, "code": " cmd=[java, '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self", "label": 0}, {"snippet_id": 47525, "code": " self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__", "label": 0}, {"snippet_id": 27853, "code": ": self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle", "label": 0}, {"snippet_id": 93670, "code": ".check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running", "label": 0}, {"snippet_id": 66317, "code": " if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 38116, "code": "() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher", "label": 0}, {"snippet_id": 5920, "code": " the fulltext from local or remote documents. Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url", "label": 0}, {"snippet_id": 34238, "code": " message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate", "label": 0}, {"snippet_id": 35530, "code": " consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall", "label": 0}, {"snippet_id": 7719, "code": ".items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append", "label": 0}, {"snippet_id": 40541, "code": " flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type", "label": 0}, {"snippet_id": 94161, "code": " session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info", "label": 0}, {"snippet_id": 94834, "code": " args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check)", "label": 0}, {"snippet_id": 37745, "code": "=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str", "label": 0}, {"snippet_id": 42734, "code": " flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True,", "label": 0}, {"snippet_id": 63969, "code": ".installed_tool_dependencies or[] return dependencies.DependenciesDescription( requirements=requirements, installed_tool_dependencies=installed_tool_dependencies, ) @staticmethod def __dependency_resolution", "label": 0}, {"snippet_id": 71186, "code": "%s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target", "label": 0}, {"snippet_id": 95416, "code": ") except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}", "label": 0}, {"snippet_id": 51082, "code": "=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self):", "label": 0}, {"snippet_id": 48674, "code": ") try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards", "label": 0}, {"snippet_id": 36624, "code": "._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except", "label": 0}, {"snippet_id": 40033, "code": " return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self", "label": 1}, {"snippet_id": 63805, "code": " pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id", "label": 0}, {"snippet_id": 78200, "code": "=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets) super().__init__(*args, **kvargs) def on_caprate_limit(self, rate): if not self.logined: self._capdata=(0, 0", "label": 0}, {"snippet_id": 58743, "code": " user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission) self.client.login( username=self.tester.username, password", "label": 0}, {"snippet_id": 93154, "code": " argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime", "label": 0}, {"snippet_id": 4949, "code": " composite_keywords, author_keywords, acronyms)) output.append('</record></collection>') return '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field", "label": 0}, {"snippet_id": 91872, "code": ".python_distribution import PythonDistribution from pants.base.exceptions import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import", "label": 0}, {"snippet_id": 9953, "code": " if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords", "label": 0}, {"snippet_id": 21869, "code": " vars from ansible.executor import playbook_executor from ansible.parsing import dataloader from ansible.utils.display import Display from dciclient.v1 import helper as dci_helper from dciagent.plugins", "label": 0}, {"snippet_id": 85535, "code": ".ZINC_COMPILER_TOOL_NAME, cls.options_scope) @classmethod def _compiler_bridge(cls, products): return cls.tool_jar_from_products(products, 'compiler-bridge', cls.options_scope) @classmethod def _compiler_interface(cls", "label": 0}, {"snippet_id": 384, "code": "() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False", "label": 0}, {"snippet_id": 14547, "code": "()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 55810, "code": ".shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate", "label": 0}, {"snippet_id": 28571, "code": "['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl", "label": 0}, {"snippet_id": 70663, "code": ".nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view", "label": 0}, {"snippet_id": 58275, "code": " from tcms.tests import BasePlanCase from tcms.tests import remove_perm_from_user from tcms.tests import user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories import", "label": 0}, {"snippet_id": 27757, "code": " self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 21351, "code": " pass to `mpv`.') args=parser.parse_args() subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ['HOME'] +\"/.reddytt\" sr_dir", "label": 1}, {"snippet_id": 50126, "code": " first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]", "label": 0}, {"snippet_id": 57308, "code": ") t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"\" Update Case Run", "label": 0}, {"snippet_id": 78294, "code": ".sleep(self.comment_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.schedule(self.add_comment,(t, msg)) except exc.UnknownAnswer as e: self.log.warn('%s: ", "label": 0}, {"snippet_id": 13491, "code": " import os\r from random import randint\r from threading import Thread\r from chippyRuxpin_audioPlayer import AudioPlayer\r from chippyRuxpin_gpio import GPIO\r from chippyRuxpin_twitter import ChippyTwitter\r", "label": 0}, {"snippet_id": 58557, "code": ".many_comments_url, {'comment': new_comment, 'run': ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response':", "label": 0}, {"snippet_id": 42902, "code": "\"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name", "label": 0}, {"snippet_id": 70274, "code": " start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv", "label": 0}, {"snippet_id": 60603, "code": " queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue", "label": 0}, {"snippet_id": 57527, "code": " resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets(self): \"\"\"Get selected cases to update their properties\"\"\" case_ids=map(int, self.request.POST", "label": 0}, {"snippet_id": 20271, "code": " launch_script(self, filename, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is", "label": 0}, {"snippet_id": 9967, "code": ") acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"", "label": 0}, {"snippet_id": 80310, "code": " args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size", "label": 0}, {"snippet_id": 61542, "code": " @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A(openqml.Operation or openqml.Expectation): operation/observable. Returns: array: matrix representation.", "label": 0}, {"snippet_id": 66726, "code": " CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except", "label": 1}, {"snippet_id": 72313, "code": " del kwargs['source'] irc.reply(text, source=irc.pseudoclient.uid, **kwargs) old_reply=remoteirc.reply with remoteirc.reply_lock: try: log.debug('(%s) networks.remote: overriding reply() of IRC object %s'", "label": 1}, {"snippet_id": 8950, "code": " string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str ", "label": 0}, {"snippet_id": 64543, "code": " \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self)", "label": 0}, {"snippet_id": 66539, "code": " GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes())", "label": 0}, {"snippet_id": 59121, "code": ".backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()\t A simple introspective simulator", "label": 0}, {"snippet_id": 92458, "code": " path: self.assertEqual(tempdir, path) self.assertEqual(os.path.realpath(tempdir), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_nested_pushd(self)", "label": 0}, {"snippet_id": 44707, "code": ".included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys", "label": 0}, {"snippet_id": 74626, "code": " to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config", "label": 0}, {"snippet_id": 19162, "code": "/response cycle of an api call against a swagger schema. Request/Response objects from the `requests` and `urllib` library are supported. \"\"\" request=normalize_request(raw_request) with ErrorDict() as errors", "label": 0}, {"snippet_id": 47814, "code": " self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow", "label": 0}, {"snippet_id": 22104, "code": "/ansible/hosts' ) self.variable_manager.set_inventory(self.inventory) pb_dir=os.path.abspath('.') playbook_path=\"%s/%s\" %(pb_dir, playbook) display.verbosity=self.options.verbosity self.pbex=playbook_executor", "label": 1}, {"snippet_id": 36786, "code": ".missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if", "label": 0}, {"snippet_id": 16980, "code": " if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache", "label": 0}, {"snippet_id": 49726, "code": " logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False", "label": 0}, {"snippet_id": 38095, "code": "(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames", "label": 0}, {"snippet_id": 52992, "code": ".rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern,", "label": 0}, {"snippet_id": 73027, "code": "(remote_subdirs_list is not None) and(len(remote_subdirs_list) > 0): remote_path_relative=\"/\".join(remote_subdirs_list) remote_path_absolute=\"/\" +remote_directory +\"/\" +remote_path_relative +\"/\" else: remote_subdirs_list", "label": 0}, {"snippet_id": 68864, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout", "label": 0}, {"snippet_id": 3678, "code": ".debug(\"No custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug", "label": 0}, {"snippet_id": 19330, "code": " def test_yaml_file_path(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file", "label": 0}, {"snippet_id": 36616, "code": "(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name", "label": 0}, {"snippet_id": 44482, "code": ".persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items,", "label": 0}, {"snippet_id": 34172, "code": ", rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate", "label": 0}, {"snippet_id": 66984, "code": " self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in", "label": 0}, {"snippet_id": 61084, "code": " 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_x \\theta/2}` \"\"\" return expm(-1j * theta", "label": 0}, {"snippet_id": 10256, "code": " def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their", "label": 0}, {"snippet_id": 54497, "code": " def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False):", "label": 0}, {"snippet_id": 72514, "code": " config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\",", "label": 0}, {"snippet_id": 11367, "code": " LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s, writing to %s\" % (self.source, self.target_dir)", "label": 0}, {"snippet_id": 67493, "code": ".Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base", "label": 0}, {"snippet_id": 75288, "code": " raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value(tuple(iden), reqid) handler(reqid, interface, method, msg[1:]) return() def _parse_rep", "label": 0}, {"snippet_id": 71255, "code": "=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append", "label": 0}, {"snippet_id": 89208, "code": ": The path to scan; by default, the build root. :returns: A new build graph encapsulating the targets found. \"\"\" build_graph=self.build_graph.clone_new() for address in self.address_mapper.scan_addresses", "label": 0}, {"snippet_id": 9439, "code": "(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords", "label": 0}, {"snippet_id": 16872, "code": "/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response", "label": 0}, {"snippet_id": 4493, "code": ".normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext", "label": 0}, {"snippet_id": 22913, "code": " the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. We also", "label": 0}, {"snippet_id": 49713, "code": " and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing", "label": 0}, {"snippet_id": 28870, "code": "': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 42238, "code": " shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(", "label": 0}, {"snippet_id": 29275, "code": "(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP ", "label": 0}, {"snippet_id": 61123, "code": " array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm(-1j * theta/2 * Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns", "label": 0}, {"snippet_id": 71454, "code": " import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine", "label": 0}, {"snippet_id": 19587, "code": "('--host', '--server-host', '--port', '-m'): if arg=='-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append", "label": 1}, {"snippet_id": 21763, "code": "=dataset.iloc[:, 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X[:, 1]=labelencoder_X_1.fit_transform(X[:, 1]) labelencoder_X_2", "label": 0}, {"snippet_id": 37962, "code": " output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile", "label": 0}, {"snippet_id": 16831, "code": " _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description'", "label": 0}, {"snippet_id": 64352, "code": " parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[ parameter_value] if parameter_value in", "label": 0}, {"snippet_id": 11804, "code": ": http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key", "label": 1}, {"snippet_id": 7775, "code": ":return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw", "label": 0}, {"snippet_id": 81525, "code": ",regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t\t\t\tself.logger.debug(\"Requesting %s...\",url) \t\t \t\tr=self.session.get(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger", "label": 0}, {"snippet_id": 6752, "code": "(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext", "label": 0}, {"snippet_id": 40464, "code": ".escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match):", "label": 0}, {"snippet_id": 14155, "code": " OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm", "label": 0}, {"snippet_id": 37328, "code": " in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item", "label": 0}, {"snippet_id": 94038, "code": " dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name", "label": 0}, {"snippet_id": 84470, "code": " local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"%s_files\" % remote_path[ 0:-len( ", "label": 0}, {"snippet_id": 45630, "code": ")) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names", "label": 1}, {"snippet_id": 90397, "code": "): yield self.Location.from_home(home) class _ExplicitEnvironment(_DistributionEnvironment): def __init__(self, *homes): self._homes=homes @property def jvm_locations(self): for home in self._homes: yield", "label": 0}, {"snippet_id": 49896, "code": ".persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n", "label": 0}, {"snippet_id": 36860, "code": ".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return", "label": 0}, {"snippet_id": 94902, "code": "(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the benchmark run), and config argument for where is", "label": 0}, {"snippet_id": 67898, "code": " the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration", "label": 0}, {"snippet_id": 74622, "code": " Creates an object representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation", "label": 0}, {"snippet_id": 79053, "code": " regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing", "label": 0}, {"snippet_id": 42198, "code": " self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else", "label": 0}, {"snippet_id": 62925, "code": " import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep import os from.lwr_client import build_client_manager from.lwr_client", "label": 0}, {"snippet_id": 21367, "code": ".environ['HOME'] +\"/.reddytt\" sr_dir=work_dir +\"/%s\" % subreddit seen_file=sr_dir +\"/seen\" seen_links=[] unseen_file=sr_dir +\"/unseen\" unseen_links=[] print(\"Reddytt: Checking for reddytt working directory(", "label": 0}, {"snippet_id": 95026, "code": ".add_argument(\"--label\", type=str, default=\"run\", metavar=\"RUN_LABEL\", help=\"Label for the benchmark run.\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to", "label": 1}, {"snippet_id": 52566, "code": " self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in", "label": 0}, {"snippet_id": 60289, "code": "'Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock', 'X', 'P', 'Homodyne", "label": 0}, {"snippet_id": 94623, "code": ", comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",", "label": 0}, {"snippet_id": 50031, "code": " be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks", "label": 0}, {"snippet_id": 44675, "code": "(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included:", "label": 0}, {"snippet_id": 6068, "code": " fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try", "label": 1}, {"snippet_id": 81584, "code": "(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes", "label": 1}, {"snippet_id": 72038, "code": " list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1: network", "label": 0}, {"snippet_id": 56408, "code": " self.product_id=0 def builds(self): try: is_active=strtobool(self.request.GET.get('is_active', default='False')) except(ValueError, TypeError): is_active=False return Build.objects.filter(product_id=self", "label": 0}, {"snippet_id": 7101, "code": "[w[0].concept]=w[0].type for w in single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags", "label": 0}, {"snippet_id": 22276, "code": ".common.utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger", "label": 0}, {"snippet_id": 57282, "code": "%( field, getattr(t, field), request.user ) ) field='assignee' try: assignee=t.assginee if assignee !=request.user: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr", "label": 0}, {"snippet_id": 50468, "code": "=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate", "label": 0}, {"snippet_id": 35657, "code": ", names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield", "label": 0}, {"snippet_id": 45974, "code": " value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString", "label": 0}, {"snippet_id": 74371, "code": "/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return", "label": 0}, {"snippet_id": 84161, "code": "): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False)) return remote_metadata @staticmethod def __remote_work_dir_copy( lwr_client): return LwrJobRunner", "label": 0}, {"snippet_id": 70727, "code": ".status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), ", "label": 1}, {"snippet_id": 39781, "code": ".norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring", "label": 0}, {"snippet_id": 87997, "code": "'d have to put the entire external classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published as \"fat jars\"(which appears to be the norm, since SBT doesn't support", "label": 0}, {"snippet_id": 92276, "code": " as output: with environment_as(HORK='BORK'): subprocess.Popen([sys.executable, '-c', 'import os; print(os.environ[\"HORK\"])'], stdout=output).wait() output.seek(0) self.assertEqual('BORK\\n', output.read", "label": 0}, {"snippet_id": 43596, "code": " urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources", "label": 0}, {"snippet_id": 26638, "code": "'battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif", "label": 0}, {"snippet_id": 34475, "code": " in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via", "label": 0}, {"snippet_id": 25415, "code": " netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name", "label": 0}, {"snippet_id": 85708, "code": "/remapped_by_pants/java_home/', get_buildroot(): '/dev/null/remapped_by_pants/buildroot/', self._zinc_factory.get_options().pants_workdir: '/dev/null/remapped_by_pants/workdir/', } return( '-rebase-map', '", "label": 0}, {"snippet_id": 56440, "code": "=self.product_id) def components(self): return Component.objects.filter(product__id=self.product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties(self): if self.request.GET.get", "label": 0}, {"snippet_id": 8960, "code": " output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache", "label": 0}, {"snippet_id": 82922, "code": "=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix", "label": 1}, {"snippet_id": 89253, "code": " :param name: A descriptive name representing the process being executed. :param labels: A tuple of WorkUnitLabels. :return: An ExecuteProcessResult with information about the execution. Note that this", "label": 0}, {"snippet_id": 3791, "code": "=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window", "label": 0}, {"snippet_id": 76758, "code": ") parser.add_argument('--caprate_minp', type=int, default=5, help='Cap rate minimum possible count for limit check') parser.add_argument('--caprate_limit', type=float, default=0.8, help='Captcha rate limit", "label": 0}, {"snippet_id": 48804, "code": " IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self", "label": 0}, {"snippet_id": 29805, "code": " after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that", "label": 0}, {"snippet_id": 12173, "code": " script on the files and update the data dictionary \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository", "label": 0}, {"snippet_id": 91564, "code": " target_adaptor in python_target_adaptors for constraint in python_setup.compatibility_or_constraints( getattr(target_adaptor, 'compatibility', None) ) } constraints_args=[] for constraint in sorted(constraints)", "label": 0}, {"snippet_id": 6361, "code": " using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and", "label": 0}, {"snippet_id": 57604, "code": "(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets().update(**", "label": 0}, {"snippet_id": 13634, "code": " Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\" 2>/dev/null\") time.sleep( 0.5)\r os.system( \"espeak -w speech.wav \\\"\" +myText +\"\\\" -s 130\")\r audio.play(\"speech.wav\")\r return", "label": 1}, {"snippet_id": 4701, "code": " object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader", "label": 0}, {"snippet_id": 26411, "code": "\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self", "label": 0}, {"snippet_id": 38100, "code": "(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given", "label": 0}, {"snippet_id": 64744, "code": " print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand", "label": 0}, {"snippet_id": 52326, "code": " self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output", "label": 0}, {"snippet_id": 35180, "code": " output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary", "label": 0}, {"snippet_id": 91649, "code": "=sorted(all_target_requirements +list(pytest.get_requirement_strings())) python_binary=text_type(sys.executable) interpreter_constraint_args=parse_interpreter_constraints( python_setup, python_target_adaptors", "label": 0}, {"snippet_id": 66550, "code": ", None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf", "label": 0}, {"snippet_id": 55197, "code": " f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster", "label": 0}, {"snippet_id": 86925, "code": "--incremental', advanced=True, type=bool, default=True, help='When set, zinc will use sub-target incremental compilation, which dramatically ' 'improves compile performance while changing large targets", "label": 0}, {"snippet_id": 68302, "code": " layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index", "label": 0}, {"snippet_id": 41085, "code": ", j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda", "label": 0}, {"snippet_id": 88817, "code": " labels=None, cmd='', log_config=None): \"\"\"Create a new workunit under the calling thread's current workunit. :API: public \"\"\" with self.run_tracker.new_workunit(name=name, labels=labels, cmd=cmd, log_config", "label": 0}, {"snippet_id": 20903, "code": "'.format(command, seq) with self._wait_for_message(match, handlername, **kwargs): yield result def _close(self): if self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread", "label": 0}, {"snippet_id": 66050, "code": " \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"", "label": 0}, {"snippet_id": 19188, "code": "['request'].add_error(err.messages or getattr(err, 'detail')) return response=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema", "label": 0}, {"snippet_id": 27274, "code": "'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl", "label": 1}, {"snippet_id": 76503, "code": ": self.log.info('Aborted') self.running.set() self.unbind_methods() self.running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase", "label": 0}, {"snippet_id": 15821, "code": ": dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA:", "label": 0}, {"snippet_id": 60489, "code": ", Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CoherentState': Coherent, 'DisplacedSqueezed': DisplacedSqueezed", "label": 0}, {"snippet_id": 52222, "code": " RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs", "label": 0}, {"snippet_id": 92765, "code": ".finish, clock.time()) def test_open_zipDefault(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w') as zf: self.assertTrue(zf._allowZip64) def test_open_zipTrue(self):", "label": 0}, {"snippet_id": 978, "code": " action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group", "label": 0}, {"snippet_id": 54576, "code": "=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules", "label": 0}, {"snippet_id": 53472, "code": "\"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input", "label": 0}, {"snippet_id": 74441, "code": "\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"", "label": 0}, {"snippet_id": 81685, "code": " \t\t\t\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex", "label": 0}, {"snippet_id": 75685, "code": ".wz_auth_requests=[] self.wz_bind_methods=[] self.wz_poll_timeout=30 def __sinit__(self): '''Initializes thread-local interface on startup''' self.log=logging.getLogger(self.name) self.running=threading.Event()", "label": 1}, {"snippet_id": 93166, "code": " import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT,", "label": 0}, {"snippet_id": 17675, "code": " 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else", "label": 0}, {"snippet_id": 41057, "code": "(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"", "label": 0}, {"snippet_id": 23212, "code": ".IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)) param=struct.pack('iL', expected*struct_size, buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno(), 0x8912, param) retsize=(struct.unpack('iL',", "label": 0}, {"snippet_id": 81681, "code": "\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode", "label": 0}, {"snippet_id": 50439, "code": "(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, ", "label": 0}, {"snippet_id": 81105, "code": "\t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms", "label": 0}, {"snippet_id": 59014, "code": "=cls.group_nitrate, property=cls.property_os) EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_python) EnvGroupPropertyMapFactory(group=cls.group_new, property=cls.property_django", "label": 0}, {"snippet_id": 78669, "code": " \"\"\"To be overridden by sub classes\"\"\" pass def run(self): try: if self.options is not None and self.options.daemon: log.logger.debug('Executing remotely') return self.executer(*sys.argv) log.logger.debug", "label": 1}, {"snippet_id": 3487, "code": "(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info", "label": 0}, {"snippet_id": 17383, "code": "+str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash", "label": 0}, {"snippet_id": 6645, "code": " spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param", "label": 1}, {"snippet_id": 15935, "code": " @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri", "label": 1}, {"snippet_id": 43576, "code": ": comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order.__iter__()", "label": 0}, {"snippet_id": 66917, "code": " import commandList from Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def", "label": 0}, {"snippet_id": 36685, "code": ".params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\":", "label": 0}, {"snippet_id": 90747, "code": "(self._distribution_environment.jvm_locations): try: dist=Distribution(home_path=location.home_path, bin_path=location.bin_path, minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk)", "label": 0}, {"snippet_id": 89508, "code": " the path to the java distribution's home dir :param string bin_path: the path to the java distribution's bin dir :param minimum_version: a modified semantic version string or else a Revision object :param", "label": 0}, {"snippet_id": 71174, "code": ": if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status", "label": 0}, {"snippet_id": 33941, "code": " if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c", "label": 0}, {"snippet_id": 19391, "code": "\"\" PYDEVD_OPTS={ '--file', '--client', '--vm_type', } PYDEVD_FLAGS={ '--DEBUG', '--DEBUG_RECORD_SOCKET_READS', '--cmd-line', '--module', '--multiproc', '--multiprocess', '--print-in-debugger-startup', ", "label": 0}, {"snippet_id": 9850, "code": " int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format", "label": 0}, {"snippet_id": 38654, "code": " items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self", "label": 0}, {"snippet_id": 75526, "code": "): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self", "label": 0}, {"snippet_id": 39221, "code": "))) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()", "label": 0}, {"snippet_id": 72881, "code": " :type ftp_config: config.FTPConfigurationRepresentation :type local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server", "label": 0}, {"snippet_id": 95962, "code": " is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset", "label": 0}, {"snippet_id": 61833, "code": ") def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1.6,[0]) qm.RY(y,[1]) qm.CNOT([1, 0]) qm.RX(z,[0]) qm.CNOT([0, 1]) qm.expectation.Hermitian(np.array([[0, 1],[1, 0]]), 0) circuits={'demo_ev': QNode", "label": 0}, {"snippet_id": 95931, "code": " input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion :type input_vcf_path: str :type output_zarr_path: str :type", "label": 0}, {"snippet_id": 73559, "code": ".vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read", "label": 0}, {"snippet_id": 58012, "code": ".get('a') data['bz_external_track']=True if request.GET.get('bz_external_track', False) else False return(data, '') def update_bugs_to_caseruns(request): \"\"\" Add one or more bugs to or remove that from", "label": 0}, {"snippet_id": 20357, "code": " read_messages, raw_write_one as write_message ) from.socket import( Connection, create_server, create_client, close, recv_as_read, send_as_write, timeout as socket_timeout) from.threading import get_locked_and_waiter", "label": 0}, {"snippet_id": 15673, "code": " 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive", "label": 0}, {"snippet_id": 58144, "code": "(product__in=p_pks) attr=ctypes[target][1] results=[(r.pk, getattr(r, attr)) for r in results] return results def get_prod_related_obj_json(request): \"\"\" View for updating product drop-down\\n in a Ajax way. \"\"", "label": 0}, {"snippet_id": 3026, "code": ", comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component", "label": 0}, {"snippet_id": 91899, "code": ".objects import SubclassesOf logger=logging.getLogger(__name__) class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope='python", "label": 1}, {"snippet_id": 43507, "code": " def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add", "label": 0}, {"snippet_id": 24792, "code": " >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle']", "label": 0}, {"snippet_id": 65196, "code": " to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>", "label": 0}, {"snippet_id": 21831, "code": " classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11)) classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu')) classifier.add(Dense(units", "label": 1}, {"snippet_id": 3449, "code": " found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if self.kill_mode: self.logger", "label": 0}, {"snippet_id": 18938, "code": " callable(source.read): raw_source=source.read() elif os.path.exists(os.path.expanduser(str(source))): with open(os.path.expanduser(str(source)), 'r') as source_file: raw_source=source_file.read() elif", "label": 0}, {"snippet_id": 70146, "code": " target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc", "label": 0}, {"snippet_id": 23782, "code": " processor cores.\") try: return int(output) except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set", "label": 0}, {"snippet_id": 79179, "code": "): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex", "label": 0}, {"snippet_id": 50009, "code": ".resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\")", "label": 0}, {"snippet_id": 75256, "code": ": del self.response_handlers[reqid] def del_sig_handler(self, interface, method): del self.sig_handlers[(interface, method)] def _parse_req(self, iden, msg, reqid, interface, method): try: handler=self", "label": 0}, {"snippet_id": 5685, "code": " \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone", "label": 0}, {"snippet_id": 87955, "code": " plugin. This allows us to have in-repo plugins with dependencies(unlike javac, scalac doesn't load plugins or their deps from the regular classpath, so we have to provide these entries separately, in the", "label": 0}, {"snippet_id": 94305, "code": " start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self.window_name) def", "label": 0}, {"snippet_id": 74269, "code": " \"\"\" Args: location of the configuration file, existing configuration dictionary Returns: a dictionary of the form <dict>.<section>[<option>] and the corresponding values. \"\"\" config=ConfigurationRepresentation", "label": 0}, {"snippet_id": 37861, "code": " concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output", "label": 0}, {"snippet_id": 64165, "code": "]=remote_system_properties.get('galaxy_dataset_files_path', None) if LwrJobRunner.__use_remote_datatypes_conf( client): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file", "label": 0}, {"snippet_id": 84636, "code": "): if not self.get_options().transitive: targets=self.context.target_roots input_snapshots=tuple( target.sources_snapshot(scheduler=self.context._scheduler) for target in targets ) input_files={f.path for", "label": 0}, {"snippet_id": 37614, "code": " start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs", "label": 0}, {"snippet_id": 80770, "code": "]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\"", "label": 1}, {"snippet_id": 17033, "code": "() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data", "label": 0}, {"snippet_id": 46008, "code": " shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An", "label": 0}, {"snippet_id": 36105, "code": " if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input:", "label": 0}, {"snippet_id": 86531, "code": " import DirectoryToMaterialize, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator from pants", "label": 0}, {"snippet_id": 86262, "code": ".fatal_warnings_enabled_args) else: javac_cmd.extend(self.get_options().fatal_warnings_disabled_args) with argfile.safe_args(ctx.sources, self.get_options()) as batched_sources: javac_cmd.extend(batched_sources", "label": 0}, {"snippet_id": 89050, "code": " transitive dependencies with a postorder traversal; `False` or preorder by default. :returns: A list of matching targets. \"\"\" target_set=self._collect_targets(self.target_roots, **kwargs) synthetics=OrderedSet", "label": 0}, {"snippet_id": 70394, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 18911, "code": "-python object(dictionary-like) -path to yaml file -path to json file -file object(json or yaml). -json string. -yaml string. \"\"\" if isinstance(source, collections.Mapping): return source elif hasattr(source", "label": 0}, {"snippet_id": 6205, "code": " number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"", "label": 1}, {"snippet_id": 95012, "code": "\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default", "label": 1}, {"snippet_id": 3133, "code": " unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill", "label": 0}, {"snippet_id": 25474, "code": " the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the", "label": 0}, {"snippet_id": 40788, "code": " values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists ", "label": 0}, {"snippet_id": 55158, "code": " updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self", "label": 0}, {"snippet_id": 83716, "code": " run_results=client.full_status() stdout=run_results.get('stdout', '') stderr=run_results.get('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results", "label": 0}, {"snippet_id": 19872, "code": " RuntimeError('debug client closed') if self._adapter is None: raise RuntimeError('debugger not running') if self._session is not None: self._detach() try: self._adapter.close() except ClosedError: pass", "label": 0}, {"snippet_id": 67710, "code": " %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to", "label": 0}, {"snippet_id": 33656, "code": ".persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items,", "label": 0}, {"snippet_id": 24824, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] ", "label": 0}, {"snippet_id": 69763, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client", "label": 0}, {"snippet_id": 80857, "code": "\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a \t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName", "label": 0}, {"snippet_id": 37736, "code": ".allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item", "label": 0}, {"snippet_id": 81811, "code": " +=\"\\n\\tDefault templates are the following(name -description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection", "label": 0}, {"snippet_id": 184, "code": " print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", },", "label": 0}, {"snippet_id": 48313, "code": "(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item)", "label": 0}, {"snippet_id": 60255, "code": " number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x,", "label": 0}, {"snippet_id": 27879, "code": " if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" ", "label": 0}, {"snippet_id": 84123, "code": " installed_tool_dependencies=job_wrapper.tool.installed_tool_dependencies or[] return dependencies.DependenciesDescription( requirements=requirements, installed_tool_dependencies=installed_tool_dependencies, ", "label": 0}, {"snippet_id": 2261, "code": ", safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen", "label": 0}, {"snippet_id": 77154, "code": ".pr_sock=self.p.ctx.socket(zmq.PUB) self.pr_sock.bind(self.pr_sa) def init_pr_back_sock(self): self.log.info( 'Initializing interprocess backward socket %s', self.pr_ba) self.pr_back_sock=self.p.ctx.socket", "label": 0}, {"snippet_id": 13641, "code": " 0.5)\r os.system( \"espeak -w speech.wav \\\"\" +myText +\"\\\" -s 130\")\r audio.play(\"speech.wav\")\r return myText\r \r mouthThread=Thread(target=updateMouth)\r mouthThread.start()\r eyesThread=Thread(target=updateEyes", "label": 1}, {"snippet_id": 52092, "code": "\"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file", "label": 0}, {"snippet_id": 25544, "code": ": self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1", "label": 0}, {"snippet_id": 6881, "code": " are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position,", "label": 0}, {"snippet_id": 41946, "code": " unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_", "label": 0}, {"snippet_id": 75740, "code": " s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) self.wz_sock=s self.wz=WZHandler() def term_handler(interface, method, data): self.log.info( 'Termination", "label": 1}, {"snippet_id": 93843, "code": " window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s", "label": 0}, {"snippet_id": 4283, "code": "=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify", "label": 1}, {"snippet_id": 73404, "code": ": Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str(input_vcf_dir) output_zarr_dir", "label": 0}, {"snippet_id": 16607, "code": " self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self)", "label": 0}, {"snippet_id": 74645, "code": "(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str", "label": 0}, {"snippet_id": 87717, "code": ".materialize_directories(( DirectoryToMaterialize(get_buildroot(), res.output_directory_digest), )) return res.output_directory_digest else: if self.runjava(classpath=[self._zinc.zinc], main=Zinc.ZINC_COMPILE_MAIN,", "label": 0}, {"snippet_id": 37984, "code": ".snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given", "label": 0}, {"snippet_id": 51605, "code": " in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\"", "label": 0}, {"snippet_id": 23430, "code": " \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None: cmd=\"pw useradd{0} -e{1} -m\".format", "label": 0}, {"snippet_id": 32113, "code": "(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError", "label": 0}, {"snippet_id": 59074, "code": " expected_json=json.loads( serializers.serialize( 'json', group.property.all(), fields=('name', 'value'))) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), expected_json)", "label": 0}, {"snippet_id": 14130, "code": " data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data[ 'message'])", "label": 0}, {"snippet_id": 45622, "code": " f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill", "label": 1}, {"snippet_id": 244, "code": "'nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname", "label": 0}, {"snippet_id": 1894, "code": " datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8)", "label": 0}, {"snippet_id": 4761, "code": " the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list", "label": 0}, {"snippet_id": 68054, "code": ">][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for", "label": 0}, {"snippet_id": 15867, "code": " import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self", "label": 0}, {"snippet_id": 24309, "code": " vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass,", "label": 0}, {"snippet_id": 32140, "code": " files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for", "label": 0}, {"snippet_id": 85268, "code": " create_jardep_func in specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address): jars=[create_jardep_func(self", "label": 0}, {"snippet_id": 30880, "code": ".expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\"", "label": 1}, {"snippet_id": 44418, "code": " in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False", "label": 0}, {"snippet_id": 63803, "code": " self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM", "label": 0}, {"snippet_id": 78587, "code": ".forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try:", "label": 0}, {"snippet_id": 23164, "code": " curiously, our 64bit platform is identified by python in Azure(Stack) as 32 bit and without adjusting the struct_size, we can't get the information we need. I believe this may be caused by only python", "label": 0}, {"snippet_id": 18836, "code": " urllib_parse as urlparse import os import collections import requests import six import json import yaml from flex.context_managers import ErrorDict from flex.exceptions import ValidationError from flex", "label": 0}, {"snippet_id": 54348, "code": ".name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames))", "label": 0}, {"snippet_id": 6166, "code": " word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines", "label": 1}, {"snippet_id": 55813, "code": "\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring", "label": 0}, {"snippet_id": 37532, "code": ": start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have", "label": 0}, {"snippet_id": 84400, "code": ".working_directory()) self._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self", "label": 0}, {"snippet_id": 24870, "code": "='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 86244, "code": ") else: javac_cmd.extend([ '-d', ctx.classes_dir, ]) javac_cmd.extend(self._javac_plugin_args(javac_plugin_map)) javac_cmd.extend(args) if fatal_warnings: javac_cmd.extend(self.get_options().fatal_warnings_enabled_args", "label": 0}, {"snippet_id": 86017, "code": ") +(JvmPlatform,) @classmethod def prepare(cls, options, round_manager): super(JavacCompile, cls).prepare(options, round_manager) @classmethod def product_types(cls): return['runtime_classpath'] def __init__", "label": 0}, {"snippet_id": 31265, "code": " in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self", "label": 0}, {"snippet_id": 62264, "code": " for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name", "label": 0}, {"snippet_id": 88846, "code": ": \"\"\" Acquire the global lock for the root directory associated with this context. When a goal requires serialization, it will call this to acquire the lock. :API: public \"\"\" if self.options.for_global_scope", "label": 0}, {"snippet_id": 54934, "code": "(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain", "label": 0}, {"snippet_id": 61805, "code": " 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit", "label": 0}, {"snippet_id": 49415, "code": " force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait", "label": 0}, {"snippet_id": 1810, "code": "\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name'", "label": 0}, {"snippet_id": 85449, "code": " Shader.exclude_package('xsbt', recursive=True), Shader.exclude_package('xsbti', recursive=True), Shader.exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc", "label": 0}, {"snippet_id": 40118, "code": ": mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file", "label": 0}, {"snippet_id": 84539, "code": " import os from builtins import open from future.utils import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants.base.workunit import WorkUnitLabel from pants.engine", "label": 0}, {"snippet_id": 16650, "code": "): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive", "label": 0}, {"snippet_id": 21811, "code": " StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) import keras from keras.models import Sequential from keras.layers import Dense classifier=Sequential()", "label": 0}, {"snippet_id": 24086, "code": "{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*", "label": 0}, {"snippet_id": 17560, "code": "._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return", "label": 0}, {"snippet_id": 72329, "code": ".remote: overriding reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '", "label": 1}, {"snippet_id": 14818, "code": "'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py", "label": 0}, {"snippet_id": 53024, "code": " self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else", "label": 0}, {"snippet_id": 69523, "code": "=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self", "label": 0}, {"snippet_id": 52503, "code": "\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in", "label": 0}, {"snippet_id": 60144, "code": " contains the device class and context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate", "label": 0}, {"snippet_id": 82302, "code": " <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload", "label": 0}, {"snippet_id": 16929, "code": ", 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session", "label": 1}, {"snippet_id": 29274, "code": ".path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat", "label": 0}, {"snippet_id": 2762, "code": "' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found", "label": 0}, {"snippet_id": 66222, "code": "\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag", "label": 0}, {"snippet_id": 38064, "code": "\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self,", "label": 0}, {"snippet_id": 57629, "code": " user=User.objects.get(Q(username=self.new_value) | Q(email=self.new_value)) except User.DoesNotExist: raise ObjectDoesNotExist('Default tester not found!') self.get_update_targets().update(**{str(self", "label": 0}, {"snippet_id": 66924, "code": "\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list)", "label": 0}, {"snippet_id": 29968, "code": ") def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard", "label": 0}, {"snippet_id": 89161, "code": " def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets parsed in the", "label": 0}, {"snippet_id": 38634, "code": ".global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items", "label": 0}, {"snippet_id": 8560, "code": " log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb ", "label": 1}, {"snippet_id": 41958, "code": " omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark", "label": 0}, {"snippet_id": 55264, "code": ")) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 17422, "code": ".PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen", "label": 0}, {"snippet_id": 94775, "code": "=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch to kill mode\", action=\"store_true\") remote_mutex.add_argument('-c', '--check', help=", "label": 0}, {"snippet_id": 83204, "code": " string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\"", "label": 0}, {"snippet_id": 75450, "code": ", iden): return self.iden_reqid_map.get_values(iden) def make_reqid(self): while True: reqid=random.randint(1,(2**64)-1) if not reqid in self.response_handlers: return reqid def make_auth_req_data(self", "label": 1}, {"snippet_id": 42207, "code": ".nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\")", "label": 0}, {"snippet_id": 38586, "code": ", drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary", "label": 0}, {"snippet_id": 51298, "code": "\"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards", "label": 0}, {"snippet_id": 94645, "code": "'echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory)", "label": 0}, {"snippet_id": 37631, "code": "(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str", "label": 0}, {"snippet_id": 62458, "code": ". Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the", "label": 0}, {"snippet_id": 88741, "code": " workunit_parent=workunit_parent, done_hook=done_hook) def background_worker_pool(self): \"\"\"Returns the pool to which tasks can submit background work. :API: public \"\"\" return self.run_tracker.background_worker_pool", "label": 0}, {"snippet_id": 51999, "code": " return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr", "label": 0}, {"snippet_id": 43314, "code": ".output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input,", "label": 0}, {"snippet_id": 23872, "code": " err: raise OSUtilError(\"Can't find ether interface:{0}\".format(output)) ifaces=output.split() if not ifaces: raise OSUtilError(\"Can't find ether interface.\") iface=ifaces[0] err, output=shellutil.run_get_output", "label": 0}, {"snippet_id": 29065, "code": " get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data", "label": 1}, {"snippet_id": 32609, "code": " if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or", "label": 0}, {"snippet_id": 70607, "code": ".view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE:", "label": 0}, {"snippet_id": 50333, "code": " integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have", "label": 0}, {"snippet_id": 76358, "code": " send_to_router(self, msg): msg.insert(0, b'') self.wz_sock.send_multipart(msg) def inter_sleep(self, timeout): self.sleep_ticker.tick() self.poll(timeout * 1000) while self.sleep_ticker.elapsed(False) <", "label": 1}, {"snippet_id": 57806, "code": ".target_field: sortkey} while 1: sub_cases=update_targets[offset:offset +step_length] case_pks=[case.pk for case in sub_cases] if len(case_pks)==0: break queryset_filter(plan=plan, case__in=case_pks).update(**data", "label": 0}, {"snippet_id": 30842, "code": ": raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output", "label": 0}, {"snippet_id": 33562, "code": " missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join", "label": 0}, {"snippet_id": 24571, "code": "'sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure'", "label": 0}, {"snippet_id": 18088, "code": "=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY", "label": 1}, {"snippet_id": 22646, "code": " useradd(self, username, expiration=None): \"\"\"Create user account using tmsh Our policy is to create two accounts when booting a BIG-IP instance. The first account is the one that the user specified when", "label": 1}, {"snippet_id": 2879, "code": ": self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self", "label": 0}, {"snippet_id": 83778, "code": " outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing job %d\" ", "label": 0}, {"snippet_id": 49566, "code": "(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall,", "label": 0}, {"snippet_id": 66710, "code": " print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help", "label": 0}, {"snippet_id": 14394, "code": "._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self", "label": 0}, {"snippet_id": 37257, "code": " self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item", "label": 0}, {"snippet_id": 40425, "code": " ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format", "label": 0}, {"snippet_id": 78509, "code": ": continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in forum %s:%s', lt, user, forum) else: self.log.debug('Found no new targets in forum %s:%s'", "label": 1}, {"snippet_id": 64917, "code": "\"\" Shine `start' command classes. The start command aims to start Lustre filesystem servers or just some of the filesystem targets on local or remote servers. It is available for any filesystems previously", "label": 0}, {"snippet_id": 63580, "code": " job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client", "label": 0}, {"snippet_id": 35391, "code": " wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values))", "label": 0}, {"snippet_id": 23777, "code": " if ret: raise OSUtilError(\"Failed to get processor cores.\") try: return int(output) except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self", "label": 0}, {"snippet_id": 25449, "code": "=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\"", "label": 0}, {"snippet_id": 82671, "code": "\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds", "label": 0}, {"snippet_id": 26257, "code": ", None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status", "label": 0}, {"snippet_id": 2721, "code": " remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self", "label": 0}, {"snippet_id": 84463, "code": ".remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if", "label": 0}, {"snippet_id": 51884, "code": ") pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i", "label": 0}, {"snippet_id": 37733, "code": " name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self", "label": 0}, {"snippet_id": 47966, "code": "=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in", "label": 0}, {"snippet_id": 14807, "code": " expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']", "label": 0}, {"snippet_id": 82375, "code": ": \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates", "label": 0}, {"snippet_id": 78626, "code": " import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec': 'executer', 'dbexport': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self", "label": 0}, {"snippet_id": 56715, "code": " HTTP GET request, containing the primary key and the type of object to be selected :type request: HttpRequest \"\"\" for obj in['plan', 'case', 'run']: if request.GET.get(obj): self.object=obj self.object_pk", "label": 0}, {"snippet_id": 8487, "code": " @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) ", "label": 1}, {"snippet_id": 30192, "code": ", name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self", "label": 0}, {"snippet_id": 4393, "code": " list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int", "label": 0}, {"snippet_id": 37949, "code": ", lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match", "label": 0}, {"snippet_id": 61915, "code": " Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions ---------", "label": 0}, {"snippet_id": 72324, "code": ".debug('(%s) networks.remote: overriding reply() of IRC object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc", "label": 1}, {"snippet_id": 94074, "code": " and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None", "label": 0}, {"snippet_id": 60075, "code": ")) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities", "label": 0}, {"snippet_id": 34196, "code": " def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return", "label": 0}, {"snippet_id": 45186, "code": " def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None", "label": 0}, {"snippet_id": 8731, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: ", "label": 0}, {"snippet_id": 50165, "code": "._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir", "label": 0}, {"snippet_id": 12406, "code": "\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8 issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}),", "label": 0}, {"snippet_id": 74661, "code": " alt_number_str=runtime_config.vcf_to_zarr[\"alt_number\"] if str(alt_number_str).lower()==\"auto\": self.alt_number=None elif isint(alt_number_str): self.alt_number=int(alt_number_str) else: raise TypeError(\"Invalid", "label": 0}, {"snippet_id": 61437, "code": " if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError('State vector must be of length", "label": 0}, {"snippet_id": 64452, "code": ", opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments", "label": 0}, {"snippet_id": 45088, "code": " decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources", "label": 0}, {"snippet_id": 74926, "code": " self.benchmark_data_input=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"] if \"benchmark_aggregations\" in", "label": 0}, {"snippet_id": 56707, "code": "\"\"\" def __init__(self, request): \"\"\" :param request: An HTTP GET request, containing the primary key and the type of object to be selected :type request: HttpRequest \"\"\" for obj in['plan', 'case', 'run", "label": 0}, {"snippet_id": 3428, "code": "(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self", "label": 0}, {"snippet_id": 2745, "code": ".session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host", "label": 0}, {"snippet_id": 8586, "code": " line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os", "label": 1}, {"snippet_id": 44109, "code": ")) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets", "label": 0}, {"snippet_id": 85663, "code": "._zinc_factory._compiler_interface(self._products) @memoized_method def snapshot(self, scheduler): buildroot=get_buildroot() return scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs( tuple( fast_relpath", "label": 0}, {"snippet_id": 62542, "code": " \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits", "label": 0}, {"snippet_id": 42850, "code": " output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if", "label": 0}, {"snippet_id": 48523, "code": "\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards", "label": 0}, {"snippet_id": 22397, "code": "=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise", "label": 0}, {"snippet_id": 91397, "code": ", action=ResolveRequirements).install('pyprep') task(name='sources', action=GatherSources).install('pyprep') task(name='py', action=PythonRun).install('run') task(name='pytest-prep', action=PytestPrep)", "label": 0}, {"snippet_id": 84754, "code": " __future__ import absolute_import, division, print_function, unicode_literals from collections import namedtuple from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend", "label": 0}, {"snippet_id": 70369, "code": "]: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh", "label": 0}, {"snippet_id": 53506, "code": " input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item,", "label": 0}, {"snippet_id": 51296, "code": "\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value", "label": 0}, {"snippet_id": 66735, "code": ".print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration", "label": 1}, {"snippet_id": 28415, "code": "'Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type", "label": 0}, {"snippet_id": 71669, "code": " ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import *", "label": 0}, {"snippet_id": 7777, "code": "\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes)", "label": 0}, {"snippet_id": 84987, "code": "-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default='2.12', choices=['2.10', '2.11', '2.12', 'custom'],", "label": 0}, {"snippet_id": 60490, "code": ", Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CoherentState': Coherent, 'DisplacedSqueezed': DisplacedSqueezed", "label": 0}, {"snippet_id": 16291, "code": ".GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush", "label": 1}, {"snippet_id": 43995, "code": ", printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes", "label": 0}, {"snippet_id": 81387, "code": "[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for", "label": 0}, {"snippet_id": 43959, "code": " dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False", "label": 0}, {"snippet_id": 27852, "code": ">=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle", "label": 0}, {"snippet_id": 84467, "code": "._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"%s_files\"", "label": 0}, {"snippet_id": 59038, "code": ") expected_json=json.loads( serializers.serialize( 'json', EnvProperty.objects.all(), fields=('name', 'value'))) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), expected_json", "label": 0}, {"snippet_id": 51040, "code": "=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names", "label": 1}, {"snippet_id": 51932, "code": ", index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self", "label": 0}, {"snippet_id": 8325, "code": "'Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file", "label": 1}, {"snippet_id": 28497, "code": " entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self", "label": 0}, {"snippet_id": 45445, "code": "): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size", "label": 1}, {"snippet_id": 13745, "code": ".globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def", "label": 0}, {"snippet_id": 28060, "code": " self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle", "label": 1}, {"snippet_id": 17563, "code": "', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer", "label": 0}, {"snippet_id": 84952, "code": ", advanced=True, type=list, fingerprint=True, help='Use these scalac plugins.') register('--scalac-plugin-args', advanced=True, type=dict, default={}, fingerprint=True, help='Map from scalac plugin name", "label": 0}, {"snippet_id": 88249, "code": ".common.collections import OrderedSet from pants.base.build_environment import get_buildroot, get_scm from pants.base.worker_pool import SubprocPool from pants.base.workunit import WorkUnit, WorkUnitLabel", "label": 0}, {"snippet_id": 35850, "code": ". Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError", "label": 0}, {"snippet_id": 76909, "code": "=='HTTPS': net.proxy_type=sup.proxytype.http elif proxytype=='SOCKS4': net.proxy_type=sup.proxytype.socks4 elif proxytype=='SOCKS5': net.proxy_type=sup.proxytype.socks5 else: raise TypeError('Invalid proxytype", "label": 1}, {"snippet_id": 40134, "code": " root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self)", "label": 0}, {"snippet_id": 22335, "code": " to wait that this is available before we go provisioning the system. I call this method at the first opportunity I have(during the DVD mounting call). This ensures that the rest of the provisioning does", "label": 0}, {"snippet_id": 10007, "code": " spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): ", "label": 0}, {"snippet_id": 91537, "code": " PythonTestsAdaptor from pants.engine.rules import UnionRule, optionable_rule, rule from pants.engine.selectors import Get from pants.rules.core.core_test_model import Status, TestResult, TestTarget from pants", "label": 0}, {"snippet_id": 93557, "code": " stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component", "label": 0}, {"snippet_id": 51454, "code": " be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\"", "label": 0}, {"snippet_id": 51937, "code": "=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]:", "label": 0}, {"snippet_id": 28236, "code": "'Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass", "label": 0}, {"snippet_id": 45942, "code": ", str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value", "label": 0}, {"snippet_id": 95222, "code": " determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP", "label": 0}, {"snippet_id": 53724, "code": ".dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput", "label": 0}, {"snippet_id": 17832, "code": " not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description': x.description } for x in rawsnips]", "label": 0}, {"snippet_id": 91541, "code": ", optionable_rule, rule from pants.engine.selectors import Get from pants.rules.core.core_test_model import Status, TestResult, TestTarget from pants.source.source_root import SourceRootConfig def parse_interpreter_constraints", "label": 0}, {"snippet_id": 11595, "code": " empty string\"\"\" if isinstance(value, list): return \",\".join([str(x) if(x is not None) else \"\" for x in value]) else: return str(value) class OutputWriter(object): def __init__(self, output_file): self", "label": 0}, {"snippet_id": 45436, "code": " specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK)", "label": 1}, {"snippet_id": 14751, "code": " self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded", "label": 0}, {"snippet_id": 12676, "code": ".environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/{}/issues/{}/comments\" query=query.format(data[\"repository\"], str(data[\"pr_number\"])", "label": 0}, {"snippet_id": 43976, "code": " keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph", "label": 0}, {"snippet_id": 26215, "code": "'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None", "label": 0}, {"snippet_id": 8471, "code": " the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return", "label": 1}, {"snippet_id": 24526, "code": ".get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1)", "label": 0}, {"snippet_id": 53783, "code": ".set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params", "label": 0}, {"snippet_id": 54282, "code": " bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"", "label": 0}, {"snippet_id": 78170, "code": " wzworkers import WorkerInterrupt from wipeskel import WipeSkel, WipeState, cstate from beon import exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, ", "label": 0}, {"snippet_id": 94145, "code": "): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new", "label": 0}, {"snippet_id": 92290, "code": "'], stdout=output).wait() output.seek(0) self.assertEqual('BORK\\n', output.read()) with temporary_file(binary_mode=False) as new_output: subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\"", "label": 0}, {"snippet_id": 37067, "code": "._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd", "label": 0}, {"snippet_id": 31140, "code": " f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in", "label": 0}, {"snippet_id": 84254, "code": ", False)) or False def __build_metadata_configuration(self, client, job_wrapper, remote_metadata, remote_job_config): metadata_kwds={} if remote_metadata: remote_system_properties=remote_job_config.get", "label": 0}, {"snippet_id": 70335, "code": ".verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel", "label": 0}, {"snippet_id": 41191, "code": " except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist", "label": 0}, {"snippet_id": 93104, "code": " test_exception_logging(self): fake_logger=mock.Mock() with self.assertRaises(AssertionError): with exception_logging(fake_logger, 'error!'): assert True is False fake_logger.exception.assert_called_once_with('error", "label": 0}, {"snippet_id": 33273, "code": "=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse", "label": 0}, {"snippet_id": 71969, "code": ": pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error", "label": 1}, {"snippet_id": 29372, "code": " open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile", "label": 1}, {"snippet_id": 53233, "code": ".shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other", "label": 0}, {"snippet_id": 90261, "code": "=os.environ.get(home_env_var) return self.Location.from_home(home) if home else None jdk_home=env_home('JDK_HOME') if jdk_home: yield jdk_home java_home=env_home('JAVA_HOME') if java_home: yield java_home", "label": 0}, {"snippet_id": 47179, "code": " wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self", "label": 0}, {"snippet_id": 16636, "code": "._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface", "label": 0}, {"snippet_id": 57077, "code": " 'ok'})) @require_POST def update(request): \"\"\" Generic approach to update a model,\\n based on contenttype. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type\") vtype", "label": 0}, {"snippet_id": 30962, "code": " output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return", "label": 0}, {"snippet_id": 74552, "code": "\"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[", "label": 0}, {"snippet_id": 81974, "code": " Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify", "label": 0}, {"snippet_id": 16174, "code": " import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync", "label": 0}, {"snippet_id": 46950, "code": ".input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule", "label": 0}, {"snippet_id": 12992, "code": "\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data", "label": 0}, {"snippet_id": 91766, "code": " requirements_pex_response.output_directory_digest, ] merged_input_files=yield Get( Digest, DirectoriesToMerge, DirectoriesToMerge(directories=tuple(all_input_digests)), ) request=ExecuteProcessRequest( argv=(python_binary", "label": 0}, {"snippet_id": 6441, "code": " taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags", "label": 0}, {"snippet_id": 52313, "code": ".resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in", "label": 0}, {"snippet_id": 68566, "code": "\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout", "label": 0}, {"snippet_id": 39192, "code": "())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info", "label": 0}, {"snippet_id": 72268, "code": ".users[source].account def _remote_reply(placeholder_self, text, **kwargs): \"\"\" reply() rerouter for the 'remote' command. \"\"\" assert irc.name !=placeholder_self.name, \\ \"Refusing to route reply back to the", "label": 0}, {"snippet_id": 39540, "code": ".set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo", "label": 0}, {"snippet_id": 36775, "code": " Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived", "label": 0}, {"snippet_id": 34368, "code": ".norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring", "label": 0}, {"snippet_id": 77158, "code": " self.pr_sock.bind(self.pr_sa) def init_pr_back_sock(self): self.log.info( 'Initializing interprocess backward socket %s', self.pr_ba) self.pr_back_sock=self.p.ctx.socket(zmq.ROUTER) self.pr_back_sock.bind", "label": 0}, {"snippet_id": 82276, "code": " form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName", "label": 0}, {"snippet_id": 28307, "code": ".extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather", "label": 0}, {"snippet_id": 4211, "code": "=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms", "label": 0}, {"snippet_id": 40194, "code": ".touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file", "label": 0}, {"snippet_id": 11594, "code": " produce an empty string\"\"\" if isinstance(value, list): return \",\".join([str(x) if(x is not None) else \"\" for x in value]) else: return str(value) class OutputWriter(object): def __init__(self, output_file", "label": 0}, {"snippet_id": 72765, "code": "\" Main module for the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server", "label": 0}, {"snippet_id": 83722, "code": "=run_results.get('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR", "label": 0}, {"snippet_id": 73221, "code": " directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir", "label": 0}, {"snippet_id": 73887, "code": " Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation of VCF to Zarr conversion module configuration. \"\"\" enabled=False", "label": 0}, {"snippet_id": 9665, "code": ", info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete", "label": 0}, {"snippet_id": 27639, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500:", "label": 0}, {"snippet_id": 45600, "code": " snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing", "label": 0}, {"snippet_id": 65255, "code": " result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler", "label": 0}, {"snippet_id": 44876, "code": "[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources", "label": 0}, {"snippet_id": 34577, "code": " or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex", "label": 0}, {"snippet_id": 29155, "code": " rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__", "label": 0}, {"snippet_id": 57820, "code": "(plan=plan, case__in=case_pks).update(**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list('pk', flat=True) if not reviewers: err_msg", "label": 0}, {"snippet_id": 80395, "code": " disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume", "label": 0}, {"snippet_id": 79312, "code": "\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor: \t\t\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom", "label": 0}, {"snippet_id": 58640, "code": " username=self.tester.username, password='password') remove_perm_from_user(self.tester, self.permission) post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active", "label": 0}, {"snippet_id": 22823, "code": " the length of the salt value used to do it. \"\"\" cmd=\"/usr/bin/tmsh modify auth user{0} password '{1}'\".format(username, password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if", "label": 0}, {"snippet_id": 31817, "code": " contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self", "label": 0}, {"snippet_id": 88181, "code": "(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile): \"\"\"Compile Scala and Java code to classfiles using Zinc.\"\"\" @classmethod def product_types(cls)", "label": 0}, {"snippet_id": 15622, "code": " def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self", "label": 0}, {"snippet_id": 43648, "code": ".io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow:", "label": 1}, {"snippet_id": 25530, "code": " _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state", "label": 0}, {"snippet_id": 61008, "code": " __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P", "label": 0}, {"snippet_id": 84312, "code": " default_config_file=os.path.join(remote_galaxy_home, 'universe_wsgi.ini') metadata_kwds['config_file']=remote_system_properties.get('galaxy_config_file', default_config_file) metadata_kwds['dataset_files_path", "label": 0}, {"snippet_id": 17509, "code": "'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self):", "label": 0}, {"snippet_id": 45331, "code": "\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product", "label": 0}, {"snippet_id": 62331, "code": ". \"\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive.", "label": 0}, {"snippet_id": 28982, "code": ": if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self", "label": 0}, {"snippet_id": 43699, "code": "=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self", "label": 0}, {"snippet_id": 63410, "code": " prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error", "label": 0}, {"snippet_id": 67806, "code": " eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support", "label": 0}, {"snippet_id": 11778, "code": "=\"https://api.github.com/user/following/{}\" url=url.format(user) r=requests.put(url, headers=headers, auth=auth) def update_dict(base, head): \"\"\" Recursively merge or update dict-like objects. >>> update", "label": 0}, {"snippet_id": 93675, "code": "(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp[", "label": 0}, {"snippet_id": 217, "code": ", currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn", "label": 0}, {"snippet_id": 19686, "code": " '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None) clienthost=ns.pop('host', None) if serverhost: args.address=Address", "label": 0}, {"snippet_id": 83528, "code": "=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception", "label": 1}, {"snippet_id": 15697, "code": "(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format(", "label": 0}, {"snippet_id": 92488, "code": ".assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual", "label": 0}, {"snippet_id": 73836, "code": "\"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in", "label": 0}, {"snippet_id": 35401, "code": "*{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to", "label": 0}, {"snippet_id": 33481, "code": ": subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 65240, "code": " RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 0}, {"snippet_id": 24092, "code": "(cmd_search_storvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*(//'| sed -e 's/).*//'\".format(output) err, output=shellutil.run_get_output", "label": 0}, {"snippet_id": 63227, "code": "=job_wrapper.extra_filenames, dependencies_description=dependencies_description, env=client.env, rewrite_paths=rewrite_paths, arbitrary_files=unstructured_path_rewrites, ) job_id=lwr_submit_job(client,", "label": 0}, {"snippet_id": 15928, "code": " BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout)", "label": 0}, {"snippet_id": 85348, "code": ".jvm.targets.scala_jar_dependency import ScalaJarDependency from pants.backend.jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants", "label": 0}, {"snippet_id": 38459, "code": "(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"", "label": 0}, {"snippet_id": 11756, "code": "\"\"\"Follow the user of the service\"\"\" headers={ \"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"], \"Content-Length\": \"0\", } auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https:/", "label": 0}, {"snippet_id": 64250, "code": "] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path() new_version_path=self.path_mapper", "label": 0}, {"snippet_id": 17903, "code": " PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout", "label": 0}, {"snippet_id": 92219, "code": " zipfile from builtins import next, object, range, str from contextlib import contextmanager import mock from future.utils import PY3 from pants.util.contextutil import(InvalidZipPath, Timer, environment_as,", "label": 0}, {"snippet_id": 93893, "code": "(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out==':", "label": 0}, {"snippet_id": 2900, "code": " self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component(node.component) if(state", "label": 0}, {"snippet_id": 38111, "code": " class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self,", "label": 0}, {"snippet_id": 55557, "code": "=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror", "label": 0}, {"snippet_id": 55045, "code": " try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions", "label": 0}, {"snippet_id": 5969, "code": " bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\")", "label": 1}, {"snippet_id": 39213, "code": " and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and", "label": 0}, {"snippet_id": 75105, "code": " seqnum, status, data): if status==wzrpc.status.success: self.p.log.debug('Keepalive was successfull') elif status==wzrpc.status.e_req_denied: self.p.log.warn('Keepalive status{0}, reauthentificating and", "label": 0}, {"snippet_id": 68365, "code": " in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline", "label": 0}, {"snippet_id": 68527, "code": " c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs", "label": 0}, {"snippet_id": 37707, "code": " isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems", "label": 0}, {"snippet_id": 80111, "code": ".add_argument_group('Manual Form Detection arguments') manualFormArgs.add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when", "label": 0}, {"snippet_id": 32055, "code": " may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow", "label": 0}, {"snippet_id": 9832, "code": " keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords ", "label": 0}, {"snippet_id": 83069, "code": " ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none", "label": 0}, {"snippet_id": 34462, "code": "): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if", "label": 0}, {"snippet_id": 2061, "code": "=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action==", "label": 0}, {"snippet_id": 45267, "code": " self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths):", "label": 0}, {"snippet_id": 492, "code": " output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output", "label": 0}, {"snippet_id": 85710, "code": "/java_home/', get_buildroot(): '/dev/null/remapped_by_pants/buildroot/', self._zinc_factory.get_options().pants_workdir: '/dev/null/remapped_by_pants/workdir/', } return( '-rebase-map', ','.join('{}:{}'", "label": 0}, {"snippet_id": 85937, "code": ".Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): \"\"\"Compile Java code using Javac.\"\"\" _name='java", "label": 0}, {"snippet_id": 33978, "code": "(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update", "label": 0}, {"snippet_id": 80042, "code": "\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser.add_argument(\"-T\",\"--threads\",metavar=\"Threads\",nargs=1,dest=\"nbThreads", "label": 0}, {"snippet_id": 69911, "code": " CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()", "label": 0}, {"snippet_id": 47439, "code": ".workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self", "label": 0}, {"snippet_id": 91005, "code": "(human_readable_os_aliases)) register('--minimum-version', advanced=True, help='Minimum version of the JVM pants will use') register('--maximum-version', advanced=True, help='Maximum version of the JVM", "label": 0}, {"snippet_id": 94972, "code": ", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation", "label": 0}, {"snippet_id": 81493, "code": " \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures", "label": 0}, {"snippet_id": 45478, "code": " WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self", "label": 1}, {"snippet_id": 74365, "code": "', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark", "label": 0}, {"snippet_id": 93151, "code": " import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import", "label": 0}, {"snippet_id": 45301, "code": " in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via", "label": 0}, {"snippet_id": 23302, "code": " net route \" \"{0}/{1} gw{2}\").format(net, mask, gateway) return shellutil.run(cmd, chk_err=False) def device_for_ide_port(self, port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in", "label": 0}, {"snippet_id": 23365, "code": " import DefaultOSUtil from azurelinuxagent.common.future import ustr class FreeBSDOSUtil(DefaultOSUtil): def __init__(self): super(FreeBSDOSUtil, self).__init__() self._scsi_disks_timeout_set=False def", "label": 0}, {"snippet_id": 26969, "code": "] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low", "label": 0}, {"snippet_id": 11023, "code": " response.headers[field] if field in response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime", "label": 1}, {"snippet_id": 43918, "code": ".has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources", "label": 0}, {"snippet_id": 68262, "code": "=RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], ", "label": 0}, {"snippet_id": 55140, "code": ".info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag", "label": 0}, {"snippet_id": 70100, "code": " handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %(node, \\", "label": 0}, {"snippet_id": 2911, "code": "(node.comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries ", "label": 0}, {"snippet_id": 81207, "code": "] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with:", "label": 0}, {"snippet_id": 29335, "code": "(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name", "label": 1}, {"snippet_id": 48123, "code": "._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files", "label": 0}, {"snippet_id": 9852, "code": " of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text", "label": 0}, {"snippet_id": 79635, "code": " templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on", "label": 0}, {"snippet_id": 93956, "code": " host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH", "label": 0}, {"snippet_id": 52301, "code": ".resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output", "label": 0}, {"snippet_id": 66613, "code": " from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(", "label": 1}, {"snippet_id": 7085, "code": " separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p=_sort_kw_matches", "label": 0}, {"snippet_id": 40922, "code": ", name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. ", "label": 0}, {"snippet_id": 12076, "code": ".environ[\"GITHUB_TOKEN\"]} diff_headers=headers.copy() diff_headers[\"Accept\"]=\"application/vnd.github.VERSION.diff\" auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository", "label": 0}, {"snippet_id": 49040, "code": ", print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from", "label": 1}, {"snippet_id": 2959, "code": " Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp", "label": 0}, {"snippet_id": 75735, "code": "(self.name, 'utf-8')) self.sig_sock=s s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) self.wz_sock=s self.wz=WZHandler() def term_handler(interface, method,", "label": 1}, {"snippet_id": 67984, "code": " GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass", "label": 0}, {"snippet_id": 41065, "code": ".items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j", "label": 0}, {"snippet_id": 535, "code": ":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if", "label": 0}, {"snippet_id": 58887, "code": ".tester, self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self.plan.pk", "label": 0}, {"snippet_id": 61884, "code": "..])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()\t A simple introspective simulator that only permits classical operations", "label": 0}, {"snippet_id": 81330, "code": " self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult", "label": 0}, {"snippet_id": 64259, "code": " version_path=self.local_path_config.version_path() new_version_path=self.path_mapper.remote_version_path_rewrite(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path", "label": 0}, {"snippet_id": 34811, "code": "=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self", "label": 1}, {"snippet_id": 60986, "code": "\"This module contains the device class and context manager\"\"\" import numpy as np from scipy.linalg import expm, eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable,", "label": 0}, {"snippet_id": 61058, "code": "]]) Y=np.array([[0, -1j],[1j, 0]]) Z=np.array([[1, 0],[0, -1]]) CNOT=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0]]) SWAP=np.array([[1, 0, 0, 0],[0, 0, 1, 0],[0, 1, 0, 0],[0, 0, 0, 1]])", "label": 0}, {"snippet_id": 66496, "code": "(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR", "label": 0}, {"snippet_id": 80268, "code": " if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s", "label": 0}, {"snippet_id": 86929, "code": ", type=bool, default=True, help='When set, zinc will use sub-target incremental compilation, which dramatically ' 'improves compile performance while changing large targets. When unset, ' 'changed targets", "label": 0}, {"snippet_id": 50577, "code": " ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return", "label": 0}, {"snippet_id": 9293, "code": ", only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output", "label": 0}, {"snippet_id": 4898, "code": " author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left", "label": 0}, {"snippet_id": 25619, "code": "._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self", "label": 0}, {"snippet_id": 54922, "code": " if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set", "label": 0}, {"snippet_id": 89461, "code": "/github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception): \"\"\"Indicates an invalid java distribution.\"\"\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path,", "label": 0}, {"snippet_id": 45468, "code": ".check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError", "label": 1}, {"snippet_id": 84157, "code": " return dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False)) return remote_metadata", "label": 0}, {"snippet_id": 81905, "code": ",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID", "label": 0}, {"snippet_id": 92855, "code": ") with self.assertRaisesRegexp(zipfile.BadZipfile, r'{}'.format(not_zip.name)): next(open_zip(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness to replace `sys.std*` with tempfiles", "label": 0}, {"snippet_id": 27137, "code": ".helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station", "label": 1}, {"snippet_id": 79683, "code": "(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted", "label": 0}, {"snippet_id": 58845, "code": "'app_form': 'testcases.CaseAutomatedForm'}) form=CaseAutomatedForm() self.assertHTMLEqual(str(response.content, encoding=settings.DEFAULT_CHARSET), form.as_p()) class TestUpdateCasePriority(BasePlanCase):", "label": 1}, {"snippet_id": 60466, "code": ", Ket, Squeezed, Thermal, Gaussian) from strawberryfields.ops import(GaussianTransform, Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate", "label": 0}, {"snippet_id": 34079, "code": ".\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if", "label": 0}, {"snippet_id": 82538, "code": "\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal", "label": 0}, {"snippet_id": 23591, "code": " get_first_if(self): return self._get_net_info()[:2] def route_add(self, net, mask, gateway): cmd='route add{0}{1}{2}'.format(net, gateway, mask) return shellutil.run(cmd, chk_err=False) def is_missing_default_route", "label": 0}, {"snippet_id": 34201, "code": " kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams):", "label": 0}, {"snippet_id": 4391, "code": ":param text_lines: list of strings(will be normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param", "label": 0}, {"snippet_id": 40370, "code": "'name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try", "label": 0}, {"snippet_id": 91161, "code": ".python.rules import inject_init, python_test_runner from pants.backend.python.targets.python_app import PythonApp from pants.backend.python.targets.python_binary import PythonBinary from pants.backend", "label": 0}, {"snippet_id": 20570, "code": " create_client(cls, addr=None, **kwargs): if addr is None: addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_client( addr, timeout=kwargs.get('timeout'), ) return cls(conn, owned=True, **kwargs", "label": 0}, {"snippet_id": 66770, "code": " Globals from Shine.Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command", "label": 0}, {"snippet_id": 85671, "code": ": buildroot=get_buildroot() return scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs( tuple( fast_relpath(a, buildroot) for a in(self.zinc, self.compiler_bridge, self.compiler_interface) ) ), buildroot", "label": 1}, {"snippet_id": 84571, "code": " import ConsoleTask from pants.util.contextutil import temporary_dir class CountLinesOfCode(ConsoleTask): \"\"\"Print counts of lines of code.\"\"\" @classmethod def subsystem_dependencies(cls): return super", "label": 0}, {"snippet_id": 73572, "code": ":{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format", "label": 0}, {"snippet_id": 24062, "code": ".run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible cmd_search_storvsc=\"camcontrol devlist -b | grep storvsc{0} | awk '{{print", "label": 0}, {"snippet_id": 38477, "code": " name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False", "label": 0}, {"snippet_id": 48299, "code": " self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError(", "label": 0}, {"snippet_id": 23682, "code": " get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device() retcode=shellutil", "label": 0}, {"snippet_id": 41387, "code": ".utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def", "label": 0}, {"snippet_id": 80226, "code": "] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() ", "label": 0}, {"snippet_id": 43351, "code": " or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True", "label": 0}, {"snippet_id": 40767, "code": "(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(", "label": 0}, {"snippet_id": 49492, "code": "(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is", "label": 0}, {"snippet_id": 31595, "code": ".workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies", "label": 0}, {"snippet_id": 94649, "code": ": if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger", "label": 0}, {"snippet_id": 76135, "code": " self.log.debug('Succesfully set route type for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status", "label": 0}, {"snippet_id": 81703, "code": ".detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\"", "label": 0}, {"snippet_id": 91709, "code": ", requirements_pex_request) source_roots=source_root_config.get_source_roots() sources_snapshots_and_source_roots=[] for maybe_source_target in all_targets: if hasattr(maybe_source_target, 'sources'): tgt_snapshot", "label": 0}, {"snippet_id": 49555, "code": " if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag", "label": 0}, {"snippet_id": 16842, "code": " from retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json", "label": 0}, {"snippet_id": 82839, "code": " valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont", "label": 0}, {"snippet_id": 87469, "code": "'-compiler-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala-path', ':'.join(scala_path)]) zinc_args.extend(self._javac_plugin_args(javac_plugin_map", "label": 1}, {"snippet_id": 22591, "code": " proper value should have been bigip.xxx.yyy WAAgent will not fail if this command fails, but the hostname will not be what the user set either. Currently we do not set the hostname when WAAgent starts", "label": 0}, {"snippet_id": 37345, "code": " self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names(", "label": 0}, {"snippet_id": 88210, "code": " if not isinstance(target, JvmTarget): return False return target.has_sources('.java') or target.has_sources('.scala') def select_source(self, source_file_path): return source_file_path.endswith('.java'", "label": 0}, {"snippet_id": 79404, "code": " detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r", "label": 0}, {"snippet_id": 94495, "code": " returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name", "label": 0}, {"snippet_id": 50754, "code": "\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError", "label": 1}, {"snippet_id": 79373, "code": "._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t\t\t\tself.logger.debug(\"Requesting %s...\",url) \t\t \t\tr=self.session.get(url) \t\tif", "label": 0}, {"snippet_id": 4490, "code": "=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None", "label": 0}, {"snippet_id": 75284, "code": " handler=self.req_handlers[(interface, None)] except KeyError: raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value(tuple(iden), reqid", "label": 0}, {"snippet_id": 75484, "code": "(interface, method, reqid, key)] return(b'Router', b'auth-request', args, reqid) def make_auth_bind_route_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface", "label": 0}, {"snippet_id": 33010, "code": "._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name", "label": 0}, {"snippet_id": 71698, "code": ".Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle>\" % m.group", "label": 1}, {"snippet_id": 35647, "code": " for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names", "label": 0}, {"snippet_id": 12926, "code": "[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON[\"public\"]", "label": 0}, {"snippet_id": 64360, "code": " parameter_value] if parameter_value in unstructured_path_rewrites.itervalues(): return parameter_value rewrite, new_unstructured_path_rewrites=self.path_mapper.check_for_arbitrary_rewrite( parameter_value) if", "label": 0}, {"snippet_id": 11021, "code": "): return response.headers[field] if field in response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified", "label": 1}, {"snippet_id": 66156, "code": ") elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled", "label": 0}, {"snippet_id": 56336, "code": "(request=request, product_id=request.GET.get('product_id')) info_type=getattr(objects, request.GET.get('info_type')) if not info_type: return HttpResponse('Unrecognizable info-type') if request.GET.get", "label": 0}, {"snippet_id": 42450, "code": "=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input", "label": 0}, {"snippet_id": 54965, "code": "=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error", "label": 0}, {"snippet_id": 25740, "code": "'battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp", "label": 0}, {"snippet_id": 93580, "code": ".stop_remote_component(comp['name'], comp['host']) else: window=find_window(self.session, comp['name']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting down window..", "label": 0}, {"snippet_id": 11929, "code": "\", \"footer\": \"\" } }, \"scanner\":{\"diff_only\": False}, \"pycodestyle\":{ \"ignore\":[], \"max-line-length\": 79, \"count\": False, \"first\": False, \"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show", "label": 0}, {"snippet_id": 54770, "code": ".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets", "label": 0}, {"snippet_id": 59670, "code": ",[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice", "label": 0}, {"snippet_id": 53722, "code": "(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[", "label": 0}, {"snippet_id": 50330, "code": " values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(", "label": 0}, {"snippet_id": 83401, "code": " submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job", "label": 0}, {"snippet_id": 3357, "code": " and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server", "label": 0}, {"snippet_id": 76509, "code": ".set() self.unbind_methods() self.running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx", "label": 0}, {"snippet_id": 70849, "code": ") layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3", "label": 0}, {"snippet_id": 7173, "code": " acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons ", "label": 0}, {"snippet_id": 43950, "code": ", rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None", "label": 0}, {"snippet_id": 33272, "code": ": forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets", "label": 0}, {"snippet_id": 75404, "code": " msg.extend(self.make_req_msg(interface, method, args, fun, reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer): iden=self.iden_reqid_map.get_key(reqid) if seqnum==0: self.iden_reqid_map", "label": 0}, {"snippet_id": 23980, "code": "-86cb-44a2-9b5c-50d1417354f5 deviceid=00000000-0001-8899-0000-000000000000' \"\"\" cmd_search_ide=\"sysctl dev.storvsc | grep pnpinfo | grep deviceid={0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide", "label": 0}, {"snippet_id": 85513, "code": "=zinc_rev), ], main='no.such.main.Main', custom_rules=shader_rules) cls.register_jvm_tool(register, Zinc.ZINC_EXTRACTOR_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-extractor_2.11', '0.0", "label": 1}, {"snippet_id": 28128, "code": ", DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger", "label": 1}, {"snippet_id": 11327, "code": " class MonitoringConfigGenerator(object): def __init__(self, url, debug_enabled=False, target_dir=None, skip_checks=False): self.skip_checks=skip_checks self.target_dir=target_dir if target_dir else CONFIG", "label": 0}, {"snippet_id": 7555, "code": " :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean", "label": 0}, {"snippet_id": 73578, "code": ".vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)) if conversion_config.compressor=", "label": 0}, {"snippet_id": 20185, "code": " already running') assert self._session is None addr=('localhost', self._addr.port) self._run_server_ex=None def run(): try: self._session=self.SESSION.create_server(addr, **kwargs) except Exception as", "label": 0}, {"snippet_id": 78748, "code": ".debug('Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e))", "label": 0}, {"snippet_id": 75572, "code": "', b'auth-set-route-type', args, reqid) def make_auth_clear_data(self, reqid=None): if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return", "label": 0}, {"snippet_id": 17536, "code": ") and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self", "label": 0}, {"snippet_id": 46949, "code": " for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash", "label": 0}, {"snippet_id": 70314, "code": ", OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute", "label": 0}, {"snippet_id": 89093, "code": ", root_targets, **kwargs): return Target.closure_for_targets( target_roots=root_targets, **kwargs ) def dependents(self, on_predicate=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy", "label": 0}, {"snippet_id": 10073, "code": " fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()", "label": 0}, {"snippet_id": 58870, "code": ", cls).setUpTestData() cls.permission='testcases.change_testcase' cls.case_update_url=reverse('ajax-update_cases_default_tester') def setUp(self): user_should_have_perm(self.tester, self.permission) def", "label": 0}, {"snippet_id": 39624, "code": " def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo", "label": 0}, {"snippet_id": 61139, "code": " def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm(-1j * theta/2 * Z", "label": 0}, {"snippet_id": 66544, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of", "label": 0}, {"snippet_id": 32841, "code": " update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None", "label": 0}, {"snippet_id": 70544, "code": "(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client)", "label": 0}, {"snippet_id": 56154, "code": "\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]), path", "label": 0}, {"snippet_id": 92075, "code": ": return False platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys()) if not platform_names or platform_names==['current", "label": 0}, {"snippet_id": 29056, "code": "\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 82461, "code": "-l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error", "label": 0}, {"snippet_id": 46256, "code": " Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if", "label": 0}, {"snippet_id": 28837, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self", "label": 0}, {"snippet_id": 57584, "code": " mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context) except Exception: pass def _update_priority(self): exists=Priority", "label": 0}, {"snippet_id": 49641, "code": " return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error:", "label": 0}, {"snippet_id": 74241, "code": ".benchmark_allele_count=config_str_to_bool(runtime_config.benchmark[\"benchmark_allele_count\"]) if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark", "label": 1}, {"snippet_id": 5649, "code": ".getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches", "label": 0}, {"snippet_id": 79879, "code": ",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=", "label": 0}, {"snippet_id": 14164, "code": ".completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import", "label": 0}, {"snippet_id": 84227, "code": " the remote datatype config -but there is no guarentee that it will contain all the datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( ", "label": 0}, {"snippet_id": 77536, "code": "(f.read()) try: for domain in users.keys(): uq=Queue() for ud in users[domain]: self.log.debug('Loaded user %s:%s', domain, ud['login']) uq.put(ud) self.userqueues[domain]=uq except Exception as e: self", "label": 0}, {"snippet_id": 9412, "code": " > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords, _kw(_sort_kw_matches(acronyms, output_limit))) else", "label": 0}, {"snippet_id": 63348, "code": ".__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory", "label": 0}, {"snippet_id": 30394, "code": ": pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\"", "label": 0}, {"snippet_id": 15831, "code": " dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ ", "label": 0}, {"snippet_id": 13236, "code": "].split(\"/\")[-1]==data[\"target_repo_branch\"]: sha=ref[\"object\"][\"sha\"] url=\"https://api.github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data", "label": 0}, {"snippet_id": 26383, "code": "): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return", "label": 0}, {"snippet_id": 93723, "code": "=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug", "label": 0}, {"snippet_id": 80838, "code": ".submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads:", "label": 1}, {"snippet_id": 53570, "code": "._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output", "label": 0}, {"snippet_id": 89365, "code": " normalize_os_name from pants.util.process_handler import subprocess logger=logging.getLogger(__name__) def _parse_java_version(name, version): if isinstance(version, string_types): version=Revision.lenient", "label": 0}, {"snippet_id": 87178, "code": " None: for compile_context in compile_contexts: with open(compile_context.zinc_args_file, 'r') as fp: args=fp.read().split() zinc_args[compile_context.target]=args def create_empty_extra_products(self): if", "label": 0}, {"snippet_id": 27502, "code": "\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data", "label": 0}, {"snippet_id": 76094, "code": "=True else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m", "label": 0}, {"snippet_id": 71938, "code": ") if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try:", "label": 0}, {"snippet_id": 25846, "code": " data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength", "label": 0}, {"snippet_id": 56550, "code": " as form' %(q_app, q_form)) __import__('tcms.%s.forms' % q_app) q_app_module=sys.modules['tcms.%s.forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html", "label": 1}, {"snippet_id": 65815, "code": ") def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[", "label": 0}, {"snippet_id": 45746, "code": ") if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after", "label": 0}, {"snippet_id": 28286, "code": ":wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA", "label": 1}, {"snippet_id": 19538, "code": " break if arg=='--client': arg='--host' elif arg=='--file': if nextarg is None: pydevd.append(arg) continue if nextarg.endswith(':') and '--module' in pydevd: pydevd.remove('--module') arg='-m' argv[i ", "label": 0}, {"snippet_id": 85250, "code": "'scala-repl', self.version) def injectables(self, build_graph): if self.version=='custom': return specs_to_create=[ ('scalac', self._create_compiler_jardep), ('scala-library', self._create_runtime_jardep) ]", "label": 1}, {"snippet_id": 70298, "code": " __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE", "label": 0}, {"snippet_id": 72478, "code": "\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser", "label": 0}, {"snippet_id": 52715, "code": ".expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self)", "label": 0}, {"snippet_id": 82445, "code": "(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int", "label": 0}, {"snippet_id": 33107, "code": "( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule", "label": 0}, {"snippet_id": 64512, "code": "\n from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support", "label": 0}, {"snippet_id": 40680, "code": " for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand", "label": 0}, {"snippet_id": 49436, "code": ", wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None,", "label": 0}, {"snippet_id": 33322, "code": " is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles", "label": 0}, {"snippet_id": 4910, "code": " composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms", "label": 0}, {"snippet_id": 78463, "code": " targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map", "label": 0}, {"snippet_id": 26650, "code": "': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low", "label": 0}, {"snippet_id": 78225, "code": ") return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self): for t in self.targets: self.schedule(self.add_comment,(t, self.msgfun())) if len(self", "label": 0}, {"snippet_id": 23201, "code": " python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)) param=struct.pack('iL", "label": 0}, {"snippet_id": 90094, "code": ".home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{} executable,{} does not appear to be a' '", "label": 0}, {"snippet_id": 56914, "code": " counting for :type tag::class:`tcms.management.models.Tag` :return: the number of times a tag is assigned to object :rtype: int \"\"\" if self.counter['tag'] !=tag.pk: try: self.counter=self.test_tags.__next__", "label": 0}, {"snippet_id": 25635, "code": "'battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif", "label": 0}, {"snippet_id": 17653, "code": ".UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), ", "label": 0}, {"snippet_id": 9275, "code": " type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags", "label": 0}, {"snippet_id": 48048, "code": ") return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self", "label": 0}, {"snippet_id": 59365, "code": " \"\"\" name='ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend", "label": 0}, {"snippet_id": 1661, "code": "*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s", "label": 0}, {"snippet_id": 77592, "code": " f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues[domain] except KeyError: self.log.info('Created userqueue", "label": 0}, {"snippet_id": 73871, "code": "=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\", \"lz4hc\", \"zlib\", \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc", "label": 0}, {"snippet_id": 52270, "code": " is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict", "label": 0}, {"snippet_id": 57521, "code": " ' 'support from your organization.') else: if resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets(self): \"\"\"Get selected cases to update their properties", "label": 0}, {"snippet_id": 64681, "code": " import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print ", "label": 0}, {"snippet_id": 68991, "code": " client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ ", "label": 0}, {"snippet_id": 33827, "code": ": self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib", "label": 0}, {"snippet_id": 95347, "code": " ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive", "label": 0}, {"snippet_id": 87136, "code": " select_source(self, source_file_path): raise NotImplementedError() def register_extra_products_from_contexts(self, targets, compile_contexts): compile_contexts=[self.select_runtime_context(compile_contexts[t]) for", "label": 0}, {"snippet_id": 24908, "code": " >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 7835, "code": " fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict", "label": 0}, {"snippet_id": 22538, "code": " you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has", "label": 0}, {"snippet_id": 14238, "code": " SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options", "label": 0}, {"snippet_id": 73092, "code": "(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file", "label": 0}, {"snippet_id": 46198, "code": " filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the", "label": 0}, {"snippet_id": 50184, "code": "._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config", "label": 0}, {"snippet_id": 49581, "code": "=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete", "label": 0}, {"snippet_id": 73263, "code": "\") for path in pathlist_gz: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str", "label": 0}, {"snippet_id": 47618, "code": ".noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are", "label": 0}, {"snippet_id": 12645, "code": " old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body'].lower(): break elif 'quiet' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False return", "label": 0}, {"snippet_id": 85504, "code": " 'compiler-interface', classpath=[ JarDependency(org='org.scala-sbt', name='compiler-interface', rev=zinc_rev), ], main='no.such.main.Main', custom_rules=shader_rules) cls.register_jvm_tool(register, Zinc", "label": 0}, {"snippet_id": 66114, "code": " elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size", "label": 0}, {"snippet_id": 8169, "code": " marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace", "label": 0}, {"snippet_id": 87540, "code": ".fatal_warnings_enabled_args zinc_args.extend(enabled_args) for option_set, disabled_args in self.get_options().compiler_option_sets_disabled_args.items(): if option_set not in compiler_option_sets: if option_set=", "label": 0}, {"snippet_id": 84067, "code": " def shutdown( self): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client", "label": 0}, {"snippet_id": 67713, "code": " succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s):", "label": 0}, {"snippet_id": 86873, "code": " get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super(BaseZincCompile, cls).register_options(register) register('--whitelisted-args', advanced=True, type=dict, default={", "label": 0}, {"snippet_id": 7116, "code": " composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for", "label": 0}, {"snippet_id": 92404, "code": "('AAA', os.environ) def test_hermetic_environment_unicode(self): UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output=UNICODE_CHAR if PY3 else ENCODED_CHAR with environment_as(**dict", "label": 1}, {"snippet_id": 34519, "code": " import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake", "label": 1}, {"snippet_id": 16740, "code": " all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes", "label": 0}, {"snippet_id": 74544, "code": "\"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files", "label": 0}, {"snippet_id": 37158, "code": " input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old)", "label": 0}, {"snippet_id": 20529, "code": ")) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed write=send_as_write(self._sock) body=json.dumps(req) write_message", "label": 0}, {"snippet_id": 11848, "code": ") is not False: header_signature=request.headers.get('X-Hub-Signature') if header_signature is None: abort(403) sha_name, signature=header_signature.split('=') if sha_name !='sha1': abort(501) mac=hmac", "label": 0}, {"snippet_id": 66861, "code": ".targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read()", "label": 0}, {"snippet_id": 70801, "code": ": status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes", "label": 0}, {"snippet_id": 70970, "code": ") if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0:", "label": 0}, {"snippet_id": 72060, "code": ")).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return irc.reply(\"Done. If you want to reconnect this network, use the 'rehash' command.\") control.remove_network", "label": 0}, {"snippet_id": 91401, "code": "'pyprep') task(name='sources', action=GatherSources).install('pyprep') task(name='py', action=PythonRun).install('run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action", "label": 0}, {"snippet_id": 30128, "code": "\"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if", "label": 0}, {"snippet_id": 20918, "code": "._conn.close() except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still", "label": 0}, {"snippet_id": 70308, "code": "\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self", "label": 0}, {"snippet_id": 83298, "code": "=self.__find_watched_job( job_id) if not job_state: log.warn( \"Failed to find job corresponding to final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state", "label": 1}, {"snippet_id": 88386, "code": "._run_tracker.log(Report.WARN, *msg_elements) def error(self, *msg_elements): self._run_tracker.log(Report.ERROR, *msg_elements) def fatal(self, *msg_elements): self._run_tracker.log(Report.FATAL, *msg_elements", "label": 0}, {"snippet_id": 45763, "code": " raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer", "label": 0}, {"snippet_id": 67638, "code": " print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler", "label": 0}, {"snippet_id": 79984, "code": "-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose", "label": 0}, {"snippet_id": 7765, "code": "..]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes:", "label": 0}, {"snippet_id": 40351, "code": " files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard", "label": 0}, {"snippet_id": 61230, "code": " Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape[0] !=U.shape[1]: raise ValueError(\"Operator must be a square matrix.\") if not np.allclose(U @ U.conj().T, np.identity(U.shape[0])", "label": 0}, {"snippet_id": 46344, "code": " A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False", "label": 0}, {"snippet_id": 85611, "code": "=products @memoized_property def zinc(self): \"\"\"Return the Zinc wrapper compiler classpath. :rtype: list of str \"\"\" return self._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the", "label": 0}, {"snippet_id": 44458, "code": " if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes", "label": 0}, {"snippet_id": 31262, "code": " in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule", "label": 0}, {"snippet_id": 81660, "code": "\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace", "label": 0}, {"snippet_id": 58377, "code": "=HTTPStatus.OK) def test_when_logged_in_index_page_redirects_to_dashboard(self): self.client.login( username=self.tester.username, password='password') response=self.client.get(reverse('core-views-index'))", "label": 0}, {"snippet_id": 44687, "code": ", snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack", "label": 0}, {"snippet_id": 33049, "code": "\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self", "label": 0}, {"snippet_id": 5040, "code": " :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield", "label": 0}, {"snippet_id": 76301, "code": ", m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep(self, reqid, data): self.send_rep(reqid", "label": 0}, {"snippet_id": 43453, "code": " bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards", "label": 0}, {"snippet_id": 65087, "code": " target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): ", "label": 0}, {"snippet_id": 55668, "code": " rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1])", "label": 0}, {"snippet_id": 74877, "code": " __init__(self, runtime_config=None): \"\"\" Creates an object representation of the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from", "label": 0}, {"snippet_id": 10944, "code": "%s' % uri) def read_config_from_file(path): yaml_config=merge_yaml_files(path) etag=None mtime=os.path.getmtime(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url): try", "label": 0}, {"snippet_id": 60776, "code": " *args, **kwargs) return new_object class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an illegal operation in the quantum circuit. \"\"\" pass class Device(abc.ABC):", "label": 0}, {"snippet_id": 79298, "code": "\ttmpExtList.append((e,getMime(extensions,e))) \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self.threads)", "label": 0}, {"snippet_id": 45593, "code": ".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file,", "label": 0}, {"snippet_id": 4574, "code": ", position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound", "label": 0}, {"snippet_id": 53916, "code": " if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards", "label": 0}, {"snippet_id": 25785, "code": " data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self", "label": 0}, {"snippet_id": 43859, "code": "=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments", "label": 0}, {"snippet_id": 9058, "code": "={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if", "label": 0}, {"snippet_id": 30095, "code": "(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names.", "label": 0}, {"snippet_id": 37932, "code": " ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile)", "label": 0}, {"snippet_id": 28961, "code": "\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'", "label": 0}, {"snippet_id": 47316, "code": " protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag", "label": 0}, {"snippet_id": 9738, "code": "(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output,", "label": 0}, {"snippet_id": 20676, "code": " return{ 'type': 'request', 'seq': seq, 'command': command, 'arguments': args, } def send_request(self, command, **args): if self.closed: raise RuntimeError('session closed') wait=args.pop('wait', False", "label": 0}, {"snippet_id": 27076, "code": ".update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth", "label": 1}, {"snippet_id": 37737, "code": "(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item", "label": 0}, {"snippet_id": 66620, "code": " FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m", "label": 1}, {"snippet_id": 41761, "code": " name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f", "label": 0}, {"snippet_id": 45366, "code": " return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode", "label": 0}, {"snippet_id": 16602, "code": " OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync", "label": 0}, {"snippet_id": 72355, "code": "(%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname) remoteirc.reply=old_reply remoteirc.pseudoclient.account='' @utils.add_cmd def reloadproto(irc, source, args): \"\"\"<protocol", "label": 1}, {"snippet_id": 73780, "code": " __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config:", "label": 0}, {"snippet_id": 86877, "code": " return() @classmethod def register_options(cls, register): super(BaseZincCompile, cls).register_options(register) register('--whitelisted-args', advanced=True, type=dict, default={ '-S.*': False, '-C.", "label": 0}, {"snippet_id": 51435, "code": ") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged", "label": 0}, {"snippet_id": 82041, "code": ") requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\"", "label": 0}, {"snippet_id": 40679, "code": ")) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand", "label": 0}, {"snippet_id": 48647, "code": " wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, ", "label": 0}, {"snippet_id": 20755, "code": ": if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event handlername='event{!r}'.format(event) with self", "label": 0}, {"snippet_id": 34090, "code": " \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise", "label": 0}, {"snippet_id": 11835, "code": " return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get('X-Hub-Signature')", "label": 0}, {"snippet_id": 20779, "code": ", handlername, **kwargs): yield result def get_awaiter_for_event(self, event, condition=lambda msg: True, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg", "label": 0}, {"snippet_id": 5145, "code": "=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw", "label": 0}, {"snippet_id": 19621, "code": " gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ) parser.add_argument", "label": 0}, {"snippet_id": 70426, "code": " Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to enquire", "label": 0}, {"snippet_id": 89012, "code": " and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of the run. See Target.closure_for_targets for", "label": 0}, {"snippet_id": 52737, "code": " and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger", "label": 0}, {"snippet_id": 10547, "code": "\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False", "label": 1}, {"snippet_id": 38848, "code": " to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill", "label": 0}, {"snippet_id": 15312, "code": "(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'", "label": 0}, {"snippet_id": 5744, "code": ": component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison", "label": 0}, {"snippet_id": 87831, "code": " and \".\").{} is not.'.format(path)) def log_zinc_file(self, analysis_file): self.context.log.debug('Calling zinc on:{}({})' .format(analysis_file, hash_file(analysis_file).upper() if os.path.exists(analysis_file", "label": 0}, {"snippet_id": 88166, "code": " else: with open_zip(classpath_element, 'r') as jarfile: try: with closing(jarfile.open(_SCALAC_PLUGIN_INFO_FILE, 'r')) as plugin_info_file: return process_info_file(classpath_element, plugin_info_file", "label": 0}, {"snippet_id": 13514, "code": "=408 MOUTH_CLOSE=412 EYES_OPEN=410 EYES_CLOSE=414 \r io=GPIO() io.setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def updateMouth", "label": 0}, {"snippet_id": 43908, "code": "[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring)", "label": 0}, {"snippet_id": 35985, "code": ", ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job", "label": 0}, {"snippet_id": 2632, "code": ".comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res: if node is", "label": 0}, {"snippet_id": 37744, "code": " item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_,", "label": 0}, {"snippet_id": 91863, "code": " pants.backend.python.subsystems.python_setup import PythonSetup from pants.backend.python.targets.python_distribution import PythonDistribution from pants.base.exceptions import IncompatiblePlatformsError", "label": 0}, {"snippet_id": 28441, "code": "._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.", "label": 0}, {"snippet_id": 26655, "code": " self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000:", "label": 0}, {"snippet_id": 31875, "code": " name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self", "label": 0}, {"snippet_id": 29596, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append", "label": 0}, {"snippet_id": 83662, "code": " job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\"", "label": 0}, {"snippet_id": 36439, "code": " f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill", "label": 0}, {"snippet_id": 586, "code": " return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor", "label": 0}, {"snippet_id": 40476, "code": "(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value", "label": 0}, {"snippet_id": 32117, "code": "(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and", "label": 0}, {"snippet_id": 49770, "code": ") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if", "label": 0}, {"snippet_id": 5797, "code": " return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in", "label": 0}, {"snippet_id": 91260, "code": ".python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import PythonBinaryCreate from pants.backend.python.tasks.python_bundle import PythonBundle from pants.backend", "label": 0}, {"snippet_id": 95913, "code": " def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a Zarr format. Only converts a single VCF file. :param input_vcf_path: The input VCF file", "label": 1}, {"snippet_id": 51052, "code": ".dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None", "label": 1}, {"snippet_id": 69975, "code": " RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try:", "label": 0}, {"snippet_id": 58886, "code": "(self.tester, self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self.plan", "label": 0}, {"snippet_id": 47482, "code": " ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not", "label": 0}, {"snippet_id": 2398, "code": "/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging", "label": 0}, {"snippet_id": 92886, "code": ".uuid4()) def u(string): return '{} stdin_data=u('stdio') stdout_data=u('stdout') stderr_data=u('stderr') with temporary_file(binary_mode=False) as tmp_stdin,\\ temporary_file(binary_mode=False) as tmp_stdout", "label": 0}, {"snippet_id": 95526, "code": " file_list_total=len(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file)", "label": 0}, {"snippet_id": 12130, "code": " patchset in patch: file=patchset.target_file[1:] files[file]=[] for hunk in patchset: for line in hunk.target_lines(): if line.is_added: files[file].append(line.target_line_no) return files def get_python_files_involved_in_pr", "label": 0}, {"snippet_id": 28401, "code": " add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{", "label": 0}, {"snippet_id": 74607, "code": " chunk_length=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): \"\"\" Creates", "label": 0}, {"snippet_id": 42297, "code": "\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io", "label": 0}, {"snippet_id": 6754, "code": "=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines", "label": 0}, {"snippet_id": 36066, "code": "=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set", "label": 0}, {"snippet_id": 22792, "code": " accounts have the UID 0. So we can't rely on this value. :param username: The username whose password to change :param password: The unencrypted password to set for the user :param crypt_id: If encrypting", "label": 0}, {"snippet_id": 73266, "code": " path in pathlist_gz: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)) print(", "label": 0}, {"snippet_id": 796, "code": ",'1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse", "label": 0}, {"snippet_id": 25030, "code": "._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the", "label": 0}, {"snippet_id": 65198, "code": " start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv", "label": 0}, {"snippet_id": 65786, "code": " AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER)", "label": 0}, {"snippet_id": 65336, "code": " status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) if hasattr(eh, 'post'): eh.post(fs) return rc", "label": 1}, {"snippet_id": 48624, "code": " is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if", "label": 0}, {"snippet_id": 5911, "code": " field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error(\"Please use bibclassify_cli from now on.", "label": 0}, {"snippet_id": 39134, "code": "(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules", "label": 0}, {"snippet_id": 2506, "code": "\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config", "label": 0}, {"snippet_id": 29254, "code": ".\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len", "label": 0}, {"snippet_id": 49994, "code": " ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources:", "label": 0}, {"snippet_id": 67803, "code": " fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support", "label": 0}, {"snippet_id": 61596, "code": " wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem Returns: float", "label": 0}, {"snippet_id": 33252, "code": "): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list()", "label": 0}, {"snippet_id": 83414, "code": " model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState", "label": 0}, {"snippet_id": 40538, "code": "): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value", "label": 0}, {"snippet_id": 69699, "code": " print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f %s' to initialize the file system.\" % \\ fs_conf.get_fs_name()", "label": 0}, {"snippet_id": 17283, "code": " def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self", "label": 1}, {"snippet_id": 36981, "code": ".version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args", "label": 0}, {"snippet_id": 25444, "code": ".type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"", "label": 0}, {"snippet_id": 86070, "code": " javac_classpath(self): return Java.global_javac_classpath(self.context.products) def write_extra_resources(self, compile_context): \"\"\"Override write_extra_resources to produce plugin and annotation processor files", "label": 0}, {"snippet_id": 72504, "code": "='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path", "label": 0}, {"snippet_id": 70522, "code": " GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass", "label": 0}, {"snippet_id": 79859, "code": " detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group('Required named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\"", "label": 0}, {"snippet_id": 60542, "code": " initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields", "label": 0}, {"snippet_id": 29756, "code": " AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError(", "label": 1}, {"snippet_id": 37812, "code": " newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise", "label": 0}, {"snippet_id": 89438, "code": " exercise features only available in that version forward. :API: public TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https", "label": 0}, {"snippet_id": 20703, "code": "*args) if self.VERBOSE: msg=parse_message(req) print(' <-', msg) if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter", "label": 0}, {"snippet_id": 23554, "code": ":{1}\" \"\").format(username, output)) def del_root_password(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed to delete root password: Failed to update password database.", "label": 0}, {"snippet_id": 10169, "code": " info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else:", "label": 0}, {"snippet_id": 49936, "code": "=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness", "label": 0}, {"snippet_id": 82331, "code": ".parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: ", "label": 0}, {"snippet_id": 59684, "code": " in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args:", "label": 0}, {"snippet_id": 65753, "code": " target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 62432, "code": " for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): ", "label": 0}, {"snippet_id": 35176, "code": " \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag", "label": 0}, {"snippet_id": 56661, "code": " run_counter=_TagCounter('num_runs', test_run_tags) for tag in all_tags: tag.num_plans=plan_counter.calculate_tag_count(tag) tag.num_cases=case_counter.calculate_tag_count(tag) tag.num_runs=run_counter", "label": 0}, {"snippet_id": 40702, "code": " \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per", "label": 0}, {"snippet_id": 15010, "code": " DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None", "label": 0}, {"snippet_id": 77264, "code": ".get_userqueue): self.log.info('Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self,", "label": 0}, {"snippet_id": 72636, "code": " overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==\"setup\": print(\"[Setup] Setting up benchmark data.", "label": 0}, {"snippet_id": 26064, "code": " self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle", "label": 1}, {"snippet_id": 35679, "code": "=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if", "label": 0}, {"snippet_id": 2459, "code": "\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running", "label": 0}, {"snippet_id": 60687, "code": "': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self._observe.params) elif self._observe.name=='Displacement': ex=self", "label": 0}, {"snippet_id": 19548, "code": " continue if nextarg.endswith(':') and '--module' in pydevd: pydevd.remove('--module') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg", "label": 0}, {"snippet_id": 95837, "code": " configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data", "label": 0}, {"snippet_id": 35035, "code": " else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(", "label": 0}, {"snippet_id": 55967, "code": " *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate", "label": 0}, {"snippet_id": 15940, "code": "=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout)", "label": 1}, {"snippet_id": 3562, "code": "'cmd'][1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']", "label": 0}, {"snippet_id": 77602, "code": "('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues[domain] except KeyError: self.log.info('Created userqueue for %s', domain) uq=Queue() self.userqueues[domain]=uq return uq def load_targets", "label": 0}, {"snippet_id": 43412, "code": " requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output", "label": 0}, {"snippet_id": 649, "code": "\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name'", "label": 0}, {"snippet_id": 13953, "code": " method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri", "label": 1}, {"snippet_id": 55817, "code": ".globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo", "label": 0}, {"snippet_id": 51098, "code": "(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self", "label": 0}, {"snippet_id": 84956, "code": " fingerprint=True, help='Use these scalac plugins.') register('--scalac-plugin-args', advanced=True, type=dict, default={}, fingerprint=True, help='Map from scalac plugin name to list of arguments for that plugin", "label": 0}, {"snippet_id": 29634, "code": ") last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic", "label": 0}, {"snippet_id": 48915, "code": "(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self", "label": 0}, {"snippet_id": 6486, "code": " spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms ) if api", "label": 0}, {"snippet_id": 5687, "code": " structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info", "label": 0}, {"snippet_id": 76571, "code": " import random import zmq from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import UniWipe from wipeskel import * import wzrpc from beon import", "label": 0}, {"snippet_id": 59416, "code": "'num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg", "label": 0}, {"snippet_id": 27098, "code": " for the NetAtmo Weather Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import", "label": 1}, {"snippet_id": 43746, "code": ".overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config", "label": 0}, {"snippet_id": 48078, "code": " rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files", "label": 0}, {"snippet_id": 22660, "code": " when booting a BIG-IP instance. The first account is the one that the user specified when they did the instance creation. The second one is the admin account that is, or should be, built in to the system.", "label": 0}, {"snippet_id": 95353, "code": "() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=ftp_config", "label": 0}, {"snippet_id": 56417, "code": "', default='False')) except(ValueError, TypeError): is_active=False return Build.objects.filter(product_id=self.product_id, is_active=is_active) def categories(self): return Category.objects.filter(product__id", "label": 0}, {"snippet_id": 8845, "code": " text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires", "label": 0}, {"snippet_id": 16267, "code": "=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer", "label": 1}, {"snippet_id": 77769, "code": ".send_multipart(msg) if hasattr(self, 'pr_sock'): self.pr_sock.send_multipart(msg) def join_threads(self): for t in self.threads: t.join() def send_passthrough(self, interface, method, frames): msg=[frames[0]] msg", "label": 0}, {"snippet_id": 20652, "code": "='test.session', ) self._listenerthread.start() @property def is_client(self): return self._conn.is_client @property def received(self): return list(self._received) def _create_request(self, command, *", "label": 0}, {"snippet_id": 25493, "code": " of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the", "label": 0}, {"snippet_id": 54041, "code": "=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is", "label": 0}, {"snippet_id": 64431, "code": "[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len", "label": 0}, {"snippet_id": 38731, "code": ".name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self,", "label": 0}, {"snippet_id": 6697, "code": " match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract", "label": 0}, {"snippet_id": 82257, "code": ".add_argument_group('Manual Form Detection arguments') manualFormArgs.add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when", "label": 0}, {"snippet_id": 24495, "code": " of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the", "label": 0}, {"snippet_id": 16878, "code": " BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 39062, "code": "=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map", "label": 0}, {"snippet_id": 82525, "code": " |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without", "label": 0}, {"snippet_id": 61087, "code": " def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_x \\theta/2}` \"\"\" return expm(-1j * theta/2 * X", "label": 0}, {"snippet_id": 93624, "code": ", comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res", "label": 0}, {"snippet_id": 24484, "code": "\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return", "label": 0}, {"snippet_id": 21063, "code": " self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event() def handler(msg): if not match(msg): return msg, False event.set() return msg, True self", "label": 0}, {"snippet_id": 75386, "code": " reqid) self.set_response_handler(reqid, fun) return msg def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface", "label": 0}, {"snippet_id": 91897, "code": " from pants.util.objects import SubclassesOf logger=logging.getLogger(__name__) class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"", "label": 1}, {"snippet_id": 56556, "code": "' % q_app) q_app_module=sys.modules['tcms.%s.forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse", "label": 1}, {"snippet_id": 89724, "code": "(path, name) if os.path.exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate{} library'.format(name)) return list(collect_existing_libs()) @property def home(self): \"", "label": 0}, {"snippet_id": 39873, "code": ": if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job", "label": 0}, {"snippet_id": 75978, "code": ".status.success: self.log.debug('Successfull auth for(%s, %s)', i, m) elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3}'.\\ format(i, m,", "label": 1}, {"snippet_id": 55206, "code": " logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \"", "label": 0}, {"snippet_id": 53812, "code": "._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append", "label": 0}, {"snippet_id": 93809, "code": "/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start", "label": 0}, {"snippet_id": 34819, "code": "(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self", "label": 0}, {"snippet_id": 55283, "code": "))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes", "label": 0}, {"snippet_id": 40666, "code": "\"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError", "label": 1}, {"snippet_id": 17468, "code": ")): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request", "label": 0}, {"snippet_id": 51043, "code": ")) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names", "label": 1}, {"snippet_id": 78415, "code": ".w.sleep(self.topic_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10) except exc.UnknownAnswer as e: self.log.warning('%s: %s', e, e.answer", "label": 0}, {"snippet_id": 5256, "code": ".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var", "label": 0}, {"snippet_id": 3016, "code": "['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window", "label": 0}, {"snippet_id": 17728, "code": "): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 70870, "code": " AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 47372, "code": " omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare()", "label": 0}, {"snippet_id": 84573, "code": ".util.contextutil import temporary_dir class CountLinesOfCode(ConsoleTask): \"\"\"Print counts of lines of code.\"\"\" @classmethod def subsystem_dependencies(cls): return super(CountLinesOfCode, cls).subsystem_dependencies", "label": 0}, {"snippet_id": 66248, "code": "[\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout", "label": 0}, {"snippet_id": 18656, "code": ": if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message'])", "label": 0}, {"snippet_id": 34925, "code": "} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n", "label": 0}, {"snippet_id": 69693, "code": "\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f ", "label": 0}, {"snippet_id": 52565, "code": " in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination", "label": 0}, {"snippet_id": 29085, "code": " the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data", "label": 1}, {"snippet_id": 28556, "code": "'Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2", "label": 0}, {"snippet_id": 90920, "code": " \"\"\" try: return cls.global_instance()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java", "label": 0}, {"snippet_id": 1470, "code": "(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address)", "label": 0}, {"snippet_id": 73012, "code": " files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list \"\"\" if(remote_subdirs_list is not None", "label": 0}, {"snippet_id": 82198, "code": " parser.add_argument(\"-T\",\"--threads\",metavar=\"Threads\",nargs=1,dest=\"nbThreads\",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group(", "label": 0}, {"snippet_id": 79638, "code": "\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output", "label": 0}, {"snippet_id": 54164, "code": " params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{", "label": 0}, {"snippet_id": 11238, "code": ".yaml' Usage: monconfgenerator[--debug][--targetdir=<directory>][--skip-checks][URL] monconfgenerator -h Options: -h Show this message. --debug Print additional information. --targetdir=DIR The generated", "label": 0}, {"snippet_id": 67914, "code": "\"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand", "label": 0}, {"snippet_id": 90129, "code": " exe=self._validate_executable(name) self._validated_binaries[name]=exe return exe @contextmanager def _valid_executable(self, name): exe=self._validate_executable(name) yield exe self._validated_binaries", "label": 0}, {"snippet_id": 79250, "code": "\t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(", "label": 0}, {"snippet_id": 86044, "code": "*args, **kwargs) self.set_distribution(jdk=True) def select(self, target): if not isinstance(target, JvmTarget): return False return target.has_sources('.java') def select_source(self, source_file_path", "label": 0}, {"snippet_id": 5302, "code": ":keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html", "label": 0}, {"snippet_id": 49004, "code": " os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake", "label": 0}, {"snippet_id": 62028, "code": " Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random", "label": 0}, {"snippet_id": 91332, "code": " task def build_file_aliases(): return BuildFileAliases( targets={ PythonApp.alias(): PythonApp, PythonBinary.alias(): PythonBinary, PythonLibrary.alias(): PythonLibrary, PythonTests.alias(): PythonTests", "label": 0}, {"snippet_id": 65828, "code": "): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target)", "label": 0}, {"snippet_id": 63663, "code": ": log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"", "label": 0}, {"snippet_id": 87545, "code": " in self.get_options().compiler_option_sets_disabled_args.items(): if option_set not in compiler_option_sets: if option_set=='fatal_warnings': disabled_args=self.get_options().fatal_warnings_disabled_args", "label": 0}, {"snippet_id": 74688, "code": " integer value\") if \"chunk_length\" in runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str", "label": 0}, {"snippet_id": 84791, "code": " import InjectablesMixin from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem major_version_info=namedtuple('major_version_info',['full_version']) scala_build_info", "label": 0}, {"snippet_id": 81189, "code": ".trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \"", "label": 0}, {"snippet_id": 63931, "code": ": work_dir_outputs=[] output_files=self.get_output_files( job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files", "label": 1}, {"snippet_id": 70974, "code": ".append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" %", "label": 0}, {"snippet_id": 78760, "code": " for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not available: %s', e) except", "label": 0}, {"snippet_id": 872, "code": " i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e", "label": 0}, {"snippet_id": 46844, "code": ".rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self", "label": 0}, {"snippet_id": 66334, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout", "label": 0}, {"snippet_id": 16134, "code": " subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers", "label": 0}, {"snippet_id": 35685, "code": "._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next", "label": 0}, {"snippet_id": 77103, "code": ".pickle' def init_th_sock(self): self.log.info( 'Initializing intraprocess signal socket %s', self.th_sa) self.th_sock=self.p.ctx.socket(zmq.PUB) self.th_sock.bind(self.th_sa) def init_th_back_sock(self)", "label": 0}, {"snippet_id": 70155, "code": "% \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr", "label": 0}, {"snippet_id": 68259, "code": " elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\",", "label": 0}, {"snippet_id": 73272, "code": " file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)) print(\"[Setup][Data] Decompressing file:{}\".format(path_str)) print(\" -Output:{", "label": 0}, {"snippet_id": 91905, "code": "(__name__) class PythonNativeCode(Subsystem): \"\"\"A subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope='python-native-code' default_native_source_extensions=['.c',", "label": 0}, {"snippet_id": 70316, "code": " RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 0}, {"snippet_id": 26310, "code": "}) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set", "label": 0}, {"snippet_id": 1502, "code": "\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='getSchema': schema=get_osversion() return JsonResponse({\"version_info\":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails", "label": 0}, {"snippet_id": 64896, "code": " def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return", "label": 0}, {"snippet_id": 64992, "code": ".Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose", "label": 0}, {"snippet_id": 92818, "code": "', False) for invalid in falsey: with self.assertRaises(InvalidZipPath): next(open_zip(invalid).gen) def test_open_zip_returns_realpath_on_badzipfile(self): with temporary_file() as not_zip: with temporary_dir", "label": 0}, {"snippet_id": 63451, "code": ".get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id)", "label": 0}, {"snippet_id": 65715, "code": ".state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[", "label": 0}, {"snippet_id": 62240, "code": ", and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=[x.val", "label": 0}, {"snippet_id": 52260, "code": " self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params", "label": 0}, {"snippet_id": 55780, "code": "(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring", "label": 0}, {"snippet_id": 66367, "code": " import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import", "label": 0}, {"snippet_id": 50251, "code": ".add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo", "label": 0}, {"snippet_id": 43551, "code": "): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp", "label": 0}, {"snippet_id": 80202, "code": "=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in", "label": 0}, {"snippet_id": 35655, "code": " name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self)", "label": 0}, {"snippet_id": 5314, "code": " <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches", "label": 0}, {"snippet_id": 49552, "code": "=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error", "label": 0}, {"snippet_id": 46148, "code": " len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if", "label": 0}, {"snippet_id": 10515, "code": " bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\")", "label": 1}, {"snippet_id": 35414, "code": "() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path", "label": 0}, {"snippet_id": 35637, "code": " get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names ", "label": 0}, {"snippet_id": 47833, "code": " self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self", "label": 0}, {"snippet_id": 78750, "code": "'Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except", "label": 0}, {"snippet_id": 52802, "code": ".benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job", "label": 0}, {"snippet_id": 6706, "code": " :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean", "label": 0}, {"snippet_id": 27602, "code": "'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=", "label": 0}, {"snippet_id": 14147, "code": " from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils", "label": 0}, {"snippet_id": 73144, "code": "{}\".format(file_counter, file_list_total, file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter", "label": 0}, {"snippet_id": 32070, "code": "(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[", "label": 0}, {"snippet_id": 29851, "code": ".finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch", "label": 0}, {"snippet_id": 28394, "code": " for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name", "label": 0}, {"snippet_id": 50805, "code": ") def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file", "label": 0}, {"snippet_id": 58297, "code": " EnvGroupFactory from tcms.tests.factories import EnvGroupPropertyMapFactory from tcms.tests.factories import EnvPropertyFactory class TestNavigation(test.TestCase): @classmethod def setUpTestData(cls): super", "label": 0}, {"snippet_id": 76780, "code": ".add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser.add_argument('--topic_successtimeout', type=float, default=0.1, help='Topic success timeout') parser", "label": 0}, {"snippet_id": 91784, "code": ", env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=merged_input_files, description='Run pytest for{}'.format(test_target.address.reference()), ) result=yield", "label": 0}, {"snippet_id": 11332, "code": " __init__(self, url, debug_enabled=False, target_dir=None, skip_checks=False): self.skip_checks=skip_checks self.target_dir=target_dir if target_dir else CONFIG['TARGET_DIR'] self.source=url if debug_enabled", "label": 0}, {"snippet_id": 27927, "code": " data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state", "label": 0}, {"snippet_id": 48526, "code": " or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input", "label": 0}, {"snippet_id": 77320, "code": " not hasattr(self, 'pr_sock'): self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running", "label": 0}, {"snippet_id": 70099, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %", "label": 0}, {"snippet_id": 31568, "code": ".version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args", "label": 0}, {"snippet_id": 17629, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else:", "label": 0}, {"snippet_id": 1295, "code": "=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append", "label": 0}, {"snippet_id": 1068, "code": ") elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 64545, "code": " install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install", "label": 0}, {"snippet_id": 18932, "code": ".Mapping): return source elif hasattr(source, 'read') and callable(source.read): raw_source=source.read() elif os.path.exists(os.path.expanduser(str(source))): with open(os.path.expanduser(str(source)), ", "label": 0}, {"snippet_id": 4327, "code": "\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file", "label": 1}, {"snippet_id": 80606, "code": "\ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning", "label": 0}, {"snippet_id": 23063, "code": " mcpd to load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make when mounting the provisioningiso", "label": 0}, {"snippet_id": 34143, "code": ".benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format", "label": 0}, {"snippet_id": 60110, "code": " variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=", "label": 0}, {"snippet_id": 81832, "code": "=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1", "label": 0}, {"snippet_id": 62800, "code": " argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed", "label": 0}, {"snippet_id": 32715, "code": ".. \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name", "label": 0}, {"snippet_id": 59477, "code": " the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)", "label": 0}, {"snippet_id": 70839, "code": "(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(", "label": 0}, {"snippet_id": 15096, "code": ") SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json", "label": 1}, {"snippet_id": 41039, "code": " None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names", "label": 0}, {"snippet_id": 7336, "code": " code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords:", "label": 0}, {"snippet_id": 67251, "code": " if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed", "label": 1}, {"snippet_id": 42787, "code": " output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or", "label": 0}, {"snippet_id": 75669, "code": " if name else type(self).__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests=[] self", "label": 0}, {"snippet_id": 27609, "code": "': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low", "label": 0}, {"snippet_id": 53272, "code": "=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output", "label": 0}, {"snippet_id": 59406, "code": " if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs", "label": 0}, {"snippet_id": 17452, "code": "=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and", "label": 0}, {"snippet_id": 13364, "code": "(fullname, file) params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file", "label": 0}, {"snippet_id": 76107, "code": " that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m])) def set_route_type(self, i, m, t): self.log.debug('Setting %s,%s type to %d', i,", "label": 0}, {"snippet_id": 1804, "code": "': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state':", "label": 0}, {"snippet_id": 36366, "code": ".input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark", "label": 0}, {"snippet_id": 64955, "code": ".Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base", "label": 0}, {"snippet_id": 382, "code": " queryset=RegisteredServices.objects.all() serializer=RegisteredServicesSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return", "label": 0}, {"snippet_id": 32787, "code": " format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception", "label": 0}, {"snippet_id": 54193, "code": " requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error", "label": 0}, {"snippet_id": 36743, "code": " return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value", "label": 0}, {"snippet_id": 29847, "code": " file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated", "label": 0}, {"snippet_id": 20831, "code": " **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq'] result={'msg': None} def match(msg", "label": 0}, {"snippet_id": 12445, "code": " error_string_list=error_string.split(\" \") code=error_string_list[2] code_url=\"https://duckduckgo.com/?q=pep8%20{0}\".format(code) error_string_list[2]=\"[{0}]({1})\".format(code, code_url) line, col=error_string_list[1]", "label": 0}, {"snippet_id": 74743, "code": ": \\\"default\\\" or integer value\") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types: self.compressor", "label": 0}, {"snippet_id": 9363, "code": " only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p=_sort_kw_matches(composite_keywords) for w in single_keywords_p: categories[w[0].concept]", "label": 0}, {"snippet_id": 16507, "code": ": return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self", "label": 0}, {"snippet_id": 3062, "code": ".debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self", "label": 1}, {"snippet_id": 95410, "code": "}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath", "label": 0}, {"snippet_id": 86119, "code": " with safe_open(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip())) def execute(self): if JvmPlatform.global_instance().get_options().compiler=='javac':", "label": 0}, {"snippet_id": 53166, "code": ", *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message", "label": 0}, {"snippet_id": 77778, "code": " join_threads(self): for t in self.threads: t.join() def send_passthrough(self, interface, method, frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) self.th_sock", "label": 0}, {"snippet_id": 7915, "code": ".output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords", "label": 0}, {"snippet_id": 55667, "code": " snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo", "label": 0}, {"snippet_id": 51193, "code": " set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path", "label": 0}, {"snippet_id": 37852, "code": "=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards", "label": 0}, {"snippet_id": 2919, "code": "(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s", "label": 0}, {"snippet_id": 80592, "code": "\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\":", "label": 0}, {"snippet_id": 19997, "code": "=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError('detach not supported') self._detach() def _close(self): if self._session is not None: try: self._session.close", "label": 0}, {"snippet_id": 60071, "code": ".eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng", "label": 0}, {"snippet_id": 39582, "code": ".func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, ", "label": 0}, {"snippet_id": 49975, "code": "}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources", "label": 0}, {"snippet_id": 72692, "code": ", temp_dir=temp_directory, output_dir=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service.setup_vcf_to_zarr(input_vcf_dir", "label": 1}, {"snippet_id": 36445, "code": " requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f", "label": 0}, {"snippet_id": 2967, "code": " True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp", "label": 0}, {"snippet_id": 85877, "code": " AnnotationProcessor from pants.backend.jvm.targets.javac_plugin import JavacPlugin from pants.backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile", "label": 0}, {"snippet_id": 27346, "code": ", monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions", "label": 0}, {"snippet_id": 35156, "code": "(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input", "label": 1}, {"snippet_id": 67871, "code": "=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) if hasattr(eh, 'post", "label": 0}, {"snippet_id": 72344, "code": ".service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally: log.debug('(%s) networks.remote: restoring reply() of IRC object %s', irc.name, netname) remoteirc.reply=old_reply", "label": 1}, {"snippet_id": 86502, "code": " pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants.base.build_environment import get_buildroot from pants.base", "label": 0}, {"snippet_id": 89219, "code": " build_graph=self.build_graph.clone_new() for address in self.address_mapper.scan_addresses(root): build_graph.inject_address_closure(address) return build_graph def execute_process_synchronously(self,", "label": 1}, {"snippet_id": 78193, "code": "*kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)==tuple and list(targets) or targets) super().__init__(*args, **kvargs", "label": 0}, {"snippet_id": 17901, "code": " @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data", "label": 0}, {"snippet_id": 9608, "code": "<subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in", "label": 0}, {"snippet_id": 80116, "code": ".add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript", "label": 0}, {"snippet_id": 71375, "code": "+=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled", "label": 0}, {"snippet_id": 28883, "code": ")\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210:", "label": 0}, {"snippet_id": 71726, "code": ".getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen", "label": 0}, {"snippet_id": 53486, "code": ".setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files.", "label": 0}, {"snippet_id": 495, "code": " password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect", "label": 0}, {"snippet_id": 27526, "code": " _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state", "label": 0}, {"snippet_id": 77990, "code": " targets[%s]', repr(t), domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target(domain, id_, user) def rtfu(urls):", "label": 0}, {"snippet_id": 49352, "code": " resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores", "label": 0}, {"snippet_id": 44452, "code": "*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 49334, "code": " rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores", "label": 0}, {"snippet_id": 16405, "code": "._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 28724, "code": ": self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp", "label": 0}, {"snippet_id": 8648, "code": " unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the", "label": 0}, {"snippet_id": 94473, "code": " run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient pid amount: returning true\") return", "label": 0}, {"snippet_id": 71703, "code": " def print_csdebug(task, s): m=re.search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self", "label": 1}, {"snippet_id": 26259, "code": "'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio'", "label": 0}, {"snippet_id": 53515, "code": " for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self", "label": 0}, {"snippet_id": 23625, "code": " to specify the route manually to get it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run", "label": 0}, {"snippet_id": 74907, "code": ": try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input\" in runtime_config.benchmark: benchmark_data_input_temp=runtime_config", "label": 0}, {"snippet_id": 22795, "code": ". So we can't rely on this value. :param username: The username whose password to change :param password: The unencrypted password to set for the user :param crypt_id: If encrypting the password, the crypt_id", "label": 0}, {"snippet_id": 54468, "code": " import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake", "label": 1}, {"snippet_id": 26963, "code": "._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data", "label": 0}, {"snippet_id": 28925, "code": " data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state", "label": 0}, {"snippet_id": 66485, "code": "(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ ", "label": 0}, {"snippet_id": 9036, "code": "=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None", "label": 0}, {"snippet_id": 16394, "code": ".poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr:", "label": 0}, {"snippet_id": 70767, "code": " return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state=", "label": 0}, {"snippet_id": 44966, "code": ".message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__", "label": 0}, {"snippet_id": 19846, "code": ".closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None raise NotImplementedError def stop_debugging", "label": 0}, {"snippet_id": 23761, "code": " to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print $2}'\") if ret: raise OSUtilError(\"Failed to get processor cores", "label": 0}, {"snippet_id": 83559, "code": "(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds", "label": 0}, {"snippet_id": 55059, "code": " Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that", "label": 0}, {"snippet_id": 94752, "code": " master invoking \" \"this command.\\nIf run with the --kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show a graph image\", action=\"store_true\"", "label": 0}, {"snippet_id": 26904, "code": " >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 80030, "code": " the server. Needs -l switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.", "label": 0}, {"snippet_id": 33971, "code": "(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name", "label": 0}, {"snippet_id": 70301, "code": ".__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR:", "label": 0}, {"snippet_id": 88141, "code": ")) return plugin_info.find('name').text if os.path.isdir(classpath_element): try: with open(os.path.join(classpath_element, _SCALAC_PLUGIN_INFO_FILE), 'r') as plugin_info_file: return process_info_file", "label": 0}, {"snippet_id": 77302, "code": " hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess): type_=1 if not hasattr(self, 'pr_sock'): self", "label": 0}, {"snippet_id": 31717, "code": " in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old", "label": 1}, {"snippet_id": 50836, "code": "._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property", "label": 0}, {"snippet_id": 13581, "code": " EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE,", "label": 0}, {"snippet_id": 802, "code": ".split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con", "label": 0}, {"snippet_id": 62294, "code": ": raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires", "label": 0}, {"snippet_id": 66852, "code": ".debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command),", "label": 0}, {"snippet_id": 70280, "code": "(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def", "label": 0}, {"snippet_id": 34904, "code": "\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds", "label": 0}, {"snippet_id": 49858, "code": "\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes", "label": 0}, {"snippet_id": 47936, "code": " rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand", "label": 0}, {"snippet_id": 24335, "code": " available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name", "label": 1}, {"snippet_id": 62144, "code": "\"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs", "label": 0}, {"snippet_id": 4293, "code": " process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file", "label": 1}, {"snippet_id": 44812, "code": "(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile", "label": 0}, {"snippet_id": 47785, "code": "=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1", "label": 0}, {"snippet_id": 74749, "code": " runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if compressor_temp in vcf_to_zarr_compressor_types: self.compressor=compressor_temp if \"blosc_compression_algorithm\"", "label": 0}, {"snippet_id": 70959, "code": ": t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status", "label": 0}, {"snippet_id": 58317, "code": ") cls.user=UserFactory(email='user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses(self): self.client.login( username=self.user.username, password=", "label": 0}, {"snippet_id": 42592, "code": " branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values", "label": 0}, {"snippet_id": 74673, "code": " self.alt_number=None elif isint(alt_number_str): self.alt_number=int(alt_number_str) else: raise TypeError(\"Invalid value provided for alt_number in configuration.\\n\" \"Expected: \\\"auto\\\" or integer value", "label": 0}, {"snippet_id": 42304, "code": " collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake", "label": 0}, {"snippet_id": 31837, "code": ": self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments", "label": 0}, {"snippet_id": 55186, "code": " dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency", "label": 0}, {"snippet_id": 92158, "code": " def register_options(cls, register): super(BuildSetupRequiresPex, cls).register_options(register) register('--setuptools-version', advanced=True, fingerprint=True, default='40.6.3', help='The setuptools", "label": 0}, {"snippet_id": 80422, "code": " or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password:", "label": 0}, {"snippet_id": 12522, "code": "\"Cheers ! There are no PEP8 issues in this Pull Request.:beers: \") comment_body=''.join(comment_body) comment_footer=[] if request.json[\"action\"]==\"opened\": comment_footer.append(config[\"message\"][\"opened", "label": 0}, {"snippet_id": 21172, "code": " message +='Event{}'.format(self.name) else: message +='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None):", "label": 0}, {"snippet_id": 28487, "code": " of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the", "label": 0}, {"snippet_id": 54286, "code": " bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards", "label": 0}, {"snippet_id": 20312, "code": "._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self", "label": 0}, {"snippet_id": 38196, "code": " attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, ", "label": 0}, {"snippet_id": 34346, "code": " ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self", "label": 0}, {"snippet_id": 68316, "code": ", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 23113, "code": " provisioning DVD BIG-IP does not include an eject command. It is sufficient to just umount the DVD disk. But I will log that we do not support this for future reference. :param chk_err: Whether or not", "label": 0}, {"snippet_id": 30404, "code": " pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try:", "label": 0}, {"snippet_id": 62420, "code": " and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs", "label": 0}, {"snippet_id": 79222, "code": "(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0", "label": 0}, {"snippet_id": 90137, "code": " return exe @contextmanager def _valid_executable(self, name): exe=self._validate_executable(name) yield exe self._validated_binaries[name]=exe def __repr__(self): return('Distribution({!r}, minimum_version", "label": 0}, {"snippet_id": 6070, "code": " local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document", "label": 1}, {"snippet_id": 45660, "code": "._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self", "label": 0}, {"snippet_id": 31006, "code": "): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self", "label": 0}, {"snippet_id": 85129, "code": ": return self._tool_classpath('scalac', products) def style_classpath(self, products): return self._tool_classpath('scalastyle', products) @property def version(self): return self.get_options().version", "label": 0}, {"snippet_id": 22460, "code": " shellutil.run(\"/sbin/service waagent stop\", chk_err=False) def start_agent_service(self): return shellutil.run(\"/sbin/service waagent start\", chk_err=False) def register_agent_service(self): return shellutil", "label": 0}, {"snippet_id": 36727, "code": " is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other", "label": 0}, {"snippet_id": 7584, "code": " output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace", "label": 0}, {"snippet_id": 60757, "code": " def new_object(*args, **kwargs): \"\"\"Return a new object of the same class, passing the attribute name as the first parameter, along with any additional parameters.\"\"\" return cls(name, *args, **kwargs)", "label": 0}, {"snippet_id": 37001, "code": "=1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output)", "label": 0}, {"snippet_id": 68588, "code": " \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"", "label": 0}, {"snippet_id": 71339, "code": ".set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size", "label": 0}, {"snippet_id": 44638, "code": " if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule", "label": 0}, {"snippet_id": 74085, "code": ") and(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must", "label": 0}, {"snippet_id": 23309, "code": " return shellutil.run(cmd, chk_err=False) def device_for_ide_port(self, port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in here because BIG-IP may not have yet initialized this", "label": 0}, {"snippet_id": 92405, "code": "'AAA', os.environ) def test_hermetic_environment_unicode(self): UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output=UNICODE_CHAR if PY3 else ENCODED_CHAR with environment_as(**dict", "label": 1}, {"snippet_id": 54094, "code": " _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles", "label": 0}, {"snippet_id": 38359, "code": "() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for", "label": 0}, {"snippet_id": 4956, "code": " return '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'", "label": 0}, {"snippet_id": 56526, "code": "'app_form') q_format=request.GET.get('format') if not q_format: q_format='p' if not q_app_form: return HttpResponse('Unrecognizable app_form') q_app, q_form=q_app_form.split('.')[0], q_app_form.split('.')[1]", "label": 1}, {"snippet_id": 27788, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 68377, "code": "[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering", "label": 0}, {"snippet_id": 7939, "code": "): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean", "label": 0}, {"snippet_id": 20219, "code": ".join(timeout=self._connecttimeout) if t.is_alive(): warnings.warn('timed out waiting for connection') if self._session is None: message='unable to connect after{} secs'.format( self._connecttimeout) if", "label": 0}, {"snippet_id": 38076, "code": ".workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self):", "label": 0}, {"snippet_id": 71316, "code": " [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column", "label": 0}, {"snippet_id": 95888, "code": "[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\" -Output:{}\".format", "label": 0}, {"snippet_id": 3098, "code": ", hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is", "label": 0}, {"snippet_id": 91088, "code": " _get_explicit_jdk_paths(self): if not self._normalized_jdk_paths: return() os_name=normalize_os_name(os.uname()[0].lower()) if os_name not in self._normalized_jdk_paths: logger.warning('--jvm-distributions-paths was", "label": 0}, {"snippet_id": 31120, "code": " unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_", "label": 0}, {"snippet_id": 28433, "code": "=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id']", "label": 0}, {"snippet_id": 62516, "code": "' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its", "label": 0}, {"snippet_id": 46698, "code": " WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if", "label": 0}, {"snippet_id": 16926, "code": "._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method", "label": 0}, {"snippet_id": 43783, "code": ": return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() )", "label": 0}, {"snippet_id": 56868, "code": " key: either 'num_plans', 'num_cases', 'num_runs', depending on what you want count :type key: str :param test_tags: query set, containing the Tag->Object relationship, ordered by tag and annotated by key", "label": 0}, {"snippet_id": 24501, "code": "): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update", "label": 0}, {"snippet_id": 2508, "code": " self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not", "label": 0}, {"snippet_id": 89007, "code": " in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of the run", "label": 0}, {"snippet_id": 22726, "code": ": raise OSUtilError( \"Failed to create user account:{0}, retcode:{1}, output:{2}\".format(username, retcode, out) ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id", "label": 0}, {"snippet_id": 58826, "code": "', TestCaseRun.objects.get(pk=self.case_run_1.pk).case_run_status.name) class TestGetForm(test.TestCase): \"\"\"Test case for form\"\"\" def test_get_form(self): response=self.client.get(reverse('ajax-form')", "label": 1}, {"snippet_id": 44016, "code": "=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None", "label": 0}, {"snippet_id": 76923, "code": "'SOCKS5': net.proxy_type=sup.proxytype.socks5 else: raise TypeError('Invalid proxytype %s' % proxytype) net.useragent=random.choice(d.ua_list) net.timeout=c.rp_timeout return net def upload_avatar(self, ud", "label": 1}, {"snippet_id": 77956, "code": ".remove(t) def add_target_exc(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError", "label": 0}, {"snippet_id": 49515, "code": "(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules)", "label": 0}, {"snippet_id": 37481, "code": ".dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item", "label": 0}, {"snippet_id": 76725, "code": " default='randav', help='Directory with avatars') parser.add_argument('--rp-timeout', '-T', type=int, default=10, help='Default rp timeout in seconds') parser.add_argument('--conlimit', type=int, default", "label": 0}, {"snippet_id": 60723, "code": " logging logging.getLogger() class MethodFactory(type): \"\"\"Metaclass that allows derived classes to dynamically instantiate new objects based on undefined methods. The dynamic methods pass their arguments", "label": 0}, {"snippet_id": 36500, "code": " previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning", "label": 0}, {"snippet_id": 41498, "code": "=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output:", "label": 0}, {"snippet_id": 4174, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs)", "label": 0}, {"snippet_id": 4520, "code": "=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords)", "label": 0}, {"snippet_id": 43315, "code": ")) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output", "label": 0}, {"snippet_id": 62688, "code": " super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the", "label": 0}, {"snippet_id": 96062, "code": "-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite", "label": 1}, {"snippet_id": 6429, "code": " import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\"", "label": 1}, {"snippet_id": 68674, "code": " dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO", "label": 0}, {"snippet_id": 8026, "code": "[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"", "label": 0}, {"snippet_id": 72437, "code": " records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line", "label": 1}, {"snippet_id": 80415, "code": " federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input", "label": 0}, {"snippet_id": 27116, "code": " datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE,", "label": 1}, {"snippet_id": 11668, "code": "['URL'])) exit_code=EXIT_CODE_NOT_WRITTEN except ConfigurationContainsUndefinedVariables: LOG.error(\"Configuration contained undefined variables!\") exit_code=EXIT_CODE_ERROR except SystemExit as e: exit_code", "label": 0}, {"snippet_id": 34622, "code": ") @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink", "label": 1}, {"snippet_id": 20948, "code": " self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message(self, msg): for i, handler in enumerate(list(self._handlers)", "label": 1}, {"snippet_id": 81154, "code": "=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder", "label": 0}, {"snippet_id": 67432, "code": " name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self", "label": 0}, {"snippet_id": 7398, "code": ", encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags", "label": 0}, {"snippet_id": 42210, "code": " __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules", "label": 0}, {"snippet_id": 39117, "code": " drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if", "label": 0}, {"snippet_id": 13323, "code": " _=proc.communicate() data[\"results\"][filename]=stdout.decode(r.encoding) os.remove(\"file_to_fix.py\") def commit(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[", "label": 0}, {"snippet_id": 43702, "code": ".overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile", "label": 0}, {"snippet_id": 61618, "code": " target subsystem Returns: float: expectation value:math:`\\expect{A}=\\bra{\\psi}A\\ket{\\psi}` \"\"\" if A.shape !=(2, 2): raise ValueError('2x2 matrix required.') A=self.expand_one(A, wires) expectation=np.vdot", "label": 0}, {"snippet_id": 52124, "code": " YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys", "label": 0}, {"snippet_id": 57332, "code": "(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field{} changed from{} to{}.'", "label": 0}, {"snippet_id": 3699, "code": " logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded", "label": 0}, {"snippet_id": 9269, "code": ", ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit", "label": 0}, {"snippet_id": 12040, "code": ".format(key, ','.join(value))) config[\"pycodestyle_cmd_config\"]='{arguments}'.format(arguments=' '.join(arguments)) config[\"pycodestyle\"][\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"", "label": 0}, {"snippet_id": 68360, "code": "\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in", "label": 0}, {"snippet_id": 79732, "code": ",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer", "label": 0}, {"snippet_id": 52940, "code": " \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other", "label": 0}, {"snippet_id": 74859, "code": " for object representation of the benchmark module's configuration. \"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_aggregations=False benchmark_PCA=False vcf_to_zarr_config", "label": 1}, {"snippet_id": 43974, "code": ", quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False", "label": 0}, {"snippet_id": 40221, "code": "=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard", "label": 1}, {"snippet_id": 4448, "code": " boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"", "label": 0}, {"snippet_id": 56568, "code": "=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan, TestCase or", "label": 1}, {"snippet_id": 93789, "code": ".logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name']))", "label": 0}, {"snippet_id": 49366, "code": ".name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None", "label": 0}, {"snippet_id": 24808, "code": "] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0", "label": 0}, {"snippet_id": 51888, "code": " in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name", "label": 0}, {"snippet_id": 87045, "code": " compiles to the cache.\"\"\" return self.get_options().incremental_caching @memoized_property def _zinc(self): return Zinc.Factory.global_instance().create(self.context.products) def __init__(self, *args, *", "label": 1}, {"snippet_id": 91167, "code": ".backend.python.targets.python_app import PythonApp from pants.backend.python.targets.python_binary import PythonBinary from pants.backend.python.targets.python_distribution import PythonDistribution from", "label": 0}, {"snippet_id": 77153, "code": " self.pr_sock=self.p.ctx.socket(zmq.PUB) self.pr_sock.bind(self.pr_sa) def init_pr_back_sock(self): self.log.info( 'Initializing interprocess backward socket %s', self.pr_ba) self.pr_back_sock=self.p.ctx", "label": 0}, {"snippet_id": 39551, "code": ".message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd", "label": 0}, {"snippet_id": 70538, "code": " def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target", "label": 0}, {"snippet_id": 37400, "code": " --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies", "label": 0}, {"snippet_id": 89016, "code": " dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of the run. See Target.closure_for_targets for remaining parameters. :API:", "label": 0}, {"snippet_id": 8742, "code": "): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode", "label": 0}, {"snippet_id": 55578, "code": "._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir", "label": 0}, {"snippet_id": 83805, "code": "._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to", "label": 0}, {"snippet_id": 47425, "code": "**variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self", "label": 0}, {"snippet_id": 55551, "code": ".path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack", "label": 0}, {"snippet_id": 33436, "code": " \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \"", "label": 0}, {"snippet_id": 6088, "code": " st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document", "label": 0}, {"snippet_id": 41531, "code": ".touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f", "label": 0}, {"snippet_id": 63272, "code": ") return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination", "label": 0}, {"snippet_id": 30293, "code": ": end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self", "label": 0}, {"snippet_id": 86326, "code": " return_code else WorkUnit.SUCCESS) if return_code: raise TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin", "label": 0}, {"snippet_id": 85035, "code": " be used.') register('--suffix-version', advanced=True, default=None, help='Scala suffix to be used in `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar`", "label": 0}, {"snippet_id": 85631, "code": ": list of str \"\"\" return self._zinc_factory.dist @memoized_property def compiler_bridge(self): \"\"\"Return the path to the Zinc compiler-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge", "label": 0}, {"snippet_id": 50845, "code": " raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists", "label": 1}, {"snippet_id": 70896, "code": " show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=", "label": 0}, {"snippet_id": 89071, "code": " self.build_graph.get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs", "label": 0}, {"snippet_id": 39458, "code": ".set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"", "label": 0}, {"snippet_id": 68803, "code": " AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 8063, "code": "\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short", "label": 0}, {"snippet_id": 94255, "code": " aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if", "label": 0}, {"snippet_id": 89701, "code": " collect_existing_libs(): def lib_paths(): yield os.path.join(self.home, 'lib') if self.jdk: yield os.path.join(self.home, 'jre', 'lib') for name in names: for path in lib_paths(): lib_path=os.path.join(path, name", "label": 0}, {"snippet_id": 30540, "code": " import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards,", "label": 1}, {"snippet_id": 67961, "code": ".EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776", "label": 0}, {"snippet_id": 69072, "code": "(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes", "label": 0}, {"snippet_id": 67197, "code": " from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem", "label": 0}, {"snippet_id": 85966, "code": "(javac_plugin_target.classname) @classmethod def get_args_default(cls, bootstrap_option_values): return('-encoding', 'UTF-8') @classmethod def get_warning_args_default(cls): return('-deprecation', '-Xlint", "label": 0}, {"snippet_id": 10799, "code": " the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify", "label": 1}, {"snippet_id": 16022, "code": "/localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ ", "label": 0}, {"snippet_id": 90214, "code": " `java` executable parent directory. :param string bin_path: The parent path of the `java` executable. :returns: The java distribution location. \"\"\" return cls(home_path=None, bin_path=bin_path) @abstractproperty", "label": 0}, {"snippet_id": 62535, "code": " constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset()", "label": 0}, {"snippet_id": 89560, "code": " bin_path and not os.path.isdir(bin_path): raise ValueError('The specified binary path is invalid:{}'.format(bin_path)) if not bool(home_path) ^ bool(bin_path): raise ValueError('Exactly one of home path", "label": 0}, {"snippet_id": 6984, "code": " object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw", "label": 0}, {"snippet_id": 47039, "code": ".message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex", "label": 0}, {"snippet_id": 45657, "code": " is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start", "label": 0}, {"snippet_id": 14317, "code": "-port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 64216, "code": ", remote_job_config): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths", "label": 0}, {"snippet_id": 34142, "code": " ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__", "label": 0}, {"snippet_id": 36586, "code": " since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"", "label": 0}, {"snippet_id": 43736, "code": ".globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 62959, "code": ".lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR", "label": 0}, {"snippet_id": 43905, "code": "(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name", "label": 0}, {"snippet_id": 17823, "code": "( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets", "label": 0}, {"snippet_id": 42044, "code": " log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex)", "label": 0}, {"snippet_id": 89949, "code": " self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please check you have a JDK ' 'installed. Original error:{}'.format(e)) raise def execute_java", "label": 0}, {"snippet_id": 17960, "code": " BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests", "label": 1}, {"snippet_id": 50892, "code": " file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def", "label": 1}, {"snippet_id": 21379, "code": "=[] unseen_file=sr_dir +\"/unseen\" unseen_links=[] print(\"Reddytt: Checking for reddytt working directory(%s).\" % work_dir) if not os.path.isdir(work_dir): print(\"Reddytt: Working directory not found. Creating", "label": 0}, {"snippet_id": 79766, "code": ".add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument", "label": 0}, {"snippet_id": 45423, "code": "._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property", "label": 0}, {"snippet_id": 22161, "code": ", self).__init__(conf) def generate_ansible_playbook_from_template(self, template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader", "label": 0}, {"snippet_id": 5499, "code": " to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw,", "label": 0}, {"snippet_id": 18490, "code": " self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler(", "label": 0}, {"snippet_id": 89567, "code": " specified binary path is invalid:{}'.format(bin_path)) if not bool(home_path) ^ bool(bin_path): raise ValueError('Exactly one of home path or bin path should be supplied, given: ' 'home_path={} bin_path", "label": 0}, {"snippet_id": 39219, "code": ".stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile", "label": 0}, {"snippet_id": 59308, "code": ") num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit)", "label": 0}, {"snippet_id": 19546, "code": " is None: pydevd.append(arg) continue if nextarg.endswith(':') and '--module' in pydevd: pydevd.remove('--module') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS", "label": 0}, {"snippet_id": 15295, "code": ".GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args", "label": 1}, {"snippet_id": 83147, "code": " use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class", "label": 0}, {"snippet_id": 56248, "code": ".testcases.models import TestCase, Bug from tcms.testcases.models import Category from tcms.testcases.models import TestCaseStatus, TestCaseTag from tcms.testcases.views import plan_from_request_or_none", "label": 0}, {"snippet_id": 68210, "code": " disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"]", "label": 1}, {"snippet_id": 16247, "code": " __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options)", "label": 0}, {"snippet_id": 56849, "code": ".tag_name) self.obj.remove_tag(tag) class _TagCounter(object): \"\"\" Used for counting the number of times a tag is assigned to TestRun/TestCase/TestPlan \"\"\" def __init__(self, key, test_tags): \"\"\" :param key:", "label": 0}, {"snippet_id": 39318, "code": "=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror", "label": 0}, {"snippet_id": 9516, "code": ".CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords ", "label": 0}, {"snippet_id": 28612, "code": " self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360:", "label": 0}, {"snippet_id": 4752, "code": " formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned", "label": 0}, {"snippet_id": 73704, "code": " return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): ", "label": 0}, {"snippet_id": 14819, "code": "']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def", "label": 0}, {"snippet_id": 40822, "code": " wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for", "label": 0}, {"snippet_id": 62856, "code": ".eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif", "label": 0}, {"snippet_id": 23562, "code": "=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed to delete root password: Failed to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info() if data[0]", "label": 0}, {"snippet_id": 40161, "code": "(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name", "label": 1}, {"snippet_id": 90834, "code": " class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions are searched for in the following order by default: 1. Paths listed for this operating system", "label": 0}, {"snippet_id": 3692, "code": " logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp):", "label": 0}, {"snippet_id": 57597, "code": "(**mail_context) except Exception: pass def _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change", "label": 0}, {"snippet_id": 28419, "code": ".format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon", "label": 0}, {"snippet_id": 48444, "code": " except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for", "label": 0}, {"snippet_id": 25631, "code": "._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500", "label": 0}, {"snippet_id": 15043, "code": "'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData", "label": 0}, {"snippet_id": 23974, "code": "\"\"\" search 'X' from 'dev.storvsc.X.%pnpinfo: classid=32412632-86cb-44a2-9b5c-50d1417354f5 deviceid=00000000-0001-8899-0000-000000000000' \"\"\" cmd_search_ide=\"sysctl dev.storvsc | grep pnpinfo | grep deviceid", "label": 0}, {"snippet_id": 59396, "code": " kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval", "label": 0}, {"snippet_id": 72096, "code": " <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"\"\" permissions.checkPermissions(irc, source,['networks.autoconnect']) try: netname=args[0] seconds", "label": 0}, {"snippet_id": 17620, "code": "._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request", "label": 0}, {"snippet_id": 76340, "code": " def send_wz_error(self, reqid, data, seqid=0): msg=self.wz.make_dealer_rep_msg( reqid, seqid, wzrpc.status.error, data) self.wz_sock.send_multipart(msg) def send_to_router(self, msg): msg.insert(0, b'", "label": 0}, {"snippet_id": 53177, "code": "(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict", "label": 0}, {"snippet_id": 81942, "code": ",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote server where uploads are put. Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs", "label": 0}, {"snippet_id": 81761, "code": "'%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads", "label": 0}, {"snippet_id": 22545, "code": " value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name", "label": 0}, {"snippet_id": 3307, "code": "(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check", "label": 0}, {"snippet_id": 57165, "code": "._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'", "label": 0}, {"snippet_id": 48668, "code": ", snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile,", "label": 0}, {"snippet_id": 63823, "code": " to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id", "label": 0}, {"snippet_id": 3544, "code": " session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check']", "label": 0}, {"snippet_id": 81409, "code": "[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None ", "label": 0}, {"snippet_id": 5446, "code": ".items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append", "label": 0}, {"snippet_id": 43387, "code": " False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format", "label": 0}, {"snippet_id": 82561, "code": " federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input", "label": 0}, {"snippet_id": 95003, "code": "\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file", "label": 0}, {"snippet_id": 52546, "code": "(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output):", "label": 1}, {"snippet_id": 68872, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout", "label": 0}, {"snippet_id": 67555, "code": "%(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print", "label": 0}, {"snippet_id": 5068, "code": "/datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template ", "label": 0}, {"snippet_id": 46050, "code": " raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard", "label": 0}, {"snippet_id": 43266, "code": "(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 27780, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self", "label": 0}, {"snippet_id": 80989, "code": "\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself", "label": 0}, {"snippet_id": 25045, "code": "\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth", "label": 0}, {"snippet_id": 89580, "code": " path should be supplied, given: ' 'home_path={} bin_path={}'.format(home_path, bin_path)) self._home=home_path self._bin_path=bin_path or(os.path.join(home_path, 'bin') if home_path else '/usr/bin') self", "label": 0}, {"snippet_id": 50604, "code": "=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None", "label": 0}, {"snippet_id": 10573, "code": ".escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\"", "label": 1}, {"snippet_id": 43114, "code": " dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self", "label": 0}, {"snippet_id": 21271, "code": " in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label:',", "label": 0}, {"snippet_id": 7253, "code": " MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms ", "label": 0}, {"snippet_id": 14934, "code": "( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return", "label": 1}, {"snippet_id": 82494, "code": ".legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual", "label": 0}, {"snippet_id": 41581, "code": "(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum", "label": 0}, {"snippet_id": 11731, "code": "\"INSERT INTO Users(repository, created_at) VALUES('{}', now());\" \\ \"\".format(repository) try: cursor.execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def follow_user(user): ", "label": 0}, {"snippet_id": 95699, "code": "=str(temp_dir) output_dir=str(output_dir) create_directory_tree(input_dir) create_directory_tree(temp_dir) create_directory_tree(output_dir) pathlist_gz=pathlib.Path(input_dir).glob(\"**/*.gz\") for path in", "label": 0}, {"snippet_id": 61693, "code": "=(2, 2): raise ValueError('2x2 matrix required.') if len(wires) !=1: raise ValueError('One target subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np", "label": 0}, {"snippet_id": 87863, "code": " for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-C-Xplugin", "label": 0}, {"snippet_id": 42907, "code": " raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item):", "label": 0}, {"snippet_id": 60930, "code": " .. todo:: rename to circuits? Returns: dict[str->Circuit]: circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out", "label": 0}, {"snippet_id": 32164, "code": ".items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else", "label": 0}, {"snippet_id": 35365, "code": " comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards)", "label": 0}, {"snippet_id": 47402, "code": "[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove", "label": 0}, {"snippet_id": 3420, "code": "\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error", "label": 0}, {"snippet_id": 88899, "code": "\"Whether the global lock object is actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots) def add_new_target", "label": 0}, {"snippet_id": 21077, "code": "(msg): return msg, False event.set() return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object): @classmethod def wait_all(cls, *awaitables): timeout=3.0 messages", "label": 0}, {"snippet_id": 93469, "code": ".logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2", "label": 0}, {"snippet_id": 18477, "code": "']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if", "label": 0}, {"snippet_id": 4078, "code": " PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML", "label": 0}, {"snippet_id": 93882, "code": "(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return", "label": 1}, {"snippet_id": 95107, "code": "=config.read_configuration(location=cli_arguments[\"config_file\"]) ftp_config=config.FTPConfigurationRepresentation(runtime_config) if ftp_config.enabled: print(\"[Setup][FTP] FTP module enabled. Running", "label": 0}, {"snippet_id": 45688, "code": "(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__()", "label": 0}, {"snippet_id": 93676, "code": " is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name'", "label": 0}, {"snippet_id": 56589, "code": "=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action", "label": 0}, {"snippet_id": 8398, "code": "%(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid", "label": 1}, {"snippet_id": 60239, "code": " 'TwoModeSqueezing': S2gate, 'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML. wires(int): the number of modes to initialize the", "label": 0}, {"snippet_id": 29386, "code": "._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule", "label": 1}, {"snippet_id": 85451, "code": " recursive=True), Shader.exclude_package('xsbti', recursive=True), Shader.exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath", "label": 0}, {"snippet_id": 67362, "code": "=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'", "label": 0}, {"snippet_id": 12297, "code": "[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(repository,", "label": 0}, {"snippet_id": 50624, "code": " self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property", "label": 0}, {"snippet_id": 32612, "code": " return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch", "label": 0}, {"snippet_id": 74989, "code": " generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location", "label": 0}, {"snippet_id": 71934, "code": ".append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker):", "label": 0}, {"snippet_id": 12425, "code": "}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link\"])) for issue in issues: error_string=issue.replace(file +\":\", \"Line \") error_string_list=error_string.split(\" \") code=error_string_list", "label": 0}, {"snippet_id": 79420, "code": ".verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None):", "label": 1}, {"snippet_id": 81911, "code": ") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData)", "label": 0}, {"snippet_id": 14113, "code": ".raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ ", "label": 0}, {"snippet_id": 11097, "code": " __nonzero__(self): return self.etag is None and self.mtime is 0 def __eq__(self, other): return self.etag==other.etag and self.mtime==other.mtime def __repr__(self): return \"Header(%s, %d)\" %(self.etag", "label": 0}, {"snippet_id": 428, "code": ") add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn", "label": 0}, {"snippet_id": 52483, "code": ".format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable", "label": 0}, {"snippet_id": 52020, "code": ") def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class", "label": 0}, {"snippet_id": 42296, "code": " __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from", "label": 0}, {"snippet_id": 93885, "code": ".session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out", "label": 1}, {"snippet_id": 22876, "code": " auth user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin':{0}\".format", "label": 0}, {"snippet_id": 57817, "code": ")==0: break queryset_filter(plan=plan, case__in=case_pks).update(**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list('pk', flat=True", "label": 0}, {"snippet_id": 47747, "code": " IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow", "label": 0}, {"snippet_id": 15323, "code": "._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), ", "label": 0}, {"snippet_id": 63299, "code": " this job. \"\"\" command_line=None client=None remote_job_config=None compute_environment=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool", "label": 0}, {"snippet_id": 66134, "code": ".dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif", "label": 0}, {"snippet_id": 32971, "code": " not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix", "label": 0}, {"snippet_id": 34808, "code": "=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard", "label": 1}, {"snippet_id": 29814, "code": " mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule", "label": 0}, {"snippet_id": 56630, "code": "'tag') test_case_tags=TestCaseTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_cases=Count('tag')).order_by('tag') test_run_tags=TestRunTag.objects.filter( tag__in=all_tags).values('tag", "label": 0}, {"snippet_id": 74485, "code": "\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config", "label": 0}, {"snippet_id": 76566, "code": ", threading, re, traceback, time import random import zmq from queue import Queue import sup import wzworkers as workers from dataloader import DataLoader from uniwipe import UniWipe from wipeskel import", "label": 0}, {"snippet_id": 1755, "code": "'getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor", "label": 0}, {"snippet_id": 71846, "code": " Globals from Shine.Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command", "label": 0}, {"snippet_id": 47226, "code": "): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output", "label": 0}, {"snippet_id": 1239, "code": " osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME", "label": 0}, {"snippet_id": 24928, "code": " >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 71363, "code": " AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type", "label": 0}, {"snippet_id": 65464, "code": " ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">>", "label": 0}, {"snippet_id": 33910, "code": "\"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir", "label": 0}, {"snippet_id": 67652, "code": ".dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self,", "label": 0}, {"snippet_id": 21147, "code": ",'.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message='Timeout", "label": 0}, {"snippet_id": 44316, "code": "{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update", "label": 0}, {"snippet_id": 43913, "code": " rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set(", "label": 0}, {"snippet_id": 4135, "code": " from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as", "label": 0}, {"snippet_id": 94843, "code": "(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app", "label": 0}, {"snippet_id": 21266, "code": "\"^https://youtu\\.be\", x)] newer_links=[x for x in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print", "label": 0}, {"snippet_id": 69742, "code": " import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler", "label": 0}, {"snippet_id": 25521, "code": "() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state", "label": 0}, {"snippet_id": 36120, "code": ".touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input", "label": 0}, {"snippet_id": 91142, "code": ".python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements from pants.backend", "label": 0}, {"snippet_id": 81734, "code": ",datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y", "label": 0}, {"snippet_id": 65949, "code": " len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(", "label": 0}, {"snippet_id": 91069, "code": ": logger.warning('Multiple OS names alias to \"{}\"; combining results.'.format(rename)) normalized[rename].extend(paths) else: normalized[rename]=paths return normalized def _get_explicit_jdk_paths(self", "label": 0}, {"snippet_id": 72902, "code": " ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory", "label": 0}, {"snippet_id": 28816, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] ", "label": 0}, {"snippet_id": 7174, "code": "\"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords", "label": 0}, {"snippet_id": 80400, "code": " without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse", "label": 0}, {"snippet_id": 59605, "code": ") | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend", "label": 0}, {"snippet_id": 2749, "code": " stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.stop_remote_component", "label": 0}, {"snippet_id": 80416, "code": " Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: ", "label": 0}, {"snippet_id": 91717, "code": "(maybe_source_target, 'sources'): tgt_snapshot=maybe_source_target.sources.snapshot tgt_source_root=source_roots.find_by_path(maybe_source_target.address.spec_path) sources_snapshots_and_source_roots.append", "label": 0}, {"snippet_id": 91501, "code": ".backend.python.subsystems.python_setup import PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch) from pants.engine.isolated_process import", "label": 0}, {"snippet_id": 88129, "code": "!='plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return plugin_info.find('name').text if os.path.isdir(classpath_element): try", "label": 0}, {"snippet_id": 2280, "code": ") edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',", "label": 0}, {"snippet_id": 44605, "code": "())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info", "label": 0}, {"snippet_id": 84160, "code": " __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False)) return remote_metadata @staticmethod def __remote_work_dir_copy( lwr_client", "label": 0}, {"snippet_id": 29344, "code": " MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self", "label": 0}, {"snippet_id": 53493, "code": " def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input", "label": 0}, {"snippet_id": 30983, "code": " None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested", "label": 0}, {"snippet_id": 84046, "code": ".states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue", "label": 0}, {"snippet_id": 31547, "code": ".dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority", "label": 0}, {"snippet_id": 23362, "code": " from azurelinuxagent.common.osutil.default import DefaultOSUtil from azurelinuxagent.common.future import ustr class FreeBSDOSUtil(DefaultOSUtil): def __init__(self): super(FreeBSDOSUtil, self).__init__(", "label": 0}, {"snippet_id": 92806, "code": " 'test'), 'w', allowZip64=False) as zf: self.assertFalse(zf._allowZip64) def test_open_zip_raises_exception_on_falsey_paths(self): falsey=(None, '', False) for invalid in falsey: with self.assertRaises", "label": 0}, {"snippet_id": 68205, "code": ".view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__", "label": 1}, {"snippet_id": 81575, "code": " res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0", "label": 1}, {"snippet_id": 83994, "code": " with url %s and id %s\" %(lwr_url, job_id)) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck in the queued/running state", "label": 0}, {"snippet_id": 38977, "code": "\"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input)", "label": 0}, {"snippet_id": 19879, "code": ": raise RuntimeError('debugger not running') if self._session is not None: self._detach() try: self._adapter.close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self", "label": 0}, {"snippet_id": 45609, "code": " MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)", "label": 0}, {"snippet_id": 5875, "code": "(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default", "label": 0}, {"snippet_id": 63049, "code": ", \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination", "label": 0}, {"snippet_id": 83348, "code": " command_line: return try: dependencies_description=LwrJobRunner.__dependencies_description( client, job_wrapper) rewrite_paths=not LwrJobRunner.__rewrite_parameters( client) unstructured_path_rewrites=", "label": 0}, {"snippet_id": 50079, "code": " Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join", "label": 0}, {"snippet_id": 90934, "code": ": raise cls.Error('Problem locating a java distribution:{}'.format(e)) options_scope='jvm-distributions' @classmethod def register_options(cls, register): super(DistributionLocator, cls).register_options", "label": 0}, {"snippet_id": 38067, "code": "(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp ", "label": 0}, {"snippet_id": 11280, "code": " received from the URL. \"\"\" from datetime import datetime import logging import os import sys from docopt import docopt from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, ", "label": 0}, {"snippet_id": 42753, "code": "._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" ", "label": 0}, {"snippet_id": 12949, "code": "\"files\"]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs in data[\"diff\"].items(): if len(diffs) !=0: REQUEST_JSON[\"files\"", "label": 0}, {"snippet_id": 26219, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle'", "label": 0}, {"snippet_id": 38191, "code": " chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake", "label": 0}, {"snippet_id": 48011, "code": " branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if", "label": 0}, {"snippet_id": 3594, "code": " if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug", "label": 0}, {"snippet_id": 24860, "code": " self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle", "label": 0}, {"snippet_id": 57095, "code": " ctype=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',", "label": 0}, {"snippet_id": 92987, "code": ".stdout, sys.stderr, sys.stdin with self._stdio_as_tempfiles(): with self._stdio_as_tempfiles(): pass self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys", "label": 0}, {"snippet_id": 20396, "code": "(addr, timeout): sock=create_client() for _ in range(int(timeout * 10)): try: sock.connect(addr) except(OSError, socket.error): if cls.VERBOSE: print('+', end='') sys.stdout.flush() time.sleep(0.1) else", "label": 0}, {"snippet_id": 39992, "code": "\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property", "label": 0}, {"snippet_id": 36260, "code": " raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded", "label": 0}, {"snippet_id": 47104, "code": " output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not", "label": 0}, {"snippet_id": 57354, "code": ".'.format( field, getattr(t, field), TestCaseRunStatus.id_to_string(value), ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model, 'mail_scene')", "label": 0}, {"snippet_id": 21693, "code": " plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt", "label": 0}, {"snippet_id": 24756, "code": "='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data[", "label": 0}, {"snippet_id": 5477, "code": " return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,..", "label": 0}, {"snippet_id": 79285, "code": "\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e in extList: \t\t\t\ttmpExtList.append((e,getMime(extensions,e", "label": 0}, {"snippet_id": 86452, "code": ".utils import PY3, text_type from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import", "label": 0}, {"snippet_id": 3280, "code": ", color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger", "label": 0}, {"snippet_id": 85338, "code": ".scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.shader import Shader from pants.backend.jvm.targets.scala_jar_dependency import ScalaJarDependency from pants.backend.jvm.tasks.classpath_products", "label": 0}, {"snippet_id": 84420, "code": ".remote_version_path_rewrite(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path def output_paths( self): local_output_paths=self._wrapper_output_paths results", "label": 0}, {"snippet_id": 14995, "code": " method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest", "label": 0}, {"snippet_id": 16380, "code": "=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is", "label": 0}, {"snippet_id": 75613, "code": "): super().__init__('Worker was interrupted at runtime') class Suspend(Exception): '''Exception to raise on suspend signal''' def __init__(self, interval, *args, **kvargs): self.interval=interval super", "label": 0}, {"snippet_id": 84176, "code": "( lwr_client) @staticmethod def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via", "label": 0}, {"snippet_id": 1996, "code": "(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode(", "label": 0}, {"snippet_id": 15464, "code": "): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp", "label": 0}, {"snippet_id": 59117, "code": " the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()\t", "label": 0}, {"snippet_id": 62454, "code": "\"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has", "label": 0}, {"snippet_id": 85814, "code": ") all_extra_cp_entries=list(self._compiler_plugins_cp_entries()) if extra_cp_entries: all_extra_cp_entries.extend(extra_cp_entries) return ClasspathUtil.compute_classpath_entries(iter(dependencies), classpath_product", "label": 0}, {"snippet_id": 89331, "code": " import string_types from pants.base.revision import Revision from pants.java.util import execute_java, execute_java_async from pants.subsystem.subsystem import Subsystem from pants.util.contextutil import", "label": 0}, {"snippet_id": 71051, "code": " 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted", "label": 0}, {"snippet_id": 48555, "code": " concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e:", "label": 0}, {"snippet_id": 56749, "code": "(self): return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk) def case(self): return 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk) def run(self): return 'run/get_tag", "label": 0}, {"snippet_id": 92361, "code": ") with hermetic_environment_as(**{}): self.assertNotIn('USER', os.environ) def test_hermetic_environment_subprocesses(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**dict(AAA='333", "label": 1}, {"snippet_id": 72339, "code": " netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally: log.debug('(%s) networks", "label": 1}, {"snippet_id": 70233, "code": ".status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 59902, "code": " backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend", "label": 0}, {"snippet_id": 73445, "code": " file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output", "label": 0}, {"snippet_id": 52348, "code": ".add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input", "label": 0}, {"snippet_id": 50839, "code": " @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return", "label": 0}, {"snippet_id": 28661, "code": "['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3'", "label": 0}, {"snippet_id": 85916, "code": ".distribution import DistributionLocator from pants.util.dirutil import safe_open from pants.util.process_handler import subprocess _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin", "label": 0}, {"snippet_id": 55862, "code": "**kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return", "label": 0}, {"snippet_id": 13628, "code": "\texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\" 2>/dev/null\") time.sleep( 0.5)\r os.system( \"espeak -w speech.wav", "label": 1}, {"snippet_id": 71262, "code": ": flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\"", "label": 0}, {"snippet_id": 13443, "code": "{}\".format(data[\"new_branch\"]), \"base\": data[\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code", "label": 0}, {"snippet_id": 1888, "code": "[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem", "label": 0}, {"snippet_id": 66941, "code": " number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj(", "label": 0}, {"snippet_id": 10385, "code": " in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open", "label": 0}, {"snippet_id": 43583, "code": " __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain", "label": 0}, {"snippet_id": 52870, "code": " log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex)", "label": 0}, {"snippet_id": 62634, "code": " _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def", "label": 0}, {"snippet_id": 71972, "code": " worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s", "label": 1}, {"snippet_id": 75451, "code": ": return self.iden_reqid_map.get_values(iden) def make_reqid(self): while True: reqid=random.randint(1,(2**64)-1) if not reqid in self.response_handlers: return reqid def make_auth_req_data(self, interface", "label": 1}, {"snippet_id": 29860, "code": "\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given", "label": 0}, {"snippet_id": 27575, "code": ".type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data", "label": 0}, {"snippet_id": 24449, "code": "._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.", "label": 0}, {"snippet_id": 72957, "code": ", local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format", "label": 0}, {"snippet_id": 76871, "code": ": if isinstance(t, threading.Timer): t.cancel() logger.info('Exiting') def interrupt_handler(signal, frame): pass def terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler", "label": 0}, {"snippet_id": 94594, "code": " find_window(session, window_name): window=session.find_where({ \"window_name\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send", "label": 0}, {"snippet_id": 8901, "code": " with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name, output_mode=", "label": 0}, {"snippet_id": 46994, "code": "(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum", "label": 0}, {"snippet_id": 72946, "code": "(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total", "label": 0}, {"snippet_id": 44888, "code": " integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda", "label": 0}, {"snippet_id": 79786, "code": "=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote server where uploads are put. Example: '/tmp/uploads/", "label": 0}, {"snippet_id": 90444, "code": "=possible_environments @property def jvm_locations(self): return itertools.chain(*(pe.jvm_locations for pe in self._possible_environments)) class _Locator(object): class Error(Distribution.Error): \"\"\"Error", "label": 0}, {"snippet_id": 28782, "code": " data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" %", "label": 0}, {"snippet_id": 4166, "code": " output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False,", "label": 0}, {"snippet_id": 40570, "code": ", flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file", "label": 1}, {"snippet_id": 88066, "code": "=rel_classpath_elements or[classpath_element] if active_plugins.get(name, rel_classpath_elements) !=rel_classpath_elements: raise TaskError('Plugin{} defined in{} and in{}'.format(name, active_plugins[name]", "label": 0}, {"snippet_id": 76614, "code": "/signals' sig_sock=ctx.socket(zmq.PUB) sig_sock.bind(sig_addr) domains=set() targets=dict() protected=set() forums=dict() def message(): msg=[] msg.append('[image-original-none-http://simg4.gelbooru.com", "label": 0}, {"snippet_id": 20518, "code": "=recv_as_read(self._sock) for msg, _, _ in read_messages(read, stop=stop): if self.VERBOSE: print(repr(msg)) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection", "label": 0}, {"snippet_id": 83438, "code": ".job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination):", "label": 0}, {"snippet_id": 72147, "code": "\"%s\" for <seconds>.' % seconds) return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument('network') remote_parser.add_argument('--service", "label": 0}, {"snippet_id": 75963, "code": " auth_requests(self): for i, m in self.wz_auth_requests: def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Successfull auth for(%s, %s)', i, m) elif status", "label": 0}, {"snippet_id": 71663, "code": " CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions", "label": 0}, {"snippet_id": 47551, "code": ": if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__", "label": 0}, {"snippet_id": 17391, "code": ".poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr:", "label": 0}, {"snippet_id": 26526, "code": " data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity", "label": 0}, {"snippet_id": 87303, "code": " directory where zinc can store compiled copies of the `compiler-bridge`. The compiler-bridge is specific to each scala version, and is lazily computed by zinc if the appropriate version does not exist.", "label": 1}, {"snippet_id": 9136, "code": ", skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var", "label": 0}, {"snippet_id": 46470, "code": "(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"", "label": 0}, {"snippet_id": 95270, "code": " import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The path to create dirs/subdirs for :type path: str \"\"\" path=str(path)", "label": 1}, {"snippet_id": 32459, "code": " wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards):", "label": 0}, {"snippet_id": 37209, "code": " branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self)", "label": 0}, {"snippet_id": 45993, "code": " isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\")", "label": 1}, {"snippet_id": 64016, "code": " @staticmethod def __remote_work_dir_copy( lwr_client): return LwrJobRunner.__remote_metadata( lwr_client) @staticmethod def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use", "label": 0}, {"snippet_id": 75410, "code": " reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer): iden=self.iden_reqid_map.get_key(reqid) if seqnum==0: self.iden_reqid_map.del_value(iden, reqid) msg=list(iden) msg.append", "label": 0}, {"snippet_id": 76360, "code": " msg): msg.insert(0, b'') self.wz_sock.send_multipart(msg) def inter_sleep(self, timeout): self.sleep_ticker.tick() self.poll(timeout * 1000) while self.sleep_ticker.elapsed(False) < timeout: try: self", "label": 1}, {"snippet_id": 57117, "code": "(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field and value.') field=str(field) value, error=get_value_by_type", "label": 0}, {"snippet_id": 1940, "code": "'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess", "label": 0}, {"snippet_id": 21095, "code": "*awaitables): timeout=3.0 messages=[] for _ in range(int(timeout * 10)): time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()) for awaitable in", "label": 0}, {"snippet_id": 4376, "code": ", rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined into", "label": 1}, {"snippet_id": 63181, "code": ", job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if not command_line: return try", "label": 0}, {"snippet_id": 1836, "code": "[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor", "label": 0}, {"snippet_id": 79991, "code": "\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s", "label": 0}, {"snippet_id": 24012, "code": ".run_get_output(cmd_extract_id) \"\"\" try to search 'blkvscX' and 'storvscX' to find device name \"\"\" output=output.rstrip() cmd_search_blkvsc=\"camcontrol devlist -b | grep blkvsc{0} | awk '{{print $1}}'\"", "label": 0}, {"snippet_id": 83439, "code": ".job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"", "label": 0}, {"snippet_id": 11305, "code": ".readers import Header, read_config from monitoring_config_generator.yaml_tools.config import YamlConfig from monitoring_config_generator.settings import CONFIG EXIT_CODE_CONFIG_WRITTEN=0 EXIT_CODE_ERROR", "label": 0}, {"snippet_id": 86930, "code": " type=bool, default=True, help='When set, zinc will use sub-target incremental compilation, which dramatically ' 'improves compile performance while changing large targets. When unset, ' 'changed targets", "label": 0}, {"snippet_id": 75296, "code": " for %s,%s'%(interface, method)) if iden: self.iden_reqid_map.add_value(tuple(iden), reqid) handler(reqid, interface, method, msg[1:]) return() def _parse_rep(self, iden, msg, reqid, seqnum, status): try", "label": 0}, {"snippet_id": 5225, "code": ": str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse", "label": 0}, {"snippet_id": 22845, "code": " chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for{0}:{1}\".format(username, output) ) userentry=self.get_userentry('admin') if userentry is None: raise OSUtilError(\"The 'admin' user", "label": 0}, {"snippet_id": 19921, "code": ") raise NotImplementedError def attach_socket(self, addr=None, adapter=None, **kwargs): if self.closed: raise RuntimeError('debug client closed') if adapter is None: adapter=self._adapter elif self._adapter", "label": 0}, {"snippet_id": 61652, "code": " value.'.format(expectation.imag)) return expectation.real def reset(self): \"\"\"Reset the device\"\"\" self._state =None self._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a", "label": 0}, {"snippet_id": 32270, "code": ") except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards", "label": 0}, {"snippet_id": 62649, "code": "[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and", "label": 0}, {"snippet_id": 39279, "code": " self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self", "label": 0}, {"snippet_id": 80276, "code": ".verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy", "label": 0}, {"snippet_id": 79682, "code": "\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help", "label": 0}, {"snippet_id": 39173, "code": " in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag", "label": 0}, {"snippet_id": 11174, "code": " def parse(file_name): etag, mtime=None, 0 def extract(comment, current_value): value=None if line.startswith(comment): value=line.rstrip()[len(comment):] return value or current_value try: with open(file_name", "label": 0}, {"snippet_id": 4974, "code": "'BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author", "label": 0}, {"snippet_id": 91591, "code": " PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest, python_setup, source_root_config): \"\"\"Runs pytest for one target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download/v1", "label": 1}, {"snippet_id": 42240, "code": "\"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format(", "label": 0}, {"snippet_id": 64517, "code": " import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes", "label": 0}, {"snippet_id": 26161, "code": "=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None],", "label": 1}, {"snippet_id": 68363, "code": " for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers", "label": 0}, {"snippet_id": 28786, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 14978, "code": "=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests", "label": 0}, {"snippet_id": 29907, "code": "] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items", "label": 0}, {"snippet_id": 81954, "code": " parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete", "label": 0}, {"snippet_id": 3495, "code": "(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self.logger.info(\"There is no component running by the name '%s'. Exiting kill mode\" % self", "label": 0}, {"snippet_id": 72202, "code": " others are dropped due to protocol limitations.\"\"\" permissions.checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args(args) netname=args.network if netname==irc.name: irc.error", "label": 0}, {"snippet_id": 40946, "code": " def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist", "label": 0}, {"snippet_id": 14574, "code": "._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit(", "label": 0}, {"snippet_id": 69681, "code": " been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT", "label": 0}, {"snippet_id": 88927, "code": "*kwargs): \"\"\"Creates a new target, adds it to the context and returns it. This method ensures the target resolves files against the given target_base, creating the directory if needed and registering a", "label": 0}, {"snippet_id": 27373, "code": ".get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning", "label": 0}, {"snippet_id": 4641, "code": " extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty", "label": 0}, {"snippet_id": 20107, "code": "._session if session is None: return self._session=None try: session.close() except ClosedError: pass class DebugClient(_LifecycleClient): \"\"\"A high-level abstraction of a debug client(i.e. editor).\"\"\"", "label": 0}, {"snippet_id": 15524, "code": " self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable(", "label": 0}, {"snippet_id": 6902, "code": "], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return", "label": 0}, {"snippet_id": 43609, "code": " attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, ", "label": 0}, {"snippet_id": 86058, "code": " False return target.has_sources('.java') def select_source(self, source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath(self.context", "label": 0}, {"snippet_id": 20025, "code": " self._adapter is not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not", "label": 0}, {"snippet_id": 54267, "code": " bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen", "label": 0}, {"snippet_id": 8426, "code": " communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line)", "label": 1}, {"snippet_id": 26948, "code": "% data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self", "label": 0}, {"snippet_id": 72547, "code": ". It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser", "label": 0}, {"snippet_id": 87472, "code": " zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala-path', ':'.join(scala_path)]) zinc_args.extend(self._javac_plugin_args(javac_plugin_map)) scalac_plugin_search_classpath", "label": 1}, {"snippet_id": 24762, "code": " elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0", "label": 0}, {"snippet_id": 84435, "code": " local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite( wrapper_path) results.append( self._dataset_path( local_output_path, remote_path)) return results def", "label": 0}, {"snippet_id": 19659, "code": ".add_argument('--port', type=int, required=True) target=parser.add_mutually_exclusive_group(required=True) target.add_argument('-m', dest='module') target.add_argument('filename', nargs='?') parser.add_argument(", "label": 0}, {"snippet_id": 14036, "code": " include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column,", "label": 0}, {"snippet_id": 46690, "code": " raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or", "label": 0}, {"snippet_id": 20102, "code": "): session=self._session if session is None: return self._session=None try: session.close() except ClosedError: pass class DebugClient(_LifecycleClient): \"\"\"A high-level abstraction of a debug client(i", "label": 0}, {"snippet_id": 59309, "code": "(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit). user(string", "label": 0}, {"snippet_id": 11843, "code": " GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get('X-Hub-Signature') if header_signature is None: abort(403) sha_name, signature=header_signature.split('", "label": 0}, {"snippet_id": 22938, "code": " remove that method call as well. :param username: :return: \"\"\" shellutil.run(\"> /var/run/utmp\") shellutil.run(\"/usr/bin/tmsh delete auth user \" +username) def get_dvd_device(self, dev_dir='/dev'): \"\"\"Find", "label": 0}, {"snippet_id": 74462, "code": " FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\" password=\"\" use_tls=False directory=\"\" files=[]", "label": 0}, {"snippet_id": 15289, "code": " def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self", "label": 1}, {"snippet_id": 49751, "code": ".target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup", "label": 0}, {"snippet_id": 76463, "code": " as e: self.log.warn(e) def run(self): self.__sinit__() if self.start_timer: self.inter_sleep(self.start_timer) if self.running: self.log.info('Starting') try: self.child=self.call[0](*self.call[1], **self", "label": 0}, {"snippet_id": 32899, "code": "(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict()", "label": 0}, {"snippet_id": 8915, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract", "label": 1}, {"snippet_id": 28445, "code": " module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property", "label": 0}, {"snippet_id": 91526, "code": ".engine.legacy.graph import BuildFileAddresses, TransitiveHydratedTargets from pants.engine.legacy.structs import PythonTestsAdaptor from pants.engine.rules import UnionRule, optionable_rule, rule from pants", "label": 0}, {"snippet_id": 3091, "code": "] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host", "label": 0}, {"snippet_id": 74271, "code": " of the configuration file, existing configuration dictionary Returns: a dictionary of the form <dict>.<section>[<option>] and the corresponding values. \"\"\" config=ConfigurationRepresentation(location)", "label": 0}, {"snippet_id": 44191, "code": "=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata", "label": 0}, {"snippet_id": 26012, "code": "._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=", "label": 0}, {"snippet_id": 94467, "code": "\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified", "label": 0}, {"snippet_id": 75007, "code": " os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location", "label": 0}, {"snippet_id": 83754, "code": "( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper", "label": 0}, {"snippet_id": 81413, "code": "\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions", "label": 0}, {"snippet_id": 35028, "code": " others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f", "label": 0}, {"snippet_id": 33550, "code": " os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the", "label": 0}, {"snippet_id": 61607, "code": " current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem Returns: float: expectation value:math:`\\expect{A}=\\bra{\\psi}A\\ket{\\psi}` \"\"\"", "label": 0}, {"snippet_id": 7490, "code": " } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output", "label": 0}, {"snippet_id": 91986, "code": " PythonSetup.global_instance() def pydist_has_native_sources(self, target): return target.has_sources(extension=tuple(self._native_source_extensions)) @memoized_property def _native_target_matchers(self): return{", "label": 0}, {"snippet_id": 7131, "code": " for s in style: if s !=\"raw\": my_styles[s]=functions[s](complete_output, categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches", "label": 0}, {"snippet_id": 45141, "code": " *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate", "label": 0}, {"snippet_id": 81358, "code": "\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self", "label": 0}, {"snippet_id": 39289, "code": " return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd", "label": 0}, {"snippet_id": 89928, "code": " older than' '{} and got{}'.format(java, self._maximum_version, version)) self._bin_path=os.path.join(self.home, 'bin') try: self._validated_executable('javac') self._is_jdk=True except self.Error as e", "label": 0}, {"snippet_id": 27534, "code": " self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data[", "label": 0}, {"snippet_id": 32997, "code": " add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used", "label": 0}, {"snippet_id": 94557, "code": " for p in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window", "label": 0}, {"snippet_id": 3285, "code": " SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging", "label": 0}, {"snippet_id": 22977, "code": " first device found, but in my tests with 12.1.1 it will also find /dev/sr0 on occasion. This is NOT the correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device", "label": 0}, {"snippet_id": 34627, "code": " self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def", "label": 1}, {"snippet_id": 11101, "code": " None and self.mtime is 0 def __eq__(self, other): return self.etag==other.etag and self.mtime==other.mtime def __repr__(self): return \"Header(%s, %d)\" %(self.etag, self.mtime) def is_newer_than(self, other", "label": 0}, {"snippet_id": 33784, "code": "\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats(", "label": 0}, {"snippet_id": 53094, "code": " s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join", "label": 0}, {"snippet_id": 55904, "code": " def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources", "label": 0}, {"snippet_id": 59622, "code": "\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': for qubit in self.reg: self.eng.deallocate_qubit(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate", "label": 0}, {"snippet_id": 41820, "code": "\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark", "label": 0}, {"snippet_id": 27618, "code": " data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\"", "label": 0}, {"snippet_id": 86388, "code": ", '.class'), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd), input_files=input_snapshot.directory_digest", "label": 0}, {"snippet_id": 52700, "code": "(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected", "label": 0}, {"snippet_id": 18380, "code": "+str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash", "label": 0}, {"snippet_id": 86008, "code": "(JavacCompile, cls).register_options(register) @classmethod def subsystem_dependencies(cls): return super(JavacCompile, cls).subsystem_dependencies() +(JvmPlatform,) @classmethod def prepare(cls, options,", "label": 0}, {"snippet_id": 90464, "code": " __init__(self, distribution_environment, minimum_version=None, maximum_version=None): self._cache={} self._distribution_environment=distribution_environment self._minimum_version=minimum_version self._maximum_version", "label": 0}, {"snippet_id": 93462, "code": "\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference", "label": 0}, {"snippet_id": 68600, "code": " def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled", "label": 0}, {"snippet_id": 34504, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools", "label": 0}, {"snippet_id": 53441, "code": ".items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return", "label": 0}, {"snippet_id": 45845, "code": " in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{", "label": 0}, {"snippet_id": 54852, "code": "=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False", "label": 0}, {"snippet_id": 17914, "code": ")) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync(", "label": 0}, {"snippet_id": 84381, "code": " self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client,", "label": 0}, {"snippet_id": 29284, "code": " os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root,", "label": 0}, {"snippet_id": 45451, "code": "): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self", "label": 1}, {"snippet_id": 82469, "code": ".n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not-regex or with -", "label": 0}, {"snippet_id": 76043, "code": ": self.log.debug('Binding %s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s", "label": 0}, {"snippet_id": 58102, "code": ": run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs(p_pks, target): \"\"\" Get Component, Version, Category, and Build\\n Return[(id", "label": 0}, {"snippet_id": 9809, "code": "(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted", "label": 0}, {"snippet_id": 81059, "code": ") \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself", "label": 0}, {"snippet_id": 63449, "code": "=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id,", "label": 0}, {"snippet_id": 51643, "code": "{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns", "label": 0}, {"snippet_id": 63411, "code": "=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command", "label": 0}, {"snippet_id": 17880, "code": " self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync", "label": 0}, {"snippet_id": 24266, "code": " 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None", "label": 0}, {"snippet_id": 88971, "code": ") if dependencies: dependencies=[dep.address for dep in dependencies] self.build_graph.inject_synthetic_target(address=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from", "label": 0}, {"snippet_id": 80445, "code": "[*] starting at \"+str(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions", "label": 0}, {"snippet_id": 63369, "code": " self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure", "label": 1}, {"snippet_id": 82528, "code": " |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the", "label": 0}, {"snippet_id": 22649, "code": "=None): \"\"\"Create user account using tmsh Our policy is to create two accounts when booting a BIG-IP instance. The first account is the one that the user specified when they did the instance creation. The", "label": 1}, {"snippet_id": 90951, "code": ".register_options(register) human_readable_os_aliases=', '.join('{}:[{}]'.format(str(key), ', '.join(sorted(val))) for key, val in OS_ALIASES.items()) register('--paths', advanced=True, type=dict, help='Map", "label": 0}, {"snippet_id": 32500, "code": ") benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards", "label": 0}, {"snippet_id": 6982, "code": "<keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v", "label": 0}, {"snippet_id": 65587, "code": ".nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view", "label": 0}, {"snippet_id": 30800, "code": ".message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex", "label": 0}, {"snippet_id": 998, "code": "[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username", "label": 0}, {"snippet_id": 32772, "code": " import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from", "label": 0}, {"snippet_id": 56275, "code": ".testruns.models import TestRun, TestCaseRun, TestCaseRunStatus, TestRunTag from tcms.core.helpers.comments import add_comment from tcms.core.utils.validations import validate_bug_id def check_permission", "label": 0}, {"snippet_id": 62401, "code": "(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self", "label": 0}, {"snippet_id": 72576, "code": " benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\", metavar=\"RUN_LABEL\", help=\"Label for the benchmark run.\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help", "label": 1}, {"snippet_id": 70123, "code": " target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node", "label": 0}, {"snippet_id": 78223, "code": "(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self): for t in self.targets: self.schedule(self.add_comment,(t, self.msgfun())) if len", "label": 0}, {"snippet_id": 82912, "code": " techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t", "label": 1}, {"snippet_id": 39, "code": " BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager", "label": 1}, {"snippet_id": 46408, "code": " fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index", "label": 0}, {"snippet_id": 5052, "code": " code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code", "label": 0}, {"snippet_id": 21706, "code": "=j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt.title('Classifier(Training set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib", "label": 0}, {"snippet_id": 31707, "code": "=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=", "label": 1}, {"snippet_id": 80469, "code": ".lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt: \t\t\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be", "label": 0}, {"snippet_id": 56680, "code": "(tag) context_data={ 'tags': all_tags, 'object': obj, } return render(request, template_name, context_data) class _TagObjects(object): \"\"\" Used for getting the chosen object(TestPlan, TestCase or TestRun", "label": 0}, {"snippet_id": 95076, "code": "==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode)", "label": 0}, {"snippet_id": 81029, "code": "\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server", "label": 0}, {"snippet_id": 54435, "code": " attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, ", "label": 0}, {"snippet_id": 4368, "code": "=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"", "label": 1}, {"snippet_id": 44684, "code": ") snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included", "label": 0}, {"snippet_id": 20093, "code": ".host=='localhost' self._session=self.SESSION.create_client(addr, **kwargs) def _detach(self): session=self._session if session is None: return self._session=None try: session.close() except ClosedError:", "label": 0}, {"snippet_id": 4356, "code": "=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig", "label": 0}, {"snippet_id": 21344, "code": ".add_argument('mpv', nargs=ap.REMAINDER, help='Arguments to pass to `mpv`.') args=parser.parse_args() subreddit=args.subreddit depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/", "label": 1}, {"snippet_id": 20542, "code": "(): return self.closed write=send_as_write(self._sock) body=json.dumps(req) write_message(write, body, stop=stop) def _close(self): if self._ownsock: close(self._sock) class DebugSession(Closeable): VERBOSE", "label": 0}, {"snippet_id": 40530, "code": " str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value", "label": 0}, {"snippet_id": 12894, "code": ") stdout, _=proc.communicate() data[\"diff\"][filename]=stdout.decode(r.encoding) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename", "label": 0}, {"snippet_id": 95088, "code": " overwrite=overwrite_mode) elif command==\"setup\": print(\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config", "label": 1}, {"snippet_id": 72479, "code": ".debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required", "label": 0}, {"snippet_id": 18700, "code": "{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n ", "label": 0}, {"snippet_id": 89451, "code": " has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception): \"\"\"Indicates an invalid java", "label": 0}, {"snippet_id": 73428, "code": "*/*.vcf\") for path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str", "label": 0}, {"snippet_id": 11904, "code": "-3:]=='.py': pythonic=True break return pythonic def get_config(data): \"\"\" Get.pep8speaks.yml config file from the repository and return the config dictionary \"\"\" config={ \"message\":{ \"opened\":{ \"header", "label": 0}, {"snippet_id": 67394, "code": ") rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg", "label": 1}, {"snippet_id": 26714, "code": "._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000", "label": 0}, {"snippet_id": 86014, "code": "(JavacCompile, cls).subsystem_dependencies() +(JvmPlatform,) @classmethod def prepare(cls, options, round_manager): super(JavacCompile, cls).prepare(options, round_manager) @classmethod def product_types(cls):", "label": 0}, {"snippet_id": 46265, "code": " first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name", "label": 0}, {"snippet_id": 57781, "code": " integer.') plan=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets=self.get_update_targets() offset=0 step_length=500 queryset_filter", "label": 0}, {"snippet_id": 88825, "code": " the calling thread's current workunit. :API: public \"\"\" with self.run_tracker.new_workunit(name=name, labels=labels, cmd=cmd, log_config=log_config) as workunit: yield workunit def acquire_lock(self): \"\"", "label": 0}, {"snippet_id": 42771, "code": " any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same", "label": 0}, {"snippet_id": 60241, "code": "'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the", "label": 0}, {"snippet_id": 5653, "code": "]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify", "label": 0}, {"snippet_id": 46694, "code": " YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a", "label": 0}, {"snippet_id": 14783, "code": "=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def", "label": 0}, {"snippet_id": 73052, "code": "+remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP] Created local folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format", "label": 0}, {"snippet_id": 39927, "code": "=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException,", "label": 1}, {"snippet_id": 60262, "code": " cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"", "label": 0}, {"snippet_id": 42754, "code": ", output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files", "label": 0}, {"snippet_id": 6169, "code": "\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text", "label": 1}, {"snippet_id": 35009, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append", "label": 0}, {"snippet_id": 15028, "code": " BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport", "label": 0}, {"snippet_id": 61434, "code": " operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError('State", "label": 0}, {"snippet_id": 28790, "code": "] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0", "label": 0}, {"snippet_id": 29982, "code": " arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\"", "label": 0}, {"snippet_id": 26014, "code": "'wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status", "label": 0}, {"snippet_id": 48419, "code": " callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self", "label": 0}, {"snippet_id": 86676, "code": " else 1 log.warn(\"Zinc argument '{}' is not supported, and is subject to change/removal!\".format(arg)) return 1 arg_index=0 while arg_index < len(args): arg_index +=validate(arg_index) @staticmethod def", "label": 0}, {"snippet_id": 50111, "code": "{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd", "label": 0}, {"snippet_id": 27777, "code": "\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 75032, "code": " sup.ticker import Ticker class EvaluatorProxy: def __init__(self, ev_init, *args, **kvargs): super().__init__() self.ev_init=ev_init self.bind_kt_ticker=Ticker() self.bind_kt=5 def handle_evaluate(self,", "label": 0}, {"snippet_id": 84421, "code": ".remote_version_path_rewrite(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path def output_paths( self): local_output_paths=self._wrapper_output_paths results=[]", "label": 0}, {"snippet_id": 36231, "code": ".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError", "label": 0}, {"snippet_id": 52858, "code": ".output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables", "label": 0}, {"snippet_id": 20747, "code": ", **kwargs) @contextlib.contextmanager def wait_for_event(self, event, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type", "label": 0}, {"snippet_id": 65724, "code": "=RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], ", "label": 0}, {"snippet_id": 16004, "code": ": return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666", "label": 0}, {"snippet_id": 53156, "code": " snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name", "label": 0}, {"snippet_id": 72137, "code": ".error('No such network \"%s\"(case sensitive).' % netname) return except ValueError: irc.error('Invalid argument \"%s\" for <seconds>.' % seconds) return network.serverdata['autoconnect']=seconds irc.reply", "label": 0}, {"snippet_id": 46883, "code": " for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input", "label": 0}, {"snippet_id": 10854, "code": " in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available", "label": 1}, {"snippet_id": 63386, "code": " job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '') return command_line, client, remote_job_config, compute_environment def", "label": 0}, {"snippet_id": 6578, "code": " process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False", "label": 0}, {"snippet_id": 162, "code": " encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in", "label": 1}, {"snippet_id": 45640, "code": ".dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None:", "label": 1}, {"snippet_id": 27422, "code": ", SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self", "label": 0}, {"snippet_id": 91503, "code": " PythonSetup from pants.engine.fs import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch) from pants.engine.isolated_process import(ExecuteProcessRequest, ExecuteProcessResult", "label": 0}, {"snippet_id": 11009, "code": " '%s', error: %s\" %(url, e) raise MonitoringConfigGeneratorException(msg) def get_from_header(field): return response.headers[field] if field in response.headers else None if response.status_code==200:", "label": 0}, {"snippet_id": 43776, "code": " return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output", "label": 0}, {"snippet_id": 50137, "code": "(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack", "label": 0}, {"snippet_id": 38288, "code": " self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname", "label": 0}, {"snippet_id": 59328, "code": " the end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to", "label": 0}, {"snippet_id": 70616, "code": " status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR}", "label": 0}, {"snippet_id": 35227, "code": " mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule", "label": 0}, {"snippet_id": 81153, "code": ".uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No", "label": 0}, {"snippet_id": 90703, "code": " java distribution that meets any given constraints and returns it. :param minimum_version: minimum jvm version to look for(eg, 1.7). :param maximum_version: maximum jvm version to look for(eg, 1.7.9999", "label": 0}, {"snippet_id": 44421, "code": "() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary", "label": 0}, {"snippet_id": 73595, "code": "=Blosc(cname=conversion_config.blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor", "label": 0}, {"snippet_id": 12947, "code": "\"public\"]=True REQUEST_JSON[\"files\"]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs in data[\"diff\"].items(): if len(diffs) !", "label": 0}, {"snippet_id": 34844, "code": ".search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self", "label": 0}, {"snippet_id": 73880, "code": ", \"zlib\", \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation", "label": 0}, {"snippet_id": 27514, "code": "\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=", "label": 0}, {"snippet_id": 46163, "code": " def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return", "label": 0}, {"snippet_id": 42005, "code": "(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow", "label": 0}, {"snippet_id": 3615, "code": "=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\"", "label": 1}, {"snippet_id": 12988, "code": "\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url", "label": 0}, {"snippet_id": 32206, "code": ": raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in", "label": 0}, {"snippet_id": 67244, "code": "(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS", "label": 1}, {"snippet_id": 38317, "code": ".included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config", "label": 0}, {"snippet_id": 82789, "code": " else: \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime", "label": 0}, {"snippet_id": 20616, "code": "=(), timeout=None, owned=False): super(DebugSession, self).__init__() self._conn=conn self._seq=seq self._timeout=timeout self._owned=owned self._handlers=[] for handler in handlers: if callable(handler", "label": 0}, {"snippet_id": 91099, "code": ".lower()) if os_name not in self._normalized_jdk_paths: logger.warning('--jvm-distributions-paths was specified, but has no entry for \"{}\".' .format(os_name)) return self._normalized_jdk_paths.get(os_name", "label": 0}, {"snippet_id": 48675, "code": " input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards", "label": 0}, {"snippet_id": 90907, "code": " to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" try: return cls.global_instance()._locator", "label": 0}, {"snippet_id": 78884, "code": "\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status", "label": 0}, {"snippet_id": 497, "code": " in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output", "label": 0}, {"snippet_id": 46316, "code": " dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list)", "label": 0}, {"snippet_id": 27756, "code": " elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0", "label": 0}, {"snippet_id": 9520, "code": "'BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author", "label": 0}, {"snippet_id": 53491, "code": " rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files", "label": 0}, {"snippet_id": 94320, "code": " by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self", "label": 0}, {"snippet_id": 53070, "code": ": s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self", "label": 0}, {"snippet_id": 73089, "code": " if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list", "label": 0}, {"snippet_id": 19360, "code": " import argparse import os.path import sys from ptvsd._local import debug_main, run_main from ptvsd.socket import Address from ptvsd.version import __version__, __author__ \"\"\" For the PyDevd CLI handling see", "label": 0}, {"snippet_id": 44180, "code": " ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag,", "label": 0}, {"snippet_id": 23809, "code": "{0}'.format(timeout)) if ret: raise OSUtilError(\"Failed set SCSI disks timeout:{0}\".format(output)) self._scsi_disks_timeout_set=True def check_pid_alive(self, pid): return shellutil.run('ps -p{0}'.format", "label": 0}, {"snippet_id": 45544, "code": " os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self", "label": 0}, {"snippet_id": 36110, "code": "(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self", "label": 0}, {"snippet_id": 25347, "code": " pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found',", "label": 1}, {"snippet_id": 35081, "code": ") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing:", "label": 0}, {"snippet_id": 3842, "code": ".isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__", "label": 0}, {"snippet_id": 25080, "code": ".update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth", "label": 1}, {"snippet_id": 96074, "code": "\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length, chunk_width=chunk_width) print(\"[VCF-Zarr", "label": 1}, {"snippet_id": 26870, "code": " self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state", "label": 0}, {"snippet_id": 42158, "code": ".rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"", "label": 0}, {"snippet_id": 18604, "code": " OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self", "label": 0}, {"snippet_id": 90763, "code": "=maximum_version, jdk=jdk) dist.validate() logger.debug('Located{} for constraints: minimum_version{}, maximum_version{}, jdk{}' .format(dist, minimum_version, maximum_version, jdk)) return dist except", "label": 0}, {"snippet_id": 13446, "code": "(data[\"new_branch\"]), \"base\": data[\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code==201: data[", "label": 0}, {"snippet_id": 58331, "code": " test_urls_for_emails_with_pluses(self): self.client.login( username=self.user.username, password='testing') response=self.client.get(reverse('iframe-navigation')) self.assertContains(response, urlencode({'people': self.user.email})", "label": 0}, {"snippet_id": 10166, "code": ": return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]", "label": 0}, {"snippet_id": 68645, "code": ": status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status", "label": 0}, {"snippet_id": 70525, "code": ".EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node,", "label": 0}, {"snippet_id": 61611, "code": " Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int]): target subsystem Returns: float: expectation value:math:`\\expect{A}=\\bra{\\psi}A\\ket{\\psi}` \"\"\" if A.shape !=(2,", "label": 0}, {"snippet_id": 63282, "code": ".job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination):", "label": 0}, {"snippet_id": 54464, "code": ".dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards,", "label": 1}, {"snippet_id": 25389, "code": ".keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True", "label": 0}, {"snippet_id": 61676, "code": " a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(2, 2): raise ValueError('2x2 matrix", "label": 0}, {"snippet_id": 47252, "code": "() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None", "label": 0}, {"snippet_id": 39677, "code": " threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources", "label": 0}, {"snippet_id": 26091, "code": " the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data", "label": 1}, {"snippet_id": 57173, "code": " not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field %s changed", "label": 0}, {"snippet_id": 87685, "code": ", Zinc.ZINC_COMPILE_MAIN] +zinc_args) req=ExecuteProcessRequest( argv=argv, input_files=merged_input_digest, output_files=(analysis_cache,), output_directories=(classes_dir,), description=\"zinc compile", "label": 0}, {"snippet_id": 88979, "code": " in dependencies] self.build_graph.inject_synthetic_target(address=address, target_type=target_type, dependencies=dependencies, derived_from=derived_from, **kwargs) new_target=self.build_graph.get_target", "label": 0}, {"snippet_id": 14959, "code": " handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff", "label": 1}, {"snippet_id": 25280, "code": " None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi',", "label": 1}, {"snippet_id": 71897, "code": ".targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath]", "label": 0}, {"snippet_id": 28421, "code": " SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type]", "label": 0}, {"snippet_id": 3812, "code": " cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\"", "label": 0}, {"snippet_id": 10806, "code": "=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\"", "label": 1}, {"snippet_id": 31259, "code": " res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local", "label": 0}, {"snippet_id": 56342, "code": "'product_id')) info_type=getattr(objects, request.GET.get('info_type')) if not info_type: return HttpResponse('Unrecognizable info-type') if request.GET.get('format')=='ulli': field=request.GET.get('field',", "label": 0}, {"snippet_id": 77814, "code": ".inter_sleep self.running=parent.running self.p.sig_sock.setsockopt(zmq.SUBSCRIBE, b'WipeManager') self.p.wz.set_sig_handler(b'WipeManager', b'passthrough', self.send_passthrough) if self.c.tcount > 0:", "label": 0}, {"snippet_id": 56489, "code": ", 'field', 'format')) return User.objects.filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most", "label": 1}, {"snippet_id": 84717, "code": "( argv=cmd, input_files=directory_digest, output_files=('ignored', 'report'), description='cloc', ) exec_result=self.context.execute_process_synchronously(req, 'cloc',(WorkUnitLabel.TOOL,)) files_content_tuple", "label": 1}, {"snippet_id": 83938, "code": " log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug", "label": 0}, {"snippet_id": 49123, "code": "() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self", "label": 0}, {"snippet_id": 668, "code": "], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print", "label": 0}, {"snippet_id": 37869, "code": " _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f", "label": 0}, {"snippet_id": 37401, "code": " a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item", "label": 0}, {"snippet_id": 44571, "code": "(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job", "label": 0}, {"snippet_id": 43960, "code": ", touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False", "label": 0}, {"snippet_id": 57487, "code": " self.ctype) if not has_perms: return say_no(\"You don't have enough permission to update TestCases.\") action=self.get_update_action() if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist", "label": 0}, {"snippet_id": 78737, "code": "( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson", "label": 0}, {"snippet_id": 66593, "code": " ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import *", "label": 0}, {"snippet_id": 64486, "code": "] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if", "label": 0}, {"snippet_id": 38600, "code": ", list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata", "label": 0}, {"snippet_id": 20741, "code": " raise RuntimeError('session closed') self._add_handler(handler, **kwargs) @contextlib.contextmanager def wait_for_event(self, event, **kwargs): if self.closed: raise RuntimeError('session closed') result={", "label": 0}, {"snippet_id": 39855, "code": " is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag", "label": 0}, {"snippet_id": 19748, "code": " module is None: args.name=filename args.kind='script' else: args.name=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs): if nodebug: run_main(addr, name", "label": 0}, {"snippet_id": 33372, "code": " summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init", "label": 0}, {"snippet_id": 72935, "code": " in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary", "label": 0}, {"snippet_id": 90507, "code": " look for(eg, 1.7.9999). :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None if no matching distribution is in the cache. :rtype::class:`pants", "label": 0}, {"snippet_id": 20739, "code": ".closed: raise RuntimeError('session closed') self._add_handler(handler, **kwargs) @contextlib.contextmanager def wait_for_event(self, event, **kwargs): if self.closed: raise RuntimeError('session closed'", "label": 0}, {"snippet_id": 91816, "code": "=0 else Status.FAILURE yield TestResult( status=status, stdout=result.stdout.decode('utf-8'), stderr=result.stderr.decode('utf-8'), ) def rules(): return[ run_python_test, UnionRule(TestTarget, PythonTestsAdaptor", "label": 0}, {"snippet_id": 38370, "code": ": return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() )", "label": 0}, {"snippet_id": 13417, "code": " headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/pulls\" url=url.format(data[\"target_repo_fullname", "label": 0}, {"snippet_id": 27574, "code": "'sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl':", "label": 0}, {"snippet_id": 43619, "code": " snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG", "label": 0}, {"snippet_id": 13088, "code": " auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.post(url, headers=headers, auth=auth) if r.status_code==202: data[\"fork_fullname\"]=r.json()[\"full_name\"] FORKED=True else: data", "label": 0}, {"snippet_id": 29102, "code": "\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError", "label": 1}, {"snippet_id": 37098, "code": "): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for", "label": 0}, {"snippet_id": 90386, "code": " in os.listdir(java_dist_dir): home=os.path.join(java_dist_dir, path) if os.path.isdir(home): yield self.Location.from_home(home) class _ExplicitEnvironment(_DistributionEnvironment): def __init__(self,", "label": 0}, {"snippet_id": 65672, "code": " disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"]", "label": 1}, {"snippet_id": 79567, "code": "=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t", "label": 0}, {"snippet_id": 56096, "code": " self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join", "label": 0}, {"snippet_id": 42293, "code": "\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp,", "label": 0}, {"snippet_id": 6338, "code": " main methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for", "label": 0}, {"snippet_id": 41525, "code": ".rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input", "label": 0}, {"snippet_id": 7394, "code": ".append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None,", "label": 0}, {"snippet_id": 34821, "code": "(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self)", "label": 0}, {"snippet_id": 35292, "code": " wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default)", "label": 0}, {"snippet_id": 32501, "code": "=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in", "label": 0}, {"snippet_id": 38397, "code": " for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add", "label": 0}, {"snippet_id": 10758, "code": ".1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float", "label": 1}, {"snippet_id": 42672, "code": " set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name", "label": 0}, {"snippet_id": 57947, "code": " failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data={} try: data['bugs']=request.GET.get('bug_id', '').split(',') data['runs']=map(int, request.GET.get('case_runs', '').split(',')) except(TypeError,", "label": 0}, {"snippet_id": 87496, "code": ") zinc_args.extend(self._scalac_plugin_args(scalac_plugin_map, scalac_plugin_search_classpath)) if upstream_analysis: zinc_args.extend(['-analysis-map', ','.join('{}:{}'.format( relative_to_exec_root(k", "label": 0}, {"snippet_id": 90962, "code": "))) for key, val in OS_ALIASES.items()) register('--paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME", "label": 0}, {"snippet_id": 16550, "code": " extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse", "label": 0}, {"snippet_id": 14737, "code": "): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 88097, "code": " TaskError('Could not find requested plugins:{}'.format(list(unresolved_plugins))) @classmethod @memoized_method def _maybe_get_plugin_name(cls, classpath_element): \"\"\"If classpath_element is a scalac plugin,", "label": 0}, {"snippet_id": 88995, "code": "(address) return new_target def targets(self, predicate=None, **kwargs): \"\"\"Selects targets in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets", "label": 0}, {"snippet_id": 70, "code": " your Titania os(in lowercase). \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"", "label": 0}, {"snippet_id": 22659, "code": " when booting a BIG-IP instance. The first account is the one that the user specified when they did the instance creation. The second one is the admin account that is, or should be, built in to the system", "label": 0}, {"snippet_id": 24920, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle']", "label": 0}, {"snippet_id": 1568, "code": "=='saveUserDetails': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username", "label": 0}, {"snippet_id": 35371, "code": " in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards ", "label": 0}, {"snippet_id": 50592, "code": ") @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message", "label": 0}, {"snippet_id": 44186, "code": " ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 16421, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid", "label": 0}, {"snippet_id": 16098, "code": " _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except", "label": 1}, {"snippet_id": 32400, "code": "( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException(", "label": 0}, {"snippet_id": 84465, "code": " results.append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path", "label": 0}, {"snippet_id": 49679, "code": " following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be", "label": 0}, {"snippet_id": 73011, "code": " downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list \"\"\" if(remote_subdirs_list", "label": 0}, {"snippet_id": 47989, "code": " in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old", "label": 0}, {"snippet_id": 54627, "code": ".contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def", "label": 0}, {"snippet_id": 38952, "code": ") if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but", "label": 0}, {"snippet_id": 56099, "code": ".path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths),", "label": 0}, {"snippet_id": 17856, "code": " ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 56553, "code": "('tcms.%s.forms' % q_app) q_app_module=sys.modules['tcms.%s.forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format", "label": 1}, {"snippet_id": 42076, "code": " properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items(", "label": 0}, {"snippet_id": 15868, "code": " ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass", "label": 0}, {"snippet_id": 46201, "code": " values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists ", "label": 0}, {"snippet_id": 6804, "code": " composite_keywords=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords,", "label": 0}, {"snippet_id": 9957, "code": " expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the", "label": 0}, {"snippet_id": 33598, "code": " True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\"", "label": 0}, {"snippet_id": 42097, "code": ", value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads", "label": 0}, {"snippet_id": 11830, "code": "] else: base={key: head[key]} return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request", "label": 1}, {"snippet_id": 20299, "code": ".pop('nodebug', False): argv.insert(0, '--nodebug') self._launch(argv, **kwargs) return self._adapter, self._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 6775, "code": " fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations", "label": 0}, {"snippet_id": 67711, "code": "(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start", "label": 0}, {"snippet_id": 43054, "code": " kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str)", "label": 0}, {"snippet_id": 31513, "code": "(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self", "label": 0}, {"snippet_id": 7343, "code": " output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2", "label": 0}, {"snippet_id": 72260, "code": " return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text, **kwargs): \"\"\" reply() rerouter", "label": 0}, {"snippet_id": 10085, "code": " else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for", "label": 0}, {"snippet_id": 70859, "code": " 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, ", "label": 0}, {"snippet_id": 51424, "code": " after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. ", "label": 0}, {"snippet_id": 21217, "code": " import pickle from bs4 import BeautifulSoup import urllib3 import certifi import re import sys import argparse as ap flatten=lambda l:[item for sublist in l for item in sublist] def getytlinks(link): pm", "label": 0}, {"snippet_id": 54518, "code": "\"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 58469, "code": ".post(self.many_comments_url, {'comment': 'new comment', 'run':[]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) response=self", "label": 0}, {"snippet_id": 94354, "code": " found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell", "label": 0}, {"snippet_id": 4825, "code": " composite_keywords_p=_sort_kw_matches(composite_keywords) for w in single_keywords_p: categories[w[0].concept]=w[0].type for w in single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete", "label": 0}, {"snippet_id": 96068, "code": "-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length", "label": 1}, {"snippet_id": 66315, "code": ", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label", "label": 0}, {"snippet_id": 55467, "code": " self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation", "label": 0}, {"snippet_id": 15584, "code": " OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self", "label": 0}, {"snippet_id": 36051, "code": ".resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict", "label": 0}, {"snippet_id": 17493, "code": " self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler(", "label": 0}, {"snippet_id": 79192, "code": "\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self", "label": 0}, {"snippet_id": 6993, "code": ", v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords", "label": 0}, {"snippet_id": 76625, "code": "): msg=[] msg.append('[image-original-none-http://simg4.gelbooru.com/' +'/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]') msg.append('\u041a\u0430\u0436\u0434\u044b\u0439 \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random", "label": 0}, {"snippet_id": 62975, "code": " configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when", "label": 0}, {"snippet_id": 87072, "code": "._processor_info_dir=os.path.join(self.workdir, 'apt-processor-info') ZincCompile.validate_arguments(self.context.log, self.get_options().whitelisted_args, self._args) if self.execution_strategy==self.HERMETIC: try:", "label": 0}, {"snippet_id": 59381, "code": "([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items", "label": 0}, {"snippet_id": 12327, "code": " prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request.json[\"action\"]==\"opened\": if config[\"message\"]", "label": 0}, {"snippet_id": 40747, "code": ": filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for", "label": 0}, {"snippet_id": 77413, "code": " self.init_pr_sock() if not hasattr(self, 'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: if type_", "label": 0}, {"snippet_id": 85006, "code": ", '2.11', '2.12', 'custom'], fingerprint=True, help='The scala platform version. If --version=custom, the targets ' '//:scala-library, //:scalac, //:scala-repl and //:scalastyle will be used, ' 'and must", "label": 0}, {"snippet_id": 48786, "code": " producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement", "label": 0}, {"snippet_id": 43815, "code": ".is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str", "label": 0}, {"snippet_id": 7206, "code": "<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords,", "label": 0}, {"snippet_id": 95815, "code": " data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion", "label": 0}, {"snippet_id": 39671, "code": "=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate", "label": 0}, {"snippet_id": 84637, "code": " if not self.get_options().transitive: targets=self.context.target_roots input_snapshots=tuple( target.sources_snapshot(scheduler=self.context._scheduler) for target in targets ) input_files={f.path for", "label": 0}, {"snippet_id": 19979, "code": "=None): if self.closed: raise RuntimeError('debug client closed') if self._session is None: raise RuntimeError('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not", "label": 0}, {"snippet_id": 87171, "code": "(compile_context.classes_dir, compile_context.jar_file, compile_context.analysis_file) if zinc_args is not None: for compile_context in compile_contexts: with open(compile_context.zinc_args_file, 'r') as fp:", "label": 0}, {"snippet_id": 77284, "code": ", wclass, count, args=(), kvargs={}): wname=str(wclass.__name__) self.log.info('Starting %s(s)', wname) if issubclass(wclass, workers.WZWorkerThread): type_=0 if not hasattr(self, 'th_sock'): self.init_th_sock", "label": 0}, {"snippet_id": 52525, "code": ".output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self", "label": 1}, {"snippet_id": 83398, "code": " remote_job_config) log.info(\"lwr job submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper", "label": 0}, {"snippet_id": 18633, "code": " self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady", "label": 0}, {"snippet_id": 93455, "code": " node in res: if node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex", "label": 0}, {"snippet_id": 21162, "code": "): if self._event is None: return if not self._event.wait(timeout): message='Timeout waiting for ' if isinstance(self, AwaitableEvent): message +='Event{}'.format(self.name) else: message +='Response{}", "label": 0}, {"snippet_id": 57856, "code": " selected TestCases\"\"\" proxy=TestCaseUpdateActions(request) return proxy.update() update_cases_priority=update_cases_default_tester update_cases_case_status=update_cases_default_tester update_cases_sortkey", "label": 0}, {"snippet_id": 27532, "code": " self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain", "label": 0}, {"snippet_id": 88268, "code": " pants.build_graph.target import Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products import Products from pants.goal.workspace import ScmWorkspace from", "label": 1}, {"snippet_id": 57627, "code": "(self): try: user=User.objects.get(Q(username=self.new_value) | Q(email=self.new_value)) except User.DoesNotExist: raise ObjectDoesNotExist('Default tester not found!') self.get_update_targets().update(*", "label": 0}, {"snippet_id": 24342, "code": ".NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names", "label": 1}, {"snippet_id": 17940, "code": ", method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get(", "label": 1}, {"snippet_id": 69321, "code": " class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self)", "label": 0}, {"snippet_id": 25497, "code": " unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states", "label": 0}, {"snippet_id": 17394, "code": " def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, ", "label": 0}, {"snippet_id": 14975, "code": "=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if", "label": 0}, {"snippet_id": 46343, "code": "\"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False", "label": 0}, {"snippet_id": 52285, "code": ".ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() }", "label": 0}, {"snippet_id": 94254, "code": " Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name)", "label": 0}, {"snippet_id": 54478, "code": " temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None", "label": 1}, {"snippet_id": 21601, "code": "[:, 4].values from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=0) from sklearn.preprocessing import StandardScaler", "label": 0}, {"snippet_id": 1216, "code": " getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(): \"\"\" PRETTY_NAME of your Titania os(in lowercase). \"\"\" with open", "label": 1}, {"snippet_id": 14197, "code": ", EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy'", "label": 0}, {"snippet_id": 45243, "code": ".workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\"", "label": 0}, {"snippet_id": 2007, "code": ".Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields))", "label": 0}, {"snippet_id": 60622, "code": ": for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else", "label": 0}, {"snippet_id": 27620, "code": ": self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp", "label": 0}, {"snippet_id": 57498, "code": ".get_update_action() if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception: return say_no('Update failed. Please try again or request", "label": 0}, {"snippet_id": 7891, "code": "(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output", "label": 0}, {"snippet_id": 6905, "code": " keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in", "label": 0}, {"snippet_id": 42141, "code": " return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return", "label": 0}, {"snippet_id": 79750, "code": ".add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1", "label": 0}, {"snippet_id": 32380, "code": " not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name", "label": 0}, {"snippet_id": 38880, "code": "())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated", "label": 0}, {"snippet_id": 48420, "code": "): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)", "label": 0}, {"snippet_id": 10157, "code": " kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info", "label": 0}, {"snippet_id": 72088, "code": "\"\"<network> <seconds> Sets the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"\"\" permissions.checkPermissions(irc, source", "label": 0}, {"snippet_id": 63518, "code": ": encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id,", "label": 0}, {"snippet_id": 16714, "code": " self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled", "label": 0}, {"snippet_id": 65885, "code": " status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for", "label": 0}, {"snippet_id": 78976, "code": "(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms[0][1][0][\"name\"] \t\tself.logger.debug(\"Found the following file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: ", "label": 0}, {"snippet_id": 64579, "code": "=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" %", "label": 0}, {"snippet_id": 74608, "code": "=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): \"\"\" Creates an object", "label": 0}, {"snippet_id": 24593, "code": " elif self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'", "label": 0}, {"snippet_id": 84377, "code": ".local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config", "label": 0}, {"snippet_id": 28437, "code": "[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self):", "label": 0}, {"snippet_id": 90751, "code": ".jvm_locations): try: dist=Distribution(home_path=location.home_path, bin_path=location.bin_path, minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) dist.validate() logger.debug('Located", "label": 0}, {"snippet_id": 32667, "code": " rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__", "label": 0}, {"snippet_id": 4260, "code": ".startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os", "label": 0}, {"snippet_id": 72794, "code": " FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib import allel import sys import functools import numpy as np import zarr import numcodecs from numcodecs import", "label": 1}, {"snippet_id": 76722, "code": " parser.add_argument('--av-dir', default='randav', help='Directory with avatars') parser.add_argument('--rp-timeout', '-T', type=int, default=10, help='Default rp timeout in seconds') parser.add_argument", "label": 0}, {"snippet_id": 63664, "code": " log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\"", "label": 0}, {"snippet_id": 32661, "code": "=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self", "label": 0}, {"snippet_id": 12480, "code": " error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra", "label": 0}, {"snippet_id": 44716, "code": "=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile,", "label": 0}, {"snippet_id": 7717, "code": " in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items", "label": 0}, {"snippet_id": 36848, "code": ".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 50660, "code": " if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None", "label": 0}, {"snippet_id": 77588, "code": " with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues[domain] except KeyError:", "label": 0}, {"snippet_id": 12155, "code": "=get_files_involved_in_pr(data) for file in list(files.keys()): if file[-3:] !=\".py\": del files[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"", "label": 0}, {"snippet_id": 71561, "code": "(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ ", "label": 0}, {"snippet_id": 48044, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"", "label": 0}, {"snippet_id": 8892, "code": "(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords", "label": 0}, {"snippet_id": 53051, "code": " nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output", "label": 0}, {"snippet_id": 59826, "code": "\"Z\"+'0'),[qubit]) for qubit in self.reg] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend", "label": 0}, {"snippet_id": 80832, "code": "]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested", "label": 1}, {"snippet_id": 55072, "code": ".persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n", "label": 0}, {"snippet_id": 57852, "code": " @require_POST def update_cases_default_tester(request): \"\"\"Update default tester upon selected TestCases\"\"\" proxy=TestCaseUpdateActions(request) return proxy.update() update_cases_priority=update_cases_default_tester", "label": 0}, {"snippet_id": 67395, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) return", "label": 1}, {"snippet_id": 20757, "code": "('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event handlername='event{!r}'.format(event) with self._wait_for_message(match, handlername", "label": 0}, {"snippet_id": 16660, "code": " def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport", "label": 0}, {"snippet_id": 11800, "code": ":{'k2':{'k3': 3}}}) Source: http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key", "label": 1}, {"snippet_id": 27804, "code": " data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" %", "label": 0}, {"snippet_id": 69131, "code": " ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import *", "label": 0}, {"snippet_id": 50077, "code": " \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os", "label": 0}, {"snippet_id": 46732, "code": " top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( ", "label": 0}, {"snippet_id": 31334, "code": " def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files.", "label": 0}, {"snippet_id": 42588, "code": ".protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear(", "label": 0}, {"snippet_id": 11141, "code": "%Y-%m-%d %H:%M:%S\", localtime()) lines.append(\"%s on %s\" %(Header.MON_CONF_GEN_COMMENT, time_string)) if self.etag: lines.append(\"%s%s\" %(Header.ETAG_COMMENT, self.etag)) if self.mtime: lines.append(\"%s", "label": 0}, {"snippet_id": 27338, "code": "(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error", "label": 1}, {"snippet_id": 51940, "code": " start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items", "label": 0}, {"snippet_id": 51678, "code": " first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name", "label": 0}, {"snippet_id": 29948, "code": ".format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern", "label": 0}, {"snippet_id": 67631, "code": "(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(),", "label": 0}, {"snippet_id": 44473, "code": " items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes", "label": 0}, {"snippet_id": 77476, "code": ".log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads(self): return self.spawn_nworkers(0, WipeThread, self.c.tcount, (self.pc, self.spawnqueue)) def spawn_evaluators(self):", "label": 0}, {"snippet_id": 76484, "code": "*self.call[1], **self.call[2]) self.child(self) except WorkerInterrupt as e: self.log.warn(e) except Exception as e: self.log.exception(e) self.log.info('Terminating') else: self.log.info('Aborted') self", "label": 0}, {"snippet_id": 44633, "code": "())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile(", "label": 0}, {"snippet_id": 77915, "code": "=str(id_) tuser=tuser or '' t=(tuser, id_) logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) def remove_target(domain, id_, tuser=None): tlist=targets[domain] id_=str(id_) tuser", "label": 0}, {"snippet_id": 23058, "code": " so this is the point where we should wait for mcpd to load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent", "label": 0}, {"snippet_id": 46681, "code": " YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found", "label": 0}, {"snippet_id": 17512, "code": " GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype", "label": 0}, {"snippet_id": 1951, "code": " print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4", "label": 0}, {"snippet_id": 34168, "code": "=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self", "label": 0}, {"snippet_id": 62868, "code": "['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state", "label": 0}, {"snippet_id": 31915, "code": " in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item", "label": 0}, {"snippet_id": 46278, "code": " os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for", "label": 0}, {"snippet_id": 93975, "code": "(SCRIPT_CLONE_PATH, session_name, comp_name) send_main_session_command(self.session, cmd) def start_remote_clone_session(self, comp_name, session_name, hostname): remote_cmd=(\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH", "label": 0}, {"snippet_id": 15480, "code": "{} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None)", "label": 0}, {"snippet_id": 27926, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self", "label": 0}, {"snippet_id": 11808, "code": "/stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key,{}), value", "label": 1}, {"snippet_id": 6186, "code": " return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words", "label": 1}, {"snippet_id": 14702, "code": "'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self", "label": 0}, {"snippet_id": 28933, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0:", "label": 0}, {"snippet_id": 61516, "code": ".wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self.shots)) else: a, P=spectral_decomposition_qubit(A) p0=self.ev(P[0], self._observe.wires) n0=np.random.binomial(self.shots, p0) ev=(n0*a[0] +(self", "label": 0}, {"snippet_id": 66553, "code": "=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname))", "label": 0}, {"snippet_id": 25063, "code": "\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 42945, "code": ": start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have", "label": 0}, {"snippet_id": 56505, "code": "): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters=['app_form', 'format'] parameters=strip_parameters(request.GET, internal_parameters) q_app_form=request.GET.get('app_form'", "label": 1}, {"snippet_id": 68243, "code": " for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif", "label": 0}, {"snippet_id": 44149, "code": " not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles", "label": 0}, {"snippet_id": 66562, "code": " nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc=", "label": 0}, {"snippet_id": 17991, "code": "( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout)", "label": 0}, {"snippet_id": 78137, "code": ".send_multipart(msg) def drop_users(): send_passthrough([b'WipeSkel', b'WipeSkel', b'drop-user']) def log_spawn_name(): send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name']) if c.no_shell:", "label": 1}, {"snippet_id": 29944, "code": " in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for", "label": 0}, {"snippet_id": 83025, "code": "\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: \t\t\t\t\t\traise KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear", "label": 0}, {"snippet_id": 52556, "code": " output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill)", "label": 0}, {"snippet_id": 16630, "code": ".DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics", "label": 0}, {"snippet_id": 22209, "code": ".conf: if 'playbook' in self.conf[state]: playbook=self.conf[state]['playbook'] if 'log_file' in self.conf[state]: log_file=self.conf[state]['log_file'] if 'template' in self.conf[state]: template=self", "label": 0}, {"snippet_id": 87106, "code": " be a child of the buildroot \" \"but workdir was{} and buildroot was{}\".format( self.get_options().pants_workdir, get_buildroot(), ) ) if self.get_options().use_classpath_jars: raise TaskError(\"Hermetic", "label": 0}, {"snippet_id": 78681, "code": " self.options.daemon: log.logger.debug('Executing remotely') return self.executer(*sys.argv) log.logger.debug('Executing locally') return self.execute() except BaseException as e: log.logger.exception(e)", "label": 1}, {"snippet_id": 15125, "code": " data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data", "label": 0}, {"snippet_id": 5671, "code": " _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off", "label": 0}, {"snippet_id": 22784, "code": " the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param username: The username whose password to change :param password", "label": 0}, {"snippet_id": 4506, "code": " author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations(fulltext) single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords", "label": 0}, {"snippet_id": 92078, "code": "=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys()) if not platform_names or platform_names==['current']: return True bad_targets=set() for", "label": 0}, {"snippet_id": 69926, "code": "()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Mount successful.\" elif rc==RC_RUNTIME_ERROR", "label": 1}, {"snippet_id": 27477, "code": "(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self", "label": 0}, {"snippet_id": 42169, "code": " self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class", "label": 0}, {"snippet_id": 31233, "code": " ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes", "label": 0}, {"snippet_id": 30268, "code": " items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None", "label": 0}, {"snippet_id": 21421, "code": " unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working directory found, but no subreddit directory. Creating %s, and files", "label": 0}, {"snippet_id": 32562, "code": " except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex),", "label": 0}, {"snippet_id": 34124, "code": " rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark", "label": 0}, {"snippet_id": 82324, "code": " action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt", "label": 0}, {"snippet_id": 2688, "code": " copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path)", "label": 0}, {"snippet_id": 19650, "code": "') host.add_argument('--server-host') parser.add_argument('--port', type=int, required=True) target=parser.add_mutually_exclusive_group(required=True) target.add_argument('-m', dest='module') target.add_argument", "label": 0}, {"snippet_id": 93108, "code": ".assertRaises(AssertionError): with exception_logging(fake_logger, 'error!'): assert True is False fake_logger.exception.assert_called_once_with('error!') def test_maybe_profiled(self): with temporary_dir(", "label": 0}, {"snippet_id": 46244, "code": " \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard", "label": 0}, {"snippet_id": 64531, "code": " import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__", "label": 0}, {"snippet_id": 20967, "code": "(list(self._handlers)): handle_message, _, _=handler handled=handle_message(msg) try: msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break self._received.append(msg)", "label": 0}, {"snippet_id": 60998, "code": " import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix", "label": 0}, {"snippet_id": 3770, "code": "-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name): window=session", "label": 0}, {"snippet_id": 91811, "code": " ExecuteProcessRequest, request) status=Status.SUCCESS if result.exit_code==0 else Status.FAILURE yield TestResult( status=status, stdout=result.stdout.decode('utf-8'), stderr=result.stderr.decode('utf-8'), ) def rules(", "label": 0}, {"snippet_id": 45342, "code": " os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError", "label": 1}, {"snippet_id": 93272, "code": "=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self", "label": 0}, {"snippet_id": 13719, "code": "']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self", "label": 0}, {"snippet_id": 60985, "code": "\"This module contains the device class and context manager\"\"\" import numpy as np from scipy.linalg import expm, eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable", "label": 0}, {"snippet_id": 72999, "code": " fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"\" Recursive function that automatically downloads all files with a FTP directory, including subdirectories.", "label": 0}, {"snippet_id": 45879, "code": "])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name", "label": 0}, {"snippet_id": 2089, "code": "(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 86713, "code": " which replaces $JAVA_HOME with the path to an appropriate jvm distribution. :param settings: The jvm platform settings from which to extract the arguments. :type settings::class:`JvmPlatformSettings` \"\"", "label": 0}, {"snippet_id": 74311, "code": " and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file", "label": 0}, {"snippet_id": 21164, "code": " is None: return if not self._event.wait(timeout): message='Timeout waiting for ' if isinstance(self, AwaitableEvent): message +='Event{}'.format(self.name) else: message +='Response{}'.format(self.name)", "label": 0}, {"snippet_id": 29992, "code": ".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns", "label": 0}, {"snippet_id": 71444, "code": " from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler", "label": 0}, {"snippet_id": 92441, "code": " self.assertEqual(os.environ['XXX'], expected_output) def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir) as path: self.assertEqual(tempdir, path) self", "label": 0}, {"snippet_id": 87214, "code": "'zinc_args', lambda: defaultdict(list)) def javac_classpath(self): return Java.global_javac_classpath(self.context.products) def scalac_classpath(self): return ScalaPlatform.global_instance().compiler_classpath", "label": 0}, {"snippet_id": 32357, "code": " \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item", "label": 0}, {"snippet_id": 15781, "code": " return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded", "label": 0}, {"snippet_id": 50794, "code": ".supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str", "label": 0}, {"snippet_id": 68861, "code": " AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT", "label": 0}, {"snippet_id": 14650, "code": ".ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics", "label": 0}, {"snippet_id": 46489, "code": " Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self", "label": 0}, {"snippet_id": 55997, "code": "): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func", "label": 0}, {"snippet_id": 93946, "code": "/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name)", "label": 0}, {"snippet_id": 45405, "code": "\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property", "label": 0}, {"snippet_id": 41540, "code": " if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not", "label": 0}, {"snippet_id": 84945, "code": "(ScalaPlatform, cls).register_options(register) register('--scalac-plugins', advanced=True, type=list, fingerprint=True, help='Use these scalac plugins.') register('--scalac-plugin-args', advanced=True", "label": 0}, {"snippet_id": 28648, "code": " data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 69063, "code": " self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support", "label": 0}, {"snippet_id": 16992, "code": " requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method", "label": 0}, {"snippet_id": 21627, "code": " X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors import ListedColormap X_set, y_set", "label": 0}, {"snippet_id": 23498, "code": ".active') shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user(username): raise OSUtilError((", "label": 0}, {"snippet_id": 41081, "code": " \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items", "label": 0}, {"snippet_id": 29699, "code": ") def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value", "label": 0}, {"snippet_id": 22468, "code": " start_agent_service(self): return shellutil.run(\"/sbin/service waagent start\", chk_err=False) def register_agent_service(self): return shellutil.run(\"/sbin/chkconfig --add waagent\", chk_err=False) def", "label": 0}, {"snippet_id": 30478, "code": " config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector", "label": 0}, {"snippet_id": 81317, "code": "\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t", "label": 1}, {"snippet_id": 77573, "code": " uq in self.userqueues.items(): uqsize=uq.qsize() uds=[] for i in range(uqsize): uds.append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL", "label": 0}, {"snippet_id": 46321, "code": ") match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides", "label": 0}, {"snippet_id": 723, "code": " cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0", "label": 0}, {"snippet_id": 74812, "code": "\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str=runtime_config.vcf_to_zarr[\"blosc_shuffle_mode\"] if isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int(blosc_shuffle_mode_str", "label": 0}, {"snippet_id": 85466, "code": " cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-compiler_2.11', '0.0.7'), ], main=Zinc.ZINC_COMPILE_MAIN, custom_rules=shader_rules) cls", "label": 1}, {"snippet_id": 29938, "code": " values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError", "label": 0}, {"snippet_id": 88324, "code": " in the run. Advanced uses of the context include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated", "label": 0}, {"snippet_id": 16242, "code": " SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface(", "label": 0}, {"snippet_id": 44503, "code": "\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname,", "label": 0}, {"snippet_id": 26530, "code": "\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'", "label": 0}, {"snippet_id": 29064, "code": "=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API", "label": 1}, {"snippet_id": 27734, "code": "\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self", "label": 0}, {"snippet_id": 35301, "code": " list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\"", "label": 0}, {"snippet_id": 72582, "code": "\"run\", metavar=\"RUN_LABEL\", help=\"Label for the benchmark run.\") benchmark_exec_parser.add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH", "label": 1}, {"snippet_id": 3347, "code": " self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name", "label": 0}, {"snippet_id": 80905, "code": ") \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(", "label": 0}, {"snippet_id": 25837, "code": " elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" %", "label": 0}, {"snippet_id": 38065, "code": " return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule", "label": 0}, {"snippet_id": 25458, "code": " self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property", "label": 0}, {"snippet_id": 72197, "code": " sent using irc.reply() are supported and returned here, but others are dropped due to protocol limitations.\"\"\" permissions.checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args", "label": 0}, {"snippet_id": 39964, "code": " follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile", "label": 0}, {"snippet_id": 37529, "code": " inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 63938, "code": ") client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path(), ) return", "label": 0}, {"snippet_id": 91410, "code": " task(name='py', action=PythonRun).install('run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install", "label": 0}, {"snippet_id": 90668, "code": " dist=self._cache.get(key) if not dist: dist=self._scan_constraint_match(minimum_version, maximum_version, jdk) if not dist: dist=self._locate(minimum_version=minimum_version, maximum_version=maximum_version", "label": 0}, {"snippet_id": 31801, "code": "._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if", "label": 0}, {"snippet_id": 55711, "code": " value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\")", "label": 0}, {"snippet_id": 46592, "code": "(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self", "label": 0}, {"snippet_id": 90819, "code": "{} distribution with minimum_version{}, ' 'maximum_version{}') raise self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem", "label": 0}, {"snippet_id": 19353, "code": " result==native def test_url(httpbin): native={ 'origin': '127.0.0.1', 'args':{}, } source=httpbin.url +'/get' result=load_source(source) assert isinstance(result, collections.Mapping) result.pop('headers", "label": 0}, {"snippet_id": 22740, "code": ") ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id=6, salt_len=10): \"\"\"Change a user's password with tmsh Since we are creating the user specified account and additionally", "label": 0}, {"snippet_id": 80405, "code": " illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\"", "label": 0}, {"snippet_id": 58491, "code": "(self.many_comments_url, {'comment': 'new comment'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist", "label": 0}, {"snippet_id": 5076, "code": " in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw]", "label": 0}, {"snippet_id": 33394, "code": ": self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions", "label": 0}, {"snippet_id": 85644, "code": "-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property def compiler_interface(self): \"\"\"Return the path to the Zinc compiler-interface jar. :rtype: str", "label": 0}, {"snippet_id": 53931, "code": ".\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return", "label": 0}, {"snippet_id": 89760, "code": ") if self._is_executable(os.path.join(jdk_dir, 'bin', 'javac')): home=jdk_dir self._home=home return self._home @property def real_home(self): \"\"\"Real path to the distribution java.home(resolving links", "label": 1}, {"snippet_id": 64072, "code": " config -but there is no guarentee that it will contain all the datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes", "label": 0}, {"snippet_id": 19141, "code": " request=request) if response is not None: validate_response( response=response, request_method=request_method, schema=schema ) def validate_api_call(schema, raw_request, raw_response): \"\"\" Validate the", "label": 0}, {"snippet_id": 39162, "code": ".resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources))", "label": 0}, {"snippet_id": 21457, "code": ".system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) else: print(\"Reddytt: Working directory found. Loading variables.\") with open(seen_file, 'rb') as f: seen_links", "label": 0}, {"snippet_id": 42993, "code": "._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params", "label": 0}, {"snippet_id": 58693, "code": "'value': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'", "label": 0}, {"snippet_id": 47469, "code": "*_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self", "label": 0}, {"snippet_id": 10089, "code": " fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items()", "label": 0}, {"snippet_id": 5046, "code": "<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield", "label": 0}, {"snippet_id": 83139, "code": " a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information. Defaulting", "label": 0}, {"snippet_id": 850, "code": " stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0]", "label": 0}, {"snippet_id": 20082, "code": "(addr, **kwargs) def _attach(self, addr, **kwargs): if addr is None: addr=self._addr assert addr.host=='localhost' self._session=self.SESSION.create_client(addr, **kwargs) def _detach(self): session=self", "label": 0}, {"snippet_id": 36598, "code": ", **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self", "label": 0}, {"snippet_id": 61857, "code": " plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following", "label": 0}, {"snippet_id": 90532, "code": " self._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version and dist.version > maximum_version: continue if jdk and not dist.jdk: continue return dist def locate", "label": 0}, {"snippet_id": 48132, "code": ".benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output:", "label": 0}, {"snippet_id": 13950, "code": " def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return", "label": 1}, {"snippet_id": 69657, "code": ".get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\"", "label": 0}, {"snippet_id": 41180, "code": ", plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return", "label": 0}, {"snippet_id": 41314, "code": " must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the", "label": 0}, {"snippet_id": 62133, "code": ".1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots", "label": 0}, {"snippet_id": 92411, "code": " UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output=UNICODE_CHAR if PY3 else ENCODED_CHAR with environment_as(**dict(XXX=UNICODE_CHAR)): self.assertEqual(os.environ['XXX'], expected_output", "label": 1}, {"snippet_id": 35683, "code": " name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start ", "label": 0}, {"snippet_id": 15151, "code": " import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from", "label": 0}, {"snippet_id": 39405, "code": "]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile", "label": 0}, {"snippet_id": 7298, "code": " KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=", "label": 0}, {"snippet_id": 61736, "code": " operator. Args: U(array): 4x4 matrix wires(Sequence[int]): two target subsystems(order matters!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires)", "label": 0}, {"snippet_id": 48127, "code": "(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output -", "label": 0}, {"snippet_id": 4184, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input", "label": 0}, {"snippet_id": 43039, "code": "(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item", "label": 0}, {"snippet_id": 39562, "code": ".benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]", "label": 0}, {"snippet_id": 8550, "code": "=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file", "label": 1}, {"snippet_id": 55050, "code": ".info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock(", "label": 0}, {"snippet_id": 60436, "code": ", *self.observe.params) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device\"\"\" if self.eng is not None: self.eng=None self.state=None", "label": 0}, {"snippet_id": 83336, "code": " queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if not command_line", "label": 0}, {"snippet_id": 58425, "code": "-comment_case_runs') def test_refuse_if_missing_comment(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'run':[self.case_run_1.pk,", "label": 0}, {"snippet_id": 47549, "code": "(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule", "label": 0}, {"snippet_id": 2424, "code": ".setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml", "label": 0}, {"snippet_id": 33462, "code": " \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets", "label": 0}, {"snippet_id": 67310, "code": "(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR", "label": 0}, {"snippet_id": 63398, "code": " command_line, client, remote_job_config, compute_environment def __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, ", "label": 0}, {"snippet_id": 82605, "code": "=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions", "label": 0}, {"snippet_id": 20878, "code": " @contextlib.contextmanager def wait_for_response(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req", "label": 0}, {"snippet_id": 10786, "code": " word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request", "label": 1}, {"snippet_id": 10438, "code": " _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag", "label": 0}, {"snippet_id": 63571, "code": " exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job.states.DELETED]", "label": 0}, {"snippet_id": 28938, "code": " data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 42323, "code": " import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None", "label": 0}, {"snippet_id": 6589, "code": " rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text()", "label": 1}, {"snippet_id": 21229, "code": " sublist in l for item in sublist] def getytlinks(link): pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, ", "label": 0}, {"snippet_id": 79568, "code": "\t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren", "label": 0}, {"snippet_id": 3729, "code": ": logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for", "label": 0}, {"snippet_id": 3936, "code": " locally without controlling it. The \" \"control is taken care of the remote master invoking \" \"this command.\\nIf run with the --kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"", "label": 0}, {"snippet_id": 95038, "code": ".add_argument(\"--config_file\", type=str, required=True, help=\"Specify the path to a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(", "label": 0}, {"snippet_id": 44519, "code": " cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait", "label": 0}, {"snippet_id": 46036, "code": "(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, ", "label": 0}, {"snippet_id": 11600, "code": ".join([str(x) if(x is not None) else \"\" for x in value]) else: return str(value) class OutputWriter(object): def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with", "label": 0}, {"snippet_id": 31865, "code": " item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products", "label": 0}, {"snippet_id": 22084, "code": ") self.options.verbosity=verbosity self.loader=dataloader.DataLoader() self.variable_manager=vars.VariableManager() self.inventory=inventory.Inventory( loader=self.loader, variable_manager=self.variable_manager", "label": 0}, {"snippet_id": 17569, "code": " if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={}", "label": 0}, {"snippet_id": 21489, "code": "=pickle.load(f) new_links, links=getytlinks(subreddit_link) if depth > 0: for d in range(depth): link=\"\" for l in links: if re.search(\"after=\", l): link=l if link==\"\": print(\"Reddytt: Could not identify ", "label": 0}, {"snippet_id": 30708, "code": ".add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_]", "label": 0}, {"snippet_id": 68910, "code": " Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine", "label": 0}, {"snippet_id": 22029, "code": ".private_key_file=private_key_file self.remote_user=remote_user self.connection=connection self.timeout=timeout self.ssh_common_args=ssh_common_args self.sftp_extra_args=sftp_extra_args self.scp_extra_args", "label": 0}, {"snippet_id": 71994, "code": " manipulate connections to various configured networks.\"\"\" import importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc.coremods import control", "label": 0}, {"snippet_id": 40088, "code": ".mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir", "label": 0}, {"snippet_id": 94679, "code": "\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser", "label": 0}, {"snippet_id": 54407, "code": ", Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import", "label": 0}, {"snippet_id": 36312, "code": ": \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_", "label": 0}, {"snippet_id": 52454, "code": " None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self", "label": 0}, {"snippet_id": 81880, "code": ",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default", "label": 0}, {"snippet_id": 93895, "code": "'name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self", "label": 0}, {"snippet_id": 48076, "code": ": self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments", "label": 0}, {"snippet_id": 58299, "code": ".tests.factories import EnvGroupPropertyMapFactory from tcms.tests.factories import EnvPropertyFactory class TestNavigation(test.TestCase): @classmethod def setUpTestData(cls): super(TestNavigation, cls", "label": 0}, {"snippet_id": 53271, "code": " self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set", "label": 0}, {"snippet_id": 95979, "code": "'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF", "label": 0}, {"snippet_id": 87311, "code": " The compiler-bridge is specific to each scala version, and is lazily computed by zinc if the appropriate version does not exist. Eventually it would be great to just fetch this rather than compiling it", "label": 1}, {"snippet_id": 16122, "code": " data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data", "label": 0}, {"snippet_id": 9166, "code": ":return: dictionary of matches in a format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def", "label": 0}, {"snippet_id": 6962, "code": "\"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a", "label": 0}, {"snippet_id": 49677, "code": " files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss.", "label": 0}, {"snippet_id": 25088, "code": ": \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station", "label": 1}, {"snippet_id": 81727, "code": " re,requests,argparse,logging,os,coloredlogs,datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0", "label": 0}, {"snippet_id": 43231, "code": " is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}", "label": 0}, {"snippet_id": 26627, "code": "'battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data", "label": 0}, {"snippet_id": 28301, "code": " vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass,", "label": 0}, {"snippet_id": 85925, "code": " import subprocess _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__", "label": 0}, {"snippet_id": 68591, "code": " STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s", "label": 0}, {"snippet_id": 51822, "code": "): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None", "label": 0}, {"snippet_id": 12849, "code": ":] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format(data[\"repository\"], data[\"sha\"], file) r=requests.get(url, headers=headers, auth=auth) with open(\"file_to_fix.py\", 'w+', encoding=r.encoding", "label": 0}, {"snippet_id": 87049, "code": ".get_options().incremental_caching @memoized_property def _zinc(self): return Zinc.Factory.global_instance().create(self.context.products) def __init__(self, *args, **kwargs): super(BaseZincCompile, self", "label": 1}, {"snippet_id": 15468, "code": " and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded", "label": 0}, {"snippet_id": 86216, "code": "(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings.args) javac_cmd.extend(settings_args) javac_cmd.extend([ '-source', str(settings.source_level), '-target", "label": 0}, {"snippet_id": 56490, "code": "'field', 'format')) return User.objects.filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most", "label": 1}, {"snippet_id": 51794, "code": " names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict", "label": 0}, {"snippet_id": 9745, "code": "=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, ", "label": 0}, {"snippet_id": 18758, "code": "'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd", "label": 0}, {"snippet_id": 25507, "code": " return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is", "label": 0}, {"snippet_id": 41453, "code": ", self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res", "label": 0}, {"snippet_id": 6920, "code": " from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in", "label": 0}, {"snippet_id": 59096, "code": " plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following", "label": 0}, {"snippet_id": 52071, "code": ": try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML", "label": 0}, {"snippet_id": 63453, "code": " str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper", "label": 0}, {"snippet_id": 89504, "code": " be supplied. :param string home_path: the path to the java distribution's home dir :param string bin_path: the path to the java distribution's bin dir :param minimum_version: a modified semantic version", "label": 0}, {"snippet_id": 32180, "code": " callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self", "label": 0}, {"snippet_id": 13452, "code": "\"target_repo_branch\"], \"body\": \"The changes are suggested by autopep8\", } r=requests.post(url, json=request_json, headers=headers, auth=auth) if r.status_code==201: data[\"pr_url\"]=r.json()[\"html_url\"] else:", "label": 0}, {"snippet_id": 84346, "code": "=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append(integrates_datatypes_config) metadata_kwds['datatypes_config']", "label": 0}, {"snippet_id": 34773, "code": ".lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards,", "label": 0}, {"snippet_id": 59730, "code": " _gates=set(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed", "label": 0}, {"snippet_id": 69892, "code": ")) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException", "label": 0}, {"snippet_id": 57055, "code": " error=str(e) return value, error def say_no(error_msg): ajax_response={'rc': 1, 'response': error_msg} return HttpResponse(json.dumps(ajax_response)) def say_yes(): return HttpResponse(json.dumps({'rc': 0,", "label": 0}, {"snippet_id": 85373, "code": ", PathGlobsAndRoot from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem from pants.util.dirutil import fast_relpath from pants.util.memo import memoized_method", "label": 1}, {"snippet_id": 32184, "code": " if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 22354, "code": " that the rest of the provisioning does not need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does", "label": 0}, {"snippet_id": 905, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape", "label": 0}, {"snippet_id": 44594, "code": ": logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be", "label": 0}, {"snippet_id": 430, "code": ") setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return", "label": 0}, {"snippet_id": 26790, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 64300, "code": " in local_input_paths: wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path, remote_path)) return", "label": 0}, {"snippet_id": 57074, "code": "{'rc': 0, 'response': 'ok'})) @require_POST def update(request): \"\"\" Generic approach to update a model,\\n based on contenttype. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(", "label": 0}, {"snippet_id": 71989, "code": "\"\"Networks plugin -allows you to manipulate connections to various configured networks.\"\"\" import importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from", "label": 0}, {"snippet_id": 57259, "code": "%s changed from %s to %s.' %( field, getattr(t, field), now ) ) if t.tested_by !=request.user: field='tested_by' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr", "label": 0}, {"snippet_id": 44983, "code": "=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string", "label": 0}, {"snippet_id": 68971, "code": " client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path)", "label": 1}, {"snippet_id": 1234, "code": ". \"\"\" with open(\"/etc/os-release\") as f: osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless", "label": 0}, {"snippet_id": 12005, "code": " except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key, value in confs.items(): if value: if isinstance(value, int): if isinstance(value, bool): arguments.append(\"--{}\".format(key", "label": 0}, {"snippet_id": 7324, "code": "\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code", "label": 0}, {"snippet_id": 72412, "code": " module name)') return proto=utils.getProtocolModule(name) importlib.reload(proto) irc.reply(\"Done. You will have to manually disconnect and reconnect any network using the %r module for changes to apply.\"", "label": 0}, {"snippet_id": 33599, "code": "(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed", "label": 0}, {"snippet_id": 12950, "code": "]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs in data[\"diff\"].items(): if len(diffs) !=0: REQUEST_JSON[\"files\"][file", "label": 0}, {"snippet_id": 82071, "code": ".add_mutually_exclusive_group() exclusiveArgs.add_argument(\"-l\",\"--legit-extensions\",metavar=\"listOfExtensions\",dest=\"legitExtensions\",nargs=1,help=\"Legit extensions expected, for a normal use of the form", "label": 0}, {"snippet_id": 51243, "code": "\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence", "label": 0}, {"snippet_id": 28969, "code": ": self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self", "label": 0}, {"snippet_id": 6081, "code": " not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\")", "label": 0}, {"snippet_id": 83932, "code": " 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return", "label": 0}, {"snippet_id": 7627, "code": " output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:", "label": 0}, {"snippet_id": 66107, "code": ": status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status", "label": 0}, {"snippet_id": 41184, "code": " def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str", "label": 0}, {"snippet_id": 11709, "code": " import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False", "label": 0}, {"snippet_id": 80081, "code": "=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\"", "label": 0}, {"snippet_id": 83913, "code": " % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid,", "label": 0}, {"snippet_id": 14471, "code": " and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded", "label": 0}, {"snippet_id": 37772, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=", "label": 0}, {"snippet_id": 66253, "code": "\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 66890, "code": "._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in", "label": 1}, {"snippet_id": 54784, "code": ", dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False", "label": 0}, {"snippet_id": 24235, "code": " 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength'", "label": 0}, {"snippet_id": 31542, "code": "=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input", "label": 0}, {"snippet_id": 93680, "code": " state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component", "label": 0}, {"snippet_id": 79271, "code": " !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None):", "label": 0}, {"snippet_id": 3319, "code": " self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server", "label": 0}, {"snippet_id": 34592, "code": "\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may", "label": 0}, {"snippet_id": 45399, "code": " _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\"", "label": 0}, {"snippet_id": 66492, "code": ".__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR", "label": 0}, {"snippet_id": 77865, "code": "=self.read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except WorkerInterrupt: pass except Exception as e: self.log.exception(e) self.terminate() self.join_threads() if self", "label": 0}, {"snippet_id": 3857, "code": "(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default", "label": 0}, {"snippet_id": 25813, "code": "\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60:", "label": 0}, {"snippet_id": 32182, "code": ".append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError", "label": 0}, {"snippet_id": 24514, "code": "\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self", "label": 0}, {"snippet_id": 52322, "code": ", self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in", "label": 0}, {"snippet_id": 17205, "code": "'no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer)", "label": 0}, {"snippet_id": 20646, "code": "] self._listenerthread=new_hidden_thread( target=self._listen, name='test.session', ) self._listenerthread.start() @property def is_client(self): return self._conn.is_client @property def received(self", "label": 0}, {"snippet_id": 40478, "code": " fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise", "label": 0}, {"snippet_id": 73508, "code": " output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf", "label": 0}, {"snippet_id": 67489, "code": ".Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base", "label": 0}, {"snippet_id": 12045, "code": "{arguments}'.format(arguments=' '.join(arguments)) config[\"pycodestyle\"][\"ignore\"]=[e.upper() for e in list(config[\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return", "label": 0}, {"snippet_id": 50463, "code": ": def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate", "label": 0}, {"snippet_id": 11405, "code": "=Header.parse(output_path) return header_source.is_newer_than(old_header) def output_path(self, file_name): return os.path.join(self.target_dir, file_name) def write_output(self, file_name, yaml_icinga", "label": 0}, {"snippet_id": 60545, "code": "(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0", "label": 0}, {"snippet_id": 95009, "code": " configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\",", "label": 1}, {"snippet_id": 45394, "code": " rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__", "label": 0}, {"snippet_id": 67274, "code": " ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr)", "label": 0}, {"snippet_id": 31453, "code": "}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or", "label": 0}, {"snippet_id": 68640, "code": " status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state=", "label": 0}, {"snippet_id": 54935, "code": ")) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets", "label": 0}, {"snippet_id": 94481, "code": " CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\")", "label": 0}, {"snippet_id": 3313, "code": "=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave", "label": 0}, {"snippet_id": 67430, "code": " -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\"", "label": 0}, {"snippet_id": 52692, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f", "label": 0}, {"snippet_id": 19904, "code": " client closed') if self._adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') raise NotImplementedError def attach_socket(self", "label": 0}, {"snippet_id": 94384, "code": " check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window", "label": 0}, {"snippet_id": 19221, "code": "} result=load_source(source) assert result==source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source(source) assert result==native def test_yaml_string(): native", "label": 1}, {"snippet_id": 49899, "code": ")) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler", "label": 0}, {"snippet_id": 87347, "code": "(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self.get_options().pants_bootstrapdir, 'zinc', key) def compile(self, ctx, args, dependency_classpath", "label": 1}, {"snippet_id": 24385, "code": ".station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable", "label": 0}, {"snippet_id": 84353, "code": "(integrates_datatypes_config) metadata_kwds['datatypes_config']=os.path.join(configs_directory, os.path.basename(integrates_datatypes_config)) return metadata_kwds class LwrComputeEnvironment( ComputeEnvironment)", "label": 0}, {"snippet_id": 8431, "code": " document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d", "label": 1}, {"snippet_id": 5421, "code": ") acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"", "label": 0}, {"snippet_id": 6179, "code": " log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares", "label": 1}, {"snippet_id": 37905, "code": " _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log", "label": 0}, {"snippet_id": 37549, "code": " TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item", "label": 0}, {"snippet_id": 40787, "code": " WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their", "label": 0}, {"snippet_id": 37170, "code": ".temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch", "label": 0}, {"snippet_id": 4568, "code": ": dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext", "label": 0}, {"snippet_id": 81646, "code": "\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes():", "label": 1}, {"snippet_id": 40559, "code": " not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance", "label": 0}, {"snippet_id": 23174, "code": " the struct_size, we can't get the information we need. I believe this may be caused by only python i686 being shipped with BIG-IP instead of python x86_64?? \"\"\" iface='' expected=16 python_arc=platform", "label": 0}, {"snippet_id": 93734, "code": ".STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component(node.component) if", "label": 0}, {"snippet_id": 14092, "code": " def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response", "label": 1}, {"snippet_id": 4404, "code": " string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str ", "label": 0}, {"snippet_id": 13284, "code": " not create new branch in the fork\" def autopep8ify(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests", "label": 0}, {"snippet_id": 49216, "code": " def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self,", "label": 0}, {"snippet_id": 9180, "code": ".get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{", "label": 0}, {"snippet_id": 14440, "code": "._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage", "label": 0}, {"snippet_id": 66884, "code": " try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc,", "label": 0}, {"snippet_id": 37988, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output", "label": 0}, {"snippet_id": 55884, "code": " return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 92632, "code": " should be a dir and not a file.') self.assertFalse(os.path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup", "label": 0}, {"snippet_id": 11611, "code": " else: return str(value) class OutputWriter(object): def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with open(self.output_file, 'w') as f: for line in lines", "label": 0}, {"snippet_id": 15132, "code": " vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all", "label": 0}, {"snippet_id": 87057, "code": ".global_instance().create(self.context.products) def __init__(self, *args, **kwargs): super(BaseZincCompile, self).__init__(*args, **kwargs) self._processor_info_dir=os.path.join(self.workdir, 'apt-processor-info'", "label": 0}, {"snippet_id": 94372, "code": "]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1", "label": 0}, {"snippet_id": 6720, "code": " rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted", "label": 0}, {"snippet_id": 41150, "code": " for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self", "label": 0}, {"snippet_id": 81209, "code": ") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \")", "label": 0}, {"snippet_id": 55842, "code": " def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=", "label": 0}, {"snippet_id": 17582, "code": "={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave", "label": 0}, {"snippet_id": 87959, "code": " have in-repo plugins with dependencies(unlike javac, scalac doesn't load plugins or their deps from the regular classpath, so we have to provide these entries separately, in the -Xplugin: flag). Note that", "label": 0}, {"snippet_id": 77054, "code": " def __init__(self, config, *args, **kvargs): super().__init__(*args, **kvargs) self.newproxyfile='newproxies.txt' self.proxylist=set() self.c=config self.threads=[] self.processes=[] self.th_sa='inproc", "label": 0}, {"snippet_id": 70054, "code": " Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre", "label": 0}, {"snippet_id": 95838, "code": " input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion", "label": 0}, {"snippet_id": 20504, "code": " AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed read=recv_as_read(self._sock) for msg, _, _ in read_messages", "label": 0}, {"snippet_id": 311, "code": ": request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon) setServiceDetails", "label": 0}, {"snippet_id": 16252, "code": "._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request", "label": 0}, {"snippet_id": 55473, "code": " else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include", "label": 0}, {"snippet_id": 85047, "code": " `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool('2.10') register_scala_repl_tool", "label": 0}, {"snippet_id": 4543, "code": " composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db:", "label": 1}, {"snippet_id": 77755, "code": ".extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate',[])) if hasattr(self, 'th_sock'): self.th_sock.send_multipart(msg) if hasattr(self, 'pr_sock'): self.pr_sock.send_multipart(msg) def join_threads(self):", "label": 0}, {"snippet_id": 50972, "code": " for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno", "label": 1}, {"snippet_id": 51110, "code": "}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?", "label": 0}, {"snippet_id": 72501, "code": "=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True,", "label": 0}, {"snippet_id": 17883, "code": "( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET", "label": 0}, {"snippet_id": 39323, "code": "\"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir", "label": 0}, {"snippet_id": 20478, "code": "._addr=addr return self def __init__(self, sock, ownsock=False): super(DebugSessionConnection, self).__init__() self._sock=sock self._ownsock=ownsock @property def is_client(self): try: return self._sock", "label": 0}, {"snippet_id": 19354, "code": " def test_url(httpbin): native={ 'origin': '127.0.0.1', 'args':{}, } source=httpbin.url +'/get' result=load_source(source) assert isinstance(result, collections.Mapping) result.pop('headers') result.pop(", "label": 0}, {"snippet_id": 15021, "code": "=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath", "label": 0}, {"snippet_id": 47362, "code": " self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 14337, "code": " filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port", "label": 0}, {"snippet_id": 18393, "code": " _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file", "label": 0}, {"snippet_id": 83846, "code": ".sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return True except OSError, e:", "label": 0}, {"snippet_id": 8697, "code": " as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources", "label": 1}, {"snippet_id": 719, "code": " for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS", "label": 0}, {"snippet_id": 69821, "code": "\"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__", "label": 0}, {"snippet_id": 40021, "code": "\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access", "label": 1}, {"snippet_id": 27248, "code": " None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength", "label": 0}, {"snippet_id": 63353, "code": " job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory'], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution", "label": 0}, {"snippet_id": 50670, "code": ")) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir", "label": 0}, {"snippet_id": 31371, "code": ") self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\")", "label": 0}, {"snippet_id": 14336, "code": "'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr", "label": 0}, {"snippet_id": 20262, "code": " wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script(self, filename, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed')", "label": 0}, {"snippet_id": 42256, "code": " output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input)", "label": 0}, {"snippet_id": 89812, "code": " the path to the command of the given name for this distribution. For example::: >>> d=Distribution() >>> jar=d.binary('jar') >>> jar '/usr/bin/jar' >>> If this distribution has no valid command of the", "label": 0}, {"snippet_id": 66700, "code": "\"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error", "label": 0}, {"snippet_id": 23130, "code": " not support this for future reference. :param chk_err: Whether or not to check for errors raised by the eject command \"\"\" logger.warn(\"Eject is not supported on this platform\") def get_first_if(self):", "label": 0}, {"snippet_id": 68571, "code": ".set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS", "label": 0}, {"snippet_id": 25109, "code": " at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant", "label": 1}, {"snippet_id": 13700, "code": ".iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse", "label": 0}, {"snippet_id": 5668, "code": ": matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the", "label": 0}, {"snippet_id": 44894, "code": ".resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources", "label": 0}, {"snippet_id": 2528, "code": " self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" ", "label": 0}, {"snippet_id": 26562, "code": " elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self", "label": 0}, {"snippet_id": 90143, "code": "(self, name): exe=self._validate_executable(name) yield exe self._validated_binaries[name]=exe def __repr__(self): return('Distribution({!r}, minimum_version={!r}, maximum_version={!r} jdk={!r})'.format", "label": 0}, {"snippet_id": 35729, "code": " def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name", "label": 0}, {"snippet_id": 40835, "code": " values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{", "label": 0}, {"snippet_id": 71956, "code": "): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End", "label": 0}, {"snippet_id": 1972, "code": " processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor", "label": 0}, {"snippet_id": 27213, "code": "'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None", "label": 0}, {"snippet_id": 14184, "code": ".completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification", "label": 0}, {"snippet_id": 79215, "code": " fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t", "label": 0}, {"snippet_id": 75506, "code": "=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method, key, reqid=None): if not reqid", "label": 0}, {"snippet_id": 75055, "code": " handle_evaluate(self, reqid, interface, method, data): domain, page=data self.p.log.info('Recvd page %s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log.info('Done, sending answer: %s", "label": 0}, {"snippet_id": 37214, "code": "._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if", "label": 0}, {"snippet_id": 5227, "code": " html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True", "label": 0}, {"snippet_id": 59798, "code": ".flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend.get_expectation_value(pq.ops.QubitOperator(str(observable)[-1]+'0'", "label": 0}, {"snippet_id": 89466, "code": "): \"\"\"Indicates an invalid java distribution.\"\"\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version", "label": 0}, {"snippet_id": 40371, "code": "') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os", "label": 0}, {"snippet_id": 81495, "code": " \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues", "label": 0}, {"snippet_id": 17484, "code": " CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest", "label": 0}, {"snippet_id": 33987, "code": " snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None)", "label": 0}, {"snippet_id": 2903, "code": " True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL", "label": 0}, {"snippet_id": 44125, "code": "(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule", "label": 0}, {"snippet_id": 84118, "code": " remote_dependency_resolution: return None requirements=job_wrapper.tool.requirements or[] installed_tool_dependencies=job_wrapper.tool.installed_tool_dependencies or[] return dependencies.DependenciesDescription(", "label": 0}, {"snippet_id": 88903, "code": " actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots) def add_new_target(self, address, target_type,", "label": 0}, {"snippet_id": 45334, "code": " 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable", "label": 0}, {"snippet_id": 6953, "code": "\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite", "label": 0}, {"snippet_id": 17822, "code": ".path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data", "label": 0}, {"snippet_id": 74630, "code": " data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config", "label": 0}, {"snippet_id": 36322, "code": " in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items()))", "label": 0}, {"snippet_id": 54988, "code": "( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules", "label": 0}, {"snippet_id": 10750, "code": " expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype:", "label": 1}, {"snippet_id": 93193, "code": "\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum", "label": 0}, {"snippet_id": 47434, "code": "\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads", "label": 0}, {"snippet_id": 60497, "code": "._version import __version__ operator_map={ 'CoherentState': Coherent, 'DisplacedSqueezed': DisplacedSqueezed, 'SqueezedState': Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter", "label": 0}, {"snippet_id": 50028, "code": ": logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if", "label": 0}, {"snippet_id": 10427, "code": " % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field", "label": 0}, {"snippet_id": 69743, "code": " import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler):", "label": 0}, {"snippet_id": 30626, "code": ".output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res", "label": 0}, {"snippet_id": 64395, "code": "{} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd", "label": 0}, {"snippet_id": 50680, "code": " self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths):", "label": 0}, {"snippet_id": 91047, "code": "(self): return self._create_locator() @memoized_property def _normalized_jdk_paths(self): normalized={} jdk_paths=self.get_options().paths or{} for name, paths in sorted(jdk_paths.items()): rename=normalize_os_name", "label": 0}, {"snippet_id": 18643, "code": " UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not", "label": 0}, {"snippet_id": 39760, "code": " ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun", "label": 0}, {"snippet_id": 82705, "code": "\tproxyPass=args.proxy[\"password\"] \tproxyProtocol=args.proxy[\"protocol\"] \tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\":", "label": 0}, {"snippet_id": 70749, "code": " return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other", "label": 0}, {"snippet_id": 62594, "code": " variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)", "label": 0}, {"snippet_id": 30147, "code": "._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items():", "label": 0}, {"snippet_id": 83200, "code": ": transport, 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert", "label": 0}, {"snippet_id": 15594, "code": " extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self)", "label": 0}, {"snippet_id": 75959, "code": "=True raise WorkerInterrupt() def auth_requests(self): for i, m in self.wz_auth_requests: def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Successfull auth", "label": 0}, {"snippet_id": 19251, "code": "=native def test_json_file_object(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.file.seek(0) with open(tmp_file.name)", "label": 0}, {"snippet_id": 54611, "code": "._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self):", "label": 0}, {"snippet_id": 7981, "code": " return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares", "label": 0}, {"snippet_id": 50676, "code": "): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if", "label": 0}, {"snippet_id": 16013, "code": ", handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column", "label": 0}, {"snippet_id": 37661, "code": "=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log))", "label": 0}, {"snippet_id": 60126, "code": "(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items() if state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value]", "label": 0}, {"snippet_id": 5976, "code": ": from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document", "label": 1}, {"snippet_id": 49690, "code": " on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows", "label": 0}, {"snippet_id": 73435, "code": " file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr", "label": 0}, {"snippet_id": 42233, "code": ".nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output)))", "label": 0}, {"snippet_id": 75856, "code": " data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) rs.finished=False rs.retry=False continue return elapsed=t.elapsed(False) if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,[elapsed", "label": 0}, {"snippet_id": 84850, "code": "=scala_build_info[version].full_version) @classmethod def _create_runtime_jardep(cls, version): return cls._create_jardep('scala-library', version) @classmethod def _create_compiler_jardep(cls, version)", "label": 1}, {"snippet_id": 40575, "code": " in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after", "label": 1}, {"snippet_id": 31219, "code": "=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule", "label": 0}, {"snippet_id": 27706, "code": "._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500:", "label": 0}, {"snippet_id": 67724, "code": " target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start", "label": 0}, {"snippet_id": 24953, "code": "'GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state", "label": 0}, {"snippet_id": 20621, "code": ": super(DebugSession, self).__init__() self._conn=conn self._seq=seq self._timeout=timeout self._owned=owned self._handlers=[] for handler in handlers: if callable(handler): self._add_handler(handler) else", "label": 0}, {"snippet_id": 80373, "code": "-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!]", "label": 0}, {"snippet_id": 50629, "code": " Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is", "label": 0}, {"snippet_id": 37169, "code": " branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old)", "label": 0}, {"snippet_id": 45007, "code": ", string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return", "label": 0}, {"snippet_id": 86057, "code": " return False return target.has_sources('.java') def select_source(self, source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath(self.context", "label": 0}, {"snippet_id": 46854, "code": "=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards", "label": 0}, {"snippet_id": 52225, "code": " from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize", "label": 0}, {"snippet_id": 12862, "code": "=headers, auth=auth) with open(\"file_to_fix.py\", 'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore", "label": 0}, {"snippet_id": 6763, "code": "=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None", "label": 0}, {"snippet_id": 39536, "code": ".version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo", "label": 0}, {"snippet_id": 52239, "code": " Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards", "label": 0}, {"snippet_id": 11955, "code": "\"hang-closing\": False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors\": True, } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ", "label": 0}, {"snippet_id": 29011, "code": " self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state", "label": 0}, {"snippet_id": 74320, "code": " overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been", "label": 0}, {"snippet_id": 89159, "code": ".resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets", "label": 0}, {"snippet_id": 95447, "code": " fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"\" Recursive function that automatically downloads all files with a FTP directory, including subdirectories.", "label": 0}, {"snippet_id": 94904, "code": "\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the benchmark run), and config argument for where is the", "label": 0}, {"snippet_id": 2978, "code": " self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\"", "label": 0}, {"snippet_id": 23181, "code": " believe this may be caused by only python i686 being shipped with BIG-IP instead of python x86_64?? \"\"\" iface='' expected=16 python_arc=platform.architecture()[0] if python_arc=='64bit': struct_size=40 else:", "label": 0}, {"snippet_id": 22645, "code": " def useradd(self, username, expiration=None): \"\"\"Create user account using tmsh Our policy is to create two accounts when booting a BIG-IP instance. The first account is the one that the user specified", "label": 1}, {"snippet_id": 10356, "code": " short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float", "label": 0}, {"snippet_id": 35207, "code": " return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually", "label": 0}, {"snippet_id": 16931, "code": " timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post", "label": 1}, {"snippet_id": 37364, "code": "=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names", "label": 0}, {"snippet_id": 57400, "code": ", getattr(t, field), request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return HttpResponse(json.dumps({'rc': 0, 'response'", "label": 0}, {"snippet_id": 65152, "code": ", target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" ", "label": 0}, {"snippet_id": 78661, "code": " BaseException as e: log.logger.exception(e) return -1 return 0 def execute(self): \"\"\"To be overridden by sub classes\"\"\" pass def run(self): try: if self.options is not None and self.options.daemon: log.logger", "label": 1}, {"snippet_id": 13627, "code": " myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\" 2>/dev/null\") time.sleep( 0.5)\r os.system( \"espeak ", "label": 1}, {"snippet_id": 26671, "code": " data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full", "label": 0}, {"snippet_id": 299, "code": " new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address", "label": 0}, {"snippet_id": 53277, "code": "(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input", "label": 0}, {"snippet_id": 51227, "code": ": f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group", "label": 0}, {"snippet_id": 52365, "code": ".ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True", "label": 0}, {"snippet_id": 86323, "code": " workunit.set_outcome(WorkUnit.FAILURE if return_code else WorkUnit.SUCCESS) if return_code: raise TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls,", "label": 0}, {"snippet_id": 14816, "code": " extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script,", "label": 0}, {"snippet_id": 5215, "code": " \"categories\": categories } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output", "label": 0}, {"snippet_id": 17173, "code": " from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification", "label": 0}, {"snippet_id": 54775, "code": "(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun", "label": 0}, {"snippet_id": 31008, "code": "\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 22956, "code": "'/dev'): \"\"\"Find BIG-IP's CD/DVD device This device is almost certainly /dev/cdrom so I added the ? to this pattern. Note that this method will return upon the first device found, but in my tests with 12", "label": 0}, {"snippet_id": 46209, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{", "label": 0}, {"snippet_id": 32603, "code": " dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match", "label": 0}, {"snippet_id": 27551, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise", "label": 0}, {"snippet_id": 66231, "code": "\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name", "label": 0}, {"snippet_id": 72508, "code": ". It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser", "label": 0}, {"snippet_id": 55882, "code": " kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 74203, "code": "\"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input", "label": 0}, {"snippet_id": 29267, "code": " path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise", "label": 0}, {"snippet_id": 95520, "code": "(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp.nlst() file_counter=1 file_list_total=len(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\"", "label": 0}, {"snippet_id": 44250, "code": " IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that", "label": 0}, {"snippet_id": 22800, "code": ":param username: The username whose password to change :param password: The unencrypted password to set for the user :param crypt_id: If encrypting the password, the crypt_id that was used :param salt_len", "label": 0}, {"snippet_id": 79687, "code": " formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2", "label": 0}, {"snippet_id": 72072, "code": " return irc.reply(\"Done. If you want to reconnect this network, use the 'rehash' command.\") control.remove_network(network) @utils.add_cmd def autoconnect(irc, source, args): \"\"\"<network> <seconds> Sets", "label": 0}, {"snippet_id": 77722, "code": ".pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru' and t['forum']", "label": 0}, {"snippet_id": 19247, "code": " result=load_source(source) assert result==native def test_json_file_object(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file", "label": 0}, {"snippet_id": 50509, "code": " ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate", "label": 0}, {"snippet_id": 42867, "code": " protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged", "label": 0}, {"snippet_id": 7196, "code": " reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag=\"001\"", "label": 0}, {"snippet_id": 89405, "code": "\"Represents a java distribution -either a JRE or a JDK installed on the local system. In particular provides access to the distribution's binaries; ie: java while ensuring basic constraints are met. For", "label": 0}, {"snippet_id": 94847, "code": "\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui", "label": 0}, {"snippet_id": 21609, "code": " y_train, y_test=train_test_split(X, y, test_size=0.25, random_state=0) from sklearn.preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test)", "label": 0}, {"snippet_id": 88310, "code": " Task implementations can access configuration data from pants.ini and any flags they have exposed here as well as information about the targets involved in the run. Advanced uses of the context include", "label": 0}, {"snippet_id": 7262, "code": " keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility", "label": 0}, {"snippet_id": 248, "code": "'delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={", "label": 0}, {"snippet_id": 85831, "code": " classpath_product, all_extra_cp_entries, self.DEFAULT_CONFS, ) def compile_classpath(self, classpath_product_key, target, extra_cp_entries=None): \"\"\"Compute the compile classpath for the given target.\"\"\"", "label": 0}, {"snippet_id": 44302, "code": ": globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format", "label": 0}, {"snippet_id": 52481, "code": " try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 32851, "code": "=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict", "label": 0}, {"snippet_id": 10661, "code": ", \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text", "label": 1}, {"snippet_id": 10570, "code": ".popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds", "label": 1}, {"snippet_id": 37027, "code": "._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output", "label": 0}, {"snippet_id": 8126, "code": "(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if", "label": 0}, {"snippet_id": 74633, "code": " runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled", "label": 0}, {"snippet_id": 52480, "code": "\"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 3773, "code": " def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name): window=session.find_where({ \"window_name", "label": 0}, {"snippet_id": 89692, "code": ": `Distribution.Error` if any of the jars could not be found. \"\"\" def collect_existing_libs(): def lib_paths(): yield os.path.join(self.home, 'lib') if self.jdk: yield os.path.join(self.home, 'jre', 'lib", "label": 0}, {"snippet_id": 79882, "code": "\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex", "label": 0}, {"snippet_id": 84557, "code": ".engine.fs import FilesContent, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask from pants.util.contextutil import", "label": 0}, {"snippet_id": 33512, "code": ".target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup", "label": 0}, {"snippet_id": 25932, "code": "] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0", "label": 0}, {"snippet_id": 34364, "code": ".func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version", "label": 0}, {"snippet_id": 79263, "code": "[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None ", "label": 0}, {"snippet_id": 95374, "code": "(ftp_config.directory) file_counter=1 file_list_total=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not", "label": 0}, {"snippet_id": 74213, "code": " ValueError: pass if \"benchmark_data_input\" in runtime_config.benchmark: benchmark_data_input_temp=runtime_config.benchmark[\"benchmark_data_input\"] if benchmark_data_input_temp in benchmark_data_input_types", "label": 0}, {"snippet_id": 78277, "code": "(self.add_comment,(t, msg)) except(exc.Closed, exc.UserDeny) as e: try: self.targets.remove(t) except ValueError: pass self.w.sleep(self.comment_successtimeout) except exc.Captcha as e: self.log.error(", "label": 0}, {"snippet_id": 80950, "code": "\t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself", "label": 0}, {"snippet_id": 18044, "code": " filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response", "label": 0}, {"snippet_id": 33724, "code": " or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled", "label": 0}, {"snippet_id": 51958, "code": ", getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i ", "label": 0}, {"snippet_id": 48621, "code": "): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start", "label": 0}, {"snippet_id": 19968, "code": " is None: addr=adapter.address self._attach(addr, **kwargs) return self._session def detach(self, adapter=None): if self.closed: raise RuntimeError('debug client closed') if self._session is None: raise", "label": 0}, {"snippet_id": 47923, "code": " def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict", "label": 0}, {"snippet_id": 44587, "code": ".needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())", "label": 0}, {"snippet_id": 72502, "code": ".add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help", "label": 0}, {"snippet_id": 72139, "code": " such network \"%s\"(case sensitive).' % netname) return except ValueError: irc.error('Invalid argument \"%s\" for <seconds>.' % seconds) return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\")", "label": 0}, {"snippet_id": 87286, "code": "(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip())) @memoized_property def _zinc_cache_dir(self): \"\"\"A directory where zinc can store compiled copies of the", "label": 1}, {"snippet_id": 71716, "code": ">\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self)", "label": 0}, {"snippet_id": 8875, "code": " and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text", "label": 1}, {"snippet_id": 30307, "code": " getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i >", "label": 0}, {"snippet_id": 8255, "code": "'BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not", "label": 1}, {"snippet_id": 79940, "code": "\"legitExtensions\",nargs=1,help=\"Legit extensions expected, for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n", "label": 0}, {"snippet_id": 26123, "code": " homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity", "label": 0}, {"snippet_id": 30270, "code": " name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start ", "label": 0}, {"snippet_id": 78531, "code": " in forum %s:%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets", "label": 0}, {"snippet_id": 75053, "code": " self.bind_kt=5 def handle_evaluate(self, reqid, interface, method, data): domain, page=data self.p.log.info('Recvd page %s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log.info('Done", "label": 0}, {"snippet_id": 80289, "code": ")s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"", "label": 0}, {"snippet_id": 87235, "code": "\"Override write_extra_resources to produce plugin and annotation processor files.\"\"\" target=compile_context.target if isinstance(target, ScalacPlugin): self._write_scalac_plugin_info(compile_context.classes_dir", "label": 0}, {"snippet_id": 90212, "code": "\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable. :returns: The java distribution location. \"\"\" return cls(home_path=None,", "label": 0}, {"snippet_id": 70028, "code": " import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler", "label": 0}, {"snippet_id": 19588, "code": "-host', '--server-host', '--port', '-m'): if arg=='-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append", "label": 1}, {"snippet_id": 65365, "code": " a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals", "label": 0}, {"snippet_id": 8467, "code": " text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze", "label": 1}, {"snippet_id": 9350, "code": " output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={}", "label": 0}, {"snippet_id": 91311, "code": " SetupPy from pants.backend.python.tasks.unpack_wheels import UnpackWheels from pants.build_graph.build_file_aliases import BuildFileAliases from pants.build_graph.resources import Resources from pants", "label": 0}, {"snippet_id": 90491, "code": " cached version matching the specified constraints :param Revision minimum_version: minimum jvm version to look for(eg, 1.7). :param Revision maximum_version: maximum jvm version to look for(eg, 1.7.9999", "label": 0}, {"snippet_id": 35922, "code": " substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the", "label": 0}, {"snippet_id": 19210, "code": " import six import json import yaml from flex.core import load_source def test_native_mapping_is_passthrough(): source={'foo': 'bar'} result=load_source(source) assert result==source def test_json_string()", "label": 0}, {"snippet_id": 89078, "code": "(self.build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter(predicate, target_set)) def _collect_targets(self, root_targets, **kwargs", "label": 0}, {"snippet_id": 38985, "code": " dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if", "label": 0}, {"snippet_id": 32336, "code": " BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not", "label": 0}, {"snippet_id": 13687, "code": " _safe_globals={\"__builtins__\":None} _safe_locals={} for k in[]: _safe_locals[k]=eval(k) for k, v in np.__dict__.iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count", "label": 1}, {"snippet_id": 26174, "code": ":cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi", "label": 0}, {"snippet_id": 18929, "code": "(source, collections.Mapping): return source elif hasattr(source, 'read') and callable(source.read): raw_source=source.read() elif os.path.exists(os.path.expanduser(str(source))): with open(os.path.expanduser", "label": 0}, {"snippet_id": 40850, "code": ".path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\"", "label": 0}, {"snippet_id": 58600, "code": ".comment) self.assertEqual(self.tester, comments[0].user) class TestUpdateObject(BasePlanCase): \"\"\"Test case for update\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateObject, cls).setUpTestData", "label": 0}, {"snippet_id": 24230, "code": "'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value", "label": 0}, {"snippet_id": 35527, "code": ", however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned", "label": 0}, {"snippet_id": 36242, "code": " try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 81986, "code": "-regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the template in", "label": 0}, {"snippet_id": 49920, "code": ", dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet", "label": 0}, {"snippet_id": 73051, "code": " +remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP] Created local folder:{}\".format(local_path)) except OSError: pass except error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format", "label": 0}, {"snippet_id": 86783, "code": ".replace('$JAVA_HOME', distribution.home) for a in settings.args) zinc_args.extend(settings_args) return zinc_args @classmethod def implementation_version(cls): return super(BaseZincCompile, cls).implementation_version", "label": 0}, {"snippet_id": 61928, "code": "'backend'] for a list of backend options. Functions --------- .. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from", "label": 0}, {"snippet_id": 18376, "code": ".server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed", "label": 0}, {"snippet_id": 12505, "code": " +\"\".join(data[\"extra_results\"][file])) comment_body.append(\"---\\n\\n\") if config[\"only_mention_files_with_errors\"] and not ERROR: comment_body.append(\"Cheers ! There are no PEP8 issues in this Pull Request", "label": 0}, {"snippet_id": 20834, "code": " self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq'] result={'msg': None} def match(msg): if msg.type !=", "label": 0}, {"snippet_id": 66867, "code": "% self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs", "label": 0}, {"snippet_id": 15925, "code": "=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest(", "label": 0}, {"snippet_id": 63424, "code": " raise Exception('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths=job_wrapper.get_output_fnames() return[ str", "label": 0}, {"snippet_id": 25656, "code": "=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 22550, "code": " The problem is that there is nowhere in the UI that specifies the restrictions and checks that tmsh has for the hostname. For example, if you set the name \"bigip1\" in the Web UI, Azure(Stack) considers", "label": 0}, {"snippet_id": 38781, "code": "=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata", "label": 0}, {"snippet_id": 22163, "code": ").__init__(conf) def generate_ansible_playbook_from_template(self, template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader) template", "label": 0}, {"snippet_id": 16538, "code": ".CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data=", "label": 0}, {"snippet_id": 52709, "code": " @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected:", "label": 0}, {"snippet_id": 55546, "code": ".overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule", "label": 0}, {"snippet_id": 37600, "code": " else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified", "label": 0}, {"snippet_id": 70863, "code": ".CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column", "label": 0}, {"snippet_id": 65816, "code": " def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[]", "label": 0}, {"snippet_id": 2592, "code": "'name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends", "label": 0}, {"snippet_id": 95343, "code": " create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username,", "label": 0}, {"snippet_id": 17657, "code": " def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport", "label": 0}, {"snippet_id": 90826, "code": ".Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions are", "label": 0}, {"snippet_id": 15484, "code": " extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self,", "label": 0}, {"snippet_id": 9328, "code": " taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword", "label": 0}, {"snippet_id": 77045, "code": ".comment_successtimeout=0.2 if c.upload_avatar: w.hooks['post_login'].append(upload_avatar) yield w class WipeManager: def __init__(self, config, *args, **kvargs): super().__init__(*args, **kvargs) self", "label": 0}, {"snippet_id": 70307, "code": " system servers.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc", "label": 0}, {"snippet_id": 36869, "code": " \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or self.nooutput", "label": 0}, {"snippet_id": 83132, "code": " to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting", "label": 0}, {"snippet_id": 44903, "code": " RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update", "label": 0}, {"snippet_id": 2051, "code": "['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse", "label": 0}, {"snippet_id": 79156, "code": " +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef", "label": 1}, {"snippet_id": 92269, "code": "(): pass def test_override_single_variable(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): subprocess.Popen([sys.executable, '-c', 'import os; print(os.environ", "label": 0}, {"snippet_id": 10981, "code": " except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except Timeout as e: msg=\"Connect timed out for '%s', error: %s\" %(url", "label": 0}, {"snippet_id": 86943, "code": " dramatically ' 'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if after ' 'running clean-all.') register('", "label": 0}, {"snippet_id": 88709, "code": " parent_workunit_name: workunit_parent_ctx=self.run_tracker.new_workunit_under_parent( name=parent_workunit_name, labels=[WorkUnitLabel.MULTITOOL], parent=background_root_workunit) workunit_parent=workunit_parent_ctx", "label": 0}, {"snippet_id": 39880, "code": ", \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: ", "label": 0}, {"snippet_id": 19486, "code": " return args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index('--') except ValueError: script=[] else: script=argv[pos +1:] argv=argv[:pos] for arg in argv: if arg=='-h", "label": 0}, {"snippet_id": 87267, "code": " processor_info_file=os.path.join(compile_context.classes_dir, _PROCESSOR_INFO_FILE) self._write_processor_info(processor_info_file, target.processors) def _write_processor_info(self, processor_info_file", "label": 0}, {"snippet_id": 2461, "code": " successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name", "label": 0}, {"snippet_id": 94543, "code": " is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name):", "label": 0}, {"snippet_id": 53457, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"", "label": 0}, {"snippet_id": 90028, "code": " classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self.Error('Failed to", "label": 0}, {"snippet_id": 88904, "code": " holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots) def add_new_target(self, address, target_type, target_base", "label": 0}, {"snippet_id": 30103, "code": ": \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr", "label": 0}, {"snippet_id": 36983, "code": " self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name", "label": 0}, {"snippet_id": 68097, "code": " self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support", "label": 1}, {"snippet_id": 14346, "code": "'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'", "label": 0}, {"snippet_id": 71222, "code": ".1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size", "label": 0}, {"snippet_id": 6526, "code": "\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file", "label": 0}, {"snippet_id": 44910, "code": ", resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not", "label": 0}, {"snippet_id": 55527, "code": ")) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd", "label": 0}, {"snippet_id": 28386, "code": ", variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation", "label": 0}, {"snippet_id": 33757, "code": "=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources)", "label": 0}, {"snippet_id": 75713, "code": ".Poller() s=self.ctx.socket(zmq.SUB) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) s.connect(self.sig_addr) s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL') s.setsockopt(zmq.SUBSCRIBE, b'WZWorker", "label": 0}, {"snippet_id": 13021, "code": "\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(url, headers=headers, auth=auth) for repo in r.json(): if repo", "label": 0}, {"snippet_id": 44901, "code": ".resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule", "label": 0}, {"snippet_id": 4012, "code": "(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else:", "label": 0}, {"snippet_id": 65797, "code": "(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic", "label": 0}, {"snippet_id": 51985, "code": "+add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__", "label": 0}, {"snippet_id": 17506, "code": ".PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp", "label": 0}, {"snippet_id": 53647, "code": " for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item,", "label": 0}, {"snippet_id": 52074, "code": ") except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files", "label": 0}, {"snippet_id": 74242, "code": "=config_str_to_bool(runtime_config.benchmark[\"benchmark_allele_count\"]) if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self", "label": 1}, {"snippet_id": 13202, "code": " def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ", "label": 0}, {"snippet_id": 3419, "code": ", filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session:", "label": 0}, {"snippet_id": 50832, "code": "._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be", "label": 0}, {"snippet_id": 48513, "code": " have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if", "label": 0}, {"snippet_id": 64650, "code": " import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException", "label": 0}, {"snippet_id": 50246, "code": ", lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if", "label": 0}, {"snippet_id": 29671, "code": " and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError", "label": 0}, {"snippet_id": 39548, "code": " if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule", "label": 0}, {"snippet_id": 16724, "code": ".format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable", "label": 0}, {"snippet_id": 42785, "code": "\"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be", "label": 0}, {"snippet_id": 50960, "code": " root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self)", "label": 0}, {"snippet_id": 47438, "code": "(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log,", "label": 0}, {"snippet_id": 1246, "code": "\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 88184, "code": " plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile): \"\"\"Compile Scala and Java code to classfiles using Zinc.\"\"\" @classmethod def product_types(cls): return['runtime_classpath',", "label": 0}, {"snippet_id": 64249, "code": "\"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir=remote_job_config[ \"tools_directory\"] version_path=self.local_path_config.version_path() new_version_path=self", "label": 0}, {"snippet_id": 48103, "code": " for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self)", "label": 0}, {"snippet_id": 63595, "code": ", job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args", "label": 0}, {"snippet_id": 27432, "code": "=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module", "label": 0}, {"snippet_id": 93293, "code": ".session_name) else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self", "label": 0}, {"snippet_id": 77763, "code": " hasattr(self, 'th_sock'): self.th_sock.send_multipart(msg) if hasattr(self, 'pr_sock'): self.pr_sock.send_multipart(msg) def join_threads(self): for t in self.threads: t.join() def send_passthrough(self,", "label": 0}, {"snippet_id": 64838, "code": " '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result", "label": 0}, {"snippet_id": 20613, "code": ", conn, seq=1000, handlers=(), timeout=None, owned=False): super(DebugSession, self).__init__() self._conn=conn self._seq=seq self._timeout=timeout self._owned=owned self._handlers=[] for handler in handlers", "label": 0}, {"snippet_id": 32910, "code": ".globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 63025, "code": ": \"\"\"Start the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type", "label": 0}, {"snippet_id": 22191, "code": " return outputText def run(self, state, data=None, context=None): \"\"\"Run ansible-playbook on the specified playbook. \"\"\" playbook=None log_file=None template=None if state in self.conf: if 'playbook' in", "label": 0}, {"snippet_id": 33572, "code": " dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if", "label": 0}, {"snippet_id": 48297, "code": " for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output:", "label": 0}, {"snippet_id": 95756, "code": "(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input", "label": 0}, {"snippet_id": 72418, "code": " the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks", "label": 0}, {"snippet_id": 40910, "code": "(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name", "label": 0}, {"snippet_id": 26864, "code": " elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d", "label": 0}, {"snippet_id": 7611, "code": ":var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword", "label": 0}, {"snippet_id": 36896, "code": " _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake", "label": 0}, {"snippet_id": 79017, "code": ",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder", "label": 0}, {"snippet_id": 90510, "code": " jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None if no matching distribution is in the cache. :rtype::class:`pants.java.distribution.Distribution` \"", "label": 0}, {"snippet_id": 82384, "code": "\t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args", "label": 0}, {"snippet_id": 76099, "code": "{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m])) def set_route_type(self, i, m", "label": 0}, {"snippet_id": 75764, "code": ", repr((interface, method, data))) self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info('Resume", "label": 1}, {"snippet_id": 92032, "code": " check_build_for_current_platform_only(self, targets): \"\"\" Performs a check of whether the current target closure has native sources and if so, ensures that Pants is only targeting the current platform. :param tgts:", "label": 0}, {"snippet_id": 36931, "code": " Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles", "label": 0}, {"snippet_id": 17237, "code": " for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface", "label": 0}, {"snippet_id": 23985, "code": "-000000000000' \"\"\" cmd_search_ide=\"sysctl dev.storvsc | grep pnpinfo | grep deviceid={0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk ", "label": 0}, {"snippet_id": 20947, "code": ".iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message(self, msg): for i, handler in enumerate(list(self", "label": 1}, {"snippet_id": 73566, "code": " print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF", "label": 0}, {"snippet_id": 1916, "code": ": cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io': datasets_io", "label": 0}, {"snippet_id": 89702, "code": ": def lib_paths(): yield os.path.join(self.home, 'lib') if self.jdk: yield os.path.join(self.home, 'jre', 'lib') for name in names: for path in lib_paths(): lib_path=os.path.join(path, name) if os.path", "label": 0}, {"snippet_id": 82782, "code": ".trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName) else: \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath) \tup.setup(args.url) up", "label": 0}, {"snippet_id": 62362, "code": "': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self", "label": 0}, {"snippet_id": 22826, "code": " to do it. \"\"\" cmd=\"/usr/bin/tmsh modify auth user{0} password '{1}'\".format(username, password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed", "label": 0}, {"snippet_id": 36771, "code": "(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self", "label": 0}, {"snippet_id": 63603, "code": " cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote", "label": 0}, {"snippet_id": 55165, "code": " for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag", "label": 0}, {"snippet_id": 54689, "code": ".rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules", "label": 0}, {"snippet_id": 82952, "code": " attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a", "label": 0}, {"snippet_id": 50868, "code": ".access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self", "label": 1}, {"snippet_id": 83454, "code": " for this job. \"\"\" command_line=None client=None remote_job_config=None compute_environment=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup", "label": 0}, {"snippet_id": 93214, "code": "=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes", "label": 0}, {"snippet_id": 17639, "code": " qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self", "label": 0}, {"snippet_id": 59052, "code": ".content, encoding=settings.DEFAULT_CHARSET), expected_json) def test_get_env_properties_by_group(self): response=self.client.get(self.get_info_url, {'info_type': 'env_properties', 'env_group_id': self", "label": 0}, {"snippet_id": 15591, "code": ") SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface", "label": 0}, {"snippet_id": 47815, "code": ".wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow", "label": 0}, {"snippet_id": 44160, "code": " return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules", "label": 0}, {"snippet_id": 26657, "code": "\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=", "label": 0}, {"snippet_id": 94374, "code": "], shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check", "label": 0}, {"snippet_id": 86643, "code": "(classname) @staticmethod def validate_arguments(log, whitelisted_args, args): \"\"\"Validate that all arguments match whitelisted regexes.\"\"\" valid_patterns={re.compile(p): v for p, v in whitelisted_args.items(", "label": 0}, {"snippet_id": 25514, "code": " from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self", "label": 0}, {"snippet_id": 37445, "code": ") if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError", "label": 0}, {"snippet_id": 36584, "code": " job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from", "label": 0}, {"snippet_id": 8567, "code": " % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info", "label": 1}, {"snippet_id": 18234, "code": " for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface", "label": 0}, {"snippet_id": 35464, "code": " _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk", "label": 0}, {"snippet_id": 29361, "code": " snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing", "label": 0}, {"snippet_id": 58579, "code": ".get_for_model(TestCaseRun) for case_run_pk in(self.case_run_1.pk, self.case_run_2.pk): comments=Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self.assertEqual(new_comment, comments", "label": 0}, {"snippet_id": 53751, "code": " inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len", "label": 0}, {"snippet_id": 60452, "code": ", DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix, DisplacedSqueezed, Fock, Ket, Squeezed, Thermal, Gaussian) from", "label": 0}, {"snippet_id": 45297, "code": " return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules", "label": 0}, {"snippet_id": 2628, "code": " component '%s'!\" %(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string", "label": 0}, {"snippet_id": 7538, "code": " output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite", "label": 0}, {"snippet_id": 63991, "code": "\", \"local\", \"remote\"]: raise Exception(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata", "label": 0}, {"snippet_id": 63862, "code": " job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper", "label": 0}, {"snippet_id": 52089, "code": ". Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError", "label": 0}, {"snippet_id": 43802, "code": ") def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self", "label": 0}, {"snippet_id": 45200, "code": ".params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow", "label": 0}, {"snippet_id": 72616, "code": "=\"./data/vcf/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\": output_config_location", "label": 1}, {"snippet_id": 18228, "code": " DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options", "label": 0}, {"snippet_id": 64272, "code": "): local_output_paths=self._wrapper_output_paths results=[] for local_output_path in local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite( wrapper_path", "label": 0}, {"snippet_id": 62149, "code": " wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in", "label": 0}, {"snippet_id": 69112, "code": " status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print", "label": 1}, {"snippet_id": 53788, "code": " TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item", "label": 0}, {"snippet_id": 60865, "code": "._current_context is None: Device._current_context=self self.reset() else: raise DeviceError('Only one device can be active at a time.') return self def __exit__(self, exc_type, exc_value, tb): if self", "label": 0}, {"snippet_id": 30459, "code": " WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if", "label": 0}, {"snippet_id": 46098, "code": ".group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand", "label": 0}, {"snippet_id": 14223, "code": " SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( ", "label": 0}, {"snippet_id": 42984, "code": " in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item", "label": 0}, {"snippet_id": 39649, "code": " message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo", "label": 0}, {"snippet_id": 86426, "code": ", division, print_function, unicode_literals import errno import logging import os import re import textwrap from builtins import open from collections import defaultdict from contextlib import closing", "label": 0}, {"snippet_id": 94116, "code": "(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\")", "label": 0}, {"snippet_id": 40817, "code": "{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns", "label": 0}, {"snippet_id": 82359, "code": "): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use", "label": 0}, {"snippet_id": 60094, "code": ": probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value", "label": 0}, {"snippet_id": 55724, "code": ".resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources", "label": 0}, {"snippet_id": 58569, "code": " encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct=ContentType.objects.get_for_model(TestCaseRun) for case_run_pk in(self.case_run_1.pk, self.case_run_2.pk): comments=Comment.objects", "label": 0}, {"snippet_id": 74087, "code": "(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and", "label": 0}, {"snippet_id": 71590, "code": " RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname", "label": 0}, {"snippet_id": 39127, "code": "=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(", "label": 0}, {"snippet_id": 90145, "code": "._validate_executable(name) yield exe self._validated_binaries[name]=exe def __repr__(self): return('Distribution({!r}, minimum_version={!r}, maximum_version={!r} jdk={!r})'.format( self._bin_path, self", "label": 0}, {"snippet_id": 19405, "code": ", '--multiproc', '--multiprocess', '--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST", "label": 0}, {"snippet_id": 1707, "code": ".POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action", "label": 0}, {"snippet_id": 20833, "code": ": if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq'] result={'msg': None} def match(msg): if msg.type", "label": 0}, {"snippet_id": 60062, "code": " backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable", "label": 0}, {"snippet_id": 75504, "code": "=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method, key", "label": 0}, {"snippet_id": 43882, "code": " return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException", "label": 0}, {"snippet_id": 51262, "code": " \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match", "label": 0}, {"snippet_id": 77647, "code": ".debug('Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set", "label": 0}, {"snippet_id": 64142, "code": "), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home", "label": 0}, {"snippet_id": 62192, "code": ".backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return super().__repr__(", "label": 0}, {"snippet_id": 50226, "code": " snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None)", "label": 0}, {"snippet_id": 60107, "code": "['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state", "label": 0}, {"snippet_id": 421, "code": "=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST", "label": 0}, {"snippet_id": 23343, "code": " as shellutil import azurelinuxagent.common.utils.textutil as textutil import azurelinuxagent.common.logger as logger from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common", "label": 0}, {"snippet_id": 62356, "code": " self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable", "label": 0}, {"snippet_id": 88967, "code": ".source_roots.find_by_path(rel_target_base): self.source_roots.add_source_root(rel_target_base) if dependencies: dependencies=[dep.address for dep in dependencies] self.build_graph.inject_synthetic_target(address", "label": 0}, {"snippet_id": 92170, "code": "', advanced=True, fingerprint=True, default='40.6.3', help='The setuptools version to use when executing `setup.py` scripts.') register('--wheel-version', advanced=True, fingerprint=True, default='0.32", "label": 0}, {"snippet_id": 61421, "code": "._state=np.zeros(2**self.wires, dtype=complex) self._state[0]=1 self._out=np.full(self.wires, np.nan) for operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]", "label": 0}, {"snippet_id": 43718, "code": ".rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence", "label": 0}, {"snippet_id": 28954, "code": "] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status']", "label": 0}, {"snippet_id": 63840, "code": "%s\" %(lwr_url, job_id)) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck in the queued/running state when Galaxy started", "label": 0}, {"snippet_id": 25125, "code": " homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from homeassistant.helpers.entity import Entity", "label": 0}, {"snippet_id": 67660, "code": " LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s", "label": 0}, {"snippet_id": 78176, "code": " WipeState, cstate from beon import exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums", "label": 0}, {"snippet_id": 2845, "code": ". comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is", "label": 0}, {"snippet_id": 68229, "code": " return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state=", "label": 0}, {"snippet_id": 55178, "code": ".subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input", "label": 0}, {"snippet_id": 55036, "code": ".cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error", "label": 0}, {"snippet_id": 52080, "code": " yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml", "label": 0}, {"snippet_id": 4445, "code": " from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output", "label": 0}, {"snippet_id": 69343, "code": ".__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print ", "label": 0}, {"snippet_id": 69569, "code": " new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException", "label": 0}, {"snippet_id": 67433, "code": " \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return", "label": 0}, {"snippet_id": 61627, "code": ".shape !=(2, 2): raise ValueError('2x2 matrix required.') A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing", "label": 0}, {"snippet_id": 70370, "code": ": mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh", "label": 0}, {"snippet_id": 81332, "code": "\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True \t\t\t\tif self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()", "label": 0}, {"snippet_id": 85608, "code": "._zinc_factory=zinc_factory self._products=products @memoized_property def zinc(self): \"\"\"Return the Zinc wrapper compiler classpath. :rtype: list of str \"\"\" return self._zinc_factory._zinc(self._products)", "label": 0}, {"snippet_id": 64792, "code": " fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname()", "label": 0}, {"snippet_id": 47025, "code": ": \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule)", "label": 0}, {"snippet_id": 1924, "code": ": row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads", "label": 0}, {"snippet_id": 50751, "code": ".harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import", "label": 1}, {"snippet_id": 79744, "code": " Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).", "label": 0}, {"snippet_id": 42999, "code": " item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name", "label": 0}, {"snippet_id": 10357, "code": " version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100", "label": 0}, {"snippet_id": 22680, "code": " to the system. :param username: The username that you want to add to the system :param expiration: The expiration date to use. We do not use this value. \"\"\" if self.get_userentry(username): logger.info(", "label": 0}, {"snippet_id": 49678, "code": " the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can", "label": 0}, {"snippet_id": 80868, "code": "'%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints", "label": 0}, {"snippet_id": 29031, "code": " elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station)", "label": 0}, {"snippet_id": 20029, "code": ": try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start(*args,", "label": 0}, {"snippet_id": 41459, "code": ".ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() }", "label": 0}, {"snippet_id": 75262, "code": ", method): del self.sig_handlers[(interface, method)] def _parse_req(self, iden, msg, reqid, interface, method): try: handler=self.req_handlers[(interface, method)] except KeyError: try: handler=self.req_handlers", "label": 0}, {"snippet_id": 7294, "code": " marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"", "label": 0}, {"snippet_id": 45356, "code": " Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in", "label": 1}, {"snippet_id": 11354, "code": ".target_dir or not os.path.isdir(self.target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using", "label": 0}, {"snippet_id": 15886, "code": " self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync", "label": 0}, {"snippet_id": 93859, "code": "=(\"ssh %s 'hyperion --config %s/%s.yaml slave'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def check_component(self, comp): return", "label": 1}, {"snippet_id": 74374, "code": "\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def", "label": 0}, {"snippet_id": 27731, "code": "'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self", "label": 0}, {"snippet_id": 20544, "code": ".closed write=send_as_write(self._sock) body=json.dumps(req) write_message(write, body, stop=stop) def _close(self): if self._ownsock: close(self._sock) class DebugSession(Closeable): VERBOSE=False HOST", "label": 0}, {"snippet_id": 12388, "code": "\"message\"][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]: comment_body.append( ", "label": 0}, {"snippet_id": 21640, "code": " import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors import ListedColormap X_set, y_set=X_train, y_train X1, X2=np.meshgrid(np.arange(start=X_set[:, 0].min() -1, stop=X_set", "label": 0}, {"snippet_id": 44102, "code": "(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules)", "label": 0}, {"snippet_id": 56106, "code": ".workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths]", "label": 0}, {"snippet_id": 87617, "code": " snapshots=[ self._zinc.snapshot(self.context._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry", "label": 1}, {"snippet_id": 78460, "code": " in self.forums: targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain,", "label": 0}, {"snippet_id": 4703, "code": " list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k", "label": 0}, {"snippet_id": 60954, "code": " def capabilities(cls): \"\"\"Get the other capabilities of the plugin. Measurements, batching etc. Returns: dict[str->*]: results \"\"\" return cls._capabilities @abc.abstractmethod def execute(self): \"\"\"Apply", "label": 1}, {"snippet_id": 70175, "code": " strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre", "label": 0}, {"snippet_id": 94512, "code": " Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else:", "label": 0}, {"snippet_id": 84339, "code": " 'datatypes_conf.xml') metadata_kwds['datatypes_config']=remote_datatypes_config else: integrates_datatypes_config=self.app.datatypes_registry.integrated_datatypes_configs job_wrapper.extra_filenames.append", "label": 0}, {"snippet_id": 2546, "code": " group '%s' on host '%s'\" % (comp['name'], group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']", "label": 0}, {"snippet_id": 86675, "code": " 2 if has_argument else 1 log.warn(\"Zinc argument '{}' is not supported, and is subject to change/removal!\".format(arg)) return 1 arg_index=0 while arg_index < len(args): arg_index +=validate(arg_index", "label": 0}, {"snippet_id": 15455, "code": "...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self", "label": 0}, {"snippet_id": 28364, "code": "(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append", "label": 1}, {"snippet_id": 65999, "code": ".append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(", "label": 0}, {"snippet_id": 84276, "code": "(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory=remote_job_config['outputs_directory'] configs_directory=remote_job_config['configs_directory'] working_directory=remote_job_config", "label": 0}, {"snippet_id": 50076, "code": " overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1])", "label": 0}, {"snippet_id": 87895, "code": " scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret=[] for name, cp_entries in plugin_jar_map.items(): ret.append('-S-Xplugin:{}'.format('", "label": 0}, {"snippet_id": 45016, "code": " def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=", "label": 0}, {"snippet_id": 15388, "code": "/localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self", "label": 0}, {"snippet_id": 61813, "code": " temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT", "label": 0}, {"snippet_id": 47471, "code": " except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources", "label": 0}, {"snippet_id": 55861, "code": ", **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return", "label": 0}, {"snippet_id": 63893, "code": ") is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self)", "label": 0}, {"snippet_id": 40529, "code": ", str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value", "label": 0}, {"snippet_id": 86353, "code": " in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _execute_hermetic_compile", "label": 0}, {"snippet_id": 67868, "code": " \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes", "label": 0}, {"snippet_id": 77844, "code": ".load_targets() self.load_users() self.spawn_wipethreads() if self.c.ecount > 0: self.spawn_evaluators() try: while self.running.is_set(): if self.c.tcount==0: self.inter_sleep(5) continue self.pc.check_waiting", "label": 0}, {"snippet_id": 29378, "code": " wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing,", "label": 1}, {"snippet_id": 12984, "code": "\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]", "label": 0}, {"snippet_id": 73918, "code": ", runtime_config=None): \"\"\" Creates an object representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type", "label": 0}, {"snippet_id": 88122, "code": ": plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag !='plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return", "label": 0}, {"snippet_id": 2702, "code": "%(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"'", "label": 0}, {"snippet_id": 89980, "code": " return execute_java_async(*args, distribution=self, **kwargs) @memoized_method def _get_version(self, java): return _parse_java_version('java.version', self._get_system_properties(java)['java.version'", "label": 0}, {"snippet_id": 46393, "code": " if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self,", "label": 0}, {"snippet_id": 8036, "code": " component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0", "label": 0}, {"snippet_id": 31918, "code": "._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output", "label": 0}, {"snippet_id": 54075, "code": ".name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input", "label": 0}, {"snippet_id": 87018, "code": ": \"\"\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. \"\"\" return self.get_options", "label": 0}, {"snippet_id": 60140, "code": "(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self", "label": 0}, {"snippet_id": 72838, "code": ":type path: str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified", "label": 0}, {"snippet_id": 15108, "code": " response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data", "label": 0}, {"snippet_id": 61065, "code": "=np.array([[1, 0, 0, 0],[0, 1, 0, 0],[0, 0, 0, 1],[0, 0, 1, 0]]) SWAP=np.array([[1, 0, 0, 0],[0, 0, 1, 0],[0, 1, 0, 0],[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta", "label": 0}, {"snippet_id": 89443, "code": " version forward. :API: public TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"", "label": 0}, {"snippet_id": 13047, "code": " if data[\"target_repo_fullname\"] in repo[\"description\"]: FORKED=True r=requests.delete(\"https://api.github.com/repos/\" \"{}\".format(repo[\"full_name\"]), headers=headers, auth=auth) return FORKED def fork_for_pr", "label": 0}, {"snippet_id": 42558, "code": " in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch", "label": 0}, {"snippet_id": 23156, "code": " management interface. We need to add a struct_size check here because, curiously, our 64bit platform is identified by python in Azure(Stack) as 32 bit and without adjusting the struct_size, we can't get", "label": 0}, {"snippet_id": 28922, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] ", "label": 0}, {"snippet_id": 18032, "code": "': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data", "label": 0}, {"snippet_id": 58499, "code": " {'rc': 1, 'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self", "label": 0}, {"snippet_id": 20129, "code": ": \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session", "label": 0}, {"snippet_id": 54632, "code": " clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None", "label": 0}, {"snippet_id": 2186, "code": " wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e'", "label": 0}, {"snippet_id": 43522, "code": ".name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames))", "label": 0}, {"snippet_id": 22103, "code": "=self.variable_manager, host_list='/etc/ansible/hosts' ) self.variable_manager.set_inventory(self.inventory) pb_dir=os.path.abspath('.') playbook_path=\"%s/%s\" %(pb_dir, playbook) display.verbosity=self", "label": 1}, {"snippet_id": 61783, "code": "(wires) b=np.max(wires) n_between=b-a-1 before =2**a after =2**(self.wires-b-1) between=2**n_between U=np.kron(U, np.eye(between)) if wires[0] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between", "label": 0}, {"snippet_id": 46861, "code": "=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow", "label": 0}, {"snippet_id": 30276, "code": " name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start", "label": 0}, {"snippet_id": 30580, "code": " jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag", "label": 0}, {"snippet_id": 19611, "code": "): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv): parser=argparse", "label": 1}, {"snippet_id": 72848, "code": " exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if", "label": 0}, {"snippet_id": 74384, "code": " zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False", "label": 0}, {"snippet_id": 47481, "code": " IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name", "label": 0}, {"snippet_id": 82128, "code": " exclusiveVerbosityArgs.add_argument(\"-vv\",action=\"store_true\",required=False,dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose", "label": 0}, {"snippet_id": 78073, "code": " def rffu(urls): for user, domain, forum in r_udf.findall(urls): if len(forum) > 0: get_forum_id(forum) logger.info('Removing %s:%s from forums[%s]', user, forum, domain) forums[domain].remove((user, forum", "label": 0}, {"snippet_id": 92145, "code": " for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires-pex' @classmethod def register_options(cls, register): super(BuildSetupRequiresPex, cls", "label": 0}, {"snippet_id": 34858, "code": "(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__", "label": 0}, {"snippet_id": 33297, "code": " targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 271, "code": "-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt", "label": 0}, {"snippet_id": 73610, "code": "\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path", "label": 1}, {"snippet_id": 41296, "code": " JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" ", "label": 0}, {"snippet_id": 62604, "code": " for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args:", "label": 0}, {"snippet_id": 49241, "code": ": \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno", "label": 0}, {"snippet_id": 25758, "code": "'min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=", "label": 0}, {"snippet_id": 90516, "code": " have a jdk. :return: the Distribution, or None if no matching distribution is in the cache. :rtype::class:`pants.java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version", "label": 0}, {"snippet_id": 52637, "code": " def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"", "label": 0}, {"snippet_id": 49403, "code": " jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False,", "label": 0}, {"snippet_id": 67345, "code": " fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes,", "label": 0}, {"snippet_id": 91062, "code": ", paths in sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to \"{}\"; combining results.'.format(rename)) normalized[rename].extend", "label": 0}, {"snippet_id": 42913, "code": "\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified", "label": 0}, {"snippet_id": 83649, "code": ", env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params job_id=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client", "label": 0}, {"snippet_id": 50742, "code": "\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]), path)", "label": 0}, {"snippet_id": 35476, "code": "() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re", "label": 0}, {"snippet_id": 54577, "code": " self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules(", "label": 0}, {"snippet_id": 72885, "code": ".FTPConfigurationRepresentation :type local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree(local_directory) if ftp_config.use_tls: ftp=FTP_TLS(ftp_config.server) ftp.login(ftp_config.username", "label": 0}, {"snippet_id": 56696, "code": ": \"\"\" Used for getting the chosen object(TestPlan, TestCase or TestRun) from the database \"\"\" def __init__(self, request): \"\"\" :param request: An HTTP GET request, containing the primary key and the type", "label": 0}, {"snippet_id": 79625, "code": ").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES", "label": 0}, {"snippet_id": 29069, "code": " all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self", "label": 1}, {"snippet_id": 77867, "code": ".read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except WorkerInterrupt: pass except Exception as e: self.log.exception(e) self.terminate() self.join_threads() if self.c.tcount", "label": 0}, {"snippet_id": 63742, "code": "[0].job_runner_external_pid if pid in[ None, '']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job", "label": 0}, {"snippet_id": 60504, "code": ", 'SqueezedState': Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'QuadraticPhase'", "label": 0}, {"snippet_id": 2603, "code": ".nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error", "label": 0}, {"snippet_id": 25633, "code": "\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state", "label": 0}, {"snippet_id": 28808, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self", "label": 0}, {"snippet_id": 59662, "code": "'Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for", "label": 0}, {"snippet_id": 88684, "code": " in the run tracker's daemon stats object.\"\"\" target_count=len(self.build_graph) self.run_tracker.pantsd_stats.set_affected_targets_size(target_count) return target_count def submit_background_work_chain", "label": 0}, {"snippet_id": 51230, "code": " for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError", "label": 0}, {"snippet_id": 26673, "code": "=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp", "label": 0}, {"snippet_id": 29581, "code": " _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple", "label": 0}, {"snippet_id": 84490, "code": " working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self", "label": 0}, {"snippet_id": 70204, "code": ": def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 19021, "code": " set(), } swagger_definitions=definitions_validator(raw_schema, context=context) swagger_schema=swagger_schema_validator( raw_schema, context=swagger_definitions, ) return swagger_schema def load(target", "label": 0}, {"snippet_id": 91114, "code": ",()) def _create_locator(self): homes=self._get_explicit_jdk_paths() environment=_UnknownEnvironment( _ExplicitEnvironment(*homes), _UnknownEnvironment( _EnvVarEnvironment(), _LinuxEnvironment.standard", "label": 0}, {"snippet_id": 35155, "code": " return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag", "label": 1}, {"snippet_id": 60746, "code": " of the inheriting class.\"\"\" def __getattr__(cls, name): \"\"\"Get the attribute call via name\"\"\" def new_object(*args, **kwargs): \"\"\"Return a new object of the same class, passing the attribute name as the", "label": 0}, {"snippet_id": 1140, "code": "'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset", "label": 0}, {"snippet_id": 34905, "code": " given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for", "label": 0}, {"snippet_id": 48723, "code": "(f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if", "label": 0}, {"snippet_id": 37177, "code": ".discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict", "label": 0}, {"snippet_id": 53433, "code": " branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch", "label": 0}, {"snippet_id": 6219, "code": " text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W", "label": 1}, {"snippet_id": 44776, "code": "): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder", "label": 0}, {"snippet_id": 57464, "code": ".POST.get('target_field') self.new_value=request.POST.get('new_value') def get_update_action(self): return getattr(self, '_update_%s' % self.target_field, None) def update(self): has_perms=check_permission", "label": 0}, {"snippet_id": 54733, "code": "._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule", "label": 0}, {"snippet_id": 64000, "code": " dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False)", "label": 0}, {"snippet_id": 41031, "code": "\"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name,", "label": 0}, {"snippet_id": 10718, "code": "[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if", "label": 1}, {"snippet_id": 22332, "code": " happens in mcpd so we need to wait that this is available before we go provisioning the system. I call this method at the first opportunity I have(during the DVD mounting call). This ensures that the rest", "label": 0}, {"snippet_id": 48614, "code": " ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete", "label": 0}, {"snippet_id": 86518, "code": " get_buildroot from pants.base.exceptions import TaskError from pants.base.hash_utils import hash_file from pants.base.workunit import WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize, PathGlobs,", "label": 0}, {"snippet_id": 56329, "code": "(request): \"\"\"Ajax responder for misc information\"\"\" objects=_InfoObjects(request=request, product_id=request.GET.get('product_id')) info_type=getattr(objects, request.GET.get('info_type')) if not info_type", "label": 0}, {"snippet_id": 69291, "code": " %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self", "label": 1}, {"snippet_id": 81541, "code": ") \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t", "label": 0}, {"snippet_id": 44013, "code": ", list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata", "label": 0}, {"snippet_id": 45877, "code": ".escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match):", "label": 0}, {"snippet_id": 1611, "code": ",wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"", "label": 0}, {"snippet_id": 74402, "code": "(value) return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name", "label": 0}, {"snippet_id": 2946, "code": " if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp)", "label": 0}, {"snippet_id": 84931, "code": " register_style_tool(version): cls.register_jvm_tool(register, cls._key_for_tool_version('scalastyle', version), classpath=[scala_style_jar]) super(ScalaPlatform, cls).register_options(register) register('-", "label": 1}, {"snippet_id": 40254, "code": "(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def", "label": 0}, {"snippet_id": 21045, "code": "): return msg, False lock.release() return msg, True self._add_handler(handler, handlername) try: yield finally: wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle(self, match", "label": 0}, {"snippet_id": 766, "code": "': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getThreads': print(action) rows=[]", "label": 0}, {"snippet_id": 7811, "code": "(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires", "label": 0}, {"snippet_id": 9904, "code": " single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]}", "label": 0}, {"snippet_id": 26713, "code": " self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 34300, "code": "=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 64495, "code": "(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(", "label": 0}, {"snippet_id": 70440, "code": " and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration", "label": 0}, {"snippet_id": 56593, "code": "=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk'", "label": 0}, {"snippet_id": 6293, "code": " %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log", "label": 1}, {"snippet_id": 29594, "code": ".group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.", "label": 0}, {"snippet_id": 62597, "code": "*2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value", "label": 0}, {"snippet_id": 17416, "code": " vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return", "label": 0}, {"snippet_id": 9357, "code": " composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p", "label": 0}, {"snippet_id": 80213, "code": "): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use", "label": 0}, {"snippet_id": 48362, "code": " item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or", "label": 0}, {"snippet_id": 22893, "code": " to set password for 'admin':{0}\".format(output) ) self._save_sys_config() return ret def del_account(self, username): \"\"\"Deletes a user account. Note that the default method also checks for a \"system level", "label": 0}, {"snippet_id": 64902, "code": "=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir(", "label": 0}, {"snippet_id": 6485, "code": "=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms )", "label": 0}, {"snippet_id": 18411, "code": "-NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not", "label": 0}, {"snippet_id": 56805, "code": " either a:class:`tcms.testplans.models.TestPlan`, a:class:`tcms.testcases.models.TestCase` or a:class:`tcms.testruns.models.TestRun` :param tag_name: The name of the tag to be manipulated :type tag_name", "label": 0}, {"snippet_id": 61816, "code": "=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1", "label": 0}, {"snippet_id": 87283, "code": " processors): with safe_open(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip())) @memoized_property def _zinc_cache_dir(self): \"\"\"A directory where zinc", "label": 1}, {"snippet_id": 7025, "code": " formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned", "label": 0}, {"snippet_id": 91388, "code": "-dists', action=BuildLocalPythonDistributions).install('pyprep') task(name='requirements', action=ResolveRequirements).install('pyprep') task(name='sources', action=GatherSources).install('pyprep') task", "label": 0}, {"snippet_id": 75300, "code": ".iden_reqid_map.add_value(tuple(iden), reqid) handler(reqid, interface, method, msg[1:]) return() def _parse_rep(self, iden, msg, reqid, seqnum, status): try: handler=self.response_handlers[reqid] if seqnum", "label": 0}, {"snippet_id": 51373, "code": ": if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v", "label": 0}, {"snippet_id": 84293, "code": "(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir", "label": 0}, {"snippet_id": 31764, "code": ".discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict", "label": 0}, {"snippet_id": 59524, "code": "(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate", "label": 0}, {"snippet_id": 44516, "code": ", cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds", "label": 0}, {"snippet_id": 25832, "code": "\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] ", "label": 0}, {"snippet_id": 64675, "code": " Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start", "label": 0}, {"snippet_id": 93500, "code": ".append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style", "label": 0}, {"snippet_id": 15832, "code": " 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger", "label": 0}, {"snippet_id": 554, "code": ") if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3", "label": 0}, {"snippet_id": 11359, "code": ".target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(", "label": 0}, {"snippet_id": 69854, "code": "{ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return", "label": 0}, {"snippet_id": 62997, "code": " but LWR is not configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name", "label": 0}, {"snippet_id": 56454, "code": ".all() def env_properties(self): if self.request.GET.get('env_group_id'): return EnvGroup.objects.get(id=self.request.GET['env_group_id']).property.all() return EnvProperty.objects.all() def env_values", "label": 0}, {"snippet_id": 51875, "code": " get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names", "label": 0}, {"snippet_id": 34152, "code": "=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return", "label": 0}, {"snippet_id": 15120, "code": " except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}", "label": 0}, {"snippet_id": 22023, "code": " self.become_user=become_user self.become_ask_pass=become_ask_pass self.ask_pass=ask_pass self.private_key_file=private_key_file self.remote_user=remote_user self.connection=connection self.timeout=timeout", "label": 0}, {"snippet_id": 34586, "code": "(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError", "label": 0}, {"snippet_id": 12994, "code": " url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED", "label": 0}, {"snippet_id": 17045, "code": ".line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture", "label": 0}, {"snippet_id": 32807, "code": ".shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary", "label": 1}, {"snippet_id": 9322, "code": " composite_keywords: list of composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of", "label": 0}, {"snippet_id": 45110, "code": " resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 60785, "code": "\"Exception raised by a:class:`Device` when it encounters an illegal operation in the quantum circuit. \"\"\" pass class Device(abc.ABC): \"\"\"Abstract base class for devices.\"\"\" _current_context=None name='", "label": 0}, {"snippet_id": 78057, "code": " get_forum_id(forum) logger.info('Appending %s:%s to forums[%s]', user, forum, domain) forums[domain].add((user, forum)) def rffu(urls): for user, domain, forum in r_udf.findall(urls): if len(forum) > 0", "label": 0}, {"snippet_id": 88, "code": " version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0", "label": 0}, {"snippet_id": 92679, "code": "(path) def test_temporary_dir_with_root_dir(self): with temporary_dir() as path1: with temporary_dir(root_dir=path1) as path2: self.assertTrue(os.path.realpath(path2).startswith(os.path.realpath(path1)", "label": 0}, {"snippet_id": 8715, "code": ", output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False,", "label": 0}, {"snippet_id": 89792, "code": ": \"\"\"Returns the path to this distribution's java command. If this distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the", "label": 0}, {"snippet_id": 4188, "code": "=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines", "label": 0}, {"snippet_id": 22278, "code": ".shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger as logger", "label": 0}, {"snippet_id": 17381, "code": "'http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self):", "label": 0}, {"snippet_id": 25214, "code": "], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS", "label": 0}, {"snippet_id": 20954, "code": " self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message(self, msg): for i, handler in enumerate(list(self._handlers)): handle_message, _, _=handler handled", "label": 1}, {"snippet_id": 11430, "code": ") output_writer.write_lines(lines) @staticmethod def create_filename(hostname): name='%s.cfg' % hostname if name !=os.path.basename(name): msg=\"Directory traversal attempt detected for host name %r\" raise", "label": 0}, {"snippet_id": 6713, "code": " be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords,", "label": 0}, {"snippet_id": 22754, "code": " user's password with tmsh Since we are creating the user specified account and additionally changing the password of the built-in 'admin' account, both must be modified in this method. Note that the default", "label": 0}, {"snippet_id": 55588, "code": "): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given", "label": 0}, {"snippet_id": 16857, "code": " from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor(", "label": 0}, {"snippet_id": 24636, "code": " data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full", "label": 0}, {"snippet_id": 34895, "code": "+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing", "label": 0}, {"snippet_id": 49043, "code": " WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import", "label": 1}, {"snippet_id": 11073, "code": " return yaml_config, Header(etag=etag, mtime=mtime) class Header(object): MON_CONF_GEN_COMMENT=' ETAG_COMMENT=' MTIME_COMMMENT=' def __init__(self, etag=None, mtime=0): self.etag=etag self.mtime=int(mtime", "label": 0}, {"snippet_id": 32952, "code": "._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file", "label": 0}, {"snippet_id": 35792, "code": "(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist", "label": 0}, {"snippet_id": 23450, "code": "} -m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode !=0: raise OSUtilError((\"Failed to create user account:{0}, \" \"retcode", "label": 0}, {"snippet_id": 77168, "code": " backward socket %s', self.pr_ba) self.pr_back_sock=self.p.ctx.socket(zmq.ROUTER) self.pr_back_sock.bind(self.pr_ba) def read_newproxies(self): if not os.path.isfile(self.newproxyfile): return newproxies=set", "label": 0}, {"snippet_id": 44592, "code": " resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len", "label": 0}, {"snippet_id": 77741, "code": "['forum']=='anonymous': try: add_target_exc(t['id'], t['user']) except ValueError: pass def terminate(self): msg=[b'GLOBAL'] msg.extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate',[])) if hasattr(self", "label": 0}, {"snippet_id": 57087, "code": " contenttype. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value", "label": 0}, {"snippet_id": 23432, "code": ".get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None: cmd=\"pw useradd{0} -e{1} -m\".format(username, expiration", "label": 0}, {"snippet_id": 45929, "code": " WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self", "label": 0}, {"snippet_id": 19897, "code": " attach_pid(self, pid, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError", "label": 0}, {"snippet_id": 62069, "code": ") num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the measurement result being registered(at the end of the circuit)", "label": 0}, {"snippet_id": 16241, "code": "') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface", "label": 0}, {"snippet_id": 42229, "code": " always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( ", "label": 0}, {"snippet_id": 6258, "code": "=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file", "label": 1}, {"snippet_id": 5059, "code": " code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[", "label": 0}, {"snippet_id": 89787, "code": " @property def java(self): \"\"\"Returns the path to this distribution's java command. If this distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self", "label": 0}, {"snippet_id": 33385, "code": ") return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory", "label": 0}, {"snippet_id": 38954, "code": "=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected", "label": 0}, {"snippet_id": 57933, "code": " comment, request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data={} try: data[", "label": 0}, {"snippet_id": 53494, "code": " input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self", "label": 0}, {"snippet_id": 83514, "code": "( working_directory=remote_job_config['working_directory'], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata", "label": 0}, {"snippet_id": 22869, "code": " was not found!\") cmd=\"/usr/bin/tmsh modify auth user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed", "label": 0}, {"snippet_id": 60391, "code": " i in operation.wires] self.state=self.eng.run('fock', cutoff_dim=self.cutoff) reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name=='X': ex", "label": 0}, {"snippet_id": 91416, "code": "'run') task(name='pytest-prep', action=PytestPrep).install('test') task(name='pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install('repl') task(name='setup-py', action=SetupPy", "label": 0}, {"snippet_id": 32408, "code": " wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, ", "label": 0}, {"snippet_id": 10202, "code": " return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return", "label": 0}, {"snippet_id": 3305, "code": "=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started", "label": 0}, {"snippet_id": 69039, "code": " target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status", "label": 0}, {"snippet_id": 90917, "code": " distribution could be found. \"\"\" try: return cls.global_instance()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error", "label": 0}, {"snippet_id": 70398, "code": " result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes", "label": 0}, {"snippet_id": 46892, "code": "=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set", "label": 0}, {"snippet_id": 29955, "code": " combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards", "label": 0}, {"snippet_id": 49604, "code": "=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata", "label": 0}, {"snippet_id": 29722, "code": "(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value", "label": 0}, {"snippet_id": 41071, "code": "): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name", "label": 0}, {"snippet_id": 92754, "code": ") self.assertTrue(t.finish is None) self.assertGreater(t.elapsed, 0.2) self.assertLess(t.finish, clock.time()) def test_open_zipDefault(self): with temporary_dir() as tempdir: with open_zip(os.path.join", "label": 0}, {"snippet_id": 78764, "code": "'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not available: %s', e) except BaseException as e: log.logger.exception", "label": 0}, {"snippet_id": 51759, "code": " list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"", "label": 0}, {"snippet_id": 81696, "code": "\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html)", "label": 0}, {"snippet_id": 75550, "code": " interface, method, type_, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, struct.pack('!B', type_), make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth", "label": 0}, {"snippet_id": 60040, "code": " argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed.", "label": 0}, {"snippet_id": 7932, "code": "(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION", "label": 0}, {"snippet_id": 21082, "code": ", False event.set() return msg, True self._add_handler(handler, handlername, False) return event class Awaitable(object): @classmethod def wait_all(cls, *awaitables): timeout=3.0 messages=[] for _ in range", "label": 0}, {"snippet_id": 11262, "code": " is written into this directory. If no target directory is given its value is read from /etc/monitoring_config_generator/config.yaml --skip-checks Do not run checks on the yaml file received from the URL", "label": 0}, {"snippet_id": 46790, "code": " from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException", "label": 1}, {"snippet_id": 30640, "code": " min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict)", "label": 0}, {"snippet_id": 64078, "code": " available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def __rewrite_parameters", "label": 0}, {"snippet_id": 46183, "code": " in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for", "label": 0}, {"snippet_id": 90685, "code": "(minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) self._cache[key]=dist return dist def _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution", "label": 0}, {"snippet_id": 65814, "code": ".print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=", "label": 0}, {"snippet_id": 5742, "code": " and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison", "label": 0}, {"snippet_id": 68256, "code": "=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id(", "label": 0}, {"snippet_id": 94227, "code": ", filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session:", "label": 0}, {"snippet_id": 86201, "code": "=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format(distribution.home)) settings_args=(a.replace('$JAVA_HOME", "label": 0}, {"snippet_id": 553, "code": ".first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard", "label": 0}, {"snippet_id": 7269, "code": ":var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if", "label": 0}, {"snippet_id": 11563, "code": " sorted_keys: value=section_data[key] self.icinga_lines.append((\"%s%-45s%s\" %(self.indent, key, self.value_to_icinga(value)))) self.write_line(\"}\") @staticmethod def value_to_icinga(value): \"\"\"Convert a scalar", "label": 1}, {"snippet_id": 32251, "code": " item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 5618, "code": "(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output", "label": 0}, {"snippet_id": 51953, "code": ":start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i,", "label": 0}, {"snippet_id": 13253, "code": ".format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data[\"target_repo_branch\"]) request_json={ \"ref\": \"refs/heads/{}\".format(data[\"new_branch\"]), \"sha\": sha, } r=requests.post(url,", "label": 0}, {"snippet_id": 23275, "code": " _format_single_interface_name(self, sock, offset): return sock[offset:offset+16].split(b'\\0', 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using tmsh. :param net: :param mask: :param gateway: :return:", "label": 0}, {"snippet_id": 80113, "code": " Detection arguments') manualFormArgs.add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due", "label": 0}, {"snippet_id": 39853, "code": " self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths", "label": 0}, {"snippet_id": 93532, "code": "\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self", "label": 0}, {"snippet_id": 62608, "code": "{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number", "label": 0}, {"snippet_id": 15268, "code": "._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive", "label": 1}, {"snippet_id": 35270, "code": " if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards):", "label": 0}, {"snippet_id": 23550, "code": " OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format(username, output)) def del_root_password(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed to delete root password", "label": 0}, {"snippet_id": 821, "code": " action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={", "label": 0}, {"snippet_id": 95217, "code": " line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results", "label": 0}, {"snippet_id": 75006, "code": ": if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location", "label": 0}, {"snippet_id": 75522, "code": "(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid", "label": 0}, {"snippet_id": 51127, "code": "(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for", "label": 0}, {"snippet_id": 60416, "code": " 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self.observe.params) if self.shots !=0", "label": 0}, {"snippet_id": 92685, "code": " temporary_dir() as path1: with temporary_dir(root_dir=path1) as path2: self.assertTrue(os.path.realpath(path2).startswith(os.path.realpath(path1)), 'Nested temporary dir should be created within outer", "label": 0}, {"snippet_id": 5162, "code": "=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords,", "label": 0}, {"snippet_id": 48957, "code": " self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j", "label": 0}, {"snippet_id": 40193, "code": " self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self", "label": 0}, {"snippet_id": 94700, "code": "\"cmd\") subparser_editor=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified", "label": 0}, {"snippet_id": 94198, "code": "'name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config", "label": 0}, {"snippet_id": 25496, "code": " return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo", "label": 0}, {"snippet_id": 25931, "code": " data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state", "label": 0}, {"snippet_id": 93850, "code": ", comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug", "label": 0}, {"snippet_id": 72690, "code": "(input_dir=input_directory, temp_dir=temp_directory, output_dir=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service", "label": 1}, {"snippet_id": 8972, "code": "-partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs", "label": 0}, {"snippet_id": 1645, "code": ".\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\":", "label": 0}, {"snippet_id": 2885, "code": " in line\" % comp['name']) else: self.logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self", "label": 0}, {"snippet_id": 452, "code": " return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries", "label": 0}, {"snippet_id": 66895, "code": " def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, ", "label": 1}, {"snippet_id": 10398, "code": "(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR", "label": 0}, {"snippet_id": 78470, "code": " the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page", "label": 0}, {"snippet_id": 89568, "code": " specified binary path is invalid:{}'.format(bin_path)) if not bool(home_path) ^ bool(bin_path): raise ValueError('Exactly one of home path or bin path should be supplied, given: ' 'home_path={} bin_path={}'", "label": 0}, {"snippet_id": 53806, "code": "*params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance", "label": 0}, {"snippet_id": 35235, "code": "): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if", "label": 1}, {"snippet_id": 61881, "code": "-projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends.ClassicalSimulator()\t A simple introspective", "label": 0}, {"snippet_id": 81465, "code": "\tfutures=[] \t\t\ttry: \t\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t", "label": 0}, {"snippet_id": 58612, "code": " @classmethod def setUpTestData(cls): super(TestUpdateObject, cls).setUpTestData() cls.permission='testplans.change_testplan' cls.update_url=reverse('ajax-update') def setUp(self): user_should_have_perm", "label": 0}, {"snippet_id": 86081, "code": " to produce plugin and annotation processor files.\"\"\" target=compile_context.target if isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target) elif isinstance", "label": 0}, {"snippet_id": 8733, "code": " extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text", "label": 0}, {"snippet_id": 13009, "code": "\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ", "label": 0}, {"snippet_id": 21913, "code": ", module_paths=None, extra_vars=None, forks=None, ask_vault_pass=None, vault_password_files=None, new_vault_password_file=None, output_file=None, tags=None, skip_tags=None, one_line=None, tree=None, ask_sudo_pass", "label": 0}, {"snippet_id": 78845, "code": "=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 ", "label": 0}, {"snippet_id": 47100, "code": " \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 63796, "code": " errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else:", "label": 0}, {"snippet_id": 94491, "code": " got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running", "label": 0}, {"snippet_id": 8197, "code": " formats of documents are supported: PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility", "label": 0}, {"snippet_id": 52081, "code": " ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError", "label": 0}, {"snippet_id": 41365, "code": " import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile,", "label": 1}, {"snippet_id": 77997, "code": "=re.compile(regexp.f_udi) def atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target(domain, id_, user) def rtfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_", "label": 0}, {"snippet_id": 91249, "code": " LocalPythonDistributionArtifact from pants.backend.python.tasks.pytest_prep import PytestPrep from pants.backend.python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import", "label": 0}, {"snippet_id": 95821, "code": " output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input", "label": 0}, {"snippet_id": 79756, "code": "\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use", "label": 0}, {"snippet_id": 83976, "code": "%s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\"", "label": 0}, {"snippet_id": 67802, "code": ".get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self", "label": 0}, {"snippet_id": 28234, "code": ", 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle',", "label": 0}, {"snippet_id": 11417, "code": ") def write_output(self, file_name, yaml_icinga): lines=yaml_icinga.icinga_lines output_writer=OutputWriter(self.output_path(file_name)) output_writer.write_lines(lines) @staticmethod def create_filename", "label": 0}, {"snippet_id": 14304, "code": " options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port", "label": 1}, {"snippet_id": 91257, "code": " from pants.backend.python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import PythonBinaryCreate from pants.backend.python.tasks.python_bundle import PythonBundle", "label": 0}, {"snippet_id": 89221, "code": ".clone_new() for address in self.address_mapper.scan_addresses(root): build_graph.inject_address_closure(address) return build_graph def execute_process_synchronously(self, execute_process_request, name,", "label": 1}, {"snippet_id": 34749, "code": "(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name)", "label": 1}, {"snippet_id": 12320, "code": " after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author=data[\"author\"] comment_header", "label": 0}, {"snippet_id": 58196, "code": " objects_update(objects, **kwargs): objects.update(**kwargs) kwargs['instances']=objects if objects.model.__name__==TestCaseRun.__name__ and kwargs.get( 'case_run_status', None): POST_UPDATE_SIGNAL.send(sender=None", "label": 0}, {"snippet_id": 81170, "code": ".uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(", "label": 0}, {"snippet_id": 2238, "code": " delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi", "label": 0}, {"snippet_id": 43928, "code": ".docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self", "label": 0}, {"snippet_id": 29348, "code": "{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException", "label": 0}, {"snippet_id": 467, "code": "(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if", "label": 0}, {"snippet_id": 70052, "code": " * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine", "label": 0}, {"snippet_id": 86622, "code": " javac_plugin_info_file=os.path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: classname=javac_plugin_target.classname if PY3 else javac_plugin_target.classname", "label": 0}, {"snippet_id": 4417, "code": " boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions", "label": 0}, {"snippet_id": 12965, "code": " file, diffs in data[\"diff\"].items(): if len(diffs) !=0: REQUEST_JSON[\"files\"][file.split(\"/\")[-1] +\".diff\"]={ \"content\": diffs } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os", "label": 0}, {"snippet_id": 63534, "code": " encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id), files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds) def finish_job", "label": 0}, {"snippet_id": 83201, "code": ", 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self, url): \"\"\"Convert a legacy", "label": 0}, {"snippet_id": 62438, "code": " filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int", "label": 0}, {"snippet_id": 24494, "code": " the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): ", "label": 0}, {"snippet_id": 36875, "code": " Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import", "label": 0}, {"snippet_id": 23649, "code": ".get_if_name()), chk_err=False) def allow_dhcp_broadcast(self): pass def set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255 -iface{0}\".format(ifname), chk_err=False", "label": 0}, {"snippet_id": 48669, "code": " snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio", "label": 0}, {"snippet_id": 58877, "code": "('ajax-update_cases_default_tester') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission", "label": 0}, {"snippet_id": 65642, "code": "] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk", "label": 1}, {"snippet_id": 13195, "code": " data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format(data[\"fork_fullname\"]) headers={\"Authorization\":", "label": 0}, {"snippet_id": 19980, "code": "): if self.closed: raise RuntimeError('debug client closed') if self._session is None: raise RuntimeError('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not self", "label": 0}, {"snippet_id": 52579, "code": ")) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input", "label": 0}, {"snippet_id": 39688, "code": ", **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo", "label": 0}, {"snippet_id": 78474, "code": " user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page))) for t in found", "label": 0}, {"snippet_id": 95999, "code": "] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length", "label": 0}, {"snippet_id": 86529, "code": ".engine.fs import DirectoryToMaterialize, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator", "label": 0}, {"snippet_id": 73413, "code": ".VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir) create_directory_tree(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(\"*", "label": 0}, {"snippet_id": 59707, "code": " True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\"", "label": 0}, {"snippet_id": 13040, "code": " for repo in r.json(): if repo[\"description\"]: if data[\"target_repo_fullname\"] in repo[\"description\"]: FORKED=True r=requests.delete(\"https://api.github.com/repos/\" \"{}\".format(repo[\"full_name\"]), headers", "label": 0}, {"snippet_id": 28037, "code": " self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object", "label": 0}, {"snippet_id": 5622, "code": " for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0", "label": 0}, {"snippet_id": 52066, "code": " try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been", "label": 0}, {"snippet_id": 86659, "code": " p, v in whitelisted_args.items()} def validate(idx): arg=args[idx] for pattern, has_argument in valid_patterns.items(): if pattern.match(arg): return 2 if has_argument else 1 log.warn(\"Zinc argument '{", "label": 0}, {"snippet_id": 90172, "code": "(namedtuple('Location',['home_path', 'bin_path'])): \"\"\"Represents the location of a java distribution.\"\"\" @classmethod def from_home(cls, home): \"\"\"Creates a location given the JAVA_HOME directory. :param", "label": 0}, {"snippet_id": 22162, "code": " self).__init__(conf) def generate_ansible_playbook_from_template(self, template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader", "label": 0}, {"snippet_id": 10071, "code": ".fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault", "label": 0}, {"snippet_id": 63448, "code": " input_paths=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper): job_id=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s", "label": 0}, {"snippet_id": 29519, "code": " _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern)", "label": 0}, {"snippet_id": 63041, "code": "'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(**client_manager_kwargs) def url_to_destination( self,", "label": 0}, {"snippet_id": 62088, "code": " being registered(at the end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware", "label": 0}, {"snippet_id": 42030, "code": "(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,))", "label": 0}, {"snippet_id": 62776, "code": ": raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified", "label": 0}, {"snippet_id": 83442, "code": "=True lwr_job_state.running=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and LWR client", "label": 0}, {"snippet_id": 94334, "code": ".logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component", "label": 0}, {"snippet_id": 30897, "code": " @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for", "label": 0}, {"snippet_id": 5217, "code": " } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output", "label": 0}, {"snippet_id": 44674, "code": ".isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self", "label": 0}, {"snippet_id": 68308, "code": ", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout", "label": 0}, {"snippet_id": 42792, "code": "\"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item -", "label": 0}, {"snippet_id": 79543, "code": "=self.detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult", "label": 0}, {"snippet_id": 81357, "code": " \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension", "label": 0}, {"snippet_id": 94224, "code": " provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!", "label": 0}, {"snippet_id": 33411, "code": "\" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying", "label": 0}, {"snippet_id": 7264, "code": " author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires", "label": 0}, {"snippet_id": 45658, "code": ": self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return", "label": 0}, {"snippet_id": 66208, "code": ".append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], ", "label": 0}, {"snippet_id": 1015, "code": "'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn", "label": 0}, {"snippet_id": 87089, "code": ".HERMETIC: try: fast_relpath(self.get_options().pants_workdir, get_buildroot()) except ValueError: raise TaskError( \"Hermetic zinc execution currently requires the workdir to be a child of the buildroot \"", "label": 0}, {"snippet_id": 12054, "code": ") for e in list(config[\"pycodestyle\"][\"ignore\"])] return config def get_files_involved_in_pr(data): \"\"\" Return a list of file names modified/added in the PR \"\"\" headers={\"Authorization\": \"token \" +os.environ", "label": 0}, {"snippet_id": 19714, "code": " clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')) else: args.address=Address.as_client(clienthost,", "label": 0}, {"snippet_id": 59347, "code": "(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" name='ProjectQ", "label": 0}, {"snippet_id": 24531, "code": " data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity'", "label": 0}, {"snippet_id": 38870, "code": " signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals)", "label": 0}, {"snippet_id": 5844, "code": "\"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc", "label": 0}, {"snippet_id": 88120, "code": ", info_file): plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag !='plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem", "label": 0}, {"snippet_id": 10210, "code": " keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"", "label": 0}, {"snippet_id": 16053, "code": "[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests", "label": 0}, {"snippet_id": 79197, "code": "\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t", "label": 0}, {"snippet_id": 23393, "code": ".split(\"\\n\") textutil.set_ini_config(conf_file, \"hostname\", hostname) fileutil.write_file(rc_file_path, \"\\n\".join(conf_file)) shellutil.run(\"hostname{0}\".format(hostname), chk_err=False) def restart_ssh_service", "label": 0}, {"snippet_id": 20125, "code": "(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger", "label": 0}, {"snippet_id": 73873, "code": "\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\", \"lz4hc\", \"zlib\", \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class", "label": 0}, {"snippet_id": 16775, "code": "()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ ", "label": 0}, {"snippet_id": 70343, "code": ".fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes", "label": 0}, {"snippet_id": 77652, "code": " targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data[", "label": 0}, {"snippet_id": 58680, "code": " Dinied.'}) def test_update_plan_is_active(self): self.client.login( username=self.tester.username, password='password') post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field':", "label": 0}, {"snippet_id": 50553, "code": "(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return", "label": 0}, {"snippet_id": 59535, "code": " ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def", "label": 0}, {"snippet_id": 42702, "code": " name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, ", "label": 0}, {"snippet_id": 38871, "code": "\" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow", "label": 0}, {"snippet_id": 30301, "code": ":start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i,", "label": 0}, {"snippet_id": 27588, "code": " self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] ", "label": 0}, {"snippet_id": 46469, "code": " as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs", "label": 0}, {"snippet_id": 36210, "code": ".message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:", "label": 0}, {"snippet_id": 40966, "code": " Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names", "label": 0}, {"snippet_id": 32143, "code": " strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items", "label": 0}, {"snippet_id": 33544, "code": " dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this", "label": 0}, {"snippet_id": 560, "code": "\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS", "label": 0}, {"snippet_id": 53928, "code": " specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance", "label": 0}, {"snippet_id": 2386, "code": " TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__) SCRIPT_CLONE_PATH=(\"%s/scripts/start_named_clone_session.sh\" % BASE_DIR) class CheckState(Enum", "label": 0}, {"snippet_id": 90562, "code": " distribution that meets the given constraints and returns it. First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look", "label": 0}, {"snippet_id": 67001, "code": "==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"", "label": 0}, {"snippet_id": 31805, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"", "label": 0}, {"snippet_id": 66788, "code": " command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes,", "label": 0}, {"snippet_id": 35921, "code": " the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): ", "label": 0}, {"snippet_id": 60038, "code": "\"password\" keyword argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it", "label": 0}, {"snippet_id": 52834, "code": " f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input", "label": 0}, {"snippet_id": 90066, "code": "'utf-8').split(os.linesep): key, _, val=line.partition('=') props[key]=val self._system_properties=props return self._system_properties def _validate_executable(self, name): def bin_paths(): yield self", "label": 0}, {"snippet_id": 83930, "code": ")) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig", "label": 0}, {"snippet_id": 46299, "code": " names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os", "label": 0}, {"snippet_id": 79799, "code": "\"uploadsPath\",help=\"Path on the remote server where uploads are put. Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload", "label": 0}, {"snippet_id": 40332, "code": " missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError", "label": 0}, {"snippet_id": 51310, "code": " keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as", "label": 0}, {"snippet_id": 11653, "code": "'--skip-checks']).generate() exit_code=EXIT_CODE_CONFIG_WRITTEN if file_name else EXIT_CODE_NOT_WRITTEN except HostUnreachableException: LOG.warn(\"Target url{0} unreachable. Could not get yaml config!\"", "label": 0}, {"snippet_id": 36351, "code": " combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input", "label": 0}, {"snippet_id": 35502, "code": " for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is", "label": 0}, {"snippet_id": 55219, "code": " cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for", "label": 0}, {"snippet_id": 84903, "code": "(version, with_jline=False): classpath=[cls._create_compiler_jardep(version)] if with_jline: jline_dep=JarDependency( org='org.scala-lang', name='jline', rev=scala_build_info[version].full_version ) classpath", "label": 0}, {"snippet_id": 24430, "code": "[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self", "label": 0}, {"snippet_id": 95063, "code": " vcf_directory=\"./data/vcf/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\"", "label": 1}, {"snippet_id": 45873, "code": ") last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic", "label": 0}, {"snippet_id": 49939, "code": "=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not", "label": 0}, {"snippet_id": 56548, "code": ".forms import %s as form' %(q_app, q_form)) __import__('tcms.%s.forms' % q_app) q_app_module=sys.modules['tcms.%s.forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial", "label": 1}, {"snippet_id": 69734, "code": "* from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem", "label": 0}, {"snippet_id": 6094, "code": "(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream", "label": 0}, {"snippet_id": 42555, "code": "], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output", "label": 0}, {"snippet_id": 71409, "code": " \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\",", "label": 0}, {"snippet_id": 25565, "code": "=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data[", "label": 0}, {"snippet_id": 42970, "code": " of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item", "label": 0}, {"snippet_id": 10381, "code": "(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir", "label": 0}, {"snippet_id": 9557, "code": " compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source", "label": 0}, {"snippet_id": 38895, "code": " subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 26342, "code": ") dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name:", "label": 1}, {"snippet_id": 83841, "code": ". \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return", "label": 0}, {"snippet_id": 26569, "code": " elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state", "label": 0}, {"snippet_id": 46542, "code": " yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in", "label": 0}, {"snippet_id": 28383, "code": ".keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True", "label": 0}, {"snippet_id": 54582, "code": "=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self", "label": 0}, {"snippet_id": 22396, "code": " rc=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True", "label": 0}, {"snippet_id": 64108, "code": "=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds", "label": 0}, {"snippet_id": 71000, "code": "(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s", "label": 0}, {"snippet_id": 1663, "code": " output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not", "label": 0}, {"snippet_id": 41572, "code": " priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): ", "label": 0}, {"snippet_id": 53393, "code": "(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output", "label": 0}, {"snippet_id": 28157, "code": "=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None],", "label": 1}, {"snippet_id": 45348, "code": " itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def", "label": 1}, {"snippet_id": 90693, "code": " _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets any given constraints and returns it. :param minimum_version: minimum jvm version to look for", "label": 0}, {"snippet_id": 81187, "code": " and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection", "label": 0}, {"snippet_id": 83249, "code": ".mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status=", "label": 0}, {"snippet_id": 55000, "code": ", priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp", "label": 0}, {"snippet_id": 49968, "code": ".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if", "label": 0}, {"snippet_id": 2485, "code": ".session_name) else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self", "label": 0}, {"snippet_id": 93009, "code": ".assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self): with self._stdio_as_tempfiles(): with stdio_as(stdout_fd=-1", "label": 0}, {"snippet_id": 64333, "code": ") def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return", "label": 0}, {"snippet_id": 94655, "code": "(file_path): directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser", "label": 0}, {"snippet_id": 3110, "code": "::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown", "label": 0}, {"snippet_id": 86687, "code": ") return 1 arg_index=0 while arg_index < len(args): arg_index +=validate(arg_index) @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform", "label": 0}, {"snippet_id": 63639, "code": " %d\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout, stderr, exit_code", "label": 0}, {"snippet_id": 39693, "code": "): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self", "label": 0}, {"snippet_id": 10714, "code": "(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text", "label": 1}, {"snippet_id": 16624, "code": " and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request.Response", "label": 0}, {"snippet_id": 76851, "code": ".only_cache) c.router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b'WZWorker', b'terminate']) for t", "label": 0}, {"snippet_id": 35596, "code": " Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index", "label": 0}, {"snippet_id": 35002, "code": "=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at", "label": 0}, {"snippet_id": 45856, "code": "(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 17311, "code": "'--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options", "label": 0}, {"snippet_id": 83677, "code": ") job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict( job_id=str( job_id", "label": 0}, {"snippet_id": 3360, "code": " self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState", "label": 0}, {"snippet_id": 46105, "code": " constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one", "label": 0}, {"snippet_id": 27872, "code": "': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 58313, "code": " super(TestNavigation, cls).setUpTestData() cls.user=UserFactory(email='user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses(self): self.client.login", "label": 0}, {"snippet_id": 49520, "code": ")) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles", "label": 0}, {"snippet_id": 21519, "code": " +=newer_links new_links=list(set(new_links)) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping", "label": 0}, {"snippet_id": 92729, "code": " sleep(self, duration): self._time +=duration clock=FakeClock() with Timer(clock=clock) as t: self.assertLess(t.start, clock.time()) self.assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t", "label": 0}, {"snippet_id": 22275, "code": " import azurelinuxagent.common.utils.shellutil as shellutil from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import", "label": 0}, {"snippet_id": 44603, "code": ".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag)", "label": 0}, {"snippet_id": 24622, "code": "\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=", "label": 0}, {"snippet_id": 64258, "code": "] version_path=self.local_path_config.version_path() new_version_path=self.path_mapper.remote_version_path_rewrite(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path", "label": 0}, {"snippet_id": 45732, "code": " be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files", "label": 0}, {"snippet_id": 25733, "code": " elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data", "label": 0}, {"snippet_id": 62465, "code": " device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses", "label": 0}, {"snippet_id": 53715, "code": " if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer", "label": 0}, {"snippet_id": 64439, "code": " command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue", "label": 0}, {"snippet_id": 20140, "code": " RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None self._adapter=DebugAdapter.start(argv, port=self._port) return", "label": 0}, {"snippet_id": 90429, "code": ") if len(possible_environments) < 2: raise ValueError('At least two possible environments must be supplied.') self._possible_environments=possible_environments @property def jvm_locations(self): return", "label": 0}, {"snippet_id": 90299, "code": " @classmethod def standard(cls): return cls(cls._OSX_JAVA_HOME_EXE) def __init__(self, osx_java_home_exe): self._osx_java_home_exe=osx_java_home_exe @property def jvm_locations(self): if os.path.exists", "label": 0}, {"snippet_id": 8006, "code": "\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1", "label": 0}, {"snippet_id": 30764, "code": "(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message", "label": 0}, {"snippet_id": 43451, "code": "()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments", "label": 0}, {"snippet_id": 81264, "code": "(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime", "label": 1}, {"snippet_id": 954, "code": "].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username", "label": 0}, {"snippet_id": 6378, "code": " running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this", "label": 0}, {"snippet_id": 58552, "code": " comment' response=self.client.post( self.many_comments_url, {'comment': new_comment, 'run': ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding", "label": 0}, {"snippet_id": 77064, "code": "*kvargs) self.newproxyfile='newproxies.txt' self.proxylist=set() self.c=config self.threads=[] self.processes=[] self.th_sa='inproc://wm-wth.sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm", "label": 0}, {"snippet_id": 63841, "code": "\" %(lwr_url, job_id)) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck in the queued/running state when Galaxy started\"\"", "label": 0}, {"snippet_id": 45762, "code": ": return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex", "label": 0}, {"snippet_id": 78556, "code": "('No targets found at all, sleeping for 30 seconds') self.long_sleep(30) self.schedule(self.comment_loop) if len(self.forums)==0: self.schedule(self.wait_loop) def wait_loop(self): if len(self.targets)", "label": 0}, {"snippet_id": 84794, "code": " InjectablesMixin from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem major_version_info=namedtuple('major_version_info',['full_version']) scala_build_info={ '2", "label": 0}, {"snippet_id": 90797, "code": "(minimum_version is not None and maximum_version is not None and maximum_version < minimum_version): error_format=('Pants configuration/options led to impossible constraints for{} ' 'distribution: minimum_version{},", "label": 0}, {"snippet_id": 90902, "code": ":API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg, 1.7). The stricter of this and `--jvm-distributions", "label": 0}, {"snippet_id": 66520, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None,", "label": 0}, {"snippet_id": 90882, "code": " @classmethod def cached(cls, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets the given constraints and returns it. :API: public First looks for a cached", "label": 0}, {"snippet_id": 85425, "code": " cls).subsystem_dependencies() +(DependencyContext, Java, ScalaPlatform) @classmethod def register_options(cls, register): super(Zinc.Factory, cls).register_options(register) zinc_rev='1.0.3' shader_rules", "label": 0}, {"snippet_id": 83929, "code": " job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e", "label": 0}, {"snippet_id": 29041, "code": " self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data", "label": 0}, {"snippet_id": 28695, "code": "'battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 12015, "code": " confs.items(): if value: if isinstance(value, int): if isinstance(value, bool): arguments.append(\"--{}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments", "label": 0}, {"snippet_id": 7685, "code": "\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author", "label": 0}, {"snippet_id": 21275, "code": " for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label:', lk) continue new_links.append('https://www.youtube.com/watch", "label": 0}, {"snippet_id": 27388, "code": ", variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation", "label": 0}, {"snippet_id": 9729, "code": "\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires", "label": 0}, {"snippet_id": 6527, "code": "(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename", "label": 0}, {"snippet_id": 2980, "code": " self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'", "label": 0}, {"snippet_id": 72961, "code": "}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath", "label": 0}, {"snippet_id": 74601, "code": "\"\"\" enabled=False fields=None alt_number=None chunk_length=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def", "label": 0}, {"snippet_id": 623, "code": "(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard", "label": 0}, {"snippet_id": 6818, "code": ", output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string", "label": 1}, {"snippet_id": 90927, "code": "().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java distribution:{}'.format(e)) options_scope='jvm", "label": 0}, {"snippet_id": 191, "code": ".AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }", "label": 0}, {"snippet_id": 71858, "code": " import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction", "label": 0}, {"snippet_id": 10803, "code": "\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file", "label": 1}, {"snippet_id": 37089, "code": ".shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io", "label": 0}, {"snippet_id": 4927, "code": ": dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n' '<controlfield tag=\"001\">%s</controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords", "label": 0}, {"snippet_id": 59518, "code": ".wires) self._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map", "label": 0}, {"snippet_id": 83954, "code": " sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job():", "label": 0}, {"snippet_id": 14020, "code": " handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column", "label": 0}, {"snippet_id": 47385, "code": ".output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if", "label": 0}, {"snippet_id": 57592, "code": "'user']=self.request.user try: mailto(**mail_context) except Exception: pass def _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist", "label": 0}, {"snippet_id": 17722, "code": " self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable", "label": 0}, {"snippet_id": 81740, "code": " utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install", "label": 0}, {"snippet_id": 21382, "code": " unseen_links=[] print(\"Reddytt: Checking for reddytt working directory(%s).\" % work_dir) if not os.path.isdir(work_dir): print(\"Reddytt: Working directory not found. Creating %s, and files.\" % work_dir", "label": 0}, {"snippet_id": 25858, "code": " self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle", "label": 0}, {"snippet_id": 65492, "code": "(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand", "label": 0}, {"snippet_id": 7296, "code": " the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=(", "label": 0}, {"snippet_id": 13311, "code": ".format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"results\"][filename]=stdout.decode(r.encoding) os.remove(\"file_to_fix", "label": 0}, {"snippet_id": 66739, "code": " ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError,", "label": 1}, {"snippet_id": 47250, "code": "\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested", "label": 0}, {"snippet_id": 88194, "code": " using Zinc.\"\"\" @classmethod def product_types(cls): return['runtime_classpath', 'zinc_analysis', 'zinc_args'] def select(self, target): if not isinstance(target, JvmTarget): return False return target", "label": 0}, {"snippet_id": 78335, "code": " targets', t) try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t, msg)) self.w.sleep(self.errortimeout", "label": 1}, {"snippet_id": 44068, "code": " keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule", "label": 0}, {"snippet_id": 82462, "code": " Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args.size=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least", "label": 0}, {"snippet_id": 30743, "code": "._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8", "label": 0}, {"snippet_id": 31307, "code": " self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return", "label": 0}, {"snippet_id": 84498, "code": " self): return self.working_directory() def sep( self): return self._sep def version_path( self): return self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites", "label": 0}, {"snippet_id": 11278, "code": " file received from the URL. \"\"\" from datetime import datetime import logging import os import sys from docopt import docopt from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException", "label": 0}, {"snippet_id": 88002, "code": " classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published as \"fat jars\"(which appears to be the norm, since SBT doesn't support plugins with dependencies anyway). \"", "label": 0}, {"snippet_id": 71975, "code": " of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ ", "label": 1}, {"snippet_id": 29419, "code": ": self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return", "label": 0}, {"snippet_id": 46186, "code": "[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)", "label": 0}, {"snippet_id": 44487, "code": " items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler", "label": 0}, {"snippet_id": 66158, "code": "=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target", "label": 0}, {"snippet_id": 95186, "code": " line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results", "label": 0}, {"snippet_id": 71239, "code": " %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags", "label": 0}, {"snippet_id": 84651, "code": " target in targets ) input_files={f.path for snapshot in input_snapshots for f in snapshot.files} with temporary_dir() as tmpdir: list_file=os.path.join(tmpdir, 'input_files_list') with open(list_file,", "label": 0}, {"snippet_id": 87068, "code": ".__init__(*args, **kwargs) self._processor_info_dir=os.path.join(self.workdir, 'apt-processor-info') ZincCompile.validate_arguments(self.context.log, self.get_options().whitelisted_args, self._args) if", "label": 0}, {"snippet_id": 23819, "code": ":{0}\".format(output)) self._scsi_disks_timeout_set=True def check_pid_alive(self, pid): return shellutil.run('ps -p{0}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no", "label": 0}, {"snippet_id": 84729, "code": "(req, 'cloc',(WorkUnitLabel.TOOL,)) files_content_tuple=self.context._scheduler.product_request( FilesContent, [exec_result.output_directory_digest] )[0].dependencies files_content={fc.path: fc.content", "label": 1}, {"snippet_id": 14845, "code": " requests import urlparse from retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport", "label": 0}, {"snippet_id": 74835, "code": " blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode must be a valid integer.\") else: raise TypeError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode could not be converted", "label": 0}, {"snippet_id": 61100, "code": "-i \\sigma_x \\theta/2}` \"\"\" return expm(-1j * theta/2 * X) def fry(theta): r\"\"\"One-qubit rotation about the y axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^", "label": 0}, {"snippet_id": 19991, "code": "('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError('detach not supported') self._detach() def _close(self): if self", "label": 0}, {"snippet_id": 84955, "code": "=list, fingerprint=True, help='Use these scalac plugins.') register('--scalac-plugin-args', advanced=True, type=dict, default={}, fingerprint=True, help='Map from scalac plugin name to list of arguments", "label": 0}, {"snippet_id": 89045, "code": " scope of targets returned. :param bool postorder: `True` to gather transitive dependencies with a postorder traversal; `False` or preorder by default. :returns: A list of matching targets. \"\"\" target_set", "label": 0}, {"snippet_id": 7701, "code": " _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items()", "label": 0}, {"snippet_id": 36039, "code": ".output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res", "label": 0}, {"snippet_id": 1548, "code": "(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action", "label": 0}, {"snippet_id": 16418, "code": "-NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen", "label": 0}, {"snippet_id": 20640, "code": "._add_handler(handler) else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread( target=self._listen, name='test.session', ) self._listenerthread.start() @property def", "label": 0}, {"snippet_id": 27995, "code": "\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status'", "label": 0}, {"snippet_id": 46616, "code": "\" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist", "label": 0}, {"snippet_id": 90688, "code": " maximum_version=maximum_version, jdk=jdk) self._cache[key]=dist return dist def _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets any given constraints and", "label": 0}, {"snippet_id": 38228, "code": " snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable,", "label": 1}, {"snippet_id": 52192, "code": " import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards,", "label": 1}, {"snippet_id": 18860, "code": " from flex.loading.schema import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request", "label": 0}, {"snippet_id": 89715, "code": " name in names: for path in lib_paths(): lib_path=os.path.join(path, name) if os.path.exists(lib_path): yield lib_path break else: raise Distribution.Error('Failed to locate{} library'.format(name)) return", "label": 0}, {"snippet_id": 34914, "code": " f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing", "label": 0}, {"snippet_id": 60361, "code": " supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int):", "label": 0}, {"snippet_id": 15494, "code": " None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self", "label": 0}, {"snippet_id": 46944, "code": ".touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f", "label": 0}, {"snippet_id": 72044, "code": "(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 1: network name(case sensitive)).') return except", "label": 0}, {"snippet_id": 34251, "code": " benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate", "label": 0}, {"snippet_id": 26695, "code": "._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self", "label": 0}, {"snippet_id": 12658, "code": " 'quiet' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False return PERMITTED_TO_COMMENT def create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token \" +os.environ", "label": 0}, {"snippet_id": 68922, "code": " from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler", "label": 0}, {"snippet_id": 54665, "code": " if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count", "label": 0}, {"snippet_id": 90984, "code": "'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS can be specified via several different ' 'aliases, according to this map:{}'.format", "label": 0}, {"snippet_id": 94994, "code": " benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration file\", metavar=\"FILEPATH\") benchmark_exec_parser=subparser", "label": 0}, {"snippet_id": 4536, "code": " single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags)", "label": 0}, {"snippet_id": 10338, "code": "(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext", "label": 0}, {"snippet_id": 84614, "code": " targets. ' 'Unset to operate only on the specified targets.') register('--ignored', type=bool, fingerprint=True, help='Show information about files ignored by cloc.') def console_output(self, targets)", "label": 0}, {"snippet_id": 52840, "code": "\"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards", "label": 0}, {"snippet_id": 74200, "code": " None: if hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError", "label": 0}, {"snippet_id": 44252, "code": "\"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances", "label": 0}, {"snippet_id": 53781, "code": ": inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return", "label": 0}, {"snippet_id": 65072, "code": " target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self", "label": 0}, {"snippet_id": 18963, "code": "=urlparse.urlparse(source) if parts.scheme and parts.netloc: response=requests.get(source) if isinstance(response.content, six.binary_type): raw_source=six.text_type(response.content, encoding='utf-8')", "label": 0}, {"snippet_id": 4349, "code": "=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def", "label": 0}, {"snippet_id": 69377, "code": "\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type", "label": 0}, {"snippet_id": 45065, "code": " def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def", "label": 0}, {"snippet_id": 41960, "code": ".dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): ", "label": 0}, {"snippet_id": 90100, "code": " bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{} executable,{} does not appear to be a' ' valid{} distribution'.format(name, self, ", "label": 0}, {"snippet_id": 31497, "code": " import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None", "label": 0}, {"snippet_id": 61734, "code": " full system operator. Args: U(array): 4x4 matrix wires(Sequence[int]): two target subsystems(order matters!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.", "label": 0}, {"snippet_id": 51859, "code": " self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index)", "label": 0}, {"snippet_id": 17046, "code": ", 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future", "label": 0}, {"snippet_id": 65551, "code": " RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=-1 self.init_execute()", "label": 1}, {"snippet_id": 59772, "code": " just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super", "label": 0}, {"snippet_id": 28431, "code": "._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name", "label": 0}, {"snippet_id": 72436, "code": " benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns", "label": 1}, {"snippet_id": 25560, "code": "._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self", "label": 0}, {"snippet_id": 53561, "code": " Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name)", "label": 0}, {"snippet_id": 23491, "code": "\", username) shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self", "label": 0}, {"snippet_id": 71691, "code": " Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search(\"(\\w+)", "label": 1}, {"snippet_id": 82682, "code": "(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds[\"username\"] \t\tproxyPass=args", "label": 0}, {"snippet_id": 54550, "code": "(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict", "label": 0}, {"snippet_id": 37546, "code": " end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self,", "label": 0}, {"snippet_id": 75034, "code": " EvaluatorProxy: def __init__(self, ev_init, *args, **kvargs): super().__init__() self.ev_init=ev_init self.bind_kt_ticker=Ticker() self.bind_kt=5 def handle_evaluate(self, reqid, interface, method, data", "label": 0}, {"snippet_id": 49923, "code": "=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing", "label": 0}, {"snippet_id": 3243, "code": " color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name, dep) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and ", "label": 0}, {"snippet_id": 54374, "code": " compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp", "label": 0}, {"snippet_id": 65329, "code": " print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\"", "label": 0}, {"snippet_id": 70938, "code": " elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target)", "label": 0}, {"snippet_id": 88212, "code": "): return False return target.has_sources('.java') or target.has_sources('.scala') def select_source(self, source_file_path): return source_file_path.endswith('.java') or source_file_path.endswith('.scala", "label": 0}, {"snippet_id": 17186, "code": " SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False", "label": 0}, {"snippet_id": 5545, "code": ".fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', ", "label": 0}, {"snippet_id": 51562, "code": ": combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance", "label": 0}, {"snippet_id": 32822, "code": ".io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow:", "label": 1}, {"snippet_id": 86493, "code": ".targets.jvm_target import JvmTarget from pants.backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile", "label": 0}, {"snippet_id": 29444, "code": ").match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__", "label": 0}, {"snippet_id": 25893, "code": " elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" ", "label": 0}, {"snippet_id": 49299, "code": ": \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules", "label": 0}, {"snippet_id": 26546, "code": ", 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24'", "label": 0}, {"snippet_id": 77074, "code": " self.processes=[] self.th_sa='inproc://wm-wth.sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm-wpr.sock' self.pr_ba='ipc://wm-back.sock' self.userqueues={} self.usersfile='wm_users.pickle'", "label": 0}, {"snippet_id": 45206, "code": ".threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow", "label": 0}, {"snippet_id": 50648, "code": ": if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile", "label": 0}, {"snippet_id": 2208, "code": " configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False", "label": 0}, {"snippet_id": 73531, "code": "'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF", "label": 0}, {"snippet_id": 80453, "code": ".minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in args.legitExtensions] ", "label": 0}, {"snippet_id": 26602, "code": "=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770:", "label": 0}, {"snippet_id": 9505, "code": "\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output", "label": 0}, {"snippet_id": 27873, "code": "=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data[", "label": 0}, {"snippet_id": 94501, "code": ".debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger", "label": 0}, {"snippet_id": 52407, "code": "(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum", "label": 0}, {"snippet_id": 2056, "code": "[0].split('\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}]", "label": 0}, {"snippet_id": 25625, "code": "._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and", "label": 0}, {"snippet_id": 51704, "code": ".finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for", "label": 0}, {"snippet_id": 4464, "code": " returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache", "label": 0}, {"snippet_id": 56598, "code": " q_action=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag.objects.filter", "label": 0}, {"snippet_id": 74537, "code": " runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp", "label": 0}, {"snippet_id": 36253, "code": " except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule)", "label": 0}, {"snippet_id": 42732, "code": " lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output", "label": 0}, {"snippet_id": 43624, "code": " \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser", "label": 0}, {"snippet_id": 79090, "code": ".codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t\t\telse: \t\t\t\tself.logger.warning(\"Code execution detection will not be possible as there is no path nor regex pattern configured.\") \t\telse: \t", "label": 0}, {"snippet_id": 17501, "code": " completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self)", "label": 0}, {"snippet_id": 69069, "code": " fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes,", "label": 0}, {"snippet_id": 85463, "code": ".logging.log4j', recursive=True), ] cls.register_jvm_tool(register, Zinc.ZINC_COMPILER_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-compiler_2.11', '0.0.7'), ], main=Zinc.ZINC_COMPILE_MAIN,", "label": 1}, {"snippet_id": 55840, "code": " ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo", "label": 0}, {"snippet_id": 58597, "code": ") self.assertEqual(new_comment, comments[0].comment) self.assertEqual(self.tester, comments[0].user) class TestUpdateObject(BasePlanCase): \"\"\"Test case for update\"\"\" @classmethod def setUpTestData(cls)", "label": 0}, {"snippet_id": 55142, "code": "{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update", "label": 0}, {"snippet_id": 57556, "code": " return self._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none(self.request, pk_enough) except Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene", "label": 0}, {"snippet_id": 47391, "code": ".benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might", "label": 0}, {"snippet_id": 19071, "code": " swagger spec, validate that the schema complies to spec. If `target` is provided, that target will be validated against the provided schema. \"\"\" schema=schema_validator(raw_schema, **kwargs) if target", "label": 0}, {"snippet_id": 57239, "code": "(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=='case_run_status': for t in targets: field='close_date' t.log_action( who=request.user, action='Field %s changed from", "label": 0}, {"snippet_id": 2673, "code": " circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(", "label": 0}, {"snippet_id": 38667, "code": ".relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None:", "label": 0}, {"snippet_id": 35330, "code": " if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=", "label": 0}, {"snippet_id": 70247, "code": " of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed", "label": 0}, {"snippet_id": 23846, "code": ". Returns strings: iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We will sleep and retry as the network must be up. \"\"\" iface='' inet='' mac='' err, output=shellutil.run_get_output", "label": 0}, {"snippet_id": 23069, "code": " method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make when mounting the provisioningiso.iso DVD :param chk_err: Whether to check for", "label": 0}, {"snippet_id": 12126, "code": ".content.splitlines(), encoding=r.encoding) files={} for patchset in patch: file=patchset.target_file[1:] files[file]=[] for hunk in patchset: for line in hunk.target_lines(): if line.is_added: files[file]", "label": 0}, {"snippet_id": 71877, "code": " targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes", "label": 0}, {"snippet_id": 37565, "code": " set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None)", "label": 0}, {"snippet_id": 70746, "code": " targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self", "label": 1}, {"snippet_id": 1624, "code": ".get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd", "label": 0}, {"snippet_id": 25724, "code": " self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium", "label": 0}, {"snippet_id": 12290, "code": ".remove(error) for error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github", "label": 0}, {"snippet_id": 10706, "code": "=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD.search(line) is not None] if not remote: log.info(\"Local file has %d lines and %d", "label": 1}, {"snippet_id": 13006, "code": ").json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 67540, "code": " GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on ", "label": 0}, {"snippet_id": 86638, "code": ".decode('utf-8') f.write(classname) @staticmethod def validate_arguments(log, whitelisted_args, args): \"\"\"Validate that all arguments match whitelisted regexes.\"\"\" valid_patterns={re.compile(p): v for p, v", "label": 0}, {"snippet_id": 90692, "code": " def _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets any given constraints and returns it. :param minimum_version: minimum jvm version to look", "label": 0}, {"snippet_id": 76441, "code": " try: for nfr in self.wz.parse_router_msg(frames): self.wz_sock.send_multipart(nfr) except wzrpc.WZErrorRep as e: self.log.info(e) self.wz_sock.send_multipart(e.rep_msg) except wzrpc.WZError as e: self", "label": 0}, {"snippet_id": 11747, "code": ".execute(query) conn.commit() except psycopg2.IntegrityError: conn.rollback() def follow_user(user): \"\"\"Follow the user of the service\"\"\" headers={ \"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]", "label": 0}, {"snippet_id": 33828, "code": "._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse", "label": 0}, {"snippet_id": 56352, "code": "'Unrecognizable info-type') if request.GET.get('format')=='ulli': field=request.GET.get('field', default='name') response_str='<ul>' for obj_value in info_type().values(field): response_str +='<li>' +obj_value", "label": 0}, {"snippet_id": 77882, "code": " self.join_threads() if self.c.tcount > 0: self.save_users() self.save_targets() wm=workers.WZWorkerThread(c.router_addr, WipeManager,(c,), name='SpaghettiMonster') wm.start(ctx, sig_addr) def add_target", "label": 0}, {"snippet_id": 16989, "code": " method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest", "label": 0}, {"snippet_id": 45059, "code": " ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark", "label": 0}, {"snippet_id": 72449, "code": " import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the", "label": 1}, {"snippet_id": 78566, "code": "=0: self.schedule(self.wait_loop) def wait_loop(self): if len(self.targets) > 0: self.schedule(self.comment_loop) return if len(self.forums)==0: with cstate(self, WipeState.waiting_for_targets): while len", "label": 0}, {"snippet_id": 20409, "code": ".VERBOSE: print('+', end='') sys.stdout.flush() time.sleep(0.1) else: break else: raise RuntimeError('could not connect') return sock return cls._create(connect, addr, **kwargs) @classmethod def create_server", "label": 0}, {"snippet_id": 85365, "code": ".build_environment import get_buildroot from pants.engine.fs import PathGlobs, PathGlobsAndRoot from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem from", "label": 1}, {"snippet_id": 71735, "code": " def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s", "label": 0}, {"snippet_id": 422, "code": "(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get", "label": 0}, {"snippet_id": 73770, "code": " enabled=False server=\"\" username=\"\" password=\"\" use_tls=False directory=\"\" files=[] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param", "label": 0}, {"snippet_id": 13089, "code": ".environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.post(url, headers=headers, auth=auth) if r.status_code==202: data[\"fork_fullname\"]=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]", "label": 0}, {"snippet_id": 48951, "code": " as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try", "label": 0}, {"snippet_id": 29301, "code": ".S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file,", "label": 0}, {"snippet_id": 28613, "code": "._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self", "label": 0}, {"snippet_id": 66800, "code": ", targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes", "label": 0}, {"snippet_id": 32920, "code": ".overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config", "label": 0}, {"snippet_id": 91322, "code": ".build_file_aliases import BuildFileAliases from pants.build_graph.resources import Resources from pants.goal.task_registrar import TaskRegistrar as task def build_file_aliases(): return BuildFileAliases( targets", "label": 0}, {"snippet_id": 32972, "code": " not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=", "label": 0}, {"snippet_id": 72539, "code": " data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required", "label": 0}, {"snippet_id": 91640, "code": " 'requirements'): for py_req in maybe_python_req_lib.requirements: all_target_requirements.append(str(py_req.requirement)) all_requirements=sorted(all_target_requirements +list(pytest.get_requirement_strings", "label": 0}, {"snippet_id": 58281, "code": " import remove_perm_from_user from tcms.tests import user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories import EnvGroupFactory from tcms.tests.factories import", "label": 0}, {"snippet_id": 55951, "code": "=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo", "label": 0}, {"snippet_id": 23688, "code": " -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device() retcode=shellutil.run(\"cdcontrol -f{0} eject\".format(dvd)) if chk_err and", "label": 0}, {"snippet_id": 7619, "code": " spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches", "label": 0}, {"snippet_id": 10153, "code": "\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category", "label": 0}, {"snippet_id": 6031, "code": " filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible", "label": 1}, {"snippet_id": 15726, "code": " {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable", "label": 0}, {"snippet_id": 82254, "code": " while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection arguments') manualFormArgs.add_argument(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection", "label": 0}, {"snippet_id": 71634, "code": " raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc", "label": 0}, {"snippet_id": 65457, "code": "=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s", "label": 0}, {"snippet_id": 10643, "code": "\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as", "label": 0}, {"snippet_id": 74346, "code": " numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', ", "label": 0}, {"snippet_id": 14221, "code": "( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format(", "label": 0}, {"snippet_id": 15753, "code": "'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']", "label": 0}, {"snippet_id": 25935, "code": "'GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 61378, "code": "' short_name='default.qubit' api_version='0.1.0' version='0.1.0' author='Xanadu Inc.' _gates=set(operator_map.keys()) _observables={} _circuits={} def __init__(self, wires, *, shots=0): self.wires=wires", "label": 0}, {"snippet_id": 9129, "code": ") or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken", "label": 0}, {"snippet_id": 18814, "code": ".dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager", "label": 0}, {"snippet_id": 4700, "code": " single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K", "label": 0}, {"snippet_id": 85324, "code": " pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_tool_mixin import JvmToolMixin from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend", "label": 0}, {"snippet_id": 28770, "code": "': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0", "label": 0}, {"snippet_id": 50210, "code": "(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name", "label": 0}, {"snippet_id": 21358, "code": " depth=args.depth mpv=\" \".join(args.mpv) subreddit_link=\"https://reddit.com/r/\" +subreddit work_dir=os.environ['HOME'] +\"/.reddytt\" sr_dir=work_dir +\"/%s\" % subreddit seen_file=sr_dir +\"/seen\" seen_links", "label": 1}, {"snippet_id": 91307, "code": " pants.backend.python.tasks.setup_py import SetupPy from pants.backend.python.tasks.unpack_wheels import UnpackWheels from pants.build_graph.build_file_aliases import BuildFileAliases from pants.build_graph", "label": 0}, {"snippet_id": 78899, "code": " or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(", "label": 0}, {"snippet_id": 75763, "code": " recieved', repr((interface, method, data))) self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info", "label": 1}, {"snippet_id": 67787, "code": ", status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in", "label": 0}, {"snippet_id": 62095, "code": "): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution", "label": 0}, {"snippet_id": 76878, "code": " interrupt_handler(signal, frame): pass def terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler) signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy", "label": 0}, {"snippet_id": 55218, "code": " a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend", "label": 0}, {"snippet_id": 36359, "code": " \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing", "label": 0}, {"snippet_id": 64564, "code": " def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self)", "label": 1}, {"snippet_id": 35784, "code": " hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass", "label": 0}, {"snippet_id": 34597, "code": "._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property", "label": 0}, {"snippet_id": 19606, "code": "(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd,", "label": 1}, {"snippet_id": 86928, "code": " advanced=True, type=bool, default=True, help='When set, zinc will use sub-target incremental compilation, which dramatically ' 'improves compile performance while changing large targets. When unset, '", "label": 0}, {"snippet_id": 55434, "code": ".info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats", "label": 0}, {"snippet_id": 2683, "code": ".node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR", "label": 0}, {"snippet_id": 45871, "code": "\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic", "label": 0}, {"snippet_id": 25042, "code": "'wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize", "label": 0}, {"snippet_id": 90829, "code": "'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions are searched for in the following order by default", "label": 0}, {"snippet_id": 74951, "code": ".benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config=runtime_config) def read_configuration(location):", "label": 1}, {"snippet_id": 6304, "code": " line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable)", "label": 1}, {"snippet_id": 45305, "code": ", dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def", "label": 0}, {"snippet_id": 75390, "code": " msg def make_router_req_msg(self, iden, interface, method, args, fun, reqid=None): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface, method, args, fun, reqid)) return msg def make_router_rep_msg", "label": 0}, {"snippet_id": 35348, "code": " isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in", "label": 0}, {"snippet_id": 51245, "code": " if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by", "label": 0}, {"snippet_id": 18188, "code": " EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1", "label": 0}, {"snippet_id": 30736, "code": ".dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output)", "label": 0}, {"snippet_id": 82637, "code": "/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys(): \t\ts.cookies", "label": 0}, {"snippet_id": 7892, "code": ":i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output", "label": 0}, {"snippet_id": 40229, "code": ".rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile", "label": 1}, {"snippet_id": 21514, "code": " else: newer_links, links=getytlinks(link) new_links +=newer_links new_links=list(set(new_links)) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link", "label": 0}, {"snippet_id": 44810, "code": ": sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno", "label": 0}, {"snippet_id": 55208, "code": "\"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit", "label": 0}, {"snippet_id": 39035, "code": ") return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map", "label": 0}, {"snippet_id": 52180, "code": "\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from", "label": 0}, {"snippet_id": 54475, "code": " protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__", "label": 1}, {"snippet_id": 75239, "code": ".sig_handlers[(interface, method)]=fun def del_req_handler(self, interface, method): del self.req_handlers[(interface, method)] def del_response_handler(self, reqid): del self.response_handlers[reqid] def", "label": 0}, {"snippet_id": 83415, "code": ".QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state", "label": 0}, {"snippet_id": 30409, "code": " first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is", "label": 0}, {"snippet_id": 48805, "code": " IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno", "label": 0}, {"snippet_id": 17243, "code": " def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options", "label": 0}, {"snippet_id": 95418, "code": " except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{})", "label": 0}, {"snippet_id": 56120, "code": "\"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"", "label": 0}, {"snippet_id": 11914, "code": ".pep8speaks.yml config file from the repository and return the config dictionary \"\"\" config={ \"message\":{ \"opened\":{ \"header\": \"\", \"footer\": \"\" }, \"updated\":{ \"header\": \"\", \"footer\": \"\" } }, \"scanner\":", "label": 0}, {"snippet_id": 66102, "code": " status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state=", "label": 0}, {"snippet_id": 60918, "code": ": dict[str->GateSpec]: \"\"\" return self._observables @property def templates(self): \"\"\"Get the predefined circuit templates. .. todo:: rename to circuits? Returns: dict[str->Circuit]: circuit templates ", "label": 0}, {"snippet_id": 28586, "code": " self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] ", "label": 0}, {"snippet_id": 91174, "code": ".backend.python.targets.python_binary import PythonBinary from pants.backend.python.targets.python_distribution import PythonDistribution from pants.backend.python.targets.python_library import PythonLibrary", "label": 0}, {"snippet_id": 86006, "code": ": super(JavacCompile, cls).register_options(register) @classmethod def subsystem_dependencies(cls): return super(JavacCompile, cls).subsystem_dependencies() +(JvmPlatform,) @classmethod def prepare(cls", "label": 0}, {"snippet_id": 55325, "code": " print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync", "label": 0}, {"snippet_id": 12710, "code": " old_comment[\"user\"][\"id\"]==24736507: last_comment_id=old_comment[\"id\"] break if last_comment_id is None: response=requests.post(query, json={\"body\": comment}, headers=headers, auth=auth) data[\"comment_response\"", "label": 0}, {"snippet_id": 35563, "code": " toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self", "label": 0}, {"snippet_id": 39948, "code": " WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times,", "label": 1}, {"snippet_id": 26927, "code": "\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30:", "label": 0}, {"snippet_id": 61477, "code": ": U=self.expand_two(U, operation.wires) else: raise ValueError('This plugin supports only one-and two-qubit gates.') self._state=U @ self._state A=DefaultQubit._get_operator_matrix(self._observe) if self", "label": 0}, {"snippet_id": 29472, "code": ") _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem", "label": 0}, {"snippet_id": 47175, "code": " value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in", "label": 0}, {"snippet_id": 4991, "code": " author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires", "label": 0}, {"snippet_id": 2953, "code": ".debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost", "label": 0}, {"snippet_id": 68152, "code": "~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes", "label": 0}, {"snippet_id": 47911, "code": " self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else", "label": 0}, {"snippet_id": 91592, "code": " PythonSetup, SourceRootConfig]) def run_python_test(test_target, pytest, python_setup, source_root_config): \"\"\"Runs pytest for one target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download/v1.6.6/pex", "label": 1}, {"snippet_id": 77271, "code": ".spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self, wclass, count, args=(), kvargs={}): wname=str(wclass.__name__)", "label": 0}, {"snippet_id": 12162, "code": "-3:] !=\".py\": del files[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 71545, "code": " FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__", "label": 0}, {"snippet_id": 83319, "code": " def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self,", "label": 0}, {"snippet_id": 10766, "code": " string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text)", "label": 1}, {"snippet_id": 64059, "code": " to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is no guarentee that it will contain all the datatypes", "label": 0}, {"snippet_id": 32988, "code": " not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None", "label": 0}, {"snippet_id": 84921, "code": ") cls.register_jvm_tool(register, cls._key_for_tool_version('scala-repl', version), classpath=classpath) def register_style_tool(version): cls.register_jvm_tool(register, cls._key_for_tool_version('scalastyle", "label": 1}, {"snippet_id": 65524, "code": "-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map", "label": 0}, {"snippet_id": 13312, "code": "( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"results\"][filename]=stdout.decode(r.encoding) os.remove(\"file_to_fix.py\"", "label": 0}, {"snippet_id": 89164, "code": ", root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets parsed in the root tree's", "label": 0}, {"snippet_id": 12699, "code": "\"])) comments=requests.get(query, headers=headers, auth=auth).json() last_comment_id=None for old_comment in comments: if old_comment[\"user\"][\"id\"]==24736507: last_comment_id=old_comment[\"id\"] break if", "label": 0}, {"snippet_id": 35915, "code": ", min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat", "label": 0}, {"snippet_id": 29068, "code": "\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo", "label": 1}, {"snippet_id": 83766, "code": " failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate", "label": 0}, {"snippet_id": 86883, "code": " super(BaseZincCompile, cls).register_options(register) register('--whitelisted-args', advanced=True, type=dict, default={ '-S.*': False, '-C.*': False, '-file-filter': True, '-msg-filter': True, }, help=", "label": 0}, {"snippet_id": 7848, "code": ": \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: set of formatted", "label": 0}, {"snippet_id": 18013, "code": " server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath", "label": 0}, {"snippet_id": 1362, "code": "-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id", "label": 0}, {"snippet_id": 2252, "code": ":configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deletewifi', 'endpoint': wifi_name}], safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request", "label": 0}, {"snippet_id": 18147, "code": ".general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest,", "label": 0}, {"snippet_id": 53363, "code": "(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list", "label": 1}, {"snippet_id": 34849, "code": " self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__", "label": 0}, {"snippet_id": 19057, "code": "(raw_schema, target=None, **kwargs): \"\"\" Given the python representation of a JSONschema as defined in the swagger spec, validate that the schema complies to spec. If `target` is provided, that target will", "label": 0}, {"snippet_id": 61995, "code": " operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device", "label": 0}, {"snippet_id": 11752, "code": ": conn.rollback() def follow_user(user): \"\"\"Follow the user of the service\"\"\" headers={ \"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"], \"Content-Length\": \"0\", } auth=(os.environ[\"BOT_USERNAME\"],", "label": 0}, {"snippet_id": 9538, "code": " dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output", "label": 0}, {"snippet_id": 74998, "code": "'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration", "label": 0}, {"snippet_id": 55966, "code": "(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return", "label": 0}, {"snippet_id": 85641, "code": " path to the Zinc compiler-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property def compiler_interface(self): \"\"\"Return the path to the Zinc compiler", "label": 0}, {"snippet_id": 72540, "code": "=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location", "label": 0}, {"snippet_id": 1048, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action", "label": 0}, {"snippet_id": 59897, "code": "'ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state", "label": 0}, {"snippet_id": 75263, "code": " del self.sig_handlers[(interface, method)] def _parse_req(self, iden, msg, reqid, interface, method): try: handler=self.req_handlers[(interface, method)] except KeyError: try: handler=self.req_handlers", "label": 0}, {"snippet_id": 56087, "code": " def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target", "label": 0}, {"snippet_id": 29355, "code": ".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\")", "label": 0}, {"snippet_id": 89802, "code": " raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the path to the command of the given name for this distribution. For example::: >>> d=Distribution() >>> jar=d", "label": 0}, {"snippet_id": 7122, "code": ") functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions[s](complete_output, categories)", "label": 0}, {"snippet_id": 54902, "code": " files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets", "label": 0}, {"snippet_id": 62773, "code": ": if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience", "label": 0}, {"snippet_id": 3422, "code": " open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted", "label": 0}, {"snippet_id": 14979, "code": ".5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests", "label": 0}, {"snippet_id": 92880, "code": "/flushed correctly, and acts as a contextmanager to allow for recursive tests. \"\"\" uuid_str=str(uuid.uuid4()) def u(string): return '{} stdin_data=u('stdio') stdout_data=u('stdout') stderr_data=u('stderr", "label": 0}, {"snippet_id": 94873, "code": " determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import", "label": 0}, {"snippet_id": 12407, "code": "\"only_mention_files_with_errors\"]: comment_body.append( \" -There are no PEP8 issues in the\" \" file[`{0}`]({1}) !\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are", "label": 0}, {"snippet_id": 13624, "code": " \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\" 2>/dev/null\") time.sleep", "label": 0}, {"snippet_id": 75670, "code": " else type(self).__name__ self.start_timer=start_timer self.poll_timeout=poll_timeout if poll_timeout else 5*1000 self.call=(fun, args, kvargs) self.wz_addr=wz_addr self.wz_auth_requests=[] self.wz_bind_methods", "label": 0}, {"snippet_id": 65794, "code": " AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 54443, "code": " Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake", "label": 0}, {"snippet_id": 15239, "code": " with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash", "label": 0}, {"snippet_id": 57037, "code": "'None': lambda x: None, } pipe=pipes.get(v_type, None) if pipe is None: error='Unsupported value type.' else: try: value=pipe(val) except Exception as e: error=str(e) return value, error def say_no(error_msg", "label": 0}, {"snippet_id": 45466, "code": "(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise", "label": 1}, {"snippet_id": 96004, "code": "(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length", "label": 0}, {"snippet_id": 75738, "code": "')) self.sig_sock=s s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6, True) self.wz_sock=s self.wz=WZHandler() def term_handler(interface, method, data): self.log", "label": 1}, {"snippet_id": 10351, "code": " _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length", "label": 0}, {"snippet_id": 95709, "code": "\"**/*.gz\") for path in pathlist_gz: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str", "label": 0}, {"snippet_id": 42067, "code": " IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items", "label": 0}, {"snippet_id": 29356, "code": "(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as", "label": 0}, {"snippet_id": 40750, "code": " def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return", "label": 0}, {"snippet_id": 59956, "code": " to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate", "label": 0}, {"snippet_id": 95597, "code": "\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve", "label": 0}, {"snippet_id": 48415, "code": "): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params", "label": 0}, {"snippet_id": 65730, "code": " target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device", "label": 0}, {"snippet_id": 29863, "code": " wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args -", "label": 0}, {"snippet_id": 91517, "code": " import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult) from pants.engine.legacy.graph import BuildFileAddresses, TransitiveHydratedTargets from pants.engine.legacy.structs import", "label": 0}, {"snippet_id": 31479, "code": " import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import", "label": 0}, {"snippet_id": 8723, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for", "label": 0}, {"snippet_id": 65304, "code": ".set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc", "label": 0}, {"snippet_id": 29148, "code": " mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule", "label": 0}, {"snippet_id": 12615, "code": "\"][\"id\"]==24736507: last_comment=old_comment[\"body\"] break \"\"\" text1=''.join(BeautifulSoup(markdown(comment)).findAll(text=True)) text2=''.join(BeautifulSoup(markdown(last_comment)).findAll(text=True))", "label": 0}, {"snippet_id": 25869, "code": "': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle']", "label": 0}, {"snippet_id": 61009, "code": "-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and", "label": 0}, {"snippet_id": 62982, "code": " with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally, but LWR is not configured with this information", "label": 0}, {"snippet_id": 18230, "code": " with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash", "label": 0}, {"snippet_id": 87608, "code": ".execution_strategy==self.HERMETIC: zinc_relpath=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ]", "label": 0}, {"snippet_id": 34328, "code": " decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def", "label": 0}, {"snippet_id": 64033, "code": " use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason -datatypes may not match. One can", "label": 0}, {"snippet_id": 7109, "code": ".concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml", "label": 0}, {"snippet_id": 55712, "code": " value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if", "label": 0}, {"snippet_id": 51714, "code": "=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f", "label": 0}, {"snippet_id": 34739, "code": " mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of", "label": 1}, {"snippet_id": 29423, "code": ".file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target", "label": 0}, {"snippet_id": 17492, "code": " SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest", "label": 0}, {"snippet_id": 79674, "code": "\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\",", "label": 0}, {"snippet_id": 1408, "code": ",'delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params", "label": 0}, {"snippet_id": 83695, "code": ", files_endpoint=files_endpoint, env=env ) return self.client_manager.get_client( job_destination_params, **get_client_kwds) def finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper", "label": 0}, {"snippet_id": 67859, "code": "> result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for", "label": 0}, {"snippet_id": 90190, "code": " JAVA_HOME directory. :param string home: The path of the JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path", "label": 0}, {"snippet_id": 82010, "code": " requiredNamedArgs=parser.add_argument_group('Required named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload", "label": 0}, {"snippet_id": 53624, "code": ".wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name -", "label": 0}, {"snippet_id": 23983, "code": " deviceid=00000000-0001-8899-0000-000000000000' \"\"\" cmd_search_ide=\"sysctl dev.storvsc | grep pnpinfo | grep deviceid={0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide) if err: return", "label": 0}, {"snippet_id": 10091, "code": ".fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', ", "label": 0}, {"snippet_id": 22399, "code": "-a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't", "label": 0}, {"snippet_id": 2827, "code": " start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name", "label": 0}, {"snippet_id": 25192, "code": "'Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 40855, "code": "]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex", "label": 0}, {"snippet_id": 52552, "code": "\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction", "label": 0}, {"snippet_id": 93327, "code": " data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']:", "label": 0}, {"snippet_id": 69021, "code": " class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients", "label": 0}, {"snippet_id": 47224, "code": " def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"", "label": 0}, {"snippet_id": 59664, "code": "='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs", "label": 0}, {"snippet_id": 893, "code": "'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi", "label": 0}, {"snippet_id": 72719, "code": ") runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified", "label": 0}, {"snippet_id": 25990, "code": " data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type==", "label": 0}, {"snippet_id": 6530, "code": " os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source", "label": 0}, {"snippet_id": 45800, "code": "(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern", "label": 0}, {"snippet_id": 31241, "code": " IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items", "label": 0}, {"snippet_id": 91516, "code": ".isolated_process import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult) from pants.engine.legacy.graph import BuildFileAddresses, TransitiveHydratedTargets from pants.engine.legacy.structs", "label": 0}, {"snippet_id": 68425, "code": "=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %", "label": 0}, {"snippet_id": 78216, "code": " on_caprate_limit(self, rate): if not self.logined: self._capdata=(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self): for t in self", "label": 0}, {"snippet_id": 22119, "code": ".options.verbosity self.pbex=playbook_executor.PlaybookExecutor( playbooks=[playbook], inventory=self.inventory, variable_manager=self.variable_manager, loader=self.loader, options=self.options, passwords={}", "label": 1}, {"snippet_id": 84665, "code": "(list_file, 'w') as list_file_out: for input_file in sorted(input_files): list_file_out.write(input_file) list_file_out.write('\\n') list_file_snapshot=self.context._scheduler.capture_snapshots(( PathGlobsAndRoot", "label": 0}, {"snippet_id": 8177, "code": " field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2", "label": 0}, {"snippet_id": 21568, "code": ". Saving and exiting.\") with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove", "label": 0}, {"snippet_id": 4674, "code": " def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var", "label": 0}, {"snippet_id": 15039, "code": "() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data", "label": 0}, {"snippet_id": 20605, "code": "(addr, **kwargs) return cls(conn, owned=True, **kwargs) def __init__(self, conn, seq=1000, handlers=(), timeout=None, owned=False): super(DebugSession, self).__init__() self._conn=conn self._seq=seq self", "label": 0}, {"snippet_id": 60253, "code": "(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation", "label": 0}, {"snippet_id": 64461, "code": "[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command", "label": 0}, {"snippet_id": 15080, "code": ".json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def", "label": 0}, {"snippet_id": 23366, "code": " azurelinuxagent.common.future import ustr class FreeBSDOSUtil(DefaultOSUtil): def __init__(self): super(FreeBSDOSUtil, self).__init__() self._scsi_disks_timeout_set=False def set_hostname(self, hostname", "label": 0}, {"snippet_id": 87319, "code": ", and is lazily computed by zinc if the appropriate version does not exist. Eventually it would be great to just fetch this rather than compiling it. \"\"\" hasher=sha1() for cp_entry in[self._zinc.zinc, self", "label": 1}, {"snippet_id": 83880, "code": ": %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata", "label": 0}, {"snippet_id": 57456, "code": " __init__(self, request): self.request=request self.target_field=request.POST.get('target_field') self.new_value=request.POST.get('new_value') def get_update_action(self): return getattr(self, '_update_", "label": 0}, {"snippet_id": 94393, "code": "> 1 and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process", "label": 0}, {"snippet_id": 1527, "code": " serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=='loadDependencies': print(action) queryset=RegisteredServices.objects.all() serializer", "label": 0}, {"snippet_id": 3446, "code": " Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name)", "label": 0}, {"snippet_id": 16043, "code": "'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if", "label": 0}, {"snippet_id": 79771, "code": "\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None", "label": 0}, {"snippet_id": 123, "code": " return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split", "label": 0}, {"snippet_id": 91251, "code": " pants.backend.python.tasks.pytest_prep import PytestPrep from pants.backend.python.tasks.pytest_run import PytestRun from pants.backend.python.tasks.python_binary_create import PythonBinaryCreate from", "label": 0}, {"snippet_id": 22092, "code": "=vars.VariableManager() self.inventory=inventory.Inventory( loader=self.loader, variable_manager=self.variable_manager, host_list='/etc/ansible/hosts' ) self.variable_manager.set_inventory(self.inventory", "label": 0}, {"snippet_id": 14133, "code": " import os import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from", "label": 0}, {"snippet_id": 74040, "code": " value provided for chunk_width in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"compressor\" in runtime_config.vcf_to_zarr: compressor_temp=runtime_config.vcf_to_zarr[\"compressor\"] if", "label": 0}, {"snippet_id": 76241, "code": "[i, m])) def clear_auth(self): self.log.debug('Clearing our auth records') def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Auth records on router were cleared", "label": 0}, {"snippet_id": 51769, "code": " consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall", "label": 0}, {"snippet_id": 75633, "code": " self.interval=interval super().__init__(*args, **kvargs) class Resume(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=()", "label": 0}, {"snippet_id": 33209, "code": " subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources", "label": 0}, {"snippet_id": 53269, "code": "=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output)", "label": 0}, {"snippet_id": 696, "code": "(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[]", "label": 0}, {"snippet_id": 84052, "code": " state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner", "label": 0}, {"snippet_id": 60005, "code": "'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is required') if 'password", "label": 0}, {"snippet_id": 74783, "code": "(compression_level_int >=0) and(compression_level_int <=9): self.blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level", "label": 0}, {"snippet_id": 2087, "code": " print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username], stdout=subprocess.PIPE).communicate() fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker']", "label": 0}, {"snippet_id": 56115, "code": "(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input", "label": 0}, {"snippet_id": 85011, "code": " platform version. If --version=custom, the targets ' '//:scala-library, //:scalac, //:scala-repl and //:scalastyle will be used, ' 'and must exist. Otherwise, defaults for the specified version will be used", "label": 0}, {"snippet_id": 25888, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle']", "label": 0}, {"snippet_id": 89937, "code": "._bin_path=os.path.join(self.home, 'bin') try: self._validated_executable('javac') self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please check you", "label": 0}, {"snippet_id": 29313, "code": "): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try", "label": 1}, {"snippet_id": 1638, "code": " user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password", "label": 0}, {"snippet_id": 70454, "code": " Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base", "label": 0}, {"snippet_id": 38020, "code": " filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not", "label": 0}, {"snippet_id": 13396, "code": " errors in{}\".format(file), \"content\": content_code, \"sha\": sha_blob, \"branch\": data.get(\"new_branch\"), } r=requests.put(url, json=request_json, headers=headers, auth=auth) def create_pr(data): headers={", "label": 0}, {"snippet_id": 50700, "code": " if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job", "label": 0}, {"snippet_id": 73761, "code": " class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\" password=\"\" use_tls=False directory=\"\" files=[", "label": 0}, {"snippet_id": 43633, "code": ".shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary", "label": 1}, {"snippet_id": 82606, "code": "=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif", "label": 0}, {"snippet_id": 54257, "code": " --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict", "label": 0}, {"snippet_id": 7791, "code": "(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents", "label": 0}, {"snippet_id": 93474, "code": " tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1)", "label": 0}, {"snippet_id": 89933, "code": ", self._maximum_version, version)) self._bin_path=os.path.join(self.home, 'bin') try: self._validated_executable('javac') self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to", "label": 0}, {"snippet_id": 66054, "code": "%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" ", "label": 0}, {"snippet_id": 9787, "code": "(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n-", "label": 0}, {"snippet_id": 20891, "code": " if msg.type !='response': return False result['msg']=msg return msg.request_seq==seq handlername='response(cmd:{} seq:{})'.format(command, seq) with self._wait_for_message(match, handlername, **kwargs", "label": 0}, {"snippet_id": 74821, "code": " blosc_shuffle_mode_int=int(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types: self.blosc_shuffle_mode=blosc_shuffle_mode_int else: raise ValueError(\"Invalid value for", "label": 0}, {"snippet_id": 35402, "code": " wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the", "label": 0}, {"snippet_id": 93211, "code": " RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging", "label": 0}, {"snippet_id": 22565, "code": " name \"bigip1\" in the Web UI, Azure(Stack) considers that a perfectly valid name. When WAAgent gets around to running though, tmsh will reject that value because it is not a fully qualified domain name", "label": 0}, {"snippet_id": 33069, "code": "\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets", "label": 0}, {"snippet_id": 70576, "code": " rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes", "label": 0}, {"snippet_id": 55910, "code": "=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate", "label": 0}, {"snippet_id": 43033, "code": " raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs", "label": 0}, {"snippet_id": 56312, "code": "{} for key, value in request_dict.items(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters @require_GET def info(request): \"\"\"Ajax responder for misc information\"\"", "label": 1}, {"snippet_id": 92348, "code": " stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ) with hermetic_environment_as(**{}): self.assertNotIn", "label": 1}, {"snippet_id": 17209, "code": "' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines", "label": 0}, {"snippet_id": 76050, "code": " i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i, m) elif status==wzrpc.status", "label": 0}, {"snippet_id": 32837, "code": ".persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(),", "label": 0}, {"snippet_id": 90148, "code": "]=exe def __repr__(self): return('Distribution({!r}, minimum_version={!r}, maximum_version={!r} jdk={!r})'.format( self._bin_path, self._minimum_version, self._maximum_version, self._jdk)) class _DistributionEnvironment", "label": 0}, {"snippet_id": 29180, "code": "._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be", "label": 0}, {"snippet_id": 28857, "code": "'WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self", "label": 0}, {"snippet_id": 32418, "code": "\"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards", "label": 0}, {"snippet_id": 86196, "code": "(classpath), ]) if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format(distribution", "label": 0}, {"snippet_id": 12199, "code": "[\"author\"] py_files=get_python_files_involved_in_pr(data) for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format(repository, after_commit_hash, file) r=requests", "label": 0}, {"snippet_id": 41778, "code": " self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self", "label": 0}, {"snippet_id": 30979, "code": "(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing:", "label": 0}, {"snippet_id": 45246, "code": ") if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is", "label": 0}, {"snippet_id": 28684, "code": "='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state", "label": 0}, {"snippet_id": 17977, "code": " if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache", "label": 0}, {"snippet_id": 14714, "code": " BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format(", "label": 0}, {"snippet_id": 73152, "code": "}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file", "label": 0}, {"snippet_id": 62948, "code": " as lwr_finish_job from.lwr_client import submit_job as lwr_submit_job from.lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client", "label": 0}, {"snippet_id": 51366, "code": ") def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type", "label": 0}, {"snippet_id": 33969, "code": ".overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw", "label": 0}, {"snippet_id": 35203, "code": " for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary", "label": 0}, {"snippet_id": 78312, "code": " e, e.answer) self.schedule(self.add_comment,(t, msg)) except exc.Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info", "label": 1}, {"snippet_id": 24224, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', ", "label": 0}, {"snippet_id": 2572, "code": " self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp['name'", "label": 0}, {"snippet_id": 23677, "code": " -iface{0}\".format(ifname), chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True", "label": 0}, {"snippet_id": 12526, "code": " issues in this Pull Request.:beers: \") comment_body=''.join(comment_body) comment_footer=[] if request.json[\"action\"]==\"opened\": comment_footer.append(config[\"message\"][\"opened\"][\"footer\"]) elif request", "label": 0}, {"snippet_id": 10278, "code": " labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]", "label": 0}, {"snippet_id": 33400, "code": ".\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error(", "label": 0}, {"snippet_id": 76289, "code": "(i, m, f) def unbind_methods(self): for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg", "label": 0}, {"snippet_id": 60968, "code": "(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" raise NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset the backend state. After the reset the backend", "label": 0}, {"snippet_id": 19589, "code": "', '--server-host', '--port', '-m'): if arg=='-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg", "label": 1}, {"snippet_id": 78806, "code": ".formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName", "label": 0}, {"snippet_id": 68565, "code": " layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status", "label": 0}, {"snippet_id": 57725, "code": " plan.run_case=plan.case.filter(case_status__name=confirm_status_name) plan.review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case", "label": 0}, {"snippet_id": 2864, "code": "(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next", "label": 0}, {"snippet_id": 2989, "code": ")) self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting", "label": 0}, {"snippet_id": 3767, "code": "\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name)", "label": 0}, {"snippet_id": 75398, "code": "): msg=iden[:] msg.append(b'') msg.extend(self.make_req_msg(interface, method, args, fun, reqid)) return msg def make_router_rep_msg(self, reqid, seqnum, status, answer): iden=self.iden_reqid_map.get_key", "label": 0}, {"snippet_id": 27895, "code": ")\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150:", "label": 0}, {"snippet_id": 60506, "code": " Squeezed, 'ThermalState': Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'QuadraticPhase': Pgate, 'Rotation':", "label": 0}, {"snippet_id": 52173, "code": ".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m", "label": 0}, {"snippet_id": 36946, "code": ".workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set()", "label": 0}, {"snippet_id": 52070, "code": " f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" ", "label": 0}, {"snippet_id": 74090, "code": ".blosc_compression_level=compression_level_int else: raise ValueError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value", "label": 0}, {"snippet_id": 77703, "code": " f: self.pc.sets['bumplimit'].update(pickle.loads(f.read())) def save_targets(self): data={ 'targets': targets, 'forums': forums, 'domains': domains, 'sets': self.pc.sets, } with open(self.targetsfile, ", "label": 0}, {"snippet_id": 1797, "code": ", safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows", "label": 0}, {"snippet_id": 77367, "code": ".th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_nworkers(self, type_, fun, count, args", "label": 0}, {"snippet_id": 46426, "code": "(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self", "label": 0}, {"snippet_id": 70446, "code": " enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import", "label": 0}, {"snippet_id": 93393, "code": ".config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node", "label": 0}, {"snippet_id": 87922, "code": "(name, arg)) return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin classpath entries. The first entry in each list is the classpath entry", "label": 0}, {"snippet_id": 59049, "code": " self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), expected_json) def test_get_env_properties_by_group(self): response=self.client.get(self.get_info_url, {'info_type': 'env_properties", "label": 0}, {"snippet_id": 41954, "code": "(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log", "label": 0}, {"snippet_id": 27552, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise':", "label": 0}, {"snippet_id": 2660, "code": " self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex", "label": 0}, {"snippet_id": 81015, "code": "\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: ", "label": 0}, {"snippet_id": 32468, "code": ".output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in", "label": 0}, {"snippet_id": 51908, "code": " for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items", "label": 0}, {"snippet_id": 90991, "code": "'when locating a jvm to use. The same OS can be specified via several different ' 'aliases, according to this map:{}'.format(human_readable_os_aliases)) register('--minimum-version', advanced=True, help=", "label": 0}, {"snippet_id": 48686, "code": " wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self", "label": 0}, {"snippet_id": 87365, "code": " compiler_option_sets, zinc_file_manager, javac_plugin_map, scalac_plugin_map): absolute_classpath=(ctx.classes_dir,) +tuple(ce.path for ce in dependency_classpath) if self.get_options().capture_classpath: self", "label": 0}, {"snippet_id": 1399, "code": "(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for", "label": 0}, {"snippet_id": 82151, "code": " log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered", "label": 0}, {"snippet_id": 62462, "code": " number of qubits of the device. Keyword Args: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int", "label": 0}, {"snippet_id": 15327, "code": "}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format", "label": 0}, {"snippet_id": 3030, "code": ".info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name,", "label": 0}, {"snippet_id": 92382, "code": "'333')): output=subprocess.check_output('env', shell=True).decode('utf-8') self.assertNotIn('USER=', output) self.assertIn('AAA', os.environ) self.assertEqual(os.environ['AAA'], '333') self.assertIn('USER", "label": 1}, {"snippet_id": 87625, "code": "._scheduler), ] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests) !=len(dependency_classpath): for dep in dependency_classpath", "label": 1}, {"snippet_id": 11834, "code": "]} return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get('X-Hub-Signature", "label": 1}, {"snippet_id": 60341, "code": ": self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported", "label": 0}, {"snippet_id": 47513, "code": "} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 50900, "code": ": raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self", "label": 1}, {"snippet_id": 80938, "code": ",inputName=None): \t\tself.logger=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl", "label": 0}, {"snippet_id": 27951, "code": "=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=", "label": 0}, {"snippet_id": 19136, "code": "=normalize_response(raw_response, request=request) if response is not None: validate_response( response=response, request_method=request_method, schema=schema ) def validate_api_call(schema, raw_request", "label": 0}, {"snippet_id": 88405, "code": " def __init__(self, options, run_tracker, target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser=None, address_mapper=None, console_outstream=None, scm=None, workspace", "label": 0}, {"snippet_id": 14720, "code": " self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled", "label": 0}, {"snippet_id": 50442, "code": " return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo", "label": 0}, {"snippet_id": 72621, "code": "\" zarr_directory_benchmark=\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode", "label": 1}, {"snippet_id": 8799, "code": "\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file", "label": 0}, {"snippet_id": 85860, "code": " pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants", "label": 0}, {"snippet_id": 45009, "code": ": ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, ", "label": 0}, {"snippet_id": 58405, "code": " TestCommentCaseRuns(BaseCaseRun): \"\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls).setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs'", "label": 0}, {"snippet_id": 89585, "code": "'home_path={} bin_path={}'.format(home_path, bin_path)) self._home=home_path self._bin_path=bin_path or(os.path.join(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version=_parse_java_version", "label": 0}, {"snippet_id": 10332, "code": " to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext", "label": 0}, {"snippet_id": 4602, "code": ". :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of", "label": 0}, {"snippet_id": 46803, "code": " listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type", "label": 0}, {"snippet_id": 94245, "code": " Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window:", "label": 0}, {"snippet_id": 32811, "code": " from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards", "label": 1}, {"snippet_id": 49910, "code": ", dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config,", "label": 0}, {"snippet_id": 24490, "code": " self._device_class @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\"", "label": 0}, {"snippet_id": 48275, "code": " if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked", "label": 0}, {"snippet_id": 93464, "code": "(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and ", "label": 0}, {"snippet_id": 71330, "code": ", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\"", "label": 0}, {"snippet_id": 79065, "code": "\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t", "label": 0}, {"snippet_id": 9869, "code": "\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool,", "label": 0}, {"snippet_id": 12478, "code": "(error_string_list) error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body", "label": 0}, {"snippet_id": 16146, "code": ".completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive", "label": 0}, {"snippet_id": 25814, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self", "label": 0}, {"snippet_id": 28941, "code": "._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type==", "label": 0}, {"snippet_id": 25748, "code": "< 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle", "label": 0}, {"snippet_id": 78096, "code": "[domain].remove((user, forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login': login, 'passwd': passwd}, False) def send_to_wm(frames): msg=[frames[0]] msg.extend(wzrpc", "label": 0}, {"snippet_id": 29586, "code": "[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints", "label": 0}, {"snippet_id": 82380, "code": "\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride", "label": 0}, {"snippet_id": 42120, "code": "\"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self", "label": 0}, {"snippet_id": 49211, "code": " not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=", "label": 0}, {"snippet_id": 27293, "code": ", 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv", "label": 1}, {"snippet_id": 19773, "code": " debug_main(addr, name, kind, *extra, **kwargs) if __name__=='__main__': args, extra=parse_args() main(args.address, args.name, args.kind, extra, nodebug=args.nodebug, singlesession=args.single_session)", "label": 1}, {"snippet_id": 43920, "code": " rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not", "label": 0}, {"snippet_id": 10045, "code": " to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw,", "label": 0}, {"snippet_id": 65274, "code": " GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for", "label": 0}, {"snippet_id": 72527, "code": " config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the", "label": 0}, {"snippet_id": 73992, "code": " chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError", "label": 0}, {"snippet_id": 21965, "code": " ssh_extra_args=None, poll_interval=None, seconds=None, check=None, syntax=None, diff=None, force_handlers=None, flush_cache=None, listtasks=None, listtags=None, module_path=None): self.verbosity=verbosity self", "label": 0}, {"snippet_id": 23506, "code": ", remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user(username): raise OSUtilError((\"User{0} is a system user, \" \"will not set password.\").format(username)", "label": 0}, {"snippet_id": 8163, "code": " abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field", "label": 0}, {"snippet_id": 83761, "code": ", client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception", "label": 0}, {"snippet_id": 3210, "code": "'master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res: if \"depends\" in node.component: for dep in node.component['depends'", "label": 0}, {"snippet_id": 50106, "code": " logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code", "label": 0}, {"snippet_id": 29852, "code": "(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def", "label": 0}, {"snippet_id": 61187, "code": "(c) @(fry(b) @ frz(a)) def ket(*args): r\"\"\"Input validation for an arbitary state vector. Args: args(array): NumPy array. Returns: array: normalised array. \"\"\" state=np.asarray(args) return state/np.linalg", "label": 0}, {"snippet_id": 4210, "code": ", output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms", "label": 0}, {"snippet_id": 63554, "code": " stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state(job_state) run_results=client.full_status() stdout=run_results.get('stdout', '') stderr=run_results.get('stderr', '", "label": 0}, {"snippet_id": 94862, "code": " def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center) main_window.show() sys.exit(app.exec_())", "label": 0}, {"snippet_id": 36220, "code": " RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"", "label": 0}, {"snippet_id": 14794, "code": " return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr))", "label": 0}, {"snippet_id": 70657, "code": "(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self", "label": 0}, {"snippet_id": 22129, "code": ".variable_manager, loader=self.loader, options=self.options, passwords={}) def run(self, job_id): \"\"\"Run the playbook and returns the playbook's stats.\"\"\" self.variable_manager.extra_vars={'job_id': job_id", "label": 0}, {"snippet_id": 10740, "code": " text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze", "label": 1}, {"snippet_id": 91924, "code": "'] class PythonNativeCodeError(Exception): pass @classmethod def register_options(cls, register): super(PythonNativeCode, cls).register_options(register) register('--native-source-extensions', type=list", "label": 0}, {"snippet_id": 64284, "code": ".path_mapper.remote_output_path_rewrite( wrapper_path) results.append( self._dataset_path( local_output_path, remote_path)) return results def input_paths( self): local_input_paths=self._wrapper_input_paths", "label": 0}, {"snippet_id": 38788, "code": " list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock", "label": 0}, {"snippet_id": 77963, "code": " domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info", "label": 0}, {"snippet_id": 80101, "code": "=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection arguments') manualFormArgs.add_argument(\"-m\",\"-", "label": 0}, {"snippet_id": 59428, "code": "]) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self)", "label": 0}, {"snippet_id": 32116, "code": " inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 92309, "code": " print(\"HORK\" in os.environ)'], stdout=new_output).wait() new_output.seek(0) self.assertEqual('False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as", "label": 0}, {"snippet_id": 86689, "code": " arg_index=0 while arg_index < len(args): arg_index +=validate(arg_index) @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform settings.", "label": 0}, {"snippet_id": 20946, "code": "._conn.iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message(self, msg): for i, handler in enumerate", "label": 1}, {"snippet_id": 61617, "code": " wires(Sequence[int]): target subsystem Returns: float: expectation value:math:`\\expect{A}=\\bra{\\psi}A\\ket{\\psi}` \"\"\" if A.shape !=(2, 2): raise ValueError('2x2 matrix required.') A=self.expand_one(A, wires", "label": 0}, {"snippet_id": 40812, "code": " pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the", "label": 0}, {"snippet_id": 93165, "code": " import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging", "label": 0}, {"snippet_id": 65048, "code": "(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type", "label": 0}, {"snippet_id": 70526, "code": " __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc", "label": 0}, {"snippet_id": 65774, "code": "\", 1, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, ", "label": 0}, {"snippet_id": 75419, "code": "): iden=self.iden_reqid_map.get_key(reqid) if seqnum==0: self.iden_reqid_map.del_value(iden, reqid) msg=list(iden) msg.append(b'') msg.extend(make_rep_msg(reqid, seqnum, status, answer)) return msg def", "label": 0}, {"snippet_id": 94747, "code": " \" \"control is taken care of the remote master invoking \" \"this command.\\nIf run with the --kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and", "label": 0}, {"snippet_id": 91614, "code": ", UrlToFetch(url, digest)) transitive_hydrated_targets=yield Get( TransitiveHydratedTargets, BuildFileAddresses((test_target.address,)) ) all_targets=[t.adaptor for t in transitive_hydrated_targets.closure", "label": 0}, {"snippet_id": 57564, "code": " plan_from_request_or_none(self.request, pk_enough) except Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene(objects=self._update_objects, field=self.target_field, value=self.new_value) if", "label": 0}, {"snippet_id": 63661, "code": ") except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker", "label": 0}, {"snippet_id": 35576, "code": ".take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\"", "label": 0}, {"snippet_id": 40994, "code": " in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name", "label": 0}, {"snippet_id": 72629, "code": " output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location, overwrite=overwrite_mode) elif command==", "label": 0}, {"snippet_id": 4760, "code": " is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords", "label": 0}, {"snippet_id": 73040, "code": "\" remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative os.mkdir(local_path) print(\"[Setup][FTP] Created local folder:{}\".format(local_path)) except", "label": 0}, {"snippet_id": 56291, "code": ".validations import validate_bug_id def check_permission(request, ctype): perm='%s.change_%s' % tuple(ctype.split('.')) if request.user.has_perm(perm): return True return False def strip_parameters(request_dict", "label": 0}, {"snippet_id": 80823, "code": " \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append", "label": 1}, {"snippet_id": 68172, "code": " msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs", "label": 1}, {"snippet_id": 80166, "code": "-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0", "label": 0}, {"snippet_id": 46805, "code": " snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain", "label": 0}, {"snippet_id": 37575, "code": " for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self", "label": 0}, {"snippet_id": 10115, "code": "(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of", "label": 0}, {"snippet_id": 17436, "code": " if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash", "label": 0}, {"snippet_id": 3589, "code": "['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive", "label": 0}, {"snippet_id": 86580, "code": "(__name__) class BaseZincCompile(JvmCompile): \"\"\"An abstract base class for zinc compilation tasks.\"\"\" _name='zinc' @staticmethod def _write_scalac_plugin_info(resources_dir, scalac_plugin_target): scalac_plugin_info_file", "label": 1}, {"snippet_id": 58099, "code": " bugs: if bug.case_run_id==run.pk: run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs(p_pks, target): \"\"\" Get Component, Version,", "label": 0}, {"snippet_id": 73560, "code": ".DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH", "label": 0}, {"snippet_id": 30729, "code": " self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self", "label": 0}, {"snippet_id": 57311, "code": ") except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"\" Update Case Run status. ", "label": 0}, {"snippet_id": 50516, "code": "*resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo", "label": 0}, {"snippet_id": 74458, "code": " self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration. \"\"\" enabled=False server=\"\" username=\"\" password=", "label": 0}, {"snippet_id": 63632, "code": "( message, exception=True) log.exception(\"failure finishing job %d\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements", "label": 0}, {"snippet_id": 82838, "code": ".error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(", "label": 0}, {"snippet_id": 11659, "code": " file_name else EXIT_CODE_NOT_WRITTEN except HostUnreachableException: LOG.warn(\"Target url{0} unreachable. Could not get yaml config!\".format(arg['URL'])) exit_code=EXIT_CODE_NOT_WRITTEN except ConfigurationContainsUndefinedVariables", "label": 0}, {"snippet_id": 65410, "code": " CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from", "label": 0}, {"snippet_id": 58508, "code": " test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', ", "label": 0}, {"snippet_id": 48347, "code": " \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name", "label": 0}, {"snippet_id": 25677, "code": "._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280", "label": 0}, {"snippet_id": 45491, "code": " broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard", "label": 0}, {"snippet_id": 36613, "code": ".workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self", "label": 0}, {"snippet_id": 83241, "code": ".__async_update) return job_state status=client.get_status() except Exception: self.mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return job_state", "label": 0}, {"snippet_id": 57166, "code": "._default_manager.filter(pk__in=object_pk) if not targets: return say_no('No record found') if not hasattr(targets[0], field): return say_no('%s has no field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'):", "label": 0}, {"snippet_id": 32699, "code": " Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1", "label": 0}, {"snippet_id": 64064, "code": " no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is no guarentee that it will contain all the datatypes available to this Galaxy. \"\"\"", "label": 0}, {"snippet_id": 12115, "code": "\"pr_number\"])) r=requests.get(diff_url, headers=diff_headers, auth=auth) patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) files={} for patchset in patch: file=patchset.target_file[1:", "label": 0}, {"snippet_id": 84583, "code": " subsystem_dependencies(cls): return super(CountLinesOfCode, cls).subsystem_dependencies() +(ClocBinary,) @classmethod def register_options(cls, register): super(CountLinesOfCode, cls).register_options(register) register(", "label": 0}, {"snippet_id": 55210, "code": " disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:", "label": 0}, {"snippet_id": 49002, "code": "\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter", "label": 0}, {"snippet_id": 13358, "code": "//api.github.com/repos/{}/contents/{}\" url=url.format(fullname, file) params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params", "label": 0}, {"snippet_id": 69200, "code": " cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen", "label": 0}, {"snippet_id": 14652, "code": " return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest())", "label": 0}, {"snippet_id": 84034, "code": ".command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state,", "label": 0}, {"snippet_id": 81913, "code": "\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"", "label": 0}, {"snippet_id": 88004, "code": "-Xplugin: flag, which seems excessive. Instead, external plugins should be published as \"fat jars\"(which appears to be the norm, since SBT doesn't support plugins with dependencies anyway). \"\"\" plugin_names", "label": 0}, {"snippet_id": 13740, "code": "=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals", "label": 0}, {"snippet_id": 21663, "code": ", step=0.01), np.arange(start=X_set[:, 1].min() -1, stop=X_set[:, 1].max() +1, step=0.01)) plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha=0.75, cmap", "label": 0}, {"snippet_id": 49958, "code": " dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores))", "label": 0}, {"snippet_id": 75057, "code": ", method, data): domain, page=data self.p.log.info('Recvd page %s, working on', reqid) res=self.ev.solve_capage(domain, page) self.p.log.info('Done, sending answer: %s', res) self.p.send_success_rep(reqid", "label": 0}, {"snippet_id": 66202, "code": "\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict", "label": 0}, {"snippet_id": 1432, "code": "-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt", "label": 0}, {"snippet_id": 32842, "code": " class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None", "label": 0}, {"snippet_id": 20035, "code": ", script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None: def start(*args, **kwargs): return DebugAdapter.start_wrapper_script( script, *args, **kwargs", "label": 0}, {"snippet_id": 23426, "code": " account with 'username' \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None: cmd=\"pw useradd", "label": 0}, {"snippet_id": 89332, "code": " from pants.base.revision import Revision from pants.java.util import execute_java, execute_java_async from pants.subsystem.subsystem import Subsystem from pants.util.contextutil import temporary_dir from", "label": 0}, {"snippet_id": 1036, "code": "(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':'", "label": 0}, {"snippet_id": 15198, "code": " from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost", "label": 0}, {"snippet_id": 19608, "code": "('--single-session',): supported.append(arg) elif not arg.startswith('-'): supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv", "label": 1}, {"snippet_id": 60024, "code": " keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend", "label": 0}, {"snippet_id": 67561, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %", "label": 0}, {"snippet_id": 52790, "code": " os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove", "label": 0}, {"snippet_id": 69215, "code": ".is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg", "label": 0}, {"snippet_id": 47594, "code": "\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self", "label": 0}, {"snippet_id": 3297, "code": ": self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started", "label": 0}, {"snippet_id": 44231, "code": "\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make", "label": 0}, {"snippet_id": 45584, "code": "\"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try", "label": 0}, {"snippet_id": 68687, "code": ") elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled", "label": 0}, {"snippet_id": 2289, "code": " wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors", "label": 0}, {"snippet_id": 63888, "code": ".Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states", "label": 0}, {"snippet_id": 81498, "code": "\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues.clear() \t\treturn", "label": 0}, {"snippet_id": 31471, "code": "\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io", "label": 0}, {"snippet_id": 29774, "code": "\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value", "label": 0}, {"snippet_id": 31104, "code": " if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for", "label": 0}, {"snippet_id": 70074, "code": ".Lustre.FileSystem import * class GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0:", "label": 0}, {"snippet_id": 26511, "code": " the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name", "label": 0}, {"snippet_id": 51421, "code": " shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An", "label": 0}, {"snippet_id": 62422, "code": ".backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return", "label": 0}, {"snippet_id": 82447, "code": "-creds must be used with --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0])", "label": 0}, {"snippet_id": 59880, "code": " CNOT]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator'", "label": 0}, {"snippet_id": 48424, "code": " self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 67447, "code": " get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs", "label": 0}, {"snippet_id": 23409, "code": "(hostname), chk_err=False) def restart_ssh_service(self): return shellutil.run('service sshd restart', chk_err=False) def useradd(self, username, expiration=None): \"\"\" Create user account with 'username' \"\"\"", "label": 1}, {"snippet_id": 71242, "code": " dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(", "label": 0}, {"snippet_id": 59368, "code": "'ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])", "label": 0}, {"snippet_id": 18957, "code": ") elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts.scheme and parts.netloc: response=requests.get(source) if isinstance(response.content, six.binary_type): raw_source", "label": 0}, {"snippet_id": 53665, "code": ".rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not", "label": 0}, {"snippet_id": 77621, "code": "() self.userqueues[domain]=uq return uq def load_targets(self): fname=self.targetsfile if not os.path.isfile(fname): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data", "label": 0}, {"snippet_id": 38008, "code": " matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict", "label": 0}, {"snippet_id": 54958, "code": " forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try:", "label": 0}, {"snippet_id": 61935, "code": "----- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import", "label": 0}, {"snippet_id": 30265, "code": ", end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start, end=index", "label": 0}, {"snippet_id": 31074, "code": " ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output(", "label": 0}, {"snippet_id": 54079, "code": ")), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize", "label": 0}, {"snippet_id": 40401, "code": ": f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group", "label": 0}, {"snippet_id": 24247, "code": "], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust", "label": 0}, {"snippet_id": 35733, "code": " self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self", "label": 0}, {"snippet_id": 14160, "code": " syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData", "label": 0}, {"snippet_id": 68056, "code": ">][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system", "label": 0}, {"snippet_id": 54805, "code": " printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False", "label": 0}, {"snippet_id": 78846, "code": "\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry", "label": 0}, {"snippet_id": 61639, "code": "._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation value.'.format(expectation.imag)) return expectation.real def reset(self): \"", "label": 0}, {"snippet_id": 27185, "code": "], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24", "label": 0}, {"snippet_id": 14042, "code": "() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data", "label": 0}, {"snippet_id": 14297, "code": ".GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file: self._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush", "label": 1}, {"snippet_id": 12203, "code": " py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}\" url=url.format(repository, after_commit_hash, file) r=requests.get(url, headers=headers, auth=auth) with open(\"file_to_check.py", "label": 0}, {"snippet_id": 29445, "code": "(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__", "label": 0}, {"snippet_id": 28979, "code": ".type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state", "label": 0}, {"snippet_id": 29764, "code": "\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value", "label": 0}, {"snippet_id": 35889, "code": " checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class", "label": 0}, {"snippet_id": 23779, "code": " raise OSUtilError(\"Failed to get processor cores.\") try: return int(output) except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self, timeout)", "label": 0}, {"snippet_id": 82347, "code": ": \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template", "label": 0}, {"snippet_id": 71498, "code": "%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info", "label": 1}, {"snippet_id": 91852, "code": " pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.subsystems import pex_build_util from pants.backend.python.subsystems.python_setup import PythonSetup from pants", "label": 0}, {"snippet_id": 60974, "code": " the expectation.\"\"\" raise NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset the backend state. After the reset the backend should be as if it was just constructed. Most importantly the", "label": 0}, {"snippet_id": 86862, "code": " def get_fatal_warnings_enabled_args_default(cls): return('-S-Xfatal-warnings', '-C-Werror') @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls", "label": 0}, {"snippet_id": 23231, "code": " retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned more than{0} up ' 'network interfaces.'), expected) sock=buff.tostring() for i in range(0", "label": 0}, {"snippet_id": 90869, "code": "/jvm` on Linux machines. :API: public \"\"\" class Error(Distribution.Error): \"\"\"Error locating a java distribution. :API: public \"\"\" @classmethod def cached(cls, minimum_version=None, maximum_version=None", "label": 0}, {"snippet_id": 79873, "code": "\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs", "label": 0}, {"snippet_id": 22238, "code": "] if template is None and template in self.conf: template=self.conf['template'] if log_file is None: if 'log_file' in self.conf: log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template", "label": 0}, {"snippet_id": 17978, "code": ": return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache", "label": 0}, {"snippet_id": 16642, "code": " qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self", "label": 0}, {"snippet_id": 19949, "code": " managed adapter') if adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') if addr is None: addr=adapter.address self._attach(addr", "label": 0}, {"snippet_id": 9634, "code": " %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), keywords[kw], encode_for_xml(categories[kw]))) for field, keywords in((auth_field, output_complete[\"Author keywords\"]), (acro_field,", "label": 0}, {"snippet_id": 21623, "code": " X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors import", "label": 0}, {"snippet_id": 24985, "code": "['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status", "label": 0}, {"snippet_id": 7325, "code": " code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code", "label": 0}, {"snippet_id": 79401, "code": ".warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t", "label": 0}, {"snippet_id": 37356, "code": " output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} ", "label": 0}, {"snippet_id": 92939, "code": ".fileno(), 2) self.assertEqual(stdin_data, sys.stdin.read().strip()) print(stdout_data, file=sys.stdout) yield print(stderr_data, file=sys.stderr) tmp_stdout.seek(0) tmp_stderr.seek(0) self.assertEqual", "label": 0}, {"snippet_id": 16113, "code": " try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data", "label": 0}, {"snippet_id": 65669, "code": ".get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other)", "label": 1}, {"snippet_id": 50951, "code": ".S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path", "label": 0}, {"snippet_id": 24461, "code": ".module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property", "label": 0}, {"snippet_id": 60380, "code": " isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('fock', cutoff_dim=self.cutoff) reg=self._observe.wires if self._observe.name=", "label": 0}, {"snippet_id": 83402, "code": " submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\"", "label": 0}, {"snippet_id": 20707, "code": " print(' <-', msg) if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else: resp_awaiter=self._get_awaiter_for_request(req, ", "label": 0}, {"snippet_id": 4143, "code": " text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils", "label": 1}, {"snippet_id": 49087, "code": "=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. ", "label": 0}, {"snippet_id": 8517, "code": " > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\"", "label": 1}, {"snippet_id": 31652, "code": "=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self", "label": 0}, {"snippet_id": 20732, "code": " resp_awaiter def add_handler(self, handler, **kwargs): if self.closed: raise RuntimeError('session closed') self._add_handler(handler, **kwargs) @contextlib.contextmanager def wait_for_event(self, event, ", "label": 0}, {"snippet_id": 88063, "code": "._confs)] rel_classpath_elements=rel_classpath_elements or[classpath_element] if active_plugins.get(name, rel_classpath_elements) !=rel_classpath_elements: raise TaskError('Plugin{} defined in{} and in{}'", "label": 0}, {"snippet_id": 31460, "code": " __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict", "label": 0}, {"snippet_id": 9653, "code": "\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience", "label": 0}, {"snippet_id": 17511, "code": ": return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype", "label": 0}, {"snippet_id": 81555, "code": ".status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t", "label": 0}, {"snippet_id": 76115, "code": ") def set_route_type(self, i, m, t): self.log.debug('Setting %s,%s type to %d', i, m, t) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Succesfully set route", "label": 0}, {"snippet_id": 82429, "code": "\tcoloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if", "label": 0}, {"snippet_id": 34786, "code": ".file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards", "label": 1}, {"snippet_id": 27174, "code": " None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 46929, "code": "(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input", "label": 0}, {"snippet_id": 4077, "code": " URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text,", "label": 0}, {"snippet_id": 24972, "code": "'GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=", "label": 0}, {"snippet_id": 58442, "code": ".pk, self.case_run_2.pk]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Comments needed'}) def test_refuse_if_missing_no_case_run_pk(self): self", "label": 0}, {"snippet_id": 57368, "code": "**{field: value}) if hasattr(model, 'mail_scene'): from tcms.core.utils.mailto import mailto mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk, ", "label": 0}, {"snippet_id": 2139, "code": " action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group", "label": 0}, {"snippet_id": 70588, "code": " % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def", "label": 0}, {"snippet_id": 71295, "code": ".has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], ", "label": 0}, {"snippet_id": 16576, "code": "'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync(", "label": 0}, {"snippet_id": 8118, "code": "\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close", "label": 0}, {"snippet_id": 90733, "code": " Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" for location in itertools.chain(self._distribution_environment.jvm_locations):", "label": 0}, {"snippet_id": 55651, "code": "): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input", "label": 0}, {"snippet_id": 39433, "code": "(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(", "label": 0}, {"snippet_id": 25371, "code": " module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data", "label": 1}, {"snippet_id": 84401, "code": "._config_directory=remote_job_config[ \"configs_directory\"] self._working_directory=remote_job_config[ \"working_directory\"] self._sep=remote_job_config[ \"system_properties\"][ \"separator\"] self._tool_dir", "label": 0}, {"snippet_id": 48813, "code": " ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular", "label": 0}, {"snippet_id": 65751, "code": " [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 54872, "code": ".global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self", "label": 0}, {"snippet_id": 16667, "code": "=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str(", "label": 0}, {"snippet_id": 77739, "code": "'beon.ru' and t['forum']=='anonymous': try: add_target_exc(t['id'], t['user']) except ValueError: pass def terminate(self): msg=[b'GLOBAL'] msg.extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate',[])) if", "label": 0}, {"snippet_id": 63618, "code": " find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception", "label": 0}, {"snippet_id": 52973, "code": ".dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self", "label": 0}, {"snippet_id": 5702, "code": " kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie", "label": 0}, {"snippet_id": 75569, "code": "] return(b'Router', b'auth-set-route-type', args, reqid) def make_auth_clear_data(self, reqid=None): if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self", "label": 0}, {"snippet_id": 24015, "code": "\" try to search 'blkvscX' and 'storvscX' to find device name \"\"\" output=output.rstrip() cmd_search_blkvsc=\"camcontrol devlist -b | grep blkvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil", "label": 0}, {"snippet_id": 58620, "code": " cls.permission='testplans.change_testplan' cls.update_url=reverse('ajax-update') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): self.client", "label": 0}, {"snippet_id": 91783, "code": "(output_pytest_requirements_pex_filename)), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=merged_input_files, description='Run pytest for{}'.format(test_target.address.reference()), ) result", "label": 0}, {"snippet_id": 70226, "code": ") def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print", "label": 0}, {"snippet_id": 91689, "code": "(requirements_pex_argv), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=pex_snapshot.directory_digest, description='Resolve requirements:{}'.format(\", \".join(all_requirements)", "label": 1}, {"snippet_id": 68741, "code": "\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([", "label": 0}, {"snippet_id": 62863, "code": "-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum", "label": 0}, {"snippet_id": 81069, "code": "(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit() \t\tif len(detectedForms) > 1: \t", "label": 0}, {"snippet_id": 9861, "code": ">Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches,", "label": 0}, {"snippet_id": 73285, "code": "(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip(path_str, path_temp_output) pathlist_vcf_temp=pathlib.Path(temp_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_temp: path_temp_str", "label": 0}, {"snippet_id": 70793, "code": ": status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target", "label": 0}, {"snippet_id": 20176, "code": " RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None addr=('localhost', self._addr.port) self._run_server_ex=None def run()", "label": 0}, {"snippet_id": 49319, "code": " self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring", "label": 0}, {"snippet_id": 40311, "code": "?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing", "label": 0}, {"snippet_id": 84477, "code": "=\"%s_files\" % remote_path[ 0:-len( \".dat\")] return local_dataset_path.with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory", "label": 0}, {"snippet_id": 52340, "code": ".dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f", "label": 0}, {"snippet_id": 72456, "code": "\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the benchmark run), and config argument for where is the", "label": 0}, {"snippet_id": 54388, "code": " reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards", "label": 0}, {"snippet_id": 29174, "code": " file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(", "label": 0}, {"snippet_id": 35410, "code": " values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard", "label": 0}, {"snippet_id": 33391, "code": ") if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have", "label": 0}, {"snippet_id": 68931, "code": " import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose", "label": 0}, {"snippet_id": 93959, "code": " %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name", "label": 0}, {"snippet_id": 8674, "code": " print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as", "label": 0}, {"snippet_id": 50821, "code": " def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function", "label": 0}, {"snippet_id": 37394, "code": " an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if", "label": 0}, {"snippet_id": 91970, "code": " self.get_options().native_source_extensions @memoized_property def native_toolchain(self): return NativeToolchain.scoped_instance(self) @memoized_property def _python_setup(self): return PythonSetup.global_instance", "label": 0}, {"snippet_id": 63825, "code": " signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id)) client=self", "label": 0}, {"snippet_id": 92743, "code": "()) self.assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t.elapsed, 0.1) clock.sleep(0.1) self.assertTrue(t.finish is None) self.assertGreater(t.elapsed, 0.2) self.assertLess(t.finish, clock", "label": 0}, {"snippet_id": 64221, "code": ".local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config", "label": 0}, {"snippet_id": 69773, "code": " self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: ", "label": 1}, {"snippet_id": 3074, "code": "(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return", "label": 1}, {"snippet_id": 40585, "code": " value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags", "label": 1}, {"snippet_id": 31472, "code": " os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand", "label": 0}, {"snippet_id": 15528, "code": "([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 41873, "code": "(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected", "label": 0}, {"snippet_id": 48683, "code": ".input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards)", "label": 0}, {"snippet_id": 1799, "code": " elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[]", "label": 0}, {"snippet_id": 86494, "code": ".jvm_target import JvmTarget from pants.backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile.jvm_compile", "label": 0}, {"snippet_id": 49402, "code": "=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes", "label": 0}, {"snippet_id": 90247, "code": ":class:`DistributionEnvironment.Location` \"\"\" class _EnvVarEnvironment(_DistributionEnvironment): @property def jvm_locations(self): def env_home(home_env_var): home=os.environ.get(home_env_var) return", "label": 0}, {"snippet_id": 26666, "code": "'battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data", "label": 0}, {"snippet_id": 29004, "code": "'rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] ", "label": 0}, {"snippet_id": 54469, "code": " from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake.persistence import", "label": 1}, {"snippet_id": 66130, "code": "\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=", "label": 0}, {"snippet_id": 40653, "code": " shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else", "label": 1}, {"snippet_id": 46606, "code": "(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist):", "label": 0}, {"snippet_id": 6352, "code": " text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML", "label": 0}, {"snippet_id": 38917, "code": " targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format(", "label": 0}, {"snippet_id": 36226, "code": " RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule", "label": 0}, {"snippet_id": 37403, "code": " input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item", "label": 0}, {"snippet_id": 78775, "code": " import urljoin,urlparse from threading import Lock class UploadForm: \tdef __init__(self,notRegex,trueRegex,session,size,postData,uploadsFolder=None,formUrl=None,formAction=None,inputName=None): \t\tself", "label": 0}, {"snippet_id": 16220, "code": " SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer", "label": 0}, {"snippet_id": 72199, "code": " supported and returned here, but others are dropped due to protocol limitations.\"\"\" permissions.checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args(args) netname=args.network", "label": 0}, {"snippet_id": 60703, "code": "(reg, *self._observe.params) elif self._observe.name=='Displacement': ex=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self", "label": 0}, {"snippet_id": 2526, "code": " not self.config: self.logger.error(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host ", "label": 0}, {"snippet_id": 16403, "code": " self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines", "label": 0}, {"snippet_id": 45667, "code": "(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def", "label": 0}, {"snippet_id": 16532, "code": " def NativeFiletypeCompletionUsable( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse(", "label": 0}, {"snippet_id": 59985, "code": " Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', ", "label": 0}, {"snippet_id": 37946, "code": "}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self", "label": 0}, {"snippet_id": 53279, "code": " self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other", "label": 0}, {"snippet_id": 66970, "code": "] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len", "label": 0}, {"snippet_id": 85886, "code": ".backend.jvm.targets.jvm_target import JvmTarget from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from pants.base.exceptions import TaskError from pants.base.workunit import WorkUnit", "label": 0}, {"snippet_id": 68541, "code": ".clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\",", "label": 0}, {"snippet_id": 61024, "code": " 2*2 Hermitian matrix Returns: (vector[float], list[array[complex]]):(a, P): eigenvalues and hermitian projectors such that:math:`A=\\sum_k a_k P_k`. \"\"\" d, v=eigh(A) P=[] for k in range(2): temp=v[:, k]", "label": 0}, {"snippet_id": 4811, "code": " composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p", "label": 0}, {"snippet_id": 19677, "code": "-single-session', action='store_true') parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None)", "label": 0}, {"snippet_id": 36459, "code": ".add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self)", "label": 0}, {"snippet_id": 34354, "code": " @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None", "label": 0}, {"snippet_id": 34135, "code": " if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule", "label": 0}, {"snippet_id": 88315, "code": " pants.ini and any flags they have exposed here as well as information about the targets involved in the run. Advanced uses of the context include adding new targets to it for upstream or downstream goals", "label": 0}, {"snippet_id": 6928, "code": ",....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db", "label": 0}, {"snippet_id": 80596, "code": " proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form", "label": 0}, {"snippet_id": 17107, "code": " response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf", "label": 0}, {"snippet_id": 42257, "code": " files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if", "label": 0}, {"snippet_id": 94499, "code": ": logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp", "label": 0}, {"snippet_id": 46262, "code": "=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=", "label": 0}, {"snippet_id": 77471, "code": ".append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads(self): return self.spawn_nworkers(0, WipeThread, self.c.tcount", "label": 0}, {"snippet_id": 13435, "code": "/pulls\" url=url.format(data[\"target_repo_fullname\"]) request_json={ \"title\": \"Fix pep8 errors\", \"head\": \"pep8speaks:{}\".format(data[\"new_branch\"]), \"base\": data[\"target_repo_branch\"], \"body\": \"The changes", "label": 0}, {"snippet_id": 46820, "code": " type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile", "label": 0}, {"snippet_id": 49290, "code": " of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException()", "label": 0}, {"snippet_id": 83847, "code": ".query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return True except OSError, e: if e.errno", "label": 0}, {"snippet_id": 29406, "code": "(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self", "label": 0}, {"snippet_id": 2594, "code": "=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if", "label": 0}, {"snippet_id": 89010, "code": " from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies during the course of the run. See Target", "label": 0}, {"snippet_id": 90899, "code": " given constraints and returns it. :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version to look for(eg, 1.7). The", "label": 0}, {"snippet_id": 59657, "code": " if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend", "label": 0}, {"snippet_id": 82532, "code": "{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local,", "label": 0}, {"snippet_id": 2667, "code": " for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def", "label": 0}, {"snippet_id": 13954, "code": " timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri(", "label": 1}, {"snippet_id": 5799, "code": " sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and", "label": 0}, {"snippet_id": 19731, "code": " ns.pop('port')) else: args.address=Address.as_client(clienthost, ns.pop('port')) module=ns.pop('module') filename=ns.pop('filename') if module is None: args.name=filename args.kind='script' else: args", "label": 0}, {"snippet_id": 15665, "code": ": if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message'])", "label": 0}, {"snippet_id": 16416, "code": "-NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self", "label": 0}, {"snippet_id": 76442, "code": " nfr in self.wz.parse_router_msg(frames): self.wz_sock.send_multipart(nfr) except wzrpc.WZErrorRep as e: self.log.info(e) self.wz_sock.send_multipart(e.rep_msg) except wzrpc.WZError as e: self.log.warn", "label": 0}, {"snippet_id": 14872, "code": " UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self", "label": 0}, {"snippet_id": 85395, "code": " for Pants' zinc wrapper tool.\"\"\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main' ZINC_EXTRACT_MAIN='org.pantsbuild.zinc.extractor.Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME", "label": 0}, {"snippet_id": 91339, "code": " PythonApp, PythonBinary.alias(): PythonBinary, PythonLibrary.alias(): PythonLibrary, PythonTests.alias(): PythonTests, PythonDistribution.alias(): PythonDistribution, 'python_requirement_library': PythonRequirementLibrary", "label": 0}, {"snippet_id": 60231, "code": " CZgate, 'Displacement': Dgate, 'Kerr': Kgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device): \"\"\"StrawberryFields", "label": 0}, {"snippet_id": 17753, "code": "._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded", "label": 0}, {"snippet_id": 72520, "code": "=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser", "label": 0}, {"snippet_id": 18325, "code": " filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port", "label": 0}, {"snippet_id": 42381, "code": ") self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno", "label": 0}, {"snippet_id": 1285, "code": " wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n'", "label": 0}, {"snippet_id": 75985, "code": ".e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3}'.\\ format(i, m, wzrpc.name_status(status), repr(data))) elif wzrpc.status.e_timeout: self.log.warn('Timeout{0}", "label": 1}, {"snippet_id": 65495, "code": " pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[", "label": 0}, {"snippet_id": 6923, "code": " dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type=", "label": 0}, {"snippet_id": 62936, "code": " time import sleep import os from.lwr_client import build_client_manager from.lwr_client import url_to_destination_params from.lwr_client import finish_job as lwr_finish_job from.lwr_client import submit_job", "label": 0}, {"snippet_id": 46926, "code": ".dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self", "label": 0}, {"snippet_id": 52789, "code": ".dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"", "label": 0}, {"snippet_id": 42665, "code": " rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files", "label": 0}, {"snippet_id": 39682, "code": "=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority", "label": 0}, {"snippet_id": 64110, "code": ",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception(NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE) metadata_kwds['exec_dir']=remote_galaxy_home outputs_directory", "label": 0}, {"snippet_id": 54860, "code": "=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else", "label": 0}, {"snippet_id": 37110, "code": " rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand", "label": 0}, {"snippet_id": 90524, "code": " the cache. :rtype::class:`pants.java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version and dist.version ", "label": 0}, {"snippet_id": 4138, "code": ".bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils", "label": 1}, {"snippet_id": 55077, "code": " logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other", "label": 0}, {"snippet_id": 68601, "code": " status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled", "label": 0}, {"snippet_id": 43854, "code": " self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name", "label": 0}, {"snippet_id": 61286, "code": "(args[0]) if A.shape[0] !=A.shape[1]: raise ValueError(\"Observable must be a square matrix.\") if not np.allclose(A, A.conj().T, atol=tolerance): raise ValueError(\"Observable must be Hermitian.\") return", "label": 0}, {"snippet_id": 81817, "code": "* '\"+t[\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data", "label": 0}, {"snippet_id": 93876, "code": " send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=", "label": 1}, {"snippet_id": 90561, "code": " a java distribution that meets the given constraints and returns it. First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm version", "label": 0}, {"snippet_id": 75984, "code": ") elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}),{2}:{3}'.\\ format(i, m, wzrpc.name_status(status), repr(data))) elif wzrpc.status.e_timeout", "label": 1}, {"snippet_id": 40099, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode &", "label": 0}, {"snippet_id": 85077, "code": "('2.12') register_scala_repl_tool('2.12') register_style_tool('2.12') def register_custom_tool(key): dummy_jardep=JarDependency('missing spec', ' //:{}'.format(key)) cls.register_jvm_tool(register, cls", "label": 1}, {"snippet_id": 71606, "code": "() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes", "label": 0}, {"snippet_id": 9034, "code": "(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text", "label": 0}, {"snippet_id": 27007, "code": "'rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status", "label": 0}, {"snippet_id": 92714, "code": ": def __init__(self): self._time=0.0 def time(self): ret=self._time self._time +=0.0001 return ret def sleep(self, duration): self._time +=duration clock=FakeClock() with Timer(clock=clock) as t: self.assertLess", "label": 0}, {"snippet_id": 69462, "code": "\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list)", "label": 0}, {"snippet_id": 81366, "code": "\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t \tdef detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text", "label": 0}, {"snippet_id": 19096, "code": " validate_api_request(schema, raw_request): request=normalize_request(raw_request) with ErrorDict(): validate_request(request=request, schema=schema) def validate_api_response(schema, raw_response, request_method='get'", "label": 0}, {"snippet_id": 94423, "code": "=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\"", "label": 1}, {"snippet_id": 61120, "code": " theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm(-1j * theta/2 * Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args", "label": 0}, {"snippet_id": 27566, "code": "'sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure':", "label": 0}, {"snippet_id": 7975, "code": " kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie", "label": 0}, {"snippet_id": 9955, "code": " iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False):", "label": 0}, {"snippet_id": 4608, "code": " are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position,", "label": 0}, {"snippet_id": 58041, "code": "(request) if error: return say_no(error) runs=TestCaseRun.objects.filter(pk__in=data['runs']) bug_system_id=data['bug_system_id'] bug_ids=data['bugs'] try: validate_bug_id(bug_ids, bug_system_id) except", "label": 0}, {"snippet_id": 32960, "code": ") @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause", "label": 0}, {"snippet_id": 76388, "code": " e: return def poll(self, timeout=None): try: socks=dict(self.poller.poll(timeout if timeout !=None else self.poll_timeout)) except zmq.ZMQError as e: self.log.error(e) return if socks.get(self.sig_sock", "label": 1}, {"snippet_id": 38733, "code": "(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun", "label": 0}, {"snippet_id": 22636, "code": " why I pass here :param hostname: The hostname to set on the device \"\"\" return None def useradd(self, username, expiration=None): \"\"\"Create user account using tmsh Our policy is to create two accounts when", "label": 1}, {"snippet_id": 63354, "code": " job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory'], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution, )", "label": 0}, {"snippet_id": 57578, "code": "=self._update_objects, field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context", "label": 0}, {"snippet_id": 17405, "code": " self._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE ", "label": 0}, {"snippet_id": 26770, "code": "'WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'", "label": 0}, {"snippet_id": 63092, "code": ".mark_as_finished(job_state) return None job_state=self.__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status", "label": 0}, {"snippet_id": 6581, "code": " get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False,", "label": 0}, {"snippet_id": 29124, "code": " snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not", "label": 0}, {"snippet_id": 9711, "code": " keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords", "label": 0}, {"snippet_id": 13969, "code": " timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method):", "label": 1}, {"snippet_id": 79640, "code": " in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload", "label": 0}, {"snippet_id": 86328, "code": " if return_code: raise TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items", "label": 0}, {"snippet_id": 66511, "code": ": RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 59935, "code": " IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator", "label": 0}, {"snippet_id": 5733, "code": "\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1", "label": 0}, {"snippet_id": 48926, "code": "(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given", "label": 0}, {"snippet_id": 47483, "code": " raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources", "label": 0}, {"snippet_id": 79024, "code": ".uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(", "label": 0}, {"snippet_id": 18307, "code": ", '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options", "label": 0}, {"snippet_id": 53313, "code": ".wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards", "label": 0}, {"snippet_id": 29346, "code": "\"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self", "label": 0}, {"snippet_id": 51494, "code": ") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( ", "label": 1}, {"snippet_id": 24475, "code": " in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of", "label": 0}, {"snippet_id": 26289, "code": ", '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA", "label": 1}, {"snippet_id": 78532, "code": " %s:%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self.get_targets() if", "label": 0}, {"snippet_id": 67491, "code": " from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler", "label": 0}, {"snippet_id": 73303, "code": "=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(", "label": 0}, {"snippet_id": 52357, "code": ".touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f", "label": 0}, {"snippet_id": 40394, "code": ") except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()]))", "label": 0}, {"snippet_id": 63766, "code": " %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to", "label": 0}, {"snippet_id": 54064, "code": " missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)),", "label": 0}, {"snippet_id": 73212, "code": " subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc.", "label": 0}, {"snippet_id": 20433, "code": " addr, **kwargs): def connect(addr, timeout): server=create_server(addr) with socket_timeout(server, timeout): client, _=server.accept() return Connection(client, server) return cls._create(connect, addr", "label": 0}, {"snippet_id": 50542, "code": " ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=", "label": 0}, {"snippet_id": 67245, "code": " client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully", "label": 1}, {"snippet_id": 83065, "code": " AsynchronousJobState, AsynchronousJobRunner from galaxy.jobs import ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import", "label": 0}, {"snippet_id": 17028, "code": ", column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column", "label": 0}, {"snippet_id": 4548, "code": " output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched", "label": 1}, {"snippet_id": 18886, "code": " import validate_object from flex.validation.request import validate_request from flex.validation.response import validate_response def load_source(source): \"\"\" Common entry point for loading some form", "label": 0}, {"snippet_id": 80224, "code": ".template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): ", "label": 0}, {"snippet_id": 36026, "code": ") self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies", "label": 0}, {"snippet_id": 36552, "code": " for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for", "label": 0}, {"snippet_id": 88623, "code": " invalidation_report(self): return self._invalidation_report def __str__(self): ident=Target.identify(self.targets()) return 'Context(id:{}, targets:{})'.format(ident, self.targets()) @contextmanager def executing(self)", "label": 0}, {"snippet_id": 88331, "code": " include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated with. :API: public \"\"\" class Log(object", "label": 0}, {"snippet_id": 38365, "code": "._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file", "label": 0}, {"snippet_id": 44345, "code": "{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps:", "label": 0}, {"snippet_id": 54530, "code": ".workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile", "label": 0}, {"snippet_id": 72176, "code": ".IRCParser.REMAINDER) @utils.add_cmd def remote(irc, source, args): \"\"\"<network>[--service <service name>] <command> Runs <command> on the remote network <network>. Plugin responses sent using irc.reply", "label": 0}, {"snippet_id": 24866, "code": "'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state", "label": 0}, {"snippet_id": 49675, "code": " \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \"", "label": 0}, {"snippet_id": 74276, "code": "<section>[<option>] and the corresponding values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data", "label": 0}, {"snippet_id": 69277, "code": " ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError,", "label": 1}, {"snippet_id": 85003, "code": ", choices=['2.10', '2.11', '2.12', 'custom'], fingerprint=True, help='The scala platform version. If --version=custom, the targets ' '//:scala-library, //:scalac, //:scala-repl and //:scalastyle will be", "label": 0}, {"snippet_id": 40146, "code": " for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno", "label": 1}, {"snippet_id": 6419, "code": " as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger", "label": 1}, {"snippet_id": 74061, "code": "=runtime_config.vcf_to_zarr[\"blosc_compression_algorithm\"] if blosc_compression_algorithm_temp in vcf_to_zarr_blosc_algorithm_types: self.blosc_compression_algorithm=blosc_compression_algorithm_temp if", "label": 0}, {"snippet_id": 62853, "code": " observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1)", "label": 0}, {"snippet_id": 72217, "code": "(args) netname=args.network if netname==irc.name: irc.error(\"Cannot remote-send a command to the local network; use a normal command!\") return try: remoteirc=world.networkobjects[netname] except KeyError:", "label": 0}, {"snippet_id": 43971, "code": ", forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit", "label": 0}, {"snippet_id": 10080, "code": "(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*',", "label": 0}, {"snippet_id": 42247, "code": "{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run", "label": 0}, {"snippet_id": 79581, "code": " re,requests,argparse,logging,os,coloredlogs,datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0", "label": 0}, {"snippet_id": 7916, "code": "]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items()", "label": 0}, {"snippet_id": 66647, "code": "): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len", "label": 0}, {"snippet_id": 89860, "code": " return self._validated_executable(name) def validate(self): \"\"\"Validates this distribution against its configured constraints. Raises Distribution.Error if this distribution is not valid according to the", "label": 0}, {"snippet_id": 33360, "code": " ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 63114, "code": " None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id", "label": 0}, {"snippet_id": 36648, "code": " raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split(", "label": 0}, {"snippet_id": 47696, "code": ".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or self.nooutput)", "label": 0}, {"snippet_id": 77483, "code": " spawn_wipethreads(self): return self.spawn_nworkers(0, WipeThread, self.c.tcount, (self.pc, self.spawnqueue)) def spawn_evaluators(self): self.log.info('Initializing Evaluator') from evproxy import EvaluatorProxy", "label": 0}, {"snippet_id": 71529, "code": " client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ ", "label": 0}, {"snippet_id": 26866, "code": "='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 49632, "code": " try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions", "label": 0}, {"snippet_id": 12642, "code": "): PERMITTED_TO_COMMENT=False \"\"\" for old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body'].lower(): break elif 'quiet' in old_comment['body'].lower", "label": 0}, {"snippet_id": 7064, "code": " from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords", "label": 0}, {"snippet_id": 85957, "code": ".path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod def get_args_default(cls, bootstrap_option_values)", "label": 0}, {"snippet_id": 10225, "code": "(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match,", "label": 0}, {"snippet_id": 74928, "code": "=benchmark_data_input_temp if \"benchmark_dataset\" in runtime_config.benchmark: self.benchmark_dataset=runtime_config.benchmark[\"benchmark_dataset\"] if \"benchmark_aggregations\" in runtime_config.benchmark", "label": 0}, {"snippet_id": 69560, "code": "=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else", "label": 0}, {"snippet_id": 41452, "code": ".output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res", "label": 0}, {"snippet_id": 14070, "code": " request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text", "label": 0}, {"snippet_id": 73781, "code": ", runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config: ConfigurationRepresentation", "label": 0}, {"snippet_id": 51049, "code": "=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex", "label": 1}, {"snippet_id": 7527, "code": "\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted", "label": 0}, {"snippet_id": 102, "code": ",TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi", "label": 0}, {"snippet_id": 25849, "code": "=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=", "label": 0}, {"snippet_id": 78468, "code": " page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall", "label": 0}, {"snippet_id": 64087, "code": "\"use_remote_datatypes\", False)) return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def", "label": 0}, {"snippet_id": 75692, "code": " def __sinit__(self): '''Initializes thread-local interface on startup''' self.log=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker=Ticker() self.poller=zmq.Poller() s=self", "label": 0}, {"snippet_id": 95729, "code": "[Setup][Data] Decompressing file:{}\".format(path_str)) print(\" -Output:{}\".format(path_temp_output)) decompress_gzip(path_str, path_temp_output) pathlist_vcf_temp=pathlib.Path(temp_dir).glob(\"**/*.vcf\") for", "label": 0}, {"snippet_id": 36441, "code": ".output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(", "label": 0}, {"snippet_id": 28496, "code": " this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get", "label": 0}, {"snippet_id": 65974, "code": " c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0:", "label": 0}, {"snippet_id": 27438, "code": "[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self", "label": 0}, {"snippet_id": 53227, "code": " self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow", "label": 0}, {"snippet_id": 76069, "code": ") elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0},", "label": 0}, {"snippet_id": 92000, "code": " SubclassesOf(PythonDistribution): self.pydist_has_native_sources, SubclassesOf(NativeLibrary): NativeLibrary.produces_ctypes_native_library, } def _any_targets_have_native_sources(self, targets): for tgt", "label": 0}, {"snippet_id": 78472, "code": " %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page))) for t", "label": 0}, {"snippet_id": 36217, "code": " AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property", "label": 0}, {"snippet_id": 85934, "code": ".sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): \"\"\"Compile Java code using Javac.", "label": 0}, {"snippet_id": 70433, "code": " requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine", "label": 0}, {"snippet_id": 70015, "code": ". \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import", "label": 0}, {"snippet_id": 78530, "code": " targets in forum %s:%s', user, forum) self.targets.extend(targets) return found_count def scan_targets_loop(self): with cstate(self, WipeState.scanning_for_targets): while len(self.targets)==0: c=self", "label": 0}, {"snippet_id": 30719, "code": ".add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash", "label": 0}, {"snippet_id": 27909, "code": " elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" ", "label": 0}, {"snippet_id": 4573, "code": "[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords", "label": 0}, {"snippet_id": 67648, "code": ".get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start", "label": 0}, {"snippet_id": 37555, "code": " be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item", "label": 0}, {"snippet_id": 56210, "code": " from django.views.decorators.http import require_GET from django.views.decorators.http import require_POST from tcms.signals import POST_UPDATE_SIGNAL from tcms.management.models import Component, Build", "label": 0}, {"snippet_id": 1582, "code": "=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST", "label": 0}, {"snippet_id": 69567, "code": ".startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command.has_subcommand(): new_args.append(opt) else:", "label": 0}, {"snippet_id": 77387, "code": "=(), kvargs={}): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock", "label": 0}, {"snippet_id": 23949, "code": " return None g0=\"00000000\" if port_id > 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=\"000\" +ustr", "label": 0}, {"snippet_id": 80765, "code": " techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime ", "label": 1}, {"snippet_id": 29549, "code": ")) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os", "label": 0}, {"snippet_id": 86094, "code": "(compile_context.classes_dir, target) elif isinstance(target, AnnotationProcessor) and target.processors: processor_info_file=os.path.join(compile_context.classes_dir, _PROCESSOR_INFO_FILE) self._write_processor_info", "label": 0}, {"snippet_id": 27719, "code": " Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=", "label": 0}, {"snippet_id": 65844, "code": " nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target", "label": 0}, {"snippet_id": 62964, "code": " log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured", "label": 0}, {"snippet_id": 60319, "code": " self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"", "label": 1}, {"snippet_id": 13212, "code": " headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) sha=None r=requests.get(url, headers=headers, auth=auth) for ref in r.json(", "label": 0}, {"snippet_id": 66473, "code": "%s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name", "label": 0}, {"snippet_id": 697, "code": "=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in", "label": 0}, {"snippet_id": 73008, "code": "\" Recursive function that automatically downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list", "label": 0}, {"snippet_id": 24932, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self", "label": 0}, {"snippet_id": 78502, "code": "] or t in self.pc.sets['bumplimit'] or t in self.targets): continue targets.append(t) lt=len(targets) found_count +=lt if lt > 0: self.log.info('Found %d new targets in forum %s:%s', lt, user, forum) else", "label": 1}, {"snippet_id": 36280, "code": "\"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield", "label": 0}, {"snippet_id": 47853, "code": "._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output", "label": 0}, {"snippet_id": 54416, "code": " re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter", "label": 0}, {"snippet_id": 58854, "code": "=settings.DEFAULT_CHARSET), form.as_p()) class TestUpdateCasePriority(BasePlanCase): \"\"\"Test case for update_cases_default_tester\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateCasePriority, cls", "label": 1}, {"snippet_id": 80707, "code": ": \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads", "label": 0}, {"snippet_id": 15040, "code": "{ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data", "label": 0}, {"snippet_id": 19447, "code": "\"\"Return the parsed args to use in main().\"\"\" if argv is None: argv=sys.argv prog=argv[0] if prog==__file__: prog='{} -m ptvsd'.format(os.path.basename(sys.executable)) else: prog=argv[0] argv=argv[1:]", "label": 0}, {"snippet_id": 16006, "code": "( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData", "label": 0}, {"snippet_id": 36494, "code": "\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output", "label": 0}, {"snippet_id": 38314, "code": " self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd", "label": 0}, {"snippet_id": 63801, "code": ".strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses", "label": 0}, {"snippet_id": 65279, "code": ", nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type", "label": 0}, {"snippet_id": 81061, "code": " Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML", "label": 0}, {"snippet_id": 57608, "code": ").exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets().update(**{str(self.target_field): self.new_value}) def _update_default_tester", "label": 0}, {"snippet_id": 14726, "code": " logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self", "label": 0}, {"snippet_id": 6922, "code": ":return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms", "label": 0}, {"snippet_id": 12195, "code": " after_commit_hash=data[\"after_commit_hash\"] author=data[\"author\"] py_files=get_python_files_involved_in_pr(data) for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}/{}", "label": 0}, {"snippet_id": 24537, "code": " for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=", "label": 0}, {"snippet_id": 3586, "code": " and 'check' in comp['cmd'][1] window=find_window(session, comp['name']) if window: pid=get_window_pid(window) logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process", "label": 0}, {"snippet_id": 5496, "code": "..]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw", "label": 0}, {"snippet_id": 40306, "code": "+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)", "label": 0}, {"snippet_id": 40331, "code": "(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError", "label": 0}, {"snippet_id": 85063, "code": ".10', with_jline=True) register_style_tool('2.10') register_scala_compiler_tool('2.11') register_scala_repl_tool('2.11') register_style_tool('2.11') register_scala_compiler_tool('2.12') register_scala_repl_tool", "label": 0}, {"snippet_id": 60680, "code": " ex, var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg,", "label": 0}, {"snippet_id": 51481, "code": " (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches", "label": 1}, {"snippet_id": 64594, "code": "=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre", "label": 0}, {"snippet_id": 65508, "code": ", client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self", "label": 0}, {"snippet_id": 71287, "code": " target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev", "label": 0}, {"snippet_id": 4303, "code": "(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache", "label": 0}, {"snippet_id": 64879, "code": " Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"", "label": 0}, {"snippet_id": 66408, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client", "label": 0}, {"snippet_id": 32762, "code": "\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import", "label": 0}, {"snippet_id": 29106, "code": " import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake", "label": 1}, {"snippet_id": 29458, "code": "}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?", "label": 0}, {"snippet_id": 18336, "code": "}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self", "label": 0}, {"snippet_id": 52855, "code": "(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name", "label": 0}, {"snippet_id": 5186, "code": "=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"", "label": 0}, {"snippet_id": 8267, "code": "\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if", "label": 1}, {"snippet_id": 34650, "code": "\"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time):", "label": 1}, {"snippet_id": 71076, "code": "(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\"", "label": 0}, {"snippet_id": 4518, "code": "=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords))", "label": 0}, {"snippet_id": 13403, "code": "\"sha\": sha_blob, \"branch\": data.get(\"new_branch\"), } r=requests.put(url, json=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]", "label": 0}, {"snippet_id": 26610, "code": "='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state", "label": 0}, {"snippet_id": 2730, "code": "%s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] ", "label": 0}, {"snippet_id": 63393, "code": " command_line: job_wrapper.finish( '', '') return command_line, client, remote_job_config, compute_environment def __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task splitting commands locally", "label": 0}, {"snippet_id": 85409, "code": "'default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope='zinc' @classmethod def subsystem_dependencies(cls): return super(Zinc", "label": 0}, {"snippet_id": 86834, "code": " def get_warning_args_default(cls): return('-C-deprecation', '-C-Xlint:all', '-C-Xlint:-serial', '-C-Xlint:-path', '-S-deprecation', '-S-unchecked', '-S-Xlint') @classmethod def get_no_warning_args_default", "label": 0}, {"snippet_id": 26253, "code": " 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi", "label": 0}, {"snippet_id": 68321, "code": " 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, ", "label": 0}, {"snippet_id": 58058, "code": "'bugs'] try: validate_bug_id(bug_ids, bug_system_id) except ValidationError as e: return say_no(str(e)) bz_external_track=data['bz_external_track'] action=data['action'] try: if action==\"add\": for run in", "label": 0}, {"snippet_id": 28298, "code": " vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, })", "label": 0}, {"snippet_id": 70215, "code": " print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s", "label": 0}, {"snippet_id": 81835, "code": ".RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData)", "label": 0}, {"snippet_id": 44690, "code": "(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow", "label": 0}, {"snippet_id": 63979, "code": "=installed_tool_dependencies, ) @staticmethod def __dependency_resolution( lwr_client): dependency_resolution=lwr_client.destination_params.get( \"dependency_resolution\", \"local\") if dependency_resolution not in[\"none\", \"local", "label": 0}, {"snippet_id": 27452, "code": "(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any", "label": 0}, {"snippet_id": 36895, "code": " IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable", "label": 0}, {"snippet_id": 42977, "code": "._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item,", "label": 0}, {"snippet_id": 55184, "code": ".update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input", "label": 0}, {"snippet_id": 3315, "code": ".session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session", "label": 0}, {"snippet_id": 69594, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import", "label": 0}, {"snippet_id": 30481, "code": " isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat", "label": 0}, {"snippet_id": 58547, "code": ".login( username=self.tester.username, password='password') new_comment='new comment' response=self.client.post( self.many_comments_url, {'comment': new_comment, 'run': ','.join([str(self.case_run_1.pk", "label": 0}, {"snippet_id": 39197, "code": "\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats(", "label": 0}, {"snippet_id": 62599, "code": " NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator", "label": 0}, {"snippet_id": 8658, "code": " and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six", "label": 0}, {"snippet_id": 45805, "code": "(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start", "label": 0}, {"snippet_id": 77224, "code": ", proxypair[1]) newproxies.add(proxypair) except Exception as e: self.log.exception('Line %s raised exception %s', line, e) return newproxies.difference(self.proxylist) def add_spawns(self, proxypairs)", "label": 0}, {"snippet_id": 81380, "code": " detectValidExtension(self, future): \t\tif not self.stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t", "label": 0}, {"snippet_id": 1578, "code": "\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password", "label": 0}, {"snippet_id": 71237, "code": "\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"", "label": 0}, {"snippet_id": 29924, "code": " def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return", "label": 0}, {"snippet_id": 20978, "code": " msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers", "label": 0}, {"snippet_id": 20839, "code": "=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq'] result={'msg': None} def match(msg): if msg.type !='response': return False result['msg']=msg return msg.request_seq=", "label": 0}, {"snippet_id": 71045, "code": ": status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE", "label": 0}, {"snippet_id": 66657, "code": "\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden", "label": 0}, {"snippet_id": 37137, "code": "=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not", "label": 1}, {"snippet_id": 44899, "code": ", resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have", "label": 0}, {"snippet_id": 52003, "code": ".__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self", "label": 0}, {"snippet_id": 72200, "code": " returned here, but others are dropped due to protocol limitations.\"\"\" permissions.checkPermissions(irc, source,['networks.remote']) args=remote_parser.parse_args(args) netname=args.network if netname=", "label": 0}, {"snippet_id": 68280, "code": ", [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header", "label": 0}, {"snippet_id": 27172, "code": ":cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi", "label": 0}, {"snippet_id": 4896, "code": " composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires:", "label": 0}, {"snippet_id": 69974, "code": ": RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self", "label": 0}, {"snippet_id": 71377, "code": " layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +", "label": 0}, {"snippet_id": 80584, "code": "=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https", "label": 0}, {"snippet_id": 67594, "code": " self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\"", "label": 0}, {"snippet_id": 37132, "code": "*wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_", "label": 1}, {"snippet_id": 6018, "code": ".lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file", "label": 1}, {"snippet_id": 61335, "code": " DefaultQubit(Device): \"\"\"Default qubit device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc.", "label": 0}, {"snippet_id": 91377, "code": ": task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local-dists', action=BuildLocalPythonDistributions).install('pyprep') task(name='requirements', action=ResolveRequirements", "label": 0}, {"snippet_id": 22393, "code": " see if mcpd is up\") rc=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if", "label": 0}, {"snippet_id": 65298, "code": ".get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options", "label": 0}, {"snippet_id": 8333, "code": " text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!", "label": 1}, {"snippet_id": 39000, "code": ".extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary", "label": 0}, {"snippet_id": 72442, "code": "\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object", "label": 1}, {"snippet_id": 57483, "code": " has_perms=check_permission(self.request, self.ctype) if not has_perms: return say_no(\"You don't have enough permission to update TestCases.\") action=self.get_update_action() if action is not None: try", "label": 0}, {"snippet_id": 22814, "code": " crypt_id: If encrypting the password, the crypt_id that was used :param salt_len: If encrypting the password, the length of the salt value used to do it. \"\"\" cmd=\"/usr/bin/tmsh modify auth user{0} password", "label": 0}, {"snippet_id": 86792, "code": ") zinc_args.extend(settings_args) return zinc_args @classmethod def implementation_version(cls): return super(BaseZincCompile, cls).implementation_version() +[('BaseZincCompile', 7)] @classmethod def get_jvm_options_default", "label": 0}, {"snippet_id": 9966, "code": " expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list", "label": 0}, {"snippet_id": 71337, "code": ") i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 23687, "code": "\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device() retcode=shellutil.run(\"cdcontrol -f{0} eject\".format(dvd)) if chk_err", "label": 0}, {"snippet_id": 19408, "code": "--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT", "label": 0}, {"snippet_id": 32539, "code": ".snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match(requested_output): return True return", "label": 0}, {"snippet_id": 70782, "code": " enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state", "label": 0}, {"snippet_id": 94560, "code": " def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window", "label": 0}, {"snippet_id": 4628, "code": "[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8", "label": 0}, {"snippet_id": 59955, "code": " Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate", "label": 0}, {"snippet_id": 58820, "code": ": 0, 'response': 'ok'}) self.assertEqual( 'PAUSED', TestCaseRun.objects.get(pk=self.case_run_1.pk).case_run_status.name) class TestGetForm(test.TestCase): \"\"\"Test case for form\"\"\" def test_get_form(self", "label": 1}, {"snippet_id": 49705, "code": "(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets", "label": 0}, {"snippet_id": 2153, "code": "\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(','", "label": 0}, {"snippet_id": 27447, "code": " module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property", "label": 0}, {"snippet_id": 56172, "code": ".util import strtobool from django import http from django.db.models import Q, Count from django.contrib.auth.models import User from django.core import serializers from django.core.exceptions import ObjectDoesNotExist", "label": 0}, {"snippet_id": 79247, "code": ".isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True", "label": 0}, {"snippet_id": 56208, "code": ".shortcuts import render from django.views.decorators.http import require_GET from django.views.decorators.http import require_POST from tcms.signals import POST_UPDATE_SIGNAL from tcms.management.models", "label": 0}, {"snippet_id": 53848, "code": "(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log", "label": 0}, {"snippet_id": 2974, "code": " comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'],", "label": 0}, {"snippet_id": 44530, "code": " drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if", "label": 0}, {"snippet_id": 83724, "code": "('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model.Job", "label": 0}, {"snippet_id": 26705, "code": "'battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data", "label": 0}, {"snippet_id": 94498, "code": ") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available", "label": 0}, {"snippet_id": 46126, "code": " list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists ", "label": 0}, {"snippet_id": 13727, "code": ":00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def", "label": 0}, {"snippet_id": 55556, "code": "[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func", "label": 0}, {"snippet_id": 44423, "code": " return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(", "label": 0}, {"snippet_id": 65835, "code": "[] t_runtime=[] t_unknown=[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target", "label": 0}, {"snippet_id": 62592, "code": " in self.reg] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self", "label": 0}, {"snippet_id": 86945, "code": "'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if after ' 'running clean-all.') register('--incremental-caching", "label": 0}, {"snippet_id": 73196, "code": ".vcf.gz files to *.vcf, placed in output_dir. Additionally moves *.vcf files to output_dir Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir", "label": 0}, {"snippet_id": 43480, "code": "(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp ", "label": 0}, {"snippet_id": 24627, "code": "._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and", "label": 0}, {"snippet_id": 2810, "code": "%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp[", "label": 0}, {"snippet_id": 77768, "code": ".th_sock.send_multipart(msg) if hasattr(self, 'pr_sock'): self.pr_sock.send_multipart(msg) def join_threads(self): for t in self.threads: t.join() def send_passthrough(self, interface, method, frames): msg=", "label": 0}, {"snippet_id": 18514, "code": "._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def", "label": 0}, {"snippet_id": 81572, "code": ") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes", "label": 1}, {"snippet_id": 80079, "code": "\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\"", "label": 0}, {"snippet_id": 27217, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle'", "label": 0}, {"snippet_id": 19954, "code": " None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') if addr is None: addr=adapter.address self._attach(addr, **kwargs) return self._session", "label": 0}, {"snippet_id": 70978, "code": " len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0:", "label": 0}, {"snippet_id": 45781, "code": "(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir", "label": 0}, {"snippet_id": 71178, "code": " status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state=", "label": 0}, {"snippet_id": 73640, "code": " import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str", "label": 0}, {"snippet_id": 52892, "code": ") except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources", "label": 0}, {"snippet_id": 9704, "code": "=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags: results[\"Author keywords", "label": 0}, {"snippet_id": 73907, "code": " chunk_length=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): \"\"\" Creates", "label": 0}, {"snippet_id": 59255, "code": " \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate", "label": 0}, {"snippet_id": 53034, "code": ".derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput", "label": 0}, {"snippet_id": 37892, "code": " rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile)", "label": 0}, {"snippet_id": 44480, "code": "*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 63780, "code": "( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not", "label": 0}, {"snippet_id": 91762, "code": " sources_digest, inits_digest.directory_digest, requirements_pex_response.output_directory_digest, ] merged_input_files=yield Get( Digest, DirectoriesToMerge, DirectoriesToMerge(directories=tuple(all_input_digests", "label": 0}, {"snippet_id": 93765, "code": " is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost", "label": 0}, {"snippet_id": 4757, "code": " to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords", "label": 0}, {"snippet_id": 14231, "code": "(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 41003, "code": "): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index -", "label": 0}, {"snippet_id": 14604, "code": " return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not", "label": 0}, {"snippet_id": 78238, "code": ".targets: self.schedule(self.add_comment,(t, self.msgfun())) if len(self.targets)==0: self.schedule(self.scan_targets_loop) else: self.schedule(self.comment_loop) def add_comment(self, t, msg): if True: try", "label": 0}, {"snippet_id": 62041, "code": " has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend: use_hardware(bool): If True, the", "label": 0}, {"snippet_id": 650, "code": "\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name': row[2", "label": 0}, {"snippet_id": 7836, "code": ".items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:", "label": 0}, {"snippet_id": 60652, "code": "(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('gaussian') reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg", "label": 0}, {"snippet_id": 37928, "code": " benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str", "label": 0}, {"snippet_id": 13189, "code": " headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format", "label": 0}, {"snippet_id": 41274, "code": " yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath):", "label": 0}, {"snippet_id": 4560, "code": " keywords in the fulltext :var skw_db: list of KeywordToken objects :var fulltext: string, which will be searched :return: dictionary of matches in a format{ <keyword object>,[[position, position...],], .", "label": 1}, {"snippet_id": 12757, "code": ".com/repos/{}/issues/comments/{}\" query=query.format(data[\"repository\"], str(last_comment_id)) response=requests.patch(query, json={\"body\": comment}, headers=headers, auth=auth) def autopep8(data, config", "label": 0}, {"snippet_id": 92569, "code": " exist within the context.') self.assertTrue(os.path.exists(fp.name), 'Temporary file should exist outside of context if cleanup=False.') os.unlink(fp.name) def test_temporary_file_within_other_dir(self", "label": 0}, {"snippet_id": 48226, "code": " --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies", "label": 0}, {"snippet_id": 50978, "code": " mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of", "label": 1}, {"snippet_id": 64960, "code": " Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler", "label": 0}, {"snippet_id": 3863, "code": "=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config", "label": 0}, {"snippet_id": 70705, "code": ": defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result", "label": 0}, {"snippet_id": 87066, "code": " self).__init__(*args, **kwargs) self._processor_info_dir=os.path.join(self.workdir, 'apt-processor-info') ZincCompile.validate_arguments(self.context.log, self.get_options().whitelisted_args, self._args", "label": 0}, {"snippet_id": 86734, "code": "-source', '-C{}'.format(settings.source_level), '-C-target', '-C{}'.format(settings.target_level), ] if settings.args: settings_args=settings.args if any('$JAVA_HOME' in a for a in settings.args): try:", "label": 0}, {"snippet_id": 72988, "code": "/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory,", "label": 0}, {"snippet_id": 39840, "code": ".abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir):", "label": 0}, {"snippet_id": 84830, "code": " ZincLanguageMixin, InjectablesMixin, Subsystem): \"\"\"A scala platform. :API: public \"\"\" options_scope='scala' @classmethod def _create_jardep(cls, name, version): return JarDependency(org='org.scala-lang'", "label": 0}, {"snippet_id": 58253, "code": ".testcases.forms import TestCase from tcms.testplans.models import TestPlan from tcms.testruns.models import TestCaseRun from tcms.testruns.models import TestCaseRunStatus from tcms.tests import BaseCaseRun", "label": 0}, {"snippet_id": 54380, "code": "\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0:", "label": 0}, {"snippet_id": 86983, "code": " generally a good precaution to cache ' 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies() +(Zinc.Factory, JvmPlatform,", "label": 0}, {"snippet_id": 42740, "code": " \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output", "label": 0}, {"snippet_id": 10848, "code": ") os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists", "label": 1}, {"snippet_id": 83174, "code": " self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict", "label": 0}, {"snippet_id": 89966, "code": " raise def execute_java(self, *args, **kwargs): return execute_java(*args, distribution=self, **kwargs) def execute_java_async(self, *args, **kwargs): return execute_java_async(*args, distribution=self, ", "label": 0}, {"snippet_id": 57516, "code": "'Update failed. Please try again or request ' 'support from your organization.') else: if resp is None: resp=say_yes() return resp return say_no('Not know what to update.') def get_update_targets(self)", "label": 0}, {"snippet_id": 10604, "code": "-1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does", "label": 1}, {"snippet_id": 72122, "code": ".networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 2: network name(case sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No such network \"%s\"", "label": 0}, {"snippet_id": 47603, "code": "): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self)", "label": 0}, {"snippet_id": 36884, "code": "\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io", "label": 0}, {"snippet_id": 5069, "code": "/datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag", "label": 0}, {"snippet_id": 73492, "code": " conversion :type input_vcf_path: str :type output_zarr_path: str :type conversion_config: config.VCFtoZarrConfigurationRepresentation \"\"\" if conversion_config is not None: output_zarr_path=str(output_zarr_path", "label": 0}, {"snippet_id": 83054, "code": ".CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(\"Found the following entry points:", "label": 0}, {"snippet_id": 48126, "code": ": products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened.", "label": 0}, {"snippet_id": 70715, "code": " print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs", "label": 1}, {"snippet_id": 90857, "code": " in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely locations on the file system such as `/usr/lib/jvm` on Linux machines. :API: public \"\"\" class Error(Distribution.Error):", "label": 0}, {"snippet_id": 14985, "code": "): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache", "label": 0}, {"snippet_id": 3015, "code": " % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window", "label": 0}, {"snippet_id": 45072, "code": " return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads", "label": 0}, {"snippet_id": 8301, "code": "(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise", "label": 1}, {"snippet_id": 13528, "code": "( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def updateMouth():\r lastMouthEvent=0\r lastMouthEventTime=0\r \r while( audio==None):\r time.sleep( 0.1)\r \r while isRunning:\r if( audio.mouthValue !=lastMouthEvent", "label": 0}, {"snippet_id": 64869, "code": " import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall", "label": 0}, {"snippet_id": 68693, "code": "(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if", "label": 0}, {"snippet_id": 62758, "code": " 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified", "label": 0}, {"snippet_id": 37053, "code": ") self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names", "label": 0}, {"snippet_id": 35220, "code": " if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic,", "label": 0}, {"snippet_id": 77003, "code": " targets[domain]=tlist if domain in forums: fset=forums[domain] else: fset=set() forums[domain]=fset net=make_net(proxy, proxytype) net.cookiefname=(proxy if proxy else 'noproxy')+'_'+domain w=UniWipe(fset,", "label": 0}, {"snippet_id": 3390, "code": "'name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config", "label": 0}, {"snippet_id": 62753, "code": "[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs", "label": 0}, {"snippet_id": 5101, "code": " output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output", "label": 0}, {"snippet_id": 80862, "code": "\t\t\t\t\tlogging.info(\"\\033[1m\\033[42mCode execution obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints", "label": 0}, {"snippet_id": 77075, "code": " self.th_sa='inproc://wm-wth.sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm-wpr.sock' self.pr_ba='ipc://wm-back.sock' self.userqueues={} self.usersfile='wm_users.pickle' self.targetsfile", "label": 0}, {"snippet_id": 69187, "code": "=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name(", "label": 0}, {"snippet_id": 18033, "code": ".CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport", "label": 0}, {"snippet_id": 38656, "code": " keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if", "label": 0}, {"snippet_id": 40904, "code": " dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\"", "label": 0}, {"snippet_id": 66525, "code": " self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support", "label": 0}, {"snippet_id": 27882, "code": " >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 29042, "code": "=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self", "label": 0}, {"snippet_id": 39346, "code": " workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global", "label": 0}, {"snippet_id": 11463, "code": " raise SystemExit(\"Raw yaml config from source '%s' is 'None'.\" % self.source) yaml_config=YamlConfig(raw_yaml_config, skip_checks=self.skip_checks) if yaml_config.host and self._is_newer(header_source,", "label": 0}, {"snippet_id": 86519, "code": ".base.exceptions import TaskError from pants.base.hash_utils import hash_file from pants.base.workunit import WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize, PathGlobs, PathGlobsAndRoot", "label": 0}, {"snippet_id": 22533, "code": " function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere in the UI that specifies the", "label": 0}, {"snippet_id": 466, "code": "=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username", "label": 0}, {"snippet_id": 1431, "code": "\"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return", "label": 0}, {"snippet_id": 76829, "code": "'Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net.RequestPerformer() noproxy_rp.proxy='' noproxy_rp.timeout=c.noproxy_timeout noproxy_rp.timeout=c.rp_timeout d=DataLoader", "label": 0}, {"snippet_id": 3957, "code": "-visual\", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch to", "label": 0}, {"snippet_id": 29253, "code": " symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if", "label": 0}, {"snippet_id": 90052, "code": " properties for{} with{} -exit code' '{}:{}'.format(java, ' '.join(cmd), process.returncode, stderr.decode('utf-8'))) props={} for line in stdout.decode('utf-8').split(os.linesep): key, _, val=line.partition", "label": 0}, {"snippet_id": 47435, "code": "=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self", "label": 0}, {"snippet_id": 88615, "code": " workspace, if any.\"\"\" return self._workspace @property def invalidation_report(self): return self._invalidation_report def __str__(self): ident=Target.identify(self.targets()) return 'Context(id:{}, targets", "label": 0}, {"snippet_id": 81121, "code": "(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms[0][1][0][\"name\"] \t\tself.logger.debug(\"Found the following file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry", "label": 0}, {"snippet_id": 50829, "code": "(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as", "label": 0}, {"snippet_id": 49904, "code": ") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores", "label": 0}, {"snippet_id": 21532, "code": "(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt", "label": 1}, {"snippet_id": 69248, "code": " print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help", "label": 0}, {"snippet_id": 86577, "code": ".Processor' logger=logging.getLogger(__name__) class BaseZincCompile(JvmCompile): \"\"\"An abstract base class for zinc compilation tasks.\"\"\" _name='zinc' @staticmethod def _write_scalac_plugin_info(resources_dir,", "label": 1}, {"snippet_id": 74824, "code": "(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types: self.blosc_shuffle_mode=blosc_shuffle_mode_int else: raise ValueError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\"", "label": 0}, {"snippet_id": 46886, "code": " res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set(", "label": 0}, {"snippet_id": 20549, "code": " write_message(write, body, stop=stop) def _close(self): if self._ownsock: close(self._sock) class DebugSession(Closeable): VERBOSE=False HOST='localhost' PORT=8888 TIMEOUT=None @classmethod def create_client", "label": 0}, {"snippet_id": 83015, "code": "\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args.detectAllEntryPoints: ", "label": 0}, {"snippet_id": 63747, "code": "'']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't", "label": 0}, {"snippet_id": 19149, "code": " schema=schema ) def validate_api_call(schema, raw_request, raw_response): \"\"\" Validate the request/response cycle of an api call against a swagger schema. Request/Response objects from the `requests` and", "label": 0}, {"snippet_id": 95678, "code": " directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir", "label": 0}, {"snippet_id": 12002, "code": "(config, new_config) except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key, value in confs.items(): if value: if isinstance(value, int): if isinstance(value, bool): arguments.append", "label": 0}, {"snippet_id": 34112, "code": " raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], ", "label": 0}, {"snippet_id": 93297, "code": "'starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None def load_config(self", "label": 0}, {"snippet_id": 49386, "code": " prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False,", "label": 0}, {"snippet_id": 14158, "code": ".completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import", "label": 0}, {"snippet_id": 51035, "code": " f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill", "label": 1}, {"snippet_id": 14556, "code": " extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse", "label": 0}, {"snippet_id": 87810, "code": " in working directory or ' 'part of the JDK.{} is not.'.format(path)) if path !=os.path.normpath(path): raise TaskError('Classpath entries provided to zinc should be normalized ' '(i.e. without \"..\" and ", "label": 0}, {"snippet_id": 23316, "code": "(self, port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in here because BIG-IP may not have yet initialized this list of devices. :param port_id: :return: \"\"\" for retries in range", "label": 0}, {"snippet_id": 93270, "code": ") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server", "label": 0}, {"snippet_id": 5735, "code": "=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1", "label": 0}, {"snippet_id": 28367, "code": ")) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name,", "label": 1}, {"snippet_id": 41222, "code": ": pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as", "label": 0}, {"snippet_id": 396, "code": "=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get", "label": 0}, {"snippet_id": 50247, "code": " lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if", "label": 0}, {"snippet_id": 81236, "code": ".codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t\t\telse: \t\t\t\tself.logger.warning(\"Code execution detection will not be possible as there is no path nor regex pattern configured.\") \t\telse: \t", "label": 0}, {"snippet_id": 71305, "code": ".servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index\", target.index], [\"tag\", tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\",", "label": 0}, {"snippet_id": 73938, "code": " ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled=config_str_to_bool(runtime_config.vcf_to_zarr", "label": 0}, {"snippet_id": 6889, "code": " string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty{}", "label": 0}, {"snippet_id": 13970, "code": " if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method", "label": 1}, {"snippet_id": 23521, "code": "} is a system user, \" \"will not set password.\").format(username)) passwd_hash=textutil.gen_password_hash(password, crypt_id, salt_len) cmd=\"echo '{0}'|pw usermod{1} -H 0 \".format(passwd_hash, username)", "label": 0}, {"snippet_id": 61644, "code": ".abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation value.'.format(expectation.imag)) return expectation.real def reset(self): \"\"\"Reset the device\"\"\" self._state ", "label": 0}, {"snippet_id": 4902, "code": " xml record. :var recid: ingeter :var single_keywords: dictionary of kws :var composite_keywords: dictionary of kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords", "label": 0}, {"snippet_id": 35453, "code": ".dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in", "label": 0}, {"snippet_id": 7543, "code": "\"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted", "label": 0}, {"snippet_id": 92300, "code": " temporary_file(binary_mode=False) as new_output: subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\" in os.environ)'], stdout=new_output).wait() new_output.seek(0) self.assertEqual('False\\n", "label": 0}, {"snippet_id": 19406, "code": " '--multiprocess', '--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save-asyncio', '--server', '--qt-support=auto', } USAGE=\"\"\" {0}[-h][-V][--nodebug][--host HOST | --server-host", "label": 0}, {"snippet_id": 70806, "code": " target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device", "label": 0}, {"snippet_id": 14386, "code": "=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is", "label": 0}, {"snippet_id": 48107, "code": "(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark", "label": 0}, {"snippet_id": 47731, "code": ", Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__", "label": 0}, {"snippet_id": 9088, "code": " composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in the fulltext :var", "label": 1}, {"snippet_id": 4179, "code": "=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in", "label": 0}, {"snippet_id": 26732, "code": "'battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp", "label": 0}, {"snippet_id": 78044, "code": " forum in r_udf.findall(urls): if domain not in forums: forums[domain]=set() if len(forum) > 0: get_forum_id(forum) logger.info('Appending %s:%s to forums[%s]', user, forum, domain) forums[domain].add(", "label": 0}, {"snippet_id": 94168, "code": " self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState", "label": 0}, {"snippet_id": 4502, "code": " fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations", "label": 0}, {"snippet_id": 37072, "code": "._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch", "label": 0}, {"snippet_id": 48412, "code": " item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name", "label": 0}, {"snippet_id": 44028, "code": " unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self", "label": 0}, {"snippet_id": 72262, "code": ".called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text, **kwargs): \"\"\" reply() rerouter for the 'remote", "label": 0}, {"snippet_id": 3267, "code": " %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode", "label": 0}, {"snippet_id": 18921, "code": " yaml). -json string. -yaml string. \"\"\" if isinstance(source, collections.Mapping): return source elif hasattr(source, 'read') and callable(source.read): raw_source=source.read() elif os.path.exists(os", "label": 0}, {"snippet_id": 22166, "code": " template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template.render(", "label": 0}, {"snippet_id": 76098, "code": "('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m, wzauth_data.bind_route[i, m])) def set_route_type(self", "label": 0}, {"snippet_id": 48094, "code": " Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name", "label": 0}, {"snippet_id": 89619, "code": "(self): self.validate() return self._is_jdk @property def system_properties(self): \"\"\"Returns a dict containing the system properties of this java distribution.\"\"\" return dict(self._get_system_properties", "label": 0}, {"snippet_id": 60286, "code": " \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock', 'X', 'P", "label": 0}, {"snippet_id": 75644, "code": "'Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=(), kvargs={}, name=None, start_timer=None, poll_timeout=None, pargs=(), pkvargs={}): super(", "label": 0}, {"snippet_id": 22218, "code": " 'log_file' in self.conf[state]: log_file=self.conf[state]['log_file'] if 'template' in self.conf[state]: template=self.conf[state]['template'] if playbook is None: playbook=self.conf['playbook'] if template", "label": 0}, {"snippet_id": 29430, "code": "=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self):", "label": 0}, {"snippet_id": 20702, "code": ", **args) if self.VERBOSE: msg=parse_message(req) print(' <-', msg) if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse(req, lambda: resp[\"msg\"]) else", "label": 0}, {"snippet_id": 25786, "code": "] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0", "label": 0}, {"snippet_id": 19908, "code": "._adapter is None: raise RuntimeError('debugger not running') if self._session is not None: raise RuntimeError('already attached') raise NotImplementedError def attach_socket(self, addr=None, adapter=None,", "label": 0}, {"snippet_id": 95154, "code": ".setup_vcf_to_zarr(input_vcf_dir=vcf_directory, output_zarr_dir=zarr_directory_setup, conversion_config=vcf_to_zarr_config) elif command==\"exec\": print(\"[Exec] Executing benchmark tool.\") runtime_config", "label": 1}, {"snippet_id": 93096, "code": ") as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self): fake_logger=mock.Mock() with self.assertRaises(AssertionError): with exception_logging(fake_logger, 'error", "label": 0}, {"snippet_id": 3512, "code": " by the name '%s'. Exiting kill mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self", "label": 0}, {"snippet_id": 57673, "code": " return say_no('No record(s) found') for testcase in update_object: if hasattr(testcase, 'log_action'): testcase.log_action( who=self.request.user, action='Field %s changed from %s to %s.' %( self.target_field", "label": 0}, {"snippet_id": 34485, "code": ".subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to", "label": 0}, {"snippet_id": 959, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False) elif action=='addNewUser':", "label": 0}, {"snippet_id": 58959, "code": "'response': 'ok'}) for pk in(self.case_1.pk, self.case_3.pk): self.assertEqual('P3', TestCase.objects.get(pk=pk).priority.value) class TestGetObjectInfo(BasePlanCase): \"\"\"Test case for info view method\"\"\"", "label": 0}, {"snippet_id": 9334, "code": " dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it", "label": 0}, {"snippet_id": 3642, "code": " logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED elif", "label": 0}, {"snippet_id": 23642, "code": " shellutil.run(\"/etc/rc.d/dhclient start{0}\".format(self.get_if_name()), chk_err=False) def allow_dhcp_broadcast(self): pass def set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add", "label": 0}, {"snippet_id": 70197, "code": ") class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting", "label": 0}, {"snippet_id": 9833, "code": " author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return", "label": 0}, {"snippet_id": 78263, "code": " e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout) self.schedule(self.add_comment,(t, msg)) except(exc.Closed", "label": 0}, {"snippet_id": 81152, "code": "=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning", "label": 0}, {"snippet_id": 36255, "code": ": raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property def expanded_output", "label": 0}, {"snippet_id": 90922, "code": ": return cls.global_instance()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java distribution", "label": 0}, {"snippet_id": 75189, "code": "] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init() self.bind_kt_ticker.tick() while self.p.running.is_set(): socks=self.p.poll() if self.bind_kt_ticker.elapsed(False) > self.bind_kt:", "label": 1}, {"snippet_id": 59961, "code": "(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx", "label": 0}, {"snippet_id": 65361, "code": " to either stand back and get a global status of the filesystem, or if needed, to enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from", "label": 0}, {"snippet_id": 70413, "code": "\n \"\"\" Shine `status' command classes. The status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator", "label": 0}, {"snippet_id": 86267, "code": ".fatal_warnings_disabled_args) with argfile.safe_args(ctx.sources, self.get_options()) as batched_sources: javac_cmd.extend(batched_sources) if self.execution_strategy==self.HERMETIC: self._execute_hermetic_compile", "label": 0}, {"snippet_id": 33296, "code": ") targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 19618, "code": ": supported.append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog", "label": 0}, {"snippet_id": 37236, "code": "(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return", "label": 0}, {"snippet_id": 38779, "code": "( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f", "label": 0}, {"snippet_id": 24959, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state", "label": 0}, {"snippet_id": 2593, "code": "]]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']:", "label": 0}, {"snippet_id": 79699, "code": "\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information", "label": 0}, {"snippet_id": 8953, "code": " :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only", "label": 0}, {"snippet_id": 70575, "code": " node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es", "label": 0}, {"snippet_id": 34928, "code": " files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))", "label": 0}, {"snippet_id": 86002, "code": " @classmethod def register_options(cls, register): super(JavacCompile, cls).register_options(register) @classmethod def subsystem_dependencies(cls): return super(JavacCompile, cls).subsystem_dependencies() ", "label": 0}, {"snippet_id": 21757, "code": " dataset=pd.read_csv('Churn_Modelling.csv') X=dataset.iloc[:, 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X[:", "label": 1}, {"snippet_id": 61587, "code": " x in A.params] return operator_map[A.name](*p) def ev(self, A, wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable", "label": 0}, {"snippet_id": 43632, "code": " snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp,", "label": 1}, {"snippet_id": 49192, "code": "() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not", "label": 0}, {"snippet_id": 90365, "code": ")==0: raise ValueError('Expected at least 1 java dist dir.') self._java_dist_dirs=java_dist_dirs @property def jvm_locations(self): for java_dist_dir in self._java_dist_dirs: if os.path.isdir(java_dist_dir", "label": 0}, {"snippet_id": 38432, "code": "{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name", "label": 0}, {"snippet_id": 51979, "code": "._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__", "label": 0}, {"snippet_id": 40854, "code": ".search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex", "label": 0}, {"snippet_id": 1605, "code": " len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password", "label": 0}, {"snippet_id": 17193, "code": ".server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal", "label": 0}, {"snippet_id": 54910, "code": " not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets", "label": 0}, {"snippet_id": 69400, "code": ") if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try:", "label": 0}, {"snippet_id": 12704, "code": ") last_comment_id=None for old_comment in comments: if old_comment[\"user\"][\"id\"]==24736507: last_comment_id=old_comment[\"id\"] break if last_comment_id is None: response=requests.post(query, json={\"body", "label": 0}, {"snippet_id": 33537, "code": " dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(", "label": 0}, {"snippet_id": 77193, "code": "') as f: for line in f: try: line=line.rstrip('\\n') proxypair=tuple(line.split(' ')) if len(proxypair) < 2: self.log.warning('Line %s has too few spaces', line) continue if len(proxypair) > 2: self.log", "label": 1}, {"snippet_id": 76195, "code": "', i, m) return self.log.debug('Unbinding route %s,%s', i, m) self.wz.del_req_handler(i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Route unbinded", "label": 0}, {"snippet_id": 60534, "code": " Gaussian device for OpenQML. wires(int): the number of modes to initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. ", "label": 0}, {"snippet_id": 65429, "code": " from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__", "label": 0}, {"snippet_id": 54308, "code": "))) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self)", "label": 0}, {"snippet_id": 1443, "code": " \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) return @csrf_exempt def handle_config(request): \"\"\" List all code snippets, or create a new snippet. \"\"\" if", "label": 0}, {"snippet_id": 84801, "code": " Subsystem major_version_info=namedtuple('major_version_info',['full_version']) scala_build_info={ '2.10': major_version_info(full_version='2.10.6'), '2.11': major_version_info(full_version='2.11.12'), '2.12'", "label": 0}, {"snippet_id": 45839, "code": "\"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)", "label": 0}, {"snippet_id": 36369, "code": ".subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing", "label": 0}, {"snippet_id": 259, "code": "[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless", "label": 0}, {"snippet_id": 53959, "code": ".dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start", "label": 0}, {"snippet_id": 24521, "code": ".netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature", "label": 0}, {"snippet_id": 9679, "code": " return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER):", "label": 0}, {"snippet_id": 74948, "code": "\"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config", "label": 1}, {"snippet_id": 57671, "code": " not update_object: return say_no('No record(s) found') for testcase in update_object: if hasattr(testcase, 'log_action'): testcase.log_action( who=self.request.user, action='Field %s changed from %s to ", "label": 0}, {"snippet_id": 35627, "code": " name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield", "label": 0}, {"snippet_id": 55234, "code": "\"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph", "label": 0}, {"snippet_id": 26143, "code": " Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'", "label": 1}, {"snippet_id": 88266, "code": ", WorkUnitLabel from pants.build_graph.target import Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products import Products from pants.goal.workspace import", "label": 1}, {"snippet_id": 11453, "code": "(msg % hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config(self.source) if raw_yaml_config is None: raise SystemExit(\"Raw yaml config from source '%s' is", "label": 0}, {"snippet_id": 19129, "code": " request=normalize_request(raw_request) response=None if raw_response is not None: response=normalize_response(raw_response, request=request) if response is not None: validate_response( response=response", "label": 0}, {"snippet_id": 42518, "code": " input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try", "label": 0}, {"snippet_id": 52838, "code": "**variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self", "label": 0}, {"snippet_id": 91209, "code": ".python.targets.unpacked_whls import UnpackedWheels from pants.backend.python.tasks.build_local_python_distributions import \\ BuildLocalPythonDistributions from pants.backend.python.tasks.gather_sources", "label": 0}, {"snippet_id": 85128, "code": " products): return self._tool_classpath('scalac', products) def style_classpath(self, products): return self._tool_classpath('scalastyle', products) @property def version(self): return self.get_options(", "label": 0}, {"snippet_id": 31285, "code": "\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__", "label": 0}, {"snippet_id": 57953, "code": ": data['bugs']=request.GET.get('bug_id', '').split(',') data['runs']=map(int, request.GET.get('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers", "label": 0}, {"snippet_id": 73297, "code": "*/*.vcf\") for path in pathlist_vcf_temp: path_temp_str=str(path) filename_str=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree", "label": 0}, {"snippet_id": 34440, "code": " self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths", "label": 0}, {"snippet_id": 25879, "code": " elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >", "label": 0}, {"snippet_id": 18946, "code": "): with open(os.path.expanduser(str(source)), 'r') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts.scheme and parts.netloc", "label": 0}, {"snippet_id": 64982, "code": " RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler", "label": 0}, {"snippet_id": 59606, "code": " self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Produces a segmentation fault. \"\"\" if self.eng is not None and self.backend", "label": 0}, {"snippet_id": 969, "code": " 'deleteuser', 'endpoint': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username", "label": 0}, {"snippet_id": 1035, "code": " if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers", "label": 0}, {"snippet_id": 54397, "code": " comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self", "label": 0}, {"snippet_id": 88333, "code": " include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated with. :API: public \"\"\" class Log(object): \"\"", "label": 0}, {"snippet_id": 27204, "code": ":weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':[", "label": 0}, {"snippet_id": 37715, "code": ".apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None):", "label": 0}, {"snippet_id": 8503, "code": "=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent", "label": 1}, {"snippet_id": 89591, "code": "._bin_path=bin_path or(os.path.join(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version=_parse_java_version(\"minimum_version\", minimum_version) self._maximum_version=_parse_java_version(", "label": 0}, {"snippet_id": 40281, "code": ".dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(", "label": 0}, {"snippet_id": 40181, "code": ".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\")", "label": 0}, {"snippet_id": 38130, "code": "\"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause.index(rule1.name", "label": 0}, {"snippet_id": 27264, "code": "'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '", "label": 0}, {"snippet_id": 197, "code": "-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn", "label": 0}, {"snippet_id": 77078, "code": ".sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm-wpr.sock' self.pr_ba='ipc://wm-back.sock' self.userqueues={} self.usersfile='wm_users.pickle' self.targetsfile='wm_targets.pickle' self.bumplimitfile", "label": 0}, {"snippet_id": 26026, "code": "'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object", "label": 0}, {"snippet_id": 43808, "code": "._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None):", "label": 0}, {"snippet_id": 86946, "code": "'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if after ' 'running clean-all.') register('--incremental-caching'", "label": 0}, {"snippet_id": 48007, "code": ".protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for", "label": 0}, {"snippet_id": 14711, "code": ":{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n", "label": 0}, {"snippet_id": 14875, "code": "'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self", "label": 0}, {"snippet_id": 42491, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io", "label": 0}, {"snippet_id": 32022, "code": " not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\")", "label": 0}, {"snippet_id": 52288, "code": ".expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"", "label": 0}, {"snippet_id": 28400, "code": " add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo", "label": 0}, {"snippet_id": 82943, "code": ":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor", "label": 1}, {"snippet_id": 62895, "code": " state[i]=='0')-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable", "label": 0}, {"snippet_id": 7815, "code": "): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes", "label": 0}, {"snippet_id": 80165, "code": "-form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath", "label": 0}, {"snippet_id": 52559, "code": ") for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple", "label": 0}, {"snippet_id": 7509, "code": "=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output", "label": 0}, {"snippet_id": 42470, "code": ".subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self", "label": 0}, {"snippet_id": 89098, "code": " Target.closure_for_targets( target_roots=root_targets, **kwargs ) def dependents(self, on_predicate=None, from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate to targets", "label": 0}, {"snippet_id": 82172, "code": " are expected and filtered by the server. Needs -l switch.\") parser.add_argument(\"-y\",action=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not", "label": 0}, {"snippet_id": 58076, "code": " for run in runs: for bug_id in bug_ids: run.add_bug(bug_id=bug_id, bug_system_id=bug_system_id, bz_external_track=bz_external_track) else: bugs=Bug.objects.filter(bug_id__in=bug_ids) for run in runs: for", "label": 0}, {"snippet_id": 40707, "code": " filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the", "label": 0}, {"snippet_id": 26271, "code": "', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi", "label": 0}, {"snippet_id": 70996, "code": " % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets):", "label": 0}, {"snippet_id": 64429, "code": " self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in", "label": 0}, {"snippet_id": 72001, "code": " importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc.coremods import control, permissions @utils.add_cmd def disconnect(irc, source, args): \"", "label": 0}, {"snippet_id": 82629, "code": "\tlogging.warning(\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session(", "label": 0}, {"snippet_id": 8406, "code": " line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio", "label": 1}, {"snippet_id": 81226, "code": "\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t\t\telse: \t\t\t\tself.logger.warning(\"Code execution detection", "label": 0}, {"snippet_id": 49136, "code": ".abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows", "label": 0}, {"snippet_id": 35243, "code": ") will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex", "label": 1}, {"snippet_id": 18100, "code": ".raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception']", "label": 0}, {"snippet_id": 80183, "code": " args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads[0] args.userAgent=args.userAgent[0] if args.randomUserAgent: \twith open(\"user-agents.txt\",\"r\") as fd: \t\tnb=0", "label": 0}, {"snippet_id": 46187, "code": ".format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern", "label": 0}, {"snippet_id": 40560, "code": "): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString", "label": 0}, {"snippet_id": 61317, "code": " hermitian, 'Identity': I, 'PauliX': X, 'PauliY': Y, 'PauliZ': Z, 'CNOT': CNOT, 'SWAP': SWAP, 'RX': frx, 'RY': fry, 'RZ': frz, 'Rot': fr3 } class DefaultQubit(Device): \"\"\"Default qubit device for OpenQML. wires", "label": 0}, {"snippet_id": 3567, "code": " shell=True)==0: return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check", "label": 0}, {"snippet_id": 39060, "code": " items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes", "label": 0}, {"snippet_id": 84556, "code": " pants.engine.fs import FilesContent, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask from pants.util.contextutil", "label": 0}, {"snippet_id": 6237, "code": " re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL", "label": 1}, {"snippet_id": 26614, "code": "'battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data[", "label": 0}, {"snippet_id": 42476, "code": ".priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func", "label": 0}, {"snippet_id": 4799, "code": " style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword", "label": 0}, {"snippet_id": 88596, "code": " public \"\"\" return self._console_outstream @property def scm(self): \"\"\"Returns the current workspace's scm, if any. :API: public \"\"\" return self._scm @property def workspace(self): \"\"\"Returns the current", "label": 0}, {"snippet_id": 84674, "code": "(input_files): list_file_out.write(input_file) list_file_out.write('\\n') list_file_snapshot=self.context._scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs(('input_files_list',)), text_type(tmpdir), ), ))", "label": 0}, {"snippet_id": 91911, "code": " subsystem which exposes components of the native backend to the python backend.\"\"\" options_scope='python-native-code' default_native_source_extensions=['.c', '.cpp', '.cc'] class PythonNativeCodeError", "label": 0}, {"snippet_id": 52323, "code": " self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self", "label": 0}, {"snippet_id": 77477, "code": "('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads(self): return self.spawn_nworkers(0, WipeThread, self.c.tcount, (self.pc, self.spawnqueue)) def spawn_evaluators(self): self.log.info", "label": 0}, {"snippet_id": 89184, "code": " dependencies of targets parsed in the root tree's BUILD files will be followed and this may lead to BUILD files outside of ``root`` being parsed and included in the returned build graph. :API: public :param", "label": 0}, {"snippet_id": 39172, "code": " job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join", "label": 0}, {"snippet_id": 46824, "code": " jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule", "label": 0}, {"snippet_id": 15736, "code": ".CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data):", "label": 0}, {"snippet_id": 83542, "code": " job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '') return command_line, client, remote_job_config, compute_environment def", "label": 0}, {"snippet_id": 62600, "code": "\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ", "label": 0}, {"snippet_id": 3940, "code": "\"control is taken care of the remote master invoking \" \"this command.\\nIf run with the --kill flag, the \" \"passed component will be killed\") subparser_val.add_argument(\"--visual\", help=\"Generate and show", "label": 0}, {"snippet_id": 40216, "code": "(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self):", "label": 1}, {"snippet_id": 17519, "code": " self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return", "label": 0}, {"snippet_id": 10004, "code": ".append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches", "label": 0}, {"snippet_id": 86462, "code": " pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.zinc import Zinc from pants.backend", "label": 0}, {"snippet_id": 39159, "code": " provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict", "label": 0}, {"snippet_id": 31448, "code": " \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self", "label": 0}, {"snippet_id": 38054, "code": " Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self", "label": 0}, {"snippet_id": 25938, "code": "\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] ", "label": 0}, {"snippet_id": 22123, "code": "=playbook_executor.PlaybookExecutor( playbooks=[playbook], inventory=self.inventory, variable_manager=self.variable_manager, loader=self.loader, options=self.options, passwords={}) def run(self, job_id): \"\"\"Run", "label": 0}, {"snippet_id": 47139, "code": "\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction", "label": 0}, {"snippet_id": 21464, "code": "(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) else: print(\"Reddytt: Working directory found. Loading variables.\") with open(seen_file, 'rb') as f: seen_links=pickle.load(f) with open(unseen_file, 'rb", "label": 0}, {"snippet_id": 21239, "code": " pm=urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where()) html_page=pm.request('GET', link) soup=BeautifulSoup(html_page.data, \"lxml\") links=[a.get('href') for a in soup('a') if a.get", "label": 0}, {"snippet_id": 22001, "code": ".new_vault_password_file=new_vault_password_file self.output_file=output_file self.tags=tags self.skip_tags=skip_tags self.one_line=one_line self.tree=tree self.ask_sudo_pass=ask_sudo_pass self.ask_su_pass=ask_su_pass self", "label": 0}, {"snippet_id": 30169, "code": " fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index", "label": 0}, {"snippet_id": 80347, "code": "\targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"", "label": 0}, {"snippet_id": 11629, "code": " f.write(line +\"\\n\") LOG.debug(\"Created %s\" % self.output_file) def generate_config(): arg=docopt(__doc__, version='0.1.0') start_time=datetime.now() try: file_name=MonitoringConfigGenerator(arg['URL'],", "label": 0}, {"snippet_id": 59947, "code": ", or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq", "label": 0}, {"snippet_id": 24210, "code": ":weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':[", "label": 0}, {"snippet_id": 91302, "code": ".python.tasks.select_interpreter import SelectInterpreter from pants.backend.python.tasks.setup_py import SetupPy from pants.backend.python.tasks.unpack_wheels import UnpackWheels from pants.build_graph", "label": 0}, {"snippet_id": 49381, "code": "=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None,", "label": 0}, {"snippet_id": 36250, "code": ".shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex", "label": 0}, {"snippet_id": 24275, "code": "', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi", "label": 0}, {"snippet_id": 6566, "code": " process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file", "label": 1}, {"snippet_id": 49044, "code": " WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected,", "label": 1}, {"snippet_id": 90958, "code": "(str(key), ', '.join(sorted(val))) for key, val in OS_ALIASES.items()) register('--paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ", "label": 0}, {"snippet_id": 72729, "code": " vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def main(): try: _main() except KeyboardInterrupt: print", "label": 0}, {"snippet_id": 33009, "code": "(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule", "label": 0}, {"snippet_id": 58173, "code": ".get('p_ids', None) sep=data.get('sep', None) if target and p_pks and sep: p_pks=[k for k in p_pks.split(sep) if k] res=get_prod_related_objs(p_pks, target) else: res=[] return HttpResponse(json.dumps(res", "label": 0}, {"snippet_id": 16215, "code": "( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format(", "label": 0}, {"snippet_id": 59266, "code": " device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int", "label": 0}, {"snippet_id": 62920, "code": ".command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep import", "label": 0}, {"snippet_id": 13940, "code": " timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post", "label": 1}, {"snippet_id": 91782, "code": "(output_pytest_requirements_pex_filename)), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=merged_input_files, description='Run pytest for{}'.format(test_target.address.reference()), ", "label": 0}, {"snippet_id": 70661, "code": " target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support", "label": 0}, {"snippet_id": 42781, "code": " !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name", "label": 0}, {"snippet_id": 3959, "code": ", help=\"Generate and show a graph image\", action=\"store_true\") remote_mutex=subparser_remote.add_mutually_exclusive_group(required=False) remote_mutex.add_argument('-k', '--kill', help=\"switch to kill mode", "label": 0}, {"snippet_id": 63980, "code": " @staticmethod def __dependency_resolution( lwr_client): dependency_resolution=lwr_client.destination_params.get( \"dependency_resolution\", \"local\") if dependency_resolution not in[\"none\", \"local\", \"remote", "label": 0}, {"snippet_id": 60278, "code": ", p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map", "label": 0}, {"snippet_id": 56813, "code": ".testcases.models.TestCase` or a:class:`tcms.testruns.models.TestRun` :param tag_name: The name of the tag to be manipulated :type tag_name: str \"\"\" self.obj=obj self.tag_name=tag_name def add(self): tag", "label": 0}, {"snippet_id": 82985, "code": ".submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t", "label": 1}, {"snippet_id": 23446, "code": ": cmd=\"pw useradd{0} -e{1} -m\".format(username, expiration) else: cmd=\"pw useradd{0} -m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode !=0: raise OSUtilError((\"Failed to create", "label": 0}, {"snippet_id": 59072, "code": "=self.group_new.pk) expected_json=json.loads( serializers.serialize( 'json', group.property.all(), fields=('name', 'value'))) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET", "label": 0}, {"snippet_id": 74405, "code": " return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): \"\"", "label": 0}, {"snippet_id": 2452, "code": "(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({", "label": 0}, {"snippet_id": 30363, "code": " return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist):", "label": 0}, {"snippet_id": 78849, "code": "\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get", "label": 0}, {"snippet_id": 55963, "code": "=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 90086, "code": ": yield self._bin_path if self._is_jdk: yield os.path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error", "label": 0}, {"snippet_id": 95653, "code": " files to output_dir Note: This method searches through all subdirectories within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process", "label": 0}, {"snippet_id": 53900, "code": "=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log))", "label": 0}, {"snippet_id": 96046, "code": "=conversion_config.blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor type specified.\") print(\"", "label": 1}, {"snippet_id": 25961, "code": "'GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type", "label": 0}, {"snippet_id": 16585, "code": "={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave", "label": 0}, {"snippet_id": 22062, "code": " self.flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__(self, playbook, options=None, verbosity=0): if options is None", "label": 0}, {"snippet_id": 81566, "code": ".verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None):", "label": 1}, {"snippet_id": 49298, "code": " name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name", "label": 0}, {"snippet_id": 44489, "code": "*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag", "label": 0}, {"snippet_id": 25657, "code": " self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000:", "label": 0}, {"snippet_id": 73567, "code": "\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr", "label": 0}, {"snippet_id": 90099, "code": " bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{} executable,{} does not appear to be a' ' valid{} distribution'.format(name, self", "label": 0}, {"snippet_id": 48820, "code": " lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards -", "label": 0}, {"snippet_id": 42378, "code": ".temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log() self._benchmark", "label": 0}, {"snippet_id": 50824, "code": "=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else", "label": 0}, {"snippet_id": 39200, "code": " not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json", "label": 0}, {"snippet_id": 60943, "code": "(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out @classmethod def capabilities(cls): \"\"\"Get the other capabilities of the plugin. Measurements, batching etc. Returns: dict[str-", "label": 0}, {"snippet_id": 55684, "code": ".output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads", "label": 0}, {"snippet_id": 52769, "code": "( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os", "label": 0}, {"snippet_id": 94694, "code": "-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\")", "label": 0}, {"snippet_id": 88614, "code": " current workspace, if any.\"\"\" return self._workspace @property def invalidation_report(self): return self._invalidation_report def __str__(self): ident=Target.identify(self.targets()) return 'Context(id:{", "label": 0}, {"snippet_id": 51856, "code": " index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as", "label": 0}, {"snippet_id": 28172, "code": " None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 8800, "code": "(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename", "label": 0}, {"snippet_id": 16503, "code": ", completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest(", "label": 0}, {"snippet_id": 7894, "code": " 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info", "label": 0}, {"snippet_id": 37700, "code": " or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input", "label": 0}, {"snippet_id": 54937, "code": "(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles", "label": 0}, {"snippet_id": 32435, "code": ") try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards", "label": 0}, {"snippet_id": 74164, "code": " configuration. \"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_allele_count=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\"", "label": 1}, {"snippet_id": 58467, "code": " response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run':[]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected", "label": 0}, {"snippet_id": 35896, "code": "(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\"", "label": 0}, {"snippet_id": 39195, "code": ".info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats", "label": 0}, {"snippet_id": 40847, "code": "\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname:", "label": 0}, {"snippet_id": 9338, "code": " fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately", "label": 0}, {"snippet_id": 30948, "code": " missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for", "label": 0}, {"snippet_id": 26934, "code": " >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 61203, "code": " Returns: array: normalised array. \"\"\" state=np.asarray(args) return state/np.linalg.norm(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary", "label": 0}, {"snippet_id": 37542, "code": ": inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return", "label": 0}, {"snippet_id": 82496, "code": ".split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name", "label": 0}, {"snippet_id": 81014, "code": ": \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity", "label": 0}, {"snippet_id": 13513, "code": " \r MOUTH_OPEN=408 MOUTH_CLOSE=412 EYES_OPEN=410 EYES_CLOSE=414 \r io=GPIO() io.setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def", "label": 0}, {"snippet_id": 27615, "code": "._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self", "label": 0}, {"snippet_id": 8516, "code": " word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(", "label": 1}, {"snippet_id": 76130, "code": " def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Succesfully set route type for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status", "label": 0}, {"snippet_id": 36272, "code": ") @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic", "label": 0}, {"snippet_id": 90601, "code": " and `--jvm-distributions-maximum-version` is used. :param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution. :rtype::class:`Distribution` :raises::class", "label": 0}, {"snippet_id": 92789, "code": ".path.join(tempdir, 'test'), 'w', allowZip64=True) as zf: self.assertTrue(zf._allowZip64) def test_open_zipFalse(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w'", "label": 0}, {"snippet_id": 75842, "code": ".tick() while self.running.is_set(): p(timeout*1000) if rs.finished: if rs.retry: msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) rs.finished", "label": 0}, {"snippet_id": 82497, "code": "(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print", "label": 0}, {"snippet_id": 72711, "code": "=vcf_to_zarr_config) elif command==\"exec\": print(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation", "label": 0}, {"snippet_id": 65760, "code": " layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT, \"type", "label": 0}, {"snippet_id": 24070, "code": "'): if not possible.startswith('pass'): return possible cmd_search_storvsc=\"camcontrol devlist -b | grep storvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_storvsc", "label": 0}, {"snippet_id": 22016, "code": " self.sudo=sudo self.sudo_user=sudo_user self.become=become self.become_method=become_method self.become_user=become_user self.become_ask_pass=become_ask_pass self.ask_pass=ask_pass self.private_key_file", "label": 0}, {"snippet_id": 49431, "code": " detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None,", "label": 0}, {"snippet_id": 55332, "code": "(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet", "label": 0}, {"snippet_id": 14778, "code": ": tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files", "label": 0}, {"snippet_id": 49138, "code": "(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict()", "label": 0}, {"snippet_id": 27654, "code": "._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self", "label": 0}, {"snippet_id": 30, "code": " rest_framework.decorators import list_route from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common", "label": 1}, {"snippet_id": 95573, "code": " temp=ftp.nlst() if not os.path.isfile(file_path_local): with open(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded", "label": 0}, {"snippet_id": 67118, "code": ".get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=", "label": 0}, {"snippet_id": 47268, "code": ", self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic", "label": 0}, {"snippet_id": 56764, "code": ".html', TestCase.objects.get(pk=self.object_pk) def run(self): return 'run/get_tag.html', TestRun.objects.get(pk=self.object_pk) class _TagActions(object): \"\"\" Used for performing the 'add' and 'remove'", "label": 0}, {"snippet_id": 30039, "code": " os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for", "label": 0}, {"snippet_id": 70654, "code": ": eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler", "label": 0}, {"snippet_id": 34581, "code": "\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self)", "label": 0}, {"snippet_id": 14832, "code": "( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets", "label": 0}, {"snippet_id": 83310, "code": " full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str", "label": 1}, {"snippet_id": 65995, "code": " c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])", "label": 0}, {"snippet_id": 31073, "code": ": raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output", "label": 0}, {"snippet_id": 37740, "code": "=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in", "label": 0}, {"snippet_id": 94037, "code": ": for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node", "label": 0}, {"snippet_id": 15769, "code": "( syntax_parse.SyntaxKeywordsForCurrentBuffer()) def _AddTagsFilesIfNeeded( self, extra_data): def GetTagFiles(): tag_files=vim.eval( 'tagfiles()') current_working_directory=os.getcwd() return[ os.path", "label": 0}, {"snippet_id": 81726, "code": "\nimport re,requests,argparse,logging,os,coloredlogs,datetime,getpass,tempfile,itertools,json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version", "label": 0}, {"snippet_id": 68797, "code": ") layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout", "label": 0}, {"snippet_id": 26844, "code": " data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength", "label": 0}, {"snippet_id": 55688, "code": "], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value", "label": 0}, {"snippet_id": 60322, "code": ".eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset", "label": 1}, {"snippet_id": 23219, "code": " struct_size)) param=struct.pack('iL', expected*struct_size, buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno(), 0x8912, param) retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger", "label": 0}, {"snippet_id": 82158, "code": "\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by the server. Needs -l switch", "label": 0}, {"snippet_id": 23572, "code": "\"Failed to delete root password: Failed to update password database.\") def get_if_mac(self, ifname): data=self._get_net_info() if data[0]==ifname: return data[2].replace(':', '').upper() return None def", "label": 0}, {"snippet_id": 54297, "code": ". Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule)", "label": 0}, {"snippet_id": 36746, "code": ".rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic", "label": 0}, {"snippet_id": 84837, "code": " \"\"\" options_scope='scala' @classmethod def _create_jardep(cls, name, version): return JarDependency(org='org.scala-lang', name=name, rev=scala_build_info[version].full_version) @classmethod def _create_runtime_jardep", "label": 0}, {"snippet_id": 28164, "code": " None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '", "label": 0}, {"snippet_id": 40875, "code": ") for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames", "label": 0}, {"snippet_id": 42289, "code": " K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile", "label": 0}, {"snippet_id": 11983, "code": ".format(data[\"repository\"], data[\"after_commit_hash\"]) r=requests.get(url, headers=headers, auth=auth) if r.status_code==200: try: new_config=yaml.load(r.text) config=update_dict(config, new_config) except", "label": 0}, {"snippet_id": 32934, "code": " log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def", "label": 0}, {"snippet_id": 88796, "code": "(): self.log.debug('subproc_map result still not ready...') return res.get() except KeyboardInterrupt: SubprocPool.shutdown(True) raise @contextmanager def new_workunit(self, name, labels=None, cmd='',", "label": 0}, {"snippet_id": 87203, "code": ".safe_create_data('zinc_analysis', dict) if self.context.products.is_required_data('zinc_args'): self.context.products.safe_create_data('zinc_args', lambda: defaultdict(list)) def javac_classpath(self)", "label": 0}, {"snippet_id": 52141, "code": " be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic", "label": 0}, {"snippet_id": 45742, "code": " not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time", "label": 0}, {"snippet_id": 30721, "code": " if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o", "label": 0}, {"snippet_id": 19683, "code": " parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None) clienthost=ns.pop('host', None) if", "label": 0}, {"snippet_id": 84292, "code": " outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds[", "label": 0}, {"snippet_id": 78392, "code": "'topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min exc caught, topic_successtimeout +0.1, cur: %f", "label": 0}, {"snippet_id": 34971, "code": " None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in", "label": 0}, {"snippet_id": 42153, "code": ", other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None", "label": 0}, {"snippet_id": 15855, "code": ".unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content", "label": 0}, {"snippet_id": 51325, "code": " return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match", "label": 0}, {"snippet_id": 34512, "code": ".harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import", "label": 1}, {"snippet_id": 59976, "code": " if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={", "label": 0}, {"snippet_id": 16423, "code": ") else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive", "label": 0}, {"snippet_id": 83942, "code": ": %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID ", "label": 0}, {"snippet_id": 78725, "code": " remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to", "label": 0}, {"snippet_id": 89107, "code": " from_predicate=None): \"\"\"Returns a map from targets that satisfy the from_predicate to targets they depend on that satisfy the on_predicate. :API: public \"\"\" core=set(self.targets(on_predicate)) dependees", "label": 0}, {"snippet_id": 74766, "code": " vcf_to_zarr_blosc_algorithm_types: self.blosc_compression_algorithm=blosc_compression_algorithm_temp if \"blosc_compression_level\" in runtime_config.vcf_to_zarr: blosc_compression_level_str=runtime_config", "label": 0}, {"snippet_id": 14403, "code": " def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, ", "label": 0}, {"snippet_id": 44411, "code": " return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot(", "label": 0}, {"snippet_id": 88042, "code": " classpath_element in classpath: name=self._maybe_get_plugin_name(classpath_element) if name in plugin_names: plugin_target_closure=self._plugin_targets('scalac').get(name,[]) rel_classpath_elements=[ os.path", "label": 0}, {"snippet_id": 50930, "code": " 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if", "label": 0}, {"snippet_id": 26198, "code": "'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None", "label": 0}, {"snippet_id": 75570, "code": " return(b'Router', b'auth-set-route-type', args, reqid) def make_auth_clear_data(self, reqid=None): if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self,", "label": 0}, {"snippet_id": 66952, "code": " available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register", "label": 0}, {"snippet_id": 31322, "code": ".dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self)", "label": 0}, {"snippet_id": 60376, "code": ".params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('fock', cutoff_dim=self.cutoff", "label": 0}, {"snippet_id": 59549, "code": ".reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def shutdown(self", "label": 0}, {"snippet_id": 65192, "code": "=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>][-t <target>][-i ", "label": 0}, {"snippet_id": 5937, "code": " text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe ", "label": 0}, {"snippet_id": 11618, "code": " def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with open(self.output_file, 'w') as f: for line in lines: f.write(line +\"\\n\") LOG.debug(\"Created %s\" % self.output_file", "label": 0}, {"snippet_id": 48259, "code": " \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be", "label": 0}, {"snippet_id": 26467, "code": " @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def", "label": 0}, {"snippet_id": 44524, "code": "=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not", "label": 0}, {"snippet_id": 92908, "code": " temporary_file(binary_mode=False) as tmp_stderr: print(stdin_data, file=tmp_stdin) tmp_stdin.seek(0) with stdio_as(stdout_fd=tmp_stdout.fileno(), stderr_fd=tmp_stderr.fileno(), stdin_fd=tmp_stdin.fileno", "label": 0}, {"snippet_id": 61691, "code": " if U.shape !=(2, 2): raise ValueError('2x2 matrix required.') if len(wires) !=1: raise ValueError('One target subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron", "label": 0}, {"snippet_id": 41375, "code": " chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions", "label": 1}, {"snippet_id": 77827, "code": ") if self.c.tcount > 0: self.pc=ProcessContext(self.p.name, self.p.ctx, self.c.router_addr, noproxy_rp) self.spawnqueue=Queue() self.load_bumplimit_set() self.load_targets() self.load_users() self.spawn_wipethreads", "label": 0}, {"snippet_id": 31625, "code": "(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input", "label": 0}, {"snippet_id": 93098, "code": " self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self): fake_logger=mock.Mock() with self.assertRaises(AssertionError): with exception_logging(fake_logger, 'error!'): assert", "label": 0}, {"snippet_id": 31710, "code": " enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in", "label": 1}, {"snippet_id": 63582, "code": " in[ model.Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally", "label": 0}, {"snippet_id": 10579, "code": "=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf", "label": 1}, {"snippet_id": 63767, "code": "%d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d", "label": 0}, {"snippet_id": 26085, "code": "(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self", "label": 1}, {"snippet_id": 91094, "code": ": return() os_name=normalize_os_name(os.uname()[0].lower()) if os_name not in self._normalized_jdk_paths: logger.warning('--jvm-distributions-paths was specified, but has no entry for \"{}\".' .format(os_name", "label": 0}, {"snippet_id": 50171, "code": " def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the", "label": 0}, {"snippet_id": 74757, "code": "=compressor_temp if \"blosc_compression_algorithm\" in runtime_config.vcf_to_zarr: blosc_compression_algorithm_temp=runtime_config.vcf_to_zarr[\"blosc_compression_algorithm\"] if blosc_compression_algorithm_temp", "label": 0}, {"snippet_id": 23540, "code": "(passwd_hash, username) ret, output=shellutil.run_get_output(cmd, log_cmd=False) if ret !=0: raise OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format(username, output)) def del_root_password(self", "label": 0}, {"snippet_id": 35172, "code": " value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags", "label": 1}, {"snippet_id": 70874, "code": " AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def", "label": 0}, {"snippet_id": 4945, "code": ") composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('</record></collection>') return '\\n'.join(output", "label": 0}, {"snippet_id": 66469, "code": " FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__", "label": 0}, {"snippet_id": 33224, "code": " None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files:", "label": 0}, {"snippet_id": 36811, "code": " neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(", "label": 0}, {"snippet_id": 50768, "code": " Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not", "label": 1}, {"snippet_id": 53993, "code": "(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self", "label": 0}, {"snippet_id": 28691, "code": "._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self", "label": 0}, {"snippet_id": 48212, "code": " def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name", "label": 0}, {"snippet_id": 94570, "code": " def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd,", "label": 0}, {"snippet_id": 60267, "code": " space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry Fields", "label": 0}, {"snippet_id": 53130, "code": " collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake", "label": 0}, {"snippet_id": 80371, "code": " requires --input-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _ _ ___| |___|_|_| |___ ___ | _| | |_'_|. | |. | |. | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"", "label": 0}, {"snippet_id": 1115, "code": ".POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers", "label": 0}, {"snippet_id": 54823, "code": ", printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary", "label": 0}, {"snippet_id": 40043, "code": ".access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self):", "label": 1}, {"snippet_id": 90686, "code": "=minimum_version, maximum_version=maximum_version, jdk=jdk) self._cache[key]=dist return dist def _locate(self, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Finds a java distribution that meets", "label": 0}, {"snippet_id": 68022, "code": "% message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status", "label": 0}, {"snippet_id": 92385, "code": "=subprocess.check_output('env', shell=True).decode('utf-8') self.assertNotIn('USER=', output) self.assertIn('AAA', os.environ) self.assertEqual(os.environ['AAA'], '333') self.assertIn('USER', os.environ", "label": 1}, {"snippet_id": 38297, "code": "() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self", "label": 0}, {"snippet_id": 86043, "code": " self).__init__(*args, **kwargs) self.set_distribution(jdk=True) def select(self, target): if not isinstance(target, JvmTarget): return False return target.has_sources('.java') def select_source(self, source_file_path", "label": 0}, {"snippet_id": 69645, "code": " execute(self): if not self.opt_m: print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf", "label": 1}, {"snippet_id": 69217, "code": " \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage", "label": 0}, {"snippet_id": 39185, "code": " resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule", "label": 0}, {"snippet_id": 6077, "code": " read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext", "label": 0}, {"snippet_id": 17378, "code": " stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None", "label": 0}, {"snippet_id": 72866, "code": " path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors=True) def fetch_data_via_ftp(ftp_config, local_directory): \"\"\" Get benchmarking data from a remote ftp server. :type ftp_config", "label": 0}, {"snippet_id": 79108, "code": " pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename", "label": 1}, {"snippet_id": 58652, "code": "'field': 'is_active', 'value': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc", "label": 0}, {"snippet_id": 2991, "code": ".start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in", "label": 0}, {"snippet_id": 1569, "code": "': print(action) boxname=escape(request.POST.get(\"boxname\")) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) print(username) add_user(username,password) setBoxName", "label": 0}, {"snippet_id": 48537, "code": "(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize", "label": 0}, {"snippet_id": 40687, "code": " raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given", "label": 0}, {"snippet_id": 15588, "code": "={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave", "label": 0}, {"snippet_id": 24105, "code": " Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous", "label": 1}, {"snippet_id": 68696, "code": "=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target", "label": 0}, {"snippet_id": 51801, "code": " toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item", "label": 0}, {"snippet_id": 60373, "code": ") else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('fock", "label": 0}, {"snippet_id": 37393, "code": "\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input", "label": 0}, {"snippet_id": 69257, "code": ".GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError", "label": 1}, {"snippet_id": 26417, "code": " sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class", "label": 0}, {"snippet_id": 18152, "code": ".completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import", "label": 0}, {"snippet_id": 62521, "code": " **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend", "label": 0}, {"snippet_id": 42777, "code": "=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names", "label": 0}, {"snippet_id": 45937, "code": ", pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value", "label": 0}, {"snippet_id": 34477, "code": " targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. ", "label": 0}, {"snippet_id": 60070, "code": ") self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self", "label": 0}, {"snippet_id": 71378, "code": "(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column", "label": 0}, {"snippet_id": 58924, "code": "'response': \"You don't have enough permission to \" \"update TestCases.\"}) def test_update_case_priority(self): self.client.login( username=self.tester.username, password='password') response=self.client", "label": 0}, {"snippet_id": 26898, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self", "label": 0}, {"snippet_id": 68734, "code": ": flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\"", "label": 0}, {"snippet_id": 85514, "code": "=zinc_rev), ], main='no.such.main.Main', custom_rules=shader_rules) cls.register_jvm_tool(register, Zinc.ZINC_EXTRACTOR_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-extractor_2.11', '0.0.4'", "label": 1}, {"snippet_id": 56482, "code": " users(self): query=strip_parameters(self.request.GET, skip_parameters=('info_type', 'field', 'format')) return User.objects.filter(**query) def versions(self): return Version.objects.filter(product__id", "label": 0}, {"snippet_id": 78214, "code": "*kvargs) def on_caprate_limit(self, rate): if not self.logined: self._capdata=(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self): for", "label": 0}, {"snippet_id": 20458, "code": " _create(cls, connect, addr, timeout=None): if timeout is None: timeout=cls.TIMEOUT sock=connect(addr, timeout) if cls.VERBOSE: print('connected') self=cls(sock, ownsock=True) self._addr=addr return self", "label": 0}, {"snippet_id": 60973, "code": " and measure the expectation.\"\"\" raise NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset the backend state. After the reset the backend should be as if it was just constructed. Most importantly", "label": 0}, {"snippet_id": 24734, "code": "=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state", "label": 0}, {"snippet_id": 59813, "code": ")[-1]+'0'), self.reg) variance=1 -expectation_value**2 elif observable=='AllPauliZ': expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg", "label": 0}, {"snippet_id": 70703, "code": ") if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max", "label": 0}, {"snippet_id": 18966, "code": ".scheme and parts.netloc: response=requests.get(source) if isinstance(response.content, six.binary_type): raw_source=six.text_type(response.content, encoding='utf-8') else: raw_source=response.content else:", "label": 0}, {"snippet_id": 43990, "code": " jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False,", "label": 0}, {"snippet_id": 71551, "code": "(node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self", "label": 0}, {"snippet_id": 74187, "code": " Benchmark module's configuration data. :param runtime_config: runtime_config data to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not", "label": 0}, {"snippet_id": 42037, "code": "._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except", "label": 0}, {"snippet_id": 52945, "code": " \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return", "label": 0}, {"snippet_id": 53762, "code": " specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start", "label": 0}, {"snippet_id": 55960, "code": "(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd)", "label": 0}, {"snippet_id": 63328, "code": " prepare_kwds[ 'compute_environment']=compute_environment job_wrapper.prepare( **prepare_kwds) self.__prepare_input_files_locally(job_wrapper) remote_metadata=LwrJobRunner.__remote_metadata( client) remote_work_dir_copy", "label": 0}, {"snippet_id": 21187, "code": " AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None): super(AwaitableResponse, self).__init__(req[\"command\"], event) self.req=req self._result_getter=result_getter @property def", "label": 0}, {"snippet_id": 14795, "code": " extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for", "label": 0}, {"snippet_id": 71485, "code": ".EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name", "label": 0}, {"snippet_id": 2625, "code": " dependency: '%s' for component '%s'!\" %(dep, node.comp_name)) if exit_on_fail: exit(1) self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res", "label": 0}, {"snippet_id": 10316, "code": "\"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords", "label": 0}, {"snippet_id": 21807, "code": " random_state=0) from sklearn.preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) import keras from keras.models import Sequential from", "label": 1}, {"snippet_id": 51770, "code": " names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to", "label": 0}, {"snippet_id": 14010, "code": ": return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666", "label": 0}, {"snippet_id": 48984, "code": " comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self", "label": 0}, {"snippet_id": 31064, "code": " def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution", "label": 0}, {"snippet_id": 24699, "code": "._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self", "label": 0}, {"snippet_id": 78917, "code": "\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t", "label": 0}, {"snippet_id": 8608, "code": " of BibClassify. its two main methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one", "label": 0}, {"snippet_id": 19209, "code": " import collections import six import json import yaml from flex.core import load_source def test_native_mapping_is_passthrough(): source={'foo': 'bar'} result=load_source(source) assert result==source", "label": 0}, {"snippet_id": 43607, "code": " import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException", "label": 0}, {"snippet_id": 89315, "code": " abstractproperty from builtins import object, open, str from collections import namedtuple from contextlib import contextmanager from future.utils import PY3 from six import string_types from pants.base", "label": 1}, {"snippet_id": 28833, "code": "'WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 51832, "code": " name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index", "label": 0}, {"snippet_id": 78623, "code": " Writer from dbnav import logger as log from dbnav.jsonable import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec': 'executer', 'dbexport': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class", "label": 0}, {"snippet_id": 69739, "code": " RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler", "label": 0}, {"snippet_id": 82777, "code": " --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName) else: \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size", "label": 0}, {"snippet_id": 72153, "code": " return network.serverdata['autoconnect']=seconds irc.reply(\"Done.\") remote_parser=utils.IRCParser() remote_parser.add_argument('network') remote_parser.add_argument('--service', type=str, default='pylink')", "label": 0}, {"snippet_id": 38410, "code": " add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used", "label": 0}, {"snippet_id": 11426, "code": " lines=yaml_icinga.icinga_lines output_writer=OutputWriter(self.output_path(file_name)) output_writer.write_lines(lines) @staticmethod def create_filename(hostname): name='%s.cfg' % hostname if name !=os", "label": 0}, {"snippet_id": 34873, "code": " def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,", "label": 0}, {"snippet_id": 16797, "code": " extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data", "label": 0}, {"snippet_id": 7424, "code": " if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches,", "label": 0}, {"snippet_id": 37556, "code": " strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items", "label": 0}, {"snippet_id": 7573, "code": " only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> ", "label": 0}, {"snippet_id": 95924, "code": " converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion", "label": 0}, {"snippet_id": 48745, "code": " if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule", "label": 0}, {"snippet_id": 68025, "code": " def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %", "label": 0}, {"snippet_id": 44526, "code": "=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not", "label": 0}, {"snippet_id": 40739, "code": "(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance", "label": 0}, {"snippet_id": 39424, "code": "=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo", "label": 0}, {"snippet_id": 54954, "code": " priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)", "label": 0}, {"snippet_id": 58549, "code": ".username, password='password') new_comment='new comment' response=self.client.post( self.many_comments_url, {'comment': new_comment, 'run': ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])", "label": 0}, {"snippet_id": 18606, "code": "._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request", "label": 0}, {"snippet_id": 95604, "code": "}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz", "label": 0}, {"snippet_id": 79710, "code": ") parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds", "label": 0}, {"snippet_id": 89158, "code": ".build_graph.resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies", "label": 0}, {"snippet_id": 32136, "code": " TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item", "label": 0}, {"snippet_id": 30583, "code": " chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile", "label": 0}, {"snippet_id": 56219, "code": ".decorators.http import require_POST from tcms.signals import POST_UPDATE_SIGNAL from tcms.management.models import Component, Build, Version from tcms.management.models import Priority from tcms.management", "label": 0}, {"snippet_id": 45978, "code": "=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def", "label": 1}, {"snippet_id": 95584, "code": "}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:", "label": 0}, {"snippet_id": 59651, "code": " error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self", "label": 0}, {"snippet_id": 62832, "code": ".eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng", "label": 0}, {"snippet_id": 3486, "code": ".logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name) start_window(window, self.config['cmd'][0]['start'], self.log_file, self.window_name) else: self", "label": 0}, {"snippet_id": 82089, "code": ", for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example:", "label": 0}, {"snippet_id": 7725, "code": "] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else", "label": 0}, {"snippet_id": 36209, "code": ".rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell", "label": 0}, {"snippet_id": 18440, "code": "( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False)", "label": 0}, {"snippet_id": 21125, "code": ".append('Event{}'.format(awaitable.name)) else: messages.append('Response{}'.format(awaitable.name)) if len(messages)==0: return else: raise TimeoutError('Timeout waiting for{}'.format(','.join(messages)))", "label": 0}, {"snippet_id": 50067, "code": "._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse", "label": 0}, {"snippet_id": 14379, "code": ": args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed()", "label": 0}, {"snippet_id": 6538, "code": "=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines", "label": 0}, {"snippet_id": 9918, "code": " dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output", "label": 0}, {"snippet_id": 62823, "code": " backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable", "label": 0}, {"snippet_id": 48203, "code": " \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item", "label": 0}, {"snippet_id": 19828, "code": " self._session=None self._breakpoints=breakpoints @property def adapter(self): return self._adapter @property def session(self): return self._session def start_debugging(self, launchcfg): if self.closed", "label": 0}, {"snippet_id": 45462, "code": ": return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink", "label": 0}, {"snippet_id": 56984, "code": "') (None, 'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid literal for int() with base 10: 'string'\") \"\"\" value=error=None def get_time(time): date_time=datetime.datetime", "label": 0}, {"snippet_id": 19556, "code": "') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd", "label": 0}, {"snippet_id": 93213, "code": " STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self", "label": 0}, {"snippet_id": 39818, "code": "=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os", "label": 0}, {"snippet_id": 5774, "code": " dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items(", "label": 0}, {"snippet_id": 72085, "code": ".add_cmd def autoconnect(irc, source, args): \"\"\"<network> <seconds> Sets the autoconnect time for <network> to <seconds>. You can disable autoconnect for a network by setting <seconds> to a negative value.\"", "label": 0}, {"snippet_id": 19068, "code": " as defined in the swagger spec, validate that the schema complies to spec. If `target` is provided, that target will be validated against the provided schema. \"\"\" schema=schema_validator(raw_schema, *", "label": 0}, {"snippet_id": 58798, "code": " test_change_case_run_status(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.update_url,{ 'content_type': 'testruns.testcaserun', 'object_pk", "label": 0}, {"snippet_id": 6203, "code": " to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise", "label": 1}, {"snippet_id": 48326, "code": "\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified", "label": 0}, {"snippet_id": 88176, "code": " 'r')) as plugin_info_file: return process_info_file(classpath_element, plugin_info_file) except KeyError: pass return None class ZincCompile(BaseZincCompile): \"\"\"Compile Scala and Java code to classfiles", "label": 0}, {"snippet_id": 20215, "code": ", ) t.start() def wait(): t.join(timeout=self._connecttimeout) if t.is_alive(): warnings.warn('timed out waiting for connection') if self._session is None: message='unable to connect after{} secs'.format", "label": 0}, {"snippet_id": 69966, "code": "\"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall", "label": 0}, {"snippet_id": 44909, "code": " isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority,", "label": 0}, {"snippet_id": 4104, "code": " between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are", "label": 0}, {"snippet_id": 63520, "code": ".security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id, job_key ) get_client_kwds=dict(", "label": 0}, {"snippet_id": 66342, "code": "\"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\"", "label": 0}, {"snippet_id": 30401, "code": " pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except", "label": 0}, {"snippet_id": 41910, "code": " creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if", "label": 0}, {"snippet_id": 84844, "code": " version): return JarDependency(org='org.scala-lang', name=name, rev=scala_build_info[version].full_version) @classmethod def _create_runtime_jardep(cls, version): return cls._create_jardep('scala-library", "label": 1}, {"snippet_id": 94781, "code": "-kill', help=\"switch to kill mode\", action=\"store_true\") remote_mutex.add_argument('-c', '--check', help=\"Run a component check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args", "label": 0}, {"snippet_id": 29547, "code": " in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs", "label": 0}, {"snippet_id": 63588, "code": " cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs", "label": 0}, {"snippet_id": 45683, "code": ").match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__", "label": 0}, {"snippet_id": 56400, "code": " self.request=request try: self.product_id=int(product_id) except(ValueError, TypeError): self.product_id=0 def builds(self): try: is_active=strtobool(self.request.GET.get('is_active', default='False')", "label": 0}, {"snippet_id": 49351, "code": ".resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch", "label": 0}, {"snippet_id": 95482, "code": "+remote_directory +\"/\" +remote_path_relative +\"/\" else: remote_subdirs_list=[] remote_path_relative=\"\" remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative", "label": 0}, {"snippet_id": 16349, "code": ", std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self._server_stdout)) args.append('--stderr={0}'.format( self._server_stderr", "label": 0}, {"snippet_id": 78943, "code": " \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1", "label": 0}, {"snippet_id": 95540, "code": "(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file", "label": 0}, {"snippet_id": 1585, "code": ".get(\"password\")) print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if", "label": 0}, {"snippet_id": 44395, "code": " please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in", "label": 0}, {"snippet_id": 26711, "code": "'battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif", "label": 0}, {"snippet_id": 53253, "code": ".message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set", "label": 0}, {"snippet_id": 17467, "code": "._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic", "label": 0}, {"snippet_id": 64233, "code": "._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config.working_directory()) self._config_directory=remote_job_config", "label": 0}, {"snippet_id": 31426, "code": ".incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{", "label": 0}, {"snippet_id": 83537, "code": "=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '", "label": 0}, {"snippet_id": 64480, "code": "\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg", "label": 0}, {"snippet_id": 8671, "code": "\"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor", "label": 0}, {"snippet_id": 55623, "code": "(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name", "label": 0}, {"snippet_id": 43121, "code": " isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems,", "label": 0}, {"snippet_id": 90926, "code": "()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java distribution:{}'.format(e)) options_scope", "label": 0}, {"snippet_id": 45810, "code": " os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\"", "label": 0}, {"snippet_id": 94089, "code": "\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode=False, check_mode=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__", "label": 0}, {"snippet_id": 56441, "code": ") def components(self): return Component.objects.filter(product__id=self.product_id) def env_groups(self): return EnvGroup.objects.all() def env_properties(self): if self.request.GET.get('env_group_id'", "label": 0}, {"snippet_id": 35498, "code": " f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items.", "label": 0}, {"snippet_id": 3112, "code": "\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts", "label": 0}, {"snippet_id": 47588, "code": "=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set", "label": 0}, {"snippet_id": 57777, "code": ": return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets=self.get_update_targets", "label": 0}, {"snippet_id": 11637, "code": "% self.output_file) def generate_config(): arg=docopt(__doc__, version='0.1.0') start_time=datetime.now() try: file_name=MonitoringConfigGenerator(arg['URL'], arg['--debug'], arg['--targetdir'], arg['-", "label": 0}, {"snippet_id": 31856, "code": " lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property", "label": 0}, {"snippet_id": 38453, "code": ".first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name", "label": 0}, {"snippet_id": 7210, "code": "/controlfield>' % recid] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)", "label": 0}, {"snippet_id": 56514, "code": "=['app_form', 'format'] parameters=strip_parameters(request.GET, internal_parameters) q_app_form=request.GET.get('app_form') q_format=request.GET.get('format') if not q_format: q_format='p' if not q_app_form", "label": 1}, {"snippet_id": 70686, "code": "(\"disk\") or view.startswith(\"target\"): status_flags &=~STATUS_CLIENTS if view.startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR", "label": 0}, {"snippet_id": 74765, "code": "] if blosc_compression_algorithm_temp in vcf_to_zarr_blosc_algorithm_types: self.blosc_compression_algorithm=blosc_compression_algorithm_temp if \"blosc_compression_level\" in runtime_config.vcf_to_zarr:", "label": 0}, {"snippet_id": 44637, "code": "(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile", "label": 0}, {"snippet_id": 5760, "code": " component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords:", "label": 0}, {"snippet_id": 91220, "code": "\\ BuildLocalPythonDistributions from pants.backend.python.tasks.gather_sources import GatherSources from pants.backend.python.tasks.isort_prep import IsortPrep from pants.backend.python.tasks.isort_run", "label": 0}, {"snippet_id": 2873, "code": " is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component '%s", "label": 0}, {"snippet_id": 37233, "code": "\"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input", "label": 0}, {"snippet_id": 39280, "code": " logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code", "label": 0}, {"snippet_id": 40660, "code": " has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if", "label": 1}, {"snippet_id": 32441, "code": "=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output", "label": 0}, {"snippet_id": 69306, "code": ".Globals import Globals from Shine.Configuration.Configuration import Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file", "label": 0}, {"snippet_id": 68886, "code": "\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic,", "label": 0}, {"snippet_id": 94791, "code": "('-c', '--check', help=\"Run a component check\", action=\"store_true\") args=parser.parse_args() logger.debug(args) if args.cmd=='edit': logger.debug(\"Launching editor mode\") elif args.cmd=='run': logger.debug", "label": 0}, {"snippet_id": 83373, "code": ".__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description=dependencies_description", "label": 0}, {"snippet_id": 34096, "code": ") rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric", "label": 0}, {"snippet_id": 61079, "code": ", 1, 0, 0],[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_x \\theta/2}` \"\"\" return", "label": 0}, {"snippet_id": 52477, "code": " Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError", "label": 0}, {"snippet_id": 9776, "code": " output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0", "label": 0}, {"snippet_id": 326, "code": " print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({\"STATUS\":\"SUCCESS", "label": 0}, {"snippet_id": 82863, "code": "\"Exiting.\") entryPoints=[] up.stopThreads=True with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\" c=datetime.datetime.now() nbOfEntryPointsFound", "label": 0}, {"snippet_id": 6260, "code": "=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\"", "label": 1}, {"snippet_id": 24933, "code": " data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state", "label": 0}, {"snippet_id": 50665, "code": " return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs", "label": 0}, {"snippet_id": 24659, "code": " self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000:", "label": 0}, {"snippet_id": 24096, "code": ".*//'\".format(output) err, output=shellutil.run_get_output(cmd_search_dev) if err==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible return None @staticmethod", "label": 0}, {"snippet_id": 63705, "code": " try: os.kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d", "label": 0}, {"snippet_id": 63956, "code": "=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution==\"remote\" if not remote_dependency_resolution: return None requirements=job_wrapper.tool.requirements or[", "label": 0}, {"snippet_id": 92061, "code": " current target closure has native sources. :raises::class:`pants.base.exceptions.IncompatiblePlatformsError` \"\"\" if not self._any_targets_have_native_sources(targets): return False platforms_with_sources", "label": 0}, {"snippet_id": 84422, "code": "(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path def output_paths( self): local_output_paths=self._wrapper_output_paths results=[] for local_output_path in", "label": 0}, {"snippet_id": 39632, "code": " params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message", "label": 0}, {"snippet_id": 86331, "code": " TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ", "label": 0}, {"snippet_id": 13556, "code": "==1):\r io.set( MOUTH_OPEN, 1)\r io.set( MOUTH_CLOSE, 0)\r else:\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE, 1)\r else:\r if( time.time() -lastMouthEventTime > 0.4):\r io.set( MOUTH_OPEN, 0)\r io.set( MOUTH_CLOSE", "label": 0}, {"snippet_id": 51126, "code": "?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing", "label": 0}, {"snippet_id": 13677, "code": " TWITTER CREDENTIALS. Please read README.md for instructions.\") \r else:\r twitter=ChippyTwitter(consumerKey,consumerSecret,accessTokenKey,accessTokenSecret)\r \r web=WebFramework(talk)\r isRunning=False\r io", "label": 0}, {"snippet_id": 63124, "code": ".job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep( 2", "label": 0}, {"snippet_id": 24124, "code": " import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const import( TEMP_CELSIUS, DEVICE_CLASS_HUMIDITY, DEVICE_CLASS_TEMPERATURE, STATE_UNKNOWN) from", "label": 0}, {"snippet_id": 16598, "code": " return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not", "label": 0}, {"snippet_id": 34525, "code": " product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os", "label": 1}, {"snippet_id": 37343, "code": "=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards", "label": 0}, {"snippet_id": 66746, "code": "\"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\"", "label": 1}, {"snippet_id": 59080, "code": "================ **Module name:**:mod:`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize", "label": 0}, {"snippet_id": 4834, "code": ": categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text", "label": 0}, {"snippet_id": 88103, "code": " @classmethod @memoized_method def _maybe_get_plugin_name(cls, classpath_element): \"\"\"If classpath_element is a scalac plugin, returns its name. Returns None otherwise. \"\"\" def process_info_file(cp_elem", "label": 0}, {"snippet_id": 38208, "code": ", CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler", "label": 0}, {"snippet_id": 76657, "code": " return sup.randstr(1, 30) import argparse parser=argparse.ArgumentParser(add_help=True) parser.add_argument('--only-cache', '-C', action='store_true', help=\"Disables any requests in DataLoader(includes", "label": 0}, {"snippet_id": 48917, "code": " return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list", "label": 0}, {"snippet_id": 46943, "code": " in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input", "label": 0}, {"snippet_id": 21659, "code": ".min() -1, stop=X_set[:, 0].max() +1, step=0.01), np.arange(start=X_set[:, 1].min() -1, stop=X_set[:, 1].max() +1, step=0.01)) plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T", "label": 0}, {"snippet_id": 29691, "code": "(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value", "label": 0}, {"snippet_id": 29906, "code": "\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values", "label": 0}, {"snippet_id": 77227, "code": ") except Exception as e: self.log.exception('Line %s raised exception %s', line, e) return newproxies.difference(self.proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try:", "label": 0}, {"snippet_id": 75629, "code": " interval, *args, **kvargs): self.interval=interval super().__init__(*args, **kvargs) class Resume(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__", "label": 0}, {"snippet_id": 60086, "code": "(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']", "label": 0}, {"snippet_id": 84541, "code": " builtins import open from future.utils import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants.base.workunit import WorkUnitLabel from pants.engine.fs import", "label": 0}, {"snippet_id": 33182, "code": " list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False,", "label": 0}, {"snippet_id": 31107, "code": ".warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self", "label": 0}, {"snippet_id": 42531, "code": "=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError:", "label": 1}, {"snippet_id": 82053, "code": "\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group", "label": 0}, {"snippet_id": 23514, "code": " self.is_sys_user(username): raise OSUtilError((\"User{0} is a system user, \" \"will not set password.\").format(username)) passwd_hash=textutil.gen_password_hash(password, crypt_id, salt_len) cmd=\"echo '{0", "label": 0}, {"snippet_id": 78032, "code": "(id_, 10) return id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not in forums: forums[domain]=set() if len(forum) > 0: get_forum_id(forum", "label": 0}, {"snippet_id": 47654, "code": " executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join", "label": 0}, {"snippet_id": 55388, "code": "}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources", "label": 0}, {"snippet_id": 86321, "code": ".wait() workunit.set_outcome(WorkUnit.FAILURE if return_code else WorkUnit.SUCCESS) if return_code: raise TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args", "label": 0}, {"snippet_id": 1733, "code": ") con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart", "label": 0}, {"snippet_id": 82011, "code": "=parser.add_argument_group('Required named arguments') requiredNamedArgs.add_argument(\"-u\",\"--url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested", "label": 0}, {"snippet_id": 40884, "code": "\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\"", "label": 0}, {"snippet_id": 52869, "code": ", log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex", "label": 0}, {"snippet_id": 45719, "code": "+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)", "label": 0}, {"snippet_id": 76293, "code": "): for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)", "label": 0}, {"snippet_id": 83534, "code": " remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line", "label": 0}, {"snippet_id": 44533, "code": "=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa", "label": 0}, {"snippet_id": 40664, "code": "=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"", "label": 1}, {"snippet_id": 19597, "code": "'-m'): if arg=='-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg) skip +=1 elif arg in('--single-session',): supported.append(arg) elif not arg.startswith('-')", "label": 1}, {"snippet_id": 90753, "code": " try: dist=Distribution(home_path=location.home_path, bin_path=location.bin_path, minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) dist.validate() logger.debug('Located{} for constraints", "label": 0}, {"snippet_id": 36817, "code": " always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \",", "label": 0}, {"snippet_id": 20670, "code": ") def _create_request(self, command, **args): seq=self._seq self._seq +=1 return{ 'type': 'request', 'seq': seq, 'command': command, 'arguments': args, } def send_request(self, command, **args): if self", "label": 0}, {"snippet_id": 83915, "code": ") return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except", "label": 0}, {"snippet_id": 85044, "code": " suffix to be used in `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool('2.10'", "label": 0}, {"snippet_id": 7383, "code": " keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw)", "label": 0}, {"snippet_id": 83409, "code": ".set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job ", "label": 0}, {"snippet_id": 32260, "code": ": self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards", "label": 0}, {"snippet_id": 22215, "code": ".conf[state]['playbook'] if 'log_file' in self.conf[state]: log_file=self.conf[state]['log_file'] if 'template' in self.conf[state]: template=self.conf[state]['template'] if playbook is None: playbook=self", "label": 0}, {"snippet_id": 37107, "code": " else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for", "label": 0}, {"snippet_id": 69102, "code": "%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel >", "label": 0}, {"snippet_id": 81822, "code": "\"templateName\"]+\"' -\"+t[\"description\"] parser=argparse.ArgumentParser(epilog=templatesSection,description=__doc__, formatter_class=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar", "label": 0}, {"snippet_id": 71153, "code": " other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target", "label": 0}, {"snippet_id": 39961, "code": " return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile", "label": 0}, {"snippet_id": 91365, "code": " context_aware_object_factories={ 'python_requirements': PythonRequirements, PantsRequirement.alias: PantsRequirement, } ) def register_goals(): task(name='interpreter', action=SelectInterpreter).install", "label": 0}, {"snippet_id": 65285, "code": " for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self", "label": 0}, {"snippet_id": 89300, "code": " import absolute_import, division, print_function, unicode_literals import itertools import logging import os import pkgutil import plistlib from abc import abstractproperty from builtins import object, open", "label": 0}, {"snippet_id": 39295, "code": ".included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert", "label": 0}, {"snippet_id": 67438, "code": ") self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals", "label": 0}, {"snippet_id": 80940, "code": "\tself.logger=logging.getLogger(\"fuxploider\") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl", "label": 0}, {"snippet_id": 49018, "code": " functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions", "label": 0}, {"snippet_id": 58517, "code": ") response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run': '99999998,1009900'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response", "label": 0}, {"snippet_id": 48060, "code": " return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input", "label": 0}, {"snippet_id": 54307, "code": ", wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0", "label": 0}, {"snippet_id": 69724, "code": " Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions", "label": 0}, {"snippet_id": 39063, "code": "\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map", "label": 0}, {"snippet_id": 10645, "code": " is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read", "label": 0}, {"snippet_id": 61537, "code": " / self.shots self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given operation. Args: A(openqml.Operation or openqml.Expectation): operation/observable. Returns", "label": 0}, {"snippet_id": 56727, "code": " in['plan', 'case', 'run']: if request.GET.get(obj): self.object=obj self.object_pk=request.GET.get(obj) break def get(self): func=getattr(self, self.object) return func() def plan(self): return 'management", "label": 0}, {"snippet_id": 23176, "code": " struct_size, we can't get the information we need. I believe this may be caused by only python i686 being shipped with BIG-IP instead of python x86_64?? \"\"\" iface='' expected=16 python_arc=platform.architecture(", "label": 0}, {"snippet_id": 11273, "code": "/monitoring_config_generator/config.yaml --skip-checks Do not run checks on the yaml file received from the URL. \"\"\" from datetime import datetime import logging import os import sys from docopt import", "label": 0}, {"snippet_id": 41045, "code": " name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names):", "label": 0}, {"snippet_id": 93465, "code": " node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!", "label": 0}, {"snippet_id": 36067, "code": ".resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(),", "label": 0}, {"snippet_id": 21689, "code": "'red', 'green'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'", "label": 0}, {"snippet_id": 93590, "code": "']) if window: self.logger.debug(\"window '%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self", "label": 0}, {"snippet_id": 35783, "code": " return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist):", "label": 0}, {"snippet_id": 86581, "code": ": \"\"\"An abstract base class for zinc compilation tasks.\"\"\" _name='zinc' @staticmethod def _write_scalac_plugin_info(resources_dir, scalac_plugin_target): scalac_plugin_info_file=os.path.join(resources_dir", "label": 1}, {"snippet_id": 85264, "code": "._create_runtime_jardep) ] for spec_key, create_jardep_func in specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address):", "label": 0}, {"snippet_id": 92905, "code": "(binary_mode=False) as tmp_stdout,\\ temporary_file(binary_mode=False) as tmp_stderr: print(stdin_data, file=tmp_stdin) tmp_stdin.seek(0) with stdio_as(stdout_fd=tmp_stdout.fileno(), stderr_fd=tmp_stderr.fileno(", "label": 0}, {"snippet_id": 6404, "code": " six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer", "label": 0}, {"snippet_id": 4319, "code": "=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(", "label": 1}, {"snippet_id": 67692, "code": ".verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target.type.upper(", "label": 0}, {"snippet_id": 10260, "code": "): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len", "label": 0}, {"snippet_id": 27533, "code": ") self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data", "label": 0}, {"snippet_id": 21091, "code": " class Awaitable(object): @classmethod def wait_all(cls, *awaitables): timeout=3.0 messages=[] for _ in range(int(timeout * 10)): time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event", "label": 0}, {"snippet_id": 12389, "code": "][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]: comment_body.append( \" -There", "label": 0}, {"snippet_id": 5412, "code": "\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author", "label": 0}, {"snippet_id": 48848, "code": " if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or", "label": 0}, {"snippet_id": 90588, "code": "-minimum-version` is used. :param maximum_version: maximum jvm version to look for(eg, 1.7.9999). The stricter of this and `--jvm-distributions-maximum-version` is used. :param bool jdk: whether the found", "label": 0}, {"snippet_id": 57767, "code": " sortkey > 32300: return say_no('New sortkey is out of range[0, 32300].') except ValueError: return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True)", "label": 0}, {"snippet_id": 70934, "code": "=TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target)", "label": 0}, {"snippet_id": 26421, "code": "{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self", "label": 0}, {"snippet_id": 47786, "code": ".dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority", "label": 0}, {"snippet_id": 50392, "code": ".docstring rule.run_func=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo", "label": 0}, {"snippet_id": 86059, "code": " return target.has_sources('.java') def select_source(self, source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath(self.context.products", "label": 0}, {"snippet_id": 25337, "code": ".netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items", "label": 1}, {"snippet_id": 22004, "code": ".output_file=output_file self.tags=tags self.skip_tags=skip_tags self.one_line=one_line self.tree=tree self.ask_sudo_pass=ask_sudo_pass self.ask_su_pass=ask_su_pass self.sudo=sudo self.sudo_user=sudo_user self", "label": 0}, {"snippet_id": 70202, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper", "label": 0}, {"snippet_id": 51452, "code": " file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic", "label": 0}, {"snippet_id": 16937, "code": "=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout)", "label": 1}, {"snippet_id": 84332, "code": "'galaxy_datatypes_config_file', None) if not remote_datatypes_config: log.warn(NO_REMOTE_DATATYPES_CONFIG) remote_datatypes_config=os.path.join(remote_galaxy_home, 'datatypes_conf.xml') metadata_kwds['datatypes_config", "label": 0}, {"snippet_id": 30648, "code": " in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self", "label": 0}, {"snippet_id": 77069, "code": " self.proxylist=set() self.c=config self.threads=[] self.processes=[] self.th_sa='inproc://wm-wth.sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm-wpr.sock' self.pr_ba='ipc://wm-back.sock'", "label": 0}, {"snippet_id": 48607, "code": "(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards)", "label": 0}, {"snippet_id": 46439, "code": " name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self):", "label": 0}, {"snippet_id": 78854, "code": "): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None", "label": 0}, {"snippet_id": 3600, "code": " logger.debug(\"Found window pid: %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes", "label": 0}, {"snippet_id": 23257, "code": "=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name(self, sock, offset", "label": 0}, {"snippet_id": 21709, "code": "[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt.title('Classifier(Training set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors import", "label": 0}, {"snippet_id": 50759, "code": " import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging", "label": 1}, {"snippet_id": 73579, "code": ".DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)) if conversion_config.compressor==\"Blosc\"", "label": 0}, {"snippet_id": 25848, "code": "] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type", "label": 0}, {"snippet_id": 7002, "code": " type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags", "label": 0}, {"snippet_id": 35267, "code": " for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand", "label": 0}, {"snippet_id": 93542, "code": " % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and", "label": 0}, {"snippet_id": 49535, "code": ") targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 81765, "code": "(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames", "label": 0}, {"snippet_id": 77341, "code": "(count): if not self.running.is_set(): break try: w=wclass(*args, name='.'.join( (wname,('pr{0}' if type_ else 'th{0}').format(i))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self", "label": 0}, {"snippet_id": 95950, "code": "\"\"\" if conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants", "label": 0}, {"snippet_id": 17645, "code": " UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self):", "label": 0}, {"snippet_id": 77068, "code": "'newproxies.txt' self.proxylist=set() self.c=config self.threads=[] self.processes=[] self.th_sa='inproc://wm-wth.sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm-wpr.sock' self.pr_ba='ipc://wm", "label": 0}, {"snippet_id": 35775, "code": " return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist", "label": 0}, {"snippet_id": 86329, "code": " return_code: raise TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin, args in javac_plugin_map.items():", "label": 0}, {"snippet_id": 63162, "code": "\"status\"]) def __find_watched_job( self, job_id): found_job=None for async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job", "label": 0}, {"snippet_id": 74909, "code": ".benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input\" in runtime_config.benchmark: benchmark_data_input_temp=runtime_config.benchmark", "label": 0}, {"snippet_id": 42586, "code": " branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch", "label": 0}, {"snippet_id": 54344, "code": ") def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,.", "label": 0}, {"snippet_id": 91866, "code": ".subsystems.python_setup import PythonSetup from pants.backend.python.targets.python_distribution import PythonDistribution from pants.base.exceptions import IncompatiblePlatformsError from pants.binaries", "label": 0}, {"snippet_id": 6727, "code": " output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache:", "label": 0}, {"snippet_id": 56281, "code": " TestCaseRun, TestCaseRunStatus, TestRunTag from tcms.core.helpers.comments import add_comment from tcms.core.utils.validations import validate_bug_id def check_permission(request, ctype): perm='%s.change_%s", "label": 0}, {"snippet_id": 10995, "code": " Timeout as e: msg=\"Connect timed out for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except RequestException as e: msg=\"Could not get monitoring yaml from '%s', error: %s\" %(url, e) raise", "label": 0}, {"snippet_id": 80800, "code": "\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a in attempts", "label": 1}, {"snippet_id": 49081, "code": " class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None", "label": 0}, {"snippet_id": 23271, "code": ".inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name(self, sock, offset): return sock[offset:offset+16].split(b'\\0', 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using", "label": 0}, {"snippet_id": 65916, "code": "(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown", "label": 0}, {"snippet_id": 8176, "code": " in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1", "label": 0}, {"snippet_id": 66372, "code": " Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine", "label": 0}, {"snippet_id": 84839, "code": "'scala' @classmethod def _create_jardep(cls, name, version): return JarDependency(org='org.scala-lang', name=name, rev=scala_build_info[version].full_version) @classmethod def _create_runtime_jardep(cls", "label": 0}, {"snippet_id": 35384, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}", "label": 0}, {"snippet_id": 54290, "code": " @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule", "label": 0}, {"snippet_id": 72371, "code": " reloadproto(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for changes", "label": 0}, {"snippet_id": 47683, "code": ".append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s)", "label": 0}, {"snippet_id": 15826, "code": "( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except", "label": 0}, {"snippet_id": 56840, "code": ".obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter(object): \"\"\" Used for counting the number of times a tag is assigned to TestRun/TestCase", "label": 0}, {"snippet_id": 20631, "code": " self._handlers=[] for handler in handlers: if callable(handler): self._add_handler(handler) else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread( target=self._listen", "label": 0}, {"snippet_id": 94241, "code": " not self.config: self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self", "label": 0}, {"snippet_id": 48559, "code": " name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self", "label": 0}, {"snippet_id": 46240, "code": "() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path", "label": 0}, {"snippet_id": 15575, "code": " if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={}", "label": 0}, {"snippet_id": 18617, "code": "._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics=self._latest_file_parse_request", "label": 0}, {"snippet_id": 55335, "code": ", local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing", "label": 0}, {"snippet_id": 7771, "code": " spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires))", "label": 0}, {"snippet_id": 37152, "code": " dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch", "label": 0}, {"snippet_id": 26221, "code": "'Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass',", "label": 0}, {"snippet_id": 65118, "code": " print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self", "label": 0}, {"snippet_id": 47609, "code": "=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution", "label": 0}, {"snippet_id": 13656, "code": "(\"speech.wav\")\r return myText\r \r mouthThread=Thread(target=updateMouth)\r mouthThread.start()\r eyesThread=Thread(target=updateEyes)\r eyesThread.start() \r audio=AudioPlayer()\r \r if( consumerKey.find( 'TWITTER", "label": 0}, {"snippet_id": 68829, "code": " layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 85896, "code": " pants.base.exceptions import TaskError from pants.base.workunit import WorkUnit, WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize from pants.engine.isolated_process import ExecuteProcessRequest", "label": 0}, {"snippet_id": 2172, "code": ":wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len", "label": 0}, {"snippet_id": 45278, "code": ".path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for", "label": 0}, {"snippet_id": 58888, "code": " self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self.plan.pk, 'case'", "label": 0}, {"snippet_id": 70081, "code": " verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs)", "label": 0}, {"snippet_id": 67840, "code": "(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc >", "label": 0}, {"snippet_id": 91056, "code": " jdk_paths=self.get_options().paths or{} for name, paths in sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to \"{}\"; combining", "label": 0}, {"snippet_id": 16669, "code": ".PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self):", "label": 0}, {"snippet_id": 8974, "code": " in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. ", "label": 0}, {"snippet_id": 36086, "code": "), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self", "label": 0}, {"snippet_id": 84170, "code": ") return remote_metadata @staticmethod def __remote_work_dir_copy( lwr_client): return LwrJobRunner.__remote_metadata( lwr_client) @staticmethod def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting", "label": 0}, {"snippet_id": 28186, "code": "'Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 32297, "code": " IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 20829, "code": "(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command, seq=req.command, req.seq except AttributeError: command, seq=req['command'], req['seq'] result={'msg': None} def", "label": 0}, {"snippet_id": 19932, "code": ".closed: raise RuntimeError('debug client closed') if adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError('already using managed adapter') if adapter is None: raise", "label": 0}, {"snippet_id": 24110, "code": " documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA", "label": 1}, {"snippet_id": 10264, "code": " keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1]", "label": 0}, {"snippet_id": 16994, "code": "( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout)", "label": 0}, {"snippet_id": 63406, "code": " task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !", "label": 0}, {"snippet_id": 17170, "code": ".command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification", "label": 0}, {"snippet_id": 47166, "code": ")) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input", "label": 0}, {"snippet_id": 25965, "code": "._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data", "label": 0}, {"snippet_id": 60840, "code": "\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ' +self.author +'\\n' def __enter__", "label": 0}, {"snippet_id": 14699, "code": ".PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer", "label": 0}, {"snippet_id": 49134, "code": " self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals", "label": 0}, {"snippet_id": 36269, "code": "\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self", "label": 0}, {"snippet_id": 69990, "code": " def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs(conf_dir_path, 0755) except OSError, ex: print \"OSError", "label": 1}, {"snippet_id": 1247, "code": ") return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate", "label": 0}, {"snippet_id": 57815, "code": "] if len(case_pks)==0: break queryset_filter(plan=plan, case__in=case_pks).update(**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list", "label": 0}, {"snippet_id": 35981, "code": ".exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter", "label": 0}, {"snippet_id": 48593, "code": ": raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else", "label": 0}, {"snippet_id": 66751, "code": " print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError", "label": 1}, {"snippet_id": 9078, "code": "=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms", "label": 0}, {"snippet_id": 27659, "code": ": self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp", "label": 0}, {"snippet_id": 66652, "code": " self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen", "label": 0}, {"snippet_id": 58166, "code": ". \"\"\" data=request.GET.copy() target=data.get('target', None) p_pks=data.get('p_ids', None) sep=data.get('sep', None) if target and p_pks and sep: p_pks=[k for k in p_pks.split(sep) if k] res=get_prod_related_objs", "label": 0}, {"snippet_id": 41223, "code": " pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f:", "label": 0}, {"snippet_id": 87333, "code": "\"\" hasher=sha1() for cp_entry in[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest", "label": 1}, {"snippet_id": 15281, "code": " self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False", "label": 0}, {"snippet_id": 9683, "code": " _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw", "label": 0}, {"snippet_id": 52524, "code": ".rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f", "label": 1}, {"snippet_id": 13854, "code": " retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from ycm.server", "label": 0}, {"snippet_id": 11836, "code": " match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get('X-Hub-Signature') if header_signature is", "label": 0}, {"snippet_id": 95283, "code": " create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files", "label": 0}, {"snippet_id": 95585, "code": "'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, file_path_local)) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{", "label": 0}, {"snippet_id": 3639, "code": " run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\")", "label": 0}, {"snippet_id": 78138, "code": " drop_users(): send_passthrough([b'WipeSkel', b'WipeSkel', b'drop-user']) def log_spawn_name(): send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name']) if c.no_shell: while True: time.sleep", "label": 1}, {"snippet_id": 47674, "code": ".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 29309, "code": " files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self", "label": 0}, {"snippet_id": 11991, "code": " headers=headers, auth=auth) if r.status_code==200: try: new_config=yaml.load(r.text) config=update_dict(config, new_config) except yaml.YAMLError: pass arguments=[] confs=config[\"pycodestyle\"] for key,", "label": 0}, {"snippet_id": 74726, "code": "\"] if chunk_width_str==\"default\": self.chunk_width=None elif isint(chunk_width_str): self.chunk_width=int(chunk_width_str) else: raise TypeError(\"Invalid value provided for chunk_width in configuration", "label": 0}, {"snippet_id": 75777, "code": " term_handler) def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method, data))) raise Resume() self.wz.set_sig_handler(b'WZWorker', b'resume', term_handler", "label": 1}, {"snippet_id": 60677, "code": " elif self._observe.name=='X': ex, var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self", "label": 0}, {"snippet_id": 72005, "code": " pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc.coremods import control, permissions @utils.add_cmd def disconnect(irc, source, args): \"\"\"<network> Disconnects the", "label": 0}, {"snippet_id": 93499, "code": "): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile", "label": 0}, {"snippet_id": 9810, "code": ")) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list", "label": 0}, {"snippet_id": 1756, "code": "': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common", "label": 0}, {"snippet_id": 16392, "code": ": returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash", "label": 0}, {"snippet_id": 76730, "code": ".add_argument('--rp-timeout', '-T', type=int, default=10, help='Default rp timeout in seconds') parser.add_argument('--conlimit', type=int, default=3, help='http_request conlimit') parser.add_argument(", "label": 0}, {"snippet_id": 79392, "code": ".get(url) \t\tif self.shouldLog: \t\t\tif r.status_code >=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity ", "label": 0}, {"snippet_id": 59855, "code": " ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([", "label": 0}, {"snippet_id": 64342, "code": " self): return self.working_directory() def sep( self): return self._sep def version_path( self): return self._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites", "label": 0}, {"snippet_id": 90855, "code": " operating system in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely locations on the file system such as `/usr/lib/jvm` on Linux machines. :API: public \"\"\" class Error(Distribution", "label": 0}, {"snippet_id": 48289, "code": "\"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self", "label": 0}, {"snippet_id": 62025, "code": " qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator).", "label": 0}, {"snippet_id": 59685, "code": "() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool", "label": 0}, {"snippet_id": 75537, "code": " reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface", "label": 0}, {"snippet_id": 81795, "code": " malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following", "label": 0}, {"snippet_id": 68792, "code": ", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\"", "label": 0}, {"snippet_id": 11805, "code": " http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping): base[key]=update_dict(base.get(key,", "label": 1}, {"snippet_id": 36252, "code": " None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self", "label": 0}, {"snippet_id": 83533, "code": "=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not", "label": 1}, {"snippet_id": 47317, "code": " prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason", "label": 0}, {"snippet_id": 37148, "code": ")] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output", "label": 0}, {"snippet_id": 5277, "code": " :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms", "label": 0}, {"snippet_id": 60326, "code": " super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine", "label": 1}, {"snippet_id": 37662, "code": ", str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise", "label": 0}, {"snippet_id": 71343, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout", "label": 0}, {"snippet_id": 12373, "code": "[\"message\"][\"updated\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for updating the PR.\\n\\n\" else: comment_header=config[\"message\"][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=", "label": 0}, {"snippet_id": 30469, "code": "\"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or", "label": 0}, {"snippet_id": 53720, "code": ".dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item", "label": 0}, {"snippet_id": 34016, "code": " rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1])", "label": 0}, {"snippet_id": 6250, "code": " \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file=tempfile", "label": 1}, {"snippet_id": 10053, "code": "{} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes", "label": 0}, {"snippet_id": 34250, "code": ", benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate", "label": 0}, {"snippet_id": 37657, "code": ": self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name", "label": 0}, {"snippet_id": 53559, "code": " are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True", "label": 0}, {"snippet_id": 43822, "code": ") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already", "label": 0}, {"snippet_id": 57807, "code": " sortkey} while 1: sub_cases=update_targets[offset:offset +step_length] case_pks=[case.pk for case in sub_cases] if len(case_pks)==0: break queryset_filter(plan=plan, case__in=case_pks).update(**data) offset ", "label": 0}, {"snippet_id": 58022, "code": "(data, '') def update_bugs_to_caseruns(request): \"\"\" Add one or more bugs to or remove that from\\n one or more caserun at a time. \"\"\" data, error=clean_bug_form(request) if error: return say_no(error) runs", "label": 0}, {"snippet_id": 48772, "code": "}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self", "label": 0}, {"snippet_id": 46884, "code": " name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(),", "label": 0}, {"snippet_id": 82828, "code": ": \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)", "label": 0}, {"snippet_id": 7838, "code": "[fieldcode]=', '.join(keywords) return output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var", "label": 0}, {"snippet_id": 39529, "code": "\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if", "label": 0}, {"snippet_id": 63326, "code": ", job_wrapper, remote_job_config) prepare_kwds[ 'compute_environment']=compute_environment job_wrapper.prepare( **prepare_kwds) self.__prepare_input_files_locally(job_wrapper) remote_metadata=LwrJobRunner", "label": 0}, {"snippet_id": 4107, "code": " standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"", "label": 0}, {"snippet_id": 27523, "code": ".module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=", "label": 0}, {"snippet_id": 74563, "code": "(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\",", "label": 0}, {"snippet_id": 32564, "code": " ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile,", "label": 0}, {"snippet_id": 59269, "code": " Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random", "label": 0}, {"snippet_id": 64680, "code": ".FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1:", "label": 0}, {"snippet_id": 5779, "code": " return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator", "label": 0}, {"snippet_id": 28929, "code": "'GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle", "label": 0}, {"snippet_id": 48406, "code": "._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params", "label": 0}, {"snippet_id": 22715, "code": " add{ all-partitions{ role admin}} shell bash\" %(username) retcode, out=shellutil.run_get_output(cmd, log_cmd=True, chk_err=True) if retcode !=0: raise OSUtilError( \"Failed to create user account:{0}, retcode", "label": 0}, {"snippet_id": 2605, "code": ".get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '", "label": 0}, {"snippet_id": 81950, "code": ". Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known", "label": 0}, {"snippet_id": 92380, "code": " hermetic_environment_as(**dict(AAA='333')): output=subprocess.check_output('env', shell=True).decode('utf-8') self.assertNotIn('USER=', output) self.assertIn('AAA', os.environ) self.assertEqual(os.environ['AAA'], '333", "label": 1}, {"snippet_id": 49660, "code": ".lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If", "label": 0}, {"snippet_id": 81927, "code": ". Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote", "label": 0}, {"snippet_id": 45812, "code": "(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards", "label": 0}, {"snippet_id": 89074, "code": ".get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter(predicate,", "label": 0}, {"snippet_id": 57396, "code": " %s.' %( field, getattr(t, field), request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return HttpResponse(json.dumps({'rc':", "label": 0}, {"snippet_id": 36486, "code": ": raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output", "label": 0}, {"snippet_id": 87662, "code": "(PathGlobsAndRoot( PathGlobs(scala_path), get_buildroot(), ),))[0] ) merged_input_digest=self.context._scheduler.merge_directories( tuple(s.directory_digest for s in(snapshots)) +directory_digests ) argv=tuple([", "label": 0}, {"snippet_id": 16338, "code": "), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout", "label": 0}, {"snippet_id": 19639, "code": ".format(prog), ) parser.add_argument('--nodebug', action='store_true') host=parser.add_mutually_exclusive_group() host.add_argument('--host') host.add_argument('--server-host') parser.add_argument('--port'", "label": 0}, {"snippet_id": 94939, "code": " subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates", "label": 0}, {"snippet_id": 66900, "code": " command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action", "label": 1}, {"snippet_id": 92264, "code": " test_empty_environment(self): with environment_as(): pass def test_override_single_variable(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): subprocess.Popen([sys.executable", "label": 0}, {"snippet_id": 39070, "code": ".persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n", "label": 0}, {"snippet_id": 80129, "code": " automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image", "label": 0}, {"snippet_id": 92645, "code": " exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False) as path: self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context", "label": 0}, {"snippet_id": 78619, "code": " import urllib2 import json import ijson from dbnav.writer import Writer from dbnav import logger as log from dbnav.jsonable import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec': 'executer', 'dbexport'", "label": 0}, {"snippet_id": 64519, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class", "label": 0}, {"snippet_id": 32569, "code": " statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self", "label": 0}, {"snippet_id": 95630, "code": " file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir", "label": 0}, {"snippet_id": 40930, "code": "\"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False", "label": 0}, {"snippet_id": 91473, "code": " print_function, unicode_literals import os import sys from builtins import str from future.utils import text_type from pants.backend.python.rules.inject_init import InjectedInitDigest from pants.backend", "label": 0}, {"snippet_id": 35135, "code": "(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value", "label": 0}, {"snippet_id": 71450, "code": ".Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs", "label": 0}, {"snippet_id": 39935, "code": " itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def", "label": 1}, {"snippet_id": 84698, "code": ".merge_directories(tuple(s.directory_digest for s in input_snapshots +( cloc_snapshot, list_file_snapshot, ))) cmd=( '/usr/bin/perl', cloc_path, '--skip-uniqueness', '--ignored=ignored', '--list-file=input_files_list", "label": 0}, {"snippet_id": 69952, "code": "* from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name", "label": 0}, {"snippet_id": 20252, "code": ".linesep +self._run_server_ex raise Exception(message) self._launch( argv, script=script, wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script(self,", "label": 0}, {"snippet_id": 9011, "code": " formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader", "label": 0}, {"snippet_id": 66566, "code": "(nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print", "label": 1}, {"snippet_id": 63685, "code": ". \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return", "label": 0}, {"snippet_id": 50969, "code": "(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError", "label": 1}, {"snippet_id": 36723, "code": "(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule", "label": 0}, {"snippet_id": 88100, "code": ".format(list(unresolved_plugins))) @classmethod @memoized_method def _maybe_get_plugin_name(cls, classpath_element): \"\"\"If classpath_element is a scalac plugin, returns its name. Returns None otherwise.", "label": 0}, {"snippet_id": 81350, "code": " moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept:", "label": 0}, {"snippet_id": 69285, "code": "\"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" %", "label": 1}, {"snippet_id": 77254, "code": ".proxylist.add(proxypair) for spawn in create_spawn(proxypair[0], proxypair[1], self.pc, self.get_userqueue): self.log.info('Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as", "label": 0}, {"snippet_id": 48170, "code": " for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names", "label": 0}, {"snippet_id": 47006, "code": " the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return", "label": 0}, {"snippet_id": 36989, "code": ".wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow", "label": 0}, {"snippet_id": 69679, "code": "%s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"", "label": 0}, {"snippet_id": 14318, "code": "( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self", "label": 0}, {"snippet_id": 7076, "code": " output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories=", "label": 0}, {"snippet_id": 89629, "code": " a dict containing the system properties of this java distribution.\"\"\" return dict(self._get_system_properties(self.java)) @property def version(self): \"\"\"Returns the distribution version. Raises Distribution", "label": 0}, {"snippet_id": 50163, "code": "(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir", "label": 0}, {"snippet_id": 56971, "code": " get_value_by_type('string', 'str') ('string', None) 5. get_value_by_type('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type('string',", "label": 0}, {"snippet_id": 84733, "code": ") files_content_tuple=self.context._scheduler.product_request( FilesContent, [exec_result.output_directory_digest] )[0].dependencies files_content={fc.path: fc.content.decode('utf-8') for fc in files_content_tuple", "label": 1}, {"snippet_id": 40640, "code": " mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule", "label": 0}, {"snippet_id": 25357, "code": ".get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name", "label": 1}, {"snippet_id": 19752, "code": "='script' else: args.name=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs): if nodebug: run_main(addr, name, kind, *extra, **kwargs) else: debug_main(addr", "label": 0}, {"snippet_id": 45329, "code": "\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]), path)", "label": 0}, {"snippet_id": 87928, "code": ", scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin classpath entries. The first entry in each list is the classpath entry containing the plugin metadata. The rest are the", "label": 0}, {"snippet_id": 60858, "code": "+self.author +'\\n' def __enter__(self): if Device._current_context is None: Device._current_context=self self.reset() else: raise DeviceError('Only one device can be active at a time.') return self def", "label": 0}, {"snippet_id": 31276, "code": " self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json", "label": 0}, {"snippet_id": 87940, "code": " first entry in each list is the classpath entry containing the plugin metadata. The rest are the internal transitive deps of the plugin. This allows us to have in-repo plugins with dependencies(unlike", "label": 0}, {"snippet_id": 48469, "code": "._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name", "label": 0}, {"snippet_id": 72253, "code": " service %r.' % args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self, text,", "label": 0}, {"snippet_id": 74993, "code": " default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and not overwrite", "label": 0}, {"snippet_id": 15160, "code": ".completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client", "label": 0}, {"snippet_id": 33313, "code": "=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error", "label": 0}, {"snippet_id": 79946, "code": " separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs", "label": 0}, {"snippet_id": 34325, "code": " ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo", "label": 0}, {"snippet_id": 60686, "code": ".name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self._observe.params) elif self._observe.name=='Displacement'", "label": 0}, {"snippet_id": 91424, "code": "'pytest', action=PytestRun).install('test') task(name='py', action=PythonRepl).install('repl') task(name='setup-py', action=SetupPy).install() task(name='py', action=PythonBinaryCreate).install('binary", "label": 0}, {"snippet_id": 29848, "code": " matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value", "label": 0}, {"snippet_id": 89415, "code": ". In particular provides access to the distribution's binaries; ie: java while ensuring basic constraints are met. For example a minimum version can be specified if you know need to compile source code", "label": 0}, {"snippet_id": 8326, "code": "'Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that", "label": 1}, {"snippet_id": 80117, "code": "(\"-m\",\"--manual-form-detection\",action=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple", "label": 0}, {"snippet_id": 14928, "code": "=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync( data, handler, 'POST', timeout) @staticmethod def _TalkToHandlerAsync( data, handler, method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest(", "label": 0}, {"snippet_id": 85295, "code": " build_graph.get_target(target_address).is_synthetic: raise build_graph.ManualSyntheticTargetError(target_address) @property def injectables_spec_mapping(self): maybe_suffix='' if self.version=='custom'", "label": 0}, {"snippet_id": 19620, "code": ".append(arg) gottarget=True else: supported.append(arg) break return supported, pydevd, script def _parse_args(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ) parser", "label": 0}, {"snippet_id": 47571, "code": ".rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"", "label": 0}, {"snippet_id": 4100, "code": " or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the", "label": 0}, {"snippet_id": 93704, "code": "%(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component", "label": 0}, {"snippet_id": 58755, "code": ", self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post(self.update_url,{ 'content_type': 'testruns.testcaserun', 'object_pk': self.case_run_1", "label": 0}, {"snippet_id": 80250, "code": "=args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args", "label": 0}, {"snippet_id": 39803, "code": " Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is", "label": 0}, {"snippet_id": 61165, "code": " fr3(a, b, c): r\"\"\"Arbitrary one-qubit rotation using three Euler angles. Args: a,b,c(float): rotation angles Returns: array: unitary 2x2 rotation matrix rz(c) @ ry(b) @ rz(a) \"\"\" return frz(c) @(fry(b", "label": 0}, {"snippet_id": 49802, "code": "\" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input", "label": 0}, {"snippet_id": 20294, "code": " argv=[ filename, ] +list(argv) if kwargs.pop('nodebug', False): argv.insert(0, '--nodebug') self._launch(argv, **kwargs) return self._adapter, self._session def launch_module(self, module, *argv, **kwargs", "label": 0}, {"snippet_id": 28846, "code": " data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state", "label": 0}, {"snippet_id": 65085, "code": ".get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s ", "label": 0}, {"snippet_id": 78441, "code": ".error(e) self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.log.warn(e) self.w.sleep(self.errortimeout) def get_targets(self): found_count=0 for user, forum in self.forums: targets=[", "label": 0}, {"snippet_id": 17535, "code": ".CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data=", "label": 0}, {"snippet_id": 6034, "code": "[1] except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find", "label": 1}, {"snippet_id": 71619, "code": ".get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client", "label": 0}, {"snippet_id": 40295, "code": "==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3", "label": 0}, {"snippet_id": 82731, "code": "\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy", "label": 0}, {"snippet_id": 47744, "code": ".exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of", "label": 0}, {"snippet_id": 29845, "code": " annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained", "label": 0}, {"snippet_id": 40468, "code": " f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\")", "label": 0}, {"snippet_id": 12268, "code": ".search(\"^file_to_check.py:\\d+:\\d+:\\s[WE]\\d+\\s.*\", error): data[\"results\"][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error in list(data[", "label": 0}, {"snippet_id": 6745, "code": ") if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1", "label": 0}, {"snippet_id": 59254, "code": "(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a", "label": 0}, {"snippet_id": 29620, "code": "(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:", "label": 0}, {"snippet_id": 51916, "code": ".set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1][0]): start", "label": 0}, {"snippet_id": 21374, "code": " subreddit seen_file=sr_dir +\"/seen\" seen_links=[] unseen_file=sr_dir +\"/unseen\" unseen_links=[] print(\"Reddytt: Checking for reddytt working directory(%s).\" % work_dir) if not os.path.isdir(work_dir): print", "label": 0}, {"snippet_id": 27171, "code": "'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', ", "label": 0}, {"snippet_id": 16897, "code": " BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data,", "label": 0}, {"snippet_id": 38348, "code": ": None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules", "label": 0}, {"snippet_id": 83013, "code": " obtained('%s','%s','%s')\\033[m\",foundEntryPoint[\"suffix\"],foundEntryPoint[\"mime\"],foundEntryPoint[\"templateName\"]) \t\t\t\t\tnbOfEntryPointsFound +=1 \t\t\t\t\tentryPoints.append(foundEntryPoint) \t\t\t\t\tif not args", "label": 0}, {"snippet_id": 303, "code": "'POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon", "label": 0}, {"snippet_id": 36305, "code": " yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self", "label": 1}, {"snippet_id": 75720, "code": ".setsockopt(zmq.IPV6, True) s.connect(self.sig_addr) s.setsockopt(zmq.SUBSCRIBE, b'GLOBAL') s.setsockopt(zmq.SUBSCRIBE, b'WZWorker') s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8')) self.sig_sock", "label": 0}, {"snippet_id": 57966, "code": "('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str", "label": 0}, {"snippet_id": 21425, "code": ", 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working directory found, but no subreddit directory. Creating %s, and files.\" % sr_dir) os.mkdir(sr_dir) os.system", "label": 0}, {"snippet_id": 1514, "code": ":schema}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False", "label": 0}, {"snippet_id": 59149, "code": "...])\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions", "label": 0}, {"snippet_id": 35533, "code": " def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist", "label": 0}, {"snippet_id": 79810, "code": "(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates,", "label": 0}, {"snippet_id": 56283, "code": ", TestCaseRunStatus, TestRunTag from tcms.core.helpers.comments import add_comment from tcms.core.utils.validations import validate_bug_id def check_permission(request, ctype): perm='%s.change_%s' % tuple", "label": 0}, {"snippet_id": 3626, "code": ") if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process terminated but check was successful", "label": 1}, {"snippet_id": 17899, "code": " timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync", "label": 0}, {"snippet_id": 55285, "code": " items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes", "label": 0}, {"snippet_id": 76819, "code": " closed topics') parser.add_argument('--die-on-neterror', action='store_true', default=False, help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net.RequestPerformer(", "label": 0}, {"snippet_id": 56050, "code": " workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir", "label": 0}, {"snippet_id": 51546, "code": " to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif", "label": 0}, {"snippet_id": 15814, "code": "[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server", "label": 0}, {"snippet_id": 80906, "code": "\t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(\"Found", "label": 0}, {"snippet_id": 47173, "code": " combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in", "label": 0}, {"snippet_id": 1468, "code": "\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address", "label": 0}, {"snippet_id": 23795, "code": "(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern.cam.da.default_timeout={0}'.format(timeout)) if ret: raise", "label": 0}, {"snippet_id": 24658, "code": "=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 63896, "code": " state, adding to the LWR queue\" %( job.get_id())) job_state.old_state=True job_state.running=state==model.Job.states.RUNNING self.monitor_queue.put( job_state) def shutdown( self): super( LwrJobRunner", "label": 0}, {"snippet_id": 95680, "code": "*.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir=str(temp_dir", "label": 0}, {"snippet_id": 6377, "code": " between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are", "label": 0}, {"snippet_id": 53884, "code": " name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name", "label": 0}, {"snippet_id": 28494, "code": " \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update", "label": 0}, {"snippet_id": 43818, "code": " raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules", "label": 0}, {"snippet_id": 41358, "code": "=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator", "label": 0}, {"snippet_id": 82760, "code": "\tif args.formAction==\"\": \t\tlogger.warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm", "label": 0}, {"snippet_id": 45589, "code": " \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException:", "label": 0}, {"snippet_id": 57417, "code": ": 0, 'response': 'ok'})) class ModelUpdateActions(object): \"\"\"Abstract class defining interfaces to update a model properties\"\"\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each", "label": 0}, {"snippet_id": 92788, "code": " open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=True) as zf: self.assertTrue(zf._allowZip64) def test_open_zipFalse(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'", "label": 0}, {"snippet_id": 36254, "code": " AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule) @property", "label": 0}, {"snippet_id": 51092, "code": " self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance", "label": 0}, {"snippet_id": 85859, "code": " from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from", "label": 0}, {"snippet_id": 46763, "code": "=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m.group(\"value\")", "label": 0}, {"snippet_id": 31290, "code": ", \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is", "label": 0}, {"snippet_id": 74875, "code": " vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\" Creates an object representation of the Benchmark module's configuration data. :param runtime_config: runtime_config data to extract", "label": 0}, {"snippet_id": 30622, "code": "=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow", "label": 0}, {"snippet_id": 87533, "code": " if option_set=='fatal_warnings': enabled_args=self.get_options().fatal_warnings_enabled_args zinc_args.extend(enabled_args) for option_set, disabled_args in self.get_options().compiler_option_sets_disabled_args", "label": 0}, {"snippet_id": 24984, "code": "._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif", "label": 0}, {"snippet_id": 2331, "code": " import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz", "label": 0}, {"snippet_id": 292, "code": " def handle_config(request): \"\"\" List all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name", "label": 0}, {"snippet_id": 55784, "code": "**ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo", "label": 0}, {"snippet_id": 30341, "code": " end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key)", "label": 0}, {"snippet_id": 35396, "code": " with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the", "label": 0}, {"snippet_id": 54679, "code": "(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if", "label": 0}, {"snippet_id": 10009, "code": ".items(): matches_str.append(skw.output(spires)) if matches_str: out[keyword]=matches_str else: out[keyword]=0 return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output", "label": 0}, {"snippet_id": 78440, "code": ".log.error(e) self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.log.warn(e) self.w.sleep(self.errortimeout) def get_targets(self): found_count=0 for user, forum in self.forums: targets", "label": 0}, {"snippet_id": 1868, "code": "=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter", "label": 0}, {"snippet_id": 86203, "code": " in a for a in settings.args): logger.debug('Substituting \"$JAVA_HOME\" with \"{}\" in jvm-platform args.' .format(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings", "label": 0}, {"snippet_id": 8420, "code": " is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line", "label": 1}, {"snippet_id": 28694, "code": " data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\"", "label": 0}, {"snippet_id": 95092, "code": "\"[Setup] Setting up benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments", "label": 1}, {"snippet_id": 46342, "code": ": \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr", "label": 0}, {"snippet_id": 42064, "code": "(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name,", "label": 0}, {"snippet_id": 25596, "code": " self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full", "label": 0}, {"snippet_id": 44117, "code": ".has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update", "label": 0}, {"snippet_id": 86560, "code": " _SCALAC_PLUGIN_INFO_FILE='scalac-plugin.xml' _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger", "label": 0}, {"snippet_id": 74851, "code": ") benchmark_data_input_types=[\"vcf\", \"zarr\"] class BenchmarkConfigurationRepresentation: \"\"\" Utility class for object representation of the benchmark module's configuration. \"\"\" benchmark_number_runs=5", "label": 0}, {"snippet_id": 46251, "code": " given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname", "label": 0}, {"snippet_id": 25057, "code": " __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the", "label": 0}, {"snippet_id": 83843, "code": "\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return", "label": 0}, {"snippet_id": 68622, "code": " jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state", "label": 0}, {"snippet_id": 30602, "code": "=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards", "label": 0}, {"snippet_id": 37034, "code": "=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output)", "label": 0}, {"snippet_id": 31011, "code": "\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested", "label": 0}, {"snippet_id": 60838, "code": " __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ' +self.author +", "label": 0}, {"snippet_id": 18366, "code": "]: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed(", "label": 0}, {"snippet_id": 20325, "code": " RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ '-m', module, ] +list(argv) if kwargs.pop('nodebug'", "label": 0}, {"snippet_id": 49476, "code": "._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule,", "label": 0}, {"snippet_id": 48038, "code": "._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\"", "label": 0}, {"snippet_id": 39633, "code": " *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo", "label": 0}, {"snippet_id": 29110, "code": " import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f", "label": 1}, {"snippet_id": 94819, "code": "=ControlCenter(args.config) cc.init() start_gui(cc) elif args.cmd=='validate': logger.debug(\"Launching validation mode\") cc=ControlCenter(args.config) if args.visual: cc.set_dependencies(False) cc.draw_graph()", "label": 0}, {"snippet_id": 83470, "code": " remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters: compute_environment=LwrComputeEnvironment( client", "label": 0}, {"snippet_id": 52666, "code": " if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or", "label": 0}, {"snippet_id": 96023, "code": "(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)", "label": 0}, {"snippet_id": 25795, "code": " data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self", "label": 0}, {"snippet_id": 45230, "code": "._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile)", "label": 0}, {"snippet_id": 26436, "code": "._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)[", "label": 0}, {"snippet_id": 18357, "code": "-stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest", "label": 0}, {"snippet_id": 22168, "code": ": templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template.render( data) return", "label": 0}, {"snippet_id": 5074, "code": ") for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw)", "label": 0}, {"snippet_id": 84445, "code": "._dataset_path( local_output_path, remote_path)) return results def input_paths( self): local_input_paths=self._wrapper_input_paths results=[] for local_input_path in local_input_paths: wrapper_path=str(", "label": 0}, {"snippet_id": 42722, "code": " set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output", "label": 0}, {"snippet_id": 41208, "code": ") class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile", "label": 0}, {"snippet_id": 40537, "code": " value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString", "label": 0}, {"snippet_id": 27450, "code": " station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in", "label": 0}, {"snippet_id": 86062, "code": " select_source(self, source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath(self.context.products) def write_extra_resources(self, compile_context", "label": 0}, {"snippet_id": 15684, "code": " vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug", "label": 0}, {"snippet_id": 23835, "code": "=0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We will sleep and retry", "label": 0}, {"snippet_id": 40823, "code": " values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard", "label": 0}, {"snippet_id": 23948, "code": " 3: return None g0=\"00000000\" if port_id > 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=\"000\" +ustr", "label": 0}, {"snippet_id": 63937, "code": " job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path()", "label": 0}, {"snippet_id": 18000, "code": "( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData", "label": 0}, {"snippet_id": 9991, "code": " author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items():", "label": 0}, {"snippet_id": 26382, "code": "(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo", "label": 0}, {"snippet_id": 13461, "code": " \r \r \r consumerKey='INSERT YOUR CONSUMER KEY HERE FROM TWITTER'\r consumerSecret='INSERT YOUR CONSUMER SECRET HERE FROM TWITTER'\r accessTokenKey='INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret", "label": 0}, {"snippet_id": 68355, "code": " status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[", "label": 0}, {"snippet_id": 13574, "code": "( MOUTH_CLOSE, 0)\r \r def updateEyes():\r while isRunning:\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE", "label": 0}, {"snippet_id": 81199, "code": " regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing", "label": 0}, {"snippet_id": 33683, "code": ", local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing", "label": 0}, {"snippet_id": 78859, "code": ") \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity", "label": 0}, {"snippet_id": 13911, "code": " timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync", "label": 0}, {"snippet_id": 4255, "code": "): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename)", "label": 0}, {"snippet_id": 63612, "code": "*finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server", "label": 0}, {"snippet_id": 76838, "code": ".RequestPerformer() noproxy_rp.proxy='' noproxy_rp.timeout=c.noproxy_timeout noproxy_rp.timeout=c.rp_timeout d=DataLoader(noproxy_rp, c.only_cache) c.router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random", "label": 0}, {"snippet_id": 77627, "code": "): fname=self.targetsfile if not os.path.isfile(fname): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list was loaded') targets.update(data", "label": 0}, {"snippet_id": 85074, "code": "'2.11') register_scala_compiler_tool('2.12') register_scala_repl_tool('2.12') register_style_tool('2.12') def register_custom_tool(key): dummy_jardep=JarDependency('missing spec', ' //:{}'.format(key))", "label": 0}, {"snippet_id": 59246, "code": "': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool):", "label": 0}, {"snippet_id": 5780, "code": " def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator) return", "label": 0}, {"snippet_id": 10445, "code": " return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2", "label": 0}, {"snippet_id": 57285, "code": " field), request.user ) ) field='assignee' try: assignee=t.assginee if assignee !=request.user: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), request", "label": 0}, {"snippet_id": 972, "code": "'endpoint': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers", "label": 0}, {"snippet_id": 75447, "code": ".get_key(reqid) def get_reqids(self, iden): return self.iden_reqid_map.get_values(iden) def make_reqid(self): while True: reqid=random.randint(1,(2**64)-1) if not reqid in self.response_handlers: return reqid", "label": 1}, {"snippet_id": 78037, "code": "(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not in forums: forums[domain]=set() if len(forum) > 0: get_forum_id(forum) logger.info('Appending %s:%s to forums", "label": 0}, {"snippet_id": 66698, "code": " msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e", "label": 0}, {"snippet_id": 69492, "code": " cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert", "label": 0}, {"snippet_id": 73585, "code": " width:{}\".format(chunk_width)) if conversion_config.compressor==\"Blosc\": compressor=Blosc(cname=conversion_config.blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle", "label": 0}, {"snippet_id": 27080, "code": ".keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None", "label": 1}, {"snippet_id": 72304, "code": ".name, text, placeholder_self.name) if 'source' in kwargs: del kwargs['source'] irc.reply(text, source=irc.pseudoclient.uid, **kwargs) old_reply=remoteirc.reply with remoteirc.reply_lock: try: log.debug", "label": 1}, {"snippet_id": 12671, "code": "={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/{}/issues/{}/comments\" query=query.format(data", "label": 0}, {"snippet_id": 62231, "code": ".execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"", "label": 1}, {"snippet_id": 28396, "code": " module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): ", "label": 0}, {"snippet_id": 60143, "code": " module contains the device class and context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import", "label": 0}, {"snippet_id": 56493, "code": "'format')) return User.objects.filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in", "label": 1}, {"snippet_id": 23753, "code": "(output)/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '{print", "label": 0}, {"snippet_id": 40190, "code": " else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False", "label": 0}, {"snippet_id": 17482, "code": "._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive", "label": 0}, {"snippet_id": 47742, "code": " from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name ", "label": 0}, {"snippet_id": 49996, "code": "=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources)", "label": 0}, {"snippet_id": 26668, "code": "._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640", "label": 0}, {"snippet_id": 5957, "code": "\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener", "label": 1}, {"snippet_id": 92398, "code": "(os.environ['AAA'], '333') self.assertIn('USER', os.environ) self.assertNotIn('AAA', os.environ) def test_hermetic_environment_unicode(self): UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output", "label": 1}, {"snippet_id": 14913, "code": " handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 4285, "code": "(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry", "label": 1}, {"snippet_id": 53611, "code": "\"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be", "label": 0}, {"snippet_id": 83407, "code": ") job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure", "label": 0}, {"snippet_id": 80060, "code": ",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent", "label": 0}, {"snippet_id": 12246, "code": ", shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"extra_results\"][filename]=stdout.decode(r.encoding).splitlines() data[\"results\"][filename]=[] for error in list(data[\"extra_results", "label": 0}, {"snippet_id": 37967, "code": ": for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile,", "label": 0}, {"snippet_id": 73597, "code": "=conversion_config.blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor type specified.\"", "label": 0}, {"snippet_id": 1392, "code": "'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps)", "label": 0}, {"snippet_id": 29554, "code": " _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last", "label": 0}, {"snippet_id": 38576, "code": "=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes", "label": 0}, {"snippet_id": 44170, "code": ", forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete", "label": 0}, {"snippet_id": 19088, "code": " target is not None: validate_object(target, schema=schema, **kwargs) def validate_api_request(schema, raw_request): request=normalize_request(raw_request) with ErrorDict(): validate_request(request=request", "label": 0}, {"snippet_id": 23812, "code": ")) if ret: raise OSUtilError(\"Failed set SCSI disks timeout:{0}\".format(output)) self._scsi_disks_timeout_set=True def check_pid_alive(self, pid): return shellutil.run('ps -p{0}'.format(pid), chk_err=False", "label": 0}, {"snippet_id": 32256, "code": ": try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings", "label": 0}, {"snippet_id": 69846, "code": " get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR,", "label": 0}, {"snippet_id": 74392, "code": "(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class", "label": 0}, {"snippet_id": 58947, "code": ": Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) for pk in(self.case_1.pk, self.case_3.pk): self.assertEqual", "label": 0}, {"snippet_id": 46986, "code": "(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return", "label": 0}, {"snippet_id": 18494, "code": "(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return", "label": 0}, {"snippet_id": 4238, "code": ": for i in output: print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if", "label": 0}, {"snippet_id": 64598, "code": " print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on", "label": 0}, {"snippet_id": 55616, "code": " update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow", "label": 0}, {"snippet_id": 62875, "code": " elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in", "label": 0}, {"snippet_id": 38351, "code": " global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules", "label": 0}, {"snippet_id": 6224, "code": " False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words", "label": 1}, {"snippet_id": 89058, "code": "=self._collect_targets(self.target_roots, **kwargs) synthetics=OrderedSet() for synthetic_address in self.build_graph.synthetic_addresses: if self.build_graph.get_concrete_derived_from(synthetic_address)", "label": 0}, {"snippet_id": 24444, "code": "[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self", "label": 0}, {"snippet_id": 23183, "code": " python i686 being shipped with BIG-IP instead of python x86_64?? \"\"\" iface='' expected=16 python_arc=platform.architecture()[0] if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket", "label": 0}, {"snippet_id": 89189, "code": " root tree's BUILD files will be followed and this may lead to BUILD files outside of ``root`` being parsed and included in the returned build graph. :API: public :param string root: The path to scan; by", "label": 0}, {"snippet_id": 48361, "code": " for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as", "label": 0}, {"snippet_id": 35731, "code": "(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len", "label": 0}, {"snippet_id": 90932, "code": "=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java distribution:{}'.format(e)) options_scope='jvm-distributions' @classmethod def register_options(cls, register", "label": 0}, {"snippet_id": 18437, "code": " utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer", "label": 0}, {"snippet_id": 56942, "code": ": return self.counter[self.key] return 0 def get_value_by_type(val, v_type): \"\"\" Exampls: 1. get_value_by_type('True', 'bool') (1, None) 2. get_value_by_type('19860624 123059', 'datetime') (datetime.datetime", "label": 0}, {"snippet_id": 54678, "code": " rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return", "label": 0}, {"snippet_id": 69075, "code": "(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf", "label": 0}, {"snippet_id": 27851, "code": "'WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type", "label": 0}, {"snippet_id": 39933, "code": " import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging", "label": 1}, {"snippet_id": 56599, "code": "=request.GET.get('a') if q_action: tag_actions=_TagActions(obj=obj, tag_name=q_tag) getattr(tag_actions, q_action)() all_tags=obj.tag.all().order_by('pk') test_plan_tags=TestPlanTag.objects.filter( tag__in", "label": 0}, {"snippet_id": 61297, "code": " np.allclose(A, A.conj().T, atol=tolerance): raise ValueError(\"Observable must be Hermitian.\") return A operator_map={ 'QubitStateVector': ket, 'QubitUnitary': unitary, 'Hermitian': hermitian, 'Identity", "label": 0}, {"snippet_id": 66426, "code": "%(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s:", "label": 1}, {"snippet_id": 21773, "code": " labelencoder_X_1=LabelEncoder() X[:, 1]=labelencoder_X_1.fit_transform(X[:, 1]) labelencoder_X_2=LabelEncoder() X[:, 2]=labelencoder_X_2.fit_transform(X[:, 2]) onehotencoder=OneHotEncoder(categorical_features=[1]) X", "label": 1}, {"snippet_id": 21885, "code": " from dciclient.v1 import helper as dci_helper from dciagent.plugins import plugin import jinja2 import os import subprocess display=Display() class Options(object): def __init__(self, verbosity=None, inventory", "label": 1}, {"snippet_id": 80761, "code": "=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants: \t\t\tfor legitExt in up.validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t", "label": 1}, {"snippet_id": 62596, "code": " -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value", "label": 0}, {"snippet_id": 22729, "code": "( \"Failed to create user account:{0}, retcode:{1}, output:{2}\".format(username, retcode, out) ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id=6, salt_len=10): \"", "label": 0}, {"snippet_id": 69942, "code": " Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand from Base.Support.FS import FS", "label": 0}, {"snippet_id": 36420, "code": "\"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 10917, "code": " return parsed_uri.scheme in['http', 'https'] def read_config(uri): uri_parsed=urlparse.urlparse(uri) if is_file(uri_parsed): return read_config_from_file(uri_parsed.path) elif is_host(uri_parsed): return", "label": 0}, {"snippet_id": 85273, "code": "(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address): jars=[create_jardep_func(self.version)] build_graph.inject_synthetic_target(target_address, JarLibrary, jars", "label": 0}, {"snippet_id": 16942, "code": " data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest", "label": 1}, {"snippet_id": 21620, "code": " sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from", "label": 0}, {"snippet_id": 15505, "code": " arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest", "label": 0}, {"snippet_id": 77529, "code": " return with open(self.usersfile, 'rb') as f: users=pickle.loads(f.read()) try: for domain in users.keys(): uq=Queue() for ud in users[domain]: self.log.debug('Loaded user %s:%s', domain, ud['login']) uq.put", "label": 0}, {"snippet_id": 44143, "code": ".name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self", "label": 0}, {"snippet_id": 83270, "code": " None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id", "label": 0}, {"snippet_id": 48530, "code": " concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output)", "label": 0}, {"snippet_id": 55129, "code": " globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format", "label": 0}, {"snippet_id": 3712, "code": "(comp): logger.debug(\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed", "label": 0}, {"snippet_id": 28758, "code": "=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 9114, "code": ": dictionary of matches in a format{ <keyword object>,[[position, position...],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext", "label": 0}, {"snippet_id": 80306, "code": ") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args.size[0]) args", "label": 0}, {"snippet_id": 30480, "code": "(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat", "label": 0}, {"snippet_id": 6536, "code": " continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry", "label": 0}, {"snippet_id": 45860, "code": " else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append", "label": 0}, {"snippet_id": 23105, "code": " chk_err=True): \"\"\"Runs the eject command to eject the provisioning DVD BIG-IP does not include an eject command. It is sufficient to just umount the DVD disk. But I will log that we do not support this", "label": 0}, {"snippet_id": 14528, "code": " self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport.CurrentFiletypes()]) def NativeFiletypeCompletionUsable( self): return", "label": 0}, {"snippet_id": 88137, "code": " descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return plugin_info.find('name').text if os.path.isdir(classpath_element): try: with open(os.path.join(classpath_element, _SCALAC_PLUGIN_INFO_FILE)", "label": 0}, {"snippet_id": 60343, "code": " self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format", "label": 0}, {"snippet_id": 60085, "code": ".All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities[", "label": 0}, {"snippet_id": 67665, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(),", "label": 0}, {"snippet_id": 86963, "code": ") register('--incremental-caching', advanced=True, type=bool, help='When set, the results of incremental compiles will be written to the cache. ' 'This is unset by default, because it is generally a good", "label": 0}, {"snippet_id": 9264, "code": "\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords", "label": 0}, {"snippet_id": 86177, "code": " DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=False) javac_cmd=['{}/bin/javac'.format(distribution.real_home)] javac_cmd.extend([ '-classpath', ':'.join", "label": 0}, {"snippet_id": 20402, "code": ": sock.connect(addr) except(OSError, socket.error): if cls.VERBOSE: print('+', end='') sys.stdout.flush() time.sleep(0.1) else: break else: raise RuntimeError('could not connect') return sock return cls", "label": 0}, {"snippet_id": 13467, "code": " TWITTER'\r consumerSecret='INSERT YOUR CONSUMER SECRET HERE FROM TWITTER'\r accessTokenKey='INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR ACCESS TOKEN SECRET HERE FROM TWITTER", "label": 0}, {"snippet_id": 41397, "code": " RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)", "label": 0}, {"snippet_id": 75139, "code": ".bind_methods() elif status==wzrpc.status.e_timeout: self.p.log.warn('Keepalive timeout') else: self.p.log.warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self.p", "label": 0}, {"snippet_id": 78624, "code": " import logger as log from dbnav.jsonable import from_json COMMANDS={ 'dbdiff': 'differ', 'dbexec': 'executer', 'dbexport': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object):", "label": 0}, {"snippet_id": 77298, "code": " workers.WZWorkerThread): type_=0 if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess): type_=1", "label": 0}, {"snippet_id": 86392, "code": " input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd), input_files=input_snapshot.directory_digest, output_files=output_files, description='Compiling{", "label": 0}, {"snippet_id": 6218, "code": " text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split", "label": 1}, {"snippet_id": 12118, "code": ".get(diff_url, headers=diff_headers, auth=auth) patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) files={} for patchset in patch: file=patchset.target_file[1:] files[file]=[] for hunk", "label": 0}, {"snippet_id": 44113, "code": "=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets", "label": 0}, {"snippet_id": 8943, "code": " normalized before being joined into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True", "label": 0}, {"snippet_id": 94497, "code": " true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available", "label": 0}, {"snippet_id": 1619, "code": ") elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication", "label": 0}, {"snippet_id": 6303, "code": " line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable", "label": 1}, {"snippet_id": 62090, "code": " end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True", "label": 0}, {"snippet_id": 75580, "code": ": if not reqid: reqid=self.make_reqid() return(b'Router', b'auth-clear',[], reqid) def req_from_data(self, d, fun): return self.make_req_msg(d[0], d[1], d[2], fun, d[3]) def _parse_err(self, iden, msg,", "label": 0}, {"snippet_id": 30126, "code": "=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self)", "label": 0}, {"snippet_id": 37710, "code": " IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 25889, "code": ")\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210:", "label": 0}, {"snippet_id": 57632, "code": "(Q(username=self.new_value) | Q(email=self.new_value)) except User.DoesNotExist: raise ObjectDoesNotExist('Default tester not found!') self.get_update_targets().update(**{str(self.target_field): user.pk", "label": 0}, {"snippet_id": 7976, "code": ".nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they", "label": 0}, {"snippet_id": 66502, "code": "{ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return", "label": 0}, {"snippet_id": 70219, "code": ")...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target", "label": 0}, {"snippet_id": 85825, "code": " ClasspathUtil.compute_classpath_entries(iter(dependencies), classpath_product, all_extra_cp_entries, self.DEFAULT_CONFS, ) def compile_classpath(self, classpath_product_key, target, extra_cp_entries=None): \"\"", "label": 0}, {"snippet_id": 85247, "code": "\" return self._key_for_tool_version('scala-repl', self.version) def injectables(self, build_graph): if self.version=='custom': return specs_to_create=[ ('scalac', self._create_compiler_jardep), ('scala", "label": 1}, {"snippet_id": 80096, "code": "-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting the target.\") manualFormArgs=parser.add_argument_group('Manual Form Detection arguments", "label": 0}, {"snippet_id": 86212, "code": "\" in jvm-platform args.' .format(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings.args) javac_cmd.extend(settings_args) javac_cmd.extend([ '-source', str(settings", "label": 0}, {"snippet_id": 82312, "code": "-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0", "label": 0}, {"snippet_id": 15688, "code": " def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer", "label": 0}, {"snippet_id": 21117, "code": " awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'.format(awaitable.name)) else: messages.append('Response{}'.format(awaitable.name)) if len(messages)==0: return else", "label": 0}, {"snippet_id": 95225, "code": " static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import", "label": 0}, {"snippet_id": 10370, "code": "\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text", "label": 0}, {"snippet_id": 93468, "code": " self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex", "label": 0}, {"snippet_id": 53226, "code": "=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other", "label": 0}, {"snippet_id": 84127, "code": " or[] return dependencies.DependenciesDescription( requirements=requirements, installed_tool_dependencies=installed_tool_dependencies, ) @staticmethod def __dependency_resolution( lwr_client): dependency_resolution", "label": 0}, {"snippet_id": 36175, "code": ".decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return", "label": 0}, {"snippet_id": 94524, "code": "\"Component was not started by Hyperion, but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false", "label": 0}, {"snippet_id": 11956, "code": " False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors\": True, } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]", "label": 0}, {"snippet_id": 4848, "code": "=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions[s](complete_output", "label": 0}, {"snippet_id": 9525, "code": " MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms", "label": 0}, {"snippet_id": 31602, "code": "=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output", "label": 0}, {"snippet_id": 30936, "code": " value in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in", "label": 0}, {"snippet_id": 91877, "code": ".exceptions import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import memoized_property", "label": 0}, {"snippet_id": 34253, "code": "(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, ", "label": 0}, {"snippet_id": 94152, "code": " \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session", "label": 0}, {"snippet_id": 75637, "code": "*args, **kvargs) class Resume(Exception): '''Exception to raise when suspend sleep is interrupted''' class WZWorkerBase: def __init__(self, wz_addr, fun, args=(), kvargs={}, name=None, start_timer=None", "label": 0}, {"snippet_id": 5102, "code": "\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template ", "label": 0}, {"snippet_id": 64799, "code": ": result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self", "label": 0}, {"snippet_id": 19233, "code": " source=json.dumps(native) result=load_source(source) assert result==native def test_yaml_string(): native={'foo': 'bar'} source=yaml.dump(native) result=load_source(source) assert result==native def test_json_file_object", "label": 0}, {"snippet_id": 5620, "code": ": return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]", "label": 0}, {"snippet_id": 55403, "code": " resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources:", "label": 0}, {"snippet_id": 20965, "code": " i, handler in enumerate(list(self._handlers)): handle_message, _, _=handler handled=handle_message(msg) try: msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break", "label": 0}, {"snippet_id": 24379, "code": ".get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning", "label": 0}, {"snippet_id": 468, "code": ".POST.get(\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd", "label": 0}, {"snippet_id": 30797, "code": ".message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:", "label": 0}, {"snippet_id": 91314, "code": ".backend.python.tasks.unpack_wheels import UnpackWheels from pants.build_graph.build_file_aliases import BuildFileAliases from pants.build_graph.resources import Resources from pants.goal.task_registrar", "label": 0}, {"snippet_id": 14263, "code": " user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr=None self._server_popen", "label": 0}, {"snippet_id": 54646, "code": "\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException", "label": 0}, {"snippet_id": 76950, "code": "['avatar_uploaded'] is True): return files=[] for sd in os.walk(c.av_dir): files.extend(sd[2]) av=os.path.join(sd[0], random.choice(files)) self.log.info('Uploading %s as new avatar', av) self.site.uploadavatar", "label": 0}, {"snippet_id": 95184, "code": " the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks", "label": 0}, {"snippet_id": 30916, "code": ", w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value", "label": 0}, {"snippet_id": 78387, "code": ") except exc.Success as e: self.counters['topics'] +=1 self.w.sleep(self.topic_successtimeout) except exc.Wait5Min as e: self.topic_successtimeout=self.topic_successtimeout +0.1 self.log.info('Wait5Min", "label": 0}, {"snippet_id": 51284, "code": "\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic", "label": 0}, {"snippet_id": 5250, "code": "(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories)", "label": 0}, {"snippet_id": 59302, "code": " run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition to the", "label": 0}, {"snippet_id": 61632, "code": " required.') A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part{} in expectation value.'.format", "label": 0}, {"snippet_id": 8069, "code": ") return limit and sorted_keywords[:limit] or sorted_keywords def _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of", "label": 0}, {"snippet_id": 86591, "code": " _write_scalac_plugin_info(resources_dir, scalac_plugin_target): scalac_plugin_info_file=os.path.join(resources_dir, _SCALAC_PLUGIN_INFO_FILE) with safe_open(scalac_plugin_info_file, 'w') as f: f.write(textwrap", "label": 0}, {"snippet_id": 40302, "code": "<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files", "label": 0}, {"snippet_id": 203, "code": "-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"", "label": 0}, {"snippet_id": 62968, "code": "=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG", "label": 0}, {"snippet_id": 67188, "code": " import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException", "label": 0}, {"snippet_id": 63948, "code": " ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution", "label": 1}, {"snippet_id": 81618, "code": "\t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex", "label": 0}, {"snippet_id": 74903, "code": "\"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input", "label": 0}, {"snippet_id": 84819, "code": ".4'), } scala_style_jar=JarDependency('org.scalastyle', 'scalastyle_2.11', '0.8.0') class ScalaPlatform(JvmToolMixin, ZincLanguageMixin, InjectablesMixin, Subsystem): \"\"\"A scala platform. :API: public \"", "label": 0}, {"snippet_id": 15842, "code": " requests import urlparse from retries import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport", "label": 0}, {"snippet_id": 67078, "code": " class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install", "label": 0}, {"snippet_id": 94136, "code": "(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running", "label": 0}, {"snippet_id": 21799, "code": " X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=0) from sklearn.preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform", "label": 1}, {"snippet_id": 16272, "code": "._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self):", "label": 1}, {"snippet_id": 52690, "code": " not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output", "label": 0}, {"snippet_id": 36979, "code": ".priority=0 self.version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)=", "label": 0}, {"snippet_id": 53020, "code": " self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s", "label": 0}, {"snippet_id": 85370, "code": ".fs import PathGlobs, PathGlobsAndRoot from pants.java.jar.jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem from pants.util.dirutil import fast_relpath from pants.util", "label": 1}, {"snippet_id": 15700, "code": " debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid)", "label": 0}, {"snippet_id": 63107, "code": "==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return", "label": 0}, {"snippet_id": 56285, "code": " TestCaseRunStatus, TestRunTag from tcms.core.helpers.comments import add_comment from tcms.core.utils.validations import validate_bug_id def check_permission(request, ctype): perm='%s.change_%s' % tuple(ctype.split('", "label": 0}, {"snippet_id": 77897, "code": ", name='SpaghettiMonster') wm.start(ctx, sig_addr) def add_target(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_", "label": 0}, {"snippet_id": 40069, "code": ". \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard", "label": 1}, {"snippet_id": 16692, "code": ".PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info ", "label": 0}, {"snippet_id": 57179, "code": " field %s' %(ctype, field)) if hasattr(targets[0], 'log_action'): for t in targets: try: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), value ) ) except", "label": 0}, {"snippet_id": 5485, "code": " output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={}", "label": 0}, {"snippet_id": 40547, "code": ": if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v", "label": 0}, {"snippet_id": 15244, "code": "') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface", "label": 0}, {"snippet_id": 46280, "code": "(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]", "label": 0}, {"snippet_id": 62031, "code": " backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0", "label": 0}, {"snippet_id": 69799, "code": ") else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message", "label": 1}, {"snippet_id": 3542, "code": " No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]", "label": 0}, {"snippet_id": 31959, "code": "\"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be", "label": 0}, {"snippet_id": 95458, "code": " that automatically downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list \"\"\" if", "label": 0}, {"snippet_id": 52319, "code": "), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output", "label": 0}, {"snippet_id": 36696, "code": "\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return", "label": 0}, {"snippet_id": 33004, "code": " rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno", "label": 0}, {"snippet_id": 57445, "code": " _update_[property name] to hold specific update logic. \"\"\" ctype='testcases.testcase' def __init__(self, request): self.request=request self.target_field=request.POST.get('target_field') self.new_value", "label": 0}, {"snippet_id": 82786, "code": ".url,args.formAction,args.inputName) else: \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput", "label": 0}, {"snippet_id": 55428, "code": ".run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and", "label": 0}, {"snippet_id": 59083, "code": "== **Module name:**:mod:`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits", "label": 0}, {"snippet_id": 12696, "code": "(data[\"pr_number\"])) comments=requests.get(query, headers=headers, auth=auth).json() last_comment_id=None for old_comment in comments: if old_comment[\"user\"][\"id\"]==24736507: last_comment_id=old_comment", "label": 0}, {"snippet_id": 88637, "code": ")) @contextmanager def executing(self): \"\"\"A contextmanager that sets metrics in the context of a(v1) engine execution.\"\"\" self._set_target_root_count_in_runtracker() yield self.run_tracker.pantsd_stats", "label": 0}, {"snippet_id": 76584, "code": " import UniWipe from wipeskel import * import wzrpc from beon import regexp import pickle from logging import config from logconfig import logging_config config.dictConfig(logging_config) logger=logging", "label": 0}, {"snippet_id": 94018, "code": "'master_node') for current in node.depends_on: deps.node(current.comp_name) res=[] unres=[] dep_resolve(current, res, unres) for node in res: if \"depends\" in node.component: for dep in node.component['depends'", "label": 0}, {"snippet_id": 11675, "code": " ConfigurationContainsUndefinedVariables: LOG.error(\"Configuration contained undefined variables!\") exit_code=EXIT_CODE_ERROR except SystemExit as e: exit_code=e.code except BaseException as e: LOG.error(e", "label": 0}, {"snippet_id": 93596, "code": "%s' found running\" % comp['name']) self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion ", "label": 0}, {"snippet_id": 8379, "code": "-enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return", "label": 0}, {"snippet_id": 72798, "code": " error_perm import time import csv import logging import os.path import pathlib import allel import sys import functools import numpy as np import zarr import numcodecs from numcodecs import Blosc, LZ4, LZMA", "label": 1}, {"snippet_id": 20784, "code": " result def get_awaiter_for_event(self, event, condition=lambda msg: True, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg", "label": 0}, {"snippet_id": 14307, "code": "._temp_options_filename=options_file.name json.dump( dict( self._user_options), options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), ", "label": 1}, {"snippet_id": 84146, "code": "[\"none\", \"local\", \"remote\"]: raise Exception(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution @staticmethod def __remote_metadata( lwr_client):", "label": 0}, {"snippet_id": 67691, "code": "): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target", "label": 0}, {"snippet_id": 29637, "code": ".escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match", "label": 0}, {"snippet_id": 62033, "code": "): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default", "label": 0}, {"snippet_id": 68126, "code": ".nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None:", "label": 0}, {"snippet_id": 41437, "code": "=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self", "label": 0}, {"snippet_id": 82800, "code": ".threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not args.skipRecon: \tif len(args.legitExtensions) > 0: \t\tn=up.detectValidExtensions(extensions,args", "label": 0}, {"snippet_id": 49155, "code": " self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror", "label": 0}, {"snippet_id": 14222, "code": ") NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH", "label": 0}, {"snippet_id": 25318, "code": " cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components", "label": 0}, {"snippet_id": 31589, "code": "=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params", "label": 0}, {"snippet_id": 88666, "code": "'s daemon stats object.\"\"\" target_count=len(self._target_roots) self.run_tracker.pantsd_stats.set_target_root_size(target_count) return target_count def _set_affected_target_count_in_runtracker(self): \"", "label": 0}, {"snippet_id": 34972, "code": "(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex", "label": 0}, {"snippet_id": 49224, "code": " rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"", "label": 0}, {"snippet_id": 46560, "code": "[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self)", "label": 0}, {"snippet_id": 30569, "code": " import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type", "label": 0}, {"snippet_id": 20720, "code": " lambda: resp[\"msg\"]) else: resp_awaiter=self._get_awaiter_for_request(req, **args) self._conn.send(req) return resp_awaiter def add_handler(self, handler, **kwargs): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 64091, "code": " def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration(self, client, job_wrapper", "label": 0}, {"snippet_id": 71327, "code": " target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +", "label": 0}, {"snippet_id": 10781, "code": "[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file", "label": 1}, {"snippet_id": 49338, "code": "=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info", "label": 0}, {"snippet_id": 44645, "code": " return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None):", "label": 0}, {"snippet_id": 79337, "code": "=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f) \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t", "label": 0}, {"snippet_id": 91111, "code": ") return self._normalized_jdk_paths.get(os_name,()) def _create_locator(self): homes=self._get_explicit_jdk_paths() environment=_UnknownEnvironment( _ExplicitEnvironment(*homes), _UnknownEnvironment( _EnvVarEnvironment", "label": 0}, {"snippet_id": 31521, "code": " of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params(", "label": 0}, {"snippet_id": 57997, "code": "') not in('add', 'remove'): return(None, 'Actions only allow \"add\" and \"remove\".') else: data['action']=request.GET.get('a') data['bz_external_track']=True if request.GET.get('bz_external_track', False", "label": 0}, {"snippet_id": 21580, "code": "(unseen_file, 'wb') as f: pickle.dump(save_links, f) sys.exit() else: seen_links.append(link) save_links.remove(link) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) with open(unseen_file, 'wb", "label": 0}, {"snippet_id": 88463, "code": ".pants.workdir.file_lock')) self._java_sysprops=None self.requested_goals=requested_goals or[] self._console_outstream=console_outstream or sys.stdout self._scm=scm or get_scm() self._workspace=workspace or", "label": 0}, {"snippet_id": 40258, "code": ".file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self", "label": 0}, {"snippet_id": 51450, "code": "\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected", "label": 0}, {"snippet_id": 77000, "code": ": tlist=list() targets[domain]=tlist if domain in forums: fset=forums[domain] else: fset=set() forums[domain]=fset net=make_net(proxy, proxytype) net.cookiefname=(proxy if proxy else 'noproxy')+'_'+domain", "label": 0}, {"snippet_id": 32, "code": " list_route from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager", "label": 1}, {"snippet_id": 56157, "code": " functions for plan/case/run. Most of these functions are use for Ajax. \"\"\" import datetime import sys import json from distutils.util import strtobool from django import http from django.db.models import", "label": 1}, {"snippet_id": 69960, "code": " from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def", "label": 0}, {"snippet_id": 87626, "code": "] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests) !=len(dependency_classpath): for dep in dependency_classpath: if", "label": 1}, {"snippet_id": 5306, "code": " of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text", "label": 0}, {"snippet_id": 75726, "code": ", b'GLOBAL') s.setsockopt(zmq.SUBSCRIBE, b'WZWorker') s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8')) self.sig_sock=s s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt", "label": 0}, {"snippet_id": 40782, "code": ")) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments", "label": 0}, {"snippet_id": 84249, "code": " string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration(self, client, job_wrapper, remote_metadata, remote_job_config): metadata_kwds", "label": 0}, {"snippet_id": 52486, "code": ") if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:", "label": 0}, {"snippet_id": 71103, "code": " layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status", "label": 0}, {"snippet_id": 74208, "code": ": self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"]) except ValueError: pass if \"benchmark_data_input\" in runtime_config.benchmark: benchmark_data_input_temp=runtime_config", "label": 0}, {"snippet_id": 75503, "code": " reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data(self, interface, method", "label": 0}, {"snippet_id": 71548, "code": ": %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name", "label": 0}, {"snippet_id": 35552, "code": " a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone", "label": 0}, {"snippet_id": 85981, "code": ":all', '-Xlint:-serial', '-Xlint:-path') @classmethod def get_no_warning_args_default(cls): return('-nowarn', '-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-Werror", "label": 0}, {"snippet_id": 56288, "code": ".comments import add_comment from tcms.core.utils.validations import validate_bug_id def check_permission(request, ctype): perm='%s.change_%s' % tuple(ctype.split('.')) if request.user.has_perm(perm): return", "label": 0}, {"snippet_id": 31754, "code": ".temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch", "label": 0}, {"snippet_id": 59180, "code": " Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq", "label": 0}, {"snippet_id": 48084, "code": "._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item", "label": 0}, {"snippet_id": 1742, "code": ".execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor", "label": 0}, {"snippet_id": 55649, "code": "(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo", "label": 0}, {"snippet_id": 7159, "code": "(single_keywords_p, composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create", "label": 0}, {"snippet_id": 11216, "code": " receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is given it reads it's default configuration from file system. The configuration file is", "label": 0}, {"snippet_id": 95282, "code": " to create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files", "label": 0}, {"snippet_id": 56826, "code": " tag_name: str \"\"\" self.obj=obj self.tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name)", "label": 0}, {"snippet_id": 94211, "code": "/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self", "label": 0}, {"snippet_id": 1919, "code": ",iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val) data={'container_id': row[0], 'container_name': row[1], 'data_io': datasets_io, 'data_mem': datasets_mem, 'data_perc': datasets_perc", "label": 0}, {"snippet_id": 8745, "code": "\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache", "label": 0}, {"snippet_id": 5427, "code": " _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords", "label": 0}, {"snippet_id": 85185, "code": " custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not specified, then the version specified in ' '--scala-suffix-version is used. For example for Scala ", "label": 0}, {"snippet_id": 74636, "code": " configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled\" in runtime_config.vcf_to_zarr: self.enabled", "label": 0}, {"snippet_id": 83941, "code": "\"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s", "label": 0}, {"snippet_id": 56781, "code": "\" Used for performing the 'add' and 'remove' actions on a given tag \"\"\" def __init__(self, obj, tag_name): \"\"\" :param obj: the object for which the tag actions would be performed :type obj: either a:class", "label": 0}, {"snippet_id": 3517, "code": " mode\" % self.window_name) def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No", "label": 0}, {"snippet_id": 38594, "code": " list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None", "label": 0}, {"snippet_id": 87117, "code": " get_buildroot(), ) ) if self.get_options().use_classpath_jars: raise TaskError(\"Hermetic zinc execution currently doesn't work with classpath jars\") def select(self, target): raise NotImplementedError() def", "label": 0}, {"snippet_id": 61560, "code": ": array: matrix representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)) if not callable(operator_map[A.name]): return operator_map", "label": 0}, {"snippet_id": 64816, "code": ")) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException", "label": 0}, {"snippet_id": 48722, "code": ".update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards", "label": 0}, {"snippet_id": 85874, "code": ".jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin import JavacPlugin from pants.backend.jvm.targets.jvm_target import JvmTarget from pants.backend", "label": 0}, {"snippet_id": 22597, "code": " WAAgent will not fail if this command fails, but the hostname will not be what the user set either. Currently we do not set the hostname when WAAgent starts up, so I am passing on setting it here too. :param", "label": 0}, {"snippet_id": 86301, "code": " workunit: self.context.log.debug('Executing{}'.format(' '.join(javac_cmd))) p=subprocess.Popen(javac_cmd, stdout=workunit.output('stdout'), stderr=workunit.output('stderr')) return_code=p.wait() workunit", "label": 0}, {"snippet_id": 58320, "code": "'user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses(self): self.client.login( username=self.user.username, password='testing') response=self.client", "label": 0}, {"snippet_id": 71266, "code": "(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\"", "label": 0}, {"snippet_id": 1676, "code": "='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output", "label": 0}, {"snippet_id": 90762, "code": "=minimum_version, maximum_version=maximum_version, jdk=jdk) dist.validate() logger.debug('Located{} for constraints: minimum_version{}, maximum_version{}, jdk{}' .format(dist, minimum_version, maximum_version, jdk", "label": 0}, {"snippet_id": 71125, "code": " print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"", "label": 0}, {"snippet_id": 25611, "code": ".module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self", "label": 0}, {"snippet_id": 29723, "code": " AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value", "label": 0}, {"snippet_id": 11942, "code": ", \"first\": False, \"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors", "label": 0}, {"snippet_id": 19310, "code": " source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.flush() with open(tmp_file.name) as yaml_file: result=load_source(yaml_file) assert result==native", "label": 0}, {"snippet_id": 34019, "code": "(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params", "label": 0}, {"snippet_id": 79, "code": ".read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn", "label": 0}, {"snippet_id": 46166, "code": " wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb", "label": 0}, {"snippet_id": 43584, "code": "=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools", "label": 0}, {"snippet_id": 79591, "code": ",json,concurrent.futures,random from utils import * from UploadForm import UploadForm from threading import Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger", "label": 0}, {"snippet_id": 8819, "code": ".text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename", "label": 0}, {"snippet_id": 62430, "code": ".backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs}", "label": 0}, {"snippet_id": 52364, "code": "=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__(", "label": 0}, {"snippet_id": 45416, "code": "(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as", "label": 0}, {"snippet_id": 72850, "code": " remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path", "label": 0}, {"snippet_id": 23547, "code": " if ret !=0: raise OSUtilError((\"Failed to set password for{0}:{1}\" \"\").format(username, output)) def del_root_password(self): err=shellutil.run('pw usermod root -h -') if err: raise OSUtilError(\"Failed", "label": 0}, {"snippet_id": 61282, "code": " hermitian matrix. \"\"\" A=np.asarray(args[0]) if A.shape[0] !=A.shape[1]: raise ValueError(\"Observable must be a square matrix.\") if not np.allclose(A, A.conj().T, atol=tolerance): raise ValueError(\"Observable", "label": 0}, {"snippet_id": 36173, "code": "\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input", "label": 0}, {"snippet_id": 26270, "code": " 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status", "label": 0}, {"snippet_id": 88341, "code": " to the targets the products are associated with. :API: public \"\"\" class Log(object): \"\"\"A logger facade that logs into the pants reporting framework.\"\"\" def __init__(self, run_tracker): self._run_tracker", "label": 0}, {"snippet_id": 27762, "code": " self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state", "label": 0}, {"snippet_id": 81494, "code": "() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures.thread._threads_queues", "label": 0}, {"snippet_id": 49534, "code": "))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule", "label": 0}, {"snippet_id": 19091, "code": ", schema=schema, **kwargs) def validate_api_request(schema, raw_request): request=normalize_request(raw_request) with ErrorDict(): validate_request(request=request, schema=schema) def validate_api_response", "label": 0}, {"snippet_id": 12070, "code": " PR \"\"\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} diff_headers=headers.copy() diff_headers[\"Accept\"]=\"application/vnd.github.VERSION.diff\" auth=(os.environ[\"BOT_USERNAME\"], os.environ", "label": 0}, {"snippet_id": 75122, "code": ".p.log.warn('Keepalive status{0}, reauthentificating and rebinding'. format(wzrpc.name_status(status))) self.p.auth_requests() self.p.bind_methods() elif status==wzrpc.status.e_timeout: self.p.log.warn", "label": 0}, {"snippet_id": 65897, "code": " status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online", "label": 0}, {"snippet_id": 31036, "code": ": if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files", "label": 0}, {"snippet_id": 87035, "code": "().incremental @property def cache_incremental(self): \"\"\"Optionally write the results of incremental compiles to the cache.\"\"\" return self.get_options().incremental_caching @memoized_property def _zinc", "label": 1}, {"snippet_id": 19326, "code": "(yaml_file) assert result==native def test_yaml_file_path(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file", "label": 0}, {"snippet_id": 92595, "code": " temporary_file(root_dir=path) as f: self.assertTrue(os.path.realpath(f.name).startswith(os.path.realpath(path)), 'file should be created in root_dir if specified.') def test_temporary_dir_no_args(self", "label": 0}, {"snippet_id": 24867, "code": "] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=", "label": 0}, {"snippet_id": 26185, "code": "'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24", "label": 0}, {"snippet_id": 48595, "code": " RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable", "label": 0}, {"snippet_id": 83625, "code": " job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env", "label": 0}, {"snippet_id": 41977, "code": ": self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since", "label": 0}, {"snippet_id": 94140, "code": " self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif", "label": 0}, {"snippet_id": 62998, "code": " LWR is not configured with this information. Defaulting to datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name", "label": 0}, {"snippet_id": 93372, "code": ".copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail): for group in self.config['groups']: for comp", "label": 0}, {"snippet_id": 44875, "code": "*ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo", "label": 0}, {"snippet_id": 72132, "code": " seconds)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return except ValueError: irc.error('Invalid argument \"%s\" for <seconds>.' % seconds) return network.serverdata", "label": 0}, {"snippet_id": 39355, "code": "(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile", "label": 0}, {"snippet_id": 68798, "code": ".set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i ", "label": 0}, {"snippet_id": 94428, "code": " running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(", "label": 1}, {"snippet_id": 4941, "code": "] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('</record", "label": 0}, {"snippet_id": 59728, "code": " short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key for(key,val) in operator_map.items() if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs", "label": 0}, {"snippet_id": 91054, "code": "): normalized={} jdk_paths=self.get_options().paths or{} for name, paths in sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to", "label": 0}, {"snippet_id": 66688, "code": " print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc()", "label": 0}, {"snippet_id": 44027, "code": "=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False)", "label": 0}, {"snippet_id": 26187, "code": "], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24", "label": 0}, {"snippet_id": 1647, "code": "=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password", "label": 0}, {"snippet_id": 51191, "code": "(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file", "label": 0}, {"snippet_id": 31986, "code": " item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item", "label": 0}, {"snippet_id": 43692, "code": "\"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 26897, "code": ")\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150:", "label": 0}, {"snippet_id": 28491, "code": " unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states", "label": 0}, {"snippet_id": 30511, "code": "=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None", "label": 0}, {"snippet_id": 82154, "code": " parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by the", "label": 0}, {"snippet_id": 93090, "code": ".assertEqual(0o700, os.stat(f.name)[0] & 0o777) with temporary_dir(permissions=0o644) as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self): fake_logger=mock.Mock()", "label": 0}, {"snippet_id": 6792, "code": " composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors", "label": 0}, {"snippet_id": 84798, "code": ".subsystem.subsystem import Subsystem major_version_info=namedtuple('major_version_info',['full_version']) scala_build_info={ '2.10': major_version_info(full_version='2.10.6'), '2.11': major_version_info", "label": 0}, {"snippet_id": 79270, "code": "\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None", "label": 0}, {"snippet_id": 33985, "code": "=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None", "label": 0}, {"snippet_id": 86843, "code": "'-C-Xlint:-serial', '-C-Xlint:-path', '-S-deprecation', '-S-unchecked', '-S-Xlint') @classmethod def get_no_warning_args_default(cls): return('-C-nowarn', '-C-Xlint:none', '-S-nowarn', '-S-Xlint:none',", "label": 0}, {"snippet_id": 13477, "code": " ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR ACCESS TOKEN SECRET HERE FROM TWITTER'\r \r import sys\r import time\r import subprocess\r import os\r from random import randint\r from threading", "label": 0}, {"snippet_id": 32766, "code": " import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake", "label": 0}, {"snippet_id": 23938, "code": " port_id): \"\"\" Return device name attached to ide port 'n'. \"\"\" if port_id > 3: return None g0=\"00000000\" if port_id > 1: g0=\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev", "label": 0}, {"snippet_id": 73823, "code": " runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool", "label": 0}, {"snippet_id": 18863, "code": " import( swagger_schema_validator, ) from flex.loading.schema.paths.path_item.operation.responses.single.schema import( schema_validator, ) from flex.http import( normalize_request, normalize_response,", "label": 0}, {"snippet_id": 53877, "code": "._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule", "label": 0}, {"snippet_id": 19703, "code": "'host', None) if serverhost: args.address=Address.as_server(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address", "label": 0}, {"snippet_id": 63683, "code": " threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill", "label": 0}, {"snippet_id": 92217, "code": " uuid import zipfile from builtins import next, object, range, str from contextlib import contextmanager import mock from future.utils import PY3 from pants.util.contextutil import(InvalidZipPath, Timer", "label": 0}, {"snippet_id": 81901, "code": "\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies", "label": 0}, {"snippet_id": 58511, "code": " test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run': '99999998,1009900'}) self", "label": 0}, {"snippet_id": 68599, "code": "=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other", "label": 0}, {"snippet_id": 15228, "code": "(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 50596, "code": " return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads", "label": 0}, {"snippet_id": 84131, "code": " installed_tool_dependencies=installed_tool_dependencies, ) @staticmethod def __dependency_resolution( lwr_client): dependency_resolution=lwr_client.destination_params.get( \"dependency_resolution\", \"local\"", "label": 0}, {"snippet_id": 76586, "code": " from wipeskel import * import wzrpc from beon import regexp import pickle from logging import config from logconfig import logging_config config.dictConfig(logging_config) logger=logging.getLogger() ctx", "label": 0}, {"snippet_id": 61556, "code": " openqml.Expectation): operation/observable. Returns: array: matrix representation. \"\"\" if A.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(A.name, cls.short_name)) if", "label": 0}, {"snippet_id": 49390, "code": "=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False", "label": 0}, {"snippet_id": 65113, "code": " target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self", "label": 0}, {"snippet_id": 81793, "code": "\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates", "label": 0}, {"snippet_id": 19297, "code": " tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_yaml_file_object(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file", "label": 0}, {"snippet_id": 19815, "code": " self).__init__() self._addr=Address.from_raw(addr, defaultport=port) self._connecttimeout=connecttimeout self._adapter=None self._session=None self._breakpoints=breakpoints @property def adapter(self):", "label": 0}, {"snippet_id": 14598, "code": " OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup", "label": 0}, {"snippet_id": 70310, "code": "={ \\ MOUNTED: RC_OK, RECOVERING: RC_OK, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self", "label": 0}, {"snippet_id": 16019, "code": " server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath", "label": 0}, {"snippet_id": 55377, "code": ": logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down", "label": 0}, {"snippet_id": 76858, "code": " terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b'WZWorker', b'terminate']) for t in threading.enumerate(): if isinstance(t, threading.Timer): t.cancel() logger.info('Exiting') def", "label": 0}, {"snippet_id": 28355, "code": " name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable", "label": 1}, {"snippet_id": 65852, "code": " t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target", "label": 0}, {"snippet_id": 711, "code": "=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor.execute(common.Q_GET_CONTAINER_STATS_CPU,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_perc", "label": 0}, {"snippet_id": 11939, "code": "], \"max-line-length\": 79, \"count\": False, \"first\": False, \"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment", "label": 0}, {"snippet_id": 4845, "code": " author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw", "label": 0}, {"snippet_id": 41828, "code": " None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files", "label": 0}, {"snippet_id": 6301, "code": "(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)", "label": 1}, {"snippet_id": 30898, "code": " dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in", "label": 0}, {"snippet_id": 47666, "code": " s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \"", "label": 0}, {"snippet_id": 1516, "code": "=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif action=", "label": 0}, {"snippet_id": 1515, "code": "}, safe=False) elif action=='getIfConfigured': print(action) queryset=BoxDetails.objects.all() serializer=BoxDetailsSerializer(queryset, many=True) return JsonResponse(serializer.data, safe=False) elif", "label": 0}, {"snippet_id": 36435, "code": ".exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self", "label": 0}, {"snippet_id": 80807, "code": " concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a[\"templateName\"]] \t", "label": 0}, {"snippet_id": 2267, "code": ": print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker", "label": 0}, {"snippet_id": 71256, "code": ".tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if", "label": 0}, {"snippet_id": 51425, "code": " \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp", "label": 0}, {"snippet_id": 83225, "code": ")) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager, 'ensure_has_status_update_callback'): self.client_manager.ensure_has_status_update_callback", "label": 0}, {"snippet_id": 46314, "code": " dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class", "label": 0}, {"snippet_id": 65577, "code": ".iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset()", "label": 0}, {"snippet_id": 69777, "code": "%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info", "label": 1}, {"snippet_id": 34155, "code": "=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def", "label": 0}, {"snippet_id": 18438, "code": ".RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer()", "label": 0}, {"snippet_id": 5341, "code": "{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info", "label": 0}, {"snippet_id": 68512, "code": " c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0:", "label": 0}, {"snippet_id": 3332, "code": " self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif", "label": 0}, {"snippet_id": 61337, "code": "\"\"\"Default qubit device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention", "label": 0}, {"snippet_id": 2796, "code": " window...\") kill_window(window) self.logger.info(\"... done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)", "label": 0}, {"snippet_id": 46318, "code": "=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list", "label": 0}, {"snippet_id": 67606, "code": "), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self", "label": 0}, {"snippet_id": 20149, "code": "'debugger already running') assert self._session is None self._adapter=DebugAdapter.start(argv, port=self._port) return self._adapter def host_local_debugger(self, argv, script=None, env=None, cwd=None", "label": 0}, {"snippet_id": 78068, "code": " domain) forums[domain].add((user, forum)) def rffu(urls): for user, domain, forum in r_udf.findall(urls): if len(forum) > 0: get_forum_id(forum) logger.info('Removing %s:%s from forums[%s]', user, forum,", "label": 0}, {"snippet_id": 22154, "code": " class AnsiblePlugin(plugin.Plugin): def __init__(self, conf): super(AnsiblePlugin, self).__init__(conf) def generate_ansible_playbook_from_template(self, template_file, data): templateLoader=jinja2.FileSystemLoader", "label": 0}, {"snippet_id": 82050, "code": " matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"--true-regex\",metavar=\"regex\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\"", "label": 0}, {"snippet_id": 72715, "code": "(\"[Exec] Executing benchmark tool.\") runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else:", "label": 0}, {"snippet_id": 77559, "code": "[domain]=uq except Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users(self): users={} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds=[] for i in range", "label": 0}, {"snippet_id": 29925, "code": " flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern", "label": 0}, {"snippet_id": 35738, "code": ",(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return", "label": 0}, {"snippet_id": 56239, "code": ".models import Tag from tcms.management.models import EnvGroup, EnvProperty, EnvValue from tcms.testcases.models import TestCase, Bug from tcms.testcases.models import Category from tcms.testcases.models", "label": 0}, {"snippet_id": 43301, "code": " None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self", "label": 0}, {"snippet_id": 92731, "code": " duration): self._time +=duration clock=FakeClock() with Timer(clock=clock) as t: self.assertLess(t.start, clock.time()) self.assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t.elapsed, 0.1)", "label": 0}, {"snippet_id": 54099, "code": " wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self", "label": 0}, {"snippet_id": 904, "code": ") configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action)", "label": 0}, {"snippet_id": 58463, "code": ".tester.username, password='password') response=self.client.post(self.many_comments_url, {'comment': 'new comment', 'run':[]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET", "label": 0}, {"snippet_id": 45654, "code": " regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self", "label": 0}, {"snippet_id": 29917, "code": " if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=", "label": 0}, {"snippet_id": 22369, "code": " :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within roughly 50 minutes(100 * 30 seconds) \"\"\" for retries in range(1, 100): logger.info(\"Checking", "label": 0}, {"snippet_id": 36635, "code": ", rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex", "label": 0}, {"snippet_id": 73673, "code": " +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return", "label": 0}, {"snippet_id": 34451, "code": ".abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target", "label": 0}, {"snippet_id": 10489, "code": "'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import", "label": 1}, {"snippet_id": 13406, "code": "\"branch\": data.get(\"new_branch\"), } r=requests.put(url, json=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[", "label": 0}, {"snippet_id": 9256, "code": " object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return", "label": 0}, {"snippet_id": 6037, "code": " except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") >", "label": 0}, {"snippet_id": 48755, "code": " ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex))", "label": 0}, {"snippet_id": 86348, "code": " plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append('-Xplugin:{}{}'", "label": 0}, {"snippet_id": 13782, "code": "(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp", "label": 0}, {"snippet_id": 18220, "code": " lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 71290, "code": " flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\",", "label": 0}, {"snippet_id": 62852, "code": " observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0'", "label": 0}, {"snippet_id": 18179, "code": " from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True", "label": 0}, {"snippet_id": 30987, "code": "): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output", "label": 0}, {"snippet_id": 60834, "code": ".__class__.__name__ +'\\nInstance: ' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version", "label": 0}, {"snippet_id": 4759, "code": " chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var", "label": 0}, {"snippet_id": 8879, "code": " get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode", "label": 1}, {"snippet_id": 67541, "code": " GlobalStartEventHandler(FSGlobalEventHandler): def __init__(self, verbose=1): FSGlobalEventHandler.__init__(self, verbose) def handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count,", "label": 0}, {"snippet_id": 58752, "code": "(self): remove_perm_from_user(self.tester, self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post(self.update_url,{ 'content_type': 'testruns.testcaserun", "label": 0}, {"snippet_id": 70798, "code": ".state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type", "label": 0}, {"snippet_id": 93397, "code": "'components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node) if \"depends\" in node.component: for dep in", "label": 0}, {"snippet_id": 45033, "code": "(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params,", "label": 0}, {"snippet_id": 8679, "code": " import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import", "label": 0}, {"snippet_id": 18723, "code": " def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable", "label": 0}, {"snippet_id": 87152, "code": " in targets] zinc_analysis=self.context.products.get_data('zinc_analysis') zinc_args=self.context.products.get_data('zinc_args') if zinc_analysis is not None: for compile_context in compile_contexts: zinc_analysis", "label": 0}, {"snippet_id": 20306, "code": "-nodebug') self._launch(argv, **kwargs) return self._adapter, self._session def launch_module(self, module, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not", "label": 0}, {"snippet_id": 81042, "code": "\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as", "label": 0}, {"snippet_id": 42146, "code": " self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__", "label": 0}, {"snippet_id": 6350, "code": " URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text,", "label": 0}, {"snippet_id": 73882, "code": " \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation of", "label": 0}, {"snippet_id": 38842, "code": " locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on", "label": 0}, {"snippet_id": 26176, "code": " None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 59944, "code": " Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool):", "label": 0}, {"snippet_id": 12185, "code": "\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) repository=data[\"repository\"] after_commit_hash=data[\"after_commit_hash\"] author=data[\"author\"] py_files=get_python_files_involved_in_pr(data) for file in py_files", "label": 0}, {"snippet_id": 133, "code": " ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry)", "label": 0}, {"snippet_id": 52521, "code": ", f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f", "label": 0}, {"snippet_id": 23486, "code": ".error(\"{0} is a system user. Will not delete it.\", username) shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username", "label": 0}, {"snippet_id": 5637, "code": " in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors", "label": 0}, {"snippet_id": 57900, "code": " for i in data.get('run', '').split(',') if i] if not run_ids: return say_no('No runs selected.') runs=TestCaseRun.objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun found.'", "label": 0}, {"snippet_id": 12685, "code": "\"https://api.github.com/repos/{}/issues/{}/comments\" query=query.format(data[\"repository\"], str(data[\"pr_number\"])) comments=requests.get(query, headers=headers, auth=auth).json() last_comment_id=None for", "label": 0}, {"snippet_id": 40567, "code": " value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A", "label": 1}, {"snippet_id": 68879, "code": " AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT,", "label": 0}, {"snippet_id": 68582, "code": ", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self", "label": 0}, {"snippet_id": 24320, "code": " cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components", "label": 0}, {"snippet_id": 36621, "code": ", wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string", "label": 0}, {"snippet_id": 87087, "code": ".execution_strategy==self.HERMETIC: try: fast_relpath(self.get_options().pants_workdir, get_buildroot()) except ValueError: raise TaskError( \"Hermetic zinc execution currently requires the workdir to be a child of the", "label": 0}, {"snippet_id": 81705, "code": ",codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] ", "label": 0}, {"snippet_id": 67872, "code": ".get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) if hasattr(eh, 'post'): eh", "label": 0}, {"snippet_id": 5654, "code": "=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify", "label": 0}, {"snippet_id": 37868, "code": " _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None", "label": 0}, {"snippet_id": 50004, "code": ".resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\")", "label": 0}, {"snippet_id": 58935, "code": " test_update_case_priority(self): self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { 'target_field': 'priority', 'from_plan': self", "label": 0}, {"snippet_id": 19172, "code": " are supported. \"\"\" request=normalize_request(raw_request) with ErrorDict() as errors: try: validate_request( request=request, schema=schema, ) except ValidationError as err: errors['request'].add_error", "label": 0}, {"snippet_id": 10498, "code": " This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from", "label": 1}, {"snippet_id": 35275, "code": "\"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments", "label": 0}, {"snippet_id": 60997, "code": " eigh import openqml as qm from openqml import Device, DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian", "label": 0}, {"snippet_id": 85751, "code": ", toolname): scope=instance.options_scope return instance.tool_classpath_from_products(self._products, toolname, scope=scope) classpaths=(cp(java_options_src, 'javac-plugin-dep') + cp(scala_options_src", "label": 0}, {"snippet_id": 22886, "code": ", chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin':{0}\".format(output) ) self._save_sys_config() return ret def del_account(self, username): \"\"\"Deletes a user account. Note", "label": 0}, {"snippet_id": 2470, "code": ": self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self.session_name) else: self.logger.info('starting new session", "label": 0}, {"snippet_id": 67015, "code": "(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]", "label": 0}, {"snippet_id": 74131, "code": "=blosc_shuffle_mode_int else: raise ValueError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode must be a valid integer.\") else: raise TypeError(\"Invalid value for blosc_shuffle_mode", "label": 0}, {"snippet_id": 70476, "code": " from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine", "label": 0}, {"snippet_id": 59762, "code": " reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends", "label": 0}, {"snippet_id": 72817, "code": " numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The", "label": 1}, {"snippet_id": 64324, "code": " remote_path[ 0:-len( \".dat\")] return local_dataset_path.with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self", "label": 0}, {"snippet_id": 41666, "code": " except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self.rule)", "label": 0}, {"snippet_id": 39207, "code": ") if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile", "label": 0}, {"snippet_id": 27769, "code": " elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >", "label": 0}, {"snippet_id": 63459, "code": "=job_wrapper.job_id if hasattr(job_wrapper, 'task_id'): job_id=\"%s_%s\" %(job_id, job_wrapper.task_id) params=job_wrapper.job_destination.params.copy() for key, value in params.iteritems(): if value: params", "label": 0}, {"snippet_id": 92924, "code": "=tmp_stderr.fileno(), stdin_fd=tmp_stdin.fileno()): self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(stdin_data,", "label": 0}, {"snippet_id": 43394, "code": " wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards", "label": 0}, {"snippet_id": 79085, "code": "\t\t\t\tself.codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t\t\telse: \t\t\t\tself.logger.warning(\"Code execution detection will not be possible as there is no path nor regex pattern configured.\"", "label": 0}, {"snippet_id": 61423, "code": ".wires, dtype=complex) self._state[0]=1 self._out=np.full(self.wires, np.nan) for operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1", "label": 0}, {"snippet_id": 46749, "code": "\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring", "label": 0}, {"snippet_id": 69630, "code": ".__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system.\" def execute(self): if not self.opt_m:", "label": 0}, {"snippet_id": 10240, "code": " filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"", "label": 0}, {"snippet_id": 5261, "code": "{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches", "label": 0}, {"snippet_id": 38206, "code": " snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG", "label": 0}, {"snippet_id": 77434, "code": ": break try: if type_==0: w=workers.WZWorkerThread( self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1", "label": 0}, {"snippet_id": 63483, "code": ", value) env=getattr( job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params", "label": 0}, {"snippet_id": 37919, "code": " if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule", "label": 0}, {"snippet_id": 40131, "code": " os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self", "label": 0}, {"snippet_id": 52795, "code": ".output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output", "label": 0}, {"snippet_id": 73017, "code": " ftplib.FTP :type local_directory: str :type remote_directory: str :type remote_subdirs_list: list \"\"\" if(remote_subdirs_list is not None) and(len(remote_subdirs_list) > 0): remote_path_relative=\"/\".join", "label": 0}, {"snippet_id": 84971, "code": " fingerprint=True, help='Map from scalac plugin name to list of arguments for that plugin.') cls.register_jvm_tool(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well", "label": 0}, {"snippet_id": 47751, "code": ": def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring", "label": 0}, {"snippet_id": 34646, "code": " def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self", "label": 1}, {"snippet_id": 37208, "code": " branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def", "label": 0}, {"snippet_id": 34104, "code": " isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule", "label": 0}, {"snippet_id": 80418, "code": " no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds", "label": 0}, {"snippet_id": 58831, "code": ".pk).case_run_status.name) class TestGetForm(test.TestCase): \"\"\"Test case for form\"\"\" def test_get_form(self): response=self.client.get(reverse('ajax-form'), {'app_form': 'testcases.CaseAutomatedForm'}", "label": 1}, {"snippet_id": 9504, "code": " '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output", "label": 0}, {"snippet_id": 22883, "code": "=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for 'admin':{0}\".format(output) ) self._save_sys_config() return ret def del_account(self", "label": 0}, {"snippet_id": 4833, "code": " single_keywords_p: categories[w[0].concept]=w[0].type complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={", "label": 0}, {"snippet_id": 13139, "code": ", headers=headers, auth=auth) ATTEMPT=0 while(r.status_code !=200): time.sleep(5) r=requests.get(url, headers=headers, auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than", "label": 0}, {"snippet_id": 68628, "code": "(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif", "label": 0}, {"snippet_id": 10503, "code": "\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener", "label": 1}, {"snippet_id": 6139, "code": "'\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in", "label": 1}, {"snippet_id": 37520, "code": " SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output)", "label": 0}, {"snippet_id": 17097, "code": ": response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return", "label": 1}, {"snippet_id": 84297, "code": ".path.basename(path)), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']", "label": 0}, {"snippet_id": 27997, "code": " elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data[", "label": 0}, {"snippet_id": 31376, "code": ") self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input", "label": 0}, {"snippet_id": 71231, "code": "(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if", "label": 0}, {"snippet_id": 50158, "code": ".included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir", "label": 0}, {"snippet_id": 17409, "code": ".join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR", "label": 0}, {"snippet_id": 43591, "code": " os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake", "label": 0}, {"snippet_id": 14429, "code": ") else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive", "label": 0}, {"snippet_id": 15615, "code": "._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request", "label": 0}, {"snippet_id": 90924, "code": ".global_instance()._locator().locate( minimum_version=minimum_version, maximum_version=maximum_version, jdk=jdk) except _Locator.Error as e: raise cls.Error('Problem locating a java distribution:{}'.format", "label": 0}, {"snippet_id": 51271, "code": "\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 6849, "code": "],], .. } or empty{} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number", "label": 0}, {"snippet_id": 7389, "code": " ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return ", "label": 0}, {"snippet_id": 92135, "code": " exactly['current']. Bad targets: {} \"\"\".format('\\n'.join(sorted(target.address.reference() for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope='build-setup-requires", "label": 0}, {"snippet_id": 83394, "code": ") job_id=lwr_submit_job(client, client_job_description, remote_job_config) log.info(\"lwr job submitted with job_id %s\" % job_id) job_wrapper.set_job_destination( job_destination, job_id) job_wrapper.change_state", "label": 0}, {"snippet_id": 2410, "code": "=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self.server", "label": 0}, {"snippet_id": 16984, "code": "( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest", "label": 0}, {"snippet_id": 3268, "code": "(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red\") deps.view() class SlaveLauncher: def __init__(self, configfile=None, kill_mode", "label": 0}, {"snippet_id": 28960, "code": "%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status", "label": 0}, {"snippet_id": 60414, "code": ".quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self.observe.params", "label": 0}, {"snippet_id": 58592, "code": ".objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self.assertEqual(new_comment, comments[0].comment) self.assertEqual(self.tester, comments[0].user) class TestUpdateObject(BasePlanCase): \"", "label": 0}, {"snippet_id": 78675, "code": " def run(self): try: if self.options is not None and self.options.daemon: log.logger.debug('Executing remotely') return self.executer(*sys.argv) log.logger.debug('Executing locally') return self.execute", "label": 1}, {"snippet_id": 55305, "code": ": items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs", "label": 0}, {"snippet_id": 35387, "code": "**wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard", "label": 0}, {"snippet_id": 43979, "code": " printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False", "label": 0}, {"snippet_id": 48286, "code": "(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output", "label": 0}, {"snippet_id": 59776, "code": " the quantum state is reset to its initial value. \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable", "label": 0}, {"snippet_id": 87021, "code": " implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. \"\"\" return self.get_options()", "label": 0}, {"snippet_id": 35491, "code": " dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\"", "label": 0}, {"snippet_id": 95741, "code": "=pathlib.Path(temp_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_temp: path_temp_str=str(path) filename_str=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move", "label": 0}, {"snippet_id": 40071, "code": " self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re", "label": 1}, {"snippet_id": 45055, "code": "=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate", "label": 0}, {"snippet_id": 64721, "code": " client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc", "label": 1}, {"snippet_id": 15110, "code": ".raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ ", "label": 0}, {"snippet_id": 35177, "code": "\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value", "label": 0}, {"snippet_id": 73687, "code": " def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False class ConfigurationRepresentation(object", "label": 0}, {"snippet_id": 15206, "code": " ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd", "label": 0}, {"snippet_id": 52167, "code": "<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\"", "label": 0}, {"snippet_id": 88330, "code": " context include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated with. :API: public \"\"\" class Log", "label": 0}, {"snippet_id": 37114, "code": "=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion", "label": 1}, {"snippet_id": 81203, "code": "\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \") \t\t\t", "label": 0}, {"snippet_id": 8736, "code": "**kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode", "label": 0}, {"snippet_id": 83131, "code": " configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when", "label": 0}, {"snippet_id": 28953, "code": "'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'", "label": 0}, {"snippet_id": 78480, "code": " user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum)) found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page))) for t in found: if(t in self.pc.sets['closed'] or t in self.pc", "label": 1}, {"snippet_id": 86463, "code": ".backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from pants.backend.jvm.subsystems.zinc import Zinc from pants.backend.jvm.targets", "label": 0}, {"snippet_id": 33482, "code": " subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 55898, "code": " return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads", "label": 0}, {"snippet_id": 38352, "code": " config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values", "label": 0}, {"snippet_id": 38651, "code": ".__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items))", "label": 0}, {"snippet_id": 3763, "code": " kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter", "label": 0}, {"snippet_id": 58627, "code": "(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): self.client.login( username=self.tester.username, password='password') remove_perm_from_user(self", "label": 0}, {"snippet_id": 95259, "code": " import numpy as np import zarr import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for", "label": 1}, {"snippet_id": 30097, "code": " name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\"", "label": 0}, {"snippet_id": 45142, "code": "*logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate", "label": 0}, {"snippet_id": 57595, "code": ".user try: mailto(**mail_context) except Exception: pass def _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you", "label": 0}, {"snippet_id": 52508, "code": "\".format(str(ex)), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self", "label": 0}, {"snippet_id": 30392, "code": "(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into", "label": 0}, {"snippet_id": 38249, "code": ".persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(", "label": 0}, {"snippet_id": 32296, "code": " _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards", "label": 0}, {"snippet_id": 79099, "code": " detection will not be possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd:", "label": 0}, {"snippet_id": 69875, "code": ": result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self", "label": 0}, {"snippet_id": 9287, "code": " style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style. This is the main routing call, this function will", "label": 0}, {"snippet_id": 51757, "code": " A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False", "label": 0}, {"snippet_id": 66364, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from", "label": 0}, {"snippet_id": 31489, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError,", "label": 0}, {"snippet_id": 44799, "code": ": self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules", "label": 0}, {"snippet_id": 4422, "code": " codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords", "label": 0}, {"snippet_id": 94459, "code": " else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState", "label": 0}, {"snippet_id": 13788, "code": "['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds", "label": 0}, {"snippet_id": 64665, "code": " from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler", "label": 0}, {"snippet_id": 69197, "code": " def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s", "label": 0}, {"snippet_id": 84386, "code": ".local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config.working_directory()) self", "label": 0}, {"snippet_id": 37994, "code": " lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards -", "label": 0}, {"snippet_id": 61500, "code": " if self.shots==0: ev=self.ev(A,[self._observe.wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self._observe.wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self.shots)) else", "label": 0}, {"snippet_id": 39771, "code": " f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None self.threads=None", "label": 0}, {"snippet_id": 33785, "code": " done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats", "label": 0}, {"snippet_id": 2649, "code": " if node is not master_node: dep_string=\"%s -> %s\" %(dep_string, node.comp_name) self.logger.debug(\"Dependency tree for start all: %s\" % dep_string) except CircularReferenceException as ex: self.logger", "label": 0}, {"snippet_id": 54326, "code": "=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class", "label": 0}, {"snippet_id": 65868, "code": " t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0:", "label": 0}, {"snippet_id": 50860, "code": ".path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self", "label": 1}, {"snippet_id": 37118, "code": "=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError:", "label": 1}, {"snippet_id": 92596, "code": ") as f: self.assertTrue(os.path.realpath(f.name).startswith(os.path.realpath(path)), 'file should be created in root_dir if specified.') def test_temporary_dir_no_args(self): with temporary_dir() as path", "label": 0}, {"snippet_id": 12510, "code": "[file])) comment_body.append(\"---\\n\\n\") if config[\"only_mention_files_with_errors\"] and not ERROR: comment_body.append(\"Cheers ! There are no PEP8 issues in this Pull Request.:beers: \") comment_body=''", "label": 0}, {"snippet_id": 6104, "code": ") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1", "label": 0}, {"snippet_id": 40003, "code": "(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as", "label": 0}, {"snippet_id": 86127, "code": "}\\n'.format(processor.strip())) def execute(self): if JvmPlatform.global_instance().get_options().compiler=='javac': return super(JavacCompile, self).execute() def compile(self, ctx, args, dependency_classpath", "label": 0}, {"snippet_id": 68338, "code": "\"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs", "label": 0}, {"snippet_id": 51083, "code": ".search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self", "label": 0}, {"snippet_id": 75225, "code": " method)]=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method)]=fun def del_req_handler", "label": 0}, {"snippet_id": 44891, "code": "=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance", "label": 0}, {"snippet_id": 29403, "code": ".rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile", "label": 1}, {"snippet_id": 40025, "code": " function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def", "label": 1}, {"snippet_id": 53364, "code": " in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion", "label": 1}, {"snippet_id": 48301, "code": "(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files", "label": 0}, {"snippet_id": 76883, "code": " def terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler) signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net=sup.net.RequestPerformer", "label": 0}, {"snippet_id": 43186, "code": " function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item]", "label": 0}, {"snippet_id": 70647, "code": " target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self", "label": 0}, {"snippet_id": 24892, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self", "label": 0}, {"snippet_id": 34352, "code": " return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self", "label": 0}, {"snippet_id": 95981, "code": "=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt", "label": 0}, {"snippet_id": 21892, "code": " import plugin import jinja2 import os import subprocess display=Display() class Options(object): def __init__(self, verbosity=None, inventory=None, listhosts=None, subset=None, module_paths=None, extra_vars", "label": 1}, {"snippet_id": 71789, "code": " run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except", "label": 0}, {"snippet_id": 65173, "code": "(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start", "label": 0}, {"snippet_id": 71224, "code": ".dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target", "label": 0}, {"snippet_id": 90274, "code": " java_home=env_home('JAVA_HOME') if java_home: yield java_home search_path=os.environ.get('PATH') if search_path: for bin_path in search_path.strip().split(os.pathsep): yield self.Location.from_bin(bin_path)", "label": 0}, {"snippet_id": 77978, "code": " protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu(urls): for user", "label": 0}, {"snippet_id": 4227, "code": "=only_core_tags, extract_acronyms=extract_acronyms ) if api: return output else: if isinstance(output, dict): for i in output: print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.", "label": 0}, {"snippet_id": 21461, "code": ") with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) else: print(\"Reddytt: Working directory found. Loading variables.\") with open(seen_file, 'rb') as f: seen_links=pickle.load(f) with open", "label": 0}, {"snippet_id": 76894, "code": " signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net=sup.net.RequestPerformer() net.proxy=proxy if proxytype=='HTTP' or proxytype=='HTTPS': net.proxy_type=sup.proxytype", "label": 0}, {"snippet_id": 26694, "code": " self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560:", "label": 0}, {"snippet_id": 19583, "code": " elif arg=='--nodebug': supported.append(arg) elif arg in('--host', '--server-host', '--port', '-m'): if arg=='-m': gottarget=True supported.append(arg) if nextarg is not None: supported.append(nextarg", "label": 0}, {"snippet_id": 93807, "code": "=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0][", "label": 0}, {"snippet_id": 25283, "code": "'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema", "label": 1}, {"snippet_id": 39630, "code": " ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 93352, "code": " component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'", "label": 0}, {"snippet_id": 23592, "code": "(self): return self._get_net_info()[:2] def route_add(self, net, mask, gateway): cmd='route add{0}{1}{2}'.format(net, gateway, mask) return shellutil.run(cmd, chk_err=False) def is_missing_default_route", "label": 0}, {"snippet_id": 37974, "code": " False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format", "label": 0}, {"snippet_id": 43474, "code": " of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder", "label": 0}, {"snippet_id": 87383, "code": " ctx.classes_dir) self._verify_zinc_classpath(absolute_classpath, allow_dist=(self.execution_strategy !=self.HERMETIC)) self._verify_zinc_classpath(upstream_analysis.keys()) def relative_to_exec_root(path", "label": 0}, {"snippet_id": 17118, "code": " _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'", "label": 0}, {"snippet_id": 33738, "code": ") logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources", "label": 0}, {"snippet_id": 26558, "code": "._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self", "label": 0}, {"snippet_id": 81968, "code": "=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override", "label": 0}, {"snippet_id": 37822, "code": " None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join", "label": 0}, {"snippet_id": 670, "code": "'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect", "label": 0}, {"snippet_id": 63038, "code": " self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url=galaxy_url self.client_manager=build_client_manager(", "label": 0}, {"snippet_id": 65983, "code": " status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count", "label": 0}, {"snippet_id": 93181, "code": "(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname", "label": 0}, {"snippet_id": 10205, "code": "(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION", "label": 0}, {"snippet_id": 81022, "code": " \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code ", "label": 0}, {"snippet_id": 71625, "code": "=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\"", "label": 0}, {"snippet_id": 69718, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs", "label": 0}, {"snippet_id": 83879, "code": " attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid", "label": 0}, {"snippet_id": 6105, "code": "\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)", "label": 0}, {"snippet_id": 43308, "code": " ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log, self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards", "label": 0}, {"snippet_id": 51217, "code": ": try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 65266, "code": " self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset", "label": 0}, {"snippet_id": 94946, "code": ".required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config", "label": 0}, {"snippet_id": 51005, "code": ".\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file", "label": 0}, {"snippet_id": 46572, "code": "+add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__", "label": 0}, {"snippet_id": 81629, "code": "\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None", "label": 0}, {"snippet_id": 55762, "code": "): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0", "label": 0}, {"snippet_id": 91238, "code": ".python.tasks.isort_run import IsortRun from pants.backend.python.tasks.local_python_distribution_artifact import \\ LocalPythonDistributionArtifact from pants.backend.python.tasks.pytest_prep import PytestPrep", "label": 0}, {"snippet_id": 7160, "code": ", composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. ", "label": 0}, {"snippet_id": 90778, "code": " minimum_version, maximum_version, jdk)) return dist except(ValueError, Distribution.Error) as e: logger.debug('{} is not a valid distribution because:{}' .format(location.home_path, str(e))) pass if(minimum_version", "label": 0}, {"snippet_id": 39271, "code": ") snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included", "label": 0}, {"snippet_id": 25761, "code": " self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 53155, "code": " from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name ", "label": 0}, {"snippet_id": 35038, "code": " f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards", "label": 0}, {"snippet_id": 50916, "code": " def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError", "label": 0}, {"snippet_id": 62670, "code": " Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset", "label": 0}, {"snippet_id": 74149, "code": " not be converted to integer.\") benchmark_data_input_types=[\"vcf\", \"zarr\"] class BenchmarkConfigurationRepresentation: \"\"\" Utility class for object representation of the benchmark module's configuration", "label": 0}, {"snippet_id": 2741, "code": " send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Stopping remote component '%s' on host", "label": 0}, {"snippet_id": 26209, "code": "', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer',", "label": 0}, {"snippet_id": 19722, "code": "(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')) else: args.address=Address.as_client(clienthost, ns.pop('port')) module=ns.pop('module') filename=ns.pop('filename'", "label": 0}, {"snippet_id": 61524, "code": ".shots)) else: a, P=spectral_decomposition_qubit(A) p0=self.ev(P[0], self._observe.wires) n0=np.random.binomial(self.shots, p0) ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod", "label": 0}, {"snippet_id": 87016, "code": " incremental(self): \"\"\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir for a target into the new results_dir for a target. ", "label": 0}, {"snippet_id": 31121, "code": ") if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self", "label": 0}, {"snippet_id": 51095, "code": ": return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return", "label": 0}, {"snippet_id": 9070, "code": " only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords", "label": 0}, {"snippet_id": 58242, "code": " tcms.management.models import EnvProperty from tcms.testcases.forms import CaseAutomatedForm from tcms.testcases.forms import TestCase from tcms.testplans.models import TestPlan from tcms.testruns.models", "label": 1}, {"snippet_id": 83047, "code": "\t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests", "label": 0}, {"snippet_id": 35277, "code": " dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first", "label": 0}, {"snippet_id": 94262, "code": ".config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window", "label": 0}, {"snippet_id": 67664, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper", "label": 0}, {"snippet_id": 72014, "code": " permissions @utils.add_cmd def disconnect(irc, source, args): \"\"\"<network> Disconnects the network <network>. When all networks are disconnected, PyLink will automatically exit. To reconnect a network", "label": 0}, {"snippet_id": 86159, "code": "().capture_classpath: self._record_compile_classpath(classpath, ctx.target, ctx.classes_dir) try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator", "label": 0}, {"snippet_id": 31132, "code": " omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark", "label": 0}, {"snippet_id": 92993, "code": ": with self._stdio_as_tempfiles(): pass self.assertEqual(sys.stdin.fileno(), 0) self.assertEqual(sys.stdout.fileno(), 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout", "label": 0}, {"snippet_id": 35928, "code": "<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\"", "label": 0}, {"snippet_id": 77724, "code": ".sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def targets_from_witch(self): for t in d.witch_targets: if t['domain']=='beon.ru' and t['forum']=='anonymous", "label": 0}, {"snippet_id": 92220, "code": " import next, object, range, str from contextlib import contextmanager import mock from future.utils import PY3 from pants.util.contextutil import(InvalidZipPath, Timer, environment_as, exception_logging", "label": 0}, {"snippet_id": 76215, "code": ".success: self.log.debug('Route unbinded for(%s, %s)', i, m) else: self.log.warn('Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_unbind_route_data(i", "label": 0}, {"snippet_id": 73644, "code": " numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1'", "label": 0}, {"snippet_id": 92794, "code": " allowZip64=True) as zf: self.assertTrue(zf._allowZip64) def test_open_zipFalse(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=False) as zf: self.assertFalse", "label": 0}, {"snippet_id": 86904, "code": " dict of option regexes that make up pants\\' supported API for zinc. ' 'Options not listed here are subject to change/removal. The value of the dict ' 'indicates that an option accepts an argument.') register", "label": 0}, {"snippet_id": 95483, "code": "+remote_path_relative +\"/\" else: remote_subdirs_list=[] remote_path_relative=\"\" remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative os.mkdir(local_path) print", "label": 0}, {"snippet_id": 46222, "code": " with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the", "label": 0}, {"snippet_id": 18166, "code": " ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification", "label": 0}, {"snippet_id": 87716, "code": "._scheduler.materialize_directories(( DirectoryToMaterialize(get_buildroot(), res.output_directory_digest), )) return res.output_directory_digest else: if self.runjava(classpath=[self._zinc.zinc], main", "label": 0}, {"snippet_id": 44305, "code": " subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake", "label": 0}, {"snippet_id": 2034, "code": "[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e',", "label": 0}, {"snippet_id": 70791, "code": ".state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[", "label": 0}, {"snippet_id": 72781, "code": " the server, runs the benchmarks, and records the timer results. \"\"\" import urllib.request from ftplib import FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib", "label": 0}, {"snippet_id": 84803, "code": "'major_version_info',['full_version']) scala_build_info={ '2.10': major_version_info(full_version='2.10.6'), '2.11': major_version_info(full_version='2.11.12'), '2.12': major_version_info(full_version='2.12.4'), ", "label": 0}, {"snippet_id": 93647, "code": ", res, unres) for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node", "label": 0}, {"snippet_id": 2022, "code": " processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action", "label": 0}, {"snippet_id": 9501, "code": ") return '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify", "label": 0}, {"snippet_id": 57917, "code": ".objects.filter(pk__in=run_ids).only('pk') if not runs: return say_no('No caserun found.') add_comment(runs, comment, request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data", "label": 0}, {"snippet_id": 3552, "code": ".session, self.logger) exit(check_state.value) def run_component_check(comp): if call(comp['cmd'][1]['check'], shell=True)==0: return True else: return False def check_component(comp, session, logger):", "label": 0}, {"snippet_id": 20942, "code": ") def _listen(self): try: for msg in self._conn.iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except EOFError: try: self.close() except ClosedError: pass def _receive_message", "label": 1}, {"snippet_id": 73712, "code": " small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): \"\"\" Initializes the configuration representation with a supplied file. \"\"\" parser=ConfigParser", "label": 0}, {"snippet_id": 79102, "code": " possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd", "label": 0}, {"snippet_id": 57293, "code": "=request.user: t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update", "label": 0}, {"snippet_id": 36297, "code": " omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from", "label": 1}, {"snippet_id": 57388, "code": " value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=", "label": 0}, {"snippet_id": 89489, "code": ", maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param string home_path: the path to", "label": 0}, {"snippet_id": 90652, "code": "(minimum_version, self._minimum_version, \"minimum_version\", max) maximum_version=_get_stricter_version(maximum_version, self._maximum_version, \"maximum_version\", min) key=(minimum_version, maximum_version,", "label": 0}, {"snippet_id": 68795, "code": " layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, ", "label": 0}, {"snippet_id": 91953, "code": " native source files in `python_dist()` sources.') @classmethod def subsystem_dependencies(cls): return super(PythonNativeCode, cls).subsystem_dependencies() +( NativeToolchain.scoped(cls), PythonSetup, )", "label": 0}, {"snippet_id": 638, "code": " elif action=='getDockerOverview': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[]", "label": 0}, {"snippet_id": 70732, "code": ".status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets", "label": 1}, {"snippet_id": 27454, "code": " self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property", "label": 0}, {"snippet_id": 38316, "code": "] self.included_stack=[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config", "label": 0}, {"snippet_id": 15865, "code": ".server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object", "label": 0}, {"snippet_id": 40437, "code": " first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group", "label": 0}, {"snippet_id": 61110, "code": " theta/2 * X) def fry(theta): r\"\"\"One-qubit rotation about the y axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm(-1j *", "label": 0}, {"snippet_id": 24497, "code": ".\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from", "label": 0}, {"snippet_id": 95205, "code": "\" import time import csv import logging def run_benchmark(bench_conf): pass def run_dynamic(ftp_location): pass def run_static(): pass def get_remote_files(ftp_server, ftp_directory, files=None): pass def", "label": 1}, {"snippet_id": 82504, "code": "=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print(\"\"\"\\033[1;32m ___ _ _ _ | _|_ _ _ _", "label": 0}, {"snippet_id": 19657, "code": "-host') parser.add_argument('--port', type=int, required=True) target=parser.add_mutually_exclusive_group(required=True) target.add_argument('-m', dest='module') target.add_argument('filename', nargs='?'", "label": 0}, {"snippet_id": 75727, "code": " s.setsockopt(zmq.SUBSCRIBE, b'WZWorker') s.setsockopt(zmq.SUBSCRIBE, bytes(self.name, 'utf-8')) self.sig_sock=s s=self.ctx.socket(zmq.DEALER) self.poller.register(s, zmq.POLLIN) s.setsockopt(zmq.IPV6,", "label": 0}, {"snippet_id": 7069, "code": " extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning", "label": 0}, {"snippet_id": 92254, "code": " subprocess PATCH_OPTS=dict(autospec=True, spec_set=True) class ContextutilTest(unittest.TestCase): def test_empty_environment(self): with environment_as(): pass def test_override_single_variable(self): with", "label": 0}, {"snippet_id": 66414, "code": " node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info:", "label": 0}, {"snippet_id": 42922, "code": "(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else:", "label": 0}, {"snippet_id": 95961, "code": " conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout)", "label": 0}, {"snippet_id": 80625, "code": " Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName)", "label": 0}, {"snippet_id": 72571, "code": " modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\", metavar=\"RUN_LABEL\", help=\"Label for the benchmark run.\") benchmark_exec_parser.add_argument", "label": 1}, {"snippet_id": 68606, "code": " disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type", "label": 0}, {"snippet_id": 42658, "code": " self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\"", "label": 0}, {"snippet_id": 30034, "code": ".start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names", "label": 0}, {"snippet_id": 25769, "code": "'windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\"", "label": 0}, {"snippet_id": 48062, "code": "(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return", "label": 0}, {"snippet_id": 51465, "code": " flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain", "label": 0}, {"snippet_id": 11947, "code": "[], \"exclude\":[], \"select\":[], \"show-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors\": True, } headers={\"Authorization\": \"token ", "label": 0}, {"snippet_id": 47352, "code": " when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill", "label": 0}, {"snippet_id": 89180, "code": " in the graph, but any dependencies of targets parsed in the root tree's BUILD files will be followed and this may lead to BUILD files outside of ``root`` being parsed and included in the returned build", "label": 0}, {"snippet_id": 72163, "code": "('network') remote_parser.add_argument('--service', type=str, default='pylink') remote_parser.add_argument('command', nargs=utils.IRCParser.REMAINDER) @utils.add_cmd def remote(irc, source, args): \"\"\"<network", "label": 0}, {"snippet_id": 10414, "code": " tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return", "label": 0}, {"snippet_id": 34160, "code": ".func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo):", "label": 0}, {"snippet_id": 44729, "code": " self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess", "label": 0}, {"snippet_id": 59653, "code": " for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range", "label": 0}, {"snippet_id": 19488, "code": " args, extra def _group_args(argv): supported=[] pydevd=[] script=[] try: pos=argv.index('--') except ValueError: script=[] else: script=argv[pos +1:] argv=argv[:pos] for arg in argv: if arg=='-h' or arg==", "label": 0}, {"snippet_id": 54275, "code": ".get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given", "label": 0}, {"snippet_id": 13302, "code": ": file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate()", "label": 0}, {"snippet_id": 34780, "code": " self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file if self._is_function: f=self", "label": 0}, {"snippet_id": 29393, "code": "(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard", "label": 1}, {"snippet_id": 77793, "code": "], frames[2], frames[3:])) self.th_sock.send_multipart(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self.log=parent.log self.inter_sleep=parent.inter_sleep self.running", "label": 0}, {"snippet_id": 91566, "code": ".compatibility_or_constraints( getattr(target_adaptor, 'compatibility', None) ) } constraints_args=[] for constraint in sorted(constraints): constraints_args.extend([\"--interpreter-constraint\", text_type(constraint", "label": 0}, {"snippet_id": 90256, "code": "(self): def env_home(home_env_var): home=os.environ.get(home_env_var) return self.Location.from_home(home) if home else None jdk_home=env_home('JDK_HOME') if jdk_home: yield jdk_home java_home=env_home", "label": 0}, {"snippet_id": 12519, "code": " not ERROR: comment_body.append(\"Cheers ! There are no PEP8 issues in this Pull Request.:beers: \") comment_body=''.join(comment_body) comment_footer=[] if request.json[\"action\"]==\"opened\": comment_footer", "label": 0}, {"snippet_id": 77456, "code": " self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'pr{0}'.format(i)))) self.processes.append(w) w.start(self.pr_sa) except Exception as e:", "label": 0}, {"snippet_id": 34, "code": " from flask import escape from.models import BoxDetails, RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os", "label": 1}, {"snippet_id": 10500, "code": " STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils", "label": 1}, {"snippet_id": 61766, "code": ") if np.any(wires < 0) or np.any(wires >=self.wires) or wires[0]==wires[1]: raise ValueError('Bad target subsystems.') a=np.min(wires) b=np.max(wires) n_between=b-a-1 before =2**a after =2**(self.wires", "label": 0}, {"snippet_id": 48147, "code": " flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True,", "label": 0}, {"snippet_id": 15889, "code": "( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET", "label": 0}, {"snippet_id": 26079, "code": ") return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self", "label": 1}, {"snippet_id": 74292, "code": "=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and", "label": 0}, {"snippet_id": 25143, "code": " import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=", "label": 1}, {"snippet_id": 54887, "code": " map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse", "label": 0}, {"snippet_id": 81781, "code": " templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on", "label": 0}, {"snippet_id": 28685, "code": "': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low", "label": 0}, {"snippet_id": 27349, "code": " config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor", "label": 0}, {"snippet_id": 73099, "code": "\"/\" +file)) new_remote_subdirs_list=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory", "label": 0}, {"snippet_id": 4583, "code": ") or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken", "label": 0}, {"snippet_id": 35586, "code": ".add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an", "label": 0}, {"snippet_id": 2342, "code": " import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui", "label": 0}, {"snippet_id": 6601, "code": " file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file", "label": 1}, {"snippet_id": 85901, "code": " import WorkUnit, WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution import DistributionLocator", "label": 0}, {"snippet_id": 83815, "code": ", stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we", "label": 0}, {"snippet_id": 92508, "code": ") self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_temporary_file_no_args", "label": 0}, {"snippet_id": 85583, "code": ":type products::class:`pants.goal.products.Products` :returns: A Zinc instance with access to relevant Zinc compiler wrapper jars and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self, products) def", "label": 0}, {"snippet_id": 76517, "code": " self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx, sig_addr, *args, **kvargs): self.ctx=ctx self", "label": 0}, {"snippet_id": 3827, "code": "(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove(file_path) def ensure_dir(file_path): directory=os.path.dirname", "label": 0}, {"snippet_id": 55734, "code": "(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo", "label": 0}, {"snippet_id": 75466, "code": " self.response_handlers: return reqid def make_auth_req_data(self, interface, method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid", "label": 1}, {"snippet_id": 13359, "code": "/repos/{}/contents/{}\" url=url.format(fullname, file) params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code", "label": 0}, {"snippet_id": 69103, "code": "\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.umount() rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0:", "label": 0}, {"snippet_id": 40845, "code": " wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if", "label": 0}, {"snippet_id": 53772, "code": " start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have", "label": 0}, {"snippet_id": 25805, "code": " data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self", "label": 0}, {"snippet_id": 58321, "code": ".com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses(self): self.client.login( username=self.user.username, password='testing') response=self.client.get(reverse(", "label": 0}, {"snippet_id": 13024, "code": "\"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(url, headers=headers, auth=auth) for repo in r.json(): if repo[\"description\"]: if data[", "label": 0}, {"snippet_id": 71661, "code": ".CommandRegistry import CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from", "label": 0}, {"snippet_id": 53182, "code": " self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set()", "label": 0}, {"snippet_id": 63106, "code": " if lwr_status==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING", "label": 0}, {"snippet_id": 66681, "code": "*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s ", "label": 0}, {"snippet_id": 11913, "code": ": \"\"\" Get.pep8speaks.yml config file from the repository and return the config dictionary \"\"\" config={ \"message\":{ \"opened\":{ \"header\": \"\", \"footer\": \"\" }, \"updated\":{ \"header\": \"\", \"footer\": \"\" } }, \"scanner", "label": 0}, {"snippet_id": 32640, "code": "\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self", "label": 0}, {"snippet_id": 90266, "code": ".from_home(home) if home else None jdk_home=env_home('JDK_HOME') if jdk_home: yield jdk_home java_home=env_home('JAVA_HOME') if java_home: yield java_home search_path=os.environ.get('PATH') if search_path", "label": 0}, {"snippet_id": 81560, "code": ".logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False", "label": 0}, {"snippet_id": 80540, "code": "-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds[\"username\"] \t\tproxyPass=args.proxyCreds[\"password\"] \telse: \t\tproxyUser=args.proxy", "label": 0}, {"snippet_id": 90069, "code": ": key, _, val=line.partition('=') props[key]=val self._system_properties=props return self._system_properties def _validate_executable(self, name): def bin_paths(): yield self._bin_path if self._is_jdk", "label": 0}, {"snippet_id": 25995, "code": "['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status", "label": 0}, {"snippet_id": 33986, "code": "(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile", "label": 0}, {"snippet_id": 9689, "code": " acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches", "label": 0}, {"snippet_id": 80343, "code": "-regex.\") if args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args", "label": 0}, {"snippet_id": 27673, "code": "._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280", "label": 0}, {"snippet_id": 51044, "code": " IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self", "label": 1}, {"snippet_id": 84368, "code": " __init__( self, lwr_client, job_wrapper, remote_job_config): self.lwr_client=lwr_client self.job_wrapper=job_wrapper self.local_path_config=job_wrapper.default_compute_environment() self.unstructured_path_rewrites", "label": 0}, {"snippet_id": 15947, "code": " method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri", "label": 1}, {"snippet_id": 35852, "code": " \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file", "label": 0}, {"snippet_id": 87361, "code": "(self, ctx, args, dependency_classpath, upstream_analysis, settings, compiler_option_sets, zinc_file_manager, javac_plugin_map, scalac_plugin_map): absolute_classpath=(ctx.classes_dir,) +tuple(ce.path for", "label": 0}, {"snippet_id": 25842, "code": "%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength", "label": 0}, {"snippet_id": 21616, "code": " from sklearn.preprocessing import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix", "label": 0}, {"snippet_id": 63110, "code": ".mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update", "label": 0}, {"snippet_id": 37386, "code": " def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name", "label": 0}, {"snippet_id": 34532, "code": " import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f): return os.stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f", "label": 1}, {"snippet_id": 68814, "code": "\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout.RIGHT, \"dev size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT", "label": 0}, {"snippet_id": 52884, "code": " except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources", "label": 0}, {"snippet_id": 19823, "code": ") self._connecttimeout=connecttimeout self._adapter=None self._session=None self._breakpoints=breakpoints @property def adapter(self): return self._adapter @property def session(self): return self._session", "label": 0}, {"snippet_id": 55908, "code": ".benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources)", "label": 0}, {"snippet_id": 77648, "code": "'Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded", "label": 0}, {"snippet_id": 83928, "code": "\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode", "label": 0}, {"snippet_id": 8489, "code": " text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length", "label": 1}, {"snippet_id": 78548, "code": ".targets)==0: c=self.get_targets() if c==0: self.log.info('No targets found at all, sleeping for 30 seconds') self.long_sleep(30) self.schedule(self.comment_loop) if len(self.forums)==0: self.schedule(self", "label": 0}, {"snippet_id": 49288, "code": "\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self", "label": 0}, {"snippet_id": 92491, "code": "(tempdir1), os.getcwd()) with temporary_dir(root_dir=tempdir1) as tempdir2: with pushd(tempdir2): self.assertEqual(os.path.realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os", "label": 0}, {"snippet_id": 76427, "code": ".get(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg(self, frames): try: for nfr in self.wz.parse_router_msg(frames): self.wz_sock.send_multipart", "label": 0}, {"snippet_id": 16128, "code": " import vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers", "label": 0}, {"snippet_id": 37244, "code": " return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"", "label": 0}, {"snippet_id": 25617, "code": "=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 84626, "code": ", fingerprint=True, help='Show information about files ignored by cloc.') def console_output(self, targets): if not self.get_options().transitive: targets=self.context.target_roots input_snapshots=tuple", "label": 0}, {"snippet_id": 72565, "code": "\"FILEPATH\") benchmark_exec_parser=subparser.add_parser(\"exec\", help='Execution of the benchmark modes. It requires a configuration file.') benchmark_exec_parser.add_argument(\"--label\", type=str, default=\"run\",", "label": 1}, {"snippet_id": 59090, "code": ".projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports", "label": 0}, {"snippet_id": 81746, "code": ".5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging", "label": 0}, {"snippet_id": 80485, "code": "%s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in", "label": 0}, {"snippet_id": 92959, "code": "(0) tmp_stderr.seek(0) self.assertEqual(stdout_data, tmp_stdout.read().strip()) self.assertEqual(stderr_data, tmp_stderr.read().strip()) def test_stdio_as(self): self.assertTrue(sys.stderr.fileno() > 2", "label": 0}, {"snippet_id": 59497, "code": ") par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate", "label": 0}, {"snippet_id": 8614, "code": " output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the", "label": 0}, {"snippet_id": 2, "code": ".shortcuts import render from django.http import HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers", "label": 0}, {"snippet_id": 42056, "code": "*_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self", "label": 0}, {"snippet_id": 80775, "code": ": \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts", "label": 1}, {"snippet_id": 44718, "code": ", overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self", "label": 0}, {"snippet_id": 1659, "code": "\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User", "label": 0}, {"snippet_id": 26869, "code": "'WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle']", "label": 0}, {"snippet_id": 48045, "code": " branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"", "label": 0}, {"snippet_id": 90226, "code": "\" return cls(home_path=None, bin_path=bin_path) @abstractproperty def jvm_locations(self): \"\"\"Return the jvm locations discovered in this environment. :returns: An iterator over all discovered jvm locations", "label": 0}, {"snippet_id": 72517, "code": "\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it", "label": 0}, {"snippet_id": 65214, "code": "][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) def get_name(self): return \"start\" def get_desc(self): return \"Start file system servers.\" target_status_rc_map={", "label": 0}, {"snippet_id": 17274, "code": "._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete", "label": 1}, {"snippet_id": 27916, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self", "label": 0}, {"snippet_id": 48276, "code": " not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for", "label": 0}, {"snippet_id": 49627, "code": ".init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed", "label": 0}, {"snippet_id": 8566, "code": " %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log", "label": 1}, {"snippet_id": 65331, "code": " successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg", "label": 0}, {"snippet_id": 8209, "code": " module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE", "label": 0}, {"snippet_id": 63003, "code": " datatypes_conf.xml.\" DEFAULT_GALAXY_URL=\"http://localhost:8080\" class LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None,", "label": 0}, {"snippet_id": 35435, "code": " pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname", "label": 0}, {"snippet_id": 2356, "code": " import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging", "label": 0}, {"snippet_id": 4110, "code": " for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import", "label": 0}, {"snippet_id": 64332, "code": " remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep(", "label": 0}, {"snippet_id": 95811, "code": " with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr", "label": 0}, {"snippet_id": 18106, "code": " SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__:", "label": 0}, {"snippet_id": 64382, "code": " Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the", "label": 0}, {"snippet_id": 67642, "code": "%s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose", "label": 0}, {"snippet_id": 95986, "code": "=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read", "label": 0}, {"snippet_id": 11723, "code": " users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: query=r\"INSERT INTO Users(repository, created_at) VALUES('{}', now());\" \\ \"\".format(repository) try: cursor", "label": 0}, {"snippet_id": 82365, "code": "] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\")", "label": 0}, {"snippet_id": 76065, "code": " binded route(%s, %s)', i, m) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self", "label": 0}, {"snippet_id": 84430, "code": "._wrapper_output_paths results=[] for local_output_path in local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite( wrapper_path) results.append( self", "label": 0}, {"snippet_id": 80207, "code": " \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown", "label": 0}, {"snippet_id": 84158, "code": " dependency_resolution @staticmethod def __remote_metadata( lwr_client): remote_metadata=string_as_bool_or_none( lwr_client.destination_params.get( \"remote_metadata\", False)) return remote_metadata @staticmethod", "label": 0}, {"snippet_id": 30891, "code": ": yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self", "label": 1}, {"snippet_id": 49452, "code": ", keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources", "label": 0}, {"snippet_id": 33051, "code": " of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException()", "label": 0}, {"snippet_id": 389, "code": " return JsonResponse(serializer.data, safe=False) elif action=='getAllAPs': wifi_aps=get_allAPs() return JsonResponse(wifi_aps, safe=False) elif action=='saveUserDetails': print(action) boxname=escape(request", "label": 0}, {"snippet_id": 71069, "code": " FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", '", "label": 0}, {"snippet_id": 612, "code": "(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data", "label": 0}, {"snippet_id": 69216, "code": "): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print", "label": 0}, {"snippet_id": 69005, "code": " \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand", "label": 0}, {"snippet_id": 88722, "code": " workunit_parent=workunit_parent_ctx.__enter__() done_hook=lambda: workunit_parent_ctx.__exit__(None, None, None) else: workunit_parent=background_root_workunit done_hook=None self.run_tracker.background_worker_pool", "label": 0}, {"snippet_id": 67876, "code": "\"\" Shine `status' command classes. The status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator", "label": 0}, {"snippet_id": 31242, "code": " IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name", "label": 0}, {"snippet_id": 12318, "code": "+\"_link\"]=url.format(repository, after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"", "label": 0}, {"snippet_id": 1003, "code": "=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi':", "label": 0}, {"snippet_id": 148, "code": " wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p", "label": 1}, {"snippet_id": 20988, "code": " break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[", "label": 0}, {"snippet_id": 44497, "code": ", dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config,", "label": 0}, {"snippet_id": 18465, "code": ")): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request", "label": 0}, {"snippet_id": 67937, "code": " View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import", "label": 0}, {"snippet_id": 82273, "code": "\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name", "label": 0}, {"snippet_id": 52549, "code": " @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for", "label": 0}, {"snippet_id": 20467, "code": "=connect(addr, timeout) if cls.VERBOSE: print('connected') self=cls(sock, ownsock=True) self._addr=addr return self def __init__(self, sock, ownsock=False): super(DebugSessionConnection, self).__init__()", "label": 0}, {"snippet_id": 36190, "code": " if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards", "label": 0}, {"snippet_id": 1485, "code": " print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({", "label": 0}, {"snippet_id": 3698, "code": " CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available and run_component_check(comp): logger.debug(\"Component was not started by Hyperion, but", "label": 0}, {"snippet_id": 51156, "code": ".path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep", "label": 0}, {"snippet_id": 79424, "code": "+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime", "label": 1}, {"snippet_id": 63732, "code": " def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning", "label": 0}, {"snippet_id": 62190, "code": ".wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self): return", "label": 0}, {"snippet_id": 4765, "code": " strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var composite_keywords: list of composite keywords :var taxonomy_name: string", "label": 0}, {"snippet_id": 68211, "code": " return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other", "label": 0}, {"snippet_id": 72390, "code": " the module for changes to apply.\"\"\" permissions.checkPermissions(irc, source,['networks.reloadproto']) try: name=args[0] except IndexError: irc.error('Not enough arguments(needs 1: protocol module name)", "label": 0}, {"snippet_id": 22412, "code": "\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys config\" rc", "label": 0}, {"snippet_id": 14169, "code": ".ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import", "label": 0}, {"snippet_id": 19387, "code": "/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py \"\"\" PYDEVD_OPTS={ '--file', '--client', '--vm_type', } PYDEVD_FLAGS={ '--DEBUG', '--DEBUG_RECORD_SOCKET_READS', '--cmd", "label": 0}, {"snippet_id": 62762, "code": "'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified via the \"user\" keyword argument is", "label": 0}, {"snippet_id": 9386, "code": " complete_output=_output_complete(single_keywords_p, composite_keywords_p, author_keywords, acronyms, spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\"", "label": 0}, {"snippet_id": 30356, "code": " plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \"", "label": 0}, {"snippet_id": 94629, "code": " -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\", \"exec 1> >(exec tee -i -a '%s')\" % file, \"Enter\") window.cmd(\"send-keys\",('echo \" def clear_log(file_path): if os.path.isfile(file_path): os.remove", "label": 0}, {"snippet_id": 35479, "code": "]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if", "label": 0}, {"snippet_id": 58013, "code": "['bz_external_track']=True if request.GET.get('bz_external_track', False) else False return(data, '') def update_bugs_to_caseruns(request): \"\"\" Add one or more bugs to or remove that from\\n one or more", "label": 0}, {"snippet_id": 83468, "code": " tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters: compute_environment=LwrComputeEnvironment", "label": 0}, {"snippet_id": 53185, "code": ".workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set()", "label": 0}, {"snippet_id": 37588, "code": " name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self", "label": 0}, {"snippet_id": 80157, "code": " type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php", "label": 0}, {"snippet_id": 26458, "code": "=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class", "label": 0}, {"snippet_id": 94032, "code": " for node in res: if \"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif", "label": 0}, {"snippet_id": 30057, "code": "\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !", "label": 0}, {"snippet_id": 41006, "code": " name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index", "label": 0}, {"snippet_id": 81384, "code": ".stopThreads: \t\t\thtml=future.result()[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m", "label": 0}, {"snippet_id": 83509, "code": " job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory'], metadata_kwds=metadata_kwds, dependency_resolution=dependency_resolution", "label": 0}, {"snippet_id": 31583, "code": ".norun=False elif len(args)==1: other=args[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output", "label": 0}, {"snippet_id": 59468, "code": "\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map", "label": 1}, {"snippet_id": 46253, "code": " filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard", "label": 0}, {"snippet_id": 37167, "code": ".temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch", "label": 0}, {"snippet_id": 24689, "code": "='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 65064, "code": "%s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 21845, "code": "'relu')) classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) classifier.fit(X_train", "label": 1}, {"snippet_id": 72531, "code": " action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires", "label": 0}, {"snippet_id": 95513, "code": "(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp.nlst() file_counter=1 file_list_total=len(file_list) for file in file_list: file_path_local", "label": 0}, {"snippet_id": 36129, "code": ".dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output", "label": 0}, {"snippet_id": 13775, "code": " _safe_locals[k]=eval(k) for k, v in np.__dict__.iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop", "label": 0}, {"snippet_id": 72470, "code": " benchmark run), and config argument for where is the config file. \"\"\" logging.debug('Getting cli arguments') parser=argparse.ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser", "label": 0}, {"snippet_id": 8229, "code": " safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import", "label": 1}, {"snippet_id": 48986, "code": " < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return", "label": 0}, {"snippet_id": 89001, "code": "*kwargs): \"\"\"Selects targets in-play in this run from the target roots and their transitive dependencies. Also includes any new synthetic targets created from the target roots or their transitive dependencies", "label": 0}, {"snippet_id": 30052, "code": ".finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for", "label": 0}, {"snippet_id": 28450, "code": "(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any", "label": 0}, {"snippet_id": 75200, "code": " class WZHandler(WZBase): def __init__(self): self.req_handlers={} self.response_handlers={} self.sig_handlers={} self.iden_reqid_map=BijectiveSetMap() def set_req_handler(self, interface, method, fun)", "label": 0}, {"snippet_id": 2023, "code": "]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings", "label": 0}, {"snippet_id": 69697, "code": ".mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\" %(fs.ost_count, fs.ost_servers) print print \"Use `shine format -f %s' to initialize the file system", "label": 0}, {"snippet_id": 68009, "code": ": Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node", "label": 0}, {"snippet_id": 71931, "code": "(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler", "label": 0}, {"snippet_id": 85728, "code": ".items()) ) @memoized_method def _compiler_plugins_cp_entries(self): \"\"\"Any additional global compiletime classpath entries for compiler plugins.\"\"\" java_options_src=Java.global_instance() scala_options_src", "label": 0}, {"snippet_id": 40140, "code": " dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self", "label": 1}, {"snippet_id": 24680, "code": "\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state", "label": 0}, {"snippet_id": 1276, "code": " for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list", "label": 0}, {"snippet_id": 6247, "code": " user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try: distant_stream=urlopen(request) local_file", "label": 1}, {"snippet_id": 41160, "code": " j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self", "label": 0}, {"snippet_id": 73847, "code": ".directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config", "label": 0}, {"snippet_id": 65089, "code": ") self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node", "label": 0}, {"snippet_id": 95668, "code": ": The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf files should go :type", "label": 0}, {"snippet_id": 50724, "code": ".subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to", "label": 0}, {"snippet_id": 43909, "code": " list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources", "label": 0}, {"snippet_id": 69685, "code": ".\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers", "label": 0}, {"snippet_id": 78947, "code": " 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(", "label": 0}, {"snippet_id": 47865, "code": ") self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources", "label": 0}, {"snippet_id": 53792, "code": " files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for", "label": 0}, {"snippet_id": 69835, "code": " print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.", "label": 0}, {"snippet_id": 75009, "code": ".exists(output_location) and not overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location, 'wb')", "label": 0}, {"snippet_id": 75031, "code": " import wzrpc from sup.ticker import Ticker class EvaluatorProxy: def __init__(self, ev_init, *args, **kvargs): super().__init__() self.ev_init=ev_init self.bind_kt_ticker=Ticker() self.bind_kt=5 def handle_evaluate", "label": 0}, {"snippet_id": 47184, "code": "(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing", "label": 0}, {"snippet_id": 16208, "code": "'no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer)", "label": 0}, {"snippet_id": 83577, "code": " 0 !=os.system(cmd): raise Exception('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths=job_wrapper.get_output_fnames", "label": 0}, {"snippet_id": 26777, "code": "'WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 19510, "code": " or arg=='--help': return argv,[], script gottarget=False skip=0 for i in range(len(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except IndexError: nextarg=None if gottarget: script", "label": 0}, {"snippet_id": 12487, "code": "{0}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file:\\n\\n\") comment_body.append(\"> \" +\"\".join(data", "label": 0}, {"snippet_id": 77899, "code": "'SpaghettiMonster') wm.start(ctx, sig_addr) def add_target(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) logger", "label": 0}, {"snippet_id": 61505, "code": ".wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self._observe.wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self.shots)) else: a, P=spectral_decomposition_qubit(A) p0=self.ev", "label": 0}, {"snippet_id": 63949, "code": " client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution==", "label": 1}, {"snippet_id": 51570, "code": " isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values", "label": 0}, {"snippet_id": 95534, "code": "\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file", "label": 0}, {"snippet_id": 26858, "code": "%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle", "label": 0}, {"snippet_id": 47559, "code": " self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__", "label": 0}, {"snippet_id": 9845, "code": " boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify<", "label": 0}, {"snippet_id": 33773, "code": " resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if", "label": 0}, {"snippet_id": 90385, "code": " in os.listdir(java_dist_dir): home=os.path.join(java_dist_dir, path) if os.path.isdir(home): yield self.Location.from_home(home) class _ExplicitEnvironment(_DistributionEnvironment): def __init__(self", "label": 0}, {"snippet_id": 80156, "code": " <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload", "label": 0}, {"snippet_id": 60183, "code": ", CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate, Rgate, S2gate, Sgate, Vgate, Xgate, Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__", "label": 0}, {"snippet_id": 9278, "code": "-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"", "label": 0}, {"snippet_id": 40121, "code": "(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for", "label": 0}, {"snippet_id": 32611, "code": " requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l", "label": 0}, {"snippet_id": 26591, "code": " self.type=='pressure': self._state=round(data['Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >", "label": 0}, {"snippet_id": 21474, "code": " variables.\") with open(seen_file, 'rb') as f: seen_links=pickle.load(f) with open(unseen_file, 'rb') as f: unseen_links=pickle.load(f) new_links, links=getytlinks(subreddit_link) if depth > 0: for d in", "label": 0}, {"snippet_id": 93163, "code": " subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s", "label": 0}, {"snippet_id": 57113, "code": "[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk, field and value.') field=str", "label": 0}, {"snippet_id": 47960, "code": "(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i", "label": 1}, {"snippet_id": 54927, "code": "=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards,", "label": 0}, {"snippet_id": 93002, "code": " 1) self.assertEqual(sys.stderr.fileno(), 2) self.assertEqual(sys.stdout, old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self): with", "label": 0}, {"snippet_id": 53261, "code": "._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies=dict(other.dependencies) self.dynamic_output=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self", "label": 0}, {"snippet_id": 77368, "code": " type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_nworkers(self, type_, fun, count, args=(), kvargs=", "label": 0}, {"snippet_id": 15890, "code": " self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET',", "label": 0}, {"snippet_id": 91376, "code": "(): task(name='interpreter', action=SelectInterpreter).install('pyprep') task(name='build-local-dists', action=BuildLocalPythonDistributions).install('pyprep') task(name='requirements', action=ResolveRequirements", "label": 0}, {"snippet_id": 11402, "code": "(self.create_filename(hostname)) old_header=Header.parse(output_path) return header_source.is_newer_than(old_header) def output_path(self, file_name): return os.path.join(self.target_dir, file_name) def", "label": 0}, {"snippet_id": 86278, "code": " as batched_sources: javac_cmd.extend(batched_sources) if self.execution_strategy==self.HERMETIC: self._execute_hermetic_compile(javac_cmd, ctx) else: with self.context.new_workunit(name='javac', cmd=' '", "label": 0}, {"snippet_id": 19275, "code": "(json_file) assert result==native def test_json_file_path(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.json') tmp_file.write(source) tmp_file.flush", "label": 0}, {"snippet_id": 46100, "code": " raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given", "label": 0}, {"snippet_id": 31646, "code": ".resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno", "label": 0}, {"snippet_id": 81312, "code": "\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html)", "label": 1}, {"snippet_id": 78972, "code": " form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms[0][1][0][\"name\"] \t\tself.logger.debug(\"Found the following file upload input: %s\",self.inputName", "label": 0}, {"snippet_id": 50071, "code": " overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack", "label": 0}, {"snippet_id": 4882, "code": " my_styles[\"raw\"]=(single_keywords_p, composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms", "label": 0}, {"snippet_id": 63080, "code": "'ensure_has_status_update_callback'): self.client_manager.ensure_has_status_update_callback(self.__async_update) return job_state status=client.get_status() except Exception: self.mark_as_finished(job_state) return None", "label": 0}, {"snippet_id": 45497, "code": " is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists", "label": 0}, {"snippet_id": 10314, "code": " def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given", "label": 0}, {"snippet_id": 27865, "code": "': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle']", "label": 0}, {"snippet_id": 19054, "code": " parse(raw_schema) def validate(raw_schema, target=None, **kwargs): \"\"\" Given the python representation of a JSONschema as defined in the swagger spec, validate that the schema complies to spec. If `target`", "label": 0}, {"snippet_id": 84038, "code": ") job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( \"(LWR/%s) is still in running state, adding to the LWR queue\" %( job", "label": 0}, {"snippet_id": 45528, "code": "=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs:", "label": 0}, {"snippet_id": 42546, "code": " expansion[i].append(IOFile(e, rule=branch)) except KeyError: return None replacements=[(i, io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old)", "label": 1}, {"snippet_id": 19851, "code": " closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None raise NotImplementedError def stop_debugging(self): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 40015, "code": "(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self", "label": 0}, {"snippet_id": 76993, "code": ": if domain in targets: tlist=targets[domain] else: tlist=list() targets[domain]=tlist if domain in forums: fset=forums[domain] else: fset=set() forums[domain]=fset net=make_net(proxy, proxytype) net.cookiefname", "label": 0}, {"snippet_id": 70004, "code": " some of the filesystem targets on local or remote servers. It is available for any filesystems previously installed and formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration", "label": 0}, {"snippet_id": 46051, "code": "\"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will", "label": 0}, {"snippet_id": 47386, "code": " in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(", "label": 0}, {"snippet_id": 27893, "code": "\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle", "label": 0}, {"snippet_id": 24760, "code": "'min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=", "label": 0}, {"snippet_id": 31890, "code": " products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"", "label": 0}, {"snippet_id": 48348, "code": " be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name", "label": 0}, {"snippet_id": 28991, "code": "] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self", "label": 0}, {"snippet_id": 28780, "code": "] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0", "label": 0}, {"snippet_id": 13464, "code": "'INSERT YOUR CONSUMER KEY HERE FROM TWITTER'\r consumerSecret='INSERT YOUR CONSUMER SECRET HERE FROM TWITTER'\r accessTokenKey='INSERT YOUR ACCESS TOKEN KEY HERE FROM TWITTER'\r accessTokenSecret='INSERT YOUR", "label": 0}, {"snippet_id": 90522, "code": " distribution is in the cache. :rtype::class:`pants.java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version and dist.version < minimum_version: continue if maximum_version", "label": 0}, {"snippet_id": 36609, "code": "=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self", "label": 0}, {"snippet_id": 80822, "code": "\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t", "label": 1}, {"snippet_id": 37927, "code": " benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self", "label": 0}, {"snippet_id": 35964, "code": " from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException", "label": 1}, {"snippet_id": 91075, "code": "}\"; combining results.'.format(rename)) normalized[rename].extend(paths) else: normalized[rename]=paths return normalized def _get_explicit_jdk_paths(self): if not self._normalized_jdk_paths: return() os_name", "label": 0}, {"snippet_id": 54787, "code": " touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False", "label": 0}, {"snippet_id": 57024, "code": "='True' and 1 or 0, 'datetime': get_time, 'int': lambda x: str(int(x)), 'str': lambda x: str(x), 'None': lambda x: None, } pipe=pipes.get(v_type, None) if pipe is None: error='Unsupported value type.' else", "label": 0}, {"snippet_id": 84496, "code": " self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self._sep def version_path( self): return self._version_path def rewriter( self, parameter_value)", "label": 0}, {"snippet_id": 23994, "code": " deviceid={0}\".format(g0g1) err, output=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk -F. '{print $3}'\" err, output=shellutil.run_get_output(cmd_extract_id)", "label": 0}, {"snippet_id": 77356, "code": "))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised", "label": 0}, {"snippet_id": 42121, "code": " resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other", "label": 0}, {"snippet_id": 9972, "code": " acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches", "label": 0}, {"snippet_id": 37793, "code": " not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name", "label": 0}, {"snippet_id": 45288, "code": "): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if", "label": 0}, {"snippet_id": 25236, "code": " TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy',", "label": 0}, {"snippet_id": 9563, "code": " for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return:", "label": 0}, {"snippet_id": 68396, "code": "=TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target)", "label": 0}, {"snippet_id": 81598, "code": " \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime", "label": 0}, {"snippet_id": 18247, "code": "._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None", "label": 0}, {"snippet_id": 2813, "code": "\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres", "label": 0}, {"snippet_id": 65804, "code": " layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre", "label": 0}, {"snippet_id": 70253, "code": ".upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type", "label": 0}, {"snippet_id": 25101, "code": "\" Support for the NetAtmo Weather Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime", "label": 1}, {"snippet_id": 50704, "code": ".workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self", "label": 0}, {"snippet_id": 40054, "code": "): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError", "label": 1}, {"snippet_id": 8321, "code": ".ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document", "label": 1}, {"snippet_id": 52383, "code": "() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self", "label": 0}, {"snippet_id": 54586, "code": " log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def", "label": 0}, {"snippet_id": 11347, "code": "] self.source=url if debug_enabled: set_log_level_to_debug() if not self.target_dir or not os.path.isdir(self.target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir", "label": 0}, {"snippet_id": 73565, "code": ".chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"", "label": 0}, {"snippet_id": 82393, "code": " if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose:", "label": 0}, {"snippet_id": 69090, "code": " indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(),", "label": 0}, {"snippet_id": 50887, "code": " check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer", "label": 1}, {"snippet_id": 91999, "code": "{ SubclassesOf(PythonDistribution): self.pydist_has_native_sources, SubclassesOf(NativeLibrary): NativeLibrary.produces_ctypes_native_library, } def _any_targets_have_native_sources(self, targets): for", "label": 0}, {"snippet_id": 12641, "code": "\"updating\"): PERMITTED_TO_COMMENT=False \"\"\" for old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body'].lower(): break elif 'quiet' in old_comment", "label": 0}, {"snippet_id": 11161, "code": ".etag)) if self.mtime: lines.append(\"%s%d\" %(Header.MTIME_COMMMENT, self.mtime)) return lines @staticmethod def parse(file_name): etag, mtime=None, 0 def extract(comment, current_value): value=None if line", "label": 0}, {"snippet_id": 31131, "code": "=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark:", "label": 0}, {"snippet_id": 57831, "code": ".objects.filter(username=self.new_value).values_list('pk', flat=True) if not reviewers: err_msg='Reviewer %s is not found' % self.new_value raise ObjectDoesNotExist(err_msg) self.get_update_targets().update", "label": 0}, {"snippet_id": 59922, "code": ") self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args", "label": 0}, {"snippet_id": 94447, "code": " run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\")", "label": 0}, {"snippet_id": 21958, "code": ", ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args=None, poll_interval=None, seconds=None, check=None, syntax=None, diff=None, force_handlers=None, flush_cache=None, listtasks", "label": 0}, {"snippet_id": 91551, "code": " Status, TestResult, TestTarget from pants.source.source_root import SourceRootConfig def parse_interpreter_constraints(python_setup, python_target_adaptors): constraints={ constraint for target_adaptor", "label": 0}, {"snippet_id": 56308, "code": "(request_dict, skip_parameters): parameters={} for key, value in request_dict.items(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters @require_GET def info(request):", "label": 1}, {"snippet_id": 74379, "code": "./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value", "label": 0}, {"snippet_id": 68320, "code": ", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT,", "label": 0}, {"snippet_id": 89490, "code": " maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param string home_path: the path to the java", "label": 0}, {"snippet_id": 15453, "code": "'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 50954, "code": " ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode", "label": 0}, {"snippet_id": 57020, "code": "%H%M%S') pipes={ 'bool': lambda x: x=='True' and 1 or 0, 'datetime': get_time, 'int': lambda x: str(int(x)), 'str': lambda x: str(x), 'None': lambda x: None, } pipe=pipes.get(v_type, None) if pipe is None", "label": 0}, {"snippet_id": 40712, "code": " as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists", "label": 0}, {"snippet_id": 95553, "code": ") new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute", "label": 0}, {"snippet_id": 25693, "code": " data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 26158, "code": "['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure", "label": 1}, {"snippet_id": 67476, "code": " formatted. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status", "label": 0}, {"snippet_id": 30549, "code": " chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions", "label": 1}, {"snippet_id": 29533, "code": "(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None", "label": 0}, {"snippet_id": 60533, "code": "\"StrawberryFields Gaussian device for OpenQML. wires(int): the number of modes to initialize the device in. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value", "label": 0}, {"snippet_id": 33933, "code": " workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global", "label": 0}, {"snippet_id": 52339, "code": ".dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self", "label": 0}, {"snippet_id": 61003, "code": " DeviceError, qfunc, QNode, Variable, __version__ tolerance=1e-10 def spectral_decomposition_qubit(A): r\"\"\"Spectral decomposition of a 2*2 Hermitian matrix. Args: A(array): 2*2 Hermitian matrix Returns: ", "label": 0}, {"snippet_id": 60982, "code": " reset(self): \"\"\"Reset the backend state. After the reset the backend should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" raise NotImplementedError", "label": 0}, {"snippet_id": 61801, "code": "] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)", "label": 0}, {"snippet_id": 19301, "code": " result==native def test_yaml_file_object(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.flush() with open(tmp_file.name", "label": 0}, {"snippet_id": 79825, "code": " for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1", "label": 0}, {"snippet_id": 83903, "code": "'']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't", "label": 0}, {"snippet_id": 49628, "code": "() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe", "label": 0}, {"snippet_id": 20499, "code": ": return self._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed read=recv_as_read(self", "label": 0}, {"snippet_id": 77431, "code": "): if not self.running.is_set(): break try: if type_==0: w=workers.WZWorkerThread( self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p", "label": 0}, {"snippet_id": 4488, "code": "(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text", "label": 0}, {"snippet_id": 74728, "code": " chunk_width_str==\"default\": self.chunk_width=None elif isint(chunk_width_str): self.chunk_width=int(chunk_width_str) else: raise TypeError(\"Invalid value provided for chunk_width in configuration.\\n\" ", "label": 0}, {"snippet_id": 72950, "code": "\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, filepath)) except error_perm: print", "label": 0}, {"snippet_id": 30340, "code": " end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key", "label": 0}, {"snippet_id": 45337, "code": "\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions", "label": 1}, {"snippet_id": 13717, "code": ", count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self", "label": 0}, {"snippet_id": 10150, "code": " def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires", "label": 0}, {"snippet_id": 54637, "code": " rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"", "label": 0}, {"snippet_id": 6513, "code": " print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('", "label": 0}, {"snippet_id": 80080, "code": ",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=", "label": 0}, {"snippet_id": 18431, "code": " _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self._temp_options_filename) def RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...", "label": 0}, {"snippet_id": 45824, "code": ".escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string", "label": 0}, {"snippet_id": 57589, "code": " mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context) except Exception: pass def _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not", "label": 0}, {"snippet_id": 95356, "code": "(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=ftp_config.directory) else", "label": 0}, {"snippet_id": 13351, "code": ", new_file in data[\"results\"].items(): url=\"https://api.github.com/repos/{}/contents/{}\" url=url.format(fullname, file) params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers", "label": 0}, {"snippet_id": 2279, "code": ")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split('", "label": 0}, {"snippet_id": 21173, "code": "'Event{}'.format(self.name) else: message +='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None): super(AwaitableResponse", "label": 0}, {"snippet_id": 74289, "code": " generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location", "label": 0}, {"snippet_id": 95392, "code": " local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\"", "label": 0}, {"snippet_id": 81418, "code": "\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger", "label": 0}, {"snippet_id": 32288, "code": " dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self", "label": 0}, {"snippet_id": 46523, "code": " key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next", "label": 0}, {"snippet_id": 70450, "code": " detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import", "label": 0}, {"snippet_id": 21318, "code": " subreddit.') parser.add_argument('--depth', metavar='d', type=int, default=0, help='How many pages into the subreddit you want to go.') parser.add_argument('subreddit', type=str, help='The subreddit you", "label": 0}, {"snippet_id": 94182, "code": ".logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves", "label": 0}, {"snippet_id": 12572, "code": " comments\"\"\" PERMITTED_TO_COMMENT=True repository=data[\"repository\"] headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https", "label": 0}, {"snippet_id": 297, "code": " all code snippets, or create a new snippet. \"\"\" if request.method=='POST': action=request.POST.get(\"_action\") print(action) if action=='registerService': request_name=request.POST.get(\"name\") request_address", "label": 0}, {"snippet_id": 1355, "code": " print(currentwifi) params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params,", "label": 0}, {"snippet_id": 33810, "code": ".stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include", "label": 0}, {"snippet_id": 87660, "code": "._scheduler.capture_snapshots((PathGlobsAndRoot( PathGlobs(scala_path), get_buildroot(), ),))[0] ) merged_input_digest=self.context._scheduler.merge_directories( tuple(s.directory_digest for s in(snapshots)", "label": 0}, {"snippet_id": 36986, "code": " self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0] self.name=other.name self", "label": 0}, {"snippet_id": 25064, "code": "\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update", "label": 0}, {"snippet_id": 22743, "code": " chpasswd(self, username, password, crypt_id=6, salt_len=10): \"\"\"Change a user's password with tmsh Since we are creating the user specified account and additionally changing the password of the built-in ", "label": 0}, {"snippet_id": 17969, "code": "=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests", "label": 0}, {"snippet_id": 12560, "code": " comment_body, comment_footer, ERROR def comment_permission_check(data, comment): \"\"\"Check for quite and resume status or duplicate comments\"\"\" PERMITTED_TO_COMMENT=True repository=data[\"repository\"] headers={", "label": 0}, {"snippet_id": 1299, "code": " shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password", "label": 0}, {"snippet_id": 60950, "code": "\"\"\" return self._out @classmethod def capabilities(cls): \"\"\"Get the other capabilities of the plugin. Measurements, batching etc. Returns: dict[str->*]: results \"\"\" return cls._capabilities @abc.abstractmethod", "label": 1}, {"snippet_id": 67553, "code": " targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self", "label": 0}, {"snippet_id": 79708, "code": "=valid_postData) parser.add_argument(\"--proxy\", metavar=\"proxyUrl\", dest=\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument", "label": 0}, {"snippet_id": 65787, "code": ".CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column", "label": 0}, {"snippet_id": 52215, "code": " format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs,", "label": 0}, {"snippet_id": 84016, "code": " job_state.job_id=str( job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line", "label": 0}, {"snippet_id": 74451, "code": ": dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration.", "label": 0}, {"snippet_id": 42705, "code": " output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput):", "label": 0}, {"snippet_id": 26607, "code": "='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 4280, "code": ".path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent", "label": 1}, {"snippet_id": 80065, "code": ",default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use", "label": 0}, {"snippet_id": 56650, "code": "(num_runs=Count('tag')).order_by('tag') plan_counter=_TagCounter('num_plans', test_plan_tags) case_counter=_TagCounter('num_cases', test_case_tags) run_counter=_TagCounter('num_runs', test_run_tags) for", "label": 0}, {"snippet_id": 67266, "code": " mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s", "label": 0}, {"snippet_id": 30519, "code": "},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if", "label": 0}, {"snippet_id": 58356, "code": ")) class TestIndex(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self.client.get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-login", "label": 0}, {"snippet_id": 59403, "code": " kwargs: kwargs.setdefault(v, kwargs[k]) if 'num_runs' in kwargs: if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs", "label": 0}, {"snippet_id": 601, "code": ".sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor", "label": 0}, {"snippet_id": 90267, "code": "(home) if home else None jdk_home=env_home('JDK_HOME') if jdk_home: yield jdk_home java_home=env_home('JAVA_HOME') if java_home: yield java_home search_path=os.environ.get('PATH') if search_path: for bin_path", "label": 0}, {"snippet_id": 6805, "code": "=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords) return get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms", "label": 0}, {"snippet_id": 19195, "code": "'detail')) return response=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors[", "label": 0}, {"snippet_id": 33616, "code": " detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n", "label": 0}, {"snippet_id": 66655, "code": "().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self", "label": 0}, {"snippet_id": 23390, "code": "=fileutil.read_file(rc_file_path).split(\"\\n\") textutil.set_ini_config(conf_file, \"hostname\", hostname) fileutil.write_file(rc_file_path, \"\\n\".join(conf_file)) shellutil.run(\"hostname{0}\".format(hostname", "label": 0}, {"snippet_id": 34329, "code": " shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self", "label": 0}, {"snippet_id": 22474, "code": " start\", chk_err=False) def register_agent_service(self): return shellutil.run(\"/sbin/chkconfig --add waagent\", chk_err=False) def unregister_agent_service(self): return shellutil.run(\"/sbin/chkconfig --del", "label": 0}, {"snippet_id": 51403, "code": " def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"", "label": 1}, {"snippet_id": 54570, "code": "=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self", "label": 0}, {"snippet_id": 77503, "code": " evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy, self.c.ecount, (ev_init,)) def load_users", "label": 0}, {"snippet_id": 12513, "code": "--\\n\\n\") if config[\"only_mention_files_with_errors\"] and not ERROR: comment_body.append(\"Cheers ! There are no PEP8 issues in this Pull Request.:beers: \") comment_body=''.join(comment_body) comment_footer", "label": 0}, {"snippet_id": 91572, "code": " constraints_args=[] for constraint in sorted(constraints): constraints_args.extend([\"--interpreter-constraint\", text_type(constraint)]) return constraints_args @rule(TestResult,[PythonTestsAdaptor, PyTest", "label": 1}, {"snippet_id": 74252, "code": ".benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config=runtime_config) def read_configuration(location): \"", "label": 0}, {"snippet_id": 21104, "code": ".1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages.append('Event{}'.format", "label": 0}, {"snippet_id": 22840, "code": " output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for{0}:{1}\".format(username, output) ) userentry=self.get_userentry('admin') if", "label": 0}, {"snippet_id": 84776, "code": " from pants.backend.jvm.targets.jar_library import JarLibrary from pants.build_graph.address import Address from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java.jar.jar_dependency", "label": 0}, {"snippet_id": 25812, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 34231, "code": ") return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 13618, "code": "\"\r myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",..", "label": 0}, {"snippet_id": 5608, "code": " keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)", "label": 0}, {"snippet_id": 38056, "code": " the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp ", "label": 0}, {"snippet_id": 90080, "code": " self._system_properties def _validate_executable(self, name): def bin_paths(): yield self._bin_path if self._is_jdk: yield os.path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path", "label": 0}, {"snippet_id": 70725, "code": "\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support", "label": 1}, {"snippet_id": 73527, "code": "=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number", "label": 0}, {"snippet_id": 73345, "code": " return head def path_leaf(path): head, tail=os.path.split(path) return tail or os.path.basename(head) def read_file_contents(local_filepath): if os.path.isfile(local_filepath): with open(local_filepath", "label": 0}, {"snippet_id": 93618, "code": "%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp[", "label": 0}, {"snippet_id": 77268, "code": "'Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers(self, wclass, count, args=(), kvargs", "label": 0}, {"snippet_id": 77583, "code": ".append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL)) self.log.info('Saved users') def get_userqueue(self, domain): try: uq=self", "label": 0}, {"snippet_id": 80082, "code": "\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required", "label": 0}, {"snippet_id": 46349, "code": " items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another", "label": 0}, {"snippet_id": 44224, "code": ".info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock(", "label": 0}, {"snippet_id": 93672, "code": "(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running, skipping to next", "label": 0}, {"snippet_id": 52921, "code": " value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\"", "label": 0}, {"snippet_id": 40225, "code": ", dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if", "label": 1}, {"snippet_id": 59488, "code": " DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, ", "label": 0}, {"snippet_id": 9995, "code": "] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)) if matches_str", "label": 0}, {"snippet_id": 59990, "code": " operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs", "label": 0}, {"snippet_id": 55921, "code": "=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority", "label": 0}, {"snippet_id": 62654, "code": " __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was", "label": 0}, {"snippet_id": 37968, "code": " self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self", "label": 0}, {"snippet_id": 77072, "code": "=config self.threads=[] self.processes=[] self.th_sa='inproc://wm-wth.sock' self.th_ba='inproc://wm-back.sock' self.pr_sa='ipc://wm-wpr.sock' self.pr_ba='ipc://wm-back.sock' self.userqueues={} self.usersfile", "label": 0}, {"snippet_id": 43057, "code": "._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name:", "label": 0}, {"snippet_id": 85774, "code": " jar in classpaths] @memoized_property def extractor(self): return self._zinc_factory.tool_classpath_from_products(self._products, self.ZINC_EXTRACTOR_TOOL_NAME, scope=self._zinc_factory.options_scope)", "label": 0}, {"snippet_id": 88564, "code": " self.targets(). Note that for a command line invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots", "label": 0}, {"snippet_id": 4049, "code": ".run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center) main_window.show()", "label": 0}, {"snippet_id": 56794, "code": ": the object for which the tag actions would be performed :type obj: either a:class:`tcms.testplans.models.TestPlan`, a:class:`tcms.testcases.models.TestCase` or a:class:`tcms.testruns.models.TestRun` ", "label": 0}, {"snippet_id": 10609, "code": " remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st", "label": 1}, {"snippet_id": 23620, "code": " goes to current default gw, not a all-ones broadcast address, need to specify the route manually to get it work in a VNET environment. SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled", "label": 0}, {"snippet_id": 54564, "code": ") self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess", "label": 0}, {"snippet_id": 95527, "code": "(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP", "label": 0}, {"snippet_id": 24906, "code": " data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 32690, "code": ".name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2", "label": 0}, {"snippet_id": 94104, "code": "=False): self.kill_mode=kill_mode self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(", "label": 0}, {"snippet_id": 90453, "code": "._possible_environments)) class _Locator(object): class Error(Distribution.Error): \"\"\"Error locating a java distribution.\"\"\" def __init__(self, distribution_environment, minimum_version=None, maximum_version", "label": 0}, {"snippet_id": 84011, "code": " the queued/running state when Galaxy started\"\"\" job_state=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state", "label": 0}, {"snippet_id": 8125, "code": "(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR", "label": 0}, {"snippet_id": 25159, "code": " DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None]", "label": 1}, {"snippet_id": 71068, "code": ".append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[", "label": 0}, {"snippet_id": 90520, "code": " the Distribution, or None if no matching distribution is in the cache. :rtype::class:`pants.java.distribution.Distribution` \"\"\" for dist in self._cache.values(): if minimum_version and dist.version < minimum_version", "label": 0}, {"snippet_id": 59716, "code": " for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables=set([ key for(key,val)", "label": 0}, {"snippet_id": 27106, "code": "//home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant.components.sensor import PLATFORM_SCHEMA from homeassistant.const", "label": 1}, {"snippet_id": 86136, "code": ").compiler=='javac': return super(JavacCompile, self).execute() def compile(self, ctx, args, dependency_classpath, upstream_analysis, settings, fatal_warnings, zinc_file_manager, javac_plugin_map, scalac_plugin_map", "label": 0}, {"snippet_id": 42417, "code": " self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params", "label": 0}, {"snippet_id": 94184, "code": ".logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" ", "label": 0}, {"snippet_id": 84183, "code": "): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason", "label": 0}, {"snippet_id": 8641, "code": " of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode", "label": 0}, {"snippet_id": 83283, "code": " return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep( 2) job_state=self.__find_watched_job( job_id) if", "label": 0}, {"snippet_id": 66637, "code": " \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage", "label": 0}, {"snippet_id": 90808, "code": "/options led to impossible constraints for{} ' 'distribution: minimum_version{}, maximum_version{}') else: error_format=('Failed to locate a{} distribution with minimum_version{}, ' 'maximum_version{}') raise", "label": 0}, {"snippet_id": 90969, "code": "-paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' ", "label": 0}, {"snippet_id": 6906, "code": ".get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt", "label": 0}, {"snippet_id": 69219, "code": "*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s ", "label": 0}, {"snippet_id": 81517, "code": ".thread._threads_queues.clear() \t\treturn n \t \tdef detectCodeExec(self,url,regex): \t\tif self.shouldLog: \t\t\tif self.logger.verbosity > 0: \t\t\t\tself.logger.debug(\"Requesting %s...\",url) \t\t \t\tr=self.session", "label": 0}, {"snippet_id": 4988, "code": " list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only", "label": 0}, {"snippet_id": 22189, "code": ".render( data) return outputText def run(self, state, data=None, context=None): \"\"\"Run ansible-playbook on the specified playbook. \"\"\" playbook=None log_file=None template=None if state in self.conf: if ", "label": 0}, {"snippet_id": 16037, "code": "{ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line, 'filepath': filepath } if include_buffer_data: request_data", "label": 0}, {"snippet_id": 82309, "code": " manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args(", "label": 0}, {"snippet_id": 32854, "code": "=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None, config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir", "label": 0}, {"snippet_id": 5200, "code": "(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\":", "label": 0}, {"snippet_id": 9393, "code": " only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions", "label": 0}, {"snippet_id": 21423, "code": " with open(unseen_file, 'wb') as f: pickle.dump(unseen_links, f) elif not os.path.isdir(sr_dir): print(\"Reddytt: Working directory found, but no subreddit directory. Creating %s, and files.\" % sr_dir) os", "label": 0}, {"snippet_id": 47653, "code": "\"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format(", "label": 0}, {"snippet_id": 49883, "code": ".code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True", "label": 0}, {"snippet_id": 40652, "code": " file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated", "label": 1}, {"snippet_id": 58309, "code": ".TestCase): @classmethod def setUpTestData(cls): super(TestNavigation, cls).setUpTestData() cls.user=UserFactory(email='user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses", "label": 0}, {"snippet_id": 18493, "code": "._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands')", "label": 0}, {"snippet_id": 71389, "code": ", \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT", "label": 0}, {"snippet_id": 6341, "code": " output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the", "label": 0}, {"snippet_id": 18555, "code": " extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive", "label": 0}, {"snippet_id": 79503, "code": "\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename", "label": 1}, {"snippet_id": 69541, "code": "') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command", "label": 0}, {"snippet_id": 8884, "code": " for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit,", "label": 0}, {"snippet_id": 23018, "code": "\"\" patten=r'(sr[0-9]|hd[c-z]|cdrom[0-9]?)' for dvd in[re.match(patten, dev) for dev in os.listdir(dev_dir)]: if dvd is not None: return \"/dev/{0}\".format(dvd.group(0)) raise OSUtilError(\"Failed to get dvd", "label": 0}, {"snippet_id": 30537, "code": "\"MIT\" import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import", "label": 1}, {"snippet_id": 60618, "code": ".wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x", "label": 0}, {"snippet_id": 23065, "code": " load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make when mounting the provisioningiso.iso DVD ", "label": 0}, {"snippet_id": 89127, "code": " dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in target.dependencies: if dependency in core: dependees[target].add(dependency) return dependees def resolve(self, spec):", "label": 0}, {"snippet_id": 5830, "code": " / 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir", "label": 0}, {"snippet_id": 73776, "code": "\"\" files=[] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type", "label": 0}, {"snippet_id": 40553, "code": ".flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value", "label": 0}, {"snippet_id": 85067, "code": ") register_scala_compiler_tool('2.11') register_scala_repl_tool('2.11') register_style_tool('2.11') register_scala_compiler_tool('2.12') register_scala_repl_tool('2.12') register_style_tool('2.12') def", "label": 0}, {"snippet_id": 47455, "code": ".resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \"", "label": 0}, {"snippet_id": 72766, "code": " module for the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs", "label": 0}, {"snippet_id": 88874, "code": ") def release_lock(self): \"\"\"Release the global lock if it's held. Returns True if the lock was held before this call. :API: public \"\"\" if not self._lock.acquired: return False else: self._lock.release", "label": 0}, {"snippet_id": 89165, "code": " root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any dependencies of targets parsed in the root tree's BUILD", "label": 0}, {"snippet_id": 28530, "code": " self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain", "label": 0}, {"snippet_id": 26181, "code": ", None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm',", "label": 0}, {"snippet_id": 85846, "code": " print_function, unicode_literals import logging import os from builtins import str from future.utils import text_type from pants.backend.jvm import argfile from pants.backend.jvm.subsystems.java import", "label": 0}, {"snippet_id": 54581, "code": " self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self", "label": 0}, {"snippet_id": 2028, "code": "={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset.append(data) return JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep'", "label": 0}, {"snippet_id": 40450, "code": ".add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\") return \"\"", "label": 0}, {"snippet_id": 15578, "code": " SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data", "label": 0}, {"snippet_id": 20124, "code": "\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an adapter in a background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None", "label": 0}, {"snippet_id": 28703, "code": "._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500", "label": 0}, {"snippet_id": 68495, "code": "(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append", "label": 0}, {"snippet_id": 67999, "code": ", target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target", "label": 0}, {"snippet_id": 91182, "code": ".python_distribution import PythonDistribution from pants.backend.python.targets.python_library import PythonLibrary from pants.backend.python.targets.python_requirement_library import PythonRequirementLibrary", "label": 0}, {"snippet_id": 18095, "code": " _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData", "label": 1}, {"snippet_id": 21530, "code": " new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv", "label": 1}, {"snippet_id": 75531, "code": "[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-unbind-route', args, reqid) def make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None", "label": 0}, {"snippet_id": 10399, "code": "(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if", "label": 0}, {"snippet_id": 4248, "code": " read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry, filename) if os.path", "label": 0}, {"snippet_id": 75891, "code": " self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0]) rslist.append(rs) msg=self.wz.make_req_msg(request[1][0], request[1][1], request[1][2]", "label": 0}, {"snippet_id": 80248, "code": "\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs", "label": 0}, {"snippet_id": 93899, "code": "] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host", "label": 0}, {"snippet_id": 64710, "code": "(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path", "label": 1}, {"snippet_id": 81837, "code": ".add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type=valid_postData) parser.add_argument(\"-", "label": 0}, {"snippet_id": 51212, "code": ": if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer", "label": 0}, {"snippet_id": 58530, "code": "(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No caserun found.'}) def test_add_comment_to_case_runs(self): self.client.login( username=self.tester.username, password='password", "label": 0}, {"snippet_id": 25206, "code": ", 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None", "label": 0}, {"snippet_id": 71960, "code": " try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc,", "label": 0}, {"snippet_id": 34063, "code": " integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r", "label": 0}, {"snippet_id": 80813, "code": "\t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a[\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]]", "label": 0}, {"snippet_id": 35286, "code": ") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard", "label": 0}, {"snippet_id": 34900, "code": " wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing:", "label": 0}, {"snippet_id": 57493, "code": " permission to update TestCases.\") action=self.get_update_action() if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception:", "label": 0}, {"snippet_id": 20862, "code": "(cmd:{} seq:{})'.format(command, seq) evt=self._get_message_handle(match, handlername) return AwaitableResponse(req, lambda: result[\"msg\"], evt) @contextlib.contextmanager def wait_for_response(self, req,", "label": 0}, {"snippet_id": 65062, "code": ": Start of %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id()", "label": 0}, {"snippet_id": 40548, "code": "(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value", "label": 0}, {"snippet_id": 92977, "code": " > 2, \"Expected a pseudofile as stderr, got:{}\".format(sys.stderr)) old_stdout, old_stderr, old_stdin=sys.stdout, sys.stderr, sys.stdin with self._stdio_as_tempfiles(): with self._stdio_as_tempfiles():", "label": 0}, {"snippet_id": 29694, "code": "(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict", "label": 0}, {"snippet_id": 46823, "code": "), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule", "label": 0}, {"snippet_id": 93660, "code": "['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or", "label": 0}, {"snippet_id": 39126, "code": " benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else:", "label": 0}, {"snippet_id": 71988, "code": "\"\"\"Networks plugin -allows you to manipulate connections to various configured networks.\"\"\" import importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log", "label": 0}, {"snippet_id": 15002, "code": " headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession", "label": 0}, {"snippet_id": 94842, "code": ".set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center)", "label": 0}, {"snippet_id": 29283, "code": " try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for", "label": 0}, {"snippet_id": 48922, "code": ": return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames)", "label": 0}, {"snippet_id": 92418, "code": " ENCODED_CHAR with environment_as(**dict(XXX=UNICODE_CHAR)): self.assertEqual(os.environ['XXX'], expected_output) with hermetic_environment_as(**dict(AAA=UNICODE_CHAR)): self.assertIn('AAA', os.environ", "label": 1}, {"snippet_id": 5408, "code": " expansions in iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords", "label": 0}, {"snippet_id": 63659, "code": ", stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we", "label": 0}, {"snippet_id": 48894, "code": ", wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0", "label": 0}, {"snippet_id": 1160, "code": "=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices.objects.all() serializer_class=RegisteredServicesSerializer", "label": 0}, {"snippet_id": 44008, "code": " list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False,", "label": 0}, {"snippet_id": 84136, "code": " @staticmethod def __dependency_resolution( lwr_client): dependency_resolution=lwr_client.destination_params.get( \"dependency_resolution\", \"local\") if dependency_resolution not in[\"none\", \"local\", \"remote", "label": 0}, {"snippet_id": 28249, "code": " 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi", "label": 0}, {"snippet_id": 58181, "code": " p_pks and sep: p_pks=[k for k in p_pks.split(sep) if k] res=get_prod_related_objs(p_pks, target) else: res=[] return HttpResponse(json.dumps(res)) def objects_update(objects, **kwargs): objects.update", "label": 0}, {"snippet_id": 46650, "code": " as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and", "label": 0}, {"snippet_id": 69437, "code": " of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ ", "label": 1}, {"snippet_id": 81305, "code": ".verbosity > 1: \t\t\t\t\tprintSimpleResponseObject(fu) \t\t\t\tif self.logger.verbosity > 2: \t\t\t\t\tprint(\"\\033[36m\"+fu.text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False", "label": 1}, {"snippet_id": 93936, "code": " sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd", "label": 0}, {"snippet_id": 6285, "code": " except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines:", "label": 1}, {"snippet_id": 5711, "code": " _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels", "label": 0}, {"snippet_id": 36089, "code": "=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in", "label": 0}, {"snippet_id": 76207, "code": " self.wz.del_req_handler(i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Route unbinded for(%s, %s)', i, m) else: self.log.warn('Status %s, passing'", "label": 0}, {"snippet_id": 90781, "code": ")) return dist except(ValueError, Distribution.Error) as e: logger.debug('{} is not a valid distribution because:{}' .format(location.home_path, str(e))) pass if(minimum_version is not None and maximum_version", "label": 0}, {"snippet_id": 23011, "code": " dev_dir: The root directory from which to look for devices \"\"\" patten=r'(sr[0-9]|hd[c-z]|cdrom[0-9]?)' for dvd in[re.match(patten, dev) for dev in os.listdir(dev_dir)]: if dvd is not None: return \"/dev/{0}", "label": 0}, {"snippet_id": 62786, "code": " keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend'", "label": 0}, {"snippet_id": 79112, "code": "\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif", "label": 1}, {"snippet_id": 83362, "code": ": unstructured_path_rewrites=compute_environment.unstructured_path_rewrites client_job_description=ClientJobDescription( command_line=command_line, input_files=self.get_input_files(job_wrapper), client_outputs", "label": 0}, {"snippet_id": 7135, "code": "(complete_output, categories) else: if output_limit > 0: my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords,", "label": 0}, {"snippet_id": 40999, "code": ".add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an", "label": 0}, {"snippet_id": 44463, "code": " True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence", "label": 0}, {"snippet_id": 78579, "code": "(self.forums)==0: with cstate(self, WipeState.waiting_for_targets): while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self", "label": 0}, {"snippet_id": 48524, "code": " depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards,", "label": 0}, {"snippet_id": 25446, "code": " self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the", "label": 0}, {"snippet_id": 45961, "code": "(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value", "label": 0}, {"snippet_id": 48272, "code": " is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only", "label": 0}, {"snippet_id": 72741, "code": " the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import time import", "label": 0}, {"snippet_id": 44902, "code": " raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources", "label": 0}, {"snippet_id": 75138, "code": ".bind_methods() elif status==wzrpc.status.e_timeout: self.p.log.warn('Keepalive timeout') else: self.p.log.warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self", "label": 0}, {"snippet_id": 61797, "code": " wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before", "label": 0}, {"snippet_id": 50113, "code": "(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self", "label": 0}, {"snippet_id": 77842, "code": ".load_bumplimit_set() self.load_targets() self.load_users() self.spawn_wipethreads() if self.c.ecount > 0: self.spawn_evaluators() try: while self.running.is_set(): if self.c.tcount==0: self.inter_sleep", "label": 0}, {"snippet_id": 66719, "code": ".GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError", "label": 1}, {"snippet_id": 94426, "code": "\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp)", "label": 1}, {"snippet_id": 79479, "code": ".shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): ", "label": 0}, {"snippet_id": 40310, "code": ")*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing", "label": 0}, {"snippet_id": 30017, "code": " Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if", "label": 0}, {"snippet_id": 13190, "code": " auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format(data[\"fork_fullname", "label": 0}, {"snippet_id": 66911, "code": "\n from Base.Command import Command from Shine.Commands import commandList from Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list", "label": 0}, {"snippet_id": 11540, "code": " write_line(self, line): self.icinga_lines.append(line) def write_section(self, section_name, section_data): self.write_line(\"\") self.write_line(\"define %s{\" % section_name) sorted_keys=section_data.keys(", "label": 0}, {"snippet_id": 58564, "code": "(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct=ContentType.objects.get_for_model", "label": 0}, {"snippet_id": 6185, "code": " word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size", "label": 1}, {"snippet_id": 30910, "code": ".rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list", "label": 0}, {"snippet_id": 7500, "code": " html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True", "label": 0}, {"snippet_id": 13503, "code": " chippyRuxpin_gpio import GPIO\r from chippyRuxpin_twitter import ChippyTwitter\r from chippyRuxpin_webFramework import WebFramework\r \r fullMsg=\"\"\r \r MOUTH_OPEN=408 MOUTH_CLOSE=412 EYES_OPEN=410 EYES_CLOSE", "label": 0}, {"snippet_id": 29223, "code": ": return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink", "label": 0}, {"snippet_id": 73996, "code": "] if chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration", "label": 0}, {"snippet_id": 71135, "code": " status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks \"\"\" print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[", "label": 0}, {"snippet_id": 58560, "code": ": ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct=ContentType.objects", "label": 0}, {"snippet_id": 86970, "code": ", help='When set, the results of incremental compiles will be written to the cache. ' 'This is unset by default, because it is generally a good precaution to cache ' 'only clean/cold builds.') @classmethod", "label": 0}, {"snippet_id": 40634, "code": "(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity", "label": 0}, {"snippet_id": 56570, "code": ") form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan, TestCase or TestRun \"\"\" tag_objects=_TagObjects", "label": 1}, {"snippet_id": 88469, "code": " self.requested_goals=requested_goals or[] self._console_outstream=console_outstream or sys.stdout self._scm=scm or get_scm() self._workspace=workspace or(ScmWorkspace(self._scm) if self._scm else None", "label": 0}, {"snippet_id": 26908, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self", "label": 0}, {"snippet_id": 49055, "code": " import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag, not_iterable, touch from snakemake", "label": 1}, {"snippet_id": 2059, "code": "')[0] userlist=ps.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False)", "label": 0}, {"snippet_id": 33490, "code": "{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update", "label": 0}, {"snippet_id": 71734, "code": " print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden", "label": 0}, {"snippet_id": 24693, "code": "': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low", "label": 0}, {"snippet_id": 94431, "code": " % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running custom check if available\") if check_available and run_component_check(comp): logger.debug(\"Process terminated but", "label": 1}, {"snippet_id": 49157, "code": "=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self", "label": 0}, {"snippet_id": 12644, "code": "\"\" for old_comment in reversed(comments): if '@pep8speaks' in old_comment['body']: if 'resume' in old_comment['body'].lower(): break elif 'quiet' in old_comment['body'].lower(): PERMITTED_TO_COMMENT=False", "label": 0}, {"snippet_id": 95710, "code": "*/*.gz\") for path in pathlist_gz: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str", "label": 0}, {"snippet_id": 92827, "code": " def test_open_zip_returns_realpath_on_badzipfile(self): with temporary_file() as not_zip: with temporary_dir() as tempdir: file_symlink=os.path.join(tempdir, 'foo') os.symlink(not_zip.name, file_symlink", "label": 0}, {"snippet_id": 79735, "code": "'?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"", "label": 0}, {"snippet_id": 62801, "code": " argument is required') kwargs['backend']='IBMBackend' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed.", "label": 0}, {"snippet_id": 12621, "code": "] break \"\"\" text1=''.join(BeautifulSoup(markdown(comment)).findAll(text=True)) text2=''.join(BeautifulSoup(markdown(last_comment)).findAll(text=True)) if text1==text2.replace(\"submitting\", \"updating\"):", "label": 0}, {"snippet_id": 41992, "code": " if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards", "label": 0}, {"snippet_id": 66287, "code": " AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type", "label": 0}, {"snippet_id": 68711, "code": "=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append", "label": 0}, {"snippet_id": 51625, "code": " **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format", "label": 0}, {"snippet_id": 3655, "code": " or no check available: returning false\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available", "label": 0}, {"snippet_id": 91688, "code": "(requirements_pex_argv), env={'PATH': text_type(os.pathsep.join(python_setup.interpreter_search_paths))}, input_files=pex_snapshot.directory_digest, description='Resolve requirements:{}'.format(\", \".join", "label": 1}, {"snippet_id": 28228, "code": "'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h'", "label": 0}, {"snippet_id": 73412, "code": ".VCFtoZarrConfigurationRepresentation \"\"\" input_vcf_dir=str(input_vcf_dir) output_zarr_dir=str(output_zarr_dir) create_directory_tree(input_vcf_dir) create_directory_tree(output_zarr_dir) pathlist_vcf=pathlib.Path(input_vcf_dir).glob(", "label": 0}, {"snippet_id": 52062, "code": " as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not", "label": 0}, {"snippet_id": 67384, "code": " fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print", "label": 1}, {"snippet_id": 78946, "code": " len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself", "label": 0}, {"snippet_id": 10885, "code": ".exceptions import RequestException, ConnectionError, Timeout import requests import yaml from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, HostUnreachableException", "label": 0}, {"snippet_id": 90537, "code": " < minimum_version: continue if maximum_version and dist.version > maximum_version: continue if jdk and not dist.jdk: continue return dist def locate(self, minimum_version=None, maximum_version=None, jdk", "label": 0}, {"snippet_id": 73844, "code": "\"directory\" in runtime_config.ftp: self.directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files", "label": 0}, {"snippet_id": 69912, "code": " not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc", "label": 0}, {"snippet_id": 35975, "code": " format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs", "label": 0}, {"snippet_id": 28869, "code": "'gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\"", "label": 0}, {"snippet_id": 42998, "code": "(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i)", "label": 0}, {"snippet_id": 46799, "code": " from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging", "label": 0}, {"snippet_id": 23852, "code": " unable to parse. We will sleep and retry as the network must be up. \"\"\" iface='' inet='' mac='' err, output=shellutil.run_get_output('ifconfig -l ether', chk_err=False) if err: raise OSUtilError(\"Can't find", "label": 0}, {"snippet_id": 59447, "code": ".allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"", "label": 1}, {"snippet_id": 59714, "code": " reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables", "label": 0}, {"snippet_id": 65485, "code": " message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS", "label": 0}, {"snippet_id": 45843, "code": " name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f", "label": 0}, {"snippet_id": 8342, "code": " the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf", "label": 1}, {"snippet_id": 46953, "code": " if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not", "label": 0}, {"snippet_id": 64230, "code": ".local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config.working_directory()) self", "label": 0}, {"snippet_id": 87621, "code": "._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ] directory_digests=tuple( entry.directory_digest for entry in dependency_classpath if entry.directory_digest ) if len(directory_digests) !=len", "label": 1}, {"snippet_id": 77625, "code": " def load_targets(self): fname=self.targetsfile if not os.path.isfile(fname): return with open(fname, 'rb') as f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list was loaded", "label": 0}, {"snippet_id": 43774, "code": " def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain", "label": 0}, {"snippet_id": 55108, "code": " by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict", "label": 0}, {"snippet_id": 15784, "code": " x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData", "label": 0}, {"snippet_id": 22043, "code": ".scp_extra_args=scp_extra_args self.ssh_extra_args=ssh_extra_args self.poll_interval=poll_interval self.seconds=seconds self.check=check self.syntax=syntax self.diff=diff self.force_handlers=force_handlers self", "label": 0}, {"snippet_id": 57734, "code": "=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case.count() review_case_count=plan.review_case.count() return http.JsonResponse({ 'rc': 0, ", "label": 0}, {"snippet_id": 324, "code": " print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({", "label": 0}, {"snippet_id": 29817, "code": ") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated", "label": 1}, {"snippet_id": 57428, "code": " model properties\"\"\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each possible proprety of TestCases Define your own method named _update_[property name] to hold specific update", "label": 0}, {"snippet_id": 52202, "code": " import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from snakemake.exceptions import RuleException", "label": 1}, {"snippet_id": 28212, "code": ":battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None", "label": 0}, {"snippet_id": 47377, "code": " os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove", "label": 0}, {"snippet_id": 20104, "code": "=self._session if session is None: return self._session=None try: session.close() except ClosedError: pass class DebugClient(_LifecycleClient): \"\"\"A high-level abstraction of a debug client(i.e. editor", "label": 0}, {"snippet_id": 53847, "code": "._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log", "label": 0}, {"snippet_id": 26985, "code": "'rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full", "label": 0}, {"snippet_id": 21960, "code": "=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args=None, poll_interval=None, seconds=None, check=None, syntax=None, diff=None, force_handlers=None, flush_cache=None, listtasks=None, listtags", "label": 0}, {"snippet_id": 58570, "code": "=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct=ContentType.objects.get_for_model(TestCaseRun) for case_run_pk in(self.case_run_1.pk, self.case_run_2.pk): comments=Comment.objects.filter", "label": 0}, {"snippet_id": 7142, "code": " my_styles[\"raw\"]=(_kw(_sort_kw_matches(single_keywords, output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords, _kw(_sort_kw_matches(acronyms, output_limit))) else: my_styles[", "label": 0}, {"snippet_id": 94574, "code": ".cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session,", "label": 0}, {"snippet_id": 79107, "code": " regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename", "label": 1}, {"snippet_id": 95627, "code": " gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through all files in input_dir and processes *.vcf.gz", "label": 0}, {"snippet_id": 11952, "code": "-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors\": True, } headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os", "label": 0}, {"snippet_id": 84179, "code": " def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options", "label": 0}, {"snippet_id": 18383, "code": "._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(", "label": 0}, {"snippet_id": 78867, "code": ".httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger", "label": 0}, {"snippet_id": 81288, "code": ": %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:(filename,fd,mime)},data=self.postData) \t\t\tself.httpRequests +=1 \t\t\tif self.shouldLog: \t\t\t\tif self.logger.verbosity > 1", "label": 0}, {"snippet_id": 5116, "code": " ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return ", "label": 0}, {"snippet_id": 58310, "code": " def setUpTestData(cls): super(TestNavigation, cls).setUpTestData() cls.user=UserFactory(email='user+1@example.com') cls.user.set_password('testing') cls.user.save() def test_urls_for_emails_with_pluses", "label": 0}, {"snippet_id": 3386, "code": " configfile: self.load_config(configfile) self.window_name=self.config['name'] self.flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir", "label": 0}, {"snippet_id": 16428, "code": ") def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen.terminate() utils.RemoveIfExists( self", "label": 0}, {"snippet_id": 62720, "code": " of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate", "label": 0}, {"snippet_id": 31850, "code": "**kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(", "label": 0}, {"snippet_id": 35865, "code": " file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict", "label": 0}, {"snippet_id": 21930, "code": "=None, tree=None, ask_sudo_pass=None, ask_su_pass=None, sudo=None, sudo_user=None, become=None, become_method=None, become_user=None, become_ask_pass=None, ask_pass=None, private_key_file=None, remote_user", "label": 0}, {"snippet_id": 86559, "code": " memoized_property _SCALAC_PLUGIN_INFO_FILE='scalac-plugin.xml' _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor'", "label": 0}, {"snippet_id": 27825, "code": "'WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 40056, "code": "() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to", "label": 1}, {"snippet_id": 71504, "code": " client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully", "label": 1}, {"snippet_id": 71254, "code": " tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag()", "label": 0}, {"snippet_id": 34927, "code": " files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()", "label": 0}, {"snippet_id": 65759, "code": ".sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout.LEFT", "label": 0}, {"snippet_id": 44736, "code": "\"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir", "label": 0}, {"snippet_id": 16409, "code": "._server_stderr, 'r') as server_stderr_file: error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE +", "label": 0}, {"snippet_id": 26400, "code": " module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): ", "label": 0}, {"snippet_id": 6049, "code": ".\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf def text_lines_from_local_file(document, remote=False): \"\"\"Returns the fulltext of the local file. @var document: fullpath", "label": 1}, {"snippet_id": 21309, "code": "='%(prog)s[options] <subreddit>[--[mpv-arguments]]', description='Play the youtube links from your favourite subreddit.') parser.add_argument('--depth', metavar='d', type=int, default=0, help='How many", "label": 0}, {"snippet_id": 59227, "code": "(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY'", "label": 0}, {"snippet_id": 23190, "code": " expected=16 python_arc=platform.architecture()[0] if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array", "label": 0}, {"snippet_id": 63428, "code": " running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self, job_wrapper): output_paths=job_wrapper.get_output_fnames() return[ str( o) for o in output_paths]", "label": 0}, {"snippet_id": 26451, "code": "\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use", "label": 0}, {"snippet_id": 78807, "code": "\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName \t\tself", "label": 0}, {"snippet_id": 49645, "code": ": Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" ", "label": 0}, {"snippet_id": 30943, "code": " missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output", "label": 0}, {"snippet_id": 61863, "code": " and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends", "label": 0}, {"snippet_id": 46786, "code": " from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from snakemake.utils import format, listfiles from", "label": 1}, {"snippet_id": 53716, "code": ", \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow", "label": 0}, {"snippet_id": 73785, "code": "\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config", "label": 0}, {"snippet_id": 79492, "code": ",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self", "label": 1}, {"snippet_id": 84517, "code": "] if parameter_value in unstructured_path_rewrites.itervalues(): return parameter_value rewrite, new_unstructured_path_rewrites=self.path_mapper.check_for_arbitrary_rewrite( parameter_value) if rewrite", "label": 0}, {"snippet_id": 66651, "code": "\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen", "label": 0}, {"snippet_id": 64312, "code": "( local_input_path, remote_path)) return results def _dataset_path( self, local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"%s_files\" % remote_path", "label": 0}, {"snippet_id": 39844, "code": ")) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir", "label": 0}, {"snippet_id": 13843, "code": ".locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals, self.locals) if __name__=='__main__': for k, v in _safe_locals.iteritems(): print k,", "label": 0}, {"snippet_id": 23702, "code": " retcode=shellutil.run(\"cdcontrol -f{0} eject\".format(dvd)) if chk_err and retcode !=0: raise OSUtilError(\"Failed to eject dvd: ret={0}\".format(retcode)) def restart_if(self, ifname): shellutil.run(\"/etc", "label": 0}, {"snippet_id": 67231, "code": " node, client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info:", "label": 0}, {"snippet_id": 89377, "code": "(name, version): if isinstance(version, string_types): version=Revision.lenient(version) if version and not isinstance(version, Revision): raise ValueError('{} must be a string or a Revision object, given:", "label": 0}, {"snippet_id": 49433, "code": ", benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False", "label": 0}, {"snippet_id": 8791, "code": " log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename=os.path.join(entry", "label": 0}, {"snippet_id": 32882, "code": "=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included", "label": 0}, {"snippet_id": 67884, "code": " the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or", "label": 0}, {"snippet_id": 73603, "code": ".blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print", "label": 1}, {"snippet_id": 13900, "code": "): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler", "label": 0}, {"snippet_id": 73172, "code": "): with open(local_file, 'wb') as file_out, gzip.open(local_file_gz, 'rb') as file_in: shutil.copyfileobj(file_in, file_out) def process_data_files(input_dir, temp_dir, output_dir): \"\"\" Iterates through", "label": 0}, {"snippet_id": 87166, "code": " compile_contexts: zinc_analysis[compile_context.target]=(compile_context.classes_dir, compile_context.jar_file, compile_context.analysis_file) if zinc_args is not None: for compile_context in compile_contexts", "label": 0}, {"snippet_id": 86857, "code": ":none', '-S-nowarn', '-S-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-S-Xfatal-warnings', '-C-Werror') @classmethod def get_fatal_warnings_disabled_args_default", "label": 0}, {"snippet_id": 30035, "code": ")]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards", "label": 0}, {"snippet_id": 23513, "code": " if self.is_sys_user(username): raise OSUtilError((\"User{0} is a system user, \" \"will not set password.\").format(username)) passwd_hash=textutil.gen_password_hash(password, crypt_id, salt_len) cmd=\"echo ", "label": 0}, {"snippet_id": 33096, "code": " logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes", "label": 0}, {"snippet_id": 78146, "code": " log_spawn_name(): send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name']) if c.no_shell: while True: time.sleep(1) else: try: import IPython IPython.embed() except ImportError: while True: try:", "label": 1}, {"snippet_id": 77455, "code": ".ctx, self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs, name='.'.join((wname, 'pr{0}'.format(i)))) self.processes.append(w) w.start(self.pr_sa) except Exception", "label": 0}, {"snippet_id": 8309, "code": " except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\")", "label": 0}, {"snippet_id": 78721, "code": " executer(self, *args): \"\"\"Execute remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]", "label": 1}, {"snippet_id": 16533, "code": "( self): return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive", "label": 0}, {"snippet_id": 28520, "code": ".module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self", "label": 0}, {"snippet_id": 57432, "code": "\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each possible proprety of TestCases Define your own method named _update_[property name] to hold specific update logic. \"\"\" ctype", "label": 0}, {"snippet_id": 76791, "code": "--topic_successtimeout', type=float, default=0.1, help='Topic success timeout') parser.add_argument('--errortimeout', type=float, default=3, help='Error timeout') parser.add_argument('--stop-on-closed'", "label": 0}, {"snippet_id": 58215, "code": ".contrib.contenttypes.models import ContentType from django.core import serializers from django.urls import reverse from django_comments.models import Comment from tcms.management.models import Priority", "label": 0}, {"snippet_id": 61972, "code": " XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX", "label": 0}, {"snippet_id": 15375, "code": "]: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed(", "label": 0}, {"snippet_id": 40465, "code": "[last:])) f.append(\"$\") return \"\".join(f) def apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group", "label": 0}, {"snippet_id": 95692, "code": " input_dir=str(input_dir) temp_dir=str(temp_dir) output_dir=str(output_dir) create_directory_tree(input_dir) create_directory_tree(temp_dir) create_directory_tree(output_dir) pathlist_gz=pathlib.Path(input_dir", "label": 0}, {"snippet_id": 42003, "code": "}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables", "label": 0}, {"snippet_id": 55443, "code": "\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not", "label": 0}, {"snippet_id": 1373, "code": " }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete',", "label": 0}, {"snippet_id": 54289, "code": " return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values()))", "label": 0}, {"snippet_id": 8287, "code": " file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError", "label": 1}, {"snippet_id": 36085, "code": "=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self.rule.dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output:", "label": 0}, {"snippet_id": 73156, "code": "}\".format(file_counter, file_list_total, file_path_local)) file_counter=file_counter +1 def fetch_file_from_url(url, local_file): urllib.request.urlretrieve(url, local_file) def decompress_gzip(local_file_gz", "label": 0}, {"snippet_id": 84071, "code": " self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) if not remote_work_dir_copy: work_dir_outputs", "label": 1}, {"snippet_id": 43873, "code": "): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not", "label": 0}, {"snippet_id": 94421, "code": "(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3: logger.debug(\"Main window process has finished. Running", "label": 1}, {"snippet_id": 65891, "code": "%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if", "label": 0}, {"snippet_id": 65985, "code": "(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)]", "label": 0}, {"snippet_id": 13956, "code": "=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers", "label": 1}, {"snippet_id": 72669, "code": " print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled.", "label": 1}, {"snippet_id": 64453, "code": ": c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\"", "label": 0}, {"snippet_id": 1735, "code": "=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart'", "label": 0}, {"snippet_id": 16535, "code": ": return( self.CurrentFiletypeCompletionEnabled() and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self", "label": 0}, {"snippet_id": 58295, "code": " import EnvGroupFactory from tcms.tests.factories import EnvGroupPropertyMapFactory from tcms.tests.factories import EnvPropertyFactory class TestNavigation(test.TestCase): @classmethod def setUpTestData(cls", "label": 0}, {"snippet_id": 68988, "code": "%s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s", "label": 0}, {"snippet_id": 8394, "code": " file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\", 'replace') for line in filestream] filestream.close() if not _is_english_text('\\n'.join(lines)): log.warning(\"It seems the", "label": 1}, {"snippet_id": 67289, "code": ": %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return", "label": 0}, {"snippet_id": 95214, "code": " module for the benchmark. It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs", "label": 0}, {"snippet_id": 60403, "code": ".name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name=='X': ex, var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2)", "label": 0}, {"snippet_id": 6610, "code": " for local file %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit", "label": 0}, {"snippet_id": 68270, "code": " status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index", "label": 0}, {"snippet_id": 4108, "code": " and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For the moment the pieces of the representation code are left in this module. \"\"\" from __future__", "label": 0}, {"snippet_id": 29388, "code": "=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names", "label": 1}, {"snippet_id": 26760, "code": ".type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data[", "label": 0}, {"snippet_id": 14788, "code": " in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData(", "label": 0}, {"snippet_id": 72283, "code": "!=placeholder_self.name, \\ \"Refusing to route reply back to the same \" \\ \"network, as this would cause a recursive loop\" log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name,", "label": 0}, {"snippet_id": 6273, "code": " local_file=tempfile.mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" ", "label": 1}, {"snippet_id": 75179, "code": ".wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init() self.bind_kt_ticker.tick() while self.p", "label": 0}, {"snippet_id": 29981, "code": " as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern", "label": 0}, {"snippet_id": 65543, "code": " MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status", "label": 0}, {"snippet_id": 29669, "code": " value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return", "label": 0}, {"snippet_id": 61868, "code": " circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a", "label": 0}, {"snippet_id": 36379, "code": " existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def", "label": 0}, {"snippet_id": 49622, "code": ".persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error", "label": 0}, {"snippet_id": 9645, "code": "(auth_field, output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items", "label": 0}, {"snippet_id": 32563, "code": ".error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile", "label": 0}, {"snippet_id": 78256, "code": ": try: self.postmsg(t[1], msg, t[0]) except exc.Success as e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout)", "label": 0}, {"snippet_id": 31680, "code": " dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_,", "label": 0}, {"snippet_id": 36957, "code": "=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources", "label": 0}, {"snippet_id": 47512, "code": "()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 10419, "code": " not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc", "label": 0}, {"snippet_id": 74992, "code": "=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location) and", "label": 0}, {"snippet_id": 16063, "code": " request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response", "label": 0}, {"snippet_id": 61523, "code": "(var / self.shots)) else: a, P=spectral_decomposition_qubit(A) p0=self.ev(P[0], self._observe.wires) n0=np.random.binomial(self.shots, p0) ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod", "label": 0}, {"snippet_id": 53054, "code": "\"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{", "label": 0}, {"snippet_id": 60115, "code": "=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p for(state,p) in probabilities.items() if state[i]=='1')-1)-(2*sum(p for(state,p) in probabilities.items", "label": 0}, {"snippet_id": 40186, "code": ".lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards,", "label": 0}, {"snippet_id": 90632, "code": "=_parse_java_version(name, a) version_b=_parse_java_version(name, b) if version_a is None: return version_b if version_b is None: return version_a return stricter(version_a, version_b) minimum_version=_get_stricter_version", "label": 0}, {"snippet_id": 79117, "code": ".NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) \t\t\tfd.flush() \t\t\tfd.seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: ", "label": 1}, {"snippet_id": 13245, "code": "\"object\"][\"sha\"] url=\"https://api.github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"]) data[\"new_branch\"]=\"{}-pep8-patch\".format(data[\"target_repo_branch\"]) request_json={ \"ref\": \"refs/heads/{", "label": 0}, {"snippet_id": 7244, "code": " acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords :var", "label": 0}, {"snippet_id": 52997, "code": "(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input", "label": 0}, {"snippet_id": 81435, "code": ",extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList=[] \t\t\tfor e in extList: \t\t\t\ttmpExtList.append((e,getMime(extensions,e))) \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest", "label": 0}, {"snippet_id": 20053, "code": ".start_wrapper_script( script, *args, **kwargs) else: start=DebugAdapter.start new_addr=Address.as_server if detachable else Address.as_client addr=new_addr(None, self._addr.port) self._adapter=start(argv, addr=addr,", "label": 0}, {"snippet_id": 53145, "code": " Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__", "label": 0}, {"snippet_id": 68894, "code": " to stop Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import ", "label": 0}, {"snippet_id": 11112, "code": "(self): return \"Header(%s, %d)\" %(self.etag, self.mtime) def is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self.mtime, other.mtime) > 0 else: return False def serialize", "label": 0}, {"snippet_id": 80753, "code": "\ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt]+nastyExtVariants", "label": 1}, {"snippet_id": 59134, "code": "-based kernels. -projectq.backends.ClassicalSimulator()\t A simple introspective simulator that only permits classical operations. -projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class", "label": 0}, {"snippet_id": 45168, "code": " def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self,", "label": 0}, {"snippet_id": 41139, "code": " self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add)", "label": 0}, {"snippet_id": 49226, "code": " clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if", "label": 0}, {"snippet_id": 87517, "code": "._zinc.rebase_map_args) zinc_args.extend(args) zinc_args.extend(self._get_zinc_arguments(settings)) zinc_args.append('-transactional') for option_set in compiler_option_sets: enabled_args=self.get_options", "label": 0}, {"snippet_id": 22414, "code": ") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys config\" rc=shellutil.run", "label": 0}, {"snippet_id": 91707, "code": " ExecuteProcessResult, ExecuteProcessRequest, requirements_pex_request) source_roots=source_root_config.get_source_roots() sources_snapshots_and_source_roots=[] for maybe_source_target in all_targets: if hasattr", "label": 0}, {"snippet_id": 74147, "code": " configuration.\\n\" \"blosc_shuffle_mode could not be converted to integer.\") benchmark_data_input_types=[\"vcf\", \"zarr\"] class BenchmarkConfigurationRepresentation: \"\"\" Utility class for object representation", "label": 0}, {"snippet_id": 60674, "code": ".mean_photon(reg) var=0 elif self._observe.name=='X': ex, var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name", "label": 0}, {"snippet_id": 57044, "code": "(v_type, None) if pipe is None: error='Unsupported value type.' else: try: value=pipe(val) except Exception as e: error=str(e) return value, error def say_no(error_msg): ajax_response={'rc': 1, 'response'", "label": 0}, {"snippet_id": 94707, "code": " to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser('validate'", "label": 0}, {"snippet_id": 29250, "code": "(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path", "label": 0}, {"snippet_id": 3658, "code": " returning false\") return CheckState.STOPPED elif check_available and run_component_check(comp): logger.debug(\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check", "label": 0}, {"snippet_id": 61653, "code": " value.'.format(expectation.imag)) return expectation.real def reset(self): \"\"\"Reset the device\"\"\" self._state =None self._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a full", "label": 0}, {"snippet_id": 56000, "code": " decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input", "label": 0}, {"snippet_id": 64608, "code": "\"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count", "label": 0}, {"snippet_id": 48458, "code": " **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable", "label": 0}, {"snippet_id": 7640, "code": "(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info", "label": 0}, {"snippet_id": 59325, "code": " measurement result being registered(at the end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or", "label": 0}, {"snippet_id": 9961, "code": "\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords", "label": 0}, {"snippet_id": 52744, "code": "\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of", "label": 0}, {"snippet_id": 66714, "code": "(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException", "label": 0}, {"snippet_id": 56004, "code": " return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self", "label": 0}, {"snippet_id": 27295, "code": " 'mdi:wifi', None] } MODULE_SCHEMA=vol.Schema({ vol.Required(cv.string): vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string", "label": 1}, {"snippet_id": 11059, "code": " returned with status %s. I don't know how to handle that.\" %(url, response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime=mtime) class Header(object):", "label": 0}, {"snippet_id": 54561, "code": "=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 52962, "code": "(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule", "label": 0}, {"snippet_id": 19631, "code": " _parse_args(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ) parser.add_argument('--nodebug', action='store_true') host=parser.add_mutually_exclusive_group() host.add_argument(", "label": 0}, {"snippet_id": 30171, "code": ": self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None)", "label": 0}, {"snippet_id": 39120, "code": "=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa", "label": 0}, {"snippet_id": 80566, "code": "\tproxyHostname=args.proxy[\"hostname\"] \tproxyPort=args.proxy[\"port\"] \tproxy=\"\" \tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None", "label": 0}, {"snippet_id": 43229, "code": "(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards", "label": 0}, {"snippet_id": 21647, "code": " from matplotlib.colors import ListedColormap X_set, y_set=X_train, y_train X1, X2=np.meshgrid(np.arange(start=X_set[:, 0].min() -1, stop=X_set[:, 0].max() +1, step=0.01), np.arange(start=X_set[:, 1].min()", "label": 0}, {"snippet_id": 81102, "code": "(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t", "label": 0}, {"snippet_id": 75214, "code": "=BijectiveSetMap() def set_req_handler(self, interface, method, fun): self.req_handlers[(interface, method)]=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler", "label": 0}, {"snippet_id": 55321, "code": "(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag, cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster,", "label": 0}, {"snippet_id": 41934, "code": " the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic,", "label": 0}, {"snippet_id": 88388, "code": "*msg_elements) def error(self, *msg_elements): self._run_tracker.log(Report.ERROR, *msg_elements) def fatal(self, *msg_elements): self._run_tracker.log(Report.FATAL, *msg_elements) def __init__(self, options", "label": 0}, {"snippet_id": 35650, "code": " self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name", "label": 0}, {"snippet_id": 25416, "code": ": \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None", "label": 0}, {"snippet_id": 57228, "code": " ) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=request.user try: mailto(**mail_context) except Exception: pass if ctype=='testruns.testcaserun' and field=", "label": 0}, {"snippet_id": 26422, "code": "'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self", "label": 0}, {"snippet_id": 90206, "code": ") @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable. :returns: The java distribution", "label": 0}, {"snippet_id": 77604, "code": " def get_userqueue(self, domain): try: uq=self.userqueues[domain] except KeyError: self.log.info('Created userqueue for %s', domain) uq=Queue() self.userqueues[domain]=uq return uq def load_targets(self", "label": 0}, {"snippet_id": 91031, "code": " all explicitly configured JDK paths. :return: mapping of os name -> list of jdk_paths :rtype: dict of string -> list of string \"\"\" return self._normalized_jdk_paths @memoized_method def _locator(self):", "label": 0}, {"snippet_id": 72768, "code": " It reads the command line arguments, reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records", "label": 0}, {"snippet_id": 32946, "code": "() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for", "label": 0}, {"snippet_id": 19037, "code": " swagger_schema def load(target): \"\"\" Given one of the supported target formats, load a swagger schema into it's python representation. \"\"\" raw_schema=load_source(target) return parse(raw_schema) def validate", "label": 0}, {"snippet_id": 52656, "code": ", requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f", "label": 0}, {"snippet_id": 65616, "code": ".startswith(\"client\"): status_flags &=~(STATUS_SERVERS|STATUS_HASERVERS) statusdict=fs.status(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs", "label": 0}, {"snippet_id": 38732, "code": " set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules,", "label": 0}, {"snippet_id": 29704, "code": " str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value", "label": 0}, {"snippet_id": 53039, "code": "() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell", "label": 0}, {"snippet_id": 38411, "code": ", name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule", "label": 0}, {"snippet_id": 59040, "code": "', EnvProperty.objects.all(), fields=('name', 'value'))) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), expected_json) def test_get_env_properties_by_group(self): response", "label": 0}, {"snippet_id": 42581, "code": ".discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output", "label": 0}, {"snippet_id": 44695, "code": ".info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap", "label": 0}, {"snippet_id": 91059, "code": ").paths or{} for name, paths in sorted(jdk_paths.items()): rename=normalize_os_name(name) if rename in normalized: logger.warning('Multiple OS names alias to \"{}\"; combining results.'.format(rename)) normalized", "label": 0}, {"snippet_id": 52614, "code": " output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return", "label": 0}, {"snippet_id": 95996, "code": " print(\"[VCF-Zarr] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF", "label": 0}, {"snippet_id": 39990, "code": " or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj=str.__new__(cls, file) obj._is_function=type(file).__name__==\"function\" obj._file=file obj.rule=None obj._regex", "label": 0}, {"snippet_id": 89644, "code": "\"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" return self._get_version(self.java) def find_libs(self, names", "label": 0}, {"snippet_id": 31701, "code": "=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion", "label": 1}, {"snippet_id": 68580, "code": "\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod", "label": 0}, {"snippet_id": 14348, "code": "}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format( self", "label": 0}, {"snippet_id": 93727, "code": "(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s", "label": 0}, {"snippet_id": 48753, "code": " benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self", "label": 0}, {"snippet_id": 70058, "code": " RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine.Lustre.FileSystem import * class GlobalStartEventHandler", "label": 0}, {"snippet_id": 41063, "code": " self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name", "label": 0}, {"snippet_id": 61426, "code": "=complex) self._state[0]=1 self._out=np.full(self.wires, np.nan) for operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]=", "label": 0}, {"snippet_id": 86800, "code": ".implementation_version() +[('BaseZincCompile', 7)] @classmethod def get_jvm_options_default(cls, bootstrap_option_values): return('-Dfile.encoding=UTF-8', '-Dzinc.analysis.cache.limit=1000', '-Djava.awt", "label": 0}, {"snippet_id": 25747, "code": "'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle", "label": 0}, {"snippet_id": 12156, "code": ") for file in list(files.keys()): if file[-3:] !=\".py\": del files[file] return files def run_pycodestyle(data, config): \"\"\" Run pycodestyle script on the files and update the data dictionary \"\"\" headers", "label": 0}, {"snippet_id": 3413, "code": " slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self.logger.error", "label": 0}, {"snippet_id": 82383, "code": "/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x[\"templateName\"]==args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"", "label": 0}, {"snippet_id": 53810, "code": " in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item", "label": 0}, {"snippet_id": 46585, "code": ": return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr", "label": 0}, {"snippet_id": 75972, "code": ", data): if status==wzrpc.status.success: self.log.debug('Successfull auth for(%s, %s)', i, m) elif status==wzrpc.status.e_auth_wrong_hash: raise beon.PermanentError( 'Cannot authentificate for({0},{1}", "label": 1}, {"snippet_id": 77543, "code": "[domain]: self.log.debug('Loaded user %s:%s', domain, ud['login']) uq.put(ud) self.userqueues[domain]=uq except Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users", "label": 0}, {"snippet_id": 37380, "code": " same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput", "label": 0}, {"snippet_id": 83122, "code": " __name__) __all__=[ 'LwrJobRunner'] NO_REMOTE_GALAXY_FOR_METADATA_MESSAGE=\"LWR misconfiguration -LWR client configured to set metadata remotely, but remote LWR isn't properly configured with a galaxy_home", "label": 0}, {"snippet_id": 11209, "code": " configuration. It does it by querying an URL from which it receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is given it reads it's default", "label": 0}, {"snippet_id": 43769, "code": ".overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return(", "label": 0}, {"snippet_id": 86454, "code": " text_type from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.subsystems.scala_platform import ScalaPlatform from", "label": 0}, {"snippet_id": 9820, "code": ", but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary", "label": 0}, {"snippet_id": 53176, "code": " if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies", "label": 0}, {"snippet_id": 50428, "code": " decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 59663, "code": ".backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in", "label": 0}, {"snippet_id": 90284, "code": " search_path.strip().split(os.pathsep): yield self.Location.from_bin(bin_path) class _OSXEnvironment(_DistributionEnvironment): _OSX_JAVA_HOME_EXE='/usr/libexec/java_home' @classmethod def standard(cls", "label": 0}, {"snippet_id": 5831, "code": " 100 * length) partial_text=[fulltext[get_index(start):get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os", "label": 0}, {"snippet_id": 44914, "code": " RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority", "label": 0}, {"snippet_id": 86563, "code": " _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class BaseZincCompile(JvmCompile)", "label": 0}, {"snippet_id": 46541, "code": ": yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in", "label": 0}, {"snippet_id": 79209, "code": " and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t\texcept: \t\t\t\t\tresult=str(fileUploaded.group(0)) \t\treturn result \t ", "label": 0}, {"snippet_id": 33157, "code": ", printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete", "label": 0}, {"snippet_id": 11833, "code": "{key: head[key]} return base def match_webhook_secret(request): \"\"\"Match the webhook secret sent from GitHub\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: header_signature=request.headers.get", "label": 1}, {"snippet_id": 81969, "code": "\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"--regex-override\",metavar", "label": 0}, {"snippet_id": 8918, "code": " spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param", "label": 1}, {"snippet_id": 38201, "code": " format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception,", "label": 0}, {"snippet_id": 56563, "code": "['tcms.%s.forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"", "label": 1}, {"snippet_id": 73358, "code": ": if os.path.isfile(local_filepath): with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all", "label": 0}, {"snippet_id": 16910, "code": " JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync(", "label": 0}, {"snippet_id": 57931, "code": " add_comment(runs, comment, request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data", "label": 0}, {"snippet_id": 55089, "code": " same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power", "label": 0}, {"snippet_id": 65565, "code": ".init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler", "label": 0}, {"snippet_id": 68166, "code": " in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys(", "label": 0}, {"snippet_id": 62219, "code": ".__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self._out=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\"", "label": 1}, {"snippet_id": 64526, "code": " from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model", "label": 0}, {"snippet_id": 60387, "code": " |[q[i] for i in operation.wires] self.state=self.eng.run('fock', cutoff_dim=self.cutoff) reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name", "label": 0}, {"snippet_id": 93254, "code": "-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name)", "label": 0}, {"snippet_id": 86608, "code": "}</classname> </plugin> \"\"\".format(scalac_plugin_target.plugin, scalac_plugin_target.classname)).strip()) @staticmethod def _write_javac_plugin_info(resources_dir, javac_plugin_target): javac_plugin_info_file", "label": 0}, {"snippet_id": 47510, "code": ", value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads", "label": 0}, {"snippet_id": 24378, "code": " data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning", "label": 0}, {"snippet_id": 18375, "code": " stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None", "label": 0}, {"snippet_id": 65067, "code": "(node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"%s: Start of %s %s(%s) succeeded\" % \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def", "label": 0}, {"snippet_id": 87558, "code": ".fatal_warnings_disabled_args zinc_args.extend(disabled_args) if not self._clear_invalid_analysis: zinc_args.append('-no-clear-invalid-analysis') if not zinc_file_manager: zinc_args.append('-no-zinc-file", "label": 0}, {"snippet_id": 72534, "code": " the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser", "label": 0}, {"snippet_id": 56950, "code": "\"\" Exampls: 1. get_value_by_type('True', 'bool') (1, None) 2. get_value_by_type('19860624 123059', 'datetime') (datetime.datetime(1986, 6, 24, 12, 30, 59), None) 3. get_value_by_type('5', 'int') ('5', None", "label": 0}, {"snippet_id": 41984, "code": " Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, ", "label": 0}, {"snippet_id": 45090, "code": " threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate def resources(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources", "label": 0}, {"snippet_id": 34611, "code": " a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property", "label": 1}, {"snippet_id": 81956, "code": "(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates,", "label": 0}, {"snippet_id": 68859, "code": ".set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\"", "label": 0}, {"snippet_id": 12925, "code": "}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\") def create_gist(data, config): \"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON[\"public", "label": 0}, {"snippet_id": 83740, "code": ".Job.states.ERROR, model.Job.states.DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally", "label": 0}, {"snippet_id": 35539, "code": "=None, plainstr=False): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self)", "label": 0}, {"snippet_id": 7607, "code": "(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info", "label": 0}, {"snippet_id": 1147, "code": ") def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet", "label": 0}, {"snippet_id": 71405, "code": " layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 50150, "code": "), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir", "label": 0}, {"snippet_id": 60794, "code": " class Device(abc.ABC): \"\"\"Abstract base class for devices.\"\"\" _current_context=None name='' short_name='' api_version='' version='' author='' _capabilities={} _gates={} _observables={} _circuits={} def", "label": 0}, {"snippet_id": 26596, "code": "'Pressure'], 1) elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp']", "label": 0}, {"snippet_id": 71807, "code": ".message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -%s\" % e.message except ModelFileException, e: print \"ModelFile: %s", "label": 1}, {"snippet_id": 22049, "code": " self.seconds=seconds self.check=check self.syntax=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path", "label": 0}, {"snippet_id": 18701, "code": "}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1", "label": 0}, {"snippet_id": 60697, "code": "='Homodyne': ex, var=self.state.quad_expectation(reg, *self._observe.params) elif self._observe.name=='Displacement': ex=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np", "label": 0}, {"snippet_id": 83991, "code": "(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id)) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper): \"\"\"Recovers jobs stuck", "label": 0}, {"snippet_id": 90335, "code": " plist_results: home=distribution['JVMHomePath'] yield self.Location.from_home(home) except subprocess.CalledProcessError: pass class _LinuxEnvironment(_DistributionEnvironment): _STANDARD_JAVA_DIST_DIRS=('/usr/lib", "label": 0}, {"snippet_id": 83043, "code": "(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s", "label": 0}, {"snippet_id": 32669, "code": "< 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other)", "label": 0}, {"snippet_id": 59937, "code": " OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number", "label": 0}, {"snippet_id": 70724, "code": " if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support", "label": 1}, {"snippet_id": 52277, "code": " self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name", "label": 0}, {"snippet_id": 82272, "code": "\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input", "label": 0}, {"snippet_id": 69688, "code": " nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers) print \"\\t%d OST on %s\"", "label": 0}, {"snippet_id": 68454, "code": "(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown", "label": 0}, {"snippet_id": 35490, "code": " dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list)", "label": 0}, {"snippet_id": 83072, "code": " import JobDestination from galaxy.jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch", "label": 0}, {"snippet_id": 26784, "code": "] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0", "label": 0}, {"snippet_id": 45271, "code": " if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir,", "label": 0}, {"snippet_id": 19550, "code": ":') and '--module' in pydevd: pydevd.remove('--module') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append", "label": 0}, {"snippet_id": 61504, "code": "._observe.wires]) else: if 0: ev=self.ev(A, self._observe.wires) var=self.ev(A**2, self._observe.wires) -ev**2 ev=np.random.normal(ev, np.sqrt(var / self.shots)) else: a, P=spectral_decomposition_qubit", "label": 0}, {"snippet_id": 84246, "code": " use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration", "label": 0}, {"snippet_id": 63833, "code": ".job_runner_external_id log.debug(\"Attempt remote lwr kill of job with url %s and id %s\" %(lwr_url, job_id)) client=self.get_client(job.destination_params, job_id) client.kill() def recover( self, job, job_wrapper", "label": 0}, {"snippet_id": 75018, "code": " destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration", "label": 0}, {"snippet_id": 18694, "code": " debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self", "label": 0}, {"snippet_id": 42214, "code": ") if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration", "label": 0}, {"snippet_id": 46066, "code": " shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else", "label": 1}, {"snippet_id": 44664, "code": " \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os", "label": 0}, {"snippet_id": 44822, "code": " def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate", "label": 0}, {"snippet_id": 46525, "code": " item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None,", "label": 0}, {"snippet_id": 46800, "code": ".utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def", "label": 0}, {"snippet_id": 7407, "code": "\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if", "label": 0}, {"snippet_id": 71945, "code": " self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event", "label": 0}, {"snippet_id": 13354, "code": "\"results\"].items(): url=\"https://api.github.com/repos/{}/contents/{}\" url=url.format(fullname, file) params={\"ref\": data[\"new_branch\"]} r=requests.get(url, params=params, headers=headers, auth=auth) sha_blob", "label": 0}, {"snippet_id": 37782, "code": " wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems", "label": 0}, {"snippet_id": 70649, "code": ".get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(", "label": 0}, {"snippet_id": 28499, "code": ".\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if", "label": 0}, {"snippet_id": 8645, "code": " MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For", "label": 0}, {"snippet_id": 64144, "code": " path in self.get_output_files(job_wrapper)] metadata_kwds['output_fnames']=outputs metadata_kwds['compute_tmp_dir']=working_directory metadata_kwds['config_root']=remote_galaxy_home default_config_file", "label": 0}, {"snippet_id": 19350, "code": ") tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_url(httpbin): native={ 'origin': '127.0.0.1', 'args':{}, } source=httpbin.url +'/get' result=load_source(source) assert", "label": 0}, {"snippet_id": 36029, "code": ".wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self", "label": 0}, {"snippet_id": 52778, "code": " chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare(", "label": 0}, {"snippet_id": 21630, "code": "(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors import ListedColormap X_set, y_set=X_train, y_train X1, X2", "label": 0}, {"snippet_id": 5514, "code": ".setdefault(fieldcode, set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires))", "label": 0}, {"snippet_id": 87918, "code": "]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin classpath entries. The first entry", "label": 0}, {"snippet_id": 33008, "code": "=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules", "label": 0}, {"snippet_id": 18196, "code": " except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=(", "label": 0}, {"snippet_id": 30563, "code": " format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs,", "label": 0}, {"snippet_id": 81669, "code": " \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern: \t\t\t\t\t \t\t\t\t\turl=self.codeExecUrlPattern.replace(\"$captGroup$\",uploadRes) \t\t\t\telse: \t\t\t\t\tpass \t\t\t\t\t \t\t\t\tif url: \t\t\t\t\texecutedCode", "label": 0}, {"snippet_id": 23829, "code": "}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None' if unable", "label": 0}, {"snippet_id": 54697, "code": "(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule", "label": 0}, {"snippet_id": 93775, "code": " True def start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp", "label": 0}, {"snippet_id": 50639, "code": ".workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\"))", "label": 0}, {"snippet_id": 65178, "code": "), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(", "label": 0}, {"snippet_id": 87394, "code": " self._verify_zinc_classpath(upstream_analysis.keys()) def relative_to_exec_root(path): return fast_relpath(path, get_buildroot()) scala_path=self.scalac_classpath() compiler_interface=self._zinc.compiler_interface", "label": 1}, {"snippet_id": 46960, "code": " if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o", "label": 0}, {"snippet_id": 15014, "code": " return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data", "label": 0}, {"snippet_id": 76718, "code": "=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default='randav', help='Directory with avatars') parser.add_argument('--rp-timeout', '-T', type=int, default=10, help=", "label": 0}, {"snippet_id": 12624, "code": " text1=''.join(BeautifulSoup(markdown(comment)).findAll(text=True)) text2=''.join(BeautifulSoup(markdown(last_comment)).findAll(text=True)) if text1==text2.replace(\"submitting\", \"updating\"): PERMITTED_TO_COMMENT", "label": 0}, {"snippet_id": 80683, "code": " \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a))", "label": 0}, {"snippet_id": 85938, "code": ".Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class JavacCompile(JvmCompile): \"\"\"Compile Java code using Javac.\"\"\" _name='java'", "label": 0}, {"snippet_id": 29265, "code": " prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e", "label": 0}, {"snippet_id": 25916, "code": " >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle']", "label": 0}, {"snippet_id": 64406, "code": " return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name", "label": 0}, {"snippet_id": 33894, "code": ".overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not overwrite_first_rule", "label": 0}, {"snippet_id": 33350, "code": "=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self", "label": 0}, {"snippet_id": 24355, "code": " config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor", "label": 0}, {"snippet_id": 20814, "code": ") evt=self._get_message_handle(match, handlername) return AwaitableEvent(event, lambda: result[\"msg\"], evt) def _get_awaiter_for_request(self, req, **kwargs): if self.closed: raise RuntimeError('session", "label": 0}, {"snippet_id": 9551, "code": " spires output -BUT NOTE: it is here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them", "label": 0}, {"snippet_id": 45177, "code": " func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None", "label": 0}, {"snippet_id": 85081, "code": ") def register_custom_tool(key): dummy_jardep=JarDependency('missing spec', ' //:{}'.format(key)) cls.register_jvm_tool(register, cls._key_for_tool_version(key, 'custom'), classpath=[dummy_jardep]) register_custom_tool", "label": 1}, {"snippet_id": 20026, "code": "._adapter is not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv, script=None, wait_for_connect=None, detachable=True, env=None, cwd=None, **kwargs): if script is not None", "label": 0}, {"snippet_id": 16363, "code": "-stderr={0}'.format( self._server_stderr)) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest", "label": 0}, {"snippet_id": 87285, "code": "(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip())) @memoized_property def _zinc_cache_dir(self): \"\"\"A directory where zinc can store compiled copies", "label": 1}, {"snippet_id": 21843, "code": " kernel_initializer='uniform', activation='relu')) classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid')) classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy", "label": 1}, {"snippet_id": 30188, "code": "(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self,", "label": 0}, {"snippet_id": 19042, "code": " one of the supported target formats, load a swagger schema into it's python representation. \"\"\" raw_schema=load_source(target) return parse(raw_schema) def validate(raw_schema, target=None, **kwargs): \"\"", "label": 0}, {"snippet_id": 23187, "code": " python x86_64?? \"\"\" iface='' expected=16 python_arc=platform.architecture()[0] if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP", "label": 0}, {"snippet_id": 68255, "code": ": status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target", "label": 0}, {"snippet_id": 26756, "code": "'min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=", "label": 0}, {"snippet_id": 52917, "code": " in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self", "label": 0}, {"snippet_id": 45693, "code": ".dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s", "label": 0}, {"snippet_id": 62270, "code": "(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self", "label": 0}, {"snippet_id": 73394, "code": " directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type", "label": 0}, {"snippet_id": 51169, "code": "( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names", "label": 0}, {"snippet_id": 94124, "code": "=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self", "label": 0}, {"snippet_id": 43812, "code": " in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\"", "label": 0}, {"snippet_id": 78232, "code": "') self.dologin() def comment_loop(self): for t in self.targets: self.schedule(self.add_comment,(t, self.msgfun())) if len(self.targets)==0: self.schedule(self.scan_targets_loop) else: self.schedule(self", "label": 0}, {"snippet_id": 73827, "code": "[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp: self.use_tls=config_str_to_bool(runtime_config.ftp[\"use_tls\"]) if \"directory", "label": 0}, {"snippet_id": 36719, "code": " return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other", "label": 0}, {"snippet_id": 47118, "code": ".expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self):", "label": 1}, {"snippet_id": 2972, "code": "(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component", "label": 0}, {"snippet_id": 3023, "code": "]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window=self.session.new_window(comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp", "label": 0}, {"snippet_id": 46475, "code": " in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name", "label": 0}, {"snippet_id": 29414, "code": ".file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard", "label": 0}, {"snippet_id": 48874, "code": "=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values", "label": 0}, {"snippet_id": 58800, "code": " test_change_case_run_status(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.update_url,{ 'content_type': 'testruns.testcaserun', 'object_pk': self.case_run_1.pk,", "label": 0}, {"snippet_id": 75164, "code": " self.p.wz_auth_requests=[ (b'Router', b'auth-bind-route'), (b'Router', b'auth-unbind-route'), (b'Router', b'auth-set-route-type')] self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate", "label": 0}, {"snippet_id": 46888, "code": ".resources.items() } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output", "label": 0}, {"snippet_id": 15003, "code": ") if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR", "label": 0}, {"snippet_id": 88532, "code": " @property def source_roots(self): \"\"\"Returns the:class:`pants.source.source_root.SourceRoots` instance for the current run. :API: public \"\"\" return self._source_roots @property def target_roots(self): ", "label": 0}, {"snippet_id": 83374, "code": ".__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description=dependencies_description, env", "label": 0}, {"snippet_id": 35360, "code": "[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)", "label": 0}, {"snippet_id": 77686, "code": " self.pc.sets.update(data['sets']) def load_bumplimit_set(self): if not os.path.isfile(self.bumplimitfile): return with open(self.bumplimitfile, 'rb') as f: self.pc.sets['bumplimit'].update(pickle.loads(f", "label": 0}, {"snippet_id": 81643, "code": ") and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl", "label": 1}, {"snippet_id": 78585, "code": " while len(self.forums)==0: self.counter_tick() self.w.sleep(1) self.schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker", "label": 0}, {"snippet_id": 30720, "code": "(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^", "label": 0}, {"snippet_id": 13012, "code": "\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"]", "label": 0}, {"snippet_id": 73686, "code": "/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value): try: float(value) return True except ValueError: return False class ConfigurationRepresentation", "label": 0}, {"snippet_id": 29807, "code": " if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic,", "label": 0}, {"snippet_id": 65516, "code": ">][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for", "label": 0}, {"snippet_id": 1069, "code": " action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0", "label": 0}, {"snippet_id": 61436, "code": ": if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError('State vector must be of length", "label": 0}, {"snippet_id": 29528, "code": "}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex", "label": 0}, {"snippet_id": 1052, "code": "{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'addwifi', 'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn", "label": 0}, {"snippet_id": 25946, "code": " >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif", "label": 0}, {"snippet_id": 62903, "code": " logging from galaxy import model from galaxy.jobs.runners import AsynchronousJobState, AsynchronousJobRunner from galaxy.jobs import ComputeEnvironment from galaxy.jobs import JobDestination from galaxy", "label": 0}, {"snippet_id": 60421, "code": ", var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self.observe.params) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var", "label": 0}, {"snippet_id": 92730, "code": ", duration): self._time +=duration clock=FakeClock() with Timer(clock=clock) as t: self.assertLess(t.start, clock.time()) self.assertGreater(t.elapsed, 0) clock.sleep(0.1) self.assertGreater(t.elapsed,", "label": 0}, {"snippet_id": 1256, "code": "-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row", "label": 0}, {"snippet_id": 24623, "code": " data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low", "label": 0}, {"snippet_id": 82566, "code": " are not responsible for any misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]", "label": 0}, {"snippet_id": 55380, "code": "{}\".format(nodes)) else: logger.resources_info(\"Provided cores:{}\".format(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources", "label": 0}, {"snippet_id": 8549, "code": "\")[1] local_stream=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file", "label": 1}, {"snippet_id": 93729, "code": " is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" ", "label": 0}, {"snippet_id": 38726, "code": "=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is not None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error", "label": 0}, {"snippet_id": 26265, "code": "'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl", "label": 0}, {"snippet_id": 67572, "code": " print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if", "label": 0}, {"snippet_id": 30689, "code": ".dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f", "label": 0}, {"snippet_id": 72608, "code": "\"./data/input/\" download_directory=input_directory +\"download/\" temp_directory=\"./data/temp/\" vcf_directory=\"./data/vcf/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark", "label": 1}, {"snippet_id": 95271, "code": " config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The path to create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib", "label": 1}, {"snippet_id": 68726, "code": " if target.has_first_time_flag(): flags.append(\"first_time\") if target.has_update_flag(): flags.append(\"update\") if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag", "label": 0}, {"snippet_id": 52925, "code": "()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return", "label": 0}, {"snippet_id": 92067, "code": "\"\"\" if not self._any_targets_have_native_sources(targets): return False platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources", "label": 0}, {"snippet_id": 10309, "code": " component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0", "label": 0}, {"snippet_id": 19073, "code": ", validate that the schema complies to spec. If `target` is provided, that target will be validated against the provided schema. \"\"\" schema=schema_validator(raw_schema, **kwargs) if target is not None:", "label": 0}, {"snippet_id": 41779, "code": ".input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark", "label": 0}, {"snippet_id": 75754, "code": "=WZHandler() def term_handler(interface, method, data): self.log.info( 'Termination signal %s recieved', repr((interface, method, data))) self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker'", "label": 1}, {"snippet_id": 10950, "code": "): yaml_config=merge_yaml_files(path) etag=None mtime=os.path.getmtime(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url): try: response=requests.get(url) except socket", "label": 0}, {"snippet_id": 6286, "code": " log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb", "label": 1}, {"snippet_id": 81089, "code": " \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1", "label": 0}, {"snippet_id": 48952, "code": " rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause", "label": 0}, {"snippet_id": 49865, "code": "*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print", "label": 0}, {"snippet_id": 57771, "code": "'New sortkey is out of range[0, 32300].') except ValueError: return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no(", "label": 0}, {"snippet_id": 78431, "code": ": %s', e, e.answer) self.w.sleep(self.errortimeout) except exc.PermanentError as e: self.log.error(e) self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.log.warn(e) self.w.sleep(self.errortimeout", "label": 0}, {"snippet_id": 72411, "code": " protocol module name)') return proto=utils.getProtocolModule(name) importlib.reload(proto) irc.reply(\"Done. You will have to manually disconnect and reconnect any network using the %r module for changes", "label": 0}, {"snippet_id": 90126, "code": "._validated_binaries.get(name) if not exe: exe=self._validate_executable(name) self._validated_binaries[name]=exe return exe @contextmanager def _valid_executable(self, name): exe=self._validate_executable", "label": 0}, {"snippet_id": 12830, "code": ".target_line_no) to_ignore=\",\".join(config[\"pycodestyle\"][\"ignore\"]) arg_to_ignore=\"\" if len(to_ignore) > 0: arg_to_ignore=\"--ignore \" +to_ignore for file in py_files: filename=file[1:] url=\"https://raw", "label": 0}, {"snippet_id": 78461, "code": ".forums: targets=[] self.log.debug('Scanning first page of the forum %s:%s', user, forum) page=self.site.get_page('1', forum, user) rxp=re.compile(regexp.f_sub_id.format(user, self.site.domain, forum))", "label": 0}, {"snippet_id": 94156, "code": ".logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=", "label": 0}, {"snippet_id": 55703, "code": " if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args", "label": 0}, {"snippet_id": 2717, "code": " outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host", "label": 0}, {"snippet_id": 673, "code": "'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3", "label": 0}, {"snippet_id": 80252, "code": " if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose:", "label": 0}, {"snippet_id": 80524, "code": "\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif", "label": 0}, {"snippet_id": 69625, "code": "/model.lmf \"\"\" def __init__(self): Command.__init__(self) self.lmf_support=LMF(self) self.nodes_support=Nodes(self) def get_name(self): return \"install\" def get_desc(self): return \"Install a new file system", "label": 0}, {"snippet_id": 27496, "code": " \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update", "label": 0}, {"snippet_id": 38493, "code": " self._rules[name] def list_rules(self, only_targets=False): rules=self.rules if only_targets: rules=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring", "label": 0}, {"snippet_id": 59555, "code": " i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def shutdown(self): \"\"\"Shutdown. \"\"\" pass def _deallocate(self", "label": 0}, {"snippet_id": 23891, "code": " interface.\") iface=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0}\".format(iface)) for line in output.split('\\n'):", "label": 0}, {"snippet_id": 91815, "code": ".exit_code==0 else Status.FAILURE yield TestResult( status=status, stdout=result.stdout.decode('utf-8'), stderr=result.stderr.decode('utf-8'), ) def rules(): return[ run_python_test, UnionRule(TestTarget,", "label": 0}, {"snippet_id": 46667, "code": " yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml", "label": 0}, {"snippet_id": 3333, "code": " if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not", "label": 0}, {"snippet_id": 8461, "code": " _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters", "label": 1}, {"snippet_id": 3361, "code": "'starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if", "label": 0}, {"snippet_id": 46449, "code": "=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for", "label": 0}, {"snippet_id": 6396, "code": " module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as", "label": 0}, {"snippet_id": 54411, "code": "\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import re import os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools", "label": 0}, {"snippet_id": 2713, "code": "(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s' & scp %s %s:%s/", "label": 0}, {"snippet_id": 22356, "code": " provisioning does not need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within", "label": 0}, {"snippet_id": 5615, "code": " if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw", "label": 0}, {"snippet_id": 19796, "code": " wait_for_socket_server from.debugsession import DebugSession class _LifecycleClient(Closeable): SESSION=DebugSession def __init__( self, addr=None, port=8888, breakpoints=None, connecttimeout=1.0, ): super", "label": 0}, {"snippet_id": 46556, "code": " insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name", "label": 0}, {"snippet_id": 77359, "code": " if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn", "label": 0}, {"snippet_id": 24447, "code": ".type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"", "label": 0}, {"snippet_id": 5171, "code": "=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single", "label": 0}, {"snippet_id": 11364, "code": " a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s, writing to %s", "label": 0}, {"snippet_id": 16589, "code": " 'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave", "label": 0}, {"snippet_id": 78756, "code": ".urlopen(url, request) for i in ijson.items(response, 'item'): yield from_json(i) except urllib2.HTTPError as e: raise from_json(json.load(e)) except urllib2.URLError as e: log.logger.error('Daemon not", "label": 0}, {"snippet_id": 45458, "code": " os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError", "label": 1}, {"snippet_id": 32939, "code": " config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values", "label": 0}, {"snippet_id": 21273, "code": ".youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search('v=([^&?]*)', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label:', lk) continue new_links.append('https:/", "label": 0}, {"snippet_id": 13712, "code": " for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals", "label": 0}, {"snippet_id": 75099, "code": ".send_multipart(msg) def handle_keepalive_reply(self, reqid, seqnum, status, data): if status==wzrpc.status.success: self.p.log.debug('Keepalive was successfull') elif status==wzrpc.status.e_req_denied:", "label": 0}, {"snippet_id": 62297, "code": "} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else: gate | tuple([self.reg[i] for i in wires]) def expectation(self", "label": 0}, {"snippet_id": 75770, "code": " WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method, data)", "label": 1}, {"snippet_id": 85486, "code": "'compiler-bridge', classpath=[ ScalaJarDependency(org='org.scala-sbt', name='compiler-bridge', rev=zinc_rev, classifier='sources', intransitive=True), ]) cls.register_jvm_tool(register, 'compiler-interface'", "label": 0}, {"snippet_id": 10230, "code": "): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone", "label": 0}, {"snippet_id": 95439, "code": " Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): ", "label": 0}, {"snippet_id": 1029, "code": "\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 3754, "code": ", name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file", "label": 0}, {"snippet_id": 85664, "code": "._compiler_interface(self._products) @memoized_method def snapshot(self, scheduler): buildroot=get_buildroot() return scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs( tuple( fast_relpath(a, buildroot)", "label": 0}, {"snippet_id": 17857, "code": ".utils import ToUtf8Json from ycm.server.responses import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC", "label": 0}, {"snippet_id": 83500, "code": ".__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config", "label": 0}, {"snippet_id": 42825, "code": " inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not", "label": 0}, {"snippet_id": 44756, "code": " self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath", "label": 0}, {"snippet_id": 15521, "code": " self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in vimsupport", "label": 0}, {"snippet_id": 11206, "code": " Creates an Icinga monitoring configuration. It does it by querying an URL from which it receives a specially formatted yaml file. This file is transformed into a valid Icinga configuration file. If no URL is", "label": 0}, {"snippet_id": 83190, "code": " app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url", "label": 0}, {"snippet_id": 80018, "code": "\",required=False,dest=\"skipRecon\",help=\"Skip recon phase, where fuxploider tries to determine what extensions are expected and filtered by the server. Needs -l switch.\") parser.add_argument(\"-y\",action", "label": 0}, {"snippet_id": 67723, "code": " ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc:", "label": 0}, {"snippet_id": 49879, "code": "*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(", "label": 0}, {"snippet_id": 65244, "code": " RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 84454, "code": " for local_input_path in local_input_paths: wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path", "label": 0}, {"snippet_id": 34217, "code": " ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 63481, "code": "]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env=getattr( job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state", "label": 0}, {"snippet_id": 23083, "code": " when mounting the provisioningiso.iso DVD :param chk_err: Whether to check for errors or not in the mounting commands \"\"\" self._wait_until_mcpd_is_initialized() return super(BigIpOSUtil, self).mount_dvd(*", "label": 0}, {"snippet_id": 46628, "code": "): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as", "label": 0}, {"snippet_id": 2675, "code": " reference between %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\")", "label": 0}, {"snippet_id": 68423, "code": " status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for", "label": 0}, {"snippet_id": 53701, "code": "\"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else:", "label": 0}, {"snippet_id": 68343, "code": ".set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS", "label": 0}, {"snippet_id": 13110, "code": "\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os", "label": 0}, {"snippet_id": 58946, "code": ", 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) for pk in(self.case_1.pk, self.case_3", "label": 0}, {"snippet_id": 94860, "code": " def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center) main_window.show() sys.exit(app.exec_", "label": 0}, {"snippet_id": 73650, "code": " :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation", "label": 0}, {"snippet_id": 73085, "code": " +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute +file) print(\"[Setup][FTP] Switching to directory:{}\".format(remote_path_relative +\"/\" +file", "label": 0}, {"snippet_id": 11975, "code": "\"BOT_PASSWORD\"]) url=\"https://raw.githubusercontent.com/{}/{}/.pep8speaks.yml\" url=url.format(data[\"repository\"], data[\"after_commit_hash\"]) r=requests.get(url, headers=headers, auth=auth) if r.status_code==200:", "label": 0}, {"snippet_id": 9027, "code": "=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines", "label": 0}, {"snippet_id": 41727, "code": " all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction", "label": 0}, {"snippet_id": 77175, "code": ".ctx.socket(zmq.ROUTER) self.pr_back_sock.bind(self.pr_ba) def read_newproxies(self): if not os.path.isfile(self.newproxyfile): return newproxies=set() with open(self.newproxyfile, 'rt') as f: for line", "label": 0}, {"snippet_id": 37554, "code": " have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name,", "label": 0}, {"snippet_id": 85722, "code": "','.join('{}:{}'.format(src, dst) for src, dst in rebases.items()) ) @memoized_method def _compiler_plugins_cp_entries(self): \"\"\"Any additional global compiletime classpath entries for compiler plugins", "label": 0}, {"snippet_id": 6719, "code": " pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it", "label": 0}, {"snippet_id": 87712, "code": " self.name(),[WorkUnitLabel.COMPILER]) self.context._scheduler.materialize_directories(( DirectoryToMaterialize(get_buildroot(), res.output_directory_digest), )) return res.output_directory_digest else", "label": 1}, {"snippet_id": 5229, "code": " output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n", "label": 0}, {"snippet_id": 7216, "code": "=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('</record></collection>'", "label": 0}, {"snippet_id": 50001, "code": ".needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else", "label": 0}, {"snippet_id": 72106, "code": " permissions.checkPermissions(irc, source,['networks.autoconnect']) try: netname=args[0] seconds=float(args[1]) network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs", "label": 0}, {"snippet_id": 54606, "code": " @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file", "label": 0}, {"snippet_id": 64821, "code": " fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem", "label": 0}, {"snippet_id": 10656, "code": ".escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode", "label": 0}, {"snippet_id": 62658, "code": "'ClassicalSimulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state", "label": 0}, {"snippet_id": 95117, "code": " print(\"[Setup][FTP] FTP module enabled. Running FTP download...\") data_service.fetch_data_via_ftp(ftp_config=ftp_config, local_directory=download_directory) else: print(\"[Setup][FTP] FTP module disabled.", "label": 1}, {"snippet_id": 80887, "code": " KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging", "label": 0}, {"snippet_id": 37855, "code": " _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles", "label": 0}, {"snippet_id": 40374, "code": ".finditer(pattern)) def contains_wildcard(path): return _wildcard_regex.search(path) is not None def remove(file): if os.path.exists(file): if os.path.isdir(file): try: os.removedirs(file) except OSError:", "label": 0}, {"snippet_id": 41109, "code": ".items(), key=lambda item: item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in", "label": 0}, {"snippet_id": 71937, "code": ".targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker): node, buf=worker.last_read()", "label": 0}, {"snippet_id": 85991, "code": " @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-Werror',) @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register):", "label": 0}, {"snippet_id": 91747, "code": " snapshot, source_root in sources_snapshots_and_source_roots ] sources_digest=yield Get( Digest, DirectoriesToMerge(directories=tuple(all_sources_digests)), ) inits_digest=yield Get(InjectedInitDigest, Digest", "label": 0}, {"snippet_id": 35589, "code": " add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name -", "label": 0}, {"snippet_id": 65595, "code": "), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None: view=\"fs\" else: view=view.lower() if view.startswith(\"disk\")", "label": 1}, {"snippet_id": 65756, "code": "\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type", "label": 0}, {"snippet_id": 81247, "code": " possible as there is no path nor regex pattern configured.\") \t\telse: \t\t\tpass \t \tdef uploadFile(self,suffix,mime,payload): \t\twith tempfile.NamedTemporaryFile(suffix=suffix) as fd: \t\t\tfd.write(payload) ", "label": 0}, {"snippet_id": 87934, "code": " plugin name to list of plugin classpath entries. The first entry in each list is the classpath entry containing the plugin metadata. The rest are the internal transitive deps of the plugin. This allows", "label": 0}, {"snippet_id": 27562, "code": "'sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2", "label": 0}, {"snippet_id": 59917, "code": "=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() class ProjectQIBMBackend(ProjectQDevice): \"\"\"ProjectQ IBMBackend device for", "label": 0}, {"snippet_id": 76009, "code": ".e_timeout: self.log.warn('Timeout{0}, retrying'.format(data[0])) that.retry=True else: self.log.warning('Recvd unknown reply for(%s, %s) %s: %s', i, m, wzrpc.name_status(status), repr(data)) self.wz_wait_reply", "label": 0}, {"snippet_id": 83418, "code": ".fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state", "label": 0}, {"snippet_id": 1685, "code": " found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST.get(", "label": 0}, {"snippet_id": 47407, "code": " to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, ", "label": 0}, {"snippet_id": 77384, "code": " def spawn_nworkers(self, type_, fun, count, args=(), kvargs={}): wname=str(fun.__name__) self.log.info('Starting %s(s)', wname) if type_==0: if not hasattr(self, 'th_sock'): self.init_th_sock() if not", "label": 0}, {"snippet_id": 22982, "code": ".1 it will also find /dev/sr0 on occasion. This is NOT the correct CD/DVD device though. :todo: Consider just always returning \"/dev/cdrom\" here if that device device exists on all platforms that are supported", "label": 0}, {"snippet_id": 23459, "code": "-m\".format(username) retcode, out=shellutil.run_get_output(cmd) if retcode !=0: raise OSUtilError((\"Failed to create user account:{0}, \" \"retcode:{1}, \" \"output:{2}\").format(username, retcode, out)) def", "label": 0}, {"snippet_id": 2425, "code": "(logging.DEBUG) self.configfile=configfile self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml',", "label": 0}, {"snippet_id": 201, "code": "-security\", }, \"802-11-wireless-security\":{ \"key-mgmt\": \"wpa-psk\", \"psk\": wifipass }, } conn=nm.AddAndActivateConnection(params, wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id", "label": 0}, {"snippet_id": 61624, "code": "\\ket{\\psi}` \"\"\" if A.shape !=(2, 2): raise ValueError('2x2 matrix required.') A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning", "label": 0}, {"snippet_id": 82530, "code": "\\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey", "label": 0}, {"snippet_id": 21829, "code": " import Dense classifier=Sequential() classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=11)) classifier.add(Dense(units=6, kernel_initializer='uniform', activation", "label": 1}, {"snippet_id": 75499, "code": ", method, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-bind-route', args, reqid) def make_auth_unbind_route_data", "label": 0}, {"snippet_id": 89493, "code": ": \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param string home_path: the path to the java distribution's home dir", "label": 0}, {"snippet_id": 91830, "code": " print_function, unicode_literals import logging from textwrap import dedent from pants.backend.native.subsystems.native_toolchain import NativeToolchain from pants.backend.native.targets.native_library import", "label": 0}, {"snippet_id": 76688, "code": " shell\") parser.add_argument('--tcount', '-t', type=int, default=10, help='WipeThread count') parser.add_argument('--ecount', '-e', type=int, default=0, help='EvaluatorProxy count') parser.add_argument(", "label": 0}, {"snippet_id": 87104, "code": " requires the workdir to be a child of the buildroot \" \"but workdir was{} and buildroot was{}\".format( self.get_options().pants_workdir, get_buildroot(), ) ) if self.get_options().use_classpath_jars: raise", "label": 0}, {"snippet_id": 18778, "code": "._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded( self, extra_data): def BuildExtraConfData( extra_conf_vim_data): return dict(", "label": 0}, {"snippet_id": 70881, "code": ".set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS", "label": 0}, {"snippet_id": 43826, "code": " lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name", "label": 0}, {"snippet_id": 35383, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{", "label": 0}, {"snippet_id": 82718, "code": "\tif proxyProtocol !=None: \t\tproxy +=proxyProtocol+\"://\" \telse: \t\tproxy +=\"http://\" \tif proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !", "label": 0}, {"snippet_id": 18096, "code": "'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData", "label": 1}, {"snippet_id": 71705, "code": ".search(\"(\\w+): SHINE:\\d:(\\w+):\", s) if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self", "label": 0}, {"snippet_id": 28313, "code": ".string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo", "label": 0}, {"snippet_id": 40563, "code": " value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value", "label": 1}, {"snippet_id": 36437, "code": "(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value", "label": 0}, {"snippet_id": 22411, "code": ".info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError( \"mcpd hasn't completed initialization! Cannot proceed!\" ) def _save_sys_config(self): cmd=\"/usr/bin/tmsh save sys config", "label": 0}, {"snippet_id": 83552, "code": " '', '') return command_line, client, remote_job_config, compute_environment def __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr", "label": 0}, {"snippet_id": 68253, "code": ".state==TARGET_ERROR: status=\"ERROR\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[", "label": 0}, {"snippet_id": 59834, "code": " variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return", "label": 0}, {"snippet_id": 77951, "code": " targets[%s]', repr(t), domain) tlist.remove(t) def add_target_exc(domain, id_, tuser=None): if domain not in targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_", "label": 0}, {"snippet_id": 41113, "code": "][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def", "label": 0}, {"snippet_id": 70763, "code": ": def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status", "label": 0}, {"snippet_id": 93097, "code": " path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging(self): fake_logger=mock.Mock() with self.assertRaises(AssertionError): with exception_logging(fake_logger, 'error!'):", "label": 0}, {"snippet_id": 82205, "code": "\"nbThreads\",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=", "label": 0}, {"snippet_id": 84108, "code": " __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution==\"remote\" if not remote_dependency_resolution", "label": 0}, {"snippet_id": 83417, "code": ": job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper", "label": 0}, {"snippet_id": 66466, "code": " print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self)", "label": 0}, {"snippet_id": 40387, "code": "(file): if os.path.isdir(file): try: os.removedirs(file) except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern", "label": 0}, {"snippet_id": 39356, "code": ".makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath)", "label": 0}, {"snippet_id": 31786, "code": " name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards", "label": 0}, {"snippet_id": 40060, "code": " check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file", "label": 1}, {"snippet_id": 7518, "code": " reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def", "label": 0}, {"snippet_id": 20793, "code": ": raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event and condition(msg) handlername='event{!r}'.format(event) evt=self", "label": 0}, {"snippet_id": 83970, "code": " pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt", "label": 0}, {"snippet_id": 79648, "code": "\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are", "label": 0}, {"snippet_id": 4727, "code": "(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False,", "label": 0}, {"snippet_id": 56978, "code": "('everything', 'None') (None, None) 6. get_value_by_type('buggy', 'buggy') (None, 'Unsupported value type.') 7. get_value_by_type('string', 'int') (None, \"invalid literal for int() with base 10: 'string", "label": 0}, {"snippet_id": 6177, "code": " if not remote: log.info(\"Local file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the", "label": 1}, {"snippet_id": 69547, "code": "\"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt", "label": 0}, {"snippet_id": 85386, "code": " import fast_relpath from pants.util.memo import memoized_method, memoized_property class Zinc(object): \"\"\"Configuration for Pants' zinc wrapper tool.\"\"\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main", "label": 1}, {"snippet_id": 20483, "code": ", ownsock=False): super(DebugSessionConnection, self).__init__() self._sock=sock self._ownsock=ownsock @property def is_client(self): try: return self._sock.server is None except AttributeError: return", "label": 0}, {"snippet_id": 43917, "code": "=filterfalse(Rule.has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource", "label": 0}, {"snippet_id": 71445, "code": ".Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import", "label": 0}, {"snippet_id": 60518, "code": ", 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeeze': Sgate, } class StrawberryFieldsGaussian(Device): \"\"\"StrawberryFields Gaussian device for OpenQML. wires(int): the number", "label": 0}, {"snippet_id": 78098, "code": " forum)) def add_user(domain, login, passwd): uq=wm.get_userqueue(domain) uq.put({'login': login, 'passwd': passwd}, False) def send_to_wm(frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1],", "label": 0}, {"snippet_id": 77466, "code": ".join((wname, 'pr{0}'.format(i)))) self.processes.append(w) w.start(self.pr_sa) except Exception as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads(self): return", "label": 0}, {"snippet_id": 32813, "code": " import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards, flag", "label": 1}, {"snippet_id": 40122, "code": ").st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files", "label": 0}, {"snippet_id": 23674, "code": "\"route delete 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient\", chk_err=False) return ret[1] if ret[0]==0 else None def", "label": 0}, {"snippet_id": 15155, "code": ".completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import", "label": 0}, {"snippet_id": 49749, "code": ".updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.", "label": 0}, {"snippet_id": 42366, "code": "=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output", "label": 0}, {"snippet_id": 18003, "code": " handler, method) return SendRequest( data, handler, method, timeout) session=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None", "label": 0}, {"snippet_id": 28629, "code": "'battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif", "label": 0}, {"snippet_id": 35229, "code": " exclusive.\") return flag(value, \"protected\") def dynamic(value): \"\"\" A flag for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"", "label": 0}, {"snippet_id": 68567, "code": " AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\", 2, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 3, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 34334, "code": " ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod", "label": 0}, {"snippet_id": 52511, "code": ") @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic", "label": 0}, {"snippet_id": 76763, "code": "=5, help='Cap rate minimum possible count for limit check') parser.add_argument('--caprate_limit', type=float, default=0.8, help='Captcha rate limit') parser.add_argument('--comment_successtimeout', type", "label": 0}, {"snippet_id": 74815, "code": ": blosc_shuffle_mode_str=runtime_config.vcf_to_zarr[\"blosc_shuffle_mode\"] if isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types", "label": 0}, {"snippet_id": 73810, "code": ".enabled=config_str_to_bool(runtime_config.ftp[\"enabled\"]) if \"server\" in runtime_config.ftp: self.server=runtime_config.ftp[\"server\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp", "label": 0}, {"snippet_id": 25973, "code": "='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status", "label": 0}, {"snippet_id": 608, "code": ".Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name':", "label": 0}, {"snippet_id": 42926, "code": ".add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput)", "label": 0}, {"snippet_id": 92538, "code": "'Temporary file should exist within the context.') self.assertTrue(os.path.exists(fp.name)==False, 'Temporary file should not exist outside of the context.') def test_temporary_file_without_cleanup(self)", "label": 0}, {"snippet_id": 43601, "code": " itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from snakemake.rules import Rule,", "label": 0}, {"snippet_id": 50997, "code": "\"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try", "label": 0}, {"snippet_id": 73622, "code": " VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite=True, log=sys.stdout, compressor=compressor, chunk_length=chunk_length, chunk_width=chunk_width", "label": 1}, {"snippet_id": 67666, "code": ": def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev", "label": 0}, {"snippet_id": 40219, "code": "(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard", "label": 1}, {"snippet_id": 92445, "code": " expected_output) def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir) as path: self.assertEqual(tempdir, path) self.assertEqual(os.path.realpath(tempdir),", "label": 0}, {"snippet_id": 1310, "code": "=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass", "label": 1}, {"snippet_id": 64533, "code": " import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf \"\"\" def __init__(self): Command.__init__(self) self", "label": 0}, {"snippet_id": 90141, "code": " _valid_executable(self, name): exe=self._validate_executable(name) yield exe self._validated_binaries[name]=exe def __repr__(self): return('Distribution({!r}, minimum_version={!r}, maximum_version={!r", "label": 0}, {"snippet_id": 26389, "code": "(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"", "label": 0}, {"snippet_id": 2940, "code": "['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp[", "label": 0}, {"snippet_id": 1852, "code": "'getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem", "label": 0}, {"snippet_id": 11082, "code": " ETAG_COMMENT=' MTIME_COMMMENT=' def __init__(self, etag=None, mtime=0): self.etag=etag self.mtime=int(mtime) def __nonzero__(self): return self.etag is None and self.mtime is 0 def __eq__(self, other)", "label": 0}, {"snippet_id": 15507, "code": " completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self)", "label": 0}, {"snippet_id": 91457, "code": "(name='isort-prep', action=IsortPrep).install('fmt') task(name='isort', action=IsortRun).install('fmt') task(name='py', action=PythonBundle).install('bundle') task(name='unpack-wheels', action=UnpackWheels", "label": 0}, {"snippet_id": 55080, "code": " locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running", "label": 0}, {"snippet_id": 46868, "code": ".params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name", "label": 0}, {"snippet_id": 91838, "code": ".backend.native.subsystems.native_toolchain import NativeToolchain from pants.backend.native.targets.native_library import NativeLibrary from pants.backend.python.python_requirement import PythonRequirement", "label": 0}, {"snippet_id": 23253, "code": " struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name", "label": 0}, {"snippet_id": 62854, "code": "'PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1) variance", "label": 0}, {"snippet_id": 49854, "code": " elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep", "label": 0}, {"snippet_id": 28082, "code": ": \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station", "label": 1}, {"snippet_id": 91480, "code": " builtins import str from future.utils import text_type from pants.backend.python.rules.inject_init import InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest from pants.backend", "label": 0}, {"snippet_id": 10288, "code": " and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison", "label": 0}, {"snippet_id": 78686, "code": "') return self.executer(*sys.argv) log.logger.debug('Executing locally') return self.execute() except BaseException as e: log.logger.exception(e) if log.logger.getEffectiveLevel() <=logging.DEBUG: if os", "label": 0}, {"snippet_id": 15258, "code": "._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request=None self._server_stdout=None self._server_stderr", "label": 0}, {"snippet_id": 49807, "code": " please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job", "label": 0}, {"snippet_id": 8667, "code": " code are left in this module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import", "label": 0}, {"snippet_id": 56386, "code": "=('name', 'value'))) class _InfoObjects(object): def __init__(self, request, product_id=None): self.request=request try: self.product_id=int(product_id) except(ValueError, TypeError): self.product_id=0", "label": 0}, {"snippet_id": 92055, "code": " of:class:`Target` objects. :return: a boolean value indicating whether the current target closure has native sources. :raises::class:`pants.base.exceptions.IncompatiblePlatformsError` \"\"\" if not self._any_targets_have_native_sources", "label": 0}, {"snippet_id": 2322, "code": "\n\nfrom libtmux import Server from yaml import load, dump from setupParser import Loader from DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse", "label": 0}, {"snippet_id": 83473, "code": ".version) rewrite_parameters=LwrJobRunner.__rewrite_parameters( client) prepare_kwds={} if rewrite_parameters: compute_environment=LwrComputeEnvironment( client, job_wrapper, remote_job_config) prepare_kwds[", "label": 0}, {"snippet_id": 24457, "code": ".moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if", "label": 0}, {"snippet_id": 63066, "code": "\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager, 'ensure_has_status_update_callback'", "label": 0}, {"snippet_id": 66094, "code": ".targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status", "label": 0}, {"snippet_id": 86053, "code": "): if not isinstance(target, JvmTarget): return False return target.has_sources('.java') def select_source(self, source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return", "label": 0}, {"snippet_id": 86710, "code": " responsible for the symbol substitution which replaces $JAVA_HOME with the path to an appropriate jvm distribution. :param settings: The jvm platform settings from which to extract the arguments. :type settings:", "label": 0}, {"snippet_id": 15735, "code": "=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded", "label": 0}, {"snippet_id": 8947, "code": " :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. ", "label": 0}, {"snippet_id": 31550, "code": ".dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1) self.priority=0 self.version=None self._log=Log", "label": 0}, {"snippet_id": 27612, "code": "'battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data[", "label": 0}, {"snippet_id": 21494, "code": " > 0: for d in range(depth): link=\"\" for l in links: if re.search(\"after=\", l): link=l if link==\"\": print(\"Reddytt: Could not identify 'after'-variable to progress deeper.\") else: newer_links, links=getytlinks", "label": 0}, {"snippet_id": 22664, "code": " account is the one that the user specified when they did the instance creation. The second one is the admin account that is, or should be, built in to the system. :param username: The username that you", "label": 0}, {"snippet_id": 5713, "code": " kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp", "label": 0}, {"snippet_id": 19185, "code": "=schema, ) except ValidationError as err: errors['request'].add_error(err.messages or getattr(err, 'detail')) return response=normalize_response(raw_response, raw_request) try: validate_response( response", "label": 0}, {"snippet_id": 40483, "code": ", keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as", "label": 0}, {"snippet_id": 91442, "code": ", action=PythonBinaryCreate).install('binary') task(name='py-wheels', action=LocalPythonDistributionArtifact).install('binary') task(name='isort-prep', action=IsortPrep).install('fmt') task(name='isort", "label": 0}, {"snippet_id": 43665, "code": " from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None,", "label": 0}, {"snippet_id": 47511, "code": ".params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\":", "label": 0}, {"snippet_id": 67934, "code": " Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities", "label": 0}, {"snippet_id": 45888, "code": " apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic", "label": 0}, {"snippet_id": 95426, "code": ":{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath", "label": 0}, {"snippet_id": 89265, "code": ":return: An ExecuteProcessResult with information about the execution. Note that this is an unstable, experimental API, which is subject to change with no notice. \"\"\" with self.new_workunit( name=name,", "label": 0}, {"snippet_id": 68329, "code": ", AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT,", "label": 0}, {"snippet_id": 76361, "code": ": msg.insert(0, b'') self.wz_sock.send_multipart(msg) def inter_sleep(self, timeout): self.sleep_ticker.tick() self.poll(timeout * 1000) while self.sleep_ticker.elapsed(False) < timeout: try: self.poll", "label": 1}, {"snippet_id": 45498, "code": "(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir", "label": 0}, {"snippet_id": 33893, "code": " overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not", "label": 0}, {"snippet_id": 58030, "code": " that from\\n one or more caserun at a time. \"\"\" data, error=clean_bug_form(request) if error: return say_no(error) runs=TestCaseRun.objects.filter(pk__in=data['runs']) bug_system_id=data['bug_system_id'", "label": 0}, {"snippet_id": 21516, "code": " links=getytlinks(link) new_links +=newer_links new_links=list(set(new_links)) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links:", "label": 0}, {"snippet_id": 67855, "code": " mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status", "label": 0}, {"snippet_id": 86615, "code": ".strip()) @staticmethod def _write_javac_plugin_info(resources_dir, javac_plugin_target): javac_plugin_info_file=os.path.join(resources_dir, _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file,", "label": 0}, {"snippet_id": 5066, "code": ">\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template", "label": 0}, {"snippet_id": 91728, "code": ".address.spec_path) sources_snapshots_and_source_roots.append((tgt_snapshot, tgt_source_root)) all_sources_digests=yield[ Get( Digest, DirectoryWithPrefixToStrip( directory_digest=snapshot.directory_digest", "label": 0}, {"snippet_id": 55656, "code": " def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], ", "label": 0}, {"snippet_id": 8498, "code": " otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return", "label": 1}, {"snippet_id": 57884, "code": " comment to one or more caseruns at a time. \"\"\" data=request.POST.copy() comment=data.get('comment', None) if not comment: return say_no('Comments needed') run_ids=[i for i in data.get('run', '').split(',')", "label": 0}, {"snippet_id": 55496, "code": " urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile", "label": 0}, {"snippet_id": 4670, "code": "'acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches", "label": 0}, {"snippet_id": 65032, "code": ".verbose > 1: print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose", "label": 0}, {"snippet_id": 72819, "code": " LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The path to create dirs/subdirs for :type path", "label": 1}, {"snippet_id": 94959, "code": " configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f", "label": 0}, {"snippet_id": 621, "code": ".fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getDockerOverview': print(action) con=sqlite3.connect", "label": 0}, {"snippet_id": 79757, "code": "\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests.", "label": 0}, {"snippet_id": 19267, "code": " tmp_file.write(source) tmp_file.file.seek(0) with open(tmp_file.name) as json_file: result=load_source(json_file) assert result==native def test_json_file_path(): native={'foo': 'bar'} source=json.dumps", "label": 0}, {"snippet_id": 56842, "code": "(tag) def remove(self): tag=Tag.objects.get(name=self.tag_name) self.obj.remove_tag(tag) class _TagCounter(object): \"\"\" Used for counting the number of times a tag is assigned to TestRun/TestCase/TestPlan", "label": 0}, {"snippet_id": 89634, "code": "._get_system_properties(self.java)) @property def version(self): \"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is not valid according to the configured constraints", "label": 0}, {"snippet_id": 86496, "code": " pants.backend.jvm.targets.scalac_plugin import ScalacPlugin from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants.backend.jvm.tasks.jvm_compile.jvm_compile import JvmCompile from", "label": 0}, {"snippet_id": 82879, "code": "=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"/\"+template[\"filename\"],\"rb\") \ttemplatesData[template[\"templateName", "label": 0}, {"snippet_id": 24324, "code": " def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get", "label": 0}, {"snippet_id": 49243, "code": " rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno", "label": 0}, {"snippet_id": 19245, "code": "'bar'} source=yaml.dump(native) result=load_source(source) assert result==native def test_json_file_object(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode='w", "label": 0}, {"snippet_id": 82351, "code": "+=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging", "label": 0}, {"snippet_id": 94280, "code": " down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self.window_name)", "label": 0}, {"snippet_id": 42840, "code": " _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output", "label": 0}, {"snippet_id": 69092, "code": ", event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug", "label": 0}, {"snippet_id": 75894, "code": ".wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0]) rslist.append(rs) msg=self.wz.make_req_msg(request[1][0], request[1][1], request[1][2], rs.accept, request[1", "label": 0}, {"snippet_id": 90359, "code": "._STANDARD_JAVA_DIST_DIRS) def __init__(self, *java_dist_dirs): if len(java_dist_dirs)==0: raise ValueError('Expected at least 1 java dist dir.') self._java_dist_dirs=java_dist_dirs @property def jvm_locations", "label": 0}, {"snippet_id": 6451, "code": " spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source", "label": 0}, {"snippet_id": 81051, "code": ".critical(\"Server responded with following status: %s -%s\",initGet.status_code,initGet.reason) \t\t\t\texit() \t\texcept Exception as e: \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t", "label": 0}, {"snippet_id": 89414, "code": " system. In particular provides access to the distribution's binaries; ie: java while ensuring basic constraints are met. For example a minimum version can be specified if you know need to compile source", "label": 0}, {"snippet_id": 4090, "code": " bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing,", "label": 0}, {"snippet_id": 61216, "code": "(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape[0", "label": 0}, {"snippet_id": 93649, "code": " for node in res: self.logger.debug(\"node name '%s' vs. comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name)", "label": 0}, {"snippet_id": 3971, "code": " remote_mutex.add_argument('-k', '--kill', help=\"switch to kill mode\", action=\"store_true\") remote_mutex.add_argument('-c', '--check', help=\"Run a component check\", action=\"store_true\") args=parser.parse_args", "label": 0}, {"snippet_id": 88923, "code": "=None, dependencies=None, derived_from=None, **kwargs): \"\"\"Creates a new target, adds it to the context and returns it. This method ensures the target resolves files against the given target_base, creating", "label": 0}, {"snippet_id": 33871, "code": " include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile,", "label": 0}, {"snippet_id": 71655, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Unmount successful.\" elif rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) return result", "label": 1}, {"snippet_id": 65670, "code": " targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self", "label": 1}, {"snippet_id": 9769, "code": " format. :return: str, html formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result", "label": 0}, {"snippet_id": 39164, "code": " resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources:", "label": 0}, {"snippet_id": 53242, "code": "[0] self.name=other.name self.workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params", "label": 0}, {"snippet_id": 71240, "code": "(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[", "label": 0}, {"snippet_id": 81929, "code": "=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote server where uploads", "label": 0}, {"snippet_id": 79959, "code": " common extensions to use. Example: -n 100\", type=valid_nArg) exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=", "label": 0}, {"snippet_id": 8957, "code": " -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext", "label": 0}, {"snippet_id": 2044, "code": " JsonResponse(resultset, safe=False) elif action=='getSettings': print(action) ps=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=ps.split(':", "label": 0}, {"snippet_id": 84988, "code": "=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default='2.12', choices=['2.10', '2.11', '2.12', 'custom'], fingerprint=True", "label": 0}, {"snippet_id": 45737, "code": " get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait", "label": 0}, {"snippet_id": 72291, "code": " \"network, as this would cause a recursive loop\" log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name, text, placeholder_self.name) if 'source' in kwargs: del kwargs['source'", "label": 0}, {"snippet_id": 29725, "code": ": value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for", "label": 0}, {"snippet_id": 91352, "code": " PythonRequirementLibrary, Resources.alias(): Resources, UnpackedWheels.alias(): UnpackedWheels, }, objects={ 'python_requirement': PythonRequirement, 'python_artifact': PythonArtifact, 'setup_py': PythonArtifact", "label": 0}, {"snippet_id": 9216, "code": "'acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches", "label": 0}, {"snippet_id": 16370, "code": "[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed", "label": 0}, {"snippet_id": 89214, "code": " encapsulating the targets found. \"\"\" build_graph=self.build_graph.clone_new() for address in self.address_mapper.scan_addresses(root): build_graph.inject_address_closure(address) return build_graph def", "label": 1}, {"snippet_id": 44817, "code": "._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name,", "label": 0}, {"snippet_id": 1336, "code": " add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={", "label": 0}, {"snippet_id": 14916, "code": " JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return BaseRequest._TalkToHandlerAsync(", "label": 0}, {"snippet_id": 110, "code": "[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi.append(name[0]) return wifi def get_allAPs(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen(", "label": 0}, {"snippet_id": 22345, "code": " call this method at the first opportunity I have(during the DVD mounting call). This ensures that the rest of the provisioning does not need to wait for mcpd to be available unless it absolutely wants to.", "label": 0}, {"snippet_id": 62709, "code": " \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend", "label": 0}, {"snippet_id": 87033, "code": "\"\"\" return self.get_options().incremental @property def cache_incremental(self): \"\"\"Optionally write the results of incremental compiles to the cache.\"\"\" return self.get_options().incremental_caching @memoized_property", "label": 1}, {"snippet_id": 54223, "code": ".snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given", "label": 0}, {"snippet_id": 67270, "code": " client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node", "label": 0}, {"snippet_id": 67332, "code": ": return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler", "label": 0}, {"snippet_id": 23010, "code": ") :param dev_dir: The root directory from which to look for devices \"\"\" patten=r'(sr[0-9]|hd[c-z]|cdrom[0-9]?)' for dvd in[re.match(patten, dev) for dev in os.listdir(dev_dir)]: if dvd is not None: return", "label": 0}, {"snippet_id": 54285, "code": "() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards", "label": 0}, {"snippet_id": 66536, "code": ".install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not", "label": 0}, {"snippet_id": 48856, "code": " self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod", "label": 0}, {"snippet_id": 84105, "code": " client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner.__dependency_resolution( lwr_client) remote_dependency_resolution=dependency_resolution==", "label": 1}, {"snippet_id": 28257, "code": "', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal", "label": 0}, {"snippet_id": 53247, "code": ".workflow=other.workflow self.docstring=other.docstring self.message=other.message self._input=InputFiles(other._input) self._output=OutputFiles(other._output) self._params=Params(other._params) self.dependencies", "label": 0}, {"snippet_id": 36693, "code": ".is_local(self.rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties(", "label": 0}, {"snippet_id": 23383, "code": " set_hostname(self, hostname): rc_file_path='/etc/rc.conf' conf_file=fileutil.read_file(rc_file_path).split(\"\\n\") textutil.set_ini_config(conf_file, \"hostname\", hostname) fileutil.write_file(rc_file_path", "label": 0}, {"snippet_id": 71777, "code": ": %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: ", "label": 0}, {"snippet_id": 74838, "code": ".\\n\" \"blosc_shuffle_mode must be a valid integer.\") else: raise TypeError(\"Invalid value for blosc_shuffle_mode in configuration.\\n\" \"blosc_shuffle_mode could not be converted to integer.\") benchmark_data_input_types", "label": 0}, {"snippet_id": 26000, "code": "\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if", "label": 0}, {"snippet_id": 65330, "code": " \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes", "label": 0}, {"snippet_id": 76028, "code": ".name_status(status), repr(data)) self.wz_wait_reply(accept, *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m])) def bind_route(self, i, m, f): self.log.debug('Binding %s,%s route', i, m) def", "label": 0}, {"snippet_id": 32092, "code": "[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name", "label": 0}, {"snippet_id": 35980, "code": " snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(", "label": 0}, {"snippet_id": 68937, "code": " Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client)", "label": 0}, {"snippet_id": 91485, "code": " text_type from pants.backend.python.rules.inject_init import InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest from pants.backend.python.subsystems.python_setup import PythonSetup", "label": 0}, {"snippet_id": 73324, "code": " path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head(path): head, tail=os.path.split", "label": 0}, {"snippet_id": 6869, "code": " keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans: dictionary", "label": 0}, {"snippet_id": 58739, "code": "'ajax-update_case_run_status') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission) self", "label": 0}, {"snippet_id": 76465, "code": ".log.warn(e) def run(self): self.__sinit__() if self.start_timer: self.inter_sleep(self.start_timer) if self.running: self.log.info('Starting') try: self.child=self.call[0](*self.call[1], **self.call[2", "label": 0}, {"snippet_id": 52510, "code": ")), rule=self.rule) @property def expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output", "label": 0}, {"snippet_id": 50901, "code": " WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)", "label": 0}, {"snippet_id": 85996, "code": " def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super(JavacCompile, cls).register_options(register) @classmethod def subsystem_dependencies", "label": 0}, {"snippet_id": 84796, "code": ".jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem major_version_info=namedtuple('major_version_info',['full_version']) scala_build_info={ '2.10': major_version_info(full_version='2", "label": 0}, {"snippet_id": 45835, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append", "label": 0}, {"snippet_id": 44781, "code": " config with the given dictionary. \"\"\" global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self", "label": 0}, {"snippet_id": 855, "code": ".decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1], 'data': datasets} resultset", "label": 0}, {"snippet_id": 18686, "code": ".PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info ", "label": 0}, {"snippet_id": 9460, "code": " kws :keyword spires: please don't use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\"", "label": 0}, {"snippet_id": 48483, "code": ": self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name", "label": 0}, {"snippet_id": 81028, "code": " \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical", "label": 0}, {"snippet_id": 85014, "code": "-version=custom, the targets ' '//:scala-library, //:scalac, //:scala-repl and //:scalastyle will be used, ' 'and must exist. Otherwise, defaults for the specified version will be used.') register('--suffix", "label": 0}, {"snippet_id": 53606, "code": ".wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output", "label": 0}, {"snippet_id": 46940, "code": ": self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self", "label": 0}, {"snippet_id": 32048, "code": " is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output", "label": 0}, {"snippet_id": 65154, "code": ".verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s(%s) succeeded\" %(target.type.upper(", "label": 0}, {"snippet_id": 45511, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode ", "label": 0}, {"snippet_id": 43434, "code": "\"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch", "label": 0}, {"snippet_id": 31388, "code": ") if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration", "label": 0}, {"snippet_id": 27857, "code": ")\" % data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'", "label": 0}, {"snippet_id": 48512, "code": " files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards)", "label": 0}, {"snippet_id": 7145, "code": " output_limit)), _kw(_sort_kw_matches(composite_keywords, output_limit)), author_keywords, _kw(_sort_kw_matches(acronyms, output_limit))) else: my_styles[\"raw\"]=(single_keywords_p, composite_keywords_p", "label": 0}, {"snippet_id": 66824, "code": " if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" %", "label": 0}, {"snippet_id": 56230, "code": " Component, Build, Version from tcms.management.models import Priority from tcms.management.models import Tag from tcms.management.models import EnvGroup, EnvProperty, EnvValue from tcms.testcases.models", "label": 0}, {"snippet_id": 27684, "code": " and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >", "label": 0}, {"snippet_id": 42134, "code": ".rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self", "label": 0}, {"snippet_id": 29956, "code": ")) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments", "label": 0}, {"snippet_id": 9690, "code": " spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw", "label": 0}, {"snippet_id": 60385, "code": "[operation.wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('fock', cutoff_dim=self.cutoff) reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0", "label": 0}, {"snippet_id": 81870, "code": "\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds", "label": 0}, {"snippet_id": 84289, "code": " working_directory=remote_job_config['working_directory'] outputs=[Bunch(false_path=os.path.join(outputs_directory, os.path.basename(path)), real_path=path) for path in self.get_output_files(job_wrapper)] metadata_kwds", "label": 0}, {"snippet_id": 11889, "code": " True if the PR contains at least one Python file \"\"\" files=list(get_files_involved_in_pr(data).keys()) pythonic=False for file in files: if file[-3:]=='.py': pythonic=True break return pythonic def get_config", "label": 0}, {"snippet_id": 11409, "code": "(old_header) def output_path(self, file_name): return os.path.join(self.target_dir, file_name) def write_output(self, file_name, yaml_icinga): lines=yaml_icinga.icinga_lines output_writer=OutputWriter(self", "label": 0}, {"snippet_id": 9798, "code": " list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does", "label": 0}, {"snippet_id": 92165, "code": ".register_options(register) register('--setuptools-version', advanced=True, fingerprint=True, default='40.6.3', help='The setuptools version to use when executing `setup.py` scripts.') register('--wheel-version',", "label": 0}, {"snippet_id": 48344, "code": " raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output", "label": 0}, {"snippet_id": 83186, "code": "\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache", "label": 0}, {"snippet_id": 71671, "code": " from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem", "label": 0}, {"snippet_id": 32618, "code": " match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def", "label": 0}, {"snippet_id": 7032, "code": " chosen style. This is the main routing call, this function will also strip unwanted keywords before output and limits the number of returned keywords :var single_keywords: list of single keywords :var", "label": 0}, {"snippet_id": 32858, "code": "=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir", "label": 0}, {"snippet_id": 69669, "code": ": nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print", "label": 0}, {"snippet_id": 69766, "code": ": self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node", "label": 0}, {"snippet_id": 12479, "code": " error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete", "label": 0}, {"snippet_id": 20853, "code": ".type !='response': return False result['msg']=msg return msg.request_seq==seq handlername='response(cmd:{} seq:{})'.format(command, seq) evt=self._get_message_handle(match, handlername) return AwaitableResponse", "label": 0}, {"snippet_id": 15745, "code": " filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0] if filetype", "label": 0}, {"snippet_id": 1251, "code": " get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n')", "label": 0}, {"snippet_id": 85550, "code": " @classmethod def _compiler_interface(cls, products): return cls.tool_jar_from_products(products, 'compiler-interface', cls.options_scope) def create(self, products): \"\"\"Create a Zinc instance from products active", "label": 0}, {"snippet_id": 27709, "code": "'battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif", "label": 0}, {"snippet_id": 20489, "code": ".__init__() self._sock=sock self._ownsock=ownsock @property def is_client(self): try: return self._sock.server is None except AttributeError: return True def iter_messages(self): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 4892, "code": " acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None): \"\"\"Create xml record. :var recid: ingeter :var single_keywords:", "label": 0}, {"snippet_id": 40706, "code": " given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards", "label": 0}, {"snippet_id": 7083, "code": " single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords) composite_keywords_p", "label": 0}, {"snippet_id": 49486, "code": " filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list()", "label": 0}, {"snippet_id": 17115, "code": ": return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'", "label": 0}, {"snippet_id": 65136, "code": ".verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(", "label": 0}, {"snippet_id": 56912, "code": " the tag you do the counting for :type tag::class:`tcms.management.models.Tag` :return: the number of times a tag is assigned to object :rtype: int \"\"\" if self.counter['tag'] !=tag.pk: try: self.counter", "label": 0}, {"snippet_id": 20388, "code": " def create_client(cls, addr, **kwargs): def connect(addr, timeout): sock=create_client() for _ in range(int(timeout * 10)): try: sock.connect(addr) except(OSError, socket.error): if cls.VERBOSE: print('", "label": 0}, {"snippet_id": 23905, "code": "'t get info for interface:{0}\".format(iface)) for line in output.split('\\n'): if line.find('inet ') !=-1: inet=line.split()[1] elif line.find('ether ') !=-1: mac=line.split()[1] logger.verbose(\"Interface", "label": 0}, {"snippet_id": 65337, "code": "\n \"\"\" Shine `status' command classes. The status command aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator", "label": 0}, {"snippet_id": 94528, "code": " but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid", "label": 0}, {"snippet_id": 9134, "code": ", fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite", "label": 0}, {"snippet_id": 18533, "code": ") and self.NativeFiletypeCompletionAvailable()) def OnFileReadyToParse( self): self._omnicomp.OnFileReadyToParse( None) if not self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self", "label": 0}, {"snippet_id": 49847, "code": "(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed", "label": 0}, {"snippet_id": 87947, "code": " the plugin metadata. The rest are the internal transitive deps of the plugin. This allows us to have in-repo plugins with dependencies(unlike javac, scalac doesn't load plugins or their deps from the regular", "label": 0}, {"snippet_id": 54296, "code": " values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self", "label": 0}, {"snippet_id": 58362, "code": " response=self.client.get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-login'), target_status_code=HTTPStatus.OK) def test_when_logged_in_index_page_redirects_to_dashboard", "label": 0}, {"snippet_id": 23958, "code": "\"00000001\" port_id=port_id -2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=\"000\" +ustr(port_id) g0g1=\"{0}-{1}\".format(g0, g1) \"\"\" search", "label": 0}, {"snippet_id": 51682, "code": ", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names=[match.group('name') for match in _wildcard_regex", "label": 0}, {"snippet_id": 23998, "code": "=shellutil.run_get_output(cmd_search_ide) if err: return None cmd_extract_id=cmd_search_ide +\"|awk -F. '{print $3}'\" err, output=shellutil.run_get_output(cmd_extract_id) \"\"\" try to search 'blkvscX' and", "label": 0}, {"snippet_id": 77474, "code": " as e: self.log.exception('Exception \"%s\" raised on %s spawn', e, wname) def spawn_wipethreads(self): return self.spawn_nworkers(0, WipeThread, self.c.tcount, (self.pc, self.spawnqueue)) def spawn_evaluators", "label": 0}, {"snippet_id": 67192, "code": " FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import", "label": 0}, {"snippet_id": 41163, "code": ": self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return", "label": 0}, {"snippet_id": 30156, "code": " else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add", "label": 0}, {"snippet_id": 62015, "code": "(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a", "label": 0}, {"snippet_id": 58406, "code": " \"\"\"Test case for ajax.comment_case_runs\"\"\" @classmethod def setUpTestData(cls): super(TestCommentCaseRuns, cls).setUpTestData() cls.many_comments_url=reverse('ajax-comment_case_runs') def test_refuse_if_missing_comment", "label": 0}, {"snippet_id": 55850, "code": ".input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params", "label": 0}, {"snippet_id": 70637, "code": ".target_status_rc_map[status] def execute(self): result=-1 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname():", "label": 1}, {"snippet_id": 49978, "code": ".resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources", "label": 0}, {"snippet_id": 2176, "code": "'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn", "label": 0}, {"snippet_id": 49870, "code": "))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes", "label": 0}, {"snippet_id": 26191, "code": "', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy',", "label": 0}, {"snippet_id": 65281, "code": "), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type", "label": 0}, {"snippet_id": 87348, "code": ".relpath(cp_entry, self.get_options().pants_workdir)) key=hasher.hexdigest()[:12] return os.path.join(self.get_options().pants_bootstrapdir, 'zinc', key) def compile(self, ctx, args, dependency_classpath", "label": 1}, {"snippet_id": 68184, "code": " if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError", "label": 1}, {"snippet_id": 86270, "code": " with argfile.safe_args(ctx.sources, self.get_options()) as batched_sources: javac_cmd.extend(batched_sources) if self.execution_strategy==self.HERMETIC: self._execute_hermetic_compile(javac_cmd, ctx) else", "label": 0}, {"snippet_id": 35238, "code": " for a file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable", "label": 1}, {"snippet_id": 33066, "code": " of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self, only_targets=False): rules=self.rules", "label": 0}, {"snippet_id": 8559, "code": " log.error(\"Unable to read from URL %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb", "label": 1}, {"snippet_id": 67781, "code": ": RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support", "label": 0}, {"snippet_id": 44629, "code": "(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror", "label": 0}, {"snippet_id": 47228, "code": " Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"", "label": 0}, {"snippet_id": 32770, "code": " urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources", "label": 0}, {"snippet_id": 95301, "code": "\"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors", "label": 0}, {"snippet_id": 85117, "code": " return self.tool_classpath_from_products(products, self._key_for_tool_version(tool, self.version), scope=self.options_scope) def compiler_classpath(self, products): return self._tool_classpath('scalac'", "label": 1}, {"snippet_id": 68520, "code": " > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],", "label": 0}, {"snippet_id": 13810, "code": ".total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self", "label": 0}, {"snippet_id": 83133, "code": " remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally", "label": 0}, {"snippet_id": 65549, "code": " RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 1}, {"snippet_id": 6214, "code": " @param text_lines: the text to analyze @type text_lines: string @return: True if the text is English, False otherwise @rtype: Boolean \"\"\" avg_word_length=2.55 +1 expected_word_number=float(len(text)) ", "label": 1}, {"snippet_id": 84491, "code": " self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self._sep def version_path", "label": 0}, {"snippet_id": 14822, "code": " _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not", "label": 0}, {"snippet_id": 19852, "code": ") if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None raise NotImplementedError def stop_debugging(self): if self.closed: raise RuntimeError('debug", "label": 0}, {"snippet_id": 89042, "code": " to narrow the scope of targets returned. :param bool postorder: `True` to gather transitive dependencies with a postorder traversal; `False` or preorder by default. :returns: A list of matching targets", "label": 0}, {"snippet_id": 77795, "code": ", frames[3:])) self.th_sock.send_multipart(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self.log=parent.log self.inter_sleep=parent.inter_sleep self.running=parent.running", "label": 0}, {"snippet_id": 33693, "code": " cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait", "label": 0}, {"snippet_id": 76936, "code": " net.useragent=random.choice(d.ua_list) net.timeout=c.rp_timeout return net def upload_avatar(self, ud): if('avatar_uploaded' in ud[0] and ud[0]['avatar_uploaded'] is True): return files=[] for sd in os", "label": 0}, {"snippet_id": 69604, "code": " Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path/to/model.lmf ", "label": 0}, {"snippet_id": 51906, "code": ", index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted", "label": 0}, {"snippet_id": 22102, "code": " variable_manager=self.variable_manager, host_list='/etc/ansible/hosts' ) self.variable_manager.set_inventory(self.inventory) pb_dir=os.path.abspath('.') playbook_path=\"%s/%s\" %(pb_dir, playbook) display", "label": 1}, {"snippet_id": 11025, "code": " if field in response.headers else None if response.status_code==200: yaml_config=yaml.load(response.content) etag=get_from_header('etag') mtime=get_from_header('last-modified') mtime=datetime.datetime", "label": 1}, {"snippet_id": 77780, "code": " in self.threads: t.join() def send_passthrough(self, interface, method, frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) self.th_sock.send_multipart(msg) self.pr_sock", "label": 0}, {"snippet_id": 4541, "code": "(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find single keywords in", "label": 1}, {"snippet_id": 3756, "code": " session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name)", "label": 0}, {"snippet_id": 71687, "code": " from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s): m=re.search", "label": 1}, {"snippet_id": 65521, "code": ">][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status", "label": 0}, {"snippet_id": 47005, "code": " Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): ", "label": 0}, {"snippet_id": 73788, "code": " representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if", "label": 0}, {"snippet_id": 64017, "code": " __remote_work_dir_copy( lwr_client): return LwrJobRunner.__remote_metadata( lwr_client) @staticmethod def __use_remote_datatypes_conf( lwr_client): \"\"\" When setting remote metadata, use integrated datatypes", "label": 0}, {"snippet_id": 87744, "code": "[WorkUnitLabel.COMPILER], dist=self._zinc.dist): raise TaskError('Zinc compile failed.') def _verify_zinc_classpath(self, classpath, allow_dist=True): def is_outside(path, putative_parent): return os.path", "label": 0}, {"snippet_id": 82356, "code": "\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template", "label": 0}, {"snippet_id": 50176, "code": " self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given", "label": 0}, {"snippet_id": 59679, "code": " kwargs): return{ key:value for key,value in kwargs.items() if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number", "label": 0}, {"snippet_id": 60804, "code": "'' author='' _capabilities={} _gates={} _observables={} _circuits={} def __init__(self, name, shots): self.name=name self.shots=shots self._out=None self._queue=[] self._observe=None def __repr__(self)", "label": 0}, {"snippet_id": 38004, "code": "\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath", "label": 0}, {"snippet_id": 4731, "code": "'author-kw')]=v return akw def get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): ", "label": 0}, {"snippet_id": 9591, "code": " kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2=\"%s\">\\n' ' <subfield code=\"2\">%s</subfield>\\n' ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' ", "label": 0}, {"snippet_id": 93779, "code": " start_component_without_deps(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self", "label": 0}, {"snippet_id": 51273, "code": " else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append", "label": 0}, {"snippet_id": 23705, "code": " eject\".format(dvd)) if chk_err and retcode !=0: raise OSUtilError(\"Failed to eject dvd: ret={0}\".format(retcode)) def restart_if(self, ifname): shellutil.run(\"/etc/rc.d/dhclient restart{0}\".format(ifname),", "label": 0}, {"snippet_id": 5887, "code": "(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong field", "label": 0}, {"snippet_id": 42062, "code": "\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name", "label": 0}, {"snippet_id": 20133, "code": " background process.\"\"\" if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None self._adapter", "label": 0}, {"snippet_id": 14173, "code": ".base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request", "label": 0}, {"snippet_id": 29321, "code": " in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise", "label": 1}, {"snippet_id": 75758, "code": " self.log.info( 'Termination signal %s recieved', repr((interface, method, data))) self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler", "label": 1}, {"snippet_id": 29828, "code": " the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in", "label": 1}, {"snippet_id": 42490, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True):", "label": 0}, {"snippet_id": 79398, "code": ">=400: \t\t\t\tself.logger.warning(\"Code exec detection returned an http code of %s.\",r.status_code) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger", "label": 0}, {"snippet_id": 68700, "code": ".1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags", "label": 0}, {"snippet_id": 5815, "code": " mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length=len(fulltext) get_index=lambda x: int(float(x) / 100 * length) partial_text=[fulltext[get_index(start)", "label": 0}, {"snippet_id": 89659, "code": " def find_libs(self, names): \"\"\"Looks for jars in the distribution lib folder(s). If the distribution is a JDK, both the `lib` and `jre/lib` dirs will be scanned. The endorsed and extension dirs are not", "label": 0}, {"snippet_id": 21707, "code": ", 0], X_set[y_set==j, 1], c=ListedColormap(('red', 'green'))(i), label=j) plt.title('Classifier(Training set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors", "label": 0}, {"snippet_id": 66948, "code": "): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register", "label": 0}, {"snippet_id": 26625, "code": " data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id", "label": 0}, {"snippet_id": 75069, "code": "=self.ev.solve_capage(domain, page) self.p.log.info('Done, sending answer: %s', res) self.p.send_success_rep(reqid,[v.encode('utf-8') for v in res]) def send_keepalive(self): msg=self.p.wz.make_req_msg", "label": 0}, {"snippet_id": 78155, "code": "-name']) if c.no_shell: while True: time.sleep(1) else: try: import IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except KeyboardInterrupt: print(\"KeyboardInterrupt\") except", "label": 1}, {"snippet_id": 56750, "code": " return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk) def case(self): return 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk) def run(self): return 'run/get_tag.html", "label": 0}, {"snippet_id": 11570, "code": ".value_to_icinga(value)))) self.write_line(\"}\") @staticmethod def value_to_icinga(value): \"\"\"Convert a scalar or list to Icinga value format. Lists are concatenated by, and empty(None) values produce an", "label": 1}, {"snippet_id": 94553, "code": "-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name): session=server.find_where({ \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send", "label": 0}, {"snippet_id": 90821, "code": " minimum_version{}, ' 'maximum_version{}') raise self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how", "label": 0}, {"snippet_id": 62022, "code": "): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for", "label": 0}, {"snippet_id": 26218, "code": "'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle", "label": 0}, {"snippet_id": 79767, "code": "\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"", "label": 0}, {"snippet_id": 29221, "code": " mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is", "label": 0}, {"snippet_id": 78315, "code": ".add_comment,(t, msg)) except exc.Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t)", "label": 1}, {"snippet_id": 23668, "code": " remove_route_for_dhcp_broadcast(self, ifname): shellutil.run(\"route delete 255.255.255.255 -iface{0}\".format(ifname), chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"pgrep -n dhclient", "label": 0}, {"snippet_id": 43391, "code": " IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self", "label": 0}, {"snippet_id": 16601, "code": ") def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync", "label": 0}, {"snippet_id": 48274, "code": "\"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may", "label": 0}, {"snippet_id": 56313, "code": ", value in request_dict.items(): if key not in skip_parameters and value: parameters[str(key)]=value return parameters @require_GET def info(request): \"\"\"Ajax responder for misc information\"\"\" objects=_InfoObjects", "label": 1}, {"snippet_id": 44441, "code": " elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep", "label": 0}, {"snippet_id": 58280, "code": ".tests import remove_perm_from_user from tcms.tests import user_should_have_perm from tcms.tests.factories import UserFactory from tcms.tests.factories import EnvGroupFactory from tcms.tests.factories import", "label": 0}, {"snippet_id": 31892, "code": "(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output", "label": 0}, {"snippet_id": 39391, "code": "(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update", "label": 0}, {"snippet_id": 92856, "code": " self.assertRaisesRegexp(zipfile.BadZipfile, r'{}'.format(not_zip.name)): next(open_zip(file_symlink).gen) @contextmanager def _stdio_as_tempfiles(self): \"\"\"Harness to replace `sys.std*` with tempfiles.", "label": 0}, {"snippet_id": 27729, "code": " elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data", "label": 0}, {"snippet_id": 22786, "code": " value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param username: The username whose password to change :param password: The unencrypted", "label": 0}, {"snippet_id": 37417, "code": ".input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output", "label": 0}, {"snippet_id": 39034, "code": "))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map", "label": 0}, {"snippet_id": 60581, "code": "'Heterodyne'} _circuits={} def __init__(self, wires, *, shots=0, hbar=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply", "label": 1}, {"snippet_id": 5592, "code": ":keyword spires: bool, to get the spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i ", "label": 0}, {"snippet_id": 45567, "code": " lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall", "label": 1}, {"snippet_id": 583, "code": ".Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute", "label": 0}, {"snippet_id": 14498, "code": ") return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self)", "label": 0}, {"snippet_id": 7282, "code": " here only not to break compatibility, in fact spires output should never be used for xml because if we read marc back into the KeywordToken objects, we would not find them :keyword provenience: string", "label": 0}, {"snippet_id": 1683, "code": "%s' not found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False) elif action=='logout': print(action) username=request.POST", "label": 0}, {"snippet_id": 83041, "code": ".shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info", "label": 0}, {"snippet_id": 23503, "code": " +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user(username): raise OSUtilError((\"User{0} is a system user, \" \"will", "label": 0}, {"snippet_id": 45282, "code": ")) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag)", "label": 0}, {"snippet_id": 67559, "code": ".target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(", "label": 0}, {"snippet_id": 77035, "code": ".die_on_neterror w.caprate_minp=c.caprate_minp w.caprate_limit=c.caprate_limit w.conlimit=c.conlimit w.comment_successtimeout=0.2 if c.upload_avatar: w.hooks['post_login'].append(upload_avatar) yield w class", "label": 0}, {"snippet_id": 60937, "code": ": circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out @classmethod def capabilities(cls): \"\"\"Get the other capabilities", "label": 0}, {"snippet_id": 79507, "code": "\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[", "label": 1}, {"snippet_id": 29524, "code": " raise IOError(\"Missing files after{} seconds:\\n{}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer", "label": 0}, {"snippet_id": 2559, "code": "\" and not self.run_on_localhost(comp): self.copy_component_to_remote(comp, comp['name'], comp['host']) self.host_list=list(set(self.host_list)) self.set_dependencies(True) def set_dependencies(self, exit_on_fail", "label": 0}, {"snippet_id": 69563, "code": " next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg: new_args.append(opt) next_is_arg=False else: if command: if command", "label": 0}, {"snippet_id": 37841, "code": ".lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile", "label": 0}, {"snippet_id": 75274, "code": " method): try: handler=self.req_handlers[(interface, method)] except KeyError: try: handler=self.req_handlers[(interface, None)] except KeyError: raise WZENoReqHandler(iden, reqid, 'No req handler for %s,%s", "label": 0}, {"snippet_id": 17469, "code": ": self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request", "label": 0}, {"snippet_id": 11609, "code": " in value]) else: return str(value) class OutputWriter(object): def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with open(self.output_file, 'w') as f: for line", "label": 0}, {"snippet_id": 69986, "code": " return \"Preinstall a new file system.\" def is_hidden(self): return True def execute(self): try: conf_dir_path=Globals().get_conf_dir() if not os.path.exists(conf_dir_path): os.makedirs(conf_dir_path, 0755", "label": 0}, {"snippet_id": 66955, "code": ".cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance", "label": 0}, {"snippet_id": 42329, "code": " from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name ", "label": 0}, {"snippet_id": 21836, "code": "'uniform', activation='relu', input_dim=11)) classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu')) classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))", "label": 1}, {"snippet_id": 36521, "code": " the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic,", "label": 0}, {"snippet_id": 93907, "code": " hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else: self.logger.debug(\"Host '%s' is not", "label": 0}, {"snippet_id": 8642, "code": " outputs(text, MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate", "label": 0}, {"snippet_id": 28012, "code": "'wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56:", "label": 0}, {"snippet_id": 17030, "code": ".CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value':", "label": 0}, {"snippet_id": 44525, "code": " quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun", "label": 0}, {"snippet_id": 85589, "code": " access to relevant Zinc compiler wrapper jars and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self, products) def __init__(self, zinc_factory, products): self._zinc_factory=zinc_factory self._products", "label": 0}, {"snippet_id": 42310, "code": " protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions", "label": 0}, {"snippet_id": 8424, "code": "\"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines if _ONE_WORD", "label": 1}, {"snippet_id": 89670, "code": " is a JDK, both the `lib` and `jre/lib` dirs will be scanned. The endorsed and extension dirs are not checked. :param list names: jar file names :return: list of paths to requested libraries :raises: `Distribution", "label": 0}, {"snippet_id": 88245, "code": " contextlib import contextmanager from twitter.common.collections import OrderedSet from pants.base.build_environment import get_buildroot, get_scm from pants.base.worker_pool import SubprocPool from pants", "label": 0}, {"snippet_id": 60203, "code": " operator_map={ 'CatState:': Catstate, 'CoherentState': Coherent, 'FockDensityMatrix': DensityMatrix, 'DisplacedSqueezed': DisplacedSqueezed, 'FockState': Fock, 'FockStateVector': Ket, 'SqueezedState': Squeezed,", "label": 0}, {"snippet_id": 53596, "code": " not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain", "label": 0}, {"snippet_id": 46347, "code": " functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone=None, fromdict=None, plainstr=False): \"\"\" Create the object. Arguments", "label": 0}, {"snippet_id": 45858, "code": "\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern", "label": 0}, {"snippet_id": 19516, "code": " script gottarget=False skip=0 for i in range(len(argv)): if skip: skip -=1 continue arg=argv[i] try: nextarg=argv[i +1] except IndexError: nextarg=None if gottarget: script=argv[i:] +script break if arg=='-", "label": 0}, {"snippet_id": 72370, "code": ".add_cmd def reloadproto(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for", "label": 0}, {"snippet_id": 71991, "code": " plugin -allows you to manipulate connections to various configured networks.\"\"\" import importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc", "label": 0}, {"snippet_id": 40223, "code": "=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex", "label": 1}, {"snippet_id": 52237, "code": " jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule", "label": 0}, {"snippet_id": 44606, "code": ")) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info", "label": 0}, {"snippet_id": 24422, "code": "._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self", "label": 0}, {"snippet_id": 83639, "code": ", value) env=getattr( job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params", "label": 0}, {"snippet_id": 67514, "code": " * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from Shine", "label": 0}, {"snippet_id": 60437, "code": "\n \"\"\"This module contains the device class and context manager\"\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields", "label": 0}, {"snippet_id": 78916, "code": " \t\t\t\tself.logger.critical(\"%s: Host unreachable(%s)\",getHost(initUrl),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here", "label": 0}, {"snippet_id": 57638, "code": " raise ObjectDoesNotExist('Default tester not found!') self.get_update_targets().update(**{str(self.target_field): user.pk}) def _update_case_status(self): try: new_status=TestCaseStatus.objects.get(pk=self", "label": 0}, {"snippet_id": 68882, "code": " AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 41810, "code": " @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested", "label": 0}, {"snippet_id": 56220, "code": " import require_POST from tcms.signals import POST_UPDATE_SIGNAL from tcms.management.models import Component, Build, Version from tcms.management.models import Priority from tcms.management.models import", "label": 0}, {"snippet_id": 94936, "code": " Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark", "label": 0}, {"snippet_id": 79043, "code": ".trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \"", "label": 0}, {"snippet_id": 66241, "code": " tag], [\"label\", target.label], [\"flags\", ' '.join(flags)], [\"fsname\", target.fs.fs_name], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column", "label": 0}, {"snippet_id": 12832, "code": "\".join(config[\"pycodestyle\"][\"ignore\"]) arg_to_ignore=\"\" if len(to_ignore) > 0: arg_to_ignore=\"--ignore \" +to_ignore for file in py_files: filename=file[1:] url=\"https://raw.githubusercontent.com/{}/{}", "label": 0}, {"snippet_id": 7429, "code": ":limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches, ckw_matches, spires=spires)} if not only_core_tags", "label": 0}, {"snippet_id": 18469, "code": "._omnicomp) else: extra_data={} self._AddExtraConfDataIfNeeded( extra_data) if force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self", "label": 0}, {"snippet_id": 51700, "code": ".group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames", "label": 0}, {"snippet_id": 7080, "code": " keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches", "label": 0}, {"snippet_id": 39113, "code": "=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not", "label": 0}, {"snippet_id": 2890, "code": " component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %", "label": 0}, {"snippet_id": 8967, "code": " output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param", "label": 0}, {"snippet_id": 35411, "code": " in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard", "label": 0}, {"snippet_id": 57138, "code": " error=get_value_by_type(value, vtype) if error: return say_no(error) has_perms=check_permission(request, ctype) if not has_perms: return say_no('Permission Dinied.') model=apps.get_model(*ctype.split(\"", "label": 0}, {"snippet_id": 6149, "code": "'t \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) lines=[line for line in lines", "label": 1}, {"snippet_id": 50907, "code": ".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) >", "label": 0}, {"snippet_id": 24936, "code": " data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 40607, "code": " temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write", "label": 0}, {"snippet_id": 39348, "code": " workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with", "label": 0}, {"snippet_id": 95512, "code": " error_perm: print(\"[Setup][FTP] Error: Could not change to:{}\".format(remote_path_absolute)) ftp.cwd(remote_path_absolute) file_list=ftp.nlst() file_counter=1 file_list_total=len(file_list) for file in", "label": 0}, {"snippet_id": 69843, "code": ": FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE:", "label": 0}, {"snippet_id": 63030, "code": "\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache", "label": 0}, {"snippet_id": 14320, "code": "'--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options", "label": 0}, {"snippet_id": 62749, "code": "([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__", "label": 0}, {"snippet_id": 52899, "code": ", rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name", "label": 0}, {"snippet_id": 59862, "code": " OpenQML. Args: wires(int): The number of qubits of the device. \"\"\" short_name='projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set", "label": 0}, {"snippet_id": 48762, "code": ", params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"", "label": 0}, {"snippet_id": 46212, "code": " **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format", "label": 0}, {"snippet_id": 7119, "code": ", spires, only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s", "label": 0}, {"snippet_id": 33833, "code": " print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path", "label": 0}, {"snippet_id": 17270, "code": "=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port", "label": 1}, {"snippet_id": 59345, "code": " Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"", "label": 0}, {"snippet_id": 45226, "code": ".workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\"))", "label": 0}, {"snippet_id": 6639, "code": " output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, **kwargs", "label": 0}, {"snippet_id": 10582, "code": " except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\")", "label": 0}, {"snippet_id": 36484, "code": " protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files.", "label": 0}, {"snippet_id": 66285, "code": " size\", AsciiTableLayout.CENTER) if jdev_col_enabled: i +=1 layout.set_column(\"jdev\", i, AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 11319, "code": " EXIT_CODE_CONFIG_WRITTEN=0 EXIT_CODE_ERROR=1 EXIT_CODE_NOT_WRITTEN=2 LOG=logging.getLogger(\"monconfgenerator\") class MonitoringConfigGenerator(object): def __init__(self, url, debug_enabled=False, target_dir", "label": 0}, {"snippet_id": 26269, "code": " Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy', None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None],", "label": 0}, {"snippet_id": 23644, "code": "/etc/rc.d/dhclient start{0}\".format(self.get_if_name()), chk_err=False) def allow_dhcp_broadcast(self): pass def set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255", "label": 0}, {"snippet_id": 80461, "code": "(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in args.legitExtensions] \tfoundExt=[a[0] for a in extensions] \tfor b in args.legitExtensions: \t\tif b in foundExt", "label": 0}, {"snippet_id": 26454, "code": "(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any", "label": 0}, {"snippet_id": 37387, "code": " _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the", "label": 0}, {"snippet_id": 67052, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import", "label": 0}, {"snippet_id": 36045, "code": " self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items()", "label": 0}, {"snippet_id": 83212, "code": " url_to_destination( self, url): \"\"\"Convert a legacy URL to a job destination\"\"\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try", "label": 0}, {"snippet_id": 51977, "code": ",(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return", "label": 0}, {"snippet_id": 32684, "code": " return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"", "label": 0}, {"snippet_id": 34703, "code": " raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod", "label": 0}, {"snippet_id": 47143, "code": " output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill)", "label": 0}, {"snippet_id": 26553, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise", "label": 0}, {"snippet_id": 31755, "code": ".discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output", "label": 0}, {"snippet_id": 78741, "code": "=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s', url, request) response=urllib2.urlopen(url, request) for i in ijson.items(response, 'item'): yield from_json(i", "label": 0}, {"snippet_id": 13291, "code": ", auth=auth) with open(\"file_to_fix.py\", 'w+', encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess", "label": 0}, {"snippet_id": 76827, "code": ", help='Terminate spawn in case of too many NetErrors') c=parser.parse_args() noproxy_rp=sup.net.RequestPerformer() noproxy_rp.proxy='' noproxy_rp.timeout=c.noproxy_timeout noproxy_rp.timeout=c.rp_timeout", "label": 0}, {"snippet_id": 86832, "code": "', '-S-g:vars') @classmethod def get_warning_args_default(cls): return('-C-deprecation', '-C-Xlint:all', '-C-Xlint:-serial', '-C-Xlint:-path', '-S-deprecation', '-S-unchecked', '-S-Xlint') @classmethod", "label": 0}, {"snippet_id": 52099, "code": " except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath", "label": 0}, {"snippet_id": 2435, "code": ".host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger", "label": 0}, {"snippet_id": 69002, "code": " else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\"", "label": 0}, {"snippet_id": 69320, "code": " import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction", "label": 0}, {"snippet_id": 90164, "code": " self._bin_path, self._minimum_version, self._maximum_version, self._jdk)) class _DistributionEnvironment(AbstractClass): class Location(namedtuple('Location',['home_path', 'bin_path'])): \"\"\"Represents", "label": 0}, {"snippet_id": 34702, "code": "=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs:", "label": 0}, {"snippet_id": 70672, "code": " event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags=STATUS_ANY view=self.view_support.get_view() if view is None: view=\"fs\" else: view=view.lower() if view.startswith(\"disk\") or view", "label": 1}, {"snippet_id": 94477, "code": "\"Check succeeded\") return CheckState.RUNNING elif not check_available: logger.debug(\"No custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug", "label": 0}, {"snippet_id": 15000, "code": "( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method, timeout)", "label": 0}, {"snippet_id": 18556, "code": " self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive():", "label": 0}, {"snippet_id": 37730, "code": "=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise", "label": 0}, {"snippet_id": 55880, "code": ".params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def", "label": 0}, {"snippet_id": 90805, "code": " minimum_version): error_format=('Pants configuration/options led to impossible constraints for{} ' 'distribution: minimum_version{}, maximum_version{}') else: error_format=('Failed to locate a{} distribution", "label": 0}, {"snippet_id": 50476, "code": ", message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def benchmark(self, benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate", "label": 0}, {"snippet_id": 541, "code": " elif action=='logout': print(action) username=request.POST.get(\"username\") print(username+' ') queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\",", "label": 0}, {"snippet_id": 25146, "code": ".util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES", "label": 1}, {"snippet_id": 21406, "code": ".mkdir(work_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle", "label": 0}, {"snippet_id": 22184, "code": " template=templateEnv.get_template( template_file) outputText=template.render( data) return outputText def run(self, state, data=None, context=None): \"\"\"Run ansible-playbook on the specified playbook. \"\"\"", "label": 0}, {"snippet_id": 16869, "code": "'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__( self): pass def Start( self): pass def Done( self", "label": 0}, {"snippet_id": 39849, "code": " workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self", "label": 0}, {"snippet_id": 73132, "code": "(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, file_path_local)) else: print(\"", "label": 0}, {"snippet_id": 30132, "code": " toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str,", "label": 0}, {"snippet_id": 54712, "code": ": \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules", "label": 0}, {"snippet_id": 70469, "code": ".CommandRCDefs import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs", "label": 0}, {"snippet_id": 67709, "code": " of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed", "label": 0}, {"snippet_id": 34541, "code": ".stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return", "label": 0}, {"snippet_id": 82449, "code": " --proxy.\") if args.skipRecon and args.legitExtensions==None: \tparser.error(\"-s switch needs -l switch. Cannot skip recon phase without any known entry point.\") args.n=int(args.n[0]) args.size=int(args", "label": 0}, {"snippet_id": 1066, "code": " safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 42591, "code": ".discard(old) branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict(", "label": 0}, {"snippet_id": 88260, "code": " SubprocPool from pants.base.workunit import WorkUnit, WorkUnitLabel from pants.build_graph.target import Target from pants.engine.isolated_process import FallibleExecuteProcessResult from pants.goal.products", "label": 1}, {"snippet_id": 4405, "code": " name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full", "label": 0}, {"snippet_id": 69904, "code": " indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(),", "label": 0}, {"snippet_id": 90275, "code": "') if java_home: yield java_home search_path=os.environ.get('PATH') if search_path: for bin_path in search_path.strip().split(os.pathsep): yield self.Location.from_bin(bin_path) class _OSXEnvironment(_DistributionEnvironment", "label": 0}, {"snippet_id": 34671, "code": " is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists", "label": 0}, {"snippet_id": 41705, "code": ".expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self):", "label": 1}, {"snippet_id": 38578, "code": ", immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes", "label": 0}, {"snippet_id": 14181, "code": " SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync", "label": 0}, {"snippet_id": 72236, "code": " except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return if args.service not in world.services: irc.error('Unknown service %r.' % args.service) return remoteirc.called_in=remoteirc", "label": 0}, {"snippet_id": 87475, "code": ".extend(['-scala-path', ':'.join(scala_path)]) zinc_args.extend(self._javac_plugin_args(javac_plugin_map)) scalac_plugin_search_classpath=( (set(absolute_classpath) | set(self.scalac_plugin_classpath_elements", "label": 0}, {"snippet_id": 24464, "code": "(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device", "label": 0}, {"snippet_id": 3069, "code": " send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[]", "label": 1}, {"snippet_id": 74321, "code": " disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been generated", "label": 0}, {"snippet_id": 15383, "code": "=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is", "label": 0}, {"snippet_id": 37412, "code": " inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not", "label": 0}, {"snippet_id": 29506, "code": " missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError", "label": 0}, {"snippet_id": 56677, "code": ".num_runs=run_counter.calculate_tag_count(tag) context_data={ 'tags': all_tags, 'object': obj, } return render(request, template_name, context_data) class _TagObjects(object): \"\"\" Used for getting the chosen", "label": 0}, {"snippet_id": 50569, "code": "(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func", "label": 0}, {"snippet_id": 90373, "code": "') self._java_dist_dirs=java_dist_dirs @property def jvm_locations(self): for java_dist_dir in self._java_dist_dirs: if os.path.isdir(java_dist_dir): for path in os.listdir(java_dist_dir): home=os.path", "label": 0}, {"snippet_id": 86158, "code": " if self.get_options().capture_classpath: self._record_compile_classpath(classpath, ctx.target, ctx.classes_dir) try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except", "label": 0}, {"snippet_id": 38513, "code": " docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource", "label": 0}, {"snippet_id": 61136, "code": " theta/2 * Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm(-1j *", "label": 0}, {"snippet_id": 76627, "code": "] msg.append('[image-original-none-http://simg4.gelbooru.com/' +'/images/db/1d/db1dfb62a40f5ced2043bb8966da9a98.png]') msg.append('\u041a\u0430\u0436\u0434\u044b\u0439 \u0445\u043e\u0447\u0435\u0442 \u0434\u0440\u0443\u0436\u0438\u0442\u044c \u0441 \u044f\u0434\u0435\u0440\u043d\u043e\u0439 \u0431\u043e\u043c\u0431\u043e\u0439.') msg.append(str(random.randint", "label": 0}, {"snippet_id": 21953, "code": " remote_user=None, connection=None, timeout=None, ssh_common_args=None, sftp_extra_args=None, scp_extra_args=None, ssh_extra_args=None, poll_interval=None, seconds=None, check=None, syntax=None, diff=None,", "label": 0}, {"snippet_id": 78633, "code": "': 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run())", "label": 0}, {"snippet_id": 34523, "code": " import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger def lstat(f", "label": 1}, {"snippet_id": 5307, "code": " :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output", "label": 0}, {"snippet_id": 55141, "code": " \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files", "label": 0}, {"snippet_id": 55544, "code": ", overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self", "label": 0}, {"snippet_id": 95440, "code": " Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive(ftp, local_directory, remote_directory, remote_subdirs_list=None): \"\"", "label": 0}, {"snippet_id": 17199, "code": " except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=(", "label": 0}, {"snippet_id": 60265, "code": ": the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Strawberry", "label": 0}, {"snippet_id": 77854, "code": "() try: while self.running.is_set(): if self.c.tcount==0: self.inter_sleep(5) continue self.pc.check_waiting() new=self.read_newproxies() if not new: self.inter_sleep(5) continue self.add_spawns(new) except", "label": 0}, {"snippet_id": 36078, "code": ".dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio[f] if f_ in self", "label": 0}, {"snippet_id": 22020, "code": ".become=become self.become_method=become_method self.become_user=become_user self.become_ask_pass=become_ask_pass self.ask_pass=ask_pass self.private_key_file=private_key_file self.remote_user=remote_user", "label": 0}, {"snippet_id": 19706, "code": " args.address=Address.as_server(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost,", "label": 0}, {"snippet_id": 2582, "code": ", exit_on_fail): for group in self.config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes", "label": 0}, {"snippet_id": 63638, "code": " finishing job %d\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements=True) try: job_wrapper.finish( stdout", "label": 0}, {"snippet_id": 43236, "code": "=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names", "label": 0}, {"snippet_id": 92652, "code": "): with temporary_dir(cleanup=False) as path: self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self.assertTrue(os.path.exists(path), 'Temporary dir should exist outside", "label": 0}, {"snippet_id": 33814, "code": " no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False", "label": 0}, {"snippet_id": 22352, "code": ". This ensures that the rest of the provisioning does not need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception", "label": 0}, {"snippet_id": 93819, "code": ": self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) else: self.logger.info(\"creating window '%s'\" % comp['name']) window", "label": 0}, {"snippet_id": 91147, "code": ".backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements from pants.backend.python.rules import inject_init, python_test_runner", "label": 0}, {"snippet_id": 60225, "code": ", 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'Kerr': Kgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeezing'", "label": 0}, {"snippet_id": 56213, "code": ".decorators.http import require_GET from django.views.decorators.http import require_POST from tcms.signals import POST_UPDATE_SIGNAL from tcms.management.models import Component, Build, Version from tcms", "label": 0}, {"snippet_id": 49599, "code": " ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes", "label": 0}, {"snippet_id": 34306, "code": "(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return", "label": 0}, {"snippet_id": 53159, "code": " import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"", "label": 0}, {"snippet_id": 41886, "code": " filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule,", "label": 0}, {"snippet_id": 79937, "code": "\"listOfExtensions\",dest=\"legitExtensions\",nargs=1,help=\"Legit extensions expected, for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1", "label": 0}, {"snippet_id": 23307, "code": ", mask, gateway) return shellutil.run(cmd, chk_err=False) def device_for_ide_port(self, port_id): \"\"\"Return device name attached to ide port 'n'. Include a wait in here because BIG-IP may not have yet initialized", "label": 0}, {"snippet_id": 52850, "code": ".update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log", "label": 0}, {"snippet_id": 6961, "code": " string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of", "label": 0}, {"snippet_id": 48795, "code": ".products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno", "label": 0}, {"snippet_id": 18082, "code": " handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get(", "label": 1}, {"snippet_id": 23960, "code": "-2 err, output=shellutil.run_get_output('sysctl dev.storvsc | grep pnpinfo | grep deviceid=') if err: return None g1=\"000\" +ustr(port_id) g0g1=\"{0}-{1}\".format(g0, g1) \"\"\" search 'X' from 'dev.storvsc.X", "label": 0}, {"snippet_id": 50274, "code": "*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException", "label": 0}, {"snippet_id": 23232, "code": " retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected * struct_size): logger.warn(('SIOCGIFCONF returned more than{0} up ' 'network interfaces.'), expected) sock=buff.tostring() for i in range(0,", "label": 0}, {"snippet_id": 54858, "code": "=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources=dict() if resources", "label": 0}, {"snippet_id": 87772, "code": "(os.pardir) dist=self._zinc.dist for path in classpath: if not os.path.isabs(path): raise TaskError('Classpath entries provided to zinc should be absolute. ' '{} is not.'.format(path)) if is_outside(path", "label": 0}, {"snippet_id": 75476, "code": "=None): if not reqid: reqid=self.make_reqid() args=[interface, method, make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-request', args, reqid) def make_auth_bind_route_data(self,", "label": 0}, {"snippet_id": 72535, "code": " if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument", "label": 0}, {"snippet_id": 71400, "code": ".LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\"", "label": 0}, {"snippet_id": 53105, "code": "}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s) return s def __bool__(self): return bool(self.updated_input or self.missing_output or self.forced or self.updated_input_run or self.noio or", "label": 0}, {"snippet_id": 80907, "code": ".CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime.now() print() logging.info(\"%s entry point(s) found using %s HTTP requests.\",nbOfEntryPointsFound,up.httpRequests) print(\"Found the following entry points", "label": 0}, {"snippet_id": 24469, "code": " return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class", "label": 0}, {"snippet_id": 59738, "code": " if val in[XGate, YGate, ZGate, AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires", "label": 0}, {"snippet_id": 11374, "code": "(\"Using URL: %s\" % self.source) LOG.debug(\"MonitoringConfigGenerator start: reading from %s, writing to %s\" % (self.source, self.target_dir)) def _is_newer(self, header_source, hostname): if not hostname", "label": 0}, {"snippet_id": 61695, "code": " raise ValueError('2x2 matrix required.') if len(wires) !=1: raise ValueError('One target subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np.eye(before)", "label": 0}, {"snippet_id": 94960, "code": " configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH\") config_parser.add_argument(\"-f\", action=", "label": 0}, {"snippet_id": 83254, "code": ".__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running", "label": 0}, {"snippet_id": 63739, "code": " job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning( \"stop_job(): %s: no PID in database for job, unable to stop\" % job.id) return pid=int( pid)", "label": 0}, {"snippet_id": 62419, "code": " None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self", "label": 0}, {"snippet_id": 51789, "code": " dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist", "label": 0}, {"snippet_id": 86718, "code": " path to an appropriate jvm distribution. :param settings: The jvm platform settings from which to extract the arguments. :type settings::class:`JvmPlatformSettings` \"\"\" zinc_args=[ '-C-source', '-C{}'", "label": 0}, {"snippet_id": 63262, "code": ".fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state", "label": 0}, {"snippet_id": 30782, "code": "._inputsize @property def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise", "label": 0}, {"snippet_id": 35036, "code": " wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\")", "label": 0}, {"snippet_id": 42071, "code": "\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name:", "label": 0}, {"snippet_id": 3689, "code": " true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name']) if check_available", "label": 0}, {"snippet_id": 29976, "code": " Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join", "label": 0}, {"snippet_id": 38279, "code": "\"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 30723, "code": ": self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self", "label": 0}, {"snippet_id": 6402, "code": " import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import", "label": 0}, {"snippet_id": 9909, "code": "=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted", "label": 0}, {"snippet_id": 28374, "code": " variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for", "label": 0}, {"snippet_id": 56474, "code": " def env_values(self): return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id')) def users(self): query=strip_parameters(self.request.GET, skip_parameters=('info_type', 'field',", "label": 0}, {"snippet_id": 34210, "code": "**kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths, kwpaths) return ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return", "label": 0}, {"snippet_id": 72429, "code": " if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark", "label": 1}, {"snippet_id": 85521, "code": ", Zinc.ZINC_EXTRACTOR_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-extractor_2.11', '0.0.4') ]) @classmethod def _zinc(cls, products): return cls.tool_jar_from_products(products, Zinc.ZINC_COMPILER_TOOL_NAME", "label": 1}, {"snippet_id": 69588, "code": "\n from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support", "label": 0}, {"snippet_id": 15073, "code": "() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler", "label": 0}, {"snippet_id": 24615, "code": "': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low", "label": 0}, {"snippet_id": 77752, "code": "): msg=[b'GLOBAL'] msg.extend(wzrpc.make_sig_msg(b'WZWorker', b'terminate',[])) if hasattr(self, 'th_sock'): self.th_sock.send_multipart(msg) if hasattr(self, 'pr_sock'): self.pr_sock.send_multipart(msg", "label": 0}, {"snippet_id": 70043, "code": " from Base.FSEventHandler import FSGlobalEventHandler from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine", "label": 0}, {"snippet_id": 77608, "code": ".userqueues[domain] except KeyError: self.log.info('Created userqueue for %s', domain) uq=Queue() self.userqueues[domain]=uq return uq def load_targets(self): fname=self.targetsfile if not os.path.isfile(fname):", "label": 0}, {"snippet_id": 81422, "code": " matched the following information: %s\\033[m\",r) \t\t\treturn r \t\telse: \t\t\treturn None \t \tdef detectValidExtensions(self,extensions,maxN,extList=None): \t\tself.logger.info(\" \t\tn=0 \t\tif extList: \t\t\ttmpExtList", "label": 0}, {"snippet_id": 73117, "code": " remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp=ftp.nlst() if not os.path.isfile(file_path_local): with open(file_path_local, \"wb\") as local_file: ftp.retrbinary", "label": 0}, {"snippet_id": 44692, "code": " self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self", "label": 0}, {"snippet_id": 7466, "code": "(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories", "label": 0}, {"snippet_id": 4672, "code": "]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the", "label": 0}, {"snippet_id": 76178, "code": " m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug('Route %s,%s was not bound', i, m) return self.log.debug('Unbinding route %s,", "label": 0}, {"snippet_id": 61804, "code": ", 2, between] p=np.array(p) perm=np.r_[p, p+3] temp=np.prod(dim) U=U.reshape(dim * 2).transpose(perm).reshape([temp, temp]) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit", "label": 0}, {"snippet_id": 85434, "code": " register): super(Zinc.Factory, cls).register_options(register) zinc_rev='1.0.3' shader_rules=[ Shader.exclude_package('scala', recursive=True), Shader.exclude_package('xsbt', recursive=True), Shader.exclude_package", "label": 0}, {"snippet_id": 10423, "code": "(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not", "label": 0}, {"snippet_id": 8340, "code": " the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"", "label": 1}, {"snippet_id": 76937, "code": "=random.choice(d.ua_list) net.timeout=c.rp_timeout return net def upload_avatar(self, ud): if('avatar_uploaded' in ud[0] and ud[0]['avatar_uploaded'] is True): return files=[] for sd in os.walk(c.av_dir):", "label": 0}, {"snippet_id": 82291, "code": ".\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\"", "label": 0}, {"snippet_id": 7844, "code": " output def _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,.", "label": 0}, {"snippet_id": 68875, "code": " layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column", "label": 0}, {"snippet_id": 3757, "code": " \"session_name\": name }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file", "label": 0}, {"snippet_id": 81617, "code": ") \t\t\t \t\t\tif uploadRes !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex", "label": 0}, {"snippet_id": 40307, "code": ",\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing", "label": 0}, {"snippet_id": 79999, "code": "\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip recon", "label": 0}, {"snippet_id": 12109, "code": " diff_url=diff_url.format(repository, str(data[\"pr_number\"])) r=requests.get(diff_url, headers=diff_headers, auth=auth) patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) files={} for patchset", "label": 0}, {"snippet_id": 7480, "code": " def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories } def _output_text(complete_output, categories): \"\"\"Output the results obtained in text", "label": 0}, {"snippet_id": 46401, "code": " self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name", "label": 0}, {"snippet_id": 50743, "code": "\n__author__=\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools", "label": 0}, {"snippet_id": 86748, "code": "('$JAVA_HOME' in a for a in settings.args): try: distribution=JvmPlatform.preferred_jvm_distribution([settings], strict=True) except DistributionLocator.Error: distribution=JvmPlatform.preferred_jvm_distribution", "label": 0}, {"snippet_id": 40803, "code": " wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values", "label": 0}, {"snippet_id": 74476, "code": "\"\" files=[] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type", "label": 0}, {"snippet_id": 80968, "code": ".trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself.inputName=inputName \t\tself.uploadsFolder=uploadsFolder \t\tself.size=size \t\tself.validExtensions=[] \t\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None", "label": 0}, {"snippet_id": 35875, "code": " found.\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict", "label": 0}, {"snippet_id": 26828, "code": " >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif", "label": 0}, {"snippet_id": 91140, "code": " pants.backend.python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements", "label": 0}, {"snippet_id": 68919, "code": " Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import *", "label": 0}, {"snippet_id": 47726, "code": " snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException", "label": 0}, {"snippet_id": 86988, "code": " clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies() +(Zinc.Factory, JvmPlatform,) @classmethod def prepare(cls, options, round_manager", "label": 0}, {"snippet_id": 15727, "code": ".format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[ 'filetype_specific_completion_to_disable", "label": 0}, {"snippet_id": 62522, "code": "*kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq", "label": 0}, {"snippet_id": 53714, "code": "(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files", "label": 0}, {"snippet_id": 61448, "code": "=1 and state.shape[0]==2**self.wires: self._state=state else: raise ValueError('State vector must be of length 2**wires.') continue U=DefaultQubit._get_operator_matrix(operation) if len(operation.wires", "label": 0}, {"snippet_id": 63330, "code": "']=compute_environment job_wrapper.prepare( **prepare_kwds) self.__prepare_input_files_locally(job_wrapper) remote_metadata=LwrJobRunner.__remote_metadata( client) remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy", "label": 0}, {"snippet_id": 29658, "code": " keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as", "label": 0}, {"snippet_id": 27148, "code": "=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS,", "label": 1}, {"snippet_id": 84013, "code": " started\"\"\" job_state=AsynchronousJobState() job_state.job_id=str( job.get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination", "label": 0}, {"snippet_id": 30316, "code": " def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name", "label": 0}, {"snippet_id": 1811, "code": "\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name': row[2", "label": 0}, {"snippet_id": 26967, "code": "'GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self", "label": 0}, {"snippet_id": 23349, "code": " import azurelinuxagent.common.logger as logger from azurelinuxagent.common.exception import OSUtilError from azurelinuxagent.common.osutil.default import DefaultOSUtil from azurelinuxagent.common.future", "label": 0}, {"snippet_id": 5135, "code": "(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit", "label": 0}, {"snippet_id": 28898, "code": " data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 26178, "code": ":['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], ", "label": 0}, {"snippet_id": 50426, "code": "=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def", "label": 0}, {"snippet_id": 42471, "code": " self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other", "label": 0}, {"snippet_id": 20253, "code": "+self._run_server_ex raise Exception(message) self._launch( argv, script=script, wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script(self, filename", "label": 0}, {"snippet_id": 83192, "code": ".async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type': transport, 'cache': string_as_bool_or_none(cache), \"url\": url} self.galaxy_url", "label": 0}, {"snippet_id": 82229, "code": "\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False", "label": 0}, {"snippet_id": 96027, "code": ".DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)) if conversion_config.compressor==\"Blosc\"", "label": 0}, {"snippet_id": 49396, "code": ", printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete", "label": 0}, {"snippet_id": 53550, "code": " *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name", "label": 0}, {"snippet_id": 77873, "code": " self.add_spawns(new) except WorkerInterrupt: pass except Exception as e: self.log.exception(e) self.terminate() self.join_threads() if self.c.tcount > 0: self.save_users() self.save_targets() wm=workers", "label": 0}, {"snippet_id": 39591, "code": " return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input", "label": 0}, {"snippet_id": 22375, "code": " exception if mcpd does not come up within roughly 50 minutes(100 * 30 seconds) \"\"\" for retries in range(1, 100): logger.info(\"Checking to see if mcpd is up\") rc=shellutil.run(\"/usr/bin/tmsh -a show sys", "label": 0}, {"snippet_id": 85568, "code": " from products active in the current Pants run. :param products: The active Pants run products to pluck classpaths from. :type products::class:`pants.goal.products.Products` :returns: A Zinc instance with", "label": 0}, {"snippet_id": 30248, "code": " names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def", "label": 0}, {"snippet_id": 26736, "code": "\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self", "label": 0}, {"snippet_id": 73450, "code": ") print(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path", "label": 1}, {"snippet_id": 66587, "code": " CommandRegistry from Configuration.ModelFile import ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions", "label": 0}, {"snippet_id": 29781, "code": " temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"\"\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write", "label": 0}, {"snippet_id": 19444, "code": " parse_args(argv=None): \"\"\"Return the parsed args to use in main().\"\"\" if argv is None: argv=sys.argv prog=argv[0] if prog==__file__: prog='{} -m ptvsd'.format(os.path.basename(sys.executable)) else: prog", "label": 0}, {"snippet_id": 51122, "code": " def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))?\\s*\\}\") def wait_for_files(files, latency_wait=3): \"", "label": 0}, {"snippet_id": 29949, "code": "(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern", "label": 0}, {"snippet_id": 83529, "code": "=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(", "label": 1}, {"snippet_id": 26093, "code": "\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self.station, exclude=3600) else: self.data=self.station_data", "label": 1}, {"snippet_id": 83840, "code": " for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid", "label": 0}, {"snippet_id": 6916, "code": "(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K", "label": 0}, {"snippet_id": 50709, "code": " self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for", "label": 0}, {"snippet_id": 67185, "code": " Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 39338, "code": " self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir", "label": 0}, {"snippet_id": 72725, "code": "(location=cli_arguments[\"config_file\"]) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def main()", "label": 0}, {"snippet_id": 36881, "code": ".edu\" __license__=\"MIT\" import os import re import sys import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist", "label": 0}, {"snippet_id": 44184, "code": "=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag", "label": 0}, {"snippet_id": 47808, "code": ".version=None self._log=Log() self._benchmark=None self.wildcard_names=set() self.lineno=lineno self.snakefile=snakefile self.run_func=None self.shellcmd=None self.norun=False elif len(args)==1: other=args[0", "label": 0}, {"snippet_id": 4291, "code": "=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split(\"/\")[-1] process_lines", "label": 1}, {"snippet_id": 59780, "code": " value. \"\"\" backend=pq.backends.Simulator(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits", "label": 0}, {"snippet_id": 46247, "code": " the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search", "label": 0}, {"snippet_id": 5286, "code": " keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords ", "label": 0}, {"snippet_id": 59996, "code": "', 'num_runs', 'verbose', 'user', 'password', 'device', 'retrieve_execution'] def __init__(self, wires, **kwargs): if 'user' not in kwargs: raise ValueError('An IBM Quantum Experience user name specified", "label": 0}, {"snippet_id": 75299, "code": " iden: self.iden_reqid_map.add_value(tuple(iden), reqid) handler(reqid, interface, method, msg[1:]) return() def _parse_rep(self, iden, msg, reqid, seqnum, status): try: handler=self.response_handlers[reqid", "label": 0}, {"snippet_id": 61380, "code": "='0.1.0' version='0.1.0' author='Xanadu Inc.' _gates=set(operator_map.keys()) _observables={} _circuits={} def __init__(self, wires, *, shots=0): self.wires=wires self.eng=None self._state=None super()", "label": 0}, {"snippet_id": 49783, "code": " dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this", "label": 0}, {"snippet_id": 75828, "code": ".wz_poll_timeout rs=wzrpc.RequestState(fun) msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) t.tick() while self.running.is_set(): p(timeout*1000) if", "label": 0}, {"snippet_id": 24031, "code": " awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed", "label": 0}, {"snippet_id": 21686, "code": ".shape), alpha=0.75, cmap=ListedColormap(('red', 'green'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j", "label": 0}, {"snippet_id": 45014, "code": " ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo", "label": 0}, {"snippet_id": 78255, "code": " if True: try: self.postmsg(t[1], msg, t[0]) except exc.Success as e: self.counters['comments'] +=1 self.w.sleep(self.comment_successtimeout) except exc.Antispam as e: self.w.sleep(self.comment_successtimeout", "label": 0}, {"snippet_id": 38818, "code": "\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make", "label": 0}, {"snippet_id": 40113, "code": ": if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for", "label": 0}, {"snippet_id": 76678, "code": ")\") parser.add_argument('--no-shell', '-N', action='store_true', help=\"Sleep instead of starting the shell\") parser.add_argument('--tcount', '-t', type=int, default=10, help='WipeThread count') parser.add_argument", "label": 0}, {"snippet_id": 84553, "code": ".workunit import WorkUnitLabel from pants.engine.fs import FilesContent, PathGlobs, PathGlobsAndRoot from pants.engine.isolated_process import ExecuteProcessRequest from pants.task.console_task import ConsoleTask", "label": 0}, {"snippet_id": 24388, "code": " if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return", "label": 0}, {"snippet_id": 37638, "code": "._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule", "label": 0}, {"snippet_id": 68691, "code": ".1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev", "label": 0}, {"snippet_id": 61366, "code": " commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Default OpenQML plugin' short_name='default.qubit' api_version='0.1.0' version='0.1.0' author='Xanadu Inc.' _gates=set(operator_map", "label": 0}, {"snippet_id": 70177, "code": " Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler):", "label": 0}, {"snippet_id": 72833, "code": " path: The path to create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib.Path(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories", "label": 0}, {"snippet_id": 49612, "code": " list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic", "label": 0}, {"snippet_id": 13853, "code": " import retries from requests_futures.sessions import FuturesSession from ycm.unsafe_thread_pool_executor import UnsafeThreadPoolExecutor from ycm import vimsupport from ycm.utils import ToUtf8Json from", "label": 0}, {"snippet_id": 60831, "code": " return self.__module__ +'.' +self.__class__.__name__ +'\\nInstance: ' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self", "label": 0}, {"snippet_id": 15252, "code": " user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request", "label": 0}, {"snippet_id": 35892, "code": "=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__", "label": 0}, {"snippet_id": 66820, "code": ".targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %(action, nodes) def launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self", "label": 0}, {"snippet_id": 49563, "code": " None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules", "label": 0}, {"snippet_id": 1398, "code": " def edit_WifiConn(wifiname, wifipass): ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for", "label": 0}, {"snippet_id": 17825, "code": " dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ ", "label": 0}, {"snippet_id": 39790, "code": "=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name, snakefile, workdir", "label": 0}, {"snippet_id": 17113, "code": " except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0", "label": 0}, {"snippet_id": 88568, "code": " command line invocation that uses wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots @property def console_outstream", "label": 0}, {"snippet_id": 38912, "code": ".snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(", "label": 0}, {"snippet_id": 72938, "code": " local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename", "label": 0}, {"snippet_id": 59785, "code": "**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or", "label": 0}, {"snippet_id": 33154, "code": ", printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None", "label": 0}, {"snippet_id": 83081, "code": " import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep import os from.lwr_client import build_client_manager from.lwr_client", "label": 0}, {"snippet_id": 1471, "code": "=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon", "label": 0}, {"snippet_id": 59871, "code": "'projectq.classicalsimulator' _gates=set([ key for(key,val) in operator_map.items() if val in[XGate, CNOT]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={", "label": 0}, {"snippet_id": 25401, "code": " %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name", "label": 0}, {"snippet_id": 48357, "code": " try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files", "label": 0}, {"snippet_id": 27078, "code": " self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station", "label": 1}, {"snippet_id": 26662, "code": "._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and", "label": 0}, {"snippet_id": 81700, "code": ": \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\treturn result \t \tdef detectForms(html): \t\tsoup=BeautifulSoup(html,'html.parser') \t", "label": 0}, {"snippet_id": 43357, "code": " output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"", "label": 0}, {"snippet_id": 79194, "code": " self.trueRegex: \t\t\t\t\tmoreInfo=re.search(self.trueRegex,html) \t\t\t\t\tif moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t", "label": 0}, {"snippet_id": 23827, "code": "'ps -p{0}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None'", "label": 0}, {"snippet_id": 90088, "code": " self._is_jdk: yield os.path.join(self.home, 'jre', 'bin') for bin_path in bin_paths(): exe=os.path.join(bin_path, name) if self._is_executable(exe): return exe raise self.Error('Failed to locate the{}", "label": 0}, {"snippet_id": 30761, "code": ")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input)", "label": 0}, {"snippet_id": 95883, "code": " file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr", "label": 0}, {"snippet_id": 30749, "code": ".priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files", "label": 0}, {"snippet_id": 90233, "code": " jvm_locations(self): \"\"\"Return the jvm locations discovered in this environment. :returns: An iterator over all discovered jvm locations. :rtype: iterator of:class:`DistributionEnvironment.Location` \"\"\" class", "label": 0}, {"snippet_id": 45604, "code": " def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file, \"w\") as f: pass def apply_wildcards(self, wildcards, fill_missing=False, fail_dynamic=False): f=self._file", "label": 0}, {"snippet_id": 5601, "code": " keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw, info in skw_matches:", "label": 0}, {"snippet_id": 43957, "code": ", targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason", "label": 0}, {"snippet_id": 69014, "code": ".fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount", "label": 0}, {"snippet_id": 1238, "code": " osfilecontent=f.read().split(\"\\n\") version=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t ", "label": 0}, {"snippet_id": 85196, "code": "'scala version is not specified, then the version specified in ' '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would use the suffix version \"2.10\".') elif name.endswith(self.version", "label": 0}, {"snippet_id": 93011, "code": " old_stdout) self.assertEqual(sys.stderr, old_stderr) self.assertEqual(sys.stdin, old_stdin) def test_stdio_as_dev_null(self): with self._stdio_as_tempfiles(): with stdio_as(stdout_fd=-1, stderr_fd=-1,", "label": 0}, {"snippet_id": 75079, "code": ".p.send_success_rep(reqid,[v.encode('utf-8') for v in res]) def send_keepalive(self): msg=self.p.wz.make_req_msg(b'Router', b'bind-keepalive',[], self.handle_keepalive_reply) msg.insert(0, b'') self.p.wz_sock", "label": 0}, {"snippet_id": 17698, "code": " debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info ", "label": 0}, {"snippet_id": 67420, "code": ".RemoteCommand import RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self", "label": 0}, {"snippet_id": 10081, "code": " set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set", "label": 0}, {"snippet_id": 95188, "code": ", reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import", "label": 0}, {"snippet_id": 89304, "code": ", print_function, unicode_literals import itertools import logging import os import pkgutil import plistlib from abc import abstractproperty from builtins import object, open, str from collections import", "label": 0}, {"snippet_id": 68554, "code": "() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout.RIGHT, \" layout.set_column(\"nodes\",", "label": 0}, {"snippet_id": 69218, "code": "-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s", "label": 0}, {"snippet_id": 86115, "code": " _write_processor_info(self, processor_info_file, processors): with safe_open(processor_info_file, 'w') as f: for processor in processors: f.write('{}\\n'.format(processor.strip())) def execute(self): if", "label": 0}, {"snippet_id": 12475, "code": ") error_string=\" \".join(error_string_list) error_string=error_string.replace(\"Line[\", \"[Line \") comment_body.append(\"\\n>{0}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results", "label": 0}, {"snippet_id": 58929, "code": " enough permission to \" \"update TestCases.\"}) def test_update_case_priority(self): self.client.login( username=self.tester.username, password='password') response=self.client.post( self.case_update_url, { ", "label": 0}, {"snippet_id": 2676, "code": " %s and %s!\" %(ex.node1, ex.node2)) if exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path", "label": 0}, {"snippet_id": 38202, "code": " format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError", "label": 0}, {"snippet_id": 29866, "code": " constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one", "label": 0}, {"snippet_id": 51085, "code": " first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill,", "label": 0}, {"snippet_id": 63402, "code": " __prepare_input_files_locally(self, job_wrapper): \"\"\"Run task splitting commands locally.\"\"\" prepare_input_files_cmds=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd", "label": 0}, {"snippet_id": 31283, "code": "\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return", "label": 0}, {"snippet_id": 60205, "code": " Catstate, 'CoherentState': Coherent, 'FockDensityMatrix': DensityMatrix, 'DisplacedSqueezed': DisplacedSqueezed, 'FockState': Fock, 'FockStateVector': Ket, 'SqueezedState': Squeezed, 'ThermalState': Thermal", "label": 0}, {"snippet_id": 42182, "code": "(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set", "label": 0}, {"snippet_id": 20753, "code": " event, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event handlername='event{!r}'.format", "label": 0}, {"snippet_id": 67933, "code": " * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities", "label": 0}, {"snippet_id": 46562, "code": " add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def", "label": 0}, {"snippet_id": 23816, "code": " SCSI disks timeout:{0}\".format(output)) self._scsi_disks_timeout_set=True def check_pid_alive(self, pid): return shellutil.run('ps -p{0}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info", "label": 0}, {"snippet_id": 47737, "code": " apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile", "label": 0}, {"snippet_id": 38789, "code": " list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock:", "label": 0}, {"snippet_id": 19196, "code": ") return response=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors['response", "label": 0}, {"snippet_id": 95718, "code": "=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)) print(\"[Setup][Data] Decompressing file:{}\".format(path_str", "label": 0}, {"snippet_id": 3189, "code": "\" %(hostname, remote_cmd) send_main_session_command(self.session, cmd) def draw_graph(self): deps=Digraph(\"Deps\", strict=True) deps.graph_attr.update(rankdir=\"BT\") try: node=self.nodes.get('master_node", "label": 0}, {"snippet_id": 87956, "code": " This allows us to have in-repo plugins with dependencies(unlike javac, scalac doesn't load plugins or their deps from the regular classpath, so we have to provide these entries separately, in the -Xplugin", "label": 0}, {"snippet_id": 2129, "code": "': 'deleteuser', 'endpoint': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username", "label": 0}, {"snippet_id": 41718, "code": " yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self", "label": 1}, {"snippet_id": 53080, "code": ".append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \"", "label": 0}, {"snippet_id": 95763, "code": "=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy", "label": 0}, {"snippet_id": 26739, "code": "'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif", "label": 0}, {"snippet_id": 56471, "code": " EnvProperty.objects.all() def env_values(self): return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id')) def users(self): query=strip_parameters(self.request.GET, skip_parameters", "label": 0}, {"snippet_id": 426, "code": ") print(username) add_user(username,password) setBoxName=BoxDetails(boxname=boxname) setBoxName.save() wifi_pass=request.POST.get(\"wifi_password\") wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name", "label": 0}, {"snippet_id": 6351, "code": " PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML", "label": 0}, {"snippet_id": 61461, "code": "') continue U=DefaultQubit._get_operator_matrix(operation) if len(operation.wires)==1: U=self.expand_one(U, operation.wires) elif len(operation.wires)==2: U=self.expand_two(U, operation.wires) else: raise", "label": 0}, {"snippet_id": 82140, "code": "\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action", "label": 0}, {"snippet_id": 64775, "code": " system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def", "label": 0}, {"snippet_id": 60836, "code": "' +self.name def __str__(self): \"\"\"Verbose string representation.\"\"\" return self.__repr__() +'\\nName: ' +self.name +'\\nAPI version: ' +self.api_version\\ +'\\nPlugin version: ' +self.version +'\\nAuthor: ", "label": 0}, {"snippet_id": 61215, "code": "(state) def unitary(*args): r\"\"\"Input validation for an arbitary unitary operation. Args: args(array): square unitary matrix. Returns: array: square unitary matrix. \"\"\" U=np.asarray(args[0]) if U.shape", "label": 0}, {"snippet_id": 91594, "code": ", pytest, python_setup, source_root_config): \"\"\"Runs pytest for one target.\"\"\" url='https://github.com/pantsbuild/pex/releases/download/v1.6.6/pex' digest=Digest('61bb79384db0da8c844678440bd368bcbfac17bbdb865721ad3f9cb0ab29b629", "label": 1}, {"snippet_id": 49888, "code": "=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map", "label": 0}, {"snippet_id": 83111, "code": " from.lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger( __name__) __all__=[ 'LwrJobRunner", "label": 0}, {"snippet_id": 23405, "code": " shellutil.run(\"hostname{0}\".format(hostname), chk_err=False) def restart_ssh_service(self): return shellutil.run('service sshd restart', chk_err=False) def useradd(self, username, expiration=None): \"\"\" Create", "label": 1}, {"snippet_id": 58558, "code": ": new_comment, 'run': ','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct", "label": 0}, {"snippet_id": 68179, "code": " defect_targets=[] rc=self.fs_status_to_rc(max(statusdict.keys())) if rc > result: result=rc if view==\"fs\": self.status_view_fs(fs) elif view.startswith(\"target\"): self.status_view_targets(fs) elif view", "label": 1}, {"snippet_id": 61751, "code": ", 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires < 0) or np.any(wires >=self.wires) or wires", "label": 0}, {"snippet_id": 84847, "code": "(org='org.scala-lang', name=name, rev=scala_build_info[version].full_version) @classmethod def _create_runtime_jardep(cls, version): return cls._create_jardep('scala-library', version) @classmethod def", "label": 1}, {"snippet_id": 39435, "code": " ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params", "label": 0}, {"snippet_id": 14245, "code": " console output for logs!') SERVER_IDLE_SUICIDE_SECONDS=10800 class YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self", "label": 0}, {"snippet_id": 2236, "code": "(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(','", "label": 0}, {"snippet_id": 28417, "code": "{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self", "label": 0}, {"snippet_id": 28706, "code": " data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full", "label": 0}, {"snippet_id": 67727, "code": ".strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>", "label": 0}, {"snippet_id": 68405, "code": " t_recovering.append(target) elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0", "label": 0}, {"snippet_id": 25978, "code": ".type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] ", "label": 0}, {"snippet_id": 15104, "code": " _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData", "label": 1}, {"snippet_id": 76067, "code": " m) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() elif wzrpc.status.e_timeout: self.log.warn('Timeout{0", "label": 0}, {"snippet_id": 8689, "code": " text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio.utils", "label": 1}, {"snippet_id": 32786, "code": " logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException,", "label": 0}, {"snippet_id": 59978, "code": " XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[", "label": 0}, {"snippet_id": 87188, "code": ".split() zinc_args[compile_context.target]=args def create_empty_extra_products(self): if self.context.products.is_required_data('zinc_analysis'): self.context.products.safe_create_data('zinc_analysis'", "label": 0}, {"snippet_id": 16395, "code": " return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open", "label": 0}, {"snippet_id": 65418, "code": ".Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=", "label": 0}, {"snippet_id": 94566, "code": " }) session.kill_session() def kill_window(window): window.cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window", "label": 0}, {"snippet_id": 60061, "code": " \"\"\" backend=pq.backends.IBMBackend(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable", "label": 0}, {"snippet_id": 63304, "code": " remote_job_config=None compute_environment=None try: client=self.get_client_from_wrapper(job_wrapper) tool=job_wrapper.tool remote_job_config=client.setup(tool.id, tool.version) rewrite_parameters=LwrJobRunner", "label": 0}, {"snippet_id": 2821, "code": "\\n%s\" % cmd) send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug", "label": 0}, {"snippet_id": 19218, "code": " test_native_mapping_is_passthrough(): source={'foo': 'bar'} result=load_source(source) assert result==source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source(source)", "label": 1}, {"snippet_id": 5856, "code": ": os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory)", "label": 0}, {"snippet_id": 22169, "code": " templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template.render( data) return", "label": 0}, {"snippet_id": 19287, "code": ") tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.json') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file.name) assert result==native def test_yaml_file_object(): native={'foo", "label": 0}, {"snippet_id": 38476, "code": " by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules: raise UnknownRuleException(name) return self._rules[name] def list_rules(self", "label": 0}, {"snippet_id": 42746, "code": " output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError", "label": 0}, {"snippet_id": 82297, "code": "\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example", "label": 0}, {"snippet_id": 17613, "code": "'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self,", "label": 0}, {"snippet_id": 70612, "code": "(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR", "label": 0}, {"snippet_id": 39720, "code": " decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd", "label": 0}, {"snippet_id": 91990, "code": " return target.has_sources(extension=tuple(self._native_source_extensions)) @memoized_property def _native_target_matchers(self): return{ SubclassesOf(PythonDistribution): self.pydist_has_native_sources", "label": 0}, {"snippet_id": 551, "code": ") queryset=User.objects.all().first() if username==queryset.username: return JsonResponse({\"STATUS\":\"SUCCESS\", \"username\":queryset.username}, safe=False) elif action=='getDashboardCards': print(action)", "label": 0}, {"snippet_id": 16713, "code": "{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def", "label": 0}, {"snippet_id": 65114, "code": ".dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self,", "label": 0}, {"snippet_id": 55705, "code": " isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources", "label": 0}, {"snippet_id": 60668, "code": "') reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name=='X': ex, var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex", "label": 0}, {"snippet_id": 78331, "code": ": self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t", "label": 1}, {"snippet_id": 26449, "code": " module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property", "label": 0}, {"snippet_id": 19710, "code": "=Address.as_server(serverhost, ns.pop('port')) elif not clienthost: if args.nodebug: args.address=Address.as_client(clienthost, ns.pop('port')) else: args.address=Address.as_server(clienthost, ns.pop('port')", "label": 0}, {"snippet_id": 10299, "code": "[1][1]) / len(kw1[1][1]) component_comparison=cmp(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"", "label": 0}, {"snippet_id": 5269, "code": ": \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted", "label": 0}, {"snippet_id": 94581, "code": " def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session, window_name): window=session.find_where({ \"window_name", "label": 0}, {"snippet_id": 50944, "code": ": mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file", "label": 0}, {"snippet_id": 55222, "code": "\" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs", "label": 0}, {"snippet_id": 20601, "code": ".PORT) conn=DebugSessionConnection.create_server(addr, **kwargs) return cls(conn, owned=True, **kwargs) def __init__(self, conn, seq=1000, handlers=(), timeout=None, owned=False): super(DebugSession, self", "label": 0}, {"snippet_id": 89339, "code": " execute_java, execute_java_async from pants.subsystem.subsystem import Subsystem from pants.util.contextutil import temporary_dir from pants.util.memo import memoized_method, memoized_property from pants", "label": 0}, {"snippet_id": 43149, "code": ".allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item", "label": 0}, {"snippet_id": 95137, "code": " data_service.process_data_files(input_dir=input_directory, temp_dir=temp_directory, output_dir=vcf_directory) vcf_to_zarr_config=config.VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config", "label": 1}, {"snippet_id": 27640, "code": "\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self", "label": 0}, {"snippet_id": 57955, "code": "=request.GET.get('bug_id', '').split(',') data['runs']=map(int, request.GET.get('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns", "label": 0}, {"snippet_id": 23922, "code": "-1: mac=line.split()[1] logger.verbose(\"Interface info:({0},{1},{2})\", iface, inet, mac) return iface, inet, mac def device_for_ide_port(self, port_id): \"\"\" Return device name attached to ide port 'n'. ", "label": 0}, {"snippet_id": 66966, "code": ": return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string", "label": 0}, {"snippet_id": 51607, "code": " combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards): \"\"\" Limit wildcards", "label": 0}, {"snippet_id": 42845, "code": "(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may", "label": 0}, {"snippet_id": 1405, "code": "'nmcli', 'connection','delete','id',wifiname], stdout=subprocess.PIPE) print(ps) print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname", "label": 0}, {"snippet_id": 62034, "code": " If True, gates are cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default", "label": 0}, {"snippet_id": 4501, "code": "\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations", "label": 0}, {"snippet_id": 63655, "code": ": job_wrapper.finish( stdout, stderr, exit_code) except Exception: log.exception(\"Job wrapper finish method failed\") job_wrapper.fail(\"Unable to finish job\", exception=True) def fail_job( self, job_state", "label": 0}, {"snippet_id": 8008, "code": "=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0].isComposite(): component_avg0=sum(kw0[1][1]) / len(kw0[1][1]) component_avg1=sum(kw1[1][1", "label": 0}, {"snippet_id": 14276, "code": "._server_stderr=None self._server_popen=None self._filetypes_with_keywords_loaded=set() self._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def", "label": 1}, {"snippet_id": 824, "code": "'getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=", "label": 0}, {"snippet_id": 92427, "code": " expected_output) with hermetic_environment_as(**dict(AAA=UNICODE_CHAR)): self.assertIn('AAA', os.environ) self.assertEqual(os.environ['AAA'], expected_output) self.assertEqual(os.environ['XXX'], expected_output", "label": 1}, {"snippet_id": 16050, "code": " filepath } if include_buffer_data: request_data[ 'file_data']=vimsupport.GetUnsavedAndCurrentBufferData() if query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response", "label": 0}, {"snippet_id": 6444, "code": " output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False", "label": 0}, {"snippet_id": 55174, "code": ".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job", "label": 0}, {"snippet_id": 6, "code": " HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from rest_framework.response", "label": 0}, {"snippet_id": 58352, "code": "{'author__email__startswith': self.user.email})) class TestIndex(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self.client.get(reverse('core-views-index')) self", "label": 0}, {"snippet_id": 57824, "code": ").update(**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self.new_value).values_list('pk', flat=True) if not reviewers: err_msg='Reviewer %s is not found", "label": 0}, {"snippet_id": 35127, "code": ") def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type", "label": 0}, {"snippet_id": 69894, "code": "=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"", "label": 0}, {"snippet_id": 36139, "code": ".rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self", "label": 0}, {"snippet_id": 77297, "code": "(wclass, workers.WZWorkerThread): type_=0 if not hasattr(self, 'th_sock'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess):", "label": 0}, {"snippet_id": 67835, "code": "[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs)", "label": 0}, {"snippet_id": 36011, "code": " self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards", "label": 0}, {"snippet_id": 55583, "code": "._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath)", "label": 0}, {"snippet_id": 6978, "code": " fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords", "label": 0}, {"snippet_id": 54529, "code": ".workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath", "label": 0}, {"snippet_id": 25506, "code": "\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data", "label": 0}, {"snippet_id": 40274, "code": "(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__", "label": 0}, {"snippet_id": 56259, "code": ".testcases.models import TestCaseStatus, TestCaseTag from tcms.testcases.views import plan_from_request_or_none from tcms.testplans.models import TestPlan, TestCasePlan, TestPlanTag from tcms.testruns.models", "label": 0}, {"snippet_id": 55416, "code": ".resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())) else: logger.info(\"Nothing to be done.", "label": 0}, {"snippet_id": 5865, "code": "() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory) filename=\"bibclassify_%s.xml\" % recid abs_path=os.path.join(tmp_directory", "label": 0}, {"snippet_id": 32194, "code": " self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return", "label": 0}, {"snippet_id": 29597, "code": "\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"", "label": 0}, {"snippet_id": 36698, "code": "\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__", "label": 0}, {"snippet_id": 70571, "code": " pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[", "label": 0}, {"snippet_id": 21437, "code": ": Working directory found, but no subreddit directory. Creating %s, and files.\" % sr_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os", "label": 0}, {"snippet_id": 92795, "code": "=True) as zf: self.assertTrue(zf._allowZip64) def test_open_zipFalse(self): with temporary_dir() as tempdir: with open_zip(os.path.join(tempdir, 'test'), 'w', allowZip64=False) as zf: self.assertFalse(zf", "label": 0}, {"snippet_id": 75228, "code": " set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method)]=fun def del_req_handler(self, interface, method):", "label": 0}, {"snippet_id": 44818, "code": "]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile", "label": 0}, {"snippet_id": 68010, "code": " to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client):", "label": 0}, {"snippet_id": 32918, "code": "=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self", "label": 0}, {"snippet_id": 49106, "code": " self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set", "label": 0}, {"snippet_id": 82624, "code": "\ttmpLegitExt.append(b) \t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args", "label": 0}, {"snippet_id": 12523, "code": " There are no PEP8 issues in this Pull Request.:beers: \") comment_body=''.join(comment_body) comment_footer=[] if request.json[\"action\"]==\"opened\": comment_footer.append(config[\"message\"][\"opened\"][\"footer", "label": 0}, {"snippet_id": 16565, "code": " 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload',", "label": 0}, {"snippet_id": 24376, "code": ") else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable", "label": 1}, {"snippet_id": 80722, "code": " with open(\"techniques.json\",\"r\") as rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template", "label": 0}, {"snippet_id": 86931, "code": ", help='When set, zinc will use sub-target incremental compilation, which dramatically ' 'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with", "label": 0}, {"snippet_id": 59169, "code": "-------- .. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device", "label": 0}, {"snippet_id": 31929, "code": " output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\"", "label": 0}, {"snippet_id": 74104, "code": "\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str", "label": 0}, {"snippet_id": 77655, "code": ") if 'forums' in data: self.log.debug('Forum set was loaded') forums.update(data['forums']) if 'domains' in data: self.log.debug('Domain set was loaded') domains.update(data['domains']) if 'sets' in data", "label": 0}, {"snippet_id": 82635, "code": " a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys", "label": 0}, {"snippet_id": 63589, "code": "=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs", "label": 0}, {"snippet_id": 93982, "code": " comp_name, session_name, hostname): remote_cmd=(\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name, comp_name)) cmd=\"ssh %s 'bash -s' < %s\" %(hostname, remote_cmd) send_main_session_command(self.session", "label": 0}, {"snippet_id": 17388, "code": " _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash", "label": 0}, {"snippet_id": 30463, "code": "\".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise", "label": 0}, {"snippet_id": 83786, "code": " communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing job %d\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self", "label": 0}, {"snippet_id": 60606, "code": " measure the expectation.\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map:", "label": 0}, {"snippet_id": 87438, "code": " for c in absolute_classpath) zinc_args=[] zinc_args.extend([ '-log-level', self.get_options().level, '-analysis-cache', analysis_cache, '-classpath', ':'.join(relative_classpath), '-d', classes_dir, ]", "label": 0}, {"snippet_id": 37592, "code": " or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end", "label": 0}, {"snippet_id": 74312, "code": " overwrite: print( \"[Config] Could not generate configuration file: file exists at specified destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write", "label": 0}, {"snippet_id": 1487, "code": " print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({\"STATUS\":\"SUCCESS", "label": 0}, {"snippet_id": 60608, "code": "\"\"\" if self.eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{", "label": 0}, {"snippet_id": 45698, "code": "\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)", "label": 0}, {"snippet_id": 48134, "code": " def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item", "label": 0}, {"snippet_id": 7713, "code": " out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output", "label": 0}, {"snippet_id": 1063, "code": "'endpoint': wifi_name}], safe=False) elif action=='deleteWifi': print(action) wifi_name=request.POST.get(\"wifi\") delete_WifiConn(wifi_name) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker", "label": 0}, {"snippet_id": 17329, "code": "=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port", "label": 0}, {"snippet_id": 51558, "code": "\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values", "label": 0}, {"snippet_id": 6586, "code": "=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file.", "label": 1}, {"snippet_id": 47476, "code": " +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name", "label": 0}, {"snippet_id": 30089, "code": " for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is", "label": 0}, {"snippet_id": 9028, "code": " no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0] _ckw=cache[1] text_lines=normalizer.cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode", "label": 0}, {"snippet_id": 69245, "code": ".get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException", "label": 0}, {"snippet_id": 25536, "code": " self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain", "label": 0}, {"snippet_id": 42107, "code": ".rule), \"input\": self.input, \"output\": self.output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__", "label": 0}, {"snippet_id": 29037, "code": "\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth", "label": 0}, {"snippet_id": 22763, "code": " additionally changing the password of the built-in 'admin' account, both must be modified in this method. Note that the default method also checks for a \"system level\" of the user; based on the value of", "label": 0}, {"snippet_id": 47205, "code": " existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def", "label": 0}, {"snippet_id": 14146, "code": " utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils", "label": 0}, {"snippet_id": 15562, "code": "._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification( 'FileReadyToParse', extra_data) self._latest_file_parse_request.Start() def OnBufferUnload( self, deleted_buffer_file): if", "label": 0}, {"snippet_id": 90943, "code": ") options_scope='jvm-distributions' @classmethod def register_options(cls, register): super(DistributionLocator, cls).register_options(register) human_readable_os_aliases=', '.join('{}:[{}]'.format(str", "label": 0}, {"snippet_id": 45862, "code": " wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint\") if match.group(\"constraint\") else \".+\")) last=match.end() f.append(re.escape(filepattern[last:])) f.append(\"$\")", "label": 0}, {"snippet_id": 33240, "code": ".is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=", "label": 0}, {"snippet_id": 68042, "code": ": print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): \"\"\" shine status[-f <fsname>][-t <target>][-i <index(es)>][-n <nodes>][-qv] \"\"\" def", "label": 0}, {"snippet_id": 72336, "code": ", irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally: log.debug('", "label": 1}, {"snippet_id": 7257, "code": " single keywords :var ckw_matches: list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires", "label": 0}, {"snippet_id": 60103, "code": " else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng.backend.get_probabilities(self.reg) expectation_value=[((2*sum(p", "label": 0}, {"snippet_id": 51641, "code": " wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the", "label": 0}, {"snippet_id": 22724, "code": ", log_cmd=True, chk_err=True) if retcode !=0: raise OSUtilError( \"Failed to create user account:{0}, retcode:{1}, output:{2}\".format(username, retcode, out) ) self._save_sys_config() return retcode def", "label": 0}, {"snippet_id": 55754, "code": " if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo", "label": 0}, {"snippet_id": 31633, "code": "(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version", "label": 0}, {"snippet_id": 57423, "code": "(object): \"\"\"Abstract class defining interfaces to update a model properties\"\"\" class TestCaseUpdateActions(ModelUpdateActions): \"\"\"Actions to update each possible proprety of TestCases Define your own", "label": 0}, {"snippet_id": 25645, "code": " Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=", "label": 0}, {"snippet_id": 89081, "code": ")) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter(predicate, target_set)) def _collect_targets(self, root_targets, **kwargs): return Target.closure_for_targets( target_roots", "label": 0}, {"snippet_id": 75166, "code": "'Router', b'auth-bind-route'), (b'Router', b'auth-unbind-route'), (b'Router', b'auth-set-route-type')] self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)", "label": 0}, {"snippet_id": 57442, "code": " TestCases Define your own method named _update_[property name] to hold specific update logic. \"\"\" ctype='testcases.testcase' def __init__(self, request): self.request=request self.target_field=request.POST.get", "label": 0}, {"snippet_id": 89545, "code": " a JRE \"\"\" if home_path and not os.path.isdir(home_path): raise ValueError('The specified java home path is invalid:{}'.format(home_path)) if bin_path and not os.path.isdir(bin_path): raise ValueError(", "label": 0}, {"snippet_id": 66533, "code": ".fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None,", "label": 0}, {"snippet_id": 75805, "code": ".connect(self.wz_addr) def wz_wait_reply(self, fun, interface, method, data, reqid=None, timeout=None): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=timeout if timeout else self", "label": 1}, {"snippet_id": 27328, "code": " up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config:", "label": 1}, {"snippet_id": 16187, "code": ".event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError", "label": 0}, {"snippet_id": 50528, "code": " decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return", "label": 0}, {"snippet_id": 56077, "code": ": return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path", "label": 0}, {"snippet_id": 13198, "code": " update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format(data[\"fork_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN", "label": 0}, {"snippet_id": 83659, "code": ".params job_id=job_state.job_id return self.get_client( job_destination_params, job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id)", "label": 0}, {"snippet_id": 93261, "code": ".config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ ", "label": 0}, {"snippet_id": 6973, "code": " single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K", "label": 0}, {"snippet_id": 66366, "code": ".Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs", "label": 0}, {"snippet_id": 6435, "code": ".get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\"", "label": 0}, {"snippet_id": 34616, "code": ".\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file", "label": 1}, {"snippet_id": 52989, "code": ", other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list", "label": 0}, {"snippet_id": 8924, "code": "=False, only_core_tags=False, extract_acronyms=False, **kwargs): \"\"\"Extract keywords from the list of strings :param text_lines: list of strings(will be normalized before being joined into one string) ", "label": 1}, {"snippet_id": 50121, "code": ".included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert", "label": 0}, {"snippet_id": 93877, "code": " send_main_session_command(self.session, cmd) def check_component(self, comp): return check_component(comp, self.session, self.logger) def get_dep_list(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[]", "label": 1}, {"snippet_id": 36903, "code": " OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException", "label": 0}, {"snippet_id": 79720, "code": ": --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials", "label": 0}, {"snippet_id": 53813, "code": "(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name", "label": 0}, {"snippet_id": 67807, "code": "=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support", "label": 0}, {"snippet_id": 1656, "code": " password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt.crypt(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect", "label": 0}, {"snippet_id": 75178, "code": " self.p.wz_bind_methods=[ (b'Evaluator', b'evaluate', self.handle_evaluate, wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init() self.bind_kt_ticker.tick() while", "label": 0}, {"snippet_id": 89947, "code": "._validated_executable('javac') self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please check you have a JDK ' 'installed. Original error:{}'.format(e)) raise def", "label": 0}, {"snippet_id": 63253, "code": ".set_job_destination( job_destination, job_id) job_wrapper.change_state( model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job ", "label": 0}, {"snippet_id": 56068, "code": ".workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\"", "label": 0}, {"snippet_id": 39934, "code": " from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError, WildcardError from snakemake.logging import logger", "label": 1}, {"snippet_id": 42891, "code": " \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow", "label": 0}, {"snippet_id": 65895, "code": " len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status", "label": 0}, {"snippet_id": 61933, "code": ".. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError", "label": 0}, {"snippet_id": 51079, "code": " def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match", "label": 0}, {"snippet_id": 14408, "code": "._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file: error_output=''.join", "label": 0}, {"snippet_id": 20974, "code": " handled=handle_message(msg) try: msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler) break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None", "label": 0}, {"snippet_id": 78330, "code": " e: self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,", "label": 1}, {"snippet_id": 81476, "code": "],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f) \t\t\t\tfor future in concurrent.futures.as_completed(futures): \t\t\t\t\ta=future.result() \t\t\t", "label": 0}, {"snippet_id": 1839, "code": "': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor", "label": 0}, {"snippet_id": 29714, "code": ") def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type", "label": 0}, {"snippet_id": 80645, "code": "(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not", "label": 0}, {"snippet_id": 20872, "code": " handlername) return AwaitableResponse(req, lambda: result[\"msg\"], evt) @contextlib.contextmanager def wait_for_response(self, req, **kwargs): if self.closed: raise RuntimeError('session closed') try: command,", "label": 0}, {"snippet_id": 37312, "code": "**kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item", "label": 0}, {"snippet_id": 18335, "code": "{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr=filename_format.format( port=server_port, std='stderr') args.append('--stdout={0}'.format", "label": 0}, {"snippet_id": 39959, "code": ".supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os", "label": 0}, {"snippet_id": 88706, "code": "=self.run_tracker.get_background_root_workunit() if parent_workunit_name: workunit_parent_ctx=self.run_tracker.new_workunit_under_parent( name=parent_workunit_name, labels=[WorkUnitLabel.MULTITOOL], parent", "label": 0}, {"snippet_id": 83939, "code": " \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job", "label": 0}, {"snippet_id": 19563, "code": "=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug", "label": 0}, {"snippet_id": 15106, "code": "'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data", "label": 1}, {"snippet_id": 93781, "code": " if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name", "label": 0}, {"snippet_id": 77262, "code": ".pc, self.get_userqueue): self.log.info('Created spawn %s', spawn.name) self.spawnqueue.put(spawn, False) except Exception as e: self.log.exception('Exception \"%s\" raised on create_spawn', e) def spawn_workers", "label": 0}, {"snippet_id": 41662, "code": ".rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format", "label": 0}, {"snippet_id": 68545, "code": ".get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(", "label": 0}, {"snippet_id": 58644, "code": "'password') remove_perm_from_user(self.tester, self.permission) post_data={ 'content_type': 'testplans.testplan', 'object_pk': self.plan.pk, 'field': 'is_active', 'value': 'False', 'value_type': 'bool'", "label": 0}, {"snippet_id": 61263, "code": ".\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args(array): square hermitian matrix. Returns: array: square hermitian matrix. \"\"\" A=np.asarray(args[0", "label": 0}, {"snippet_id": 24565, "code": "'Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2':", "label": 0}, {"snippet_id": 44455, "code": ".persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\"", "label": 0}, {"snippet_id": 77572, "code": "} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds=[] for i in range(uqsize): uds.append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps(users, pickle.HIGHEST_PROTOCOL", "label": 0}, {"snippet_id": 5697, "code": " for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords", "label": 0}, {"snippet_id": 11284, "code": " import datetime import logging import os import sys from docopt import docopt from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, \\ ConfigurationContainsUndefinedVariables", "label": 0}, {"snippet_id": 27739, "code": "=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value", "label": 0}, {"snippet_id": 49171, "code": "._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values", "label": 0}, {"snippet_id": 30561, "code": ".utils import format, listfiles from snakemake.exceptions import RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def", "label": 0}, {"snippet_id": 77280, "code": " create_spawn', e) def spawn_workers(self, wclass, count, args=(), kvargs={}): wname=str(wclass.__name__) self.log.info('Starting %s(s)', wname) if issubclass(wclass, workers.WZWorkerThread): type_=0 if not", "label": 0}, {"snippet_id": 51532, "code": " given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards", "label": 0}, {"snippet_id": 12213, "code": "}/{}\" url=url.format(repository, after_commit_hash, file) r=requests.get(url, headers=headers, auth=auth) with open(\"file_to_check.py\", 'w+', encoding=r.encoding) as file_to_check: file_to_check.write(r", "label": 0}, {"snippet_id": 25322, "code": " def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get", "label": 0}, {"snippet_id": 48290, "code": " if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input", "label": 0}, {"snippet_id": 42849, "code": " SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output", "label": 0}, {"snippet_id": 49630, "code": ") if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have", "label": 0}, {"snippet_id": 46901, "code": ") self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output", "label": 0}, {"snippet_id": 28663, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'", "label": 0}, {"snippet_id": 58034, "code": " more caserun at a time. \"\"\" data, error=clean_bug_form(request) if error: return say_no(error) runs=TestCaseRun.objects.filter(pk__in=data['runs']) bug_system_id=data['bug_system_id'] bug_ids=data['bugs']", "label": 0}, {"snippet_id": 94274, "code": " running\" % self.window_name) if self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s", "label": 0}, {"snippet_id": 49011, "code": " import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake.logging import logger, format_resources, format_resource_names from", "label": 0}, {"snippet_id": 53419, "code": " branch.protected_output.update(exp) if old in branch.touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]", "label": 0}, {"snippet_id": 10142, "code": " spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i", "label": 0}, {"snippet_id": 14170, "code": " YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from", "label": 0}, {"snippet_id": 71966, "code": "._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in", "label": 1}, {"snippet_id": 47026, "code": "\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 31750, "code": " in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output.update(exp) if old", "label": 0}, {"snippet_id": 85122, "code": ", self.version), scope=self.options_scope) def compiler_classpath(self, products): return self._tool_classpath('scalac', products) def style_classpath(self, products): return self._tool_classpath('scalastyle", "label": 1}, {"snippet_id": 87009, "code": ") ScalaPlatform.prepare_tools(round_manager) @property def incremental(self): \"\"\"Zinc implements incremental compilation. Setting this property causes the task infrastructure to clone the previous results_dir", "label": 0}, {"snippet_id": 79346, "code": "): \t\t\t\t\ta=future.result() \t\t\t\t\tn +=1 \t\t\texcept KeyboardInterrupt: \t\t\t\tself.shouldLog=False \t\t\t\texecutor.shutdown(wait=False) \t\t\t\tself.stopThreads=True \t\t\t\texecutor._threads.clear() \t\t\t\tconcurrent.futures", "label": 0}, {"snippet_id": 62710, "code": ") if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int): Job ID to retrieve instead of re-running the circuit(e.g., if previous run timed out). \"\"\" short_name='projectq.ibmbackend'", "label": 0}, {"snippet_id": 8668, "code": " this module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify import ontology_reader as reader import text_extractor", "label": 0}, {"snippet_id": 15165, "code": ".client.ycmd_keepalive import YcmdKeepalive from ycm.client.base_request import BaseRequest, BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request", "label": 0}, {"snippet_id": 64808, "code": " self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalMountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None", "label": 0}, {"snippet_id": 43401, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output", "label": 0}, {"snippet_id": 71959, "code": ".last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"", "label": 0}, {"snippet_id": 55717, "code": "=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance", "label": 0}, {"snippet_id": 65993, "code": " FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", '", "label": 0}, {"snippet_id": 32190, "code": " start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.", "label": 0}, {"snippet_id": 27049, "code": " the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self)", "label": 0}, {"snippet_id": 7686, "code": " \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author", "label": 0}, {"snippet_id": 88601, "code": ": \"\"\"Returns the current workspace's scm, if any. :API: public \"\"\" return self._scm @property def workspace(self): \"\"\"Returns the current workspace, if any.\"\"\" return self._workspace @property def invalidation_report", "label": 0}, {"snippet_id": 85447, "code": " recursive=True), Shader.exclude_package('xsbt', recursive=True), Shader.exclude_package('xsbti', recursive=True), Shader.exclude_package('org.apache.logging.log4j', recursive=True), ] cls.register_jvm_tool", "label": 0}, {"snippet_id": 94853, "code": ") if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window, control_center", "label": 0}, {"snippet_id": 59629, "code": ": for qubit in self.reg: self.eng.deallocate_qubit(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability", "label": 0}, {"snippet_id": 39578, "code": ".globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo", "label": 0}, {"snippet_id": 70254, "code": "), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(", "label": 0}, {"snippet_id": 62314, "code": " gate | tuple([self.reg[i] for i in wires]) def expectation(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def shutdown(self): \"\"\"Shutdown. \"\"\"", "label": 0}, {"snippet_id": 40926, "code": " wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable, however the hash does not consider the item names. \"\"\" def __init__(self, toclone", "label": 0}, {"snippet_id": 49096, "code": " config_args=None, debug=False): \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath", "label": 0}, {"snippet_id": 82741, "code": "\tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t\tproxies={\"http\":proxy,\"https\":proxy} \ts.proxies.update(proxies) if args.manualFormDetection: \tif args.formAction==\"\": \t\tlogger.warning(\"Using", "label": 0}, {"snippet_id": 91297, "code": " import ResolveRequirements from pants.backend.python.tasks.select_interpreter import SelectInterpreter from pants.backend.python.tasks.setup_py import SetupPy from pants.backend.python.tasks.unpack_wheels", "label": 0}, {"snippet_id": 81626, "code": "\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl", "label": 0}, {"snippet_id": 81748, "code": ".basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests", "label": 0}, {"snippet_id": 41892, "code": " check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This", "label": 0}, {"snippet_id": 57977, "code": " specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id']=int(request.GET.get('bug_system_id', 1)) if request.GET.get", "label": 0}, {"snippet_id": 53973, "code": " in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable", "label": 0}, {"snippet_id": 8985, "code": " will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. :param rebuild_cache: boolean :param only_core_tags: boolean :return: if output_mode=raw, it will return (single_keywords", "label": 0}, {"snippet_id": 58502, "code": "'response': 'No runs selected.'}) def test_refuse_if_passed_case_run_pks_not_exist(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url", "label": 0}, {"snippet_id": 5859, "code": " file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s/bibclassify\" % bconfig.CFG_TMPDIR if not os.path.isdir(tmp_directory): os.mkdir(tmp_directory", "label": 0}, {"snippet_id": 45153, "code": " decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate", "label": 0}, {"snippet_id": 32525, "code": " or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str(ex)), lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True", "label": 0}, {"snippet_id": 73374, "code": " conversion_config): \"\"\" Converts all VCF files in input directory to Zarr format, placed in output directory, based on conversion configuration parameters :param input_vcf_dir: The input directory where", "label": 0}, {"snippet_id": 88930, "code": "\"Creates a new target, adds it to the context and returns it. This method ensures the target resolves files against the given target_base, creating the directory if needed and registering a source root", "label": 0}, {"snippet_id": 23254, "code": " struct_size): iface=self._format_single_interface_name(sock, i) if b'lo' in iface: continue else: break return iface.decode('latin-1'), socket.inet_ntoa(sock[i+20:i+24]) def _format_single_interface_name(self", "label": 0}, {"snippet_id": 77043, "code": ".conlimit=c.conlimit w.comment_successtimeout=0.2 if c.upload_avatar: w.hooks['post_login'].append(upload_avatar) yield w class WipeManager: def __init__(self, config, *args, **kvargs): super().__init__(*args,", "label": 0}, {"snippet_id": 38933, "code": " to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input", "label": 0}, {"snippet_id": 67662, "code": " LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)", "label": 0}, {"snippet_id": 52075, "code": " except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files", "label": 0}, {"snippet_id": 85674, "code": "=get_buildroot() return scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs( tuple( fast_relpath(a, buildroot) for a in(self.zinc, self.compiler_bridge, self.compiler_interface) ) ), buildroot, ), ))[0]", "label": 1}, {"snippet_id": 61710, "code": "*wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U def expand_two(self, U, wires): \"\"\"Expand a two-qubit operator into a full system operator. Args: U(array", "label": 0}, {"snippet_id": 83519, "code": "=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params", "label": 1}, {"snippet_id": 60433, "code": "=self.state.quad_expectation(reg, *self.observe.params) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device\"\"\" if self.eng is not None:", "label": 0}, {"snippet_id": 4470, "code": "(taxonomy_name) if not cache: reader.set_cache(taxonomy_name, reader.get_regular_expressions(taxonomy_name, rebuild=rebuild_cache, no_cache=no_cache)) cache=reader.get_cache(taxonomy_name) _skw=cache[0", "label": 0}, {"snippet_id": 68802, "code": " i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout.LEFT, \"node(s)\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"size\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 36377, "code": "\"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property", "label": 0}, {"snippet_id": 73561, "code": " conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)) chunk_width=allel.vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config", "label": 0}, {"snippet_id": 36833, "code": " files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format( \", \".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run", "label": 0}, {"snippet_id": 43803, "code": " def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self,", "label": 0}, {"snippet_id": 18178, "code": " OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager", "label": 0}, {"snippet_id": 79030, "code": " nor true regex defined, code execution detection will not be possible.\") \t\telif not self.uploadsFolder and self.trueRegex: \t\t\tprint(\"No uploads path provided, code detection can still be done using true", "label": 0}, {"snippet_id": 58863, "code": " update_cases_default_tester\"\"\" @classmethod def setUpTestData(cls): super(TestUpdateCasePriority, cls).setUpTestData() cls.permission='testcases.change_testcase' cls.case_update_url=reverse('ajax-update_cases_default_tester", "label": 0}, {"snippet_id": 74077, "code": "\"blosc_compression_level\"] if isint(blosc_compression_level_str): compression_level_int=int(blosc_compression_level_str) if(compression_level_int >=0) and(compression_level_int <=9): self.blosc_compression_level", "label": 0}, {"snippet_id": 6371, "code": " MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used.", "label": 0}, {"snippet_id": 70205, "code": " __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(), target.get_id(), target.dev) def", "label": 0}, {"snippet_id": 5676, "code": "'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone and other unwanted elements\"\"\" filtered_kw_matches", "label": 0}, {"snippet_id": 20738, "code": " self.closed: raise RuntimeError('session closed') self._add_handler(handler, **kwargs) @contextlib.contextmanager def wait_for_event(self, event, **kwargs): if self.closed: raise RuntimeError('session", "label": 0}, {"snippet_id": 19011, "code": "( \"Unable to parse `{0}`. Tried yaml and json.\".format(source), ) def parse(raw_schema): context={ 'deferred_references': set(), } swagger_definitions=definitions_validator(raw_schema, context=context)", "label": 0}, {"snippet_id": 24826, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self", "label": 0}, {"snippet_id": 62859, "code": ") if '1' in probabilities: expectation_value=2*probabilities['1']-1 else: expectation_value=-(2*probabilities['0']-1) variance=1 -expectation_value**2 elif observable=='AllPauliZ': probabilities=self.eng", "label": 0}, {"snippet_id": 8185, "code": " field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error(\"Please use bibclassify_cli from now on.\")", "label": 0}, {"snippet_id": 83944, "code": " when attempting to signal %d to PID %d: %s\" %( job.id, errno.errorcode[e.errno], sig, pid, e.strerror)) return sleep( 2) if not self.check_pid( pid): log.debug( \"stop_job(): %s: PID %d successfully killed", "label": 0}, {"snippet_id": 8289, "code": ") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version", "label": 1}, {"snippet_id": 29489, "code": " latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing() if missing: logger.info(", "label": 0}, {"snippet_id": 83628, "code": ".job_destination.params.copy() for key, value in params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env=getattr( job_wrapper.job_destination, \"env\"", "label": 0}, {"snippet_id": 12493, "code": "(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file:\\n\\n\") comment_body.append(\"> \" +\"\".join(data[\"extra_results\"][file])) comment_body.append(", "label": 0}, {"snippet_id": 79073, "code": "=input(\"Preffix capturing group of the true regex with: \") \t\t\t\tsuffixPattern=input(\"Suffix capturing group of the true regex with: \") \t\t\t\tself.codeExecUrlPattern=preffixPattern+\"$captGroup$\"+suffixPattern \t", "label": 0}, {"snippet_id": 6092, "code": "\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd", "label": 0}, {"snippet_id": 79169, "code": ".text+\"\\033[m\") \t\t\t \t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None", "label": 1}, {"snippet_id": 80140, "code": " Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\"", "label": 0}, {"snippet_id": 61144, "code": "-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2}` \"\"\" return expm(-1j * theta/2 * Z) def fr3(a, b, c): r\"\"", "label": 0}, {"snippet_id": 42695, "code": ") for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark:", "label": 0}, {"snippet_id": 50594, "code": " _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None self.output=None self.params=None self.message=None self.benchmark=None", "label": 0}, {"snippet_id": 83280, "code": ".job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep( 2", "label": 0}, {"snippet_id": 32812, "code": ".dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards,", "label": 1}, {"snippet_id": 95241, "code": " import FTP, FTP_TLS, error_perm import time import csv import logging import os.path import pathlib import allel import sys import functools import numpy as np import zarr import numcodecs from numcodecs", "label": 1}, {"snippet_id": 13706, "code": " k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04']=lambda s:(dp.parse(s) -dp.parse('2004-01-01 00:00 +01'", "label": 0}, {"snippet_id": 83539, "code": " job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) if not command_line: job_wrapper.finish( '', '') return command_line, client, remote_job_config", "label": 0}, {"snippet_id": 78295, "code": "(self.comment_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.schedule(self.add_comment,(t, msg)) except exc.UnknownAnswer as e: self.log.warn('%s: %s',", "label": 0}, {"snippet_id": 32885, "code": " self._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack", "label": 0}, {"snippet_id": 42015, "code": " Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards", "label": 0}, {"snippet_id": 56190, "code": ".core.exceptions import ObjectDoesNotExist from django.apps import apps from django.forms import ValidationError from django.http import Http404 from django.http import HttpResponse from django.shortcuts", "label": 0}, {"snippet_id": 86574, "code": " _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class BaseZincCompile(JvmCompile): \"\"\"An abstract base class for zinc compilation tasks.\"\"", "label": 1}, {"snippet_id": 95575, "code": " if not os.path.isfile(file_path_local): with open(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter", "label": 0}, {"snippet_id": 51514, "code": "\"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch\") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments", "label": 0}, {"snippet_id": 23464, "code": " OSUtilError((\"Failed to create user account:{0}, \" \"retcode:{1}, \" \"output:{2}\").format(username, retcode, out)) def del_account(self, username): if self.is_sys_user(username): logger.error(\"{0} is a system", "label": 0}, {"snippet_id": 67050, "code": "\n from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support", "label": 0}, {"snippet_id": 5185, "code": "=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results", "label": 0}, {"snippet_id": 93609, "code": " done!\") def stop_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave --kill'\" %(host, TMP_SLAVE_DIR, comp_name)) self.logger.debug(\"Run cmd:\\n%s\" % cmd) send_main_session_command", "label": 0}, {"snippet_id": 42060, "code": " ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\"", "label": 0}, {"snippet_id": 92, "code": ": \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for", "label": 0}, {"snippet_id": 75449, "code": "(self, iden): return self.iden_reqid_map.get_values(iden) def make_reqid(self): while True: reqid=random.randint(1,(2**64)-1) if not reqid in self.response_handlers: return reqid def make_auth_req_data", "label": 1}, {"snippet_id": 16384, "code": "'http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed() def _IsServerAlive( self): returncode=self._server_popen.poll() return returncode is None def _NotifyUserIfServerCrashed( self):", "label": 0}, {"snippet_id": 27486, "code": " state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement", "label": 0}, {"snippet_id": 21759, "code": ".csv') X=dataset.iloc[:, 3:13].values y=dataset.iloc[:, 13].values from sklearn.preprocessing import LabelEncoder, OneHotEncoder labelencoder_X_1=LabelEncoder() X[:, 1]=labelencoder_X_1.fit_transform(X", "label": 1}, {"snippet_id": 78128, "code": "): msg=[b'WipeManager'] msg.extend(wzrpc.make_sig_msg(b'WipeManager', b'passthrough', frames)) sig_sock.send_multipart(msg) def drop_users(): send_passthrough([b'WipeSkel', b'WipeSkel', b'drop-user']) def", "label": 0}, {"snippet_id": 67953, "code": " Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA,", "label": 0}, {"snippet_id": 24039, "code": "=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=\"camcontrol devlist | grep{0} | awk -F \\( '{{print $2}}'|sed -e 's/.*(//'| sed -e 's/).*//'\".format(output)", "label": 0}, {"snippet_id": 28055, "code": " station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\"", "label": 0}, {"snippet_id": 29343, "code": " raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def", "label": 0}, {"snippet_id": 37970, "code": "(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError", "label": 0}, {"snippet_id": 46172, "code": ", str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for", "label": 0}, {"snippet_id": 11602, "code": " if(x is not None) else \"\" for x in value]) else: return str(value) class OutputWriter(object): def __init__(self, output_file): self.output_file=output_file def write_lines(self, lines): with open(self", "label": 0}, {"snippet_id": 12357, "code": " Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[\"synchronize\", \"reopened\"]: if config[\"message\"][\"updated\"][\"header\"]==\"\"", "label": 0}, {"snippet_id": 85682, "code": " self.compiler_bridge, self.compiler_interface) ) ), buildroot, ), ))[0] @memoized_property def rebase_map_args(self): \"\"\"We rebase known stable paths in zinc analysis to make it portable across machines.\"", "label": 1}, {"snippet_id": 82596, "code": ".hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions=loadExtensions(\"file\",mimeFile) tmpLegitExt=[] if args.legitExtensions: \targs.legitExtensions=[x.lower() for x in args", "label": 0}, {"snippet_id": 20113, "code": " except ClosedError: pass class DebugClient(_LifecycleClient): \"\"\"A high-level abstraction of a debug client(i.e. editor).\"\"\" class EasyDebugClient(DebugClient): def start_detached(self, argv): \"\"\"Start an", "label": 0}, {"snippet_id": 63564, "code": ", '') stderr=run_results.get('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model", "label": 0}, {"snippet_id": 36356, "code": " missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output", "label": 0}, {"snippet_id": 45393, "code": " IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\" dynamic_fill=\"__snakemake_dynamic__\" def __new__(cls, file): obj", "label": 0}, {"snippet_id": 75547, "code": " make_auth_set_route_type_data(self, interface, method, type_, key, reqid=None): if not reqid: reqid=self.make_reqid() args=[interface, method, struct.pack('!B', type_), make_auth_hash(interface, method, reqid, key", "label": 0}, {"snippet_id": 86815, "code": "', '-Dzinc.analysis.cache.limit=1000', '-Djava.awt.headless=true', '-Xmx2g') @classmethod def get_args_default(cls, bootstrap_option_values): return('-C-encoding', '-CUTF-8', '-S-encoding', '-SUTF-8', ", "label": 0}, {"snippet_id": 90375, "code": "=java_dist_dirs @property def jvm_locations(self): for java_dist_dir in self._java_dist_dirs: if os.path.isdir(java_dist_dir): for path in os.listdir(java_dist_dir): home=os.path.join(java_dist_dir, path", "label": 0}, {"snippet_id": 48205, "code": "\"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item -", "label": 0}, {"snippet_id": 92299, "code": ") with temporary_file(binary_mode=False) as new_output: subprocess.Popen([sys.executable, '-c', 'import os; print(\"HORK\" in os.environ)'], stdout=new_output).wait() new_output.seek(0) self.assertEqual(", "label": 0}, {"snippet_id": 981, "code": ": print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'],", "label": 0}, {"snippet_id": 35139, "code": " value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for v", "label": 0}, {"snippet_id": 66309, "code": " layout.set_column(\"index\", i, AsciiTableLayout.RIGHT, \"index\", AsciiTableLayout.CENTER) if tag_col_enabled: i +=1 layout.set_column(\"tag\", i, AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +", "label": 0}, {"snippet_id": 59759, "code": "(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"", "label": 0}, {"snippet_id": 58068, "code": "'bz_external_track'] action=data['action'] try: if action==\"add\": for run in runs: for bug_id in bug_ids: run.add_bug(bug_id=bug_id, bug_system_id=bug_system_id, bz_external_track=bz_external_track) else: bugs", "label": 0}, {"snippet_id": 68529, "code": ": status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict([[\"type\", \"CLI\"],[\"count\", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers", "label": 0}, {"snippet_id": 85982, "code": " '-Xlint:-serial', '-Xlint:-path') @classmethod def get_no_warning_args_default(cls): return('-nowarn', '-Xlint:none',) @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-Werror',)", "label": 0}, {"snippet_id": 89767, "code": "'javac')): home=jdk_dir self._home=home return self._home @property def real_home(self): \"\"\"Real path to the distribution java.home(resolving links).\"\"\" return os.path.realpath(self.home) @property def java", "label": 1}, {"snippet_id": 46576, "code": ": self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return", "label": 0}, {"snippet_id": 11119, "code": " self.mtime) def is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self.mtime, other.mtime) > 0 else: return False def serialize(self): lines=[] time_string=strftime", "label": 0}, {"snippet_id": 94449, "code": " logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState.STOPPED", "label": 0}, {"snippet_id": 83968, "code": "( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log", "label": 0}, {"snippet_id": 30695, "code": " self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self", "label": 0}, {"snippet_id": 57097, "code": "\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not", "label": 0}, {"snippet_id": 13136, "code": "\"BOT_PASSWORD\"]) r=requests.get(url, headers=headers, auth=auth) ATTEMPT=0 while(r.status_code !=200): time.sleep(5) r=requests.get(url, headers=headers, auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error", "label": 0}, {"snippet_id": 60979, "code": " NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset the backend state. After the reset the backend should be as if it was just constructed. Most importantly the quantum state is reset to its initial value.", "label": 0}, {"snippet_id": 29749, "code": " in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after", "label": 1}, {"snippet_id": 84607, "code": " fingerprint=True, default=True, help='Operate on the transitive dependencies of the specified targets. ' 'Unset to operate only on the specified targets.') register('--ignored', type=bool, fingerprint", "label": 0}, {"snippet_id": 35607, "code": "): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone", "label": 0}, {"snippet_id": 61518, "code": "*2 ev=np.random.normal(ev, np.sqrt(var / self.shots)) else: a, P=spectral_decomposition_qubit(A) p0=self.ev(P[0], self._observe.wires) n0=np.random.binomial(self.shots, p0) ev=(n0*a[0] +(self.shots-n0)", "label": 0}, {"snippet_id": 53552, "code": "*kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in", "label": 0}, {"snippet_id": 90026, "code": " '-cp', classpath, 'SystemProperties'] process=subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout, stderr=process.communicate() if process.returncode !=0: raise self.Error('Failed", "label": 0}, {"snippet_id": 78568, "code": "(self.wait_loop) def wait_loop(self): if len(self.targets) > 0: self.schedule(self.comment_loop) return if len(self.forums)==0: with cstate(self, WipeState.waiting_for_targets): while len(self.forums)=", "label": 0}, {"snippet_id": 31620, "code": "=set(other.dynamic_output) self.dynamic_input=set(other.dynamic_input) self.temp_output=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output", "label": 0}, {"snippet_id": 71234, "code": "=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target", "label": 0}, {"snippet_id": 24192, "code": ", 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24'", "label": 0}, {"snippet_id": 91871, "code": ".targets.python_distribution import PythonDistribution from pants.base.exceptions import IncompatiblePlatformsError from pants.binaries.executable_pex_tool import ExecutablePexTool from pants.subsystem", "label": 0}, {"snippet_id": 11356, "code": " not os.path.isdir(self.target_dir): raise MonitoringConfigGeneratorException(\"%s is not a directory\" % self.target_dir) LOG.debug(\"Using %s as target dir\" % self.target_dir) LOG.debug(\"Using URL: %s\" ", "label": 0}, {"snippet_id": 26707, "code": "._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500", "label": 0}, {"snippet_id": 78999, "code": ".action=formDestination[\"action\"] \t\texcept: \t\t\tself.action=\"\" \t\tself.uploadUrl=urljoin(self.formUrl,self.action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self", "label": 0}, {"snippet_id": 64664, "code": " RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine", "label": 0}, {"snippet_id": 63942, "code": ".working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description", "label": 1}, {"snippet_id": 6460, "code": " extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\": print(\"Input file: %s\" % source) output=get_keywords_from_text", "label": 0}, {"snippet_id": 36774, "code": " class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self", "label": 0}, {"snippet_id": 12557, "code": "=''.join(comment_footer) return comment_header, comment_body, comment_footer, ERROR def comment_permission_check(data, comment): \"\"\"Check for quite and resume status or duplicate comments\"\"\" PERMITTED_TO_COMMENT", "label": 0}, {"snippet_id": 75834, "code": " data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart(msg) t.tick() while self.running.is_set(): p(timeout*1000) if rs.finished: if rs.retry: msg=self.wz.make_req_msg(interface, method, data, rs", "label": 0}, {"snippet_id": 41539, "code": ".ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True", "label": 0}, {"snippet_id": 40017, "code": " return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self", "label": 1}, {"snippet_id": 47306, "code": "): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This includes creation", "label": 0}, {"snippet_id": 17245, "code": " self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request", "label": 0}, {"snippet_id": 52886, "code": " ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex), rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\"", "label": 0}, {"snippet_id": 14956, "code": " BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout)", "label": 1}, {"snippet_id": 76291, "code": " unbind_methods(self): for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum,", "label": 0}, {"snippet_id": 1007, "code": "'wifi':configuredwifi,'allwifiaps':wifi_aps, 'reqtype': 'adduser', 'endpoint': username}], safe=False) elif action=='addWifi': print(action) wifi_pass=escape(request.POST.get(\"wifi_password\")) wifi_name", "label": 0}, {"snippet_id": 19425, "code": "-host HOST | --server-host HOST] --port PORT -m MODULE[arg...] {0}[-h][-V][--nodebug][--host HOST | --server-host HOST] --port PORT FILENAME[arg...] \"\"\" def parse_args(argv=None): \"\"\"Return the parsed args", "label": 0}, {"snippet_id": 23206, "code": "=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)) param=struct.pack('iL', expected*struct_size, buff.buffer_info()[0]) ret=fcntl", "label": 0}, {"snippet_id": 82638, "code": " associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys(): \t\ts.cookies[key]=args.cookies", "label": 0}, {"snippet_id": 80143, "code": " upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"", "label": 0}, {"snippet_id": 6230, "code": "=float(len(text)) / avg_word_length words=[word for word in re.split('\\W', text) if word.isalpha()] word_number=len(words) return word_number > expected_word_number def text_lines_from_url(url, user_agent", "label": 1}, {"snippet_id": 89734, "code": " library'.format(name)) return list(collect_existing_libs()) @property def home(self): \"\"\"Returns the distribution JAVA_HOME.\"\"\" if not self._home: home=self._get_system_properties(self.java)['java.home'] if", "label": 0}, {"snippet_id": 72842, "code": "(path).mkdir(parents=True, exist_ok=True) def remove_directory_tree(path): \"\"\" Removes the directory and all subdirectories/files within the path specified. :param path: The path to the directory to remove", "label": 0}, {"snippet_id": 20055, "code": " script, *args, **kwargs) else: start=DebugAdapter.start new_addr=Address.as_server if detachable else Address.as_client addr=new_addr(None, self._addr.port) self._adapter=start(argv, addr=addr, env=env, cwd", "label": 0}, {"snippet_id": 50613, "code": ".params=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow", "label": 0}, {"snippet_id": 27821, "code": " data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state", "label": 0}, {"snippet_id": 10244, "code": " kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords", "label": 0}, {"snippet_id": 13763, "code": ".locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals, self.locals) if __name__=='__main__': for k, v in _safe_locals.iteritems(): print k, v", "label": 0}, {"snippet_id": 31369, "code": ".updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(", "label": 0}, {"snippet_id": 79915, "code": "\", help=\"Regex matching an upload success\", type=valid_regex, dest=\"trueRegex\") exclusiveArgs=parser.add_mutually_exclusive_group() exclusiveArgs.add_argument(\"-l\",\"--legit-extensions\",metavar=\"listOfExtensions", "label": 0}, {"snippet_id": 43564, "code": "=clause.index(rule1.name) j=clause.index(rule2.name) comp=j -i if comp < 0: comp=-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if", "label": 0}, {"snippet_id": 74554, "code": ": delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str", "label": 0}, {"snippet_id": 51336, "code": ".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not", "label": 0}, {"snippet_id": 47880, "code": ".subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set", "label": 0}, {"snippet_id": 84216, "code": " server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is no guarentee that it will contain all the datatypes available", "label": 0}, {"snippet_id": 69590, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import", "label": 0}, {"snippet_id": 53510, "code": " flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output", "label": 0}, {"snippet_id": 69390, "code": ".debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command),", "label": 0}, {"snippet_id": 64690, "code": ": self.verbose=verbose def ev_startclient_start(self, node, client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node", "label": 0}, {"snippet_id": 11283, "code": " from datetime import datetime import logging import os import sys from docopt import docopt from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, \\ ConfigurationContainsUndefinedVariables", "label": 0}, {"snippet_id": 39817, "code": "._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile)", "label": 0}, {"snippet_id": 44785, "code": " global config c=snakemake.io.load_configfile(jsonpath) update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow", "label": 0}, {"snippet_id": 73006, "code": " remote_subdirs_list=None): \"\"\" Recursive function that automatically downloads all files with a FTP directory, including subdirectories. :type ftp: ftplib.FTP :type local_directory: str :type remote_directory: str ", "label": 0}, {"snippet_id": 76205, "code": "', i, m) self.wz.del_req_handler(i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Route unbinded for(%s, %s)', i, m) else: self.log.warn('Status %s,", "label": 0}, {"snippet_id": 27737, "code": "'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif", "label": 0}, {"snippet_id": 44877, "code": " if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args", "label": 0}, {"snippet_id": 50096, "code": "]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included", "label": 0}, {"snippet_id": 71204, "code": " status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >", "label": 0}, {"snippet_id": 31976, "code": " item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput", "label": 0}, {"snippet_id": 33038, "code": " +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule", "label": 0}, {"snippet_id": 21820, "code": " X_test=sc.transform(X_test) import keras from keras.models import Sequential from keras.layers import Dense classifier=Sequential() classifier.add(Dense(units=6, kernel_initializer='uniform', activation", "label": 1}, {"snippet_id": 58590, "code": "): comments=Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self.assertEqual(new_comment, comments[0].comment) self.assertEqual(self.tester, comments[0].user) class TestUpdateObject", "label": 0}, {"snippet_id": 9747, "code": " resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories", "label": 0}, {"snippet_id": 48280, "code": " protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged", "label": 0}, {"snippet_id": 88901, "code": " lock object is actively holding the lock. :API: public \"\"\" return not self._lock.acquired def _replace_targets(self, target_roots): self._target_roots=list(target_roots) def add_new_target(self, address", "label": 0}, {"snippet_id": 52668, "code": ".benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested:", "label": 0}, {"snippet_id": 29244, "code": " not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard", "label": 1}, {"snippet_id": 87913, "code": ".join(cp_entries))) for arg in scalac_plugin_map[name]: ret.append('-S-P:{}:{}'.format(name, arg)) return ret def _find_scalac_plugins(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to", "label": 0}, {"snippet_id": 7214, "code": "] single_keywords=single_keywords.items() composite_keywords=composite_keywords.items() output.append(_output_marc(single_keywords, composite_keywords, author_keywords, acronyms)) output.append('</record", "label": 0}, {"snippet_id": 12337, "code": " body and footer\"\"\" author=data[\"author\"] comment_header=\"\" if request.json[\"action\"]==\"opened\": if config[\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the", "label": 0}, {"snippet_id": 50531, "code": " priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate", "label": 0}, {"snippet_id": 8411, "code": "('\\n'.join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in", "label": 1}, {"snippet_id": 50151, "code": " self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self", "label": 0}, {"snippet_id": 82037, "code": "?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=\"Regex matching an upload failure\", type=valid_regex,dest=\"notRegex\") requiredNamedArgs.add_argument(\"-", "label": 0}, {"snippet_id": 78313, "code": " e.answer) self.schedule(self.add_comment,(t, msg)) except exc.Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing", "label": 1}, {"snippet_id": 2193, "code": " wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0", "label": 0}, {"snippet_id": 16891, "code": "): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler", "label": 0}, {"snippet_id": 14821, "code": ") def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data):", "label": 0}, {"snippet_id": 19549, "code": " nextarg.endswith(':') and '--module' in pydevd: pydevd.remove('--module') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None:", "label": 0}, {"snippet_id": 85244, "code": "\"\"Return the repl tool key.\"\"\" return self._key_for_tool_version('scala-repl', self.version) def injectables(self, build_graph): if self.version=='custom': return specs_to_create=[ ('scalac', self._create_compiler_jardep", "label": 1}, {"snippet_id": 7053, "code": " keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style: text|html|marc", "label": 0}, {"snippet_id": 80160, "code": "\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"\",metavar=\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser", "label": 0}, {"snippet_id": 92982, "code": "{}\".format(sys.stderr)) old_stdout, old_stderr, old_stdin=sys.stdout, sys.stderr, sys.stdin with self._stdio_as_tempfiles(): with self._stdio_as_tempfiles(): pass self.assertEqual(sys.stdin.fileno(), 0", "label": 0}, {"snippet_id": 43067, "code": " str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if", "label": 0}, {"snippet_id": 80440, "code": ".proxyCreds[\"password\"]=getpass.getpass(\"Proxy password: \") now=datetime.datetime.now() print(\"[*] starting at \"+str(now.hour)+\":\"+str(now.minute)+\":\"+str(now.second)) mimeFile=\"mimeTypes.basic\" extensions", "label": 0}, {"snippet_id": 14136, "code": " tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer", "label": 0}, {"snippet_id": 62584, "code": "[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation", "label": 0}, {"snippet_id": 61580, "code": ".name]): return operator_map[A.name] p=[x.val if isinstance(x, Variable) else x for x in A.params] return operator_map[A.name](*p) def ev(self, A, wires): r\"\"\"Expectation value of a one-qubit observable", "label": 0}, {"snippet_id": 70809, "code": "=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target", "label": 0}, {"snippet_id": 84778, "code": ".targets.jar_library import JarLibrary from pants.build_graph.address import Address from pants.build_graph.injectables_mixin import InjectablesMixin from pants.java.jar.jar_dependency import JarDependency", "label": 0}, {"snippet_id": 57603, "code": " _update_priority(self): exists=Priority.objects.filter(pk=self.new_value).exists() if not exists: raise ObjectDoesNotExist('The priority you specified to change ' 'does not exist.') self.get_update_targets(", "label": 0}, {"snippet_id": 71714, "code": "%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug) def usage", "label": 0}, {"snippet_id": 84929, "code": ", classpath=classpath) def register_style_tool(version): cls.register_jvm_tool(register, cls._key_for_tool_version('scalastyle', version), classpath=[scala_style_jar]) super(ScalaPlatform, cls).register_options", "label": 1}, {"snippet_id": 84982, "code": " cls.register_jvm_tool(register, 'scalac-plugin-dep', classpath=[], help='Search for scalac plugins here, as well as in any ' 'explicit dependencies.') register('--version', advanced=True, default='2.12'", "label": 0}, {"snippet_id": 88062, "code": " cp_product, self._confs)] rel_classpath_elements=rel_classpath_elements or[classpath_element] if active_plugins.get(name, rel_classpath_elements) !=rel_classpath_elements: raise TaskError('Plugin{} defined in{}", "label": 0}, {"snippet_id": 15959, "code": "), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest", "label": 1}, {"snippet_id": 59885, "code": " in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=[] def __init__(self, wires, **kwargs): kwargs['backend']='ClassicalSimulator' super().__init__(wires, **kwargs) def reset", "label": 0}, {"snippet_id": 70486, "code": " CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from", "label": 0}, {"snippet_id": 28350, "code": " not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for", "label": 1}, {"snippet_id": 11056, "code": ") else: msg=\"Request %s returned with status %s. I don't know how to handle that.\" %(url, response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime", "label": 0}, {"snippet_id": 75906, "code": "(request[1][0], request[1][1], request[1][2], rs.accept, request[1][3]) msg.insert(0, b'') msgdict[rs]=msg s.send_multipart(msg) while self.running.is_set(): flag=0 for rs in rslist: if rs.finished: if", "label": 0}, {"snippet_id": 34041, "code": " ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule", "label": 0}, {"snippet_id": 29060, "code": "=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES", "label": 1}, {"snippet_id": 62321, "code": "(self, observable, wires): raise NotImplementedError(\"expectation() is not yet implemented for this backend\") def shutdown(self): \"\"\"Shutdown. \"\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to", "label": 0}, {"snippet_id": 66937, "code": " self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for", "label": 0}, {"snippet_id": 12495, "code": " if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file:\\n\\n\") comment_body.append(\"> \" +\"\".join(data[\"extra_results\"][file])) comment_body.append(\"---\\n\\n", "label": 0}, {"snippet_id": 10583, "code": " except IndexError: log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") >", "label": 0}, {"snippet_id": 62254, "code": "(operation.name, self.short_name)) par=[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self", "label": 0}, {"snippet_id": 71682, "code": "* from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys", "label": 0}, {"snippet_id": 63815, "code": " sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(\"Attempt", "label": 0}, {"snippet_id": 3343, "code": "\"session_name\": \"slave-session\" }) self.logger.info('found running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self", "label": 0}, {"snippet_id": 7052, "code": " composite keywords :var taxonomy_name: string, taxonomy name :keyword author_keywords: dictionary of author keywords extracted from fulltext :keyword acronyms: dictionary of extracted acronyms :keyword style", "label": 0}, {"snippet_id": 90509, "code": ":param bool jdk: whether the found java distribution is required to have a jdk. :return: the Distribution, or None if no matching distribution is in the cache. :rtype::class:`pants.java.distribution.Distribution`", "label": 0}, {"snippet_id": 56888, "code": " and annotated by key e.g. TestPlanTag, TestCaseTag ot TestRunTag :type test_tags: QuerySet \"\"\" self.key=key self.test_tags=iter(test_tags) self.counter={'tag': 0} def calculate_tag_count(self, tag): \"\"\" ", "label": 0}, {"snippet_id": 89747, "code": " if not self._home: home=self._get_system_properties(self.java)['java.home'] if os.path.basename(home)=='jre': jdk_dir=os.path.dirname(home) if self._is_executable(os.path.join(jdk_dir, 'bin', 'javac')", "label": 0}, {"snippet_id": 74169, "code": " benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_allele_count=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\" Creates an object representation of", "label": 1}, {"snippet_id": 43008, "code": ".append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError", "label": 0}, {"snippet_id": 62189, "code": "]) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend']) self.kwargs=kwargs self.eng=None self.reg=None def reset(self): self.reg=self.eng.allocate_qureg(self.wires) def __repr__(self)", "label": 0}, {"snippet_id": 12667, "code": " create_or_update_comment(data, comment): comment_mode=None headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) query=\"https://api.github.com/repos/", "label": 0}, {"snippet_id": 86439, "code": " builtins import open from collections import defaultdict from contextlib import closing from hashlib import sha1 from xml.etree import ElementTree from future.utils import PY3, text_type from pants.backend", "label": 1}, {"snippet_id": 78960, "code": "() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way to choose which one to test.\",len(detectedForms[0])) \t\t\texit() \t\tself.inputName=detectedForms", "label": 0}, {"snippet_id": 71124, "code": ") print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs) def status_view_disks(self, fs): \"\"\" View: lustre disks", "label": 0}, {"snippet_id": 63724, "code": ": %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata", "label": 0}, {"snippet_id": 11339, "code": "): self.skip_checks=skip_checks self.target_dir=target_dir if target_dir else CONFIG['TARGET_DIR'] self.source=url if debug_enabled: set_log_level_to_debug() if not self.target_dir or not os.path.isdir", "label": 0}, {"snippet_id": 63097, "code": "=self.__update_job_state_for_lwr_status(job_state, status) return job_state def __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status==\"complete\": self.mark_as_finished(job_state)", "label": 0}, {"snippet_id": 74804, "code": "\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str", "label": 0}, {"snippet_id": 21631, "code": "=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib.colors import ListedColormap X_set, y_set=X_train, y_train X1, X2=np.meshgrid", "label": 0}, {"snippet_id": 71399, "code": " AsciiTableLayout.LEFT, \"tag\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT", "label": 0}, {"snippet_id": 87470, "code": "-bridge', compiler_bridge]) zinc_args.extend(['-zinc-cache-dir', self._zinc_cache_dir]) zinc_args.extend(['-scala-path', ':'.join(scala_path)]) zinc_args.extend(self._javac_plugin_args(javac_plugin_map", "label": 1}, {"snippet_id": 16577, "code": " { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self): if not self._IsServerAlive(): return extra_data={} _AddUltiSnipsDataIfNeeded( extra_data) SendEventNotificationAsync( 'BufferVisit'", "label": 0}, {"snippet_id": 53392, "code": ") io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output:", "label": 0}, {"snippet_id": 61741, "code": " subsystems(order matters!) Returns: array: 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np", "label": 0}, {"snippet_id": 36390, "code": " self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in", "label": 0}, {"snippet_id": 41317, "code": " or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__(self, min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"", "label": 0}, {"snippet_id": 19675, "code": " parser.add_argument('--single-session', action='store_true') parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop(", "label": 0}, {"snippet_id": 16244, "code": " YouCompleteMe( object): def __init__( self, user_options): self._user_options=user_options self._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter", "label": 0}, {"snippet_id": 65909, "code": "(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown", "label": 0}, {"snippet_id": 20635, "code": " handler in handlers: if callable(handler): self._add_handler(handler) else: self._add_handler(*handler) self._received=[] self._listenerthread=new_hidden_thread( target=self._listen, name='test.session', ", "label": 0}, {"snippet_id": 38209, "code": " CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler", "label": 0}, {"snippet_id": 61955, "code": ".random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as pq import projectq.setups.ibm from projectq.ops import(HGate, XGate, YGate, ZGate, SGate, TGate", "label": 0}, {"snippet_id": 79449, "code": "=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime", "label": 0}, {"snippet_id": 34620, "code": " return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self", "label": 1}, {"snippet_id": 5549, "code": " % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires)) for fieldcode, keywords in fieldcodes.items(): output[fieldcode]=', '.join(keywords) return output def _get_core_keywords", "label": 0}, {"snippet_id": 16313, "code": ", '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options", "label": 0}, {"snippet_id": 4082, "code": " one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the different outputs(text, MARCXML or HTML). But unfortunately", "label": 0}, {"snippet_id": 11620, "code": " self.output_file=output_file def write_lines(self, lines): with open(self.output_file, 'w') as f: for line in lines: f.write(line +\"\\n\") LOG.debug(\"Created %s\" % self.output_file) def generate_config(", "label": 0}, {"snippet_id": 57779, "code": " sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True) if plan is None: return say_no('No plan record found.') update_targets=self.get_update_targets() offset=0 step_length", "label": 0}, {"snippet_id": 53564, "code": " list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for item in self.output:", "label": 0}, {"snippet_id": 24409, "code": " add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{", "label": 0}, {"snippet_id": 44181, "code": "=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun", "label": 0}, {"snippet_id": 73028, "code": "(remote_subdirs_list) > 0): remote_path_relative=\"/\".join(remote_subdirs_list) remote_path_absolute=\"/\" +remote_directory +\"/\" +remote_path_relative +\"/\" else: remote_subdirs_list=[] remote_path_relative=", "label": 0}, {"snippet_id": 7335, "code": "<subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in", "label": 0}, {"snippet_id": 310, "code": "=='registerService': request_name=request.POST.get(\"name\") request_address=request.POST.get(\"address\") request_icon=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon", "label": 0}, {"snippet_id": 91637, "code": " if hasattr(maybe_python_req_lib, 'requirements'): for py_req in maybe_python_req_lib.requirements: all_target_requirements.append(str(py_req.requirement)) all_requirements=sorted(all_target_requirements", "label": 0}, {"snippet_id": 60082, "code": ".ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value", "label": 0}, {"snippet_id": 58979, "code": "\"\" @classmethod def setUpTestData(cls): super(TestGetObjectInfo, cls).setUpTestData() cls.get_info_url=reverse('ajax-info') cls.group_nitrate=EnvGroupFactory(name='nitrate') cls.group_new=EnvGroupFactory", "label": 0}, {"snippet_id": 25566, "code": "'sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2", "label": 0}, {"snippet_id": 54313, "code": "=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self", "label": 0}, {"snippet_id": 26825, "code": " elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" ", "label": 0}, {"snippet_id": 53489, "code": ": self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments", "label": 0}, {"snippet_id": 90194, "code": " path of the JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java`", "label": 0}, {"snippet_id": 13166, "code": "\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json={ \"name\": name, \"description\": \"Forked from @{}'s{}\".format(author, full_name) } r=requests.patch(url, data=json.dumps(request_json),", "label": 0}, {"snippet_id": 87487, "code": ".scalac_plugin_classpath_elements())) - {ctx.classes_dir, ctx.jar_file} ) zinc_args.extend(self._scalac_plugin_args(scalac_plugin_map, scalac_plugin_search_classpath)) if upstream_analysis: zinc_args.extend([", "label": 0}, {"snippet_id": 92637, "code": ") self.assertFalse(os.path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup(self): with temporary_dir(cleanup=False) as path: self.assertTrue", "label": 0}, {"snippet_id": 8788, "code": " entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry): for filename in os.listdir(entry): if filename.startswith('.'): continue filename", "label": 0}, {"snippet_id": 71685, "code": ".CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug(task, s", "label": 1}, {"snippet_id": 63024, "code": "=DEFAULT_GALAXY_URL): \"\"\"Start the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs", "label": 0}, {"snippet_id": 22464, "code": " waagent stop\", chk_err=False) def start_agent_service(self): return shellutil.run(\"/sbin/service waagent start\", chk_err=False) def register_agent_service(self): return shellutil.run(\"/sbin/chkconfig -", "label": 0}, {"snippet_id": 13378, "code": ", headers=headers, auth=auth) sha_blob=r.json().get(\"sha\") params[\"path\"]=file content_code=base64.b64encode(new_file.encode()).decode(\"utf-8\") request_json={ \"path\": file, \"message\": \"Fix pep8 errors in", "label": 0}, {"snippet_id": 85582, "code": ". :type products::class:`pants.goal.products.Products` :returns: A Zinc instance with access to relevant Zinc compiler wrapper jars and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self, products) def", "label": 0}, {"snippet_id": 55785, "code": ".log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func", "label": 0}, {"snippet_id": 40624, "code": "\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected", "label": 0}, {"snippet_id": 95667, "code": ". :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed *.vcf", "label": 0}, {"snippet_id": 22778, "code": " that the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param", "label": 0}, {"snippet_id": 40769, "code": " value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given", "label": 0}, {"snippet_id": 46890, "code": " } self.threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output", "label": 0}, {"snippet_id": 79688, "code": "=argparse.RawTextHelpFormatter) parser.add_argument(\"-d\", \"--data\", metavar=\"postData\",dest=\"data\", help=\"Additionnal data to be transmitted via POST method. Example: -d \\\"key1=value1&key2=value2\\\"\", type", "label": 0}, {"snippet_id": 9943, "code": ", \"details\": info[1]} return output def _get_acronyms(acronyms): \"\"\"Return a formatted list of acronyms.\"\"\" acronyms_str={} if acronyms: for acronym, expansions in iteritems(acronyms): expansions_str=\"", "label": 0}, {"snippet_id": 62273, "code": " *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate", "label": 0}, {"snippet_id": 51301, "code": " apply_wildcards(pattern, wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic", "label": 0}, {"snippet_id": 72126, "code": "'Not enough arguments(needs 2: network name(case sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No such network \"%s\"(case sensitive).' % netname) return except ValueError", "label": 0}, {"snippet_id": 74429, "code": " file. \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section", "label": 0}, {"snippet_id": 43206, "code": " not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name", "label": 0}, {"snippet_id": 78166, "code": ".net import NetError from wzworkers import WorkerInterrupt from wipeskel import WipeSkel, WipeState, cstate from beon import exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets", "label": 0}, {"snippet_id": 84245, "code": " return use_remote_datatypes @staticmethod def __rewrite_parameters( lwr_client): return string_as_bool_or_none( lwr_client.destination_params.get( \"rewrite_parameters\", False)) or False def __build_metadata_configuration", "label": 0}, {"snippet_id": 26868, "code": "=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle", "label": 0}, {"snippet_id": 215, "code": ", wlan0, currentwifi) def delete_WifiConn(wifiap): \"\"\" nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps", "label": 0}, {"snippet_id": 73783, "code": "): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config data to extract FTP settings from :type runtime_config: ConfigurationRepresentation \"\"\" if", "label": 0}, {"snippet_id": 58097, "code": " bug in bugs: if bug.case_run_id==run.pk: run.remove_bug(bug.bug_id, run.pk) except Exception as e: return say_no(str(e)) return say_yes() def get_prod_related_objs(p_pks, target): \"\"\" Get Component, Version", "label": 0}, {"snippet_id": 61989, "code": " CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, ", "label": 0}, {"snippet_id": 82829, "code": " \tlogger.info(\" \tup.validExtensions=args.legitExtensions if up.validExtensions==[]: \tlogger.error(\"No valid extension found.\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a))", "label": 0}, {"snippet_id": 18707, "code": "{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def", "label": 0}, {"snippet_id": 6016, "code": ") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version", "label": 1}, {"snippet_id": 5055, "code": " ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in", "label": 0}, {"snippet_id": 47378, "code": " for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for", "label": 0}, {"snippet_id": 47535, "code": "} return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self, other): if other is None: return False return self.rule==other.rule and", "label": 0}, {"snippet_id": 834, "code": "(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=[] for i in rows: data={} datasets=[] ps=subprocess.Popen(['docker', 'top',i[0]], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode", "label": 0}, {"snippet_id": 78865, "code": "=url.netloc \t\tself.httpRequests=0 \t\ttry: \t\t\tinitGet=self.session.get(self.formUrl,headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject", "label": 0}, {"snippet_id": 34389, "code": " class Subworkflow: def __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile", "label": 0}, {"snippet_id": 10792, "code": " expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(\"User-Agent\", user_agent) try", "label": 1}, {"snippet_id": 28454, "code": "=module_id[1] @property def name(self): \"\"\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class", "label": 0}, {"snippet_id": 24626, "code": ": self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp", "label": 0}, {"snippet_id": 53631, "code": ": \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self", "label": 0}, {"snippet_id": 33045, "code": "(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule", "label": 0}, {"snippet_id": 76171, "code": " return self.wz_wait_reply(accept, *self.wz.make_auth_set_route_type_data(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug(", "label": 0}, {"snippet_id": 30768, "code": " size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self.input) return self._inputsize @property def message(self): \"\"\" Return the", "label": 0}, {"snippet_id": 64381, "code": " Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return", "label": 0}, {"snippet_id": 38098, "code": ".name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records", "label": 0}, {"snippet_id": 63343, "code": " remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) dependency_resolution=LwrJobRunner.__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata", "label": 0}, {"snippet_id": 76048, "code": "%s,%s route', i, m) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.wz.set_req_handler(i, m, f) self.log.debug('Succesfully binded route(%s, %s)', i, m) elif status", "label": 0}, {"snippet_id": 15224, "code": "(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ", "label": 0}, {"snippet_id": 25880, "code": " self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240:", "label": 0}, {"snippet_id": 3301, "code": " self.check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\")", "label": 0}, {"snippet_id": 58250, "code": " import CaseAutomatedForm from tcms.testcases.forms import TestCase from tcms.testplans.models import TestPlan from tcms.testruns.models import TestCaseRun from tcms.testruns.models import TestCaseRunStatus", "label": 1}, {"snippet_id": 85646, "code": " \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property def compiler_interface(self): \"\"\"Return the path to the Zinc compiler-interface jar. :rtype: str \"\"\" return self._zinc_factory", "label": 0}, {"snippet_id": 47558, "code": ".rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def", "label": 0}, {"snippet_id": 95525, "code": ") file_counter=1 file_list_total=len(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute", "label": 0}, {"snippet_id": 82135, "code": ",dest=\"veryVerbose\",help=\"Very verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(", "label": 0}, {"snippet_id": 18969, "code": " response=requests.get(source) if isinstance(response.content, six.binary_type): raw_source=six.text_type(response.content, encoding='utf-8') else: raw_source=response.content else: raw_source=source try", "label": 0}, {"snippet_id": 19983, "code": " client closed') if self._session is None: raise RuntimeError('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError('detach", "label": 0}, {"snippet_id": 69020, "code": " message class Umount(FSClientLiveCommand): \"\"\" shine umount \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system", "label": 0}, {"snippet_id": 63591, "code": " client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs", "label": 0}, {"snippet_id": 2464, "code": "=Server() if self.server.has_session(self.session_name): self.session=self.server.find_where({ \"session_name\": self.session_name }) self.logger.info('found running session by name \"%s\" on server' % self", "label": 0}, {"snippet_id": 13751, "code": "(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals,", "label": 0}, {"snippet_id": 7897, "code": " info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i", "label": 0}, {"snippet_id": 37664, "code": " item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(", "label": 0}, {"snippet_id": 76420, "code": "[1:]) except wzrpc.WZError as e: self.log.warn(e) if socks.get(self.wz_sock)==zmq.POLLIN: self.process_wz_msg(self.wz_sock.recv_multipart()) return socks def process_wz_msg(self, frames): try: for nfr in", "label": 0}, {"snippet_id": 2360, "code": " import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S')", "label": 0}, {"snippet_id": 57075, "code": " 0, 'response': 'ok'})) @require_POST def update(request): \"\"\" Generic approach to update a model,\\n based on contenttype. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type", "label": 0}, {"snippet_id": 86283, "code": ") if self.execution_strategy==self.HERMETIC: self._execute_hermetic_compile(javac_cmd, ctx) else: with self.context.new_workunit(name='javac', cmd=' '.join(javac_cmd), labels=[WorkUnitLabel.COMPILER]) as", "label": 0}, {"snippet_id": 28190, "code": " 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery',", "label": 0}, {"snippet_id": 70971, "code": " len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0: status", "label": 0}, {"snippet_id": 71995, "code": " to various configured networks.\"\"\" import importlib import types from pylinkirc import utils, world, conf, classes from pylinkirc.log import log from pylinkirc.coremods import control, permissions @utils", "label": 0}, {"snippet_id": 6636, "code": " def get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False, match_mode=\"full\", no_cache=False, with_author_keywords", "label": 0}, {"snippet_id": 2896, "code": "%(node.comp_name, comp['name'])) self.start_component_without_deps(node.component) tries=0 while True: self.logger.debug(\"Checking %s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component", "label": 0}, {"snippet_id": 19220, "code": "': 'bar'} result=load_source(source) assert result==source def test_json_string(): native={'foo': 'bar'} source=json.dumps(native) result=load_source(source) assert result==native def test_yaml_string(", "label": 1}, {"snippet_id": 11875, "code": "\"sha1\") if not hmac.compare_digest(str(mac.hexdigest()), str(signature)): abort(403) return True def check_pythonic_pr(data): \"\"\" Return True if the PR contains at least one Python file \"\"\" files=list(get_files_involved_in_pr", "label": 0}, {"snippet_id": 20506, "code": " return True def iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed read=recv_as_read(self._sock) for msg, _, _ in read_messages(read, stop=stop): if", "label": 0}, {"snippet_id": 3571, "code": " def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd'][1] window=find_window(session,", "label": 0}, {"snippet_id": 27083, "code": "(self): \"\"\"Call the Netatmo API to update the data.\"\"\" import pyatmo self.station_data=pyatmo.WeatherStationData(self.auth) if self.station is not None: self.data=self.station_data.lastData( station=self", "label": 1}, {"snippet_id": 87696, "code": ", output_directories=(classes_dir,), description=\"zinc compile for{}\".format(ctx.target.address.spec), jdk_home=text_type(self._zinc.dist.home), ) res=self.context.execute_process_synchronously(req, self", "label": 1}, {"snippet_id": 594, "code": "'getDashboardChart': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: cursor", "label": 0}, {"snippet_id": 69065, "code": ".verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs", "label": 0}, {"snippet_id": 24193, "code": "'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm'", "label": 0}, {"snippet_id": 15064, "code": "=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status", "label": 0}, {"snippet_id": 68031, "code": ", node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class Status(FSLiveCommand): ", "label": 0}, {"snippet_id": 32126, "code": ", output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property", "label": 0}, {"snippet_id": 49587, "code": ", priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp", "label": 0}, {"snippet_id": 39695, "code": ".resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version):", "label": 0}, {"snippet_id": 28631, "code": " self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] ", "label": 0}, {"snippet_id": 1104, "code": " elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '", "label": 0}, {"snippet_id": 38506, "code": ".has_wildcards, rules) for rule in rules: logger.rule_info(name=rule.name, docstring=rule.docstring) def list_resources(self): for resource in set( resource for rule in self.rules for resource in rule.resources):", "label": 0}, {"snippet_id": 38299, "code": "._localrules=set() self.linemaps=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[", "label": 0}, {"snippet_id": 81873, "code": ".add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(", "label": 0}, {"snippet_id": 57766, "code": " or sortkey > 32300: return say_no('New sortkey is out of range[0, 32300].') except ValueError: return say_no('New sortkey is not an integer.') plan=plan_from_request_or_none(self.request, pk_enough=True", "label": 0}, {"snippet_id": 96048, "code": ".blosc_compression_algorithm, clevel=conversion_config.blosc_compression_level, shuffle=conversion_config.blosc_shuffle_mode) else: raise ValueError(\"Unexpected compressor type specified.\") print(\"[VCF-Zarr] Using{", "label": 1}, {"snippet_id": 85686, "code": " ) ), buildroot, ), ))[0] @memoized_property def rebase_map_args(self): \"\"\"We rebase known stable paths in zinc analysis to make it portable across machines.\"\"\" rebases={ self.dist.real_home: '/dev/null", "label": 0}, {"snippet_id": 90963, "code": " key, val in OS_ALIASES.items()) register('--paths', advanced=True, type=dict, help='Map of os names to lists of paths to jdks. These paths will be searched before ' 'everything else(before the JDK_HOME", "label": 0}, {"snippet_id": 66776, "code": " Configuration from ProxyAction import * from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action,", "label": 0}, {"snippet_id": 82396, "code": "=args.template][0]] if args.regexOverride: \tfor t in templates: \t\tt[\"codeExecRegex\"]=args.regexOverride[0] args.verbosity=0 if args.verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args", "label": 0}, {"snippet_id": 50841, "code": "(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self", "label": 0}, {"snippet_id": 8945, "code": " into one string) :param taxonomy_name: string, name of the taxonomy_name :param output_mode: string -text|html|marcxml|raw :param output_limit: int :param spires: boolean, if True marcxml output reflect", "label": 0}, {"snippet_id": 72243, "code": ".' % netname) return if args.service not in world.services: irc.error('Unknown service %r.' % args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient", "label": 0}, {"snippet_id": 15098, "code": " _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True", "label": 1}, {"snippet_id": 58787, "code": "=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission Dinied.'}) def test_change_case_run_status(self): self.client.login( username=self.tester.username, password='password') response=self.client", "label": 0}, {"snippet_id": 37217, "code": " _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards", "label": 0}, {"snippet_id": 84362, "code": ".basename(integrates_datatypes_config)) return metadata_kwds class LwrComputeEnvironment( ComputeEnvironment): def __init__( self, lwr_client, job_wrapper, remote_job_config): self.lwr_client=lwr_client", "label": 0}, {"snippet_id": 15939, "code": " method, timeout=_DEFAULT_TIMEOUT_SEC): def SendRequest( data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS,", "label": 1}, {"snippet_id": 72984, "code": ".remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping:{}\".format(file_counter, file_list_total, filepath)) file_counter=file_counter +1 ftp.close() def fetch_data_via_ftp_recursive", "label": 0}, {"snippet_id": 54298, "code": " Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule):", "label": 0}, {"snippet_id": 27354, "code": "): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names", "label": 1}, {"snippet_id": 85900, "code": ".base.workunit import WorkUnit, WorkUnitLabel from pants.engine.fs import DirectoryToMaterialize from pants.engine.isolated_process import ExecuteProcessRequest from pants.java.distribution.distribution", "label": 0}, {"snippet_id": 75756, "code": " term_handler(interface, method, data): self.log.info( 'Termination signal %s recieved', repr((interface, method, data))) self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate'", "label": 1}, {"snippet_id": 60711, "code": "=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device\"\"\" if self.eng is not None: self.eng=None self", "label": 0}, {"snippet_id": 11865, "code": "': abort(501) mac=hmac.new(os.environ[\"GITHUB_PAYLOAD_SECRET\"].encode(), msg=request.data, digestmod=\"sha1\") if not hmac.compare_digest(str(mac.hexdigest()), str(signature)): abort(403) return True def", "label": 0}, {"snippet_id": 72422, "code": ", reads the benchmark configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import", "label": 0}, {"snippet_id": 31192, "code": " from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads", "label": 0}, {"snippet_id": 12689, "code": "}/comments\" query=query.format(data[\"repository\"], str(data[\"pr_number\"])) comments=requests.get(query, headers=headers, auth=auth).json() last_comment_id=None for old_comment in comments: if old_comment", "label": 0}, {"snippet_id": 53544, "code": "(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output", "label": 0}, {"snippet_id": 79752, "code": "\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies", "label": 0}, {"snippet_id": 49172, "code": "=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property", "label": 0}, {"snippet_id": 2710, "code": "(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp, host)) cmd=(\"ssh %s 'mkdir -p %s'", "label": 0}, {"snippet_id": 51914, "code": " self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted(self._names.items(), key=lambda item: item[1", "label": 0}, {"snippet_id": 95890, "code": " -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr", "label": 0}, {"snippet_id": 4182, "code": " with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source in sources.\"\"\" def process_lines(): if output_mode==\"text\"", "label": 0}, {"snippet_id": 26545, "code": "], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24", "label": 0}, {"snippet_id": 21888, "code": " helper as dci_helper from dciagent.plugins import plugin import jinja2 import os import subprocess display=Display() class Options(object): def __init__(self, verbosity=None, inventory=None, listhosts=None,", "label": 1}, {"snippet_id": 84960, "code": " register('--scalac-plugin-args', advanced=True, type=dict, default={}, fingerprint=True, help='Map from scalac plugin name to list of arguments for that plugin.') cls.register_jvm_tool(register, 'scalac", "label": 0}, {"snippet_id": 3605, "code": " %s\" % pid) procs=[] for entry in pid: procs.extend(Process(entry).children(recursive=True)) pids=[p.pid for p in procs] logger.debug(\"Window is running %s child processes\" % len(pids)) if len(pids) < 3", "label": 1}, {"snippet_id": 94027, "code": "[] dep_resolve(current, res, unres) for node in res: if \"depends\" in node.component: for dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name", "label": 0}, {"snippet_id": 33127, "code": ".name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None", "label": 0}, {"snippet_id": 60083, "code": " self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if observable=='PauliZ': probabilities=self.eng.backend.get_probabilities([self.reg[wires]]) if '1' in probabilities: expectation_value", "label": 0}, {"snippet_id": 89672, "code": " and `jre/lib` dirs will be scanned. The endorsed and extension dirs are not checked. :param list names: jar file names :return: list of paths to requested libraries :raises: `Distribution.Error` if any", "label": 0}, {"snippet_id": 43961, "code": " touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False", "label": 0}, {"snippet_id": 4320, "code": " only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing", "label": 1}, {"snippet_id": 58333, "code": " self.client.login( username=self.user.username, password='testing') response=self.client.get(reverse('iframe-navigation')) self.assertContains(response, urlencode({'people': self.user.email})) self.assertContains", "label": 0}, {"snippet_id": 26337, "code": "=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not", "label": 1}, {"snippet_id": 59577, "code": "\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self", "label": 0}, {"snippet_id": 57744, "code": "() return http.JsonResponse({ 'rc': 0, 'response': 'ok', 'run_case_count': run_case_count, 'case_count': case_count, 'review_case_count': review_case_count, }) def _update_sortkey(self): try: sortkey=int", "label": 0}, {"snippet_id": 83769, "code": "*finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.", "label": 0}, {"snippet_id": 14695, "code": "._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format", "label": 0}, {"snippet_id": 91038, "code": " dict of string -> list of string \"\"\" return self._normalized_jdk_paths @memoized_method def _locator(self): return self._create_locator() @memoized_property def _normalized_jdk_paths(self): normalized={", "label": 0}, {"snippet_id": 85387, "code": " from pants.util.memo import memoized_method, memoized_property class Zinc(object): \"\"\"Configuration for Pants' zinc wrapper tool.\"\"\" ZINC_COMPILE_MAIN='org.pantsbuild.zinc.compiler.Main' ZINC_EXTRACT_MAIN", "label": 0}, {"snippet_id": 24477, "code": " frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.", "label": 0}, {"snippet_id": 66369, "code": ".Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import", "label": 0}, {"snippet_id": 49565, "code": ".wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall", "label": 0}, {"snippet_id": 65256, "code": ".init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel)", "label": 0}, {"snippet_id": 32451, "code": " ruleio=ruleio) params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()", "label": 0}, {"snippet_id": 71819, "code": " except ModelFileException, e: print \"ModelFile: %s\" % e except ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except", "label": 1}, {"snippet_id": 87482, "code": ") zinc_args.extend(self._javac_plugin_args(javac_plugin_map)) scalac_plugin_search_classpath=( (set(absolute_classpath) | set(self.scalac_plugin_classpath_elements())) - {ctx.classes_dir, ctx.jar_file}", "label": 0}, {"snippet_id": 16604, "code": " self._diag_interface.OnCursorMoved() def OnVimLeave( self): self._ServerCleanup() def OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished", "label": 0}, {"snippet_id": 80388, "code": "+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state", "label": 0}, {"snippet_id": 74666, "code": " str(alt_number_str).lower()==\"auto\": self.alt_number=None elif isint(alt_number_str): self.alt_number=int(alt_number_str) else: raise TypeError(\"Invalid value provided for alt_number in configuration.\\n", "label": 0}, {"snippet_id": 22293, "code": " azurelinuxagent.logger as logger import azurelinuxagent.utils.shellutil as shellutil from azurelinuxagent.exception import OSUtilError from azurelinuxagent.distro.default.osutil import DefaultOSUtil class", "label": 0}, {"snippet_id": 5255, "code": ".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. ", "label": 0}, {"snippet_id": 92320, "code": "'False\\n', new_output.read()) def test_environment_negation(self): with temporary_file(binary_mode=False) as output: with environment_as(HORK='BORK'): with environment_as(HORK=None): subprocess.Popen([sys", "label": 0}, {"snippet_id": 9717, "code": "=spires)} if not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single", "label": 0}, {"snippet_id": 48450, "code": " strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def", "label": 0}, {"snippet_id": 33139, "code": ", local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config", "label": 0}, {"snippet_id": 57500, "code": " if action is not None: try: resp=action() self._sendmail() except ObjectDoesNotExist as err: return say_no(str(err)) except Exception: return say_no('Update failed. Please try again or request ' 'support", "label": 0}, {"snippet_id": 46874, "code": ")=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict", "label": 0}, {"snippet_id": 12319, "code": "\"]=url.format(repository, after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and footer\"\"\" author", "label": 0}, {"snippet_id": 31870, "code": " in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append", "label": 0}, {"snippet_id": 93780, "code": "(self, comp): if comp['host'] !='localhost' and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component", "label": 0}, {"snippet_id": 25399, "code": "%s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data,", "label": 0}, {"snippet_id": 42573, "code": " exp in replacements: if old in branch.temp_output: branch.temp_output.discard(old) branch.temp_output.update(exp) if old in branch.protected_output: branch.protected_output.discard(old) branch.protected_output", "label": 0}, {"snippet_id": 50571, "code": " decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo", "label": 0}, {"snippet_id": 76140, "code": " for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() else", "label": 0}, {"snippet_id": 92504, "code": ".realpath(tempdir2), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual", "label": 0}, {"snippet_id": 94531, "code": "\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window", "label": 0}, {"snippet_id": 60588, "code": "=2): self.wires=wires self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.", "label": 1}, {"snippet_id": 69201, "code": " cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(", "label": 0}, {"snippet_id": 44311, "code": ") if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files", "label": 0}, {"snippet_id": 64260, "code": ".local_path_config.version_path() new_version_path=self.path_mapper.remote_version_path_rewrite(version_path) if new_version_path: version_path=new_version_path self._version_path=version_path def output_paths( self", "label": 0}, {"snippet_id": 53562, "code": " Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output=True) for name, item in kwoutput.items(): self._set_inoutput_item(item, output=True, name=name) for", "label": 0}, {"snippet_id": 52574, "code": ".dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def", "label": 0}, {"snippet_id": 29416, "code": "): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard", "label": 0}, {"snippet_id": 44381, "code": " logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"-", "label": 0}, {"snippet_id": 59045, "code": "'name', 'value'))) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), expected_json) def test_get_env_properties_by_group(self): response=self.client.get(self.get_info_url,", "label": 0}, {"snippet_id": 52821, "code": ".info(\"Removing output files of failed job{}\" \" since they might be corrupted:\\n{}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): ", "label": 0}, {"snippet_id": 47728, "code": " expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged, not_iterable from snakemake.exceptions import RuleException, IOFileException, WildcardError,", "label": 0}, {"snippet_id": 18177, "code": ".omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification) from ycm.server.responses import ServerError try: from UltiSnips", "label": 0}, {"snippet_id": 71678, "code": " ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import", "label": 0}, {"snippet_id": 10119, "code": " _get_core_keywords(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword", "label": 0}, {"snippet_id": 17878, "code": "( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest", "label": 0}, {"snippet_id": 84068, "code": "( self): super( LwrJobRunner, self).shutdown() self.client_manager.shutdown() def __client_outputs( self, client, job_wrapper): remote_work_dir_copy=LwrJobRunner.__remote_work_dir_copy( client) if not remote_work_dir_copy", "label": 1}, {"snippet_id": 86239, "code": ".execution_strategy==self.HERMETIC: javac_cmd.extend([ '-d', '.', ]) else: javac_cmd.extend([ '-d', ctx.classes_dir, ]) javac_cmd.extend(self._javac_plugin_args(javac_plugin_map)) javac_cmd.extend(args)", "label": 0}, {"snippet_id": 38338, "code": " self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules(", "label": 0}, {"snippet_id": 88346, "code": " with. :API: public \"\"\" class Log(object): \"\"\"A logger facade that logs into the pants reporting framework.\"\"\" def __init__(self, run_tracker): self._run_tracker=run_tracker def debug(self, *msg_elements):", "label": 0}, {"snippet_id": 79780, "code": " HTTP requests. Example: PHPSESSID=aef45aef45afeaef45aef45&JSESSID=AQSEJHQSQSG\",type=valid_postData) parser.add_argument(\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path", "label": 0}, {"snippet_id": 67311, "code": ": return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR", "label": 0}, {"snippet_id": 37489, "code": "\"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name", "label": 0}, {"snippet_id": 3328, "code": "(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\" }) self.logger.info('found running", "label": 0}, {"snippet_id": 29600, "code": "\"If multiple wildcards of the same name \" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)", "label": 0}, {"snippet_id": 38245, "code": " flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None,", "label": 1}, {"snippet_id": 37523, "code": " specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start", "label": 0}, {"snippet_id": 69288, "code": " ConfigException, e: print \"Configuration: %s\" % e return RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR", "label": 1}, {"snippet_id": 1260, "code": ".Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: name=row.split(':') print(name) wifi", "label": 0}, {"snippet_id": 52384, "code": " True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self) @property def b64id(self): return base64.b64encode((self.rule", "label": 0}, {"snippet_id": 82202, "code": "\",metavar=\"Threads\",nargs=1,dest=\"nbThreads\",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument", "label": 0}, {"snippet_id": 66810, "code": ".action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on %s\" %", "label": 0}, {"snippet_id": 36827, "code": "\"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self.incomplete_output: s.append(\"Incomplete output files:{}\".format(", "label": 0}, {"snippet_id": 93421, "code": ".component: for dep in node.component['depends']: if dep in self.nodes: node.addEdge(self.nodes[dep]) else: self.logger.error(\"Unmet dependency: '%s' for component '%s'!\" %(dep, node.comp_name)) if exit_on_fail", "label": 0}, {"snippet_id": 67327, "code": " RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for", "label": 0}, {"snippet_id": 65848, "code": " if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering.append(target) elif target.state==MOUNTED: t_online", "label": 0}, {"snippet_id": 67959, "code": " import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824", "label": 0}, {"snippet_id": 83335, "code": " found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if", "label": 0}, {"snippet_id": 23407, "code": "\".format(hostname), chk_err=False) def restart_ssh_service(self): return shellutil.run('service sshd restart', chk_err=False) def useradd(self, username, expiration=None): \"\"\" Create user account with ", "label": 1}, {"snippet_id": 68701, "code": " %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags", "label": 0}, {"snippet_id": 49182, "code": ".overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return(", "label": 0}, {"snippet_id": 58332, "code": "): self.client.login( username=self.user.username, password='testing') response=self.client.get(reverse('iframe-navigation')) self.assertContains(response, urlencode({'people': self.user.email})) self.assertContains", "label": 0}, {"snippet_id": 30025, "code": ".normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )]) if first_wildcard else os.path.dirname(pattern) if not dirname: dirname=\".\" names", "label": 0}, {"snippet_id": 55562, "code": "\"exec\"), self.globals) if not overwrite_first_rule: self.first_rule=first_rule self.included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir", "label": 0}, {"snippet_id": 30252, "code": " names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index", "label": 0}, {"snippet_id": 42905, "code": " output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable", "label": 0}, {"snippet_id": 61784, "code": ".max(wires) n_between=b-a-1 before =2**a after =2**(self.wires-b-1) between=2**n_between U=np.kron(U, np.eye(between)) if wires[0] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2, 2, between] p=np.array", "label": 0}, {"snippet_id": 4664, "code": " in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords(skw_db, ckw_db, fulltext): \"\"\"Finds out human defined keyowrds in a text string", "label": 0}, {"snippet_id": 20519, "code": "._sock) for msg, _, _ in read_messages(read, stop=stop): if self.VERBOSE: print(repr(msg)) yield parse_message(msg) def send(self, req): if self.closed: raise RuntimeError('connection closed') def stop(", "label": 0}, {"snippet_id": 46248, "code": " values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{", "label": 0}, {"snippet_id": 26787, "code": "'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 35994, "code": " type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile", "label": 0}, {"snippet_id": 76912, "code": ".proxy_type=sup.proxytype.http elif proxytype=='SOCKS4': net.proxy_type=sup.proxytype.socks4 elif proxytype=='SOCKS5': net.proxy_type=sup.proxytype.socks5 else: raise TypeError('Invalid proxytype %s' %", "label": 1}, {"snippet_id": 60044, "code": "\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.IBMBackend(", "label": 0}, {"snippet_id": 64008, "code": " lwr_client.destination_params.get( \"remote_metadata\", False)) return remote_metadata @staticmethod def __remote_work_dir_copy( lwr_client): return LwrJobRunner.__remote_metadata( lwr_client) @staticmethod", "label": 0}, {"snippet_id": 14659, "code": ".DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try:", "label": 0}, {"snippet_id": 92210, "code": " import pstats import shutil import signal import sys import unittest import uuid import zipfile from builtins import next, object, range, str from contextlib import contextmanager import mock from future", "label": 0}, {"snippet_id": 90647, "code": "(version_a, version_b) minimum_version=_get_stricter_version(minimum_version, self._minimum_version, \"minimum_version\", max) maximum_version=_get_stricter_version(maximum_version, self._maximum_version,", "label": 0}, {"snippet_id": 10241, "code": " filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare", "label": 0}, {"snippet_id": 28597, "code": "._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 71119, "code": " AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) print \"FILESYSTEM COMPONENTS STATUS(%s)\" % fs.fs_name AsciiTable().print_from_list_of_dict(ldic, layout) status_view_fs=classmethod(status_view_fs", "label": 0}, {"snippet_id": 14948, "code": " data, handler, method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest", "label": 1}, {"snippet_id": 64270, "code": " def output_paths( self): local_output_paths=self._wrapper_output_paths results=[] for local_output_path in local_output_paths: wrapper_path=str( local_output_path) remote_path=self.path_mapper.remote_output_path_rewrite", "label": 0}, {"snippet_id": 41271, "code": " try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)", "label": 0}, {"snippet_id": 47214, "code": ".benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f", "label": 0}, {"snippet_id": 95909, "code": " output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a Zarr format. Only", "label": 1}, {"snippet_id": 90000, "code": "]) def _get_system_properties(self, java): if not self._system_properties: with temporary_dir() as classpath: with open(os.path.join(classpath, 'SystemProperties.class'), 'w+b') as fp: fp.write(pkgutil", "label": 0}, {"snippet_id": 28607, "code": "': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low", "label": 0}, {"snippet_id": 30425, "code": "(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load", "label": 0}, {"snippet_id": 43497, "code": "(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other): return self.name", "label": 0}, {"snippet_id": 27924, "code": "(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] ", "label": 0}, {"snippet_id": 19555, "code": "--module') arg='-m' argv[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS", "label": 0}, {"snippet_id": 93535, "code": "-p %s' & scp %s %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp", "label": 0}, {"snippet_id": 71434, "code": " Lustre filesystem clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base", "label": 0}, {"snippet_id": 76931, "code": " TypeError('Invalid proxytype %s' % proxytype) net.useragent=random.choice(d.ua_list) net.timeout=c.rp_timeout return net def upload_avatar(self, ud): if('avatar_uploaded' in ud[0] and ud[0]['avatar_uploaded']", "label": 0}, {"snippet_id": 86712, "code": " substitution which replaces $JAVA_HOME with the path to an appropriate jvm distribution. :param settings: The jvm platform settings from which to extract the arguments. :type settings::class:`JvmPlatformSettings`", "label": 0}, {"snippet_id": 75368, "code": " interface, method, args, fun, reqid=None): if not reqid: reqid=self.make_reqid() msg=make_req_msg(interface, method, args, reqid) self.set_response_handler(reqid, fun) return msg def make_router_req_msg(self", "label": 0}, {"snippet_id": 85043, "code": "'Scala suffix to be used in `scala_jar` definitions. For example, specifying ' '`2.11` or `2.12.0-RC1` would cause `scala_jar` lookups for artifacts with ' 'those suffixes.') register_scala_compiler_tool", "label": 0}, {"snippet_id": 70533, "code": "=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done(self, node, target): pass def ev_statustarget_failed(self, node, target, rc, message): print \"%s: Failed to status %s %s", "label": 0}, {"snippet_id": 912, "code": "'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser': print(action) username=escape(request.POST.get(\"user\")) ps=subprocess.Popen(['userdel', username],", "label": 0}, {"snippet_id": 63567, "code": ".get('stderr', '') exit_code=run_results.get('returncode', None) lwr_outputs=LwrOutputs.from_status_response(run_results) completed_normally=\\ job_wrapper.get_state() not in[ model.Job.states.ERROR, model", "label": 0}, {"snippet_id": 43527, "code": " __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"", "label": 0}, {"snippet_id": 49620, "code": " in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return", "label": 0}, {"snippet_id": 64432, "code": "] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len", "label": 0}, {"snippet_id": 18439, "code": " RestartServer( self): vimsupport.PostVimMessage( 'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic", "label": 0}, {"snippet_id": 68496, "code": "]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline", "label": 0}, {"snippet_id": 65491, "code": " ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s: Failed to status of FS %s\" %(node, client.fs.fs_name) print \">> %s\" % message class", "label": 0}, {"snippet_id": 20699, "code": ", False) req=self._create_request(command, **args) if self.VERBOSE: msg=parse_message(req) print(' <-', msg) if wait: with self.wait_for_response(req) as resp: self._conn.send(req) resp_awaiter=AwaitableResponse", "label": 0}, {"snippet_id": 73555, "code": ".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format", "label": 0}, {"snippet_id": 75420, "code": ".iden_reqid_map.get_key(reqid) if seqnum==0: self.iden_reqid_map.del_value(iden, reqid) msg=list(iden) msg.append(b'') msg.extend(make_rep_msg(reqid, seqnum, status, answer)) return msg def get_iden(self", "label": 0}, {"snippet_id": 63008, "code": " LwrJobRunner( AsynchronousJobRunner): \"\"\" LWR Job Runner \"\"\" runner_name=\"LWRRunner\" def __init__( self, app, nworkers, transport=None, cache=None, url=None, galaxy_url=DEFAULT_GALAXY_URL): \"\"\"Start the", "label": 0}, {"snippet_id": 17890, "code": " GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout", "label": 0}, {"snippet_id": 22395, "code": " mcpd is up\") rc=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0:", "label": 0}, {"snippet_id": 55273, "code": "))) return True elif list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map", "label": 0}, {"snippet_id": 49130, "code": " self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self", "label": 0}, {"snippet_id": 77693, "code": " if not os.path.isfile(self.bumplimitfile): return with open(self.bumplimitfile, 'rb') as f: self.pc.sets['bumplimit'].update(pickle.loads(f.read())) def save_targets(self): data={ 'targets': targets, ", "label": 0}, {"snippet_id": 85726, "code": " dst in rebases.items()) ) @memoized_method def _compiler_plugins_cp_entries(self): \"\"\"Any additional global compiletime classpath entries for compiler plugins.\"\"\" java_options_src=Java.global_instance(", "label": 0}, {"snippet_id": 30442, "code": " YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found", "label": 0}, {"snippet_id": 49294, "code": "-a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules:", "label": 0}, {"snippet_id": 10257, "code": " _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels", "label": 0}, {"snippet_id": 32456, "code": " _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f", "label": 0}, {"snippet_id": 30659, "code": "=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict(", "label": 0}, {"snippet_id": 31882, "code": ": return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list", "label": 0}, {"snippet_id": 66212, "code": " target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev],", "label": 0}, {"snippet_id": 65423, "code": ".EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776", "label": 0}, {"snippet_id": 30234, "code": " for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names", "label": 0}, {"snippet_id": 57761, "code": " def _update_sortkey(self): try: sortkey=int(self.new_value) if sortkey < 0 or sortkey > 32300: return say_no('New sortkey is out of range[0, 32300].') except ValueError: return say_no('New sortkey is not", "label": 0}, {"snippet_id": 14122, "code": " except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0", "label": 0}, {"snippet_id": 77334, "code": " self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: w=wclass(*args, name='.'.join( (wname,('pr{0}' if type_ else 'th{0}')", "label": 0}, {"snippet_id": 76809, "code": "') parser.add_argument('--stop-on-closed', action='store_true', default=False, help='Forget about closed topics') parser.add_argument('--die-on-neterror', action='store_true', default=False, help='Terminate", "label": 0}, {"snippet_id": 56455, "code": " def env_properties(self): if self.request.GET.get('env_group_id'): return EnvGroup.objects.get(id=self.request.GET['env_group_id']).property.all() return EnvProperty.objects.all() def env_values(self)", "label": 0}, {"snippet_id": 83479, "code": "} if rewrite_parameters: compute_environment=LwrComputeEnvironment( client, job_wrapper, remote_job_config) prepare_kwds[ 'compute_environment']=compute_environment job_wrapper.prepare( **prepare_kwds)", "label": 0}, {"snippet_id": 74166, "code": "\"\"\" benchmark_number_runs=5 benchmark_data_input=\"vcf\" benchmark_dataset=\"\" benchmark_allele_count=False benchmark_PCA=False vcf_to_zarr_config=None def __init__(self, runtime_config=None): \"\"\" Creates", "label": 1}, {"snippet_id": 50703, "code": "(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is", "label": 0}, {"snippet_id": 51138, "code": " def wait_for_files(files, latency_wait=3): \"\"\"Wait for given files to be present in filesystem.\"\"\" files=list(files) get_missing=lambda:[f for f in files if not os.path.exists(f)] missing=get_missing()", "label": 0}, {"snippet_id": 24545, "code": "='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state", "label": 0}, {"snippet_id": 11058, "code": " returned with status %s. I don't know how to handle that.\" %(url, response.status_code) raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime=mtime) class Header(object", "label": 0}, {"snippet_id": 95639, "code": " through all files in input_dir and processes *.vcf.gz files to *.vcf, placed in output_dir. Additionally moves *.vcf files to output_dir Note: This method searches through all subdirectories within input_dir", "label": 0}, {"snippet_id": 27953, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state", "label": 0}, {"snippet_id": 83776, "code": " more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing", "label": 0}, {"snippet_id": 29278, "code": " 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if", "label": 0}, {"snippet_id": 64507, "code": ".has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError(opt) command.parse", "label": 0}, {"snippet_id": 32607, "code": " filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not", "label": 0}, {"snippet_id": 80144, "code": " forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form", "label": 0}, {"snippet_id": 94486, "code": ".debug(\"No custom check specified and got sufficient pid amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug", "label": 0}, {"snippet_id": 54587, "code": ": None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property def rules", "label": 0}, {"snippet_id": 73460, "code": "(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config=conversion_config) def convert_to_zarr(input_vcf_path, output_zarr_path, conversion_config): \"\"\" Converts the original data(VCF) to a", "label": 1}, {"snippet_id": 35254, "code": "\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError(", "label": 1}, {"snippet_id": 86227, "code": " javac_cmd.extend(settings_args) javac_cmd.extend([ '-source', str(settings.source_level), '-target', str(settings.target_level), ]) if self.execution_strategy==self.HERMETIC: javac_cmd.extend([ '-d', ", "label": 0}, {"snippet_id": 52631, "code": "(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing:", "label": 0}, {"snippet_id": 85961, "code": " _JAVAC_PLUGIN_INFO_FILE) with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod def get_args_default(cls, bootstrap_option_values): return('-encoding', 'UTF-8'", "label": 0}, {"snippet_id": 45077, "code": " benchmark): def decorate(ruleinfo): ruleinfo.benchmark=benchmark return ruleinfo return decorate def threads(self, threads): def decorate(ruleinfo): ruleinfo.threads=threads return ruleinfo return decorate", "label": 0}, {"snippet_id": 90358, "code": "*cls._STANDARD_JAVA_DIST_DIRS) def __init__(self, *java_dist_dirs): if len(java_dist_dirs)==0: raise ValueError('Expected at least 1 java dist dir.') self._java_dist_dirs=java_dist_dirs @property def jvm_locations", "label": 0}, {"snippet_id": 27096, "code": "\"\"\" Support for the NetAtmo Weather Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime", "label": 1}, {"snippet_id": 66144, "code": " dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\"", "label": 0}, {"snippet_id": 52695, "code": " omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output)", "label": 0}, {"snippet_id": 6140, "code": ".join(lines)): log.warning(\"It seems the file '%s' is unvalid and doesn't \" \"contain text. Please communicate this file to the Invenio \" \"team.\" % document) line_nb=len(lines) word_nb=0 for line in lines", "label": 1}, {"snippet_id": 35953, "code": " import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards,", "label": 1}, {"snippet_id": 65481, "code": ".dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done(self, node, client): pass def ev_statusclient_failed(self, node, client, rc, message): print \"%s", "label": 0}, {"snippet_id": 23488, "code": " a system user. Will not delete it.\", username) shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password", "label": 0}, {"snippet_id": 53607, "code": " !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name", "label": 0}, {"snippet_id": 7608, "code": " spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches", "label": 0}, {"snippet_id": 32370, "code": ".append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete", "label": 0}, {"snippet_id": 75767, "code": " self.term() raise WorkerInterrupt() self.wz.set_sig_handler(b'WZWorker', b'terminate', term_handler) def resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface", "label": 1}, {"snippet_id": 60465, "code": " Fock, Ket, Squeezed, Thermal, Gaussian) from strawberryfields.ops import(GaussianTransform, Interferometer) from strawberryfields.ops import(BSgate, CKgate, CXgate, CZgate, Dgate, Fouriergate, Kgate, Pgate", "label": 0}, {"snippet_id": 23892, "code": ") iface=ifaces[0] err, output=shellutil.run_get_output('ifconfig ' +iface, chk_err=False) if err: raise OSUtilError(\"Can't get info for interface:{0}\".format(iface)) for line in output.split('\\n'): if line", "label": 0}, {"snippet_id": 86903, "code": "='A dict of option regexes that make up pants\\' supported API for zinc. ' 'Options not listed here are subject to change/removal. The value of the dict ' 'indicates that an option accepts an argument.'", "label": 0}, {"snippet_id": 47176, "code": " in combination: wildcards[name].append(value) return wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self", "label": 0}, {"snippet_id": 23286, "code": "', 1)[0] def route_add(self, net, mask, gateway): \"\"\"Add specified route using tmsh. :param net: :param mask: :param gateway: :return: \"\"\" cmd=(\"/usr/bin/tmsh create net route \" \"{0}/{1} gw{2}\").format", "label": 0}, {"snippet_id": 68118, "code": ".install_eventhandler(None, GlobalStatusEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug", "label": 0}, {"snippet_id": 87140, "code": "() def register_extra_products_from_contexts(self, targets, compile_contexts): compile_contexts=[self.select_runtime_context(compile_contexts[t]) for t in targets] zinc_analysis=self.context.products.get_data", "label": 0}, {"snippet_id": 69000, "code": "=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"", "label": 0}, {"snippet_id": 26507, "code": " update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found", "label": 0}, {"snippet_id": 31093, "code": ".check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{}", "label": 0}, {"snippet_id": 70194, "code": " print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self", "label": 0}, {"snippet_id": 63258, "code": " model.Job.states.QUEUED) except Exception: job_wrapper.fail( \"failure running job\", exception=True) log.exception(\"failure running job %d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState", "label": 0}, {"snippet_id": 95683, "code": ": The output directory where processed *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir=str(temp_dir) output_dir=str(output_dir", "label": 0}, {"snippet_id": 63985, "code": "\"dependency_resolution\", \"local\") if dependency_resolution not in[\"none\", \"local\", \"remote\"]: raise Exception(\"Unknown dependency_resolution value encountered %s\" % dependency_resolution) return dependency_resolution", "label": 0}, {"snippet_id": 40110, "code": " os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root,", "label": 0}, {"snippet_id": 75879, "code": "() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request", "label": 0}, {"snippet_id": 75554, "code": " if not reqid: reqid=self.make_reqid() args=[interface, method, struct.pack('!B', type_), make_auth_hash(interface, method, reqid, key)] return(b'Router', b'auth-set-route-type', args, reqid) def make_auth_clear_data", "label": 0}, {"snippet_id": 20442, "code": " with socket_timeout(server, timeout): client, _=server.accept() return Connection(client, server) return cls._create(connect, addr, **kwargs) @classmethod def _create(cls, connect, addr, timeout=None):", "label": 0}, {"snippet_id": 42699, "code": " self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return", "label": 0}, {"snippet_id": 77442, "code": " name='.'.join((wname, 'th{0}'.format(i)))) self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: w=workers.WZWorkerProcess(self.c.router_addr, fun, args, kvargs, name='.'.join((wname, ", "label": 0}, {"snippet_id": 21151, "code": ", name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message='Timeout waiting for ' if isinstance(self, AwaitableEvent", "label": 0}, {"snippet_id": 57581, "code": " field=self.target_field, value=self.new_value) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context']['user']=self.request.user try: mailto(**mail_context) except Exception:", "label": 0}, {"snippet_id": 22388, "code": " 100): logger.info(\"Checking to see if mcpd is up\") rc=shellutil.run(\"/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is", "label": 0}, {"snippet_id": 5257, "code": "[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted", "label": 0}, {"snippet_id": 56520, "code": " internal_parameters) q_app_form=request.GET.get('app_form') q_format=request.GET.get('format') if not q_format: q_format='p' if not q_app_form: return HttpResponse('Unrecognizable app_form') q_app, q_form", "label": 1}, {"snippet_id": 52829, "code": "}\".format( self, \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables", "label": 0}, {"snippet_id": 47131, "code": " yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self", "label": 1}, {"snippet_id": 37727, "code": ", wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception,", "label": 0}, {"snippet_id": 91481, "code": " builtins import str from future.utils import text_type from pants.backend.python.rules.inject_init import InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest from pants.backend.python", "label": 0}, {"snippet_id": 33055, "code": "-a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException() if not name in self._rules:", "label": 0}, {"snippet_id": 21258, "code": "('href')] new_links=[x for x in links if re.match(\"^https://youtu\\.be\", x)] newer_links=[x for x in links if re.match(\"^https://www\\.youtube\\.com/watch\", x)] for lk in newer_links: videolabel=re.search", "label": 0}, {"snippet_id": 84379, "code": "=job_wrapper.default_compute_environment() self.unstructured_path_rewrites={} self._wrapper_input_paths=self.local_path_config.input_paths() self._wrapper_output_paths=self.local_path_config.output_paths() self", "label": 0}, {"snippet_id": 50717, "code": "(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass", "label": 0}, {"snippet_id": 46578, "code": ", i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__", "label": 0}, {"snippet_id": 7508, "code": " list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +=\"\\n\\n{0}:\\n\".format(result) for element in list_result_sorted", "label": 0}, {"snippet_id": 51797, "code": ") self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items", "label": 0}, {"snippet_id": 79804, "code": ". Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known", "label": 0}, {"snippet_id": 9534, "code": " list of composite keywords :var author_keywords: dictionary of extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean, True=generate spires output -BUT NOTE: it is here only", "label": 0}, {"snippet_id": 23832, "code": " chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac or 'None,None,None' if unable to parse. We", "label": 0}, {"snippet_id": 31969, "code": ".name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of", "label": 0}, {"snippet_id": 87513, "code": " upstream_analysis.items())]) zinc_args.extend(self._zinc.rebase_map_args) zinc_args.extend(args) zinc_args.extend(self._get_zinc_arguments(settings)) zinc_args.append('-transactional') for option_set in", "label": 0}, {"snippet_id": 46688, "code": ".YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not found.\".format(configpath)) def load_configfile(configpath): \"Loads", "label": 0}, {"snippet_id": 84184, "code": "\"\"\" When setting remote metadata, use integrated datatypes from this Galaxy instance or use the datatypes config configured via the remote LWR. Both options are broken in different ways for same reason", "label": 0}, {"snippet_id": 66140, "code": ".dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA) elif target.dev_size >=MEGA: dev_size=\"%.1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\"", "label": 0}, {"snippet_id": 25923, "code": " elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0)\" ", "label": 0}, {"snippet_id": 2860, "code": ".comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s", "label": 0}, {"snippet_id": 63962, "code": " remote_dependency_resolution: return None requirements=job_wrapper.tool.requirements or[] installed_tool_dependencies=job_wrapper.tool.installed_tool_dependencies or[] return dependencies.DependenciesDescription(", "label": 0}, {"snippet_id": 74707, "code": ".chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"chunk_width\" in runtime_config.vcf_to_zarr:", "label": 0}, {"snippet_id": 24107, "code": " more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from", "label": 1}, {"snippet_id": 74194, "code": " extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config", "label": 0}, {"snippet_id": 27565, "code": "'sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure'", "label": 0}, {"snippet_id": 17108, "code": ") if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__", "label": 0}, {"snippet_id": 93511, "code": "(TMP_COMP_DIR, comp)) ensure_dir(tmp_comp_path) with open(tmp_comp_path, 'w') as outfile: dump(infile, outfile, default_flow_style=False) self.logger.debug('Copying component \"%s\" to remote host \"%s\"' %(comp", "label": 0}, {"snippet_id": 17211, "code": " signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'", "label": 0}, {"snippet_id": 16951, "code": ".post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5,", "label": 1}, {"snippet_id": 47319, "code": " \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output", "label": 0}, {"snippet_id": 24645, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500:", "label": 0}, {"snippet_id": 11798, "code": "': 1},{'k1':{'k2':{'k3': 3}}}) Source: http://stackoverflow.com/a/32357112/4698026 \"\"\" for key, value in head.items(): if isinstance(base, collections.Mapping): if isinstance(value, collections.Mapping", "label": 1}, {"snippet_id": 54356, "code": "*rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1", "label": 0}, {"snippet_id": 53316, "code": ".wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True):", "label": 0}, {"snippet_id": 61590, "code": " operator_map[A.name](*p) def ev(self, A, wires): r\"\"\"Expectation value of a one-qubit observable in the current state. Args: A(array): 2*2 hermitian matrix corresponding to the observable wires(Sequence[int", "label": 0}, {"snippet_id": 87816, "code": "'part of the JDK.{} is not.'.format(path)) if path !=os.path.normpath(path): raise TaskError('Classpath entries provided to zinc should be normalized ' '(i.e. without \"..\" and \".\").{} is not.'.format(path", "label": 0}, {"snippet_id": 79495, "code": " valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t", "label": 1}, {"snippet_id": 36493, "code": " \"\"\" Prepare execution of job. This includes creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output", "label": 0}, {"snippet_id": 78326, "code": ".schedule_first(self.switch_user) except exc.EmptyAnswer as e: self.log.info('Removing %s from targets', t) try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except", "label": 1}, {"snippet_id": 1648, "code": "(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username if enc_pwd in[\"LK\", \"*\"]: output=\"account is locked\" if enc_pwd==\"!!\": output=\"password has expired\" if crypt", "label": 0}, {"snippet_id": 59330, "code": " end of the circuit). user(string): IBM Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True.", "label": 0}, {"snippet_id": 66507, "code": ": RC_OK, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result", "label": 0}, {"snippet_id": 91721, "code": "): tgt_snapshot=maybe_source_target.sources.snapshot tgt_source_root=source_roots.find_by_path(maybe_source_target.address.spec_path) sources_snapshots_and_source_roots.append((tgt_snapshot, tgt_source_root", "label": 0}, {"snippet_id": 21144, "code": " waiting for{}'.format(','.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout)", "label": 0}, {"snippet_id": 4348, "code": " get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache", "label": 0}, {"snippet_id": 43850, "code": ".format(name)) rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name", "label": 0}, {"snippet_id": 38178, "code": " os import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake", "label": 0}, {"snippet_id": 12771, "code": " response=requests.patch(query, json={\"body\": comment}, headers=headers, auth=auth) def autopep8(data, config): headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"],", "label": 0}, {"snippet_id": 66345, "code": " +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable()", "label": 0}, {"snippet_id": 5493, "code": " :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes={} output={} for skw, _ in skw_matches: for fieldcode in skw.fieldcodes: fieldcodes", "label": 0}, {"snippet_id": 64302, "code": " wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite( wrapper_path) results.append( self._dataset_path( local_input_path, remote_path)) return results def _dataset_path", "label": 0}, {"snippet_id": 61253, "code": "(U.shape[0]), atol=tolerance): raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args(array): square hermitian", "label": 0}, {"snippet_id": 48794, "code": " self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self", "label": 0}, {"snippet_id": 89488, "code": " minimum_version=None, maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param string home_path:", "label": 0}, {"snippet_id": 37088, "code": ".shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output", "label": 0}, {"snippet_id": 4325, "code": " api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" % local_file)", "label": 1}, {"snippet_id": 83033, "code": " KeyboardInterrupt \texcept KeyboardInterrupt: \t\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging", "label": 0}, {"snippet_id": 69820, "code": " print \"%s: Failed to mount FS %s on %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand", "label": 0}, {"snippet_id": 46529, "code": " end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index", "label": 0}, {"snippet_id": 81744, "code": " Lock version=\"0.5.0\" logging.basicConfig(datefmt='[%m/%d/%Y-%H:%M:%S]') logger=logging.getLogger(\"fuxploider\") coloredlogs.install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging", "label": 0}, {"snippet_id": 72484, "code": ".ArgumentParser(description=\"A benchmark for genomics routines in Python.\") subparser=parser.add_subparsers(title=\"commands\", dest=\"command\") subparser.required=True config_parser=subparser.add_parser(\"config\",", "label": 0}, {"snippet_id": 79758, "code": "],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use with HTTP requests. Example", "label": 0}, {"snippet_id": 4139, "code": " import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url", "label": 1}, {"snippet_id": 42204, "code": "=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output", "label": 0}, {"snippet_id": 5904, "code": " field=str(field) if len(field) < 4: raise Exception('Wrong field code: %s' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2", "label": 0}, {"snippet_id": 57843, "code": "' % self.new_value raise ObjectDoesNotExist(err_msg) self.get_update_targets().update(**{str(self.target_field): reviewers[0]}) @require_POST def update_cases_default_tester(request): \"\"\"Update default", "label": 0}, {"snippet_id": 43877, "code": " of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self._rules: raise NoRulesException()", "label": 0}, {"snippet_id": 27899, "code": " elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" ", "label": 0}, {"snippet_id": 56625, "code": ".annotate(num_plans=Count('tag')).order_by('tag') test_case_tags=TestCaseTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_cases=Count('tag')).order_by('tag') test_run_tags=TestRunTag.objects", "label": 0}, {"snippet_id": 45479, "code": " file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def", "label": 1}, {"snippet_id": 43660, "code": " touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None,", "label": 1}, {"snippet_id": 81902, "code": "\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar=\"omnomnom\",nargs=1,dest=\"cookies\",help=\"Cookies to use", "label": 0}, {"snippet_id": 33304, "code": " if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is", "label": 0}, {"snippet_id": 41825, "code": " existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested", "label": 0}, {"snippet_id": 31958, "code": " SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item", "label": 0}, {"snippet_id": 86892, "code": " False, '-C.*': False, '-file-filter': True, '-msg-filter': True, }, help='A dict of option regexes that make up pants\\' supported API for zinc. ' 'Options not listed here are subject to change/removal", "label": 0}, {"snippet_id": 82292, "code": " manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name=\\\"image\\\">\") manualFormArgs.add_argument(\"--form-action\",default=\"", "label": 0}, {"snippet_id": 45537, "code": " ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod", "label": 0}, {"snippet_id": 22768, "code": " of the built-in 'admin' account, both must be modified in this method. Note that the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our", "label": 0}, {"snippet_id": 64506, "code": " command.has_subcommand(): new_args.append(opt) else: raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError(opt", "label": 0}, {"snippet_id": 55247, "code": "() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary", "label": 0}, {"snippet_id": 95352, "code": ".prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory", "label": 0}, {"snippet_id": 94974, "code": "\"FILEPATH\") config_parser.add_argument(\"-f\", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting", "label": 0}, {"snippet_id": 48907, "code": " < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self.name.__hash__() def __eq__(self, other", "label": 0}, {"snippet_id": 90072, "code": "=line.partition('=') props[key]=val self._system_properties=props return self._system_properties def _validate_executable(self, name): def bin_paths(): yield self._bin_path if self._is_jdk: yield os.path", "label": 0}, {"snippet_id": 43825, "code": "=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format", "label": 0}, {"snippet_id": 25048, "code": "=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data", "label": 0}, {"snippet_id": 95964, "code": "[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.\") callset=allel.read_vcf(input_vcf_path, fields=['numalt'], log=sys.stdout) numalt=callset['variants/numalt'", "label": 0}, {"snippet_id": 33128, "code": "._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False", "label": 0}, {"snippet_id": 64602, "code": " %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print ", "label": 0}, {"snippet_id": 44310, "code": "=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files", "label": 0}, {"snippet_id": 81894, "code": " parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"],dest=\"size\",help=\"File size to use for files to be created and uploaded(in kB).\") parser.add_argument(\"--cookies\",metavar", "label": 0}, {"snippet_id": 54921, "code": "=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules", "label": 0}, {"snippet_id": 76296, "code": " in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep", "label": 0}, {"snippet_id": 56916, "code": ":`tcms.management.models.Tag` :return: the number of times a tag is assigned to object :rtype: int \"\"\" if self.counter['tag'] !=tag.pk: try: self.counter=self.test_tags.__next__() except StopIteration:", "label": 0}, {"snippet_id": 12279, "code": "][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int", "label": 0}, {"snippet_id": 61409, "code": "\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self._state is None: self._state=np.zeros(2**self.wires, dtype=complex) self._state[0]=1 self._out=np.full(self.wires, np", "label": 0}, {"snippet_id": 73217, "code": " of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. :param output_dir: The output directory where processed", "label": 0}, {"snippet_id": 82970, "code": "[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent", "label": 1}, {"snippet_id": 58875, "code": " cls.case_update_url=reverse('ajax-update_cases_default_tester') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self", "label": 0}, {"snippet_id": 90269, "code": " jdk_home=env_home('JDK_HOME') if jdk_home: yield jdk_home java_home=env_home('JAVA_HOME') if java_home: yield java_home search_path=os.environ.get('PATH') if search_path: for bin_path in search_path.strip()", "label": 0}, {"snippet_id": 10504, "code": " import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener", "label": 1}, {"snippet_id": 72445, "code": " import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a", "label": 1}, {"snippet_id": 65526, "code": " def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ ", "label": 0}, {"snippet_id": 52452, "code": ".message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex", "label": 0}, {"snippet_id": 36536, "code": " self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self.output", "label": 0}, {"snippet_id": 83702, "code": "*get_client_kwds) def finish_job( self, job_state): stderr=stdout='' job_wrapper=job_state.job_wrapper try: client=self.get_client_from_state(job_state) run_results=client.full_status() stdout=run_results", "label": 0}, {"snippet_id": 46441, "code": "-a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\"", "label": 0}, {"snippet_id": 9353, "code": " keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches", "label": 0}, {"snippet_id": 64647, "code": " Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 87331, "code": " it. \"\"\" hasher=sha1() for cp_entry in[self._zinc.zinc, self._zinc.compiler_interface, self._zinc.compiler_bridge]: hasher.update(os.path.relpath(cp_entry, self.get_options().pants_workdir)) key=hasher", "label": 1}, {"snippet_id": 27235, "code": "], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle'", "label": 0}, {"snippet_id": 9676, "code": "[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags=False, limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER", "label": 0}, {"snippet_id": 65276, "code": ")) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options={} mount_paths={} for target_type in[ 'mgt", "label": 0}, {"snippet_id": 90211, "code": " \"\"\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable. :returns: The java distribution location. \"\"\" return cls(home_path", "label": 0}, {"snippet_id": 13741, "code": ".globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key]=value def __getitem__(self, key): return self.locals[key] def __delitem__", "label": 0}, {"snippet_id": 51260, "code": " be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append(\"(?P<{}>{})\".format(wildcard, match.group(\"constraint", "label": 0}, {"snippet_id": 85619, "code": " str \"\"\" return self._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list of str \"\"\" return self._zinc_factory.dist @memoized_property", "label": 0}, {"snippet_id": 58922, "code": ", {'rc': 1, 'response': \"You don't have enough permission to \" \"update TestCases.\"}) def test_update_case_priority(self): self.client.login( username=self.tester.username, password='password') response", "label": 0}, {"snippet_id": 82493, "code": "\targs.legitExtensions=args.legitExtensions[0].split(\",\") if args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"", "label": 0}, {"snippet_id": 48312, "code": ".add(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append", "label": 0}, {"snippet_id": 41224, "code": " class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try", "label": 0}, {"snippet_id": 71453, "code": " import FSClientLiveCommand from Base.CommandRCDefs import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from", "label": 0}, {"snippet_id": 15572, "code": ".Start() def OnBufferUnload( self, deleted_buffer_file): if not self._IsServerAlive(): return SendEventNotificationAsync( 'BufferUnload', { 'unloaded_buffer': deleted_buffer_file}) def OnBufferVisit( self", "label": 0}, {"snippet_id": 71752, "code": " cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print", "label": 0}, {"snippet_id": 44907, "code": "(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance", "label": 0}, {"snippet_id": 55410, "code": " for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n", "label": 0}, {"snippet_id": 81030, "code": "\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\") \t\t\tif initGet.status_code < 200 or initGet.status_code > 300: \t\t\t\tself.logger.critical(\"Server responded with following status", "label": 0}, {"snippet_id": 3230, "code": " dep in node.component['depends']: if dep not in self.nodes: deps.node(dep, color=\"red\") deps.edge(node.comp_name, dep, \"missing\", color=\"red\") elif node.comp_name is not \"master_node\": deps.edge(node.comp_name", "label": 0}, {"snippet_id": 28425, "code": ".netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement", "label": 0}, {"snippet_id": 84327, "code": ".__use_remote_datatypes_conf( client): remote_datatypes_config=remote_system_properties.get('galaxy_datatypes_config_file', None) if not remote_datatypes_config: log.warn(NO_REMOTE_DATATYPES_CONFIG) remote_datatypes_config=os", "label": 0}, {"snippet_id": 93958, "code": "-t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command(self.session, cmd) def start_clone_session(self, comp_name, session_name): cmd=\"%s '%s' '%s'\" %(SCRIPT_CLONE_PATH, session_name,", "label": 0}, {"snippet_id": 41690, "code": " while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill", "label": 0}, {"snippet_id": 82919, "code": ".validExtensions: \t\t\t\tlegitMime=getMime(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant", "label": 1}, {"snippet_id": 7328, "code": " ' <subfield code=\"a\">%s</subfield>\\n' ' <subfield code=\"n\">%s</subfield>\\n' ' <subfield code=\"9\">%s</subfield>\\n' '</datafield>\\n') output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in", "label": 0}, {"snippet_id": 26488, "code": " state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement", "label": 0}, {"snippet_id": 14814, "code": "'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']=BuildExtraConfData( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return", "label": 0}, {"snippet_id": 71774, "code": " msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e", "label": 0}, {"snippet_id": 37338, "code": ": self._set_inoutput_item(item, output=True, name=name) for item in self.output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define", "label": 0}, {"snippet_id": 73103, "code": "=remote_subdirs_list.copy() new_remote_subdirs_list.append(file) fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list", "label": 0}, {"snippet_id": 33451, "code": " on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows", "label": 0}, {"snippet_id": 31046, "code": ".add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self)", "label": 0}, {"snippet_id": 13512, "code": " fullMsg=\"\"\r \r MOUTH_OPEN=408 MOUTH_CLOSE=412 EYES_OPEN=410 EYES_CLOSE=414 \r io=GPIO() io.setup( MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning", "label": 0}, {"snippet_id": 1294, "code": " ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry)", "label": 0}, {"snippet_id": 56365, "code": ".values(field): response_str +='<li>' +obj_value.get(field, None) +'</li>' response_str +='</ul>' return HttpResponse(response_str) return HttpResponse(serializers.serialize('json', info_type(), fields", "label": 0}, {"snippet_id": 95379, "code": "=len(ftp_config.files) for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath,", "label": 0}, {"snippet_id": 62725, "code": " run timed out). \"\"\" short_name='projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT,", "label": 0}, {"snippet_id": 72405, "code": ": irc.error('Not enough arguments(needs 1: protocol module name)') return proto=utils.getProtocolModule(name) importlib.reload(proto) irc.reply(\"Done. You will have to manually disconnect and reconnect", "label": 0}, {"snippet_id": 90785, "code": " as e: logger.debug('{} is not a valid distribution because:{}' .format(location.home_path, str(e))) pass if(minimum_version is not None and maximum_version is not None and maximum_version < minimum_version", "label": 0}, {"snippet_id": 13193, "code": ".status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def create_new_branch(data): url=\"https://api.github.com/repos/{}/git/refs/heads\" url=url.format(data[\"fork_fullname\"]) headers={", "label": 0}, {"snippet_id": 14198, "code": " EventNotification) from ycm.server.responses import ServerError try: from UltiSnips import UltiSnips_Manager USE_ULTISNIPS_DATA=True except ImportError: USE_ULTISNIPS_DATA=False os.environ['no_proxy']", "label": 0}, {"snippet_id": 83038, "code": "\tstopThreads=True \t\texecutor.shutdown(wait=False) \t\texecutor._threads.clear() \t\tconcurrent.futures.thread._threads_queues.clear() \t\tlogger.setLevel(logging.CRITICAL) \t\tlogger.verbosity=-1 d=datetime.datetime", "label": 0}, {"snippet_id": 76885, "code": " terminate_handler(signal, frame): terminate() signal.signal(signal.SIGINT, interrupt_handler) signal.signal(signal.SIGTERM, terminate_handler) def make_net(proxy, proxytype): net=sup.net.RequestPerformer()", "label": 0}, {"snippet_id": 85775, "code": " in classpaths] @memoized_property def extractor(self): return self._zinc_factory.tool_classpath_from_products(self._products, self.ZINC_EXTRACTOR_TOOL_NAME, scope=self._zinc_factory.options_scope) def", "label": 0}, {"snippet_id": 63622, "code": " outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing job %d\" ", "label": 0}, {"snippet_id": 8372, "code": " is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read", "label": 0}, {"snippet_id": 42759, "code": ".output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names()", "label": 0}, {"snippet_id": 51045, "code": "(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names(self.file) def contains_wildcard", "label": 1}, {"snippet_id": 28628, "code": " data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full", "label": 0}, {"snippet_id": 63347, "code": "=LwrJobRunner.__dependency_resolution( client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config", "label": 0}, {"snippet_id": 35108, "code": "(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict(", "label": 0}, {"snippet_id": 65245, "code": " RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target", "label": 0}, {"snippet_id": 55286, "code": "(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list", "label": 0}, {"snippet_id": 56559, "code": " q_app_module=sys.modules['tcms.%s.forms' % q_app] form_class=getattr(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html())", "label": 1}, {"snippet_id": 86980, "code": " unset by default, because it is generally a good precaution to cache ' 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies()", "label": 0}, {"snippet_id": 31796, "code": " branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self)", "label": 0}, {"snippet_id": 49976, "code": "(cores)) logger.resources_info(\"Rules claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources", "label": 0}, {"snippet_id": 58915, "code": " }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': \"You don't have enough permission to \" \"update TestCases.\"}) def test_update_case_priority(self", "label": 0}, {"snippet_id": 51667, "code": " filesystem. Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start", "label": 0}, {"snippet_id": 69259, "code": " \"Syntax error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print ", "label": 1}, {"snippet_id": 7592, "code": " </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword", "label": 0}, {"snippet_id": 46453, "code": " name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield", "label": 0}, {"snippet_id": 84696, "code": " directory_digest=self.context._scheduler.merge_directories(tuple(s.directory_digest for s in input_snapshots +( cloc_snapshot, list_file_snapshot, ))) cmd=( '/usr/bin/perl', cloc_path, '--skip-uniqueness', ", "label": 0}, {"snippet_id": 32014, "code": " _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output", "label": 0}, {"snippet_id": 1254, "code": " nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row", "label": 0}, {"snippet_id": 70879, "code": " AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"", "label": 0}, {"snippet_id": 41435, "code": ".wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self", "label": 0}, {"snippet_id": 64572, "code": " print \"Bad argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes", "label": 1}, {"snippet_id": 61847, "code": ":**:mod:`openqml.plugins.projectq` .. currentmodule:: openqml.plugins.projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with", "label": 0}, {"snippet_id": 55099, "code": " no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os", "label": 0}, {"snippet_id": 59597, "code": "='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def _deallocate2(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because:", "label": 0}, {"snippet_id": 37807, "code": " if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names", "label": 0}, {"snippet_id": 22530, "code": " would hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of the hostname argument to this method. The problem is that there is nowhere", "label": 0}, {"snippet_id": 1494, "code": ".get_or_create(name=request_name,address=request_address,icon=request_icon) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='getSchema': schema=get_osversion() return JsonResponse({\"version_info", "label": 0}, {"snippet_id": 24017, "code": " and 'storvscX' to find device name \"\"\" output=output.rstrip() cmd_search_blkvsc=\"camcontrol devlist -b | grep blkvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc", "label": 0}, {"snippet_id": 46366, "code": "): \"\"\" Create the object. Arguments toclone --another Namedlist that shall be cloned fromdict --a dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict", "label": 0}, {"snippet_id": 59646, "code": " to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend", "label": 0}, {"snippet_id": 91141, "code": ".backend.python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements import PythonRequirements from pants", "label": 0}, {"snippet_id": 22286, "code": " azurelinuxagent.common.osutil.default import DefaultOSUtil except ImportError: import azurelinuxagent.logger as logger import azurelinuxagent.utils.shellutil as shellutil from azurelinuxagent.exception", "label": 0}, {"snippet_id": 10468, "code": ". Currently 2 formats of documents are supported: PDF and text documents. 2 methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides", "label": 0}, {"snippet_id": 59300, "code": " True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in", "label": 0}, {"snippet_id": 3469, "code": " self.kill_mode: self.logger.info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window", "label": 0}, {"snippet_id": 974, "code": ", safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen", "label": 0}, {"snippet_id": 30054, "code": " Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames,", "label": 0}, {"snippet_id": 9994, "code": "=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches.items(): matches_str.append(ckw.output(spires)) for skw, spans in skw_matches.items(): matches_str.append(skw.output(spires)", "label": 0}, {"snippet_id": 23428, "code": " 'username' \"\"\" userentry=self.get_userentry(username) if userentry is not None: logger.warn(\"User{0} already exists, skip useradd\", username) return if expiration is not None: cmd=\"pw useradd{0} -e{1}", "label": 0}, {"snippet_id": 24492, "code": " state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement", "label": 0}, {"snippet_id": 50256, "code": "=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if", "label": 0}, {"snippet_id": 17489, "code": ") return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self)", "label": 0}, {"snippet_id": 13584, "code": " EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN", "label": 0}, {"snippet_id": 4804, "code": " output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={}", "label": 0}, {"snippet_id": 25665, "code": "\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self", "label": 0}, {"snippet_id": 42616, "code": " if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch,", "label": 0}, {"snippet_id": 46430, "code": " set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else", "label": 0}, {"snippet_id": 78944, "code": "\t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1:", "label": 0}, {"snippet_id": 4201, "code": ": %s\" % source) output=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords", "label": 0}, {"snippet_id": 85197, "code": " specified, then the version specified in ' '--scala-suffix-version is used. For example for Scala ' '2.10.7 you would use the suffix version \"2.10\".') elif name.endswith(self.version): raise ValueError", "label": 0}, {"snippet_id": 28064, "code": "=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self)", "label": 1}, {"snippet_id": 93653, "code": ". comp name '%s'\" %(node.comp_name, comp['name'])) if node.comp_name !=comp['name']: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is", "label": 0}, {"snippet_id": 23645, "code": "/dhclient start{0}\".format(self.get_if_name()), chk_err=False) def allow_dhcp_broadcast(self): pass def set_route_for_dhcp_broadcast(self, ifname): return shellutil.run(\"route add 255.255.255.255 -iface", "label": 0}, {"snippet_id": 89486, "code": " bin_path=None, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or `bin_path`. Only one of `home_path` or `bin_path` should be supplied. :param", "label": 0}, {"snippet_id": 64952, "code": " import Globals from Shine.Configuration.Exceptions import * from Shine.Commands.Status import Status from Shine.Commands.Tune import Tune from Base.FSLiveCommand import FSLiveCommand from Base.FSEventHandler", "label": 0}, {"snippet_id": 85423, "code": " super(Zinc.Factory, cls).subsystem_dependencies() +(DependencyContext, Java, ScalaPlatform) @classmethod def register_options(cls, register): super(Zinc.Factory, cls).register_options(register) zinc_rev", "label": 0}, {"snippet_id": 5420, "code": " expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False): \"\"\"Format the output for the author keywords. :return: list", "label": 0}, {"snippet_id": 52191, "code": " import os import sys import base64 import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile,", "label": 1}, {"snippet_id": 94656, "code": " directory=os.path.dirname(file_path) if not os.path.exists(directory): os.makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser(", "label": 0}, {"snippet_id": 92166, "code": "('--setuptools-version', advanced=True, fingerprint=True, default='40.6.3', help='The setuptools version to use when executing `setup.py` scripts.') register('--wheel-version', advanced=True, fingerprint", "label": 0}, {"snippet_id": 15149, "code": ".completers.all.omni_completer import OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive", "label": 0}, {"snippet_id": 13889, "code": " def __init__( self): pass def Start( self): pass def Done( self): return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture", "label": 0}, {"snippet_id": 26336, "code": ".netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try: if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items():", "label": 1}, {"snippet_id": 71039, "code": " c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(", "label": 0}, {"snippet_id": 81076, "code": "(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit() \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical(\"%s forms found containing file upload inputs", "label": 0}, {"snippet_id": 4652, "code": " object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader.KeywordToken for k, v in acronymer.get_acronyms(fulltext).items(): acronyms[K(k, type='acronym')]=v return acronyms def extract_author_keywords", "label": 0}, {"snippet_id": 89943, "code": ": self._validated_executable('javac') self._is_jdk=True except self.Error as e: if self._jdk: logger.debug('Failed to validate javac executable. Please check you have a JDK ' 'installed. Original error", "label": 0}, {"snippet_id": 58625, "code": "('ajax-update') def setUp(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): self.client.login( username=self.tester.username, password='password') remove_perm_from_user", "label": 0}, {"snippet_id": 73933, "code": " runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"vcf_to_zarr\"): if \"enabled", "label": 0}, {"snippet_id": 852, "code": ".communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0], 'container_name': i[1", "label": 0}, {"snippet_id": 22782, "code": " level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user accounts have the UID 0. So we can't rely on this value. :param username: The username whose password to change", "label": 0}, {"snippet_id": 82142, "code": "\") exclusiveVerbosityArgs.add_argument(\"-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required", "label": 0}, {"snippet_id": 60492, "code": " Zgate) from strawberryfields.ops import(MeasureFock, MeasureHeterodyne, MeasureHomodyne) from._version import __version__ operator_map={ 'CoherentState': Coherent, 'DisplacedSqueezed': DisplacedSqueezed, ", "label": 0}, {"snippet_id": 23328, "code": " not have yet initialized this list of devices. :param port_id: :return: \"\"\" for retries in range(1, 100): if os.path.exists(\"/sys/bus/vmbus/devices/\"): break else: time.sleep(10) return super(BigIpOSUtil", "label": 0}, {"snippet_id": 11944, "code": "\"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment\": True, \"only_mention_files_with_errors\": True, } headers", "label": 0}, {"snippet_id": 95328, "code": " from a remote ftp server. :type ftp_config: config.FTPConfigurationRepresentation :type local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree(local_directory) if ftp_config.use_tls: ftp", "label": 0}, {"snippet_id": 17396, "code": " _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open( self._server_stderr, 'r') as server_stderr_file", "label": 0}, {"snippet_id": 74556, "code": " else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types", "label": 0}, {"snippet_id": 35667, "code": ", index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self): next=0 for name, index in sorted", "label": 0}, {"snippet_id": 74777, "code": "\"blosc_compression_level\"] if isint(blosc_compression_level_str): compression_level_int=int(blosc_compression_level_str) if(compression_level_int >=0) and(compression_level_int <=9): self.blosc_compression_level", "label": 0}, {"snippet_id": 35287, "code": "*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values", "label": 0}, {"snippet_id": 70117, "code": ", \\ target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of", "label": 0}, {"snippet_id": 51628, "code": " Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join", "label": 0}, {"snippet_id": 3720, "code": " but the check succeeded\") return CheckState.STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid", "label": 0}, {"snippet_id": 33502, "code": " workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files=updated): return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}:", "label": 0}, {"snippet_id": 11915, "code": " config file from the repository and return the config dictionary \"\"\" config={ \"message\":{ \"opened\":{ \"header\": \"\", \"footer\": \"\" }, \"updated\":{ \"header\": \"\", \"footer\": \"\" } }, \"scanner\":{\"diff_only\": False", "label": 0}, {"snippet_id": 4067, "code": " output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which", "label": 0}, {"snippet_id": 58748, "code": ".permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission) self.client.login( username=self.tester.username, password='password') response=self.client.post", "label": 0}, {"snippet_id": 47326, "code": " previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning", "label": 0}, {"snippet_id": 92614, "code": " test_temporary_dir_no_args(self): with temporary_dir() as path: self.assertTrue(os.path.exists(path), 'Temporary dir should exist within the context.') self.assertTrue(os.path.isdir(path), 'Temporary dir should be a dir and", "label": 0}, {"snippet_id": 67313, "code": " system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def", "label": 0}, {"snippet_id": 10548, "code": " executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output", "label": 0}, {"snippet_id": 62897, "code": "-1)) for i in range(len(self.reg))] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(\"Estimation of expectation values not yet implemented for the observable{} in backend{}", "label": 0}, {"snippet_id": 24166, "code": ") SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise", "label": 1}, {"snippet_id": 32689, "code": " self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 ", "label": 0}, {"snippet_id": 45923, "code": ".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not", "label": 0}, {"snippet_id": 68356, "code": ", fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=", "label": 0}, {"snippet_id": 42195, "code": ".updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(", "label": 0}, {"snippet_id": 38925, "code": ".target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup", "label": 0}, {"snippet_id": 29974, "code": "**wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard", "label": 0}, {"snippet_id": 27139, "code": " import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=", "label": 1}, {"snippet_id": 25513, "code": " the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name", "label": 0}, {"snippet_id": 74404, "code": " return True except ValueError: return False class ConfigurationRepresentation(object): \"\"\" A small utility class for object representation of a standard config. file. \"\"\" def __init__(self, file_name): ", "label": 0}, {"snippet_id": 13004, "code": "=headers, auth=auth).json() data[\"gist_response\"]=res data[\"gist_url\"]=res[\"html_url\"] def delete_if_forked(data): FORKED=False url=\"https://api.github.com/user/repos\" headers={\"Authorization\": \"token \"", "label": 0}, {"snippet_id": 59784, "code": "(**self.filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend) super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX'", "label": 0}, {"snippet_id": 94329, "code": " def run_check(self): if not self.config: self.logger.error(\" Config not loaded yet!\") exit(CheckState.STOPPED.value) elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit", "label": 0}, {"snippet_id": 41585, "code": "\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files. Input files need to be present. \"\"\" if self._inputsize is None: self._inputsize=sum(f.size for f in self", "label": 0}, {"snippet_id": 24687, "code": " self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium", "label": 0}, {"snippet_id": 4233, "code": " output else: if isinstance(output, dict): for i in output: print(output[i]) for entry in input_sources: log.info(\"Trying to read input file %s.\" % entry) text_lines=None source=\"\" if os.path.isdir(entry", "label": 0}, {"snippet_id": 73077, "code": ") file_counter=1 file_list_total=len(file_list) for file in file_list: file_path_local=local_directory +\"/\" +remote_path_relative +\"/\" +file if not os.path.isfile(file_path_local): try: ftp.cwd(remote_path_absolute", "label": 0}, {"snippet_id": 1732, "code": " print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action", "label": 0}, {"snippet_id": 13154, "code": " auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json={ \"name\": name, ", "label": 0}, {"snippet_id": 21525, "code": ")) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link", "label": 1}, {"snippet_id": 95661, "code": " within input_dir, and files are placed in root of output_dir. :param input_dir: The input directory containing files to process :param temp_dir: The temporary directory for unzipping *.gz files, etc. ", "label": 0}, {"snippet_id": 85863, "code": ".java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin", "label": 0}, {"snippet_id": 91505, "code": " import(Digest, DirectoriesToMerge, DirectoryWithPrefixToStrip, Snapshot, UrlToFetch) from pants.engine.isolated_process import(ExecuteProcessRequest, ExecuteProcessResult, FallibleExecuteProcessResult)", "label": 0}, {"snippet_id": 48058, "code": ". \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def", "label": 0}, {"snippet_id": 19497, "code": ".index('--') except ValueError: script=[] else: script=argv[pos +1:] argv=argv[:pos] for arg in argv: if arg=='-h' or arg=='--help': return argv,[], script gottarget=False skip=0 for i in range(len(argv))", "label": 0}, {"snippet_id": 44586, "code": " in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag", "label": 0}, {"snippet_id": 30703, "code": "(f) if f_ in self.rule.touch_output: self.touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self", "label": 0}, {"snippet_id": 32383, "code": "[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len", "label": 0}, {"snippet_id": 76736, "code": " help='Default rp timeout in seconds') parser.add_argument('--conlimit', type=int, default=3, help='http_request conlimit') parser.add_argument('--noproxy-timeout', type=int, default=5, help='noproxy_rp", "label": 0}, {"snippet_id": 3124, "code": " localhost\" % hostname) return False except socket.gaierror: sys.exit(\"Host '%s' is unknown! Update your /etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host", "label": 0}, {"snippet_id": 70328, "code": ".target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname()", "label": 0}, {"snippet_id": 19271, "code": " open(tmp_file.name) as json_file: result=load_source(json_file) assert result==native def test_json_file_path(): native={'foo': 'bar'} source=json.dumps(native) tmp_file=tempfile.NamedTemporaryFile(mode=", "label": 0}, {"snippet_id": 94715, "code": ".add_parser('run', help=\"Launches the setup specified by the --config argument\") subparser_val=subparsers.add_parser('validate', help=\"Validate the setup specified by the --config argument\") subparser_remote", "label": 0}, {"snippet_id": 33291, "code": ".has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update", "label": 0}, {"snippet_id": 78184, "code": "(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)==str and[('', targets)] or type(targets)=", "label": 0}, {"snippet_id": 73424, "code": "=pathlib.Path(input_vcf_dir).glob(\"**/*.vcf\") for path in pathlist_vcf: path_str=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -4] path_zarr_output=str", "label": 0}, {"snippet_id": 71036, "code": " show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" %", "label": 0}, {"snippet_id": 41074, "code": " names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def", "label": 0}, {"snippet_id": 32568, "code": " wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards", "label": 0}, {"snippet_id": 54916, "code": " else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules", "label": 0}, {"snippet_id": 32318, "code": "=None): for name, item in olditems.allitems(): start=len(newitems) is_iterable=True if callable(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e", "label": 0}, {"snippet_id": 64350, "code": "._version_path def rewriter( self, parameter_value): unstructured_path_rewrites=self.unstructured_path_rewrites if parameter_value in unstructured_path_rewrites: return unstructured_path_rewrites[ parameter_value]", "label": 0}, {"snippet_id": 71078, "code": ", len(fs.clients)], [\"nodes\", \"%s\" % fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 90462, "code": " distribution.\"\"\" def __init__(self, distribution_environment, minimum_version=None, maximum_version=None): self._cache={} self._distribution_environment=distribution_environment self._minimum_version=minimum_version", "label": 0}, {"snippet_id": 51220, "code": ") except OSError: pass else: os.remove(file) def regex(filepattern): f=[] last=0 wildcards=set() for match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()]))", "label": 0}, {"snippet_id": 74358, "code": " return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=", "label": 0}, {"snippet_id": 87135, "code": " select_source(self, source_file_path): raise NotImplementedError() def register_extra_products_from_contexts(self, targets, compile_contexts): compile_contexts=[self.select_runtime_context(compile_contexts", "label": 0}, {"snippet_id": 443, "code": " if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password", "label": 0}, {"snippet_id": 5704, "code": " filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare 2 single keywords objects. First by the number of their spans(ie. how many times they were found", "label": 0}, {"snippet_id": 67866, "code": " 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s:", "label": 0}, {"snippet_id": 71765, "code": " errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command", "label": 0}, {"snippet_id": 68868, "code": ".set_column(\"label\", i, AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname", "label": 0}, {"snippet_id": 65758, "code": " ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1, AsciiTableLayout", "label": 0}, {"snippet_id": 35939, "code": "\"Johannes K\u00f6ster\" __copyright__=\"Copyright 2015, Johannes K\u00f6ster\" __email__=\"koester@jimmy.harvard.edu\" __license__=\"MIT\" import os import sys import base64 import json from collections import defaultdict from", "label": 0}, {"snippet_id": 44369, "code": " in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If", "label": 0}, {"snippet_id": 25104, "code": " Service. For more details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as", "label": 1}, {"snippet_id": 82527, "code": " | -_| _| |_| |___|_,_| _|_|___|_|___|___|_| |_| \\033[1m\\033[42m{version \"\"\"+version+\"\"\"}\\033[m \\033[m[!] legal disclaimer: Usage of fuxploider for attacking targets without prior mutual consent is illegal", "label": 0}, {"snippet_id": 40754, "code": " values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb", "label": 0}, {"snippet_id": 5640, "code": " output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw", "label": 0}, {"snippet_id": 95952, "code": " conversion_config is not None: output_zarr_path=str(output_zarr_path) if conversion_config.alt_number is None: print(\"[VCF-Zarr] Determining maximum number of ALT alleles by scaling all variants in the VCF file.", "label": 0}, {"snippet_id": 51364, "code": "): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value", "label": 0}, {"snippet_id": 12870, "code": ".encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE", "label": 0}, {"snippet_id": 27019, "code": "=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self", "label": 0}, {"snippet_id": 22134, "code": " def run(self, job_id): \"\"\"Run the playbook and returns the playbook's stats.\"\"\" self.variable_manager.extra_vars={'job_id': job_id} self.pbex.run() return self.pbex._tqm._stats class AnsiblePlugin(plugin", "label": 0}, {"snippet_id": 35766, "code": "(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self", "label": 0}, {"snippet_id": 50669, "code": "._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow", "label": 0}, {"snippet_id": 69865, "code": " RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for", "label": 0}, {"snippet_id": 67136, "code": " print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on", "label": 0}, {"snippet_id": 53636, "code": " output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str)", "label": 0}, {"snippet_id": 4747, "code": ", only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before output", "label": 0}, {"snippet_id": 22607, "code": " Currently we do not set the hostname when WAAgent starts up, so I am passing on setting it here too. :param hostname: The hostname to set on the device \"\"\" return None def set_dhcp_hostname(self, hostname):", "label": 0}, {"snippet_id": 93689, "code": "\"Component %s is already running, skipping to next in line\" % comp['name']) else: self.logger.debug(\"Start component '%s' as dependency of '%s'\" %(node.comp_name, comp['name'])) self.start_component_without_deps", "label": 0}, {"snippet_id": 20245, "code": " None: raise Exception(message) else: message=message +os.linesep +self._run_server_ex raise Exception(message) self._launch( argv, script=script, wait_for_connect=wait, detachable=False, env=env, cwd=cwd)", "label": 0}, {"snippet_id": 44835, "code": "=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output", "label": 0}, {"snippet_id": 69260, "code": " error: %s\" % e except CommandHelpException, e: self.print_help(e.message, e.cmd) except CommandException, e: self.print_error(e.message) return RC_USER_ERROR except ModelFileIOError, e: print \"Error -", "label": 1}, {"snippet_id": 36465, "code": " elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f", "label": 0}, {"snippet_id": 66517, "code": " fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh", "label": 0}, {"snippet_id": 75877, "code": "[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests:", "label": 0}, {"snippet_id": 92068, "code": "\"\" if not self._any_targets_have_native_sources(targets): return False platforms_with_sources=pex_build_util.targets_by_platform(targets, self._python_setup) platform_names=list(platforms_with_sources.keys", "label": 0}, {"snippet_id": 30062, "code": "=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f", "label": 0}, {"snippet_id": 52991, "code": " return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles", "label": 0}, {"snippet_id": 59289, "code": "(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend: use_hardware(bool): If True, the code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int)", "label": 0}, {"snippet_id": 7893, "code": ": return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]", "label": 0}, {"snippet_id": 62447, "code": " if key in self._backend_kwargs} class ProjectQSimulator(ProjectQDevice): \"\"\"ProjectQ Simulator device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args: gate_fusion(bool)", "label": 0}, {"snippet_id": 14900, "code": ", timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC):", "label": 0}, {"snippet_id": 59234, "code": " operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate, 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device", "label": 0}, {"snippet_id": 82680, "code": "\t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces credentials provided using the --proxy switch\") \tif args.proxyCreds: \t\tproxyUser=args.proxyCreds[\"username\"]", "label": 0}, {"snippet_id": 33515, "code": " else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete()", "label": 0}, {"snippet_id": 61427, "code": "._state[0]=1 self._out=np.full(self.wires, np.nan) for operation in self._queue: if operation.name=='QubitStateVector': state=np.asarray(operation.params[0]) if state.ndim==1 and state.shape[0]==2**self", "label": 0}, {"snippet_id": 11619, "code": ", output_file): self.output_file=output_file def write_lines(self, lines): with open(self.output_file, 'w') as f: for line in lines: f.write(line +\"\\n\") LOG.debug(\"Created %s\" % self.output_file) def generate_config", "label": 0}, {"snippet_id": 50040, "code": ": logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks", "label": 0}, {"snippet_id": 69535, "code": "-1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute", "label": 0}, {"snippet_id": 30956, "code": ".subworkflow_input) @property def output_mintime(self): \"\"\" Return oldest output file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing", "label": 0}, {"snippet_id": 47550, "code": " other): if other is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def", "label": 0}, {"snippet_id": 58139, "code": "} results=ctypes[target][0]._default_manager.filter(product__in=p_pks) attr=ctypes[target][1] results=[(r.pk, getattr(r, attr)) for r in results] return results def get_prod_related_obj_json(request): ", "label": 0}, {"snippet_id": 64340, "code": " self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self._sep def version_path( self): return self._version_path def rewriter( self, parameter_value)", "label": 0}, {"snippet_id": 85401, "code": ".Main' ZINC_EXTRACT_MAIN='org.pantsbuild.zinc.extractor.Main' DEFAULT_CONFS=['default'] ZINC_COMPILER_TOOL_NAME='zinc' ZINC_EXTRACTOR_TOOL_NAME='zinc-extractor' class Factory(Subsystem, JvmToolMixin): options_scope", "label": 0}, {"snippet_id": 1958, "code": " stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows", "label": 0}, {"snippet_id": 13102, "code": "\"fork_fullname\"]=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers", "label": 0}, {"snippet_id": 56078, "code": " return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs", "label": 0}, {"snippet_id": 72424, "code": " configuration, determines the runtime mode(dynamic vs. static); if dynamic, gets the benchmark data from the server, runs the benchmarks, and records the timer results. \"\"\" import argparse import time import", "label": 0}, {"snippet_id": 44230, "code": ".error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please", "label": 0}, {"snippet_id": 21678, "code": ".contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape), alpha=0.75, cmap=ListedColormap(('red', 'green'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i,", "label": 0}, {"snippet_id": 46624, "code": ": pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries", "label": 0}, {"snippet_id": 10456, "code": "' % field) else: field +='__' tag=field[0:3] ind1=field[3].replace('_', '') ind2=field[4].replace('_', '') return tag, ind1, ind2 if __name__==\"__main__\": log.error(\"Please use bibclassify_cli from now", "label": 0}, {"snippet_id": 37882, "code": ".take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output,", "label": 0}, {"snippet_id": 12374, "code": "][\"updated\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for updating the PR.\\n\\n\" else: comment_header=config[\"message\"][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file", "label": 0}, {"snippet_id": 82797, "code": ".uploadsPath) \tup.setup(args.url) up.threads=args.nbThreads uploadURL=up.uploadUrl fileInput={\"name\":up.inputName} a=datetime.datetime.now() if not args.skipRecon: \tif len(args.legitExtensions) > 0: \t\tn=up", "label": 0}, {"snippet_id": 85614, "code": " \"\"\"Return the Zinc wrapper compiler classpath. :rtype: list of str \"\"\" return self._zinc_factory._zinc(self._products) @property def dist(self): \"\"\"Return the distribution selected for Zinc. :rtype: list", "label": 0}, {"snippet_id": 69076, "code": " GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes(", "label": 0}, {"snippet_id": 68335, "code": "(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) layout.set_column(\"status\", 5, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict(ldic", "label": 0}, {"snippet_id": 8259, "code": "\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf(document): \"\"\"Checks if a document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found", "label": 1}, {"snippet_id": 2400, "code": " BASE_DIR) class CheckState(Enum): RUNNING=0 STOPPED=1 STOPPED_BUT_SUCCESSFUL=2 STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__)", "label": 0}, {"snippet_id": 76771, "code": "-caprate_limit', type=float, default=0.8, help='Captcha rate limit') parser.add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser.add_argument('--topic_successtimeout", "label": 0}, {"snippet_id": 11325, "code": "\"monconfgenerator\") class MonitoringConfigGenerator(object): def __init__(self, url, debug_enabled=False, target_dir=None, skip_checks=False): self.skip_checks=skip_checks self.target_dir=target_dir if", "label": 0}, {"snippet_id": 21482, "code": ": seen_links=pickle.load(f) with open(unseen_file, 'rb') as f: unseen_links=pickle.load(f) new_links, links=getytlinks(subreddit_link) if depth > 0: for d in range(depth): link=\"\" for l in links: if re", "label": 0}, {"snippet_id": 51852, "code": " name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self):", "label": 0}, {"snippet_id": 48733, "code": " self.log, wildcards, wildcards_obj, concretize=concretize_iofile) benchmark=self.benchmark.apply_wildcards( wildcards) if self.benchmark else None return input, output, params, log, benchmark, ruleio,", "label": 0}, {"snippet_id": 20962, "code": ", msg): for i, handler in enumerate(list(self._handlers)): handle_message, _, _=handler handled=handle_message(msg) try: msg, handled=handled except TypeError: pass if handled: self._handlers.remove(handler", "label": 0}, {"snippet_id": 82354, "code": ".randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: ", "label": 0}, {"snippet_id": 47144, "code": "\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations", "label": 0}, {"snippet_id": 29710, "code": "): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value)", "label": 0}, {"snippet_id": 57983, "code": " comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s)' % str(e)) data['bug_system_id']=int(request.GET.get('bug_system_id', 1)) if request.GET.get('a') not in('add', 'remove'): return(None, 'Actions", "label": 0}, {"snippet_id": 37278, "code": " item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products", "label": 0}, {"snippet_id": 93443, "code": ") self.nodes['master_node']=master_node try: node=self.nodes.get('master_node') res=[] unres=[] dep_resolve(node, res, unres) dep_string=\"\" for node in res: if node is not master_node: dep_string=\"%s -", "label": 0}, {"snippet_id": 46875, "code": ".expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads=self.resources_dict[\"_cores\"", "label": 0}, {"snippet_id": 10971, "code": " e: msg=\"Could not open socket for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException", "label": 0}, {"snippet_id": 86691, "code": " arg_index +=validate(arg_index) @staticmethod def _get_zinc_arguments(settings): \"\"\"Extracts and formats the zinc arguments given in the jvm platform settings. This is responsible for the symbol substitution", "label": 0}, {"snippet_id": 30476, "code": " checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class", "label": 0}, {"snippet_id": 86383, "code": " output_files=tuple( os.path.relpath(f.path.replace('.java', '.class'), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv", "label": 0}, {"snippet_id": 35920, "code": " maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic", "label": 0}, {"snippet_id": 61397, "code": " shots=0): self.wires=wires self.eng=None self._state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" if self", "label": 1}, {"snippet_id": 11509, "code": " YamlToIcinga(object): def __init__(self, yaml_config, header): self.icinga_lines=[] self.indent=CONFIG['INDENT'] self.icinga_lines.extend(header.serialize()) self.write_section('host', yaml_config.host", "label": 0}, {"snippet_id": 61782, "code": " a=np.min(wires) b=np.max(wires) n_between=b-a-1 before =2**a after =2**(self.wires-b-1) between=2**n_between U=np.kron(U, np.eye(between)) if wires[0] < wires[1]: p=[0, 2, 1] else: p=[1, 2, 0] dim=[2,", "label": 0}, {"snippet_id": 69369, "code": " launch(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"", "label": 0}, {"snippet_id": 16278, "code": " self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False", "label": 0}, {"snippet_id": 35080, "code": "\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill: raise WildcardError(name) return str(value) except KeyError as ex: if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing", "label": 0}, {"snippet_id": 14001, "code": " requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return _EXECUTOR.submit( DelayedSendRequest, data, handler, method) return SendRequest( data, handler, method", "label": 0}, {"snippet_id": 54700, "code": "\"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name --the name of the rule \"\"\" if not self", "label": 0}, {"snippet_id": 90424, "code": " *possible_environments): super(_DistributionEnvironment, self).__init__() if len(possible_environments) < 2: raise ValueError('At least two possible environments must be supplied.') self._possible_environments", "label": 0}, {"snippet_id": 59373, "code": " plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0)", "label": 0}, {"snippet_id": 25002, "code": "\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if", "label": 0}, {"snippet_id": 76298, "code": ".wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep(self, reqid, data", "label": 0}, {"snippet_id": 85640, "code": "\"Return the path to the Zinc compiler-bridge jar. :rtype: str \"\"\" return self._zinc_factory._compiler_bridge(self._products) @memoized_property def compiler_interface(self): \"\"\"Return the path to the Zinc", "label": 0}, {"snippet_id": 40354, "code": "}\".format( latency_wait, \"\\n\".join(get_missing()))) def get_wildcard_names(pattern): return set(match.group('name') for match in _wildcard_regex.finditer(pattern)) def contains_wildcard(path): return _wildcard_regex", "label": 0}, {"snippet_id": 6323, "code": " return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory, executable", "label": 1}, {"snippet_id": 8032, "code": "(component_avg1, component_avg0) if component_comparison: return component_comparison return cmp(len(str(kw1[0])), len(str(kw0[0]))) def _kw(keywords): \"\"\"Turn list of keywords into dictionary.\"\"\" r={} for k, v", "label": 0}, {"snippet_id": 30523, "code": "=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"\"\" m=self.regex.search(value) if m is not None: return m.group(\"value", "label": 0}, {"snippet_id": 57990, "code": " data['bug_system_id']=int(request.GET.get('bug_system_id', 1)) if request.GET.get('a') not in('add', 'remove'): return(None, 'Actions only allow \"add\" and \"remove\".') else: data['action']=request.GET.get", "label": 0}, {"snippet_id": 49769, "code": " workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag.targetjobs for f in job.input if dag.needrun(job) and not os.path.exists(f)]", "label": 0}, {"snippet_id": 69898, "code": ", fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem ", "label": 0}, {"snippet_id": 78357, "code": ": try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except UnicodeDecodeError as e: self.log.exception(e) self.w.sleep(self.errortimeout) def forumwipe_loop(self)", "label": 0}, {"snippet_id": 14431, "code": ".PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen", "label": 0}, {"snippet_id": 54876, "code": " None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files:", "label": 0}, {"snippet_id": 2482, "code": " name \"%s\" on server' % self.session_name) else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name,", "label": 0}, {"snippet_id": 4415, "code": " output_limit: int :param spires: boolean, if True marcxml output reflect spires codes. :param match_mode: str -partial|full; in partial mode only beginning of the fulltext is searched. :param no_cache: boolean,", "label": 0}, {"snippet_id": 24491, "code": " @property def state(self): \"\"\"Return the state of the device.\"\"\" return self._state @property def unit_of_measurement(self): \"\"\"Return the unit of measurement of this entity, if any.\"\"\" return self._unit_of_measurement", "label": 0}, {"snippet_id": 48883, "code": " values. Arguments wildcards --a dict of wildcards \"\"\" return sum(map(len, wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self", "label": 0}, {"snippet_id": 87706, "code": ".home), ) res=self.context.execute_process_synchronously(req, self.name(),[WorkUnitLabel.COMPILER]) self.context._scheduler.materialize_directories(( DirectoryToMaterialize(get_buildroot(), res.output_directory_digest", "label": 1}, {"snippet_id": 74318, "code": " destination and overwrite mode disabled.\") return with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration", "label": 0}, {"snippet_id": 46655, "code": "(configpath) as f: try: return json.load(f) except ValueError: f.seek(0) try: import yaml except ImportError: raise WorkflowError(\"Config file is not valid JSON and PyYAML \" \"has not been installed. Please", "label": 0}, {"snippet_id": 59115, "code": " following are useful in the current context: -projectq.backends.Simulator([gate_fusion,...])\tSimulator is a compiler engine which simulates a quantum computer using C++-based kernels. -projectq.backends", "label": 0}, {"snippet_id": 72119, "code": "]) network=world.networkobjects[netname] except IndexError: irc.error('Not enough arguments(needs 2: network name(case sensitive), autoconnect time(in seconds)).') return except KeyError: irc.error('No", "label": 0}, {"snippet_id": 2823, "code": " send_main_session_command(self.session, cmd) def start_component(self, comp): node=self.nodes.get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) for node in res: self.logger.debug(\"node name '%s' vs", "label": 0}, {"snippet_id": 70822, "code": " NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0", "label": 0}, {"snippet_id": 73305, "code": "(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/*.vcf\"", "label": 0}, {"snippet_id": 84280, "code": " outputs_directory=remote_job_config['outputs_directory'] configs_directory=remote_job_config['configs_directory'] working_directory=remote_job_config['working_directory'] outputs=[Bunch(false_path=os.path", "label": 0}, {"snippet_id": 20348, "code": " import warnings from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.message import( raw_read_all as read_messages, raw_write_one as write_message ) from.socket import( Connection, create_server", "label": 0}, {"snippet_id": 34011, "code": "=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo", "label": 0}, {"snippet_id": 95415, "code": " file_list_total, filepath)) except error_perm: print(\"[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"", "label": 0}, {"snippet_id": 4847, "code": " only_core_tags, limit=output_limit) functions={\"text\": _output_text, \"marcxml\": _output_marc, \"html\": _output_html, \"dict\": _output_dict} my_styles={} for s in style: if s !=\"raw\": my_styles[s]=functions", "label": 0}, {"snippet_id": 30047, "code": "[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath", "label": 0}, {"snippet_id": 15820, "code": "(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA", "label": 0}, {"snippet_id": 19573, "code": " pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif arg=='--nodebug': supported.append(arg) elif arg in('--host', '--server-host", "label": 0}, {"snippet_id": 36529, "code": "\".format( self.rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output", "label": 0}, {"snippet_id": 80621, "code": " Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size", "label": 0}, {"snippet_id": 36212, "code": ".rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format", "label": 0}, {"snippet_id": 21621, "code": "=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix(y_test, y_pred) from matplotlib", "label": 0}, {"snippet_id": 53435, "code": " non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )", "label": 0}, {"snippet_id": 89902, "code": " too old; expecting at least{} and' ' got{}'.format(java, self._minimum_version, version)) if self._maximum_version: version=self._get_version(java) if version > self._maximum_version: raise self.Error", "label": 0}, {"snippet_id": 55027, "code": " list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if unlock", "label": 0}, {"snippet_id": 14820, "code": "( extra_conf_vim_data) def _PathToServerScript(): dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded", "label": 0}, {"snippet_id": 69329, "code": " class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes=None): ProxyAction.__init__(self) self.fs=fs self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes", "label": 0}, {"snippet_id": 53172, "code": "-the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params", "label": 0}, {"snippet_id": 31793, "code": "=1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch.dependencies )=branch.expand_wildcards(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards", "label": 0}, {"snippet_id": 22712, "code": "%s partition-access add{ all-partitions{ role admin}} shell bash\" %(username) retcode, out=shellutil.run_get_output(cmd, log_cmd=True, chk_err=True) if retcode !=0: raise OSUtilError( \"Failed to create", "label": 0}, {"snippet_id": 21205, "code": "=result_getter @property def resp(self): return self._result_getter() class AwaitableEvent(Awaitable): def __init__(self, name, result_getter, event=None): super(AwaitableEvent, self).__init__(name, event", "label": 0}, {"snippet_id": 35706, "code": ": end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self", "label": 0}, {"snippet_id": 3794, "code": "\": window_name }) return window def send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file", "label": 0}, {"snippet_id": 25957, "code": "\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state", "label": 0}, {"snippet_id": 95581, "code": ") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, file_path_local)) else: print(\"[Setup][FTP]", "label": 0}, {"snippet_id": 72292, "code": "\"network, as this would cause a recursive loop\" log.debug('(%s) networks.remote: re-routing reply %r from network %s', irc.name, text, placeholder_self.name) if 'source' in kwargs: del kwargs['source']", "label": 0}, {"snippet_id": 71201, "code": "\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" ", "label": 0}, {"snippet_id": 65957, "code": "(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign > 0: status.append(\"not checked(%d)\" % c_ign) if c_offline > 0: status.append", "label": 0}, {"snippet_id": 32187, "code": " else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified", "label": 0}, {"snippet_id": 39714, "code": " return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 12788, "code": "\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) r=requests.get(data[\"diff_url\"], headers=headers, auth=auth) patch=unidiff.PatchSet(r.content.splitlines(), encoding=r.encoding) py_files={} for patchset in", "label": 0}, {"snippet_id": 91179, "code": " pants.backend.python.targets.python_distribution import PythonDistribution from pants.backend.python.targets.python_library import PythonLibrary from pants.backend.python.targets.python_requirement_library", "label": 0}, {"snippet_id": 55747, "code": ", rule=rule) rule.resources.update(resources) if ruleinfo.priority: if(not isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to", "label": 0}, {"snippet_id": 50019, "code": ")) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info", "label": 0}, {"snippet_id": 52866, "code": " resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(", "label": 0}, {"snippet_id": 79941, "code": ",help=\"Legit extensions expected, for a normal use of the form, comma separated. Example: 'jpg,png,bmp'\") exclusiveArgs.add_argument(\"-n\",metavar=\"n\",nargs=1,default=[\"100\"],dest=\"n\",help=\"Number of common", "label": 0}, {"snippet_id": 35884, "code": " or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with", "label": 0}, {"snippet_id": 76344, "code": " data, seqid=0): msg=self.wz.make_dealer_rep_msg( reqid, seqid, wzrpc.status.error, data) self.wz_sock.send_multipart(msg) def send_to_router(self, msg): msg.insert(0, b'') self.wz_sock.send_multipart(msg", "label": 0}, {"snippet_id": 50785, "code": ".supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os", "label": 0}, {"snippet_id": 52626, "code": " if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing", "label": 0}, {"snippet_id": 45442, "code": ".\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file", "label": 1}, {"snippet_id": 33460, "code": " removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows", "label": 0}, {"snippet_id": 34992, "code": " match in _wildcard_regex.finditer(filepattern): f.append(re.escape(filepattern[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError", "label": 0}, {"snippet_id": 38697, "code": " forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets)", "label": 0}, {"snippet_id": 30570, "code": " RuleException, ProtectedOutputException from snakemake.exceptions import UnexpectedOutputException from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs", "label": 0}, {"snippet_id": 25970, "code": "'GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=", "label": 0}, {"snippet_id": 18246, "code": "._user_notified_about_crash=False self._diag_interface=DiagnosticInterface( user_options) self._omnicomp=OmniCompleter( user_options) self._latest_completion_request=None self._latest_file_parse_request", "label": 0}, {"snippet_id": 39167, "code": ") ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored", "label": 0}, {"snippet_id": 58742, "code": "(self): user_should_have_perm(self.tester, self.permission) def test_refuse_if_missing_permission(self): remove_perm_from_user(self.tester, self.permission) self.client.login( username=self.tester.username", "label": 0}, {"snippet_id": 91478, "code": " import sys from builtins import str from future.utils import text_type from pants.backend.python.rules.inject_init import InjectedInitDigest from pants.backend.python.subsystems.pytest import PyTest from", "label": 0}, {"snippet_id": 93312, "code": ".session_name, window_name=\"Main\" ) else: self.config=None def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config:", "label": 0}, {"snippet_id": 58233, "code": ".management.models import Priority from tcms.management.models import EnvGroup from tcms.management.models import EnvProperty from tcms.testcases.forms import CaseAutomatedForm from tcms.testcases.forms", "label": 1}, {"snippet_id": 83063, "code": ".runners import AsynchronousJobState, AsynchronousJobRunner from galaxy.jobs import ComputeEnvironment from galaxy.jobs import JobDestination from galaxy.jobs.command_factory import build_command from galaxy", "label": 0}, {"snippet_id": 83878, "code": " %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata", "label": 0}, {"snippet_id": 15465, "code": "( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest( self._omnicomp) else", "label": 0}, {"snippet_id": 79717, "code": " help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help", "label": 0}, {"snippet_id": 81443, "code": "\t\t\t\ttmpExtList.append((e,getMime(extensions,e))) \t\telse: \t\t\ttmpExtList=extensions \t\tvalidExtensions=[] \t\textensionsToTest=tmpExtList[0:maxN] \t\twith concurrent.futures.ThreadPoolExecutor(max_workers=self", "label": 0}, {"snippet_id": 1289, "code": " nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f SSID,BARS device wifi list', shell=True,stdout=subprocess.PIPE).communicate()[0] wifirows=ps.split('\\n') wifi=[] for row in wifirows", "label": 0}, {"snippet_id": 48440, "code": " start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs", "label": 0}, {"snippet_id": 22398, "code": "/usr/bin/tmsh -a show sys mcp-state field-fmt 2>/dev/null | grep phase | grep running\", chk_err=False) if rc==0: logger.info(\"mcpd is up!\") break time.sleep(30) if rc is 0: return True raise OSUtilError", "label": 0}, {"snippet_id": 65079, "code": "% \\ (node, target.type.upper(), target.get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr", "label": 0}, {"snippet_id": 83262, "code": " if lwr_status==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running=True job_state.job_wrapper.change_state( model.Job.states.RUNNING", "label": 0}, {"snippet_id": 46447, "code": "[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. ", "label": 0}, {"snippet_id": 37748, "code": " BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function", "label": 0}, {"snippet_id": 70130, "code": "): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"", "label": 0}, {"snippet_id": 7475, "code": " resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def _output_dict(complete_output, categories): return{ \"complete_output\": complete_output, \"categories\": categories } def", "label": 0}, {"snippet_id": 70160, "code": ".get_id(), target.dev) self.update() def ev_starttarget_failed(self, node, target, rc, message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s", "label": 0}, {"snippet_id": 93904, "code": " return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out=='::1': self.logger.debug(\"Host '%s' is localhost\" % hostname) return True else", "label": 0}, {"snippet_id": 93348, "code": " in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name'], comp['host'])) if comp['host'] !=\"localhost\" and not self.run_on_localhost", "label": 0}, {"snippet_id": 60882, "code": " exc_type, exc_value, tb): if self._observe is None: raise DeviceError('A qfunc must always conclude with a classical expectation value.') Device._current_context=None self.execute() @property def gates(self):", "label": 0}, {"snippet_id": 58586, "code": ".case_run_1.pk, self.case_run_2.pk): comments=Comment.objects.filter(object_pk=case_run_pk, content_type=case_run_ct) self.assertEqual(new_comment, comments[0].comment) self.assertEqual(self.tester, comments", "label": 0}, {"snippet_id": 35773, "code": " __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class", "label": 0}, {"snippet_id": 84797, "code": " JarDependency from pants.subsystem.subsystem import Subsystem major_version_info=namedtuple('major_version_info',['full_version']) scala_build_info={ '2.10': major_version_info(full_version='2.10.6'), ", "label": 0}, {"snippet_id": 13681, "code": " Please read README.md for instructions.\") \r else:\r twitter=ChippyTwitter(consumerKey,consumerSecret,accessTokenKey,accessTokenSecret)\r \r web=WebFramework(talk)\r isRunning=False\r io.cleanup()\r sys.exit", "label": 0}, {"snippet_id": 56472, "code": ".objects.all() def env_values(self): return EnvValue.objects.filter(property__id=self.request.GET.get('env_property_id')) def users(self): query=strip_parameters(self.request.GET, skip_parameters=('info_type", "label": 0}, {"snippet_id": 64103, "code": " job_wrapper, remote_metadata, remote_job_config): metadata_kwds={} if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(", "label": 0}, {"snippet_id": 76785, "code": ", help='Comment success timeout') parser.add_argument('--topic_successtimeout', type=float, default=0.1, help='Topic success timeout') parser.add_argument('--errortimeout', type=float, default=3, help=", "label": 0}, {"snippet_id": 37688, "code": " to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not", "label": 0}, {"snippet_id": 45825, "code": "[last:match.start()])) wildcard=match.group(\"name\") if wildcard in wildcards: if match.group(\"constraint\"): raise ValueError( \"If multiple wildcards of the same name \" \"appear in a string, eventual constraints", "label": 0}, {"snippet_id": 24647, "code": " Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=", "label": 0}, {"snippet_id": 27062, "code": " self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle", "label": 1}, {"snippet_id": 12488, "code": "}\".format(error_string)) comment_body.append(\"\\n\\n\") if len(data[\"extra_results\"][file]) > 0: comment_body.append(\" -Complete extra results for this file:\\n\\n\") comment_body.append(\"> \" +\"\".join(data[\"extra_results", "label": 0}, {"snippet_id": 37413, "code": "=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output", "label": 0}, {"snippet_id": 10023, "code": " return out def _get_fieldcodes(skw_matches, ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,..", "label": 0}, {"snippet_id": 1814, "code": "=con.cursor() cursor.execute(common.Q_GET_DOCKER_OVERVIEW) rows=cursor.fetchall() print(rows) finalset=[] for row in rows: data={'state': row[0], 'container_id': row[1], 'name': row[2], 'image': row[3]", "label": 0}, {"snippet_id": 29303, "code": " stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode)", "label": 0}, {"snippet_id": 80263, "code": ".verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt", "label": 0}, {"snippet_id": 28356, "code": " name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\", "label": 1}, {"snippet_id": 64362, "code": " in unstructured_path_rewrites.itervalues(): return parameter_value rewrite, new_unstructured_path_rewrites=self.path_mapper.check_for_arbitrary_rewrite( parameter_value) if rewrite: unstructured_path_rewrites", "label": 0}, {"snippet_id": 58898, "code": ", { 'target_field': 'priority', 'from_plan': self.plan.pk, 'case':[self.case_1.pk, self.case_3.pk], 'new_value': Priority.objects.get(value='P3').pk, }) self.assertJSONEqual( str(response.content, encoding", "label": 0}, {"snippet_id": 22863, "code": " is None: raise OSUtilError(\"The 'admin' user account was not found!\") cmd=\"/usr/bin/tmsh modify auth user 'admin' password '{0}'\".format(password) ret, output=shellutil.run_get_output(cmd, log_cmd=False", "label": 0}, {"snippet_id": 92097, "code": " platforms_with_sources.items(): if platform=='current': continue bad_targets.update(targets) raise IncompatiblePlatformsError(dedent(\"\"\"\\ Pants doesn't currently support cross-compiling native code. The following targets", "label": 0}, {"snippet_id": 4299, "code": " text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires", "label": 0}, {"snippet_id": 43759, "code": "=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config) global rules rules=Rules() @property def subworkflows(self): return self._subworkflows.values() @property", "label": 0}, {"snippet_id": 4277, "code": " text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines", "label": 1}, {"snippet_id": 43539, "code": " rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\" for clause in reversed(self.order): try: i=clause", "label": 0}, {"snippet_id": 71970, "code": " def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes", "label": 1}, {"snippet_id": 43805, "code": ": for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno", "label": 0}, {"snippet_id": 67179, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand import FSClientLiveCommand from Base", "label": 0}, {"snippet_id": 62469, "code": " cached and only executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq", "label": 0}, {"snippet_id": 35854, "code": " to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError: raise WorkflowError(\"Config file{} not", "label": 0}, {"snippet_id": 89062, "code": ", **kwargs) synthetics=OrderedSet() for synthetic_address in self.build_graph.synthetic_addresses: if self.build_graph.get_concrete_derived_from(synthetic_address) in target_set: synthetics.add(self.build_graph", "label": 0}, {"snippet_id": 73536, "code": "=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\".format", "label": 0}, {"snippet_id": 54682, "code": " lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name", "label": 0}, {"snippet_id": 66542, "code": "=self.nodes_support.get_nodeset() fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"", "label": 0}, {"snippet_id": 45948, "code": "(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value", "label": 0}, {"snippet_id": 49362, "code": "(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun", "label": 0}, {"snippet_id": 80518, "code": " s.trust_env=False if args.proxy: \tif args.proxy[\"username\"] and args.proxy[\"password\"] and args.proxyCreds: \t\tlogging.warning(\"Proxy username and password provided by the --proxy-creds switch replaces", "label": 0}, {"snippet_id": 20507, "code": " iter_messages(self): if self.closed: raise RuntimeError('connection closed') def stop(): return self.closed read=recv_as_read(self._sock) for msg, _, _ in read_messages(read, stop=stop): if self.VERBOSE", "label": 0}, {"snippet_id": 2484, "code": " % self.session_name) else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ", "label": 0}, {"snippet_id": 74701, "code": "\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\", "label": 0}, {"snippet_id": 80088, "code": ",default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument(\"--random-user-agent\",action=\"store_true\",required=False,dest=\"randomUserAgent\",help=\"Use a random user-agent while requesting", "label": 0}, {"snippet_id": 7302, "code": " not find them :keyword provenience: string that identifies source(authority) that assigned the contents of the field :return: string, formatted MARC\"\"\" kw_template=('<datafield tag=\"%s\" ind1=\"%s\" ind2", "label": 0}, {"snippet_id": 76312, "code": " self.wz.make_router_rep_msg(reqid, seqnum, status, data)) def send_success_rep(self, reqid, data): self.send_rep(reqid, 0, wzrpc.status.success, data) def send_error_rep(self, reqid, data): self.send_rep", "label": 0}, {"snippet_id": 93047, "code": " **PATCH_OPTS) as mock_signal: mock_signal.return_value=mock_initial_handler try: with signal_handler_as(signal.SIGUSR2, mock_new_handler): raise NotImplementedError('blah') except NotImplementedError:", "label": 0}, {"snippet_id": 66858, "code": ".append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i %s\" % self.targets_indexes) self.task.shell(' '.join(command), nodes=self.nodes, handler=self) def ev_read(self, worker):", "label": 0}, {"snippet_id": 36750, "code": ", other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list", "label": 0}, {"snippet_id": 54074, "code": "( self.name, \"\\n\".join(self.wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self", "label": 0}, {"snippet_id": 95324, "code": " \"\"\" Get benchmarking data from a remote ftp server. :type ftp_config: config.FTPConfigurationRepresentation :type local_directory: str \"\"\" if ftp_config.enabled: create_directory_tree(local_directory)", "label": 0}, {"snippet_id": 24167, "code": " SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', 'mdi:gauge', None], 'noise':['Noise", "label": 0}, {"snippet_id": 89784, "code": ".realpath(self.home) @property def java(self): \"\"\"Returns the path to this distribution's java command. If this distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary(", "label": 0}, {"snippet_id": 1139, "code": "'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets.ModelViewSet)", "label": 0}, {"snippet_id": 93142, "code": " DepTree import Node, dep_resolve, CircularReferenceException import logging import os import socket import argparse from psutil import Process from subprocess import call from graphviz import Digraph from", "label": 0}, {"snippet_id": 8724, "code": " spires=False, match_mode=\"full\", no_cache=False, with_author_keywords=False, rebuild_cache=False, only_core_tags=False, extract_acronyms=False, api=False, **kwargs): \"\"\"Output the keywords for each source", "label": 0}, {"snippet_id": 32980, "code": " clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None", "label": 0}, {"snippet_id": 51350, "code": ", pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value", "label": 0}, {"snippet_id": 20781, "code": "*kwargs): yield result def get_awaiter_for_event(self, event, condition=lambda msg: True, **kwargs): if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg", "label": 0}, {"snippet_id": 9813, "code": "(complete_output, categories): \"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords:", "label": 0}, {"snippet_id": 45548, "code": " files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self", "label": 0}, {"snippet_id": 48594, "code": " raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else:", "label": 0}, {"snippet_id": 29342, "code": "==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise", "label": 0}, {"snippet_id": 24801, "code": "'WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 70452, "code": "\"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand", "label": 0}, {"snippet_id": 89759, "code": ".path.dirname(home) if self._is_executable(os.path.join(jdk_dir, 'bin', 'javac')): home=jdk_dir self._home=home return self._home @property def real_home(self): \"\"\"Real path to the distribution java.home", "label": 1}, {"snippet_id": 36397, "code": " @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return max(existing) return None def missing_output(self, requested", "label": 0}, {"snippet_id": 57213, "code": " 'mail_scene'): mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: from tcms.core.utils.mailto import mailto mail_context['context", "label": 0}, {"snippet_id": 74502, "code": " None: if hasattr(runtime_config, \"ftp\"): if \"enabled\" in runtime_config.ftp: self.enabled=config_str_to_bool(runtime_config.ftp[\"enabled\"]) if \"server\" in runtime_config.ftp: self.server=runtime_config", "label": 0}, {"snippet_id": 7227, "code": "/collection>') return '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience=", "label": 0}, {"snippet_id": 41618, "code": " try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 39845, "code": " return self._snakefile @property def workdir(self): workdir=\".\" if self._workdir is None else self._workdir if not os.path.isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir", "label": 0}, {"snippet_id": 33523, "code": "( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess() if nodeps: missing_input=[f for job in dag", "label": 0}, {"snippet_id": 51596, "code": " in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for", "label": 0}, {"snippet_id": 83303, "code": "\"Failed to find job corresponding to final status %s in %s\" %( full_status, self.watched)) else: self.__update_job_state_for_lwr_status(job_state, full_status[\"status\"]) def __find_watched_job( self, job_id", "label": 1}, {"snippet_id": 83279, "code": ".job_wrapper.change_state( model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep", "label": 0}, {"snippet_id": 36941, "code": ": name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params=Params() self.dependencies=dict() self", "label": 0}, {"snippet_id": 20792, "code": ": if self.closed: raise RuntimeError('session closed') result={'msg': None} def match(msg): result['msg']=msg return msg.type=='event' and msg.event==event and condition(msg) handlername='event{!r}'.format", "label": 0}, {"snippet_id": 15322, "code": " self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir", "label": 0}, {"snippet_id": 51889, "code": " self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name", "label": 0}, {"snippet_id": 945, "code": ", stdout=subprocess.PIPE).communicate()[0].split('\\n')[0] userlist=fetchusers.split(':')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist", "label": 0}, {"snippet_id": 45745, "code": " missing=get_missing() if missing: logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError", "label": 0}, {"snippet_id": 39471, "code": "\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads if ruleinfo.resources: args, resources=ruleinfo.resources if args: raise RuleException(\"Resources have to be named", "label": 0}, {"snippet_id": 70172, "code": " message): self.status_changed=True if rc: strerr=os.strerror(rc) else: strerr=message print \"%s: Failed to start %s %s(%s): %s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc:", "label": 0}, {"snippet_id": 27366, "code": "(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append", "label": 1}, {"snippet_id": 46289, "code": " in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os", "label": 0}, {"snippet_id": 15891, "code": ": return True def Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout", "label": 0}, {"snippet_id": 70395, "code": ".fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc=", "label": 0}, {"snippet_id": 46007, "code": " that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"temp\") def temporary(value): \"", "label": 0}, {"snippet_id": 9616, "code": " output=[] tag, ind1, ind2=_parse_marc_code(kw_field) for keywords in(output_complete[\"Single keywords\"], output_complete[\"Core keywords\"]): for kw in keywords: output.append(kw_template %(tag, ind1, ind2", "label": 0}, {"snippet_id": 65242, "code": " RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel", "label": 0}, {"snippet_id": 81581, "code": "\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,", "label": 1}, {"snippet_id": 78727, "code": " options=self.options try: url='http://{host}:{port}/{path}'.format( host=options.host, port=options.port, path=COMMANDS[options.prog]) request=json.dumps(args[1:]) log.logger.debug('Request to %s:\\n%s", "label": 0}, {"snippet_id": 62603, "code": " yet implemented for the observable{} in backend{}.\".format(observable, self.backend)) return expectation_value class ProjectQClassicalSimulator(ProjectQDevice): \"\"\"ProjectQ ClassicalSimulator device for", "label": 0}, {"snippet_id": 88396, "code": " def fatal(self, *msg_elements): self._run_tracker.log(Report.FATAL, *msg_elements) def __init__(self, options, run_tracker, target_roots, requested_goals=None, target_base=None, build_graph=None, build_file_parser", "label": 0}, {"snippet_id": 35811, "code": " class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile(configpath): \"Tries to load a configfile first as JSON, then as YAML, into a dict.\" try: with open(configpath) as f: try", "label": 0}, {"snippet_id": 78311, "code": "%s: %s', e, e.answer) self.schedule(self.add_comment,(t, msg)) except exc.Wait5Min as e: self.schedule(self.add_comment,(t, msg)) self.schedule_first(self.switch_user) except exc.EmptyAnswer as e: self", "label": 1}, {"snippet_id": 64441, "code": " isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len ", "label": 0}, {"snippet_id": 79494, "code": " and valid_regex(codeExecRegex) and(self.uploadsFolder or self.trueRegex): \t\t\t\turl=None \t\t\t\tsecondUrl=None \t\t\t\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1", "label": 1}, {"snippet_id": 39595, "code": " decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def", "label": 0}, {"snippet_id": 13760, "code": " return self.locals[key] def __delitem__(self, key): del self.locals[key] def __call__(self, expr): return eval(expr, self.globals, self.locals) if __name__=='__main__': for k, v in _safe_locals.iteritems", "label": 0}, {"snippet_id": 5836, "code": ":get_index(end)] for start, end in bconfig.CFG_BIBCLASSIFY_PARTIAL_TEXT] return \"\\n\".join(partial_text) def save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os", "label": 0}, {"snippet_id": 36857, "code": ".append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \", \".join(self.updated_input_run))) s=\"; \".join(s)", "label": 0}, {"snippet_id": 10612, "code": "\"Returns the fulltext of the local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty", "label": 1}, {"snippet_id": 27758, "code": ".type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif self.type=='windangle': if data['WindAngle'] >=330: self._state=\"N(%d\\xb0)\" % data[", "label": 0}, {"snippet_id": 18840, "code": " collections import requests import six import json import yaml from flex.context_managers import ErrorDict from flex.exceptions import ValidationError from flex.loading.definitions import( definitions_validator", "label": 0}, {"snippet_id": 67932, "code": " import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine", "label": 0}, {"snippet_id": 88240, "code": ", object from collections import defaultdict from contextlib import contextmanager from twitter.common.collections import OrderedSet from pants.base.build_environment import get_buildroot, get_scm from", "label": 0}, {"snippet_id": 56569, "code": "(q_app_module, q_form) form_params=form_class(initial=parameters) html=getattr(form_params, 'as_' +q_format) return HttpResponse(html()) def tags(request): \"\"\" Get tags for TestPlan, TestCase or TestRun", "label": 1}, {"snippet_id": 17447, "code": "'Restarting ycmd server...') self._user_notified_about_crash=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable", "label": 0}, {"snippet_id": 64514, "code": ".Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import", "label": 0}, {"snippet_id": 87609, "code": "=self.HERMETIC: zinc_relpath=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context._scheduler), ctx.target.sources_snapshot(self.context._scheduler), ] directory_digests", "label": 0}, {"snippet_id": 16455, "code": "=False self._ServerCleanup() self._SetupServer() def CreateCompletionRequest( self, force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and", "label": 0}, {"snippet_id": 17393, "code": " return returncode is None def _NotifyUserIfServerCrashed( self): if self._user_notified_about_crash or self._IsServerAlive(): return self._user_notified_about_crash=True if self._server_stderr: with open(", "label": 0}, {"snippet_id": 46155, "code": "[1] if isinstance(filepatterns, str): filepatterns=[filepatterns] def flatten(wildcards): for wildcard, values in wildcards.items(): if isinstance(values, str) or not isinstance(values, Iterable): values", "label": 0}, {"snippet_id": 32911, "code": ".globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self", "label": 0}, {"snippet_id": 23077, "code": ":param max_retry: Maximum number of retries waagent will make when mounting the provisioningiso.iso DVD :param chk_err: Whether to check for errors or not in the mounting commands \"\"\" self._wait_until_mcpd_is_initialized", "label": 0}, {"snippet_id": 9226, "code": "\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite", "label": 0}, {"snippet_id": 41328, "code": ", min_repeat=50, max_repeat=100): \"\"\" Args: max_len(int): The maximum length of the periodic substring. \"\"\" self.regex=re.compile( \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat", "label": 0}, {"snippet_id": 28788, "code": "\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self", "label": 0}, {"snippet_id": 55026, "code": " list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if", "label": 0}, {"snippet_id": 32462, "code": ".apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items", "label": 0}, {"snippet_id": 72530, "code": ", action=\"store_true\", help=\"Overwrite the destination file if it already exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires", "label": 0}, {"snippet_id": 45575, "code": "(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name)", "label": 1}, {"snippet_id": 38379, "code": " for rule in self.rules for file in chain(rule.input, rule.output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not", "label": 0}, {"snippet_id": 84388, "code": "() self._wrapper_output_paths=self.local_path_config.output_paths() self.path_mapper=PathMapper(lwr_client, remote_job_config, self.local_path_config.working_directory()) self._config_directory=remote_job_config", "label": 0}, {"snippet_id": 95843, "code": " files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config: Configuration data for the conversion :type input_vcf_dir: str :type output_zarr_dir", "label": 0}, {"snippet_id": 39263, "code": " self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info", "label": 0}, {"snippet_id": 1678, "code": ": output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False) else: return JsonResponse(output, safe=False", "label": 0}, {"snippet_id": 7709, "code": ": list of formatted author keywors \"\"\" out={} if author_keywords: for keyword, matches in author_keywords.items(): skw_matches=matches[0] ckw_matches=matches[1] matches_str=[] for ckw, spans in ckw_matches", "label": 0}, {"snippet_id": 32600, "code": ". Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match", "label": 0}, {"snippet_id": 69134, "code": " import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from", "label": 0}, {"snippet_id": 81593, "code": ",mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1", "label": 1}, {"snippet_id": 63102, "code": " __update_job_state_for_lwr_status(self, job_state, lwr_status): if lwr_status==\"complete\": self.mark_as_finished(job_state) return None if lwr_status==\"running\" and not job_state.running: job_state.running", "label": 0}, {"snippet_id": 2370, "code": "(levelname)s]:\\t%(message)s\" logging.basicConfig(level=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH", "label": 0}, {"snippet_id": 48236, "code": " item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\")", "label": 0}, {"snippet_id": 51621, "code": " limit(pattern, **wildcards): \"\"\" Limit wildcards to the given values. Arguments: **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{", "label": 0}, {"snippet_id": 30336, "code": "==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try", "label": 0}, {"snippet_id": 58433, "code": " password='password') response=self.client.post(self.many_comments_url, {'run':[self.case_run_1.pk, self.case_run_2.pk]}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {", "label": 0}, {"snippet_id": 45017, "code": " input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.output=(paths", "label": 0}, {"snippet_id": 28681, "code": "='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif data['battery_vp'] >=4920: self._state=\"Medium\" elif data", "label": 0}, {"snippet_id": 54482, "code": " glob_wildcards, flag, not_iterable, touch from snakemake.persistence import Persistence from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None,", "label": 1}, {"snippet_id": 36003, "code": "(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict", "label": 0}, {"snippet_id": 49391, "code": " printshellcmds=False, printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag", "label": 0}, {"snippet_id": 28700, "code": "['battery_vp'] >=4920: self._state=\"Medium\" elif data['battery_vp'] >=4560: self._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2'", "label": 0}, {"snippet_id": 45008, "code": " decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def", "label": 0}, {"snippet_id": 26403, "code": " return None add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name", "label": 0}, {"snippet_id": 3260, "code": ": self.logger.error(\"Detected circular dependency reference between %s and %s!\" %(ex.node1, ex.node2)) deps.edge(ex.node1, ex.node2, \"circular error\", color=\"red\") deps.edge(ex.node2, ex.node1, color=\"red", "label": 0}, {"snippet_id": 80702, "code": " detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.\") entryPoints=[] up.stopThreads=True with open", "label": 0}, {"snippet_id": 30186, "code": " self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None", "label": 0}, {"snippet_id": 37425, "code": "=item.rule _item=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\")", "label": 0}, {"snippet_id": 28305, "code": "]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): ", "label": 0}, {"snippet_id": 74762, "code": ".vcf_to_zarr[\"blosc_compression_algorithm\"] if blosc_compression_algorithm_temp in vcf_to_zarr_blosc_algorithm_types: self.blosc_compression_algorithm=blosc_compression_algorithm_temp if \"blosc_compression_level", "label": 0}, {"snippet_id": 51650, "code": " in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard", "label": 0}, {"snippet_id": 8205, "code": " methods provide the functionality of the module: text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is", "label": 0}, {"snippet_id": 50614, "code": "=None self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name", "label": 0}, {"snippet_id": 55392, "code": " claiming more threads will be scaled down.\") provided_resources=format_resources(resources) if provided_resources: logger.resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names", "label": 0}, {"snippet_id": 83842, "code": "\"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message) def check_pid( self, pid): try: os.kill( pid, 0) return", "label": 0}, {"snippet_id": 71778, "code": " %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s", "label": 0}, {"snippet_id": 33508, "code": ": return False dag.updated_subworkflow_files.update(subworkflow.target(f) for f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger", "label": 0}, {"snippet_id": 57478, "code": ".target_field, None) def update(self): has_perms=check_permission(self.request, self.ctype) if not has_perms: return say_no(\"You don't have enough permission to update TestCases.\") action=self.get_update_action", "label": 0}, {"snippet_id": 47392, "code": "() def cleanup(self): \"\"\" Cleanup output files. \"\"\" to_remove=[f for f in self.expanded_output if f.exists] if to_remove: logger.info(\"Removing output files of failed job{}\" \" since they might be corrupted", "label": 0}, {"snippet_id": 36472, "code": " filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self", "label": 0}, {"snippet_id": 46286, "code": "[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath", "label": 0}, {"snippet_id": 21171, "code": ": message +='Event{}'.format(self.name) else: message +='Response{}'.format(self.name) raise TimeoutError(message) class AwaitableResponse(Awaitable): def __init__(self, req, result_getter, event=None)", "label": 0}, {"snippet_id": 70246, "code": " print \"Start of %s %s(%s) succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print", "label": 0}, {"snippet_id": 54341, "code": " self.name.__hash__() def __eq__(self, other): return self.name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 ", "label": 0}, {"snippet_id": 28659, "code": "\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self", "label": 0}, {"snippet_id": 42143, "code": " self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__", "label": 0}, {"snippet_id": 64057, "code": " the local datatypes config to the remote server -but there is no guarentee these datatypes will be defined there. Alternatively, one can use the remote datatype config -but there is no guarentee that it", "label": 0}, {"snippet_id": 59301, "code": " code is run on the IBM quantum chip(instead of using the IBM simulator) num_runs(int): Number of runs to collect statistics.(default is 1024) verbose(bool): If True, statistics are printed, in addition", "label": 0}, {"snippet_id": 2352, "code": " Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s[%(levelname)s]:", "label": 0}, {"snippet_id": 89316, "code": " abstractproperty from builtins import object, open, str from collections import namedtuple from contextlib import contextmanager from future.utils import PY3 from six import string_types from pants.base.revision", "label": 1}, {"snippet_id": 50168, "code": ": self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath", "label": 0}, {"snippet_id": 75321, "code": ".response_handlers[reqid] if seqnum==0: del self.response_handlers[reqid] except KeyError: raise WZENoHandler(iden, 'No rep handler for reqid') handler(reqid, seqnum, status, msg[1:]) return() def _parse_sig(self", "label": 0}, {"snippet_id": 18164, "code": " BuildRequestData from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from", "label": 0}, {"snippet_id": 69970, "code": " name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall a new file system.\" def is_hidden(self", "label": 0}, {"snippet_id": 37378, "code": " \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item ", "label": 0}, {"snippet_id": 78428, "code": " self.log.warning('%s: %s', e, e.answer) self.w.sleep(self.errortimeout) except exc.PermanentError as e: self.log.error(e) self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.log.warn(e", "label": 0}, {"snippet_id": 92474, "code": ".getcwd()) def test_nested_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir1: with pushd(tempdir1): self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) with temporary_dir(root_dir", "label": 0}, {"snippet_id": 82430, "code": ".install(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon", "label": 0}, {"snippet_id": 9736, "code": "\"Single keywords\"]=_get_singlekws(resized_skw, spires=spires) results[\"Field codes\"]=_get_fieldcodes(resized_skw, resized_ckw, spires=spires) results[\"Acronyms\"]=_get_acronyms(acronyms) return results def", "label": 0}, {"snippet_id": 68608, "code": " print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets,", "label": 0}, {"snippet_id": 28868, "code": "=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0", "label": 0}, {"snippet_id": 37679, "code": ".set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on", "label": 0}, {"snippet_id": 49439, "code": "=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False", "label": 0}, {"snippet_id": 68084, "code": " RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map", "label": 0}, {"snippet_id": 66901, "code": ". \"\"\" for rc, nodes in worker.iter_retcodes(): if rc >=126: for buffer, nodes in worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer", "label": 1}, {"snippet_id": 67981, "code": " class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start(self, node, target): pass def ev_statustarget_done", "label": 0}, {"snippet_id": 30663, "code": "=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output=set(), set() self.touch_output=set() self.subworkflow_input=dict() for f in self.output: f_=self.ruleio", "label": 0}, {"snippet_id": 83520, "code": "=dependency_resolution, ) command_line=build_command( self, job_wrapper=job_wrapper, include_metadata=remote_metadata, include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except", "label": 1}, {"snippet_id": 56373, "code": "(field, None) +'</li>' response_str +='</ul>' return HttpResponse(response_str) return HttpResponse(serializers.serialize('json', info_type(), fields=('name', 'value'))) class _InfoObjects(object): def", "label": 0}, {"snippet_id": 30893, "code": " IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output", "label": 1}, {"snippet_id": 40100, "code": ".path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat", "label": 0}, {"snippet_id": 12584, "code": "\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/repos/{}/issues/{}/comments\" url=url.format(repository, str(data[\"pr_number\"])) comments=requests.get(url,", "label": 0}, {"snippet_id": 703, "code": ".Q_GET_CONTAINER_ID) rows=cursor.fetchall() print(rows) finalset=[] datasets_io=[] datasets_mem=[] datasets_perc=[] for row in rows: datasets_io=[] datasets_mem=[] datasets_perc=[] for iter in range(0,2): cursor", "label": 0}, {"snippet_id": 60556, "code": " hbar=2. \"\"\" name='Strawberry Fields OpenQML plugin' short_name='strawberryfields.fock' api_version='0.1.0' version=__version__ author='Josh Izaac' _gates=set(operator_map.keys()) _observables={'Fock',", "label": 0}, {"snippet_id": 32792, "code": " Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag", "label": 0}, {"snippet_id": 80124, "code": "=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs", "label": 0}, {"snippet_id": 80168, "code": "\"upload.php\",dest=\"formAction\",help=\"Path of form action. Example: <form method=\\\"POST\\\" action=\\\"upload.php\\\">\") args=parser.parse_args() args.uploadsPath=args.uploadsPath[0] args.nbThreads=args.nbThreads", "label": 0}, {"snippet_id": 50513, "code": "*args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return", "label": 0}, {"snippet_id": 513, "code": "(password, enc_pwd)==enc_pwd: output='' else: output=\"incorrect password\" except KeyError: output=\"User '%s' not found\" % username if len(output)==0: return JsonResponse({\"username\":username}, safe=False)", "label": 0}, {"snippet_id": 35663, "code": " Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems(self", "label": 0}, {"snippet_id": 59382, "code": ", \"ClassicalSimulator\", \"IBMBackend\"])} def __init__(self, wires, **kwargs): kwargs.setdefault('shots', 0) super().__init__(self.short_name, kwargs['shots']) for k,v in{'log':'verbose'}.items(): if k in", "label": 0}, {"snippet_id": 62002, "code": "'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for", "label": 0}, {"snippet_id": 80697, "code": "\") \texit() b=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: ", "label": 0}, {"snippet_id": 20393, "code": "*kwargs): def connect(addr, timeout): sock=create_client() for _ in range(int(timeout * 10)): try: sock.connect(addr) except(OSError, socket.error): if cls.VERBOSE: print('+', end='') sys.stdout.flush() time", "label": 0}, {"snippet_id": 74281, "code": " values. \"\"\" config=ConfigurationRepresentation(location) return config def generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark", "label": 0}, {"snippet_id": 81194, "code": ", code detection can still be done using true regex capturing group.\") \t\t\tcont=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont", "label": 0}, {"snippet_id": 45620, "code": "=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic,", "label": 1}, {"snippet_id": 82500, "code": " args.cookies: \targs.cookies=postDataFromStringToJSON(args.cookies[0]) if args.manualFormDetection and args.inputName is None: \tparser.error(\"--manual-form-detection requires --input-name\") print(\"\"\"\\033[1", "label": 0}, {"snippet_id": 37799, "code": " item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else", "label": 0}, {"snippet_id": 41450, "code": ".input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources", "label": 0}, {"snippet_id": 87528, "code": ": enabled_args=self.get_options().compiler_option_sets_enabled_args.get(option_set,[]) if option_set=='fatal_warnings': enabled_args=self.get_options().fatal_warnings_enabled_args zinc_args.extend(enabled_args", "label": 0}, {"snippet_id": 61907, "code": "-projectq.backends.IBMBackend([use_hardware,...])\tThe IBM Backend class, which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'", "label": 0}, {"snippet_id": 11719, "code": " update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if os.environ.get(\"OVER_HEROKU\", False) is not False: query=r\"INSERT INTO Users(repository, created_at) VALUES('{}', now());\" \\ ", "label": 0}, {"snippet_id": 38714, "code": "), priorityfiles, forcefiles)) if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules", "label": 0}, {"snippet_id": 41917, "code": "\"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of", "label": 0}, {"snippet_id": 55788, "code": " ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo.func rule.shellcmd", "label": 0}, {"snippet_id": 54316, "code": "._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self): return self", "label": 0}, {"snippet_id": 33859, "code": ".path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile", "label": 0}, {"snippet_id": 63943, "code": ", output_files=output_files, version_file=job_wrapper.get_version_string_path(), ) return client_outputs @staticmethod def __dependencies_description( lwr_client, job_wrapper): dependency_resolution=LwrJobRunner", "label": 1}, {"snippet_id": 68484, "code": ".upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients: (c_ign, c_offline, c_error, c_runtime, c_mounted)=fs.get_client_statecounters() status=[] if c_ign ", "label": 0}, {"snippet_id": 80076, "code": "-user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument", "label": 0}, {"snippet_id": 63376, "code": " include_work_dir_outputs=remote_work_dir_copy, remote_command_params=remote_command_params, ) except Exception: job_wrapper.fail( \"failure preparing job\", exception=True) log.exception(\"failure running job %d\" %", "label": 1}, {"snippet_id": 66070, "code": " print \"FILESYSTEM DISKS(%s)\" % fs.fs_name class target_dict(dict): def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets,", "label": 0}, {"snippet_id": 66440, "code": "\" %(node, client.status_info) else: print \"%s: FS %s succesfully unmounted from %s\" %(node, client.fs.fs_name, client.mount_path) def ev_stopclient_failed(self, node, client, rc, message): if rc: strerr", "label": 1}, {"snippet_id": 88236, "code": " import sys from builtins import filter, object from collections import defaultdict from contextlib import contextmanager from twitter.common.collections import OrderedSet from pants.base.build_environment", "label": 0}, {"snippet_id": 42987, "code": "(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name", "label": 0}, {"snippet_id": 2731, "code": " %s:%s/%s.yaml\" % (host, TMP_SLAVE_DIR, tmp_comp_path, host, TMP_SLAVE_DIR, comp)) self.logger.debug(cmd) send_main_session_command(self.session, cmd) def stop_component(self, comp): if comp['host'] !=", "label": 0}, {"snippet_id": 48775, "code": ", lineno=self.lineno, snakefile=self.snakefile) def is_producer(self, requested_output): \"\"\" Returns True if this rule is a producer of the requested output. \"\"\" try: for o in self.products: if o.match", "label": 0}, {"snippet_id": 28317, "code": " setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION", "label": 0}, {"snippet_id": 54956, "code": " if forcetargets: forcefiles.update(targetfiles) forcerules.update(targetrules) rules=self.rules if allowed_rules: rules=[rule for rule in rules if rule.name in set(allowed_rules)] if wait_for_files is", "label": 0}, {"snippet_id": 1305, "code": "=ps.split('\\n') wifi=[] for row in wifirows: entry=row.split(':') print(entry) wifi.append(entry) return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker", "label": 1}, {"snippet_id": 50315, "code": " raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule) rule.resources", "label": 0}, {"snippet_id": 29225, "code": "(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not", "label": 1}, {"snippet_id": 2315, "code": ".html') class BoxDetailsViewSet(viewsets.ModelViewSet): queryset=BoxDetails.objects.all() serializer_class=BoxDetailsSerializer class RegisteredServicesViewSet(viewsets.ModelViewSet): queryset=RegisteredServices", "label": 0}, {"snippet_id": 69907, "code": "=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes(), fsname)) fs.set_debug(self.debug_support", "label": 0}, {"snippet_id": 24876, "code": "=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0", "label": 0}, {"snippet_id": 63929, "code": ".get_work_dir_outputs( job_wrapper) else: work_dir_outputs=[] output_files=self.get_output_files( job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs", "label": 1}, {"snippet_id": 43221, "code": " is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set", "label": 0}, {"snippet_id": 66674, "code": " self.cmds: if not cmd.is_hidden(): print \" %-*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd", "label": 0}, {"snippet_id": 36764, "code": " \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)) class Reason: def __init__(self): self.updated_input=set() self.updated_input_run=set() self", "label": 0}, {"snippet_id": 15153, "code": " OmniCompleter from ycm.completers.general import syntax_parse from ycm.completers.completer_utils import FiletypeCompleterExistsForFiletype from ycm.client.ycmd_keepalive import YcmdKeepalive from ycm.client", "label": 0}, {"snippet_id": 44658, "code": " overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack", "label": 0}, {"snippet_id": 14090, "code": ") return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest.server_location, handler) SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy", "label": 0}, {"snippet_id": 82765, "code": ".warning(\"Using Manual Form Detection and no action specified with --form-action. Defaulting to empty string -meaning form action will be set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex", "label": 0}, {"snippet_id": 45571, "code": "(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.", "label": 1}, {"snippet_id": 66658, "code": " print_csdebug) def usage(self): cmd_maxlen=0 for cmd in self.cmds: if not cmd.is_hidden(): if len(cmd.get_name()) > cmd_maxlen: cmd_maxlen=len(cmd.get_name()) for cmd in self.cmds: if not cmd.is_hidden", "label": 0}, {"snippet_id": 66844, "code": ".append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"-t %s\" % self.targets_type) if self.targets_indexes: command.append(\"-i", "label": 0}, {"snippet_id": 50173, "code": ", workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with", "label": 0}, {"snippet_id": 18615, "code": ": return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self, qflist_format=False): if self.DiagnosticsForCurrentFileReady(): diagnostics", "label": 0}, {"snippet_id": 14118, "code": " SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData( data): if data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__:", "label": 0}, {"snippet_id": 27713, "code": "\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state", "label": 0}, {"snippet_id": 17303, "code": " options_file) options_file.flush() args=[ utils.PathToPythonInterpreter(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self", "label": 0}, {"snippet_id": 87988, "code": " we can't know which external classpath elements are required, and we'd have to put the entire external classpath on each -Xplugin: flag, which seems excessive. Instead, external plugins should be published", "label": 0}, {"snippet_id": 50057, "code": ".get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd", "label": 0}, {"snippet_id": 29605, "code": "\" \"appear in a string, eventual constraints have to be defined \" \"at the first occurence and will be inherited by the others.\") f.append(\"(?P={})\".format(wildcard)) else: wildcards.add(wildcard) f.append", "label": 0}, {"snippet_id": 43112, "code": " the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing", "label": 0}, {"snippet_id": 22054, "code": ".syntax=syntax self.diff=diff self.force_handlers=force_handlers self.flush_cache=flush_cache self.listtasks=listtasks self.listtags=listtags self.module_path=module_path class Runner(object): def __init__", "label": 0}, {"snippet_id": 95715, "code": "=str(path) file_output_str=path_leaf(path_str) file_output_str=file_output_str[0:len(file_output_str) -3] path_temp_output=str(pathlib.Path(temp_dir, file_output_str)) print(\"[Setup][Data] Decompressing", "label": 0}, {"snippet_id": 43200, "code": " None: ruleio[concrete]=item_ else: if not_iterable(item): item=[item] is_iterable=False for item_ in item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio", "label": 0}, {"snippet_id": 90133, "code": "._validated_binaries[name]=exe return exe @contextmanager def _valid_executable(self, name): exe=self._validate_executable(name) yield exe self._validated_binaries[name]=exe def __repr__(self): return(", "label": 0}, {"snippet_id": 54687, "code": " self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a", "label": 0}, {"snippet_id": 38750, "code": " self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules,", "label": 0}, {"snippet_id": 70802, "code": " status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes", "label": 0}, {"snippet_id": 31136, "code": ".dynamic_output)): os.remove(f) for f, f_ in zip(self.output, self.rule.output): f.prepare() for f in self.log: f.prepare() if self.benchmark: self.benchmark.prepare() def cleanup(self): \"\"\" Cleanup output files", "label": 0}, {"snippet_id": 75880, "code": " wz_multiwait(self, requests): s, p, t, wz=self.wz_sock, self.poll, self.sleep_ticker, self.wz timeout=self.wz_poll_timeout rslist=[] msgdict={} for request in requests: rs=wzrpc.RequestState(request[0", "label": 0}, {"snippet_id": 94613, "code": ": window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a '%s')\" % file, \"Enter", "label": 0}, {"snippet_id": 48288, "code": "\"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else:", "label": 0}, {"snippet_id": 73577, "code": ".vcf_read.DEFAULT_CHUNK_WIDTH if conversion_config.chunk_width is not None: chunk_width=conversion_config.chunk_width print(\"[VCF-Zarr] Chunk width:{}\".format(chunk_width)) if conversion_config.compressor", "label": 0}, {"snippet_id": 21444, "code": " and files.\" % sr_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f:", "label": 0}, {"snippet_id": 64100, "code": " def __build_metadata_configuration(self, client, job_wrapper, remote_metadata, remote_job_config): metadata_kwds={} if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\"", "label": 0}, {"snippet_id": 82410, "code": ".verbose: \targs.verbosity=1 if args.veryVerbose: \targs.verbosity=2 if args.veryVeryVerbose: \targs.verbosity=3 logger.verbosity=args.verbosity if args.verbosity > 0: \tcoloredlogs.install(logger=logger,fmt=", "label": 0}, {"snippet_id": 90185, "code": " home): \"\"\"Creates a location given the JAVA_HOME directory. :param string home: The path of the JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None", "label": 0}, {"snippet_id": 60610, "code": ".eng: self.eng.reset() self.reset() self.eng, q=sf.Engine(self.wires, hbar=self.hbar) with self.eng: for operation in self._queue: if operation.name not in operator_map: raise DeviceError(\"{} not supported", "label": 0}, {"snippet_id": 62827, "code": ".filter_kwargs_for_backend(self.kwargs)) self.eng=pq.MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0]", "label": 0}, {"snippet_id": 30178, "code": "\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the", "label": 0}, {"snippet_id": 20771, "code": " handlername='event{!r}'.format(event) with self._wait_for_message(match, handlername, **kwargs): yield result def get_awaiter_for_event(self, event, condition=lambda msg: True, **kwargs): if self.closed", "label": 0}, {"snippet_id": 83075, "code": ".jobs.command_factory import build_command from galaxy.tools.deps import dependencies from galaxy.util import string_as_bool_or_none from galaxy.util.bunch import Bunch import errno from time import sleep", "label": 0}, {"snippet_id": 52746, "code": ".check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \"", "label": 0}, {"snippet_id": 70378, "code": "(target_type) fs.set_debug(self.debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc >", "label": 0}, {"snippet_id": 90047, "code": "('Failed to determine java system properties for{} with{} -exit code' '{}:{}'.format(java, ' '.join(cmd), process.returncode, stderr.decode('utf-8'))) props={} for line in stdout.decode('utf-8').split(os", "label": 0}, {"snippet_id": 2853, "code": "]: self.logger.debug(\"Checking and starting %s\" % node.comp_name) state=self.check_component(node.component) if(state is CheckState.STOPPED_BUT_SUCCESSFUL or state is CheckState.STARTED_BY_HAND or state", "label": 0}, {"snippet_id": 5594, "code": " spires: bool, to get the spires output :return: set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i", "label": 0}, {"snippet_id": 42462, "code": " self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log", "label": 0}, {"snippet_id": 73535, "code": " numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\"", "label": 0}, {"snippet_id": 32979, "code": ": for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno", "label": 0}, {"snippet_id": 59276, "code": " executed once a certain gate-size has been reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). Keyword Args for IBMBackend backend", "label": 0}, {"snippet_id": 84995, "code": " dependencies.') register('--version', advanced=True, default='2.12', choices=['2.10', '2.11', '2.12', 'custom'], fingerprint=True, help='The scala platform version. If --version=custom, the targets ' '//", "label": 0}, {"snippet_id": 89399, "code": ") return version class Distribution(object): \"\"\"Represents a java distribution -either a JRE or a JDK installed on the local system. In particular provides access to the distribution's binaries; ie: java", "label": 0}, {"snippet_id": 63613, "code": "*finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.", "label": 0}, {"snippet_id": 82431, "code": "(logger=logger,fmt='%(asctime)s %(levelname)s -%(message)s',level=logging.DEBUG) if args.proxyCreds and args.proxy==None: \tparser.error(\"--proxy-creds must be used with --proxy.\") if args.skipRecon and args", "label": 0}, {"snippet_id": 41340, "code": "<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic.\"", "label": 0}, {"snippet_id": 24249, "code": "'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength', 'km/h', 'mdi:weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value'", "label": 0}, {"snippet_id": 1905, "code": " counter_val=cursor.fetchall() datasets_mem.append(counter_val) for iter in range(4,8): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_io.append(counter_val", "label": 0}, {"snippet_id": 86632, "code": " f: classname=javac_plugin_target.classname if PY3 else javac_plugin_target.classname.decode('utf-8') f.write(classname) @staticmethod def validate_arguments(log, whitelisted_args, args): \"\"\"Validate that", "label": 0}, {"snippet_id": 93798, "code": " self.start_remote_component(comp['name'], comp['host']) else: log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '", "label": 0}, {"snippet_id": 48409, "code": "=name) def _set_params_item(self, item, name=None): if isinstance(item, str) or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item:", "label": 0}, {"snippet_id": 53986, "code": "(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input", "label": 0}, {"snippet_id": 12317, "code": "[filename +\"_link\"]=url.format(repository, after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its header, body and", "label": 0}, {"snippet_id": 75304, "code": ") handler(reqid, interface, method, msg[1:]) return() def _parse_rep(self, iden, msg, reqid, seqnum, status): try: handler=self.response_handlers[reqid] if seqnum==0: del self.response_handlers[reqid] except", "label": 0}, {"snippet_id": 72941, "code": ".join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try: ftp.retrbinary('RETR %s' % remote_filename, local_file.write) print(\"[Setup][FTP]({", "label": 0}, {"snippet_id": 44429, "code": ".rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes", "label": 0}, {"snippet_id": 42086, "code": ", res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self", "label": 0}, {"snippet_id": 60234, "code": " Kgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing': S2gate, 'Squeezing': Sgate, 'CubicPhase': Vgate, } class StrawberryFieldsFock(Device): \"\"\"StrawberryFields Fock device for OpenQML.", "label": 0}, {"snippet_id": 34632, "code": " os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink() return os.path.getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError", "label": 1}, {"snippet_id": 43377, "code": " \"\"\" try: for o in self.products: if o.match(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile", "label": 0}, {"snippet_id": 78950, "code": " containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way", "label": 0}, {"snippet_id": 74199, "code": " runtime_config is not None: if hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config.benchmark: try: self.benchmark_number_runs=int(runtime_config.benchmark[\"benchmark_number_runs\"", "label": 0}, {"snippet_id": 60023, "code": "\"user\" keyword argument is required') if 'password' not in kwargs: raise ValueError('An IBM Quantum Experience password specified via the \"password\" keyword argument is required') kwargs['backend']='IBMBackend", "label": 0}, {"snippet_id": 32785, "code": ".logging import logger, format_resources, format_resource_names from snakemake.rules import Rule, Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException", "label": 0}, {"snippet_id": 22960, "code": "-IP's CD/DVD device This device is almost certainly /dev/cdrom so I added the ? to this pattern. Note that this method will return upon the first device found, but in my tests with 12.1.1 it will also find", "label": 0}, {"snippet_id": 34689, "code": " len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat", "label": 0}, {"snippet_id": 12270, "code": ".py:\\d+:\\d+:\\s[WE]\\d+\\s.*\", error): data[\"results\"][filename].append(error.replace(\"file_to_check.py\", filename)) data[\"extra_results\"][filename].remove(error) for error in list(data[\"results\"][filename", "label": 0}, {"snippet_id": 94947, "code": "=True config_parser=subparser.add_parser(\"config\", help='Setting up the default configuration of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\"", "label": 0}, {"snippet_id": 91933, "code": "(PythonNativeCode, cls).register_options(register) register('--native-source-extensions', type=list, default=cls.default_native_source_extensions, fingerprint=True, advanced=True, help='The extensions recognized", "label": 0}, {"snippet_id": 33156, "code": "=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None", "label": 0}, {"snippet_id": 48013, "code": ".touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values)", "label": 0}, {"snippet_id": 69422, "code": " try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. \"\"\" for rc,", "label": 0}, {"snippet_id": 57306, "code": " request.user ) ) t.save() except(AttributeError, User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"\"", "label": 0}, {"snippet_id": 79241, "code": "[0].text \t\t\text=future.ext[0] \t\t\tr=self.isASuccessfulUpload(html) \t\t\tif r: \t\t\t\tself.validExtensions.append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for", "label": 0}, {"snippet_id": 3640, "code": " run_component_check(comp): logger.debug(\"Process terminated but check was successful\") return CheckState.STOPPED_BUT_SUCCESSFUL else: logger.debug(\"Check failed or no check available: returning false\") return CheckState", "label": 0}, {"snippet_id": 57804, "code": "{self.target_field: sortkey} while 1: sub_cases=update_targets[offset:offset +step_length] case_pks=[case.pk for case in sub_cases] if len(case_pks)==0: break queryset_filter(plan=plan, case__in=case_pks", "label": 0}, {"snippet_id": 95889, "code": "(file_output_str) -4] path_zarr_output=str(pathlib.Path(output_zarr_dir, file_output_str)) print(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\" -Output:{}\".format(path_zarr_output", "label": 0}, {"snippet_id": 40886, "code": " names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os", "label": 0}, {"snippet_id": 34659, "code": ".file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill", "label": 1}, {"snippet_id": 49810, "code": " handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in", "label": 0}, {"snippet_id": 66835, "code": " \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if self.targets_type: command.append(\"", "label": 0}, {"snippet_id": 34108, "code": ".priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log", "label": 0}, {"snippet_id": 6612, "code": " %s.\" % local_file) text_lines=extractor.text_lines_from_local_file(local_file) return get_keywords_from_text(text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires", "label": 0}, {"snippet_id": 30614, "code": "._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self.benchmark, self.ruleio, self.dependencies)", "label": 0}, {"snippet_id": 21687, "code": "=0.75, cmap=ListedColormap(('red', 'green'))) plt.xlim(X1.min(), X1.max()) plt.ylim(X2.min(), X2.max()) for i, j in enumerate(np.unique(y_set)): plt.scatter(X_set[y_set==j, 0], X_set[y_set==j, 1], c=ListedColormap", "label": 0}, {"snippet_id": 82959, "code": "\t\tfor a in attempts: \t\t\tsuffix=a[\"suffix\"] \t\t\tmime=a[\"mime\"] \t\t\tpayload=templatesData[a[\"templateName\"]] \t\t\tcodeExecRegex=[t[\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]]", "label": 0}, {"snippet_id": 92450, "code": ": pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir) as path: self.assertEqual(tempdir, path) self.assertEqual(os.path.realpath(tempdir), os.getcwd()) self.assertEqual(pre_cwd, os", "label": 0}, {"snippet_id": 41610, "code": " message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule", "label": 0}, {"snippet_id": 4154, "code": ".utils.url import make_user_agent_string from invenio.utils.text import encode_for_xml log=bconfig.get_logger(\"bibclassify.engine\") def output_keywords_for_sources(input_sources, taxonomy_name, output_mode", "label": 1}, {"snippet_id": 87587, "code": ".javac_classpath()))]) jvm_options.extend(self._jvm_options) zinc_args.extend(ctx.sources) self.log_zinc_file(ctx.analysis_file) with open(ctx.zinc_args_file, 'wb') as fp: for arg in zinc_args: fp.write(arg) fp", "label": 0}, {"snippet_id": 64883, "code": " RemoteCommand from Base.Support.FS import FS import os class Preinstall(RemoteCommand): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self)", "label": 0}, {"snippet_id": 19311, "code": ") tmp_file=tempfile.NamedTemporaryFile(mode='w') tmp_file.write(source) tmp_file.flush() with open(tmp_file.name) as yaml_file: result=load_source(yaml_file) assert result==native def test_yaml_file_path", "label": 0}, {"snippet_id": 79430, "code": "\t\t\treturn True \t\telse: \t\t\treturn False \t \t \tdef submitTestCase(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text", "label": 1}, {"snippet_id": 41425, "code": "=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards", "label": 0}, {"snippet_id": 12453, "code": "/duckduckgo.com/?q=pep8%20{0}\".format(code) error_string_list[2]=\"[{0}]({1})\".format(code, code_url) line, col=error_string_list[1][:-1].split(\":\") line_url=data[file +\"_link\"] +\" error_string_list[1]=\"[{0}:{1", "label": 0}, {"snippet_id": 26745, "code": "'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle", "label": 0}, {"snippet_id": 56117, "code": ".workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job.subworkflow_input if job.subworkflow_input[f] is self", "label": 0}, {"snippet_id": 92085, "code": " platform_names or platform_names==['current']: return True bad_targets=set() for platform, targets in platforms_with_sources.items(): if platform=='current': continue bad_targets.update(targets) raise", "label": 0}, {"snippet_id": 54515, "code": " Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder(", "label": 0}, {"snippet_id": 5776, "code": ", v in keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort", "label": 0}, {"snippet_id": 37682, "code": ")) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards", "label": 0}, {"snippet_id": 63678, "code": " Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper.job_id)) job_state.job_wrapper.fail( job_state.fail_message)", "label": 0}, {"snippet_id": 48665, "code": ".wildcard_names)), lineno=self.lineno, snakefile=self.snakefile) ruleio=dict() try: input=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj", "label": 0}, {"snippet_id": 18947, "code": "(os.path.expanduser(str(source)), 'r') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts.scheme and parts.netloc: response", "label": 0}, {"snippet_id": 4355, "code": " with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name, output_mode=", "label": 0}, {"snippet_id": 23053, "code": " This is the _first_ hook that WAAgent provides for us, so this is the point where we should wait for mcpd to load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock", "label": 0}, {"snippet_id": 88111, "code": " is a scalac plugin, returns its name. Returns None otherwise. \"\"\" def process_info_file(cp_elem, info_file): plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag !='plugin': raise TaskError", "label": 0}, {"snippet_id": 1326, "code": "\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints", "label": 1}, {"snippet_id": 85759, "code": ", scope=scope) classpaths=(cp(java_options_src, 'javac-plugin-dep') + cp(scala_options_src, 'scalac-plugin-dep')) return[(conf, ClasspathEntry(jar)) for conf in self.DEFAULT_CONFS for jar in classpaths", "label": 0}, {"snippet_id": 34685, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode ", "label": 0}, {"snippet_id": 25233, "code": " 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength':['Strength'", "label": 0}, {"snippet_id": 64155, "code": "]=remote_galaxy_home default_config_file=os.path.join(remote_galaxy_home, 'universe_wsgi.ini') metadata_kwds['config_file']=remote_system_properties.get('galaxy_config_file', default_config_file) metadata_kwds", "label": 0}, {"snippet_id": 82641, "code": ",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests.Session() if args.cookies: \tfor key in args.cookies.keys(): \t\ts.cookies[key]=args.cookies[key] s.headers={'User", "label": 0}, {"snippet_id": 30941, "code": " wildcards @property def missing_input(self): \"\"\" Return missing input files. \"\"\" return set(f for f in self.input if not f.exists and not f in self.subworkflow_input) @property def output_mintime(self): ", "label": 0}, {"snippet_id": 89641, "code": " version(self): \"\"\"Returns the distribution version. Raises Distribution.Error if this distribution is not valid according to the configured constraints. \"\"\" return self._get_version(self.java) def find_libs", "label": 0}, {"snippet_id": 55484, "code": " overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack", "label": 0}, {"snippet_id": 41870, "code": "=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def", "label": 0}, {"snippet_id": 35239, "code": " file that shall be dynamic, i.e. the multiplicity (and wildcard values) will be expanded after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated", "label": 1}, {"snippet_id": 73636, "code": " copyfile import os.path from pkg_resources import resource_string from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str", "label": 0}, {"snippet_id": 62833, "code": ".MainEngine(backend, engine_list=pq.setups.ibm.get_engine_list()) super().reset() def expectation(self, observable, wires): pq.ops.R(0) | self.reg[0] pq.ops.All(pq.ops.Measure) | self.reg self.eng.flush() if", "label": 0}, {"snippet_id": 25501, "code": " of measurement of this entity, if any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data", "label": 0}, {"snippet_id": 18772, "code": " return[ os.path.join( current_working_directory, x) for x in tag_files] if not self._user_options[ 'collect_identifiers_from_tags_files']: return extra_data[ 'tag_files']=GetTagFiles() def _AddExtraConfDataIfNeeded", "label": 0}, {"snippet_id": 4796, "code": " extracted acronyms :keyword style: text|html|marc :keyword output_limit: int, number of maximum keywords printed(it applies to single and composite keywords separately) :keyword spires: boolen meaning", "label": 0}, {"snippet_id": 41612, "code": ": \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule)", "label": 0}, {"snippet_id": 22448, "code": "(self): return shellutil.run(\"/usr/bin/bigstart restart sshd\", chk_err=False) def stop_agent_service(self): return shellutil.run(\"/sbin/service waagent stop\", chk_err=False) def start_agent_service(self", "label": 0}, {"snippet_id": 35619, "code": "\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index", "label": 0}, {"snippet_id": 47715, "code": " import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards", "label": 0}, {"snippet_id": 42330, "code": " snakemake.exceptions import RuleException, IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name", "label": 0}, {"snippet_id": 59217, "code": " SqrtXGate, SwapGate, SqrtSwapGate, Rx, Ry, Rz, R) from.ops import(CNOT, CZ, Toffoli, AllZGate, Rot, Hermitian) from._version import __version__ operator_map={ 'PauliX': XGate, 'PauliY': YGate, 'PauliZ': ZGate,", "label": 0}, {"snippet_id": 4970, "code": ".CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords in the MARCXML format. :var skw_matches: list of single keywords :var ckw_matches: list of composite keywords ", "label": 0}, {"snippet_id": 66963, "code": ")) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len", "label": 0}, {"snippet_id": 41863, "code": " f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files", "label": 0}, {"snippet_id": 68071, "code": " def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE", "label": 0}, {"snippet_id": 79806, "code": "/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar=\"templateName\",nargs=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates.", "label": 0}, {"snippet_id": 56753, "code": ".html', TestPlan.objects.get(pk=self.object_pk) def case(self): return 'management/get_tag.html', TestCase.objects.get(pk=self.object_pk) def run(self): return 'run/get_tag.html', TestRun.objects.get(pk", "label": 0}, {"snippet_id": 26372, "code": ") else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable", "label": 1}, {"snippet_id": 13621, "code": "=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r return\r \r os.system( \"espeak \\\",...\\\" 2>/dev", "label": 0}, {"snippet_id": 63596, "code": " job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if", "label": 0}, {"snippet_id": 6794, "code": "=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else:", "label": 0}, {"snippet_id": 47323, "code": " creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if", "label": 0}, {"snippet_id": 91883, "code": ".executable_pex_tool import ExecutablePexTool from pants.subsystem.subsystem import Subsystem from pants.util.memo import memoized_property from pants.util.objects import SubclassesOf logger=logging.getLogger", "label": 1}, {"snippet_id": 3392, "code": ".flag_path=(\"/tmp/Hyperion/slaves/%s\" % self.window_name) self.log_file=(\"/tmp/Hyperion/log/%s\" % self.window_name) ensure_dir(self.log_file) else: self.logger.error(\"No slave component config provided", "label": 0}, {"snippet_id": 37972, "code": "): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError as ex: raise IOFileException", "label": 0}, {"snippet_id": 67018, "code": "\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg=self.cmd_optargs[opt[-1:]] elif next_is_arg", "label": 0}, {"snippet_id": 57814, "code": " for case in sub_cases] if len(case_pks)==0: break queryset_filter(plan=plan, case__in=case_pks).update(**data) offset +=step_length def _update_reviewer(self): reviewers=User.objects.filter(username=self", "label": 0}, {"snippet_id": 15024, "code": "://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data", "label": 0}, {"snippet_id": 82944, "code": ":suffix,\"mime\":mime,\"templateName\":template[\"templateName\"]}) stopThreads=False attemptsTested=0 with concurrent.futures.ThreadPoolExecutor(max_workers=args.nbThreads) as executor: \tfutures=[] \ttry: \t\tfor a", "label": 1}, {"snippet_id": 55987, "code": " return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator", "label": 0}, {"snippet_id": 63477, "code": " params.iteritems(): if value: params[key]=model.User.expand_user_properties( job_wrapper.get_job().user, value) env=getattr( job_wrapper.job_destination, \"env\",[]) return self.get_client( params, job_id", "label": 0}, {"snippet_id": 24568, "code": "'sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2", "label": 0}, {"snippet_id": 14667, "code": " ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info", "label": 0}, {"snippet_id": 49878, "code": ": items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs)", "label": 0}, {"snippet_id": 39821, "code": " def snakefile(self): if self._snakefile is None: return os.path.abspath(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow", "label": 0}, {"snippet_id": 69551, "code": ".cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=[] try: next_is_arg=False for opt in args: if opt.startswith('-'): new_args.append(opt) next_is_arg", "label": 0}, {"snippet_id": 73921, "code": "): \"\"\" Creates an object representation of VCF to Zarr Conversion module configuration data. :param runtime_config: runtime_config data to extract conversion configuration from :type runtime_config: ConfigurationRepresentation", "label": 0}, {"snippet_id": 63179, "code": " found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line, client, remote_job_config, compute_environment=self.__prepare_job( job_wrapper, job_destination) if", "label": 0}, {"snippet_id": 21320, "code": "') parser.add_argument('--depth', metavar='d', type=int, default=0, help='How many pages into the subreddit you want to go.') parser.add_argument('subreddit', type=str, help='The subreddit you want to play", "label": 0}, {"snippet_id": 88520, "code": "\"Returns the Products manager for the current run. :API: public \"\"\" return self._products @property def source_roots(self): \"\"\"Returns the:class:`pants.source.source_root.SourceRoots` instance for the current", "label": 0}, {"snippet_id": 31995, "code": " for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item.rule _item=IOFile(item, rule=self) if is_flagged(item,", "label": 0}, {"snippet_id": 28015, "code": "'wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data", "label": 0}, {"snippet_id": 33777, "code": ".join(dag.stats())) else: logger.info(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag)", "label": 0}, {"snippet_id": 44066, "code": ".is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=", "label": 0}, {"snippet_id": 31314, "code": " is None: return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other", "label": 0}, {"snippet_id": 59410, "code": " if isinstance(kwargs['num_runs'], int) and kwargs['num_runs']>0: self.n_eval=kwargs['num_runs'] else: self.n_eval=0 del(kwargs['num_runs']) self.wires=wires self.backend=kwargs['backend'] del(kwargs['backend", "label": 0}, {"snippet_id": 55126, "code": " and not printrulegraph: globals_backup=dict(self.globals) for subworkflow in self.subworkflows: subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing", "label": 0}, {"snippet_id": 67974, "code": ", GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776) class GlobalStatusEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_statustarget_start", "label": 0}, {"snippet_id": 21543, "code": " x=os.system(\"mpv %(args)s %(link)s\" %{\"link\": link, \"args\": mpv}) print(\"Reddytt: That was: %s\" % link) if x==0: seen_links.append(link) save_links.remove(link) elif x==1024: print(\"Reddytt: Forced exit", "label": 1}, {"snippet_id": 9496, "code": " acronyms)) output.append('</record></collection>') return '\\n'.join(output) def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig", "label": 0}, {"snippet_id": 23826, "code": " return shellutil.run('ps -p{0}'.format(pid), chk_err=False)==0 @staticmethod def _get_net_info(): \"\"\" There is no SIOCGIFCONF on freeBSD -just parse ifconfig. Returns strings: iface, inet4_addr, and mac", "label": 0}, {"snippet_id": 94278, "code": ".info(\"Shutting down window...\") kill_window(window) self.logger.info(\"... done!\") elif not self.kill_mode: self.logger.info(\"creating window '%s'\" % self.window_name) window=self.session.new_window(self", "label": 0}, {"snippet_id": 56682, "code": "{ 'tags': all_tags, 'object': obj, } return render(request, template_name, context_data) class _TagObjects(object): \"\"\" Used for getting the chosen object(TestPlan, TestCase or TestRun) from the database", "label": 0}, {"snippet_id": 80052, "code": " parser.add_argument(\"-T\",\"--threads\",metavar=\"Threads\",nargs=1,dest=\"nbThreads\",help=\"Number of parallel tasks(threads).\",type=int,default=[4]) exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group(", "label": 0}, {"snippet_id": 29678, "code": ": if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return", "label": 0}, {"snippet_id": 40551, "code": ": value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v, flag_type, flag_value=flag_value) for", "label": 0}, {"snippet_id": 79438, "code": "(self,suffix,mime,payload=None,codeExecRegex=None): \t\tfu=self.uploadFile(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes", "label": 1}, {"snippet_id": 51968, "code": " def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name", "label": 0}, {"snippet_id": 21283, "code": "', lk)[1] if videolabel is None: print('Reddytt: skipping URL without video label:', lk) continue new_links.append('https://www.youtube.com/watch?v=' +videolabel) return new_links, links if __name__=='__main__", "label": 0}, {"snippet_id": 60628, "code": " DeviceError(\"{} not supported by device{}\".format(operation.name, self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance", "label": 0}, {"snippet_id": 10789, "code": " word_number > expected_word_number def text_lines_from_url(url, user_agent=\"\"): \"\"\"Returns the fulltext of the file found at the URL.\"\"\" request=urllib2.Request(url) if user_agent: request.add_header(", "label": 1}, {"snippet_id": 37054, "code": ".subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority self.version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set", "label": 0}, {"snippet_id": 56483, "code": " query=strip_parameters(self.request.GET, skip_parameters=('info_type', 'field', 'format')) return User.objects.filter(**query) def versions(self): return Version.objects.filter(product__id=self.product_id)", "label": 0}, {"snippet_id": 70609, "code": " def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE", "label": 0}, {"snippet_id": 37625, "code": " @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item", "label": 0}, {"snippet_id": 93755, "code": "(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return", "label": 0}, {"snippet_id": 66385, "code": " Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine", "label": 0}, {"snippet_id": 23744, "code": " OSUtilError(\"Failed to get total memory:{0}\".format(output)) try: return int(output)/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self)", "label": 0}, {"snippet_id": 85378, "code": ".jar_dependency import JarDependency from pants.subsystem.subsystem import Subsystem from pants.util.dirutil import fast_relpath from pants.util.memo import memoized_method, memoized_property class Zinc(object):", "label": 1}, {"snippet_id": 87671, "code": ") merged_input_digest=self.context._scheduler.merge_directories( tuple(s.directory_digest for s in(snapshots)) +directory_digests ) argv=tuple(['.jdk/bin/java'] +jvm_options +['-cp', zinc_relpath, Zinc", "label": 0}, {"snippet_id": 4877, "code": " _kw(_sort_kw_matches(acronyms, output_limit))) else: my_styles[\"raw\"]=(single_keywords_p, composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords", "label": 0}, {"snippet_id": 44029, "code": ", resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0, no_hooks=False): self.global_resources", "label": 0}, {"snippet_id": 33819, "code": " return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None):", "label": 0}, {"snippet_id": 11433, "code": " @staticmethod def create_filename(hostname): name='%s.cfg' % hostname if name !=os.path.basename(name): msg=\"Directory traversal attempt detected for host name %r\" raise Exception(msg % hostname) return", "label": 0}, {"snippet_id": 64590, "code": " nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(),", "label": 0}, {"snippet_id": 51980, "code": ".items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__", "label": 0}, {"snippet_id": 81963, "code": "=1,dest=\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument", "label": 0}, {"snippet_id": 44941, "code": "(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule.version=ruleinfo.version if ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if", "label": 0}, {"snippet_id": 70427, "code": " and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the filesystem, or if needed, to enquire about filesystem", "label": 0}, {"snippet_id": 43963, "code": " cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False, cluster=None", "label": 0}, {"snippet_id": 34491, "code": " so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return", "label": 0}, {"snippet_id": 46037, "code": "\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return flag(value, \"protected", "label": 0}, {"snippet_id": 43533, "code": " \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. \"\"\"", "label": 0}, {"snippet_id": 41121, "code": " if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index", "label": 0}, {"snippet_id": 76774, "code": " default=0.8, help='Captcha rate limit') parser.add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser.add_argument('--topic_successtimeout', type=float,", "label": 0}, {"snippet_id": 6347, "code": " of sources(local files or URLs, PDF or text) while the second one outputs the keywords for text lines(which are obtained using the module bibclassify_text_normalizer). This module also takes care of the", "label": 0}, {"snippet_id": 13104, "code": "=r.json()[\"full_name\"] FORKED=True else: data[\"error\"]=\"Unable to fork\" return FORKED def update_fork_desc(data): url=\"https://api.github.com/repos/{}\".format(data[\"fork_fullname\"]) headers={\"Authorization", "label": 0}, {"snippet_id": 57094, "code": ") ctype=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data.get('field') value=data.get('value') object_pk=[int(a) for a in object_pk_str.split('", "label": 0}, {"snippet_id": 55466, "code": " no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False", "label": 0}, {"snippet_id": 40842, "code": " Returns a named tuple with a list of values for each wildcard. \"\"\" pattern=os.path.normpath(pattern) first_wildcard=re.search(\"{[^{]\", pattern) dirname=os.path.dirname(pattern[:first_wildcard.start( )", "label": 0}, {"snippet_id": 12982, "code": "+os.environ[\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) url=\"https://api.github.com/gists\" res=requests.post(url, json=REQUEST_JSON, headers=headers, auth=auth).json()", "label": 0}, {"snippet_id": 5125, "code": ", encode_for_xml(kw), '', encode_for_xml(categories[kw]))) return \"\".join(output) def _output_complete(skw_matches=None, ckw_matches=None, author_keywords=None, acronyms=None, spires=False, only_core_tags", "label": 0}, {"snippet_id": 34154, "code": "=ruleinfo.func rule.shellcmd=ruleinfo.shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate", "label": 0}, {"snippet_id": 6724, "code": " :return: if output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name", "label": 0}, {"snippet_id": 85990, "code": ") @classmethod def get_fatal_warnings_enabled_args_default(cls): return('-Werror',) @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register", "label": 0}, {"snippet_id": 13069, "code": " FORKED def fork_for_pr(data): FORKED=False url=\"https://api.github.com/repos/{}/forks\" url=url.format(data[\"target_repo_fullname\"]) headers={\"Authorization\": \"token \" +os.environ[\"GITHUB_TOKEN\"]} auth", "label": 0}, {"snippet_id": 20916, "code": " self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn", "label": 0}, {"snippet_id": 47933, "code": " else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for", "label": 0}, {"snippet_id": 60221, "code": "'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'CrossKerr': CKgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'Kerr': Kgate, 'QuadraticPhase': Pgate, 'Rotation", "label": 0}, {"snippet_id": 36468, "code": " return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output", "label": 0}, {"snippet_id": 24390, "code": " SENSOR_TYPES.keys(): dev.append(NetAtmoSensor(data, module_name, variable)) else: _LOGGER.warning(\"Ignoring unknown var %s for mod %s\", variable, module_name) except pyatmo.NoDevice: return None add_devices", "label": 0}, {"snippet_id": 10839, "code": " %s.\" % url) return None else: lines=text_lines_from_local_file(local_file, remote=True) os.remove(local_file) line_nb=len(lines) word_nb=0 for line in lines: word_nb +=len(re.findall(\"\\S+\", line)) log", "label": 1}, {"snippet_id": 50459, "code": " *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo", "label": 0}, {"snippet_id": 21511, "code": "-variable to progress deeper.\") else: newer_links, links=getytlinks(link) new_links +=newer_links new_links=list(set(new_links)) new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for", "label": 0}, {"snippet_id": 25862, "code": "% data['WindAngle'] elif self.type=='windstrength': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >", "label": 0}, {"snippet_id": 25306, "code": " vol.All(cv.ensure_list,[vol.In(SENSOR_TYPES)]), }) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass", "label": 0}, {"snippet_id": 41745, "code": "=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append", "label": 0}, {"snippet_id": 28306, "code": "}) PLATFORM_SCHEMA=PLATFORM_SCHEMA.extend({ vol.Optional(CONF_STATION): cv.string, vol.Optional(CONF_MODULES): MODULE_SCHEMA, }) def setup_platform(hass, config, add_devices, discovery_info=None): \"\"\"Set", "label": 0}, {"snippet_id": 2486, "code": ") else: self.logger.info('starting new session by name \"%s\" on server' % self.session_name) self.session=self.server.new_session( session_name=self.session_name, window_name=\"Main\" ) else: self.config=None", "label": 0}, {"snippet_id": 49371, "code": ", dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False", "label": 0}, {"snippet_id": 1109, "code": ") wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess", "label": 0}, {"snippet_id": 57443, "code": " own method named _update_[property name] to hold specific update logic. \"\"\" ctype='testcases.testcase' def __init__(self, request): self.request=request self.target_field=request.POST.get('target_field", "label": 0}, {"snippet_id": 13818, "code": " safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key]=value def __getitem__", "label": 0}, {"snippet_id": 70421, "code": " aims to return the real state of a Lustre filesystem and its components, depending of the requested \"view\". Status views let the Lustre administrator to either stand back and get a global status of the", "label": 0}, {"snippet_id": 34344, "code": " decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func):", "label": 0}, {"snippet_id": 77798, "code": ".send_multipart(msg) self.pr_sock.send_multipart(msg) def __call__(self, parent): self.p=parent self.log=parent.log self.inter_sleep=parent.inter_sleep self.running=parent.running self.p.sig_sock.setsockopt", "label": 0}, {"snippet_id": 43073, "code": " rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self", "label": 0}, {"snippet_id": 44280, "code": " lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock argument.\".format(os.getcwd())) return False if self.subworkflows and not printdag and not printrulegraph", "label": 0}, {"snippet_id": 7635, "code": "(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of", "label": 0}, {"snippet_id": 94883, "code": " the benchmarks, and records the timer results. \"\"\" import argparse import time import csv import logging import sys import shutil from benchmark import config, data_service def get_cli_arguments(): \"\"\"", "label": 1}, {"snippet_id": 82567, "code": " misuse or damage caused by this program \t\"\"\") if args.proxyCreds==True: \targs.proxyCreds={} \targs.proxyCreds[\"username\"]=input(\"Proxy username: \") \targs.proxyCreds[\"password\"]=getpass.getpass(\"Proxy password", "label": 0}, {"snippet_id": 41120, "code": "=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self[index", "label": 0}, {"snippet_id": 20416, "code": ") time.sleep(0.1) else: break else: raise RuntimeError('could not connect') return sock return cls._create(connect, addr, **kwargs) @classmethod def create_server(cls, addr, **kwargs): def connect(addr", "label": 0}, {"snippet_id": 12734, "code": "]=response.json() else: utc_time=datetime.datetime.utcnow() time_now=utc_time.strftime(\"%B %d, %Y at %H:%M Hours UTC\") comment +=\"\\n\\n comment=comment.format(time_now) query=\"https://api.github.com/repos", "label": 0}, {"snippet_id": 69650, "code": " argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if", "label": 1}, {"snippet_id": 19560, "code": "[i +1]=nextarg=nextarg[:-1] else: arg=nextarg skip +=1 if arg in PYDEVD_OPTS: pydevd.append(arg) if nextarg is not None: pydevd.append(nextarg) skip +=1 elif arg in PYDEVD_FLAGS: pydevd.append(arg) elif", "label": 0}, {"snippet_id": 51394, "code": " return[flag(v, flag_type, flag_value=flag_value) for v in value] def is_flagged(value, flag): if isinstance(value, AnnotatedString): return flag in value.flags return False def temp(value): \"\"\" A flag", "label": 1}, {"snippet_id": 65247, "code": " fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target", "label": 0}, {"snippet_id": 54089, "code": "=InputFiles() wildcards_obj=Wildcards(fromdict=wildcards) _apply_wildcards(input, self.input, wildcards, wildcards_obj, concretize=concretize_iofile, ruleio=ruleio) params=Params() _apply_wildcards(params, self", "label": 0}, {"snippet_id": 70093, "code": "%(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print", "label": 0}, {"snippet_id": 90817, "code": " locate a{} distribution with minimum_version{}, ' 'maximum_version{}') raise self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem)", "label": 0}, {"snippet_id": 52234, "code": "): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards=None): self.rule=rule self.dag=dag self.targetfile=targetfile", "label": 0}, {"snippet_id": 62274, "code": "*par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate() return result def apply(self, gate_name, wires, *par): if gate_name not in self._gates: raise ValueError('Gate{", "label": 0}, {"snippet_id": 2532, "code": "(\" Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name", "label": 0}, {"snippet_id": 83324, "code": " async_job_state in self.watched: if str( async_job_state.job_id)==job_id: found_job=async_job_state break return found_job def queue_job(self, job_wrapper): job_destination=job_wrapper.job_destination command_line", "label": 0}, {"snippet_id": 59156, "code": " which stores the circuit, transforms it to JSON QASM, and sends the circuit through the IBM API. See PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .. autosummary", "label": 0}, {"snippet_id": 13813, "code": " safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self", "label": 0}, {"snippet_id": 19751, "code": " args.name=filename args.kind='script' else: args.name=module args.kind='module' return args def main(addr, name, kind, extra=(), nodebug=False, **kwargs): if nodebug: run_main(addr, name, kind, *extra, *", "label": 0}, {"snippet_id": 51446, "code": " return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually", "label": 0}, {"snippet_id": 95835, "code": " on conversion configuration parameters :param input_vcf_dir: The input directory where VCF files are located :param output_zarr_dir: The output directory to place Zarr-formatted data :param conversion_config", "label": 0}, {"snippet_id": 75652, "code": " wz_addr, fun, args=(), kvargs={}, name=None, start_timer=None, poll_timeout=None, pargs=(), pkvargs={}): super().__init__(*pargs, **pkvargs) self.name=name if name else type(self).__name__ self.start_timer", "label": 0}, {"snippet_id": 25782, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 33044, "code": " return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules def get_rule(self, name): \"\"\" Get rule by name. Arguments name ", "label": 0}, {"snippet_id": 9924, "code": ": bool, to get the spires output :return: list of formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details", "label": 0}, {"snippet_id": 90149, "code": "('Distribution({!r}, minimum_version={!r}, maximum_version={!r} jdk={!r})'.format( self._bin_path, self._minimum_version, self._maximum_version, self._jdk)) class _DistributionEnvironment(AbstractClass", "label": 0}, {"snippet_id": 82776, "code": " set to --url parameter.\") \tup=UploadForm(args.notRegex,args.trueRegex,s,args.size,postData,args.uploadsPath,args.url,args.formAction,args.inputName) else: \tup=UploadForm(args.notRegex,args.trueRegex,s", "label": 0}, {"snippet_id": 40009, "code": "=None obj._regex=None return obj @property def file(self): if not self._is_function: return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property", "label": 0}, {"snippet_id": 65370, "code": " enquire about filesystem components detailed states. \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import", "label": 0}, {"snippet_id": 73864, "code": "(runtime_config.ftp[\"files\"]) if files_str==\"*\": self.files=[] else: self.files=files_str.split(delimiter) vcf_to_zarr_compressor_types=[\"Blosc\"] vcf_to_zarr_blosc_algorithm_types=[\"zstd\", \"blosclz\", \"lz4\", \"lz4hc", "label": 0}, {"snippet_id": 10165, "code": ":i]) else: return 0 for skw, info in skw_matches: if skw.core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output", "label": 0}, {"snippet_id": 54004, "code": "(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]", "label": 0}, {"snippet_id": 61249, "code": ".allclose(U @ U.conj().T, np.identity(U.shape[0]), atol=tolerance): raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable.", "label": 0}, {"snippet_id": 32277, "code": " specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f,", "label": 0}, {"snippet_id": 78486, "code": ") found=set(map(lambda x:(user, x[0]+x[1]), rxp.findall(page))) for t in found: if(t in self.pc.sets['closed'] or t in self.pc.sets['bumplimit'] or t in self.targets): continue targets.append(t) lt=len", "label": 1}, {"snippet_id": 88604, "code": " any. :API: public \"\"\" return self._scm @property def workspace(self): \"\"\"Returns the current workspace, if any.\"\"\" return self._workspace @property def invalidation_report(self): return self._invalidation_report", "label": 0}, {"snippet_id": 67292, "code": ", client.mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self):", "label": 0}, {"snippet_id": 35288, "code": "*wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools", "label": 0}, {"snippet_id": 22819, "code": " salt_len: If encrypting the password, the length of the salt value used to do it. \"\"\" cmd=\"/usr/bin/tmsh modify auth user{0} password '{1}'\".format(username, password) ret, output=shellutil.run_get_output", "label": 0}, {"snippet_id": 93493, "code": " exit_on_fail: exit(1) def copy_component_to_remote(self, infile, comp, host): self.host_list.append(host) self.logger.debug(\"Saving component to tmp\") tmp_comp_path=('%s/%s.yaml' %(TMP_COMP_DIR, comp)", "label": 0}, {"snippet_id": 5481, "code": " ckw_matches, spires=False): \"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires", "label": 0}, {"snippet_id": 86869, "code": ") @classmethod def get_fatal_warnings_disabled_args_default(cls): return() @classmethod def register_options(cls, register): super(BaseZincCompile, cls).register_options(register) register('--whitelisted", "label": 0}, {"snippet_id": 55677, "code": ".set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params", "label": 0}, {"snippet_id": 84315, "code": "') metadata_kwds['config_file']=remote_system_properties.get('galaxy_config_file', default_config_file) metadata_kwds['dataset_files_path']=remote_system_properties.get('galaxy_dataset_files_path', None", "label": 0}, {"snippet_id": 57743, "code": ".review_case.count() return http.JsonResponse({ 'rc': 0, 'response': 'ok', 'run_case_count': run_case_count, 'case_count': case_count, 'review_case_count': review_case_count, }) def _update_sortkey(self)", "label": 0}, {"snippet_id": 19159, "code": "\" Validate the request/response cycle of an api call against a swagger schema. Request/Response objects from the `requests` and `urllib` library are supported. \"\"\" request=normalize_request(raw_request", "label": 0}, {"snippet_id": 10747, "code": " the text and compares it to the expected number of words(based on an average size of words of 5.1 letters). @param text_lines: the text to analyze @type text_lines: string @return: True if the text is", "label": 1}, {"snippet_id": 71182, "code": "=RECOVERING: status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else", "label": 0}, {"snippet_id": 50937, "code": " except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os", "label": 0}, {"snippet_id": 12603, "code": "\"])) comments=requests.get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body\"] break ", "label": 0}, {"snippet_id": 4286, "code": ") if text_lines: source=os.path.basename(entry) process_lines() else: text_lines=extractor.text_lines_from_url(entry, user_agent=make_user_agent_string(\"BibClassify\")) if text_lines: source=entry.split", "label": 1}, {"snippet_id": 73676, "code": "/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return False def isfloat(value):", "label": 0}, {"snippet_id": 71155, "code": " return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state=", "label": 0}, {"snippet_id": 45371, "code": " os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os", "label": 0}, {"snippet_id": 18684, "code": " debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location", "label": 0}, {"snippet_id": 54525, "code": "=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps=dict() self.rule_count=0 self", "label": 0}, {"snippet_id": 18053, "code": " query: request_data[ 'query']=query return request_data def JsonFromFuture( future): response=future.result() if response.status_code==requests.codes.server_error: _RaiseExceptionForData( response.json()", "label": 0}, {"snippet_id": 52736, "code": " creation of directories and deletion of previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if", "label": 0}, {"snippet_id": 39095, "code": ", cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet,", "label": 0}, {"snippet_id": 47967, "code": ", io[i], e) for i, e in reversed(list(expansion.items()))] for i, old, exp in replacements: dynamic_io_.remove(old) io_.insert_items(i, exp) if not input: for i, old, exp in replacements: if old in branch", "label": 0}, {"snippet_id": 8159, "code": ".join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) < 4: raise Exception('Wrong", "label": 0}, {"snippet_id": 47607, "code": " self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s", "label": 0}, {"snippet_id": 34802, "code": "(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self", "label": 1}, {"snippet_id": 83663, "code": ", job_id) def get_client( self, job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint", "label": 0}, {"snippet_id": 6275, "code": ".mkstemp(prefix=\"bibclassify.\")[1] local_stream=open(local_file, \"w\") local_stream.write(distant_stream.read()) local_stream.close() except: log.error(\"Unable to read from URL %s.\" % url) return None else:", "label": 1}, {"snippet_id": 77985, "code": " tlist: logger.info('Appending %s to targets[%s]', repr(t), domain) tlist.append(t) r_di=re.compile(regexp.f_udi) def atfu(urls): for user, domain, id1, id2 in r_di.findall(urls): id_=id1+id2 add_target", "label": 0}, {"snippet_id": 93730, "code": " CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name", "label": 0}, {"snippet_id": 44153, "code": "(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall,", "label": 0}, {"snippet_id": 64574, "code": " argument\" else: fs_conf, fs=create_lustrefs(self.lmf_support.get_lmf_path(), event_handler=self) install_nodes=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if", "label": 1}, {"snippet_id": 52843, "code": " with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards", "label": 0}, {"snippet_id": 24831, "code": "'WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 23051, "code": " provisioningiso.iso file This is the _first_ hook that WAAgent provides for us, so this is the point where we should wait for mcpd to load. I am just overloading this method to add the mcpd wait. Then I", "label": 0}, {"snippet_id": 82027, "code": " help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs.add_argument(\"--not-regex\", metavar=\"regex\", help=", "label": 0}, {"snippet_id": 55282, "code": ".version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True", "label": 0}, {"snippet_id": 29103, "code": " os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException, WorkflowError", "label": 1}, {"snippet_id": 76476, "code": ".log.info('Starting') try: self.child=self.call[0](*self.call[1], **self.call[2]) self.child(self) except WorkerInterrupt as e: self.log.warn(e) except Exception as e: self.log.exception(e) self.log.info", "label": 0}, {"snippet_id": 33324, "code": " None: try: snakemake.io.wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules", "label": 0}, {"snippet_id": 73475, "code": " format. Only converts a single VCF file. :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the", "label": 0}, {"snippet_id": 85263, "code": "._create_runtime_jardep) ] for spec_key, create_jardep_func in specs_to_create: spec=self.injectables_spec_for_key(spec_key) target_address=Address.parse(spec) if not build_graph.contains_address(target_address", "label": 0}, {"snippet_id": 34852, "code": ".start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file", "label": 0}, {"snippet_id": 14669, "code": "._IsServerAlive(): return try: debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'detailed_diagnostic') if 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError", "label": 0}, {"snippet_id": 18540, "code": " self._IsServerAlive(): self._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self", "label": 0}, {"snippet_id": 6313, "code": " line)) log.info(\"Remote file has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os", "label": 1}, {"snippet_id": 45706, "code": " isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))", "label": 0}, {"snippet_id": 91287, "code": ".python.tasks.python_run import PythonRun from pants.backend.python.tasks.resolve_requirements import ResolveRequirements from pants.backend.python.tasks.select_interpreter import SelectInterpreter from", "label": 0}, {"snippet_id": 28226, "code": ":thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', '\u00ba', 'mdi:compass', None], 'windstrength", "label": 0}, {"snippet_id": 73614, "code": "-Zarr] Using{} compressor.\".format(conversion_config.compressor)) print(\"[VCF-Zarr] Performing VCF to Zarr conversion...\") allel.vcf_to_zarr(input_vcf_path, output_zarr_path, alt_number=alt_number, overwrite", "label": 1}, {"snippet_id": 44270, "code": "\"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely caused by a kill signal or \" \"a power loss. It can be removed with \" \"the --unlock", "label": 0}, {"snippet_id": 73243, "code": "\"\"\" input_dir=str(input_dir) temp_dir=str(temp_dir) output_dir=str(output_dir) create_directory_tree(input_dir) create_directory_tree(temp_dir) create_directory_tree(output_dir) pathlist_gz=pathlib.Path", "label": 0}, {"snippet_id": 83748, "code": "=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed", "label": 0}, {"snippet_id": 37226, "code": "(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark", "label": 0}, {"snippet_id": 60435, "code": "(reg, *self.observe.params) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device\"\"\" if self.eng is not None: self.eng=None self.state=None", "label": 0}, {"snippet_id": 72507, "code": " of the benchmark. It creates the default configuration file.') config_parser.add_argument(\"--output_config\", type=str, required=True, help=\"Specify the output path to a configuration file.\", metavar=\"FILEPATH", "label": 0}, {"snippet_id": 82873, "code": " rawTechniques: \ttechniques=json.loads(rawTechniques.read()) logger.info(\" c=datetime.datetime.now() nbOfEntryPointsFound=0 attempts=[] templatesData={} for template in templates: \ttemplatefd=open(templatesFolder+\"", "label": 0}, {"snippet_id": 27180, "code": "], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather", "label": 0}, {"snippet_id": 85591, "code": " wrapper jars and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self, products) def __init__(self, zinc_factory, products): self._zinc_factory=zinc_factory self._products=products @memoized_property", "label": 0}, {"snippet_id": 21060, "code": " finally: wait(timeout or self._timeout, handlername, fail=True) def _get_message_handle(self, match, handlername): event=threading.Event() def handler(msg): if not match(msg): return msg, False event.set()", "label": 0}, {"snippet_id": 51441, "code": "\" An alias for temp. \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and", "label": 0}, {"snippet_id": 77348, "code": "(wname,('pr{0}' if type_ else 'th{0}').format(i))), **kvargs) if type_==0: self.threads.append(w) w.start(self.p.ctx, self.th_sa) elif type_==1: self.processes.append(w) w.start(self.pr_sa) except Exception", "label": 0}, {"snippet_id": 10069, "code": " ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes:", "label": 0}, {"snippet_id": 30479, "code": "=_load_configfile(configpath) if not isinstance(config, dict): raise WorkflowError(\"Config file must be given as JSON or YAML \" \"with keys at top level.\") return config class PeriodicityDetector: def __init__", "label": 0}, {"snippet_id": 54786, "code": ", touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False, printdag=False", "label": 0}, {"snippet_id": 18691, "code": " debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid)", "label": 0}, {"snippet_id": 81349, "code": " moreInfo: \t\t\t\t\t\tresult=str(moreInfo.groups()) \t\tif self.trueRegex and not result: \t\t\tfileUploaded=re.search(self.trueRegex,html) \t\t\tif fileUploaded: \t\t\t\ttry: \t\t\t\t\tresult=str(fileUploaded.group(1)) \t\t\t", "label": 0}, {"snippet_id": 65009, "code": " handle_pre(self, fs): if self.verbose > 0: print \"Starting %d targets on %s\" %(fs.target_count, fs.target_servers) def handle_post(self, fs): if self.verbose > 0: Status.status_view_fs(fs, show_clients", "label": 0}, {"snippet_id": 58918, "code": ".content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': \"You don't have enough permission to \" \"update TestCases.\"}) def test_update_case_priority(self): self.client.login( username=self.tester", "label": 0}, {"snippet_id": 11121, "code": ".mtime) def is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self.mtime, other.mtime) > 0 else: return False def serialize(self): lines=[] time_string=strftime(\"%Y-%m-", "label": 0}, {"snippet_id": 39969, "code": ".supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\"", "label": 0}, {"snippet_id": 89892, "code": " java: if self._minimum_version: version=self._get_version(java) if version < self._minimum_version: raise self.Error('The java distribution at{} is too old; expecting at least{} and' ' got{}'.format(java,", "label": 0}, {"snippet_id": 41824, "code": "] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested", "label": 0}, {"snippet_id": 12416, "code": "!\".format(file, data[file +\"_link\"])) else: ERROR=True comment_body.append( \" -In the file[`{0}`]({1}), following \" \"are the PEP8 issues:\\n\".format(file, data[file +\"_link\"])) for issue in issues: error_string", "label": 0}, {"snippet_id": 10393, "code": " save_keywords(filename, xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid", "label": 0}, {"snippet_id": 22467, "code": " def start_agent_service(self): return shellutil.run(\"/sbin/service waagent start\", chk_err=False) def register_agent_service(self): return shellutil.run(\"/sbin/chkconfig --add waagent\", chk_err=False)", "label": 0}, {"snippet_id": 89798, "code": " distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"\"\"Returns the path to the command of the given name for this distribution. For", "label": 0}, {"snippet_id": 3868, "code": ".ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml\") subparsers=parser.add_subparsers(dest=\"cmd\") subparser_editor", "label": 0}, {"snippet_id": 54448, "code": " CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler", "label": 0}, {"snippet_id": 81096, "code": " containing file upload inputs, no way to choose which one to test.\",len(detectedForms)) \t\t\texit() \t\tif len(detectedForms[0][1]) > 1: \t\t\tself.logger.critical(\"%s file inputs found inside the same form, no way", "label": 0}, {"snippet_id": 46238, "code": " wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard. \"", "label": 0}, {"snippet_id": 7999, "code": " found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0])) if list_comparison: return list_comparison if kw0[0].isComposite() and kw1[0", "label": 0}, {"snippet_id": 42260, "code": "\".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 89439, "code": " exercise features only available in that version forward. :API: public TODO(John Sirois): This class has a broken API, its not reasonably useful with no methods exposed. Expose reasonable methods: https:", "label": 0}, {"snippet_id": 75217, "code": "(self, interface, method, fun): self.req_handlers[(interface, method)]=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun", "label": 0}, {"snippet_id": 3358, "code": " check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting", "label": 0}, {"snippet_id": 48346, "code": " SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output)", "label": 0}, {"snippet_id": 4041, "code": "=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI", "label": 0}, {"snippet_id": 50050, "code": "(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile", "label": 0}, {"snippet_id": 93183, "code": "=logging.WARNING, format=FORMAT, datefmt='%I:%M:%S') TMP_SLAVE_DIR=\"/tmp/Hyperion/slave/components\" TMP_COMP_DIR=\"/tmp/Hyperion/components\" TMP_LOG_PATH=\"/tmp/Hyperion/log\" BASE_DIR=os.path.dirname(__file__)", "label": 0}, {"snippet_id": 62504, "code": " AllZGate, Hermitian]]) _circuits={} _backend_kwargs=['gate_fusion', 'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"", "label": 0}, {"snippet_id": 89789, "code": " def java(self): \"\"\"Returns the path to this distribution's java command. If this distribution has no valid java command raises Distribution.Error. \"\"\" return self.binary('java') def binary(self, name): \"", "label": 0}, {"snippet_id": 74697, "code": " chunk_length_str==\"default\": self.chunk_length=None elif isint(chunk_length_str): self.chunk_length=int(chunk_length_str) else: raise TypeError(\"Invalid value provided for chunk_length in configuration", "label": 0}, {"snippet_id": 70764, "code": " def __lt__(self, other): return self[\"index\"] < other[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=", "label": 0}, {"snippet_id": 48021, "code": ".clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values))==1) (branch._input, branch._output, branch._params, branch._log, branch._benchmark, _, branch", "label": 0}, {"snippet_id": 62425, "code": "='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return{ key:value for key,value in kwargs", "label": 0}, {"snippet_id": 68547, "code": "],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count", "label": 0}, {"snippet_id": 77418, "code": "'pr_back_sock'): self.init_pr_back_sock() else: raise Exception('Unknown wclass type') for i in range(count): if not self.running.is_set(): break try: if type_==0: w=workers.WZWorkerThread( self.c.router_addr, fun", "label": 0}, {"snippet_id": 17957, "code": " timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method):", "label": 1}, {"snippet_id": 92119, "code": " targets set platforms arguments other than['current'], which is unsupported for this reason. Please either remove the platforms argument from these targets, or set them to exactly['current']. Bad targets", "label": 0}, {"snippet_id": 2187, "code": "=escape(request.POST.get(\"wifi_password\")) wifi_name=request.POST.get(\"wifi_ap\") if len(wifi_name) > 0: add_newWifiConn(wifi_name,wifi_pass) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker']", "label": 0}, {"snippet_id": 43852, "code": " rule=Rule(name, self, lineno=lineno, snakefile=snakefile) self._rules[rule.name]=rule self.rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return", "label": 0}, {"snippet_id": 13779, "code": " v in np.__dict__.iteritems(): _safe_locals[k]=getattr(np, k) _safe_locals['logbins']=lambda start, stop, count:[np.exp(x) for x in np.linspace(np.log(start), np.log(stop), count)] _safe_locals['since04", "label": 0}, {"snippet_id": 87964, "code": ", scalac doesn't load plugins or their deps from the regular classpath, so we have to provide these entries separately, in the -Xplugin: flag). Note that we don't currently support external plugins with", "label": 0}, {"snippet_id": 69083, "code": " fs_conf, fs=open_lustrefs(fsname, None, nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem", "label": 0}, {"snippet_id": 51584, "code": "(values, str) or not isinstance(values, Iterable): values=[values] yield[(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards", "label": 0}, {"snippet_id": 3686, "code": " amount: returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp[", "label": 0}, {"snippet_id": 14040, "code": " filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num': line, 'column_num': column, 'start_column': start_column, 'line_value': vim.current.line", "label": 0}, {"snippet_id": 12136, "code": " hunk in patchset: for line in hunk.target_lines(): if line.is_added: files[file].append(line.target_line_no) return files def get_python_files_involved_in_pr(data): files=get_files_involved_in_pr(data)", "label": 0}, {"snippet_id": 32020, "code": " \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be", "label": 0}, {"snippet_id": 22171, "code": ".FileSystemLoader( searchpath=\"/\") templateEnv=jinja2.Environment( loader=templateLoader) template=templateEnv.get_template( template_file) outputText=template.render( data) return outputText def run(self", "label": 0}, {"snippet_id": 34349, "code": " decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class RuleInfo: def __init__(self, func): self.func=func self.shellcmd=None self.norun=False self.input=None", "label": 0}, {"snippet_id": 70102, "code": " self.verbose > 0: Status.status_view_fs(fs, show_clients=False) def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"%s: Starting %s %s(%s)...\" %(node, \\ target.type.upper(), target", "label": 0}, {"snippet_id": 8248, "code": " else: from invenio.utils.url import make_invenio_opener urlopen=make_invenio_opener('BibClassify').open log=bconfig.get_logger(\"bibclassify.text_extractor\") _ONE_WORD=re.compile(\"[A-Za-z]{2,}\") def is_pdf", "label": 1}, {"snippet_id": 23061, "code": " we should wait for mcpd to load. I am just overloading this method to add the mcpd wait. Then I proceed with the stock code. :param max_retry: Maximum number of retries waagent will make when mounting", "label": 0}, {"snippet_id": 18408, "code": ".readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def", "label": 0}, {"snippet_id": 54040, "code": " item: concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ if name: newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if", "label": 0}, {"snippet_id": 90735, "code": ":raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" for location in itertools.chain(self._distribution_environment.jvm_locations): try: dist=Distribution(home_path=location", "label": 0}, {"snippet_id": 81202, "code": "=input(\"Do you want to use the True Regex for code execution detection ?[Y/n] \") \t\t\tif cont.lower().startswith(\"y\") or cont==\"\": \t\t\t\tpreffixPattern=input(\"Preffix capturing group of the true regex with: \"", "label": 0}, {"snippet_id": 63225, "code": "=job_wrapper.tool, config_files=job_wrapper.extra_filenames, dependencies_description=dependencies_description, env=client.env, rewrite_paths=rewrite_paths, arbitrary_files=unstructured_path_rewrites, )", "label": 0}, {"snippet_id": 36933, "code": "-the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params", "label": 0}, {"snippet_id": 25831, "code": "=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 5959, "code": " import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from invenio.utils.url import make_invenio_opener urlopen", "label": 1}, {"snippet_id": 20012, "code": " _close(self): if self._session is not None: try: self._session.close() except ClosedError: pass if self._adapter is not None: try: self._adapter.close() except ClosedError: pass def _launch(self, argv,", "label": 0}, {"snippet_id": 24522, "code": ".update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self", "label": 0}, {"snippet_id": 40095, "code": "(self.dynamic_fill, self.file)[0] dir=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self", "label": 0}, {"snippet_id": 46532, "code": ": end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None, item def insert_items(self, index, items): self", "label": 0}, {"snippet_id": 36132, "code": ".add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash", "label": 0}, {"snippet_id": 18951, "code": "') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts.scheme and parts.netloc: response=requests.get(source) if isinstance", "label": 0}, {"snippet_id": 10735, "code": " _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based on an average size of words of 5.1 letters).", "label": 1}, {"snippet_id": 86987, "code": " 'only clean/cold builds.') @classmethod def subsystem_dependencies(cls): return super(BaseZincCompile, cls).subsystem_dependencies() +(Zinc.Factory, JvmPlatform,) @classmethod def prepare(cls, options", "label": 0}, {"snippet_id": 77052, "code": " class WipeManager: def __init__(self, config, *args, **kvargs): super().__init__(*args, **kvargs) self.newproxyfile='newproxies.txt' self.proxylist=set() self.c=config self.threads=[] self.processes=[]", "label": 0}, {"snippet_id": 6083, "code": "(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q", "label": 0}, {"snippet_id": 52034, "code": ") class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist): pass def _load_configfile", "label": 0}, {"snippet_id": 43104, "code": " strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile", "label": 0}, {"snippet_id": 85962, "code": ") with safe_open(javac_plugin_info_file, 'w') as f: f.write(javac_plugin_target.classname) @classmethod def get_args_default(cls, bootstrap_option_values): return('-encoding', 'UTF-8') @classmethod def", "label": 0}, {"snippet_id": 59749, "code": "'rnd_seed'] def __init__(self, wires, **kwargs): kwargs['backend']='Simulator' super().__init__(wires, **kwargs) def reset(self): \"\"\"Resets the engine and backend After the reset the Device should be as", "label": 0}, {"snippet_id": 45328, "code": "\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path.dirname(workflow.included_stack[-1]), path", "label": 0}, {"snippet_id": 40870, "code": ": dirname=\".\" names=[match.group('name') for match in _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex", "label": 0}, {"snippet_id": 33347, "code": " forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules, ignore_ambiguity=ignore_ambiguity, force_incomplete=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or", "label": 0}, {"snippet_id": 57377, "code": "'): from tcms.core.utils.mailto import mailto mail_context=model.mail_scene( objects=targets, field=field, value=value, ctype=ctype, object_pk=object_pk, ) if mail_context: mail_context['context']['user", "label": 0}, {"snippet_id": 93157, "code": " psutil import Process from subprocess import call from graphviz import Digraph from enum import Enum from time import sleep import sys from PyQt4 import QtGui import hyperGUI FORMAT=\"%(asctime)s: %(name)s", "label": 0}, {"snippet_id": 26920, "code": "] elif data['GustAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=60: self._state=\"E(%d\\xb0", "label": 0}, {"snippet_id": 9169, "code": ", position...],[info_about_matches]], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext", "label": 0}, {"snippet_id": 81655, "code": "\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl=b.join(url.split(b)[:-1]) \t\t\t\telif self.codeExecUrlPattern", "label": 1}, {"snippet_id": 50243, "code": " def rule(self, name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], ", "label": 0}, {"snippet_id": 67135, "code": "\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on", "label": 0}, {"snippet_id": 58657, "code": "': 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission", "label": 0}, {"snippet_id": 3688, "code": " returning true\") return CheckState.RUNNING else: logger.debug(\"Check failed: returning false\") return CheckState.STOPPED else: logger.debug(\"%s window is not running. Running custom check\" % comp['name'", "label": 0}, {"snippet_id": 62475, "code": " reached(only has an effect for the c++simulator). rnd_seed(int): Random seed(uses random.randint(0, 4294967295) by default). \"\"\" short_name='projectq.simulator' _gates=set(operator_map.keys()) _observables", "label": 0}, {"snippet_id": 12255, "code": " data[\"extra_results\"][filename]=stdout.decode(r.encoding).splitlines() data[\"results\"][filename]=[] for error in list(data[\"extra_results\"][filename]): if re.search(\"^file_to_check.py:\\d+:\\d+:\\s[WE]\\d+\\s.", "label": 0}, {"snippet_id": 8311, "code": " log.error(\"Your version of the 'file' utility seems to \" \"be unsupported. Please report this to cds.support@cern.ch.\") raise Exception('Incompatible pdftotext') pdf=filetype.find(\"PDF\") > -1 return pdf", "label": 0}, {"snippet_id": 46422, "code": " Arguments name --a name \"\"\" self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index", "label": 0}, {"snippet_id": 88376, "code": "*msg_elements): self._run_tracker.log(Report.INFO, *msg_elements) def warn(self, *msg_elements): self._run_tracker.log(Report.WARN, *msg_elements) def error(self, *msg_elements): self._run_tracker.log(Report.ERROR", "label": 0}, {"snippet_id": 41478, "code": ".threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output", "label": 0}, {"snippet_id": 30902, "code": " values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards", "label": 0}, {"snippet_id": 16640, "code": "._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not self.DiagnosticsForCurrentFileReady", "label": 0}, {"snippet_id": 4205, "code": "=get_keywords_from_text( text_lines, taxonomy_name, output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords,", "label": 0}, {"snippet_id": 84087, "code": ": work_dir_outputs=[] output_files=self.get_output_files( job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files", "label": 1}, {"snippet_id": 77784, "code": ") def send_passthrough(self, interface, method, frames): msg=[frames[0]] msg.extend(wzrpc.make_sig_msg(frames[1], frames[2], frames[3:])) self.th_sock.send_multipart(msg) self.pr_sock.send_multipart(msg", "label": 0}, {"snippet_id": 53015, "code": "(self): self.updated_input=set() self.updated_input_run=set() self.missing_output=set() self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self", "label": 0}, {"snippet_id": 11474, "code": ", skip_checks=self.skip_checks) if yaml_config.host and self._is_newer(header_source, yaml_config.host_name): file_name=self.create_filename(yaml_config.host_name) yaml_icinga=YamlToIcinga(yaml_config,", "label": 0}, {"snippet_id": 39114, "code": " keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait, benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet", "label": 0}, {"snippet_id": 59257, "code": " device for OpenQML. Args: wires(int): The number of qubits of the device. Keyword Args for Simulator backend: gate_fusion(bool): If True, gates are cached and only executed once a certain gate-size has", "label": 0}, {"snippet_id": 17860, "code": " import ServerError, UnknownExtraConf _HEADERS={'content-type': 'application/json'} _EXECUTOR=UnsafeThreadPoolExecutor( max_workers=30) _DEFAULT_TIMEOUT_SEC=30 class BaseRequest( object): def __init__(", "label": 0}, {"snippet_id": 28469, "code": " frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the state of the device.", "label": 0}, {"snippet_id": 83751, "code": ", job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args", "label": 0}, {"snippet_id": 77023, "code": " sbjfun, message, pc, net, domain, Mailinator, uq(domain) if uq else None) w.stoponclose=c.stop_on_closed w.die_on_neterror=c.die_on_neterror w.caprate_minp=c.caprate_minp w.caprate_limit=c.caprate_limit", "label": 0}, {"snippet_id": 68232, "code": "[\"index\"] ldic=[] for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==TARGET_ERROR: status=\"ERROR", "label": 0}, {"snippet_id": 55344, "code": ", cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason, printshellcmds=printshellcmds, latency_wait=latency_wait", "label": 0}, {"snippet_id": 28865, "code": "'WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle']", "label": 0}, {"snippet_id": 15893, "code": " Response( self): return{} @staticmethod def GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod", "label": 0}, {"snippet_id": 59448, "code": ".allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"\" \"\"\" self", "label": 1}, {"snippet_id": 91839, "code": ".native.subsystems.native_toolchain import NativeToolchain from pants.backend.native.targets.native_library import NativeLibrary from pants.backend.python.python_requirement import PythonRequirement from", "label": 0}, {"snippet_id": 6981, "code": " in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author", "label": 0}, {"snippet_id": 51503, "code": ".finditer(file)) for match in matches: if match.group(\"constraint\"): raise SyntaxError( \"The wildcards in dynamic files cannot be constrained.\") return annotated def touch(value): return flag(value, \"touch", "label": 0}, {"snippet_id": 20250, "code": "=message +os.linesep +self._run_server_ex raise Exception(message) self._launch( argv, script=script, wait_for_connect=wait, detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script", "label": 0}, {"snippet_id": 76017, "code": ".warning('Recvd unknown reply for(%s, %s) %s: %s', i, m, wzrpc.name_status(status), repr(data)) self.wz_wait_reply(accept, *self.wz.make_auth_req_data(i, m, wzauth_data.request[i, m])) def bind_route(self,", "label": 0}, {"snippet_id": 45448, "code": ") @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file).st_mtime @property def size(self): self.check_broken_symlink", "label": 1}, {"snippet_id": 86217, "code": "(distribution.home)) settings_args=(a.replace('$JAVA_HOME', distribution.home) for a in settings.args) javac_cmd.extend(settings_args) javac_cmd.extend([ '-source', str(settings.source_level), '-target',", "label": 0}, {"snippet_id": 53503, "code": "*kwinput): \"\"\" Add a list of input files. Recursive lists are flattened. Arguments input --the list of input files \"\"\" for item in input: self._set_inoutput_item(item) for name, item in kwinput.items(): self", "label": 0}, {"snippet_id": 13522, "code": " MOUTH_OPEN)\r io.setup( EYES_OPEN)\r io.setup( MOUTH_CLOSE)\r io.setup( EYES_CLOSE)\r \r audio=None\r isRunning=True\r \r def updateMouth():\r lastMouthEvent=0\r lastMouthEventTime=0\r \r while( audio==None):\r time.sleep", "label": 0}, {"snippet_id": 21777, "code": ":, 1]) labelencoder_X_2=LabelEncoder() X[:, 2]=labelencoder_X_2.fit_transform(X[:, 2]) onehotencoder=OneHotEncoder(categorical_features=[1]) X=onehotencoder.fit_transform(X).toarray() X=X[:, 1:] from sklearn", "label": 1}, {"snippet_id": 72077, "code": " reconnect this network, use the 'rehash' command.\") control.remove_network(network) @utils.add_cmd def autoconnect(irc, source, args): \"\"\"<network> <seconds> Sets the autoconnect time for <network> to", "label": 0}, {"snippet_id": 23632, "code": ". SEE ALSO: man ip(4) IP_ONESBCAST, \"\"\" return True def is_dhcp_enabled(self): return True def start_dhcp_service(self): shellutil.run(\"/etc/rc.d/dhclient start{0}\".format(self.get_if_name()), chk_err=False", "label": 0}, {"snippet_id": 56742, "code": "(self): func=getattr(self, self.object) return func() def plan(self): return 'management/get_tag.html', TestPlan.objects.get(pk=self.object_pk) def case(self): return 'management/get_tag.html', TestCase", "label": 0}, {"snippet_id": 34716, "code": " stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode)", "label": 0}, {"snippet_id": 1892, "code": "=cursor.fetchall() datasets_perc.append(counter_val) for iter in range(2,4): cursor.execute(common.Q_GET_CONTAINER_STATS,[row[0],iter+1]) counter_val=cursor.fetchall() datasets_mem.append(counter_val) for", "label": 0}, {"snippet_id": 2977, "code": " and not self.run_on_localhost(comp): self.logger.debug(\"Starting remote component '%s' on host '%s'\" %(comp['name'], comp['host'])) self.start_remote_component(comp['name'], comp['host']) else: log_file=", "label": 0}, {"snippet_id": 29509, "code": " logger.info(\"Waiting at most{} seconds for missing files.\".format( latency_wait)) for _ in range(latency_wait): if not get_missing(): return time.sleep(1) raise IOError(\"Missing files after{} seconds:", "label": 0}, {"snippet_id": 58813, "code": ".assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) self.assertEqual( 'PAUSED', TestCaseRun.objects.get(pk=self.case_run_1.pk).case_run_status.name)", "label": 0}, {"snippet_id": 37636, "code": ": self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile", "label": 0}, {"snippet_id": 9696, "code": ".CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER): if limit: resized_skw=skw_matches[0:limit] resized_ckw=ckw_matches[0:limit] else: resized_skw=skw_matches resized_ckw=ckw_matches results={\"Core keywords\": _get_core_keywords(skw_matches,", "label": 0}, {"snippet_id": 33374, "code": " list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f in cleanup_metadata: self.persistence.cleanup_metadata(f) return True dag.init() dag.check_dynamic() if", "label": 0}, {"snippet_id": 5719, "code": " keywords objects. First by the number of their spans(ie. how many times they were found), if it is equal it compares them by lenghts of their labels. \"\"\" list_comparison=cmp(len(kw1[1][0]), len(kw0[1][0", "label": 0}, {"snippet_id": 45430, "code": " return self._file else: raise ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self", "label": 1}, {"snippet_id": 40992, "code": " fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"\"\" Add a name to the last item. Arguments name --a name \"\"\" self.set_name(name, len(self) -1)", "label": 0}, {"snippet_id": 34722, "code": " files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self", "label": 0}, {"snippet_id": 61629, "code": "): raise ValueError('2x2 matrix required.') A=self.expand_one(A, wires) expectation=np.vdot(self._state, A @ self._state) if np.abs(expectation.imag) > tolerance: log.warning('Nonvanishing imaginary part", "label": 0}, {"snippet_id": 26040, "code": "'wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize", "label": 0}, {"snippet_id": 53671, "code": "(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may", "label": 0}, {"snippet_id": 94159, "code": " running slave session on server') elif not kill_mode and not check_mode: self.logger.info('starting new slave session on server') self.session=self.server.new_session( session_name=\"slave-session\" ) else", "label": 0}, {"snippet_id": 42962, "code": " TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item", "label": 0}, {"snippet_id": 44043, "code": " greediness=1.0, no_hooks=False): self.global_resources=dict() if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map", "label": 0}, {"snippet_id": 54829, "code": " force_incomplete=False, ignore_incomplete=False, list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3", "label": 0}, {"snippet_id": 37606, "code": " item: self._set_params_item(i) if name: self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return", "label": 0}, {"snippet_id": 64635, "code": " clients. \"\"\" import os from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSClientLiveCommand", "label": 0}, {"snippet_id": 2916, "code": ".check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All", "label": 0}, {"snippet_id": 186, "code": " for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \"802-11-wireless\":{ \"security\": \"802-11-wireless-security\", }, \"802-11-wireless-security\"", "label": 0}, {"snippet_id": 39954, "code": ".stat(f, follow_symlinks=os.stat not in os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return", "label": 0}, {"snippet_id": 78843, "code": "\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef setup(self,initUrl): \t\tself.formUrl=initUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself", "label": 0}, {"snippet_id": 58357, "code": " class TestIndex(BaseCaseRun): def test_when_not_logged_in_index_page_redirects_to_login(self): response=self.client.get(reverse('core-views-index')) self.assertRedirects( response, reverse('tcms-login'", "label": 0}, {"snippet_id": 21527, "code": " new_links +=unseen_links new_links=list(set(new_links)) save_links=new_links for link in new_links: if link in seen_links: print(\"Reddytt: Link seen. Skipping.\") else: x=os.system(\"mpv %(args)s %(link)s\" %{", "label": 1}, {"snippet_id": 44872, "code": "[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo.threads, int): raise RuleException(\"Threads value has to be an integer.\", rule=rule) rule.resources[\"_cores\"]=ruleinfo.threads", "label": 0}, {"snippet_id": 64329, "code": ".with_path_for_job( remote_path, remote_extra_files_path) def working_directory( self): return self._working_directory def config_directory( self): return self._config_directory def new_file_path( self", "label": 0}, {"snippet_id": 48374, "code": ")) except TypeError: raise SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams", "label": 0}, {"snippet_id": 43631, "code": " WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected,", "label": 1}, {"snippet_id": 74820, "code": ": blosc_shuffle_mode_int=int(blosc_shuffle_mode_str) if blosc_shuffle_mode_int in vcf_to_zarr_blosc_shuffle_types: self.blosc_shuffle_mode=blosc_shuffle_mode_int else: raise ValueError(\"Invalid value for", "label": 0}, {"snippet_id": 92869, "code": " _stdio_as_tempfiles(self): \"\"\"Harness to replace `sys.std*` with tempfiles. Validates that all files are read/written/flushed correctly, and acts as a contextmanager to allow for recursive tests. \"\"\" uuid_str=str(uuid", "label": 0}, {"snippet_id": 61125, "code": " matrix:math:`e^{-i \\sigma_y \\theta/2}` \"\"\" return expm(-1j * theta/2 * Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation", "label": 0}, {"snippet_id": 60508, "code": " Thermal, 'GaussianState': Gaussian, 'Beamsplitter': BSgate, 'ControlledAddition': CXgate, 'ControlledPhase': CZgate, 'Displacement': Dgate, 'QuadraticPhase': Pgate, 'Rotation': Rgate, 'TwoModeSqueezing':", "label": 0}, {"snippet_id": 49576, "code": " self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles=priorityfiles, priorityrules=priorityrules,", "label": 0}, {"snippet_id": 45647, "code": "(self.file) def contains_wildcard(self): return contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self)", "label": 0}, {"snippet_id": 79126, "code": ".seek(0) \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:", "label": 1}, {"snippet_id": 84920, "code": " classpath.append(jline_dep) cls.register_jvm_tool(register, cls._key_for_tool_version('scala-repl', version), classpath=classpath) def register_style_tool(version): cls.register_jvm_tool(register, cls", "label": 1}, {"snippet_id": 18309, "code": "={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'.format( SERVER_IDLE_SUICIDE_SECONDS)] if not self._user_options[ 'server_use_vim_stdout", "label": 0}, {"snippet_id": 7564, "code": " extracted author keywords :var acronyms: dictionary of acronyms :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return ", "label": 0}, {"snippet_id": 16705, "code": ":{0}'.format( BaseRequest.server_location) debug_info +='\\nServer process ID:{0}'.format( self._server_popen.pid) if self._server_stderr or self._server_stdout: debug_info +='\\nServer logfiles:\\n {0}\\n", "label": 0}, {"snippet_id": 4454, "code": " output_mode=raw, it will return (single_keywords, composite_keywords, author_keywords, acronyms) for other output modes it returns formatted string \"\"\" cache=reader.get_cache(taxonomy_name) if not cache:", "label": 0}, {"snippet_id": 46587, "code": "._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key", "label": 0}, {"snippet_id": 65177, "code": ".upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type", "label": 0}, {"snippet_id": 58327, "code": ".user.save() def test_urls_for_emails_with_pluses(self): self.client.login( username=self.user.username, password='testing') response=self.client.get(reverse('iframe-navigation')) self.assertContains(response", "label": 0}, {"snippet_id": 38658, "code": "): return filterfalse(self.is_rule, items) else: def files(items): return map(os.path.relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None", "label": 0}, {"snippet_id": 83567, "code": "=getattr(job_wrapper, 'prepare_input_files_cmds', None) if prepare_input_files_cmds is not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command", "label": 0}, {"snippet_id": 19627, "code": ") break return supported, pydevd, script def _parse_args(prog, argv): parser=argparse.ArgumentParser( prog=prog, usage=USAGE.format(prog), ) parser.add_argument('--nodebug', action='store_true') host=parser", "label": 0}, {"snippet_id": 37619, "code": ": raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in", "label": 0}, {"snippet_id": 9062, "code": "=extract_abbreviations(fulltext) single_keywords=extract_single_keywords(_skw, fulltext) composite_keywords=extract_composite_keywords(_ckw, fulltext, single_keywords) if only_core_tags: single_keywords=clean_before_output", "label": 0}, {"snippet_id": 74807, "code": "\\n\" \"blosc_compression_level could not be converted to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str=runtime_config.vcf_to_zarr[\"blosc_shuffle_mode\"] if isint", "label": 0}, {"snippet_id": 89479, "code": "(path) and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version=None, maximum_version=None, jdk=False): \"\"\"Creates a distribution wrapping the given `home_path` or", "label": 0}, {"snippet_id": 38336, "code": ".overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda log: None self._onerror=lambda log: None self.debug=debug global config config=dict() config.update(self.overwrite_config)", "label": 0}, {"snippet_id": 41650, "code": "\"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except", "label": 0}, {"snippet_id": 61082, "code": ",[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_x \\theta/2}` \"\"\" return expm(-1j", "label": 0}, {"snippet_id": 70125, "code": ", target.dev) self.update() def ev_starttarget_done(self, node, target): self.status_changed=True if self.verbose > 1: if target.status_info: print \"%s: Start of %s %s(%s): %s\" % \\ (node, target.type.upper", "label": 0}, {"snippet_id": 82376, "code": "\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n]\") \t\tif not cont.lower().startswith(\"y\"): \t\t\texit() \telse: \t\ttemplates=[[x for x in templates if x", "label": 0}, {"snippet_id": 28180, "code": "'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None]", "label": 0}, {"snippet_id": 90591, "code": " :param maximum_version: maximum jvm version to look for(eg, 1.7.9999). The stricter of this and `--jvm-distributions-maximum-version` is used. :param bool jdk: whether the found java distribution is required", "label": 0}, {"snippet_id": 86327, "code": " else WorkUnit.SUCCESS) if return_code: raise TaskError('javac exited with return code{rc}'.format(rc=return_code)) @classmethod def _javac_plugin_args(cls, javac_plugin_map): ret=[] for plugin, args in", "label": 0}, {"snippet_id": 82284, "code": " loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file. Example: <input type=\\\"file\\\" name", "label": 0}, {"snippet_id": 46488, "code": " Arguments names --the given names as(name, index) pairs \"\"\" for name,(i, j) in names: self.set_name(name, i, end=j) def items(self): for name in self._names: yield name, getattr(self, name) def allitems", "label": 0}, {"snippet_id": 31965, "code": " \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item, output=False, name=None): \"\"\" Set an item to be input or output. Arguments item ", "label": 0}, {"snippet_id": 7570, "code": " :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords", "label": 0}, {"snippet_id": 65272, "code": "(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) mount_options=", "label": 0}, {"snippet_id": 14220, "code": " signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'", "label": 0}, {"snippet_id": 24871, "code": "': self._state=data['WindStrength'] elif self.type=='gustangle_value': self._state=data['GustAngle'] elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle']", "label": 0}, {"snippet_id": 48485, "code": "(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len", "label": 0}, {"snippet_id": 3890, "code": "=parser.add_subparsers(dest=\"cmd\") subparser_editor=subparsers.add_parser('edit', help=\"Launches the editor to edit or create new systems and \" \"components\") subparser_run=subparsers.add_parser('run', help", "label": 0}, {"snippet_id": 66078, "code": ": return self[\"index\"] < other[\"index\"] ldic=[] jdev_col_enabled=False tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state", "label": 0}, {"snippet_id": 26152, "code": "(__name__) CONF_MODULES='modules' CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE", "label": 1}, {"snippet_id": 43333, "code": " self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{}", "label": 0}, {"snippet_id": 83873, "code": "(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s\" %( errno.errorcode[e.errno], pid, e.strerror)) return False def stop_job( self, job): job_ext_output_metadata", "label": 0}, {"snippet_id": 12346, "code": "[\"message\"][\"opened\"][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action", "label": 0}, {"snippet_id": 66961, "code": " commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd", "label": 0}, {"snippet_id": 61530, "code": "._observe.wires) n0=np.random.binomial(self.shots, p0) ev=(n0*a[0] +(self.shots-n0)*a[1]) / self.shots self._out=ev @classmethod def _get_operator_matrix(cls, A): \"\"\"Get the operator matrix for a given", "label": 0}, {"snippet_id": 56731, "code": " if request.GET.get(obj): self.object=obj self.object_pk=request.GET.get(obj) break def get(self): func=getattr(self, self.object) return func() def plan(self): return 'management/get_tag.html', TestPlan", "label": 0}, {"snippet_id": 81019, "code": ",headers={\"Accept-Encoding\":None}) \t\t\tself.httpRequests +=1 \t\t\tif self.logger.verbosity > 1: \t\t\t\tprintSimpleResponseObject(initGet) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+initGet.text+\"\\033[m\")", "label": 0}, {"snippet_id": 65284, "code": "} mount_paths={} for target_type in[ 'mgt', 'mdt', 'ost']: mount_options[target_type]=fs_conf.get_target_mount_options(target_type) mount_paths[target_type]=fs_conf.get_target_mount_path(target_type) fs", "label": 0}, {"snippet_id": 22014, "code": " self.ask_su_pass=ask_su_pass self.sudo=sudo self.sudo_user=sudo_user self.become=become self.become_method=become_method self.become_user=become_user self.become_ask_pass=become_ask_pass self.ask_pass", "label": 0}, {"snippet_id": 93394, "code": ".config['groups']: for comp in group['components']: self.nodes[comp['name']]=Node(comp) master_node=Node({'name': 'master_node'}) for name in self.nodes: node=self.nodes.get(name) master_node.addEdge(node)", "label": 0}, {"snippet_id": 87521, "code": ".extend(self._get_zinc_arguments(settings)) zinc_args.append('-transactional') for option_set in compiler_option_sets: enabled_args=self.get_options().compiler_option_sets_enabled_args.get(option_set,[", "label": 0}, {"snippet_id": 19914, "code": " running') if self._session is not None: raise RuntimeError('already attached') raise NotImplementedError def attach_socket(self, addr=None, adapter=None, **kwargs): if self.closed: raise RuntimeError(", "label": 0}, {"snippet_id": 13614, "code": ".find( \"twitter\") >=0):\r myText +=\"0\"\r myText=myText[7:-1]\r try:\r \t myText=twitter.getTweet( myText)\r \texcept:\r \t print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\"", "label": 0}, {"snippet_id": 91391, "code": "=BuildLocalPythonDistributions).install('pyprep') task(name='requirements', action=ResolveRequirements).install('pyprep') task(name='sources', action=GatherSources).install('pyprep') task(name='py', action=PythonRun)", "label": 0}, {"snippet_id": 31940, "code": "( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all", "label": 0}, {"snippet_id": 57313, "code": " User.DoesNotExist): pass targets.update(close_date=now, tested_by=request.user) return say_yes() @require_POST def update_case_run_status(request): \"\"\" Update Case Run status. \"\"\" now=datetime.datetime", "label": 0}, {"snippet_id": 56581, "code": " \"\"\" Get tags for TestPlan, TestCase or TestRun \"\"\" tag_objects=_TagObjects(request) template_name, obj=tag_objects.get() q_tag=request.GET.get('tags') q_action=request.GET.get('a') if q_action: tag_actions", "label": 0}, {"snippet_id": 51351, "code": ") def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value", "label": 0}, {"snippet_id": 70266, "code": "(rc) else: strerr=message print \"Failed to start %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message class Start(FSLiveCommand): \"\"\" shine start[-f <fsname>]", "label": 0}, {"snippet_id": 17738, "code": " x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes()[ 0", "label": 0}, {"snippet_id": 36669, "code": "): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\"", "label": 0}, {"snippet_id": 2126, "code": ",'allwifiaps':wifi_aps, 'reqtype': 'deleteuser', 'endpoint': username}], safe=False) elif action=='addNewUser': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get", "label": 0}, {"snippet_id": 68869, "code": ", AsciiTableLayout.LEFT, \"label\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"flags\", i, AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 29039, "code": "] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data from NetAtmo.\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data", "label": 0}, {"snippet_id": 35990, "code": " from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards", "label": 0}, {"snippet_id": 68924, "code": ".RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalUmountEventHandler(Shine", "label": 0}, {"snippet_id": 28463, "code": " @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def", "label": 0}, {"snippet_id": 44048, "code": ") if resources is None else resources self.global_resources[\"_cores\"]=cores self.global_resources[\"_nodes\"]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files", "label": 0}, {"snippet_id": 26621, "code": "'battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770: self._state=\"Medium\" elif data['battery_vp'] >=4360: self._state=\"Low\" elif data['battery_vp'] < 4360: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 75863, "code": ".send_multipart(msg) rs.finished=False rs.retry=False continue return elapsed=t.elapsed(False) if elapsed >=timeout: t.tick() rs.accept(None, 0, 255,[elapsed]) raise WorkerInterrupt() def wz_multiwait(self, requests", "label": 0}, {"snippet_id": 79323, "code": "\t\t\tfor ext in extensionsToTest: \t\t\t\t\tf=executor.submit(self.uploadFile,\".\"+ext[0],ext[1],os.urandom(self.size)) \t\t\t\t\tf.ext=ext \t\t\t\t\tf.add_done_callback(self.detectValidExtension) \t\t\t\t\tfutures.append(f)", "label": 0}, {"snippet_id": 9816, "code": "\"\"\"Output the same as txt output does, but HTML formatted. :var skw_matches: sorted list of single keywords :var ckw_matches: sorted list of composite keywords :var author_keywords: dictionary of extracted", "label": 0}, {"snippet_id": 22373, "code": " OSUtilError: Raises exception if mcpd does not come up within roughly 50 minutes(100 * 30 seconds) \"\"\" for retries in range(1, 100): logger.info(\"Checking to see if mcpd is up\") rc=shellutil.run(\"/usr", "label": 0}, {"snippet_id": 31315, "code": " return False return self.rule==other.rule and( self.dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return", "label": 0}, {"snippet_id": 39874, "code": " if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path in paths] def targets(self, dag): return[f for job in dag.jobs for f in job", "label": 0}, {"snippet_id": 8385, "code": "(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return[] lines=[line.decode(\"utf-8\",", "label": 0}, {"snippet_id": 18474, "code": " force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest", "label": 0}, {"snippet_id": 64584, "code": "=self.nodes_support.get_nodeset() fs.install(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system ", "label": 0}, {"snippet_id": 36515, "code": ".intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format( self.rule, unexpected_output))", "label": 0}, {"snippet_id": 54418, "code": " import sys import signal import json import urllib from collections import OrderedDict from itertools import filterfalse, chain from functools import partial from operator import attrgetter from snakemake", "label": 0}, {"snippet_id": 59571, "code": "\"\" pass def _deallocate(self): \"\"\"Deallocate all qubits to make ProjectQ happy See also: https://github.com/ProjectQ-Framework/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"", "label": 0}, {"snippet_id": 6409, "code": " invenio.legacy.bibclassify import ontology_reader as reader import text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer", "label": 0}, {"snippet_id": 46873, "code": ", self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items() } self.threads", "label": 0}, {"snippet_id": 18730, "code": "._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax", "label": 0}, {"snippet_id": 18631, "code": "._latest_file_parse_request.Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self)", "label": 0}, {"snippet_id": 12907, "code": "[filename]=data[\"diff\"][filename].replace(\"file_to_check.py\", filename) data[\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]", "label": 0}, {"snippet_id": 25573, "code": "'sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2': self._state=data['CO2'] elif self.type=='pressure': self._state=round(data['Pressure", "label": 0}, {"snippet_id": 33630, "code": ".version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True", "label": 0}, {"snippet_id": 77306, "code": " self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess): type_=1 if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not", "label": 0}, {"snippet_id": 79505, "code": "\tif self.uploadsFolder: \t\t\t\t\turl=self.schema+\"://\"+self.host+\"/\"+self.uploadsFolder+\"/\"+fu[1] \t\t\t\t\tfilename=fu[1] \t\t\t\t\tsecondUrl=None \t\t\t\t\tfor b in getPoisoningBytes(): \t\t\t\t\t\tif b in filename: \t\t\t\t\t\t\tsecondUrl", "label": 1}, {"snippet_id": 32137, "code": " SyntaxError( \"Input and output files have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params", "label": 0}, {"snippet_id": 5805, "code": " _get_partial_text(fulltext): \"\"\" Return a short version of the fulltext used with the partial matching mode. The version is composed of 20% in the beginning and 20% in the middle of the text.\"\"\" length", "label": 0}, {"snippet_id": 63350, "code": " metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory'], metadata_kwds", "label": 0}, {"snippet_id": 4615, "code": " string to search in :skw_spans: dictionary of already identified single keywords :return: dictionary of matches in a format{ <keyword object>,[[position, position...],[info_about_matches]], .. } or empty", "label": 0}, {"snippet_id": 40261, "code": " return self.file[:first_wildcard.start()] return self.file def match(self, target): return self.regex().match(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def", "label": 0}, {"snippet_id": 36238, "code": " Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError", "label": 0}, {"snippet_id": 74193, "code": " to extract benchmark configuration from :type runtime_config: ConfigurationRepresentation \"\"\" if runtime_config is not None: if hasattr(runtime_config, \"benchmark\"): if \"benchmark_number_runs\" in runtime_config", "label": 0}, {"snippet_id": 79615, "code": "'%(asctime)s %(levelname)s -%(message)s',level=logging.INFO) logging.getLogger(\"requests\").setLevel(logging.ERROR) templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads", "label": 0}, {"snippet_id": 32515, "code": " benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{}\".format(self, str", "label": 0}, {"snippet_id": 10871, "code": " def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os.path.exists(os.path.join(directory, executable)): return", "label": 1}, {"snippet_id": 89410, "code": " JDK installed on the local system. In particular provides access to the distribution's binaries; ie: java while ensuring basic constraints are met. For example a minimum version can be specified if you", "label": 0}, {"snippet_id": 49838, "code": "(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed", "label": 0}, {"snippet_id": 95562, "code": "=local_directory, remote_directory=remote_directory, remote_subdirs_list=new_remote_subdirs_list) ftp.cwd(remote_path_absolute) except error_perm: temp=ftp.nlst() if not os.path.isfile(file_path_local): with open", "label": 0}, {"snippet_id": 40128, "code": " ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode", "label": 0}, {"snippet_id": 63754, "code": " for job, unable to stop\" % job.id) return pid=int( pid) if not self.check_pid( pid): log.warning( \"stop_job(): %s: PID %d was already dead or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]", "label": 0}, {"snippet_id": 62288, "code": ", *par): if gate_name not in self._gates: raise ValueError('Gate{} not supported on this backend'.format(gate)) gate=operator_map[gate_name](*par) if isinstance(wires, int): gate | self.reg[wires] else", "label": 0}, {"snippet_id": 13804, "code": ".parse('2004-01-01 00:00 +01')).total_seconds() class safeeval: def __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals)", "label": 0}, {"snippet_id": 3726, "code": ".STARTED_BY_HAND else: logger.debug(\"Window not running and no check command is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes'", "label": 0}, {"snippet_id": 12873, "code": " file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate", "label": 0}, {"snippet_id": 33856, "code": ".included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format(snakefile)) return", "label": 0}, {"snippet_id": 16367, "code": ")) if self._user_options[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str", "label": 0}, {"snippet_id": 9843, "code": " :var spires: boolean :var only_core_tags: boolean :keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords", "label": 0}, {"snippet_id": 52282, "code": ".log, self.benchmark, self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in", "label": 0}, {"snippet_id": 43574, "code": "-1 elif comp > 0: comp=1 return comp except ValueError: pass wildcard_cmp=rule2.has_wildcards() -rule1.has_wildcards() if wildcard_cmp !=0: return wildcard_cmp return 0 def __iter__(self): return self.order", "label": 0}, {"snippet_id": 46816, "code": " from snakemake.logging import logger def jobfiles(jobs, type): return chain(*map(attrgetter(type), jobs)) class Job: HIGHEST_PRIORITY=sys.maxsize def __init__(self, rule, dag, targetfile=None, format_wildcards", "label": 0}, {"snippet_id": 34653, "code": " file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def", "label": 1}, {"snippet_id": 72341, "code": "(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally: log.debug('(%s) networks.remote: restoring reply() of IRC object", "label": 1}, {"snippet_id": 62977, "code": " remotely, but remote LWR isn't properly configured with a galaxy_home directory.\" NO_REMOTE_DATATYPES_CONFIG=\"LWR client is configured to use remote datatypes configuration when setting metadata externally", "label": 0}, {"snippet_id": 58658, "code": ": 'False', 'value_type': 'bool' } response=self.client.post(self.update_url, post_data) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'Permission", "label": 0}, {"snippet_id": 15212, "code": "']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ", "label": 0}, {"snippet_id": 85222, "code": " name \"{0}\" should not be suffixed with the scala platform version ' '({1}): it will be added automatically.'.format(name, self.version)) return '{0}_{1}'.format(name, self.version) @property def repl(self", "label": 0}, {"snippet_id": 44080, "code": ".relpath, filterfalse(self.is_rule, items)) if not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None:", "label": 0}, {"snippet_id": 43687, "code": " \"\"\" Create the controller. \"\"\" self._rules=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder", "label": 0}, {"snippet_id": 94341, "code": " elif not self.session: self.logger.error(\" Init aborted. No session was found!\") exit(CheckState.STOPPED.value) check_state=check_component(self.config, self.session, self.logger) exit(check_state.value)", "label": 0}, {"snippet_id": 12349, "code": "][\"header\"]==\"\": comment_header=\"Hello @\" +author +\"! Thanks for submitting the PR.\\n\\n\" else: comment_header=config[\"message\"][\"opened\"][\"header\"] +\"\\n\\n\" elif request.json[\"action\"] in[\"synchronize\",", "label": 0}, {"snippet_id": 36015, "code": "=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards", "label": 0}, {"snippet_id": 29832, "code": " after a certain rule has been run \"\"\" annotated=flag(value, \"dynamic\") tocheck=[annotated] if not_iterable(annotated) else annotated for file in tocheck: matches=list(_wildcard_regex.finditer(file)) for", "label": 1}, {"snippet_id": 25604, "code": "=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self._state=\"High\" elif data['battery_vp'] >=4770:", "label": 0}, {"snippet_id": 78985, "code": "[0][\"name\"] \t\tself.logger.debug(\"Found the following file upload input: %s\",self.inputName) \t\tformDestination=detectedForms[0][0] \t\ttry: \t\t\tself.action=formDestination[\"action\"] \t\texcept: \t\t\tself.action", "label": 0}, {"snippet_id": 26960, "code": ">=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status", "label": 0}, {"snippet_id": 55660, "code": " lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if", "label": 0}, {"snippet_id": 11479, "code": " self._is_newer(header_source, yaml_config.host_name): file_name=self.create_filename(yaml_config.host_name) yaml_icinga=YamlToIcinga(yaml_config, header_source) self.write_output(file_name, yaml_icinga", "label": 0}, {"snippet_id": 67791, "code": " def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler", "label": 0}, {"snippet_id": 33963, "code": ") update_config(config, c) update_config(config, self.overwrite_config) def ruleorder(self, *rulenames): self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow", "label": 0}, {"snippet_id": 48572, "code": " except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException", "label": 0}, {"snippet_id": 45699, "code": " def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,", "label": 0}, {"snippet_id": 62554, "code": " super().reset() def expectation(self, observable, wires): self.eng.flush(deallocate_qubits=False) if observable=='PauliX' or observable=='PauliY' or observable=='PauliZ': expectation_value=self.eng.backend", "label": 0}, {"snippet_id": 54559, "code": ".persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile", "label": 0}, {"snippet_id": 73730, "code": " \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section", "label": 0}, {"snippet_id": 74373, "code": " +\"download/\" temp_dir=\"./data/temp/\" vcf_dir=\"./data/vcf/\" zarr_dir_setup=\"./data/zarr/\" zarr_dir_benchmark=\"./data/zarr_benchmark/\" def isint(value): try: int(value) return True except ValueError: return", "label": 0}, {"snippet_id": 94220, "code": ".error(\"No slave component config provided\") def load_config(self, filename=\"default.yaml\"): with open(filename) as data_file: self.config=load(data_file, Loader) def init(self): if not self.config: self", "label": 0}, {"snippet_id": 18733, "code": "] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax']: return filetype=vimsupport.CurrentFiletypes", "label": 0}, {"snippet_id": 81806, "code": " execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following(name -description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t", "label": 0}, {"snippet_id": 79839, "code": "--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the template in", "label": 0}, {"snippet_id": 4588, "code": ", fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite", "label": 0}, {"snippet_id": 85592, "code": " and classpaths. :rtype::class:`Zinc` \"\"\" return Zinc(self, products) def __init__(self, zinc_factory, products): self._zinc_factory=zinc_factory self._products=products @memoized_property def zinc(self)", "label": 0}, {"snippet_id": 16590, "code": "'BufferVisit', extra_data) def OnInsertLeave( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'InsertLeave') def OnCursorMoved( self): self._diag_interface.OnCursorMoved() def OnVimLeave", "label": 0}, {"snippet_id": 11286, "code": " logging import os import sys from docopt import docopt from monitoring_config_generator.exceptions import MonitoringConfigGeneratorException, \\ ConfigurationContainsUndefinedVariables, NoSuchHostname,", "label": 0}, {"snippet_id": 89982, "code": "*args, distribution=self, **kwargs) @memoized_method def _get_version(self, java): return _parse_java_version('java.version', self._get_system_properties(java)['java.version']) def _get_system_properties", "label": 0}, {"snippet_id": 86343, "code": ": ret=[] for plugin, args in javac_plugin_map.items(): for arg in args: if ' ' in arg: raise TaskError('javac plugin args must not contain spaces ' '(arg{} for plugin{})'.format(arg, plugin)) ret.append", "label": 0}, {"snippet_id": 70409, "code": "=Tune.get_tuning(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) if hasattr(eh, 'post", "label": 0}, {"snippet_id": 58070, "code": "'action'] try: if action==\"add\": for run in runs: for bug_id in bug_ids: run.add_bug(bug_id=bug_id, bug_system_id=bug_system_id, bz_external_track=bz_external_track) else: bugs=Bug.objects.filter(bug_id__in", "label": 0}, {"snippet_id": 20669, "code": "(self._received) def _create_request(self, command, **args): seq=self._seq self._seq +=1 return{ 'type': 'request', 'seq': seq, 'command': command, 'arguments': args, } def send_request(self, command, ", "label": 0}, {"snippet_id": 88327, "code": " Advanced uses of the context include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated with. :API:", "label": 0}, {"snippet_id": 8269, "code": " document is a PDF file. Returns True if is is.\"\"\" if not executable_exists('pdftotext'): log.warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower()", "label": 1}, {"snippet_id": 64694, "code": " client): if self.verbose > 1: print \"%s: Mounting %s on %s...\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_done(self, node, client): if self.verbose > 1: if client.status_info: print ", "label": 1}, {"snippet_id": 49244, "code": " rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule(name, self, lineno=lineno,", "label": 0}, {"snippet_id": 15333, "code": "'server_use_vim_stdout']: filename_format=os.path.join( utils.PathToTempDir(), 'server_{port}_{std}.log') self._server_stdout=filename_format.format( port=server_port, std='stdout') self._server_stderr", "label": 0}, {"snippet_id": 15800, "code": " extra_conf_vim_data): return dict(( expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data", "label": 0}, {"snippet_id": 61655, "code": "(expectation.imag)) return expectation.real def reset(self): \"\"\"Reset the device\"\"\" self._state =None self._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a full system operator.", "label": 0}, {"snippet_id": 33484, "code": "=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir=subworkflow.workdir, targets=subworkflow_targets, updated_files", "label": 0}, {"snippet_id": 82892, "code": "\") \ttemplatesData[template[\"templateName\"]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t", "label": 1}, {"snippet_id": 13984, "code": " def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri", "label": 0}, {"snippet_id": 73956, "code": "(runtime_config.vcf_to_zarr[\"enabled\"]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr[\"alt_number\"] if str(alt_number_str).lower()==\"auto\": self.alt_number=None elif", "label": 0}, {"snippet_id": 29251, "code": "} seems to be a broken symlink.\".format(self.file)) def is_newer(self, time): return self.mtime > time def prepare(self): path_until_wildcard=re.split(self.dynamic_fill, self.file)[0] dir=os.path.dirname", "label": 0}, {"snippet_id": 22495, "code": "--del waagent\", chk_err=False) def get_dhcp_pid(self): ret=shellutil.run_get_output(\"/sbin/pidof dhclient\") return ret[1] if ret[0]==0 else None def set_hostname(self, hostname): \"\"\"Set the static hostname", "label": 0}, {"snippet_id": 53893, "code": " str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item) if name: self.log.add_name(name) else: try: start=len(self.log) for i in item: self._set_log_item(i) if", "label": 0}, {"snippet_id": 67851, "code": " eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel > 0: print \"Start successful.\" tuning", "label": 0}, {"snippet_id": 79127, "code": ") \t\t\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:(filename", "label": 1}, {"snippet_id": 34495, "code": " dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source directory of the current Snakefile.\"\"\" if not workflow.included_stack: return None return os.path.join(os.path", "label": 0}, {"snippet_id": 16673, "code": " 'message' in debug_info: vimsupport.EchoText( debug_info[ 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest", "label": 0}, {"snippet_id": 20361, "code": "( Connection, create_server, create_client, close, recv_as_read, send_as_write, timeout as socket_timeout) from.threading import get_locked_and_waiter from.vsc import parse_message class DebugSessionConnection", "label": 0}, {"snippet_id": 4579, "code": "} \"\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences", "label": 0}, {"snippet_id": 91722, "code": " tgt_snapshot=maybe_source_target.sources.snapshot tgt_source_root=source_roots.find_by_path(maybe_source_target.address.spec_path) sources_snapshots_and_source_roots.append((tgt_snapshot, tgt_source_root", "label": 0}, {"snippet_id": 48270, "code": ".temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise", "label": 0}, {"snippet_id": 53915, "code": "._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"", "label": 0}, {"snippet_id": 42091, "code": " in omit_resources } params={name: value for name, value in self.params.items()} properties={ \"rule\": self.rule.name, \"local\": self.dag.workflow.is_local(self.rule), \"input\": self.input, \"output\": self", "label": 0}, {"snippet_id": 90408, "code": "._homes=homes @property def jvm_locations(self): for home in self._homes: yield self.Location.from_home(home) class _UnknownEnvironment(_DistributionEnvironment): def __init__(self, *possible_environments)", "label": 0}, {"snippet_id": 79793, "code": "\"--uploads-path\",default=[None],metavar=\"path\",nargs=1,dest=\"uploadsPath\",help=\"Path on the remote server where uploads are put. Example: '/tmp/uploads/'\") parser.add_argument(\"-t\",\"--template\",metavar", "label": 0}, {"snippet_id": 54057, "code": " is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}", "label": 0}, {"snippet_id": 21618, "code": " import StandardScaler sc=StandardScaler() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) y_pred=classifier.predict(X_test) from sklearn.metrics import confusion_matrix cm=confusion_matrix", "label": 0}, {"snippet_id": 21870, "code": " from ansible.executor import playbook_executor from ansible.parsing import dataloader from ansible.utils.display import Display from dciclient.v1 import helper as dci_helper from dciagent.plugins import", "label": 0}, {"snippet_id": 36535, "code": " if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove(f) for f, f_ in zip(self", "label": 0}, {"snippet_id": 10975, "code": " error: %s\" %(url, e) raise HostUnreachableException(msg) except ConnectionError as e: msg=\"Could not establish connection for '%s', error: %s\" %(url, e) raise HostUnreachableException(msg) except Timeout", "label": 0}, {"snippet_id": 72648, "code": " benchmark data.\") data_service.remove_directory_tree(vcf_directory) data_service.remove_directory_tree(zarr_directory_setup) runtime_config=config.read_configuration(location=cli_arguments[\"config_file\"]", "label": 1}, {"snippet_id": 63864, "code": ".get_job_runner_external_id()) job_state.runner_url=job_wrapper.get_job_runner_url() job_state.job_destination=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state", "label": 0}, {"snippet_id": 53758, "code": " SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output", "label": 0}, {"snippet_id": 52533, "code": " restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f, self.rule) else: yield f @property def dynamic_wildcards(self): \"\"\" Return", "label": 1}, {"snippet_id": 72537, "code": " exists.\") data_setup_parser=subparser.add_parser(\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file", "label": 0}, {"snippet_id": 94833, "code": ".config) if args.visual: cc.set_dependencies(False) cc.draw_graph() else: cc.set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill,", "label": 0}, {"snippet_id": 55522, "code": " include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile", "label": 0}, {"snippet_id": 16309, "code": "(), _PathToServerScript(), '--port={0}'.format( server_port), '--options_file={0}'.format( options_file.name), '--log={0}'.format( self._user_options[ 'server_log_level']), '--idle_suicide_seconds={0}'", "label": 0}, {"snippet_id": 24723, "code": "._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500:", "label": 0}, {"snippet_id": 29712, "code": "): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value", "label": 0}, {"snippet_id": 172, "code": "+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print", "label": 1}, {"snippet_id": 16736, "code": "._user_options[ 'filetype_specific_completion_to_disable'] return not all([ x in filetype_to_disable for x in filetypes]) def _AddSyntaxDataIfNeeded( self, extra_data): if not self._user_options[ 'seed_identifiers_with_syntax", "label": 0}, {"snippet_id": 44834, "code": " lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if", "label": 0}, {"snippet_id": 83926, "code": " or can't be signaled\" %( job.id, pid)) return for sig in[ 15, 9]: try: os.killpg( pid, sig) except OSError, e: log.warning( \"stop_job(): %s: Got errno %s when attempting to signal %d to PID %d: %s\" %(", "label": 0}, {"snippet_id": 30652, "code": ".threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output", "label": 0}, {"snippet_id": 38523, "code": " in rule.resources): if resource not in \"_cores _nodes\".split(): logger.info(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun", "label": 0}, {"snippet_id": 84661, "code": ".join(tmpdir, 'input_files_list') with open(list_file, 'w') as list_file_out: for input_file in sorted(input_files): list_file_out.write(input_file) list_file_out.write('\\n') list_file_snapshot=self.context", "label": 0}, {"snippet_id": 76773, "code": "=float, default=0.8, help='Captcha rate limit') parser.add_argument('--comment_successtimeout', type=float, default=0.8, help='Comment success timeout') parser.add_argument('--topic_successtimeout', type", "label": 0}, {"snippet_id": 34859, "code": "(target) or None def format_dynamic(self): return self.replace(self.dynamic_fill, \"{*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self", "label": 0}, {"snippet_id": 40148, "code": ": lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException", "label": 1}, {"snippet_id": 74097, "code": "\\n\" \"blosc_compression_level must be between 0 and 9.\") else: raise TypeError(\"Invalid value for blosc_compression_level in configuration.\\n\" \"blosc_compression_level could not be converted to integer.", "label": 0}, {"snippet_id": 49787, "code": ".needrun(job) and not os.path.exists(f)] if missing_input: logger.error( \"Dependency resolution disabled(--nodeps) \" \"but missing input \" \"files detected. If this happens on a cluster, please make sure", "label": 0}, {"snippet_id": 13231, "code": ", auth=auth) for ref in r.json(): if ref[\"ref\"].split(\"/\")[-1]==data[\"target_repo_branch\"]: sha=ref[\"object\"][\"sha\"] url=\"https://api.github.com/repos/{}/git/refs\" url=url.format(data[\"fork_fullname\"])", "label": 0}, {"snippet_id": 32150, "code": " self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self", "label": 0}, {"snippet_id": 46836, "code": " self.rule=rule self.dag=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards", "label": 0}, {"snippet_id": 36214, "code": " else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule", "label": 0}, {"snippet_id": 14984, "code": ", handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS)", "label": 0}, {"snippet_id": 72398, "code": "'networks.reloadproto']) try: name=args[0] except IndexError: irc.error('Not enough arguments(needs 1: protocol module name)') return proto=utils.getProtocolModule(name) importlib.reload(proto) irc.reply", "label": 0}, {"snippet_id": 70180, "code": "%s\" % \\ (node, target.type.upper(), target.get_id(), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose", "label": 0}, {"snippet_id": 50615, "code": " self.message=None self.benchmark=None self.threads=None self.resources=None self.priority=None self.version=None self.log=None self.docstring=None class Subworkflow: def __init__(self, workflow, name,", "label": 0}, {"snippet_id": 80479, "code": ") \t\telse: \t\t\tlogging.warning(\"Extension %s can't be found as a valid/known extension with associated mime type.\",b) args.legitExtensions=tmpLegitExt postData=postDataFromStringToJSON(args.data) s=requests", "label": 0}, {"snippet_id": 71757, "code": "*s %s\" %(cmd_maxlen, cmd.get_name(), cmd.get_params_desc()) def print_error(self, errmsg): print >>sys.stderr, \"Error:\", errmsg def print_help(self, msg, cmd): if msg: print msg print print \"Usage: %s ", "label": 0}, {"snippet_id": 25137, "code": " STATE_UNKNOWN) from homeassistant.helpers.entity import Entity from homeassistant.util import Throttle import homeassistant.helpers.config_validation as cv _LOGGER=logging.getLogger(__name__) CONF_MODULES=", "label": 1}, {"snippet_id": 20263, "code": " detachable=False, env=env, cwd=cwd) return self._adapter, self._session def launch_script(self, filename, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is", "label": 0}, {"snippet_id": 46123, "code": " arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their", "label": 0}, {"snippet_id": 1243, "code": "=osfilecontent[4].split('=')[1].strip('\\\"') return version def get_allconfiguredwifi(): \"\"\" nmcli con | grep 802-11-wireless \"\"\" ps=subprocess.Popen('nmcli -t -f NAME,TYPE conn | grep 802-11-wireless', shell", "label": 0}, {"snippet_id": 61072, "code": "[1, 0, 0, 0],[0, 0, 1, 0],[0, 1, 0, 0],[0, 0, 0, 1]]) def frx(theta): r\"\"\"One-qubit rotation about the x axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i ", "label": 0}, {"snippet_id": 34006, "code": " name=None, lineno=None, snakefile=None): name=self.add_rule(name, lineno, snakefile) rule=self.get_rule(name) def decorate(ruleinfo): if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input", "label": 0}, {"snippet_id": 31674, "code": " self.shellcmd=other.shellcmd self.norun=other.norun def dynamic_branch(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output", "label": 0}, {"snippet_id": 52560, "code": " f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): combinations.add(tuple(w.items", "label": 0}, {"snippet_id": 56718, "code": " the type of object to be selected :type request: HttpRequest \"\"\" for obj in['plan', 'case', 'run']: if request.GET.get(obj): self.object=obj self.object_pk=request.GET.get(obj) break def get(self): func", "label": 0}, {"snippet_id": 53198, "code": "=dict() self.dynamic_output=set() self.dynamic_input=set() self.temp_output=set() self.protected_output=set() self.touch_output=set() self.subworkflow_input=dict() self.resources=dict(_cores=1, _nodes=1", "label": 0}, {"snippet_id": 64667, "code": " import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler):", "label": 0}, {"snippet_id": 34514, "code": "=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import MissingOutputException,", "label": 1}, {"snippet_id": 57964, "code": ".GET.get('case_runs', '').split(',')) except(TypeError, ValueError) as e: return(None, 'Please specify only integers for bugs, ' 'caseruns(using comma to seperate IDs), ' 'and bug_system.(DEBUG INFO: %s", "label": 0}, {"snippet_id": 6985, "code": " ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output", "label": 0}, {"snippet_id": 33940, "code": " None: if not os.path.exists(workdir): os.makedirs(workdir) self._workdir=workdir os.chdir(workdir) def configfile(self, jsonpath): \"\"\" Update the global config with the given dictionary. \"\"\" global config", "label": 0}, {"snippet_id": 71289, "code": "(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev", "label": 0}, {"snippet_id": 87431, "code": " classes_dir=relative_to_exec_root(classes_dir) relative_classpath=tuple(relative_to_exec_root(c) for c in absolute_classpath) zinc_args=[] zinc_args.extend([ '-log-level', self.get_options().level, '-analysis", "label": 0}, {"snippet_id": 61701, "code": " !=1: raise ValueError('One target subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np.kron(np.kron(np.eye(before), U), np.eye(after)) return U def expand_two(self,", "label": 0}, {"snippet_id": 61664, "code": "\" self._state =None self._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem Returns:", "label": 0}, {"snippet_id": 15641, "code": ".Response() self._latest_file_parse_request=None if qflist_format: return vimsupport.ConvertDiagnosticsToQfList( diagnostics) else: return diagnostics return[] def UpdateDiagnosticInterface( self): if not", "label": 0}, {"snippet_id": 25974, "code": "'guststrength': self._state=data['GustStrength'] elif self.type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'", "label": 0}, {"snippet_id": 55571, "code": ".included_stack.pop() def onsuccess(self, func): self._onsuccess=func def onerror(self, func): self._onerror=func def workdir(self, workdir): if self.overwrite_workdir is None: if not os.path.exists(workdir", "label": 0}, {"snippet_id": 83759, "code": " cleanup_job=cleanup_job, client_outputs=client_outputs, lwr_outputs=lwr_outputs) failed=lwr_finish_job( **finish_args) if failed: job_wrapper.fail(\"Failed to find or download one or more job outputs from remote", "label": 0}, {"snippet_id": 38405, "code": " raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules", "label": 0}, {"snippet_id": 37876, "code": ".apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() }", "label": 0}, {"snippet_id": 8806, "code": ".startswith('.'): continue filename=os.path.join(entry, filename) if os.path.isfile(filename): text_lines=extractor.text_lines_from_local_file(filename) if text_lines: source=filename process_lines() elif os", "label": 0}, {"snippet_id": 24164, "code": " MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', 'mdi:cloud', None], 'pressure':['Pressure', 'mbar', ", "label": 1}, {"snippet_id": 20095, "code": "._session=self.SESSION.create_client(addr, **kwargs) def _detach(self): session=self._session if session is None: return self._session=None try: session.close() except ClosedError: pass class DebugClient", "label": 0}, {"snippet_id": 18875, "code": "( normalize_request, normalize_response, ) from flex.validation.common import validate_object from flex.validation.request import validate_request from flex.validation.response import validate_response", "label": 0}, {"snippet_id": 15463, "code": " force_semantic=False): if( not self.NativeFiletypeCompletionAvailable() and self.CurrentFiletypeCompletionEnabled() and self._omnicomp.ShouldUseNow()): self._latest_completion_request=OmniCompletionRequest", "label": 0}, {"snippet_id": 22638, "code": ":param hostname: The hostname to set on the device \"\"\" return None def useradd(self, username, expiration=None): \"\"\"Create user account using tmsh Our policy is to create two accounts when booting a BIG", "label": 1}, {"snippet_id": 91354, "code": " Resources, UnpackedWheels.alias(): UnpackedWheels, }, objects={ 'python_requirement': PythonRequirement, 'python_artifact': PythonArtifact, 'setup_py': PythonArtifact, }, context_aware_object_factories=", "label": 0}, {"snippet_id": 94609, "code": " send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i -a", "label": 0}, {"snippet_id": 75423, "code": "==0: self.iden_reqid_map.del_value(iden, reqid) msg=list(iden) msg.append(b'') msg.extend(make_rep_msg(reqid, seqnum, status, answer)) return msg def get_iden(self, reqid): return self.iden_reqid_map.get_key", "label": 0}, {"snippet_id": 91698, "code": "'.format(\", \".join(all_requirements)), output_files=(output_pytest_requirements_pex_filename,), ) requirements_pex_response=yield Get( ExecuteProcessResult, ExecuteProcessRequest, requirements_pex_request", "label": 0}, {"snippet_id": 76177, "code": "(i, m, t, wzauth_data.set_route_type[i, m])) def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug('Route %s,%s was not bound', i, m) return self.log.debug('Unbinding route ", "label": 0}, {"snippet_id": 40887, "code": " wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path", "label": 0}, {"snippet_id": 89114, "code": " targets they depend on that satisfy the on_predicate. :API: public \"\"\" core=set(self.targets(on_predicate)) dependees=defaultdict(set) for target in self.targets(from_predicate): for dependency in target", "label": 0}, {"snippet_id": 76288, "code": " self.bind_route(i, m, f) def unbind_methods(self): for i, m, f, t in self.wz_bind_methods: self.unbind_route(i, m) def send_rep(self, reqid, seqnum, status, data): self.wz_sock.send_multipart( self.wz", "label": 0}, {"snippet_id": 62738, "code": " XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs", "label": 0}, {"snippet_id": 69346, "code": " self.action=action assert isinstance(nodes, NodeSet) self.nodes=nodes self.debug=debug self.targets_type=targets_type self.targets_indexes=targets_indexes if self.fs.debug: print \"FSProxyAction %s on ", "label": 0}, {"snippet_id": 83969, "code": ".id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)) else: lwr_url=job.job_runner_name job_id=job.job_runner_external_id log.debug(", "label": 0}, {"snippet_id": 78634, "code": ": 'exporter', 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run()))", "label": 0}, {"snippet_id": 8364, "code": " list\"\"\" try: if is_pdf(document): if not executable_exists(\"pdftotext\"): log.error(\"pdftotext is not available on the system.\") cmd=\"pdftotext -q -enc UTF-8 %s -\" % re.escape(document) filestream=os.popen", "label": 0}, {"snippet_id": 21029, "code": ".contextmanager def _wait_for_message(self, match, handlername, timeout=None): if timeout is None: timeout=self.TIMEOUT lock, wait=get_locked_and_waiter() def handler(msg): if not match(msg): return msg, False", "label": 0}, {"snippet_id": 8343, "code": " local file. @var document: fullpath to the file that should be read @var remote: boolean, if True does not count lines(gosh!) @return: list of lines if st was read or an empty list\"\"\" try: if is_pdf(document", "label": 1}, {"snippet_id": 89241, "code": "\"Executes a process(possibly remotely), and returns information about its output. :param execute_process_request: The ExecuteProcessRequest to run. :param name: A descriptive name representing the process", "label": 0}, {"snippet_id": 1640, "code": " True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\", None]: output=\"User '%s' has no password set\" % username", "label": 0}, {"snippet_id": 51632, "code": "*wildcards --the wildcards as keyword arguments with their values as lists \"\"\" return pattern.format(**{ wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items", "label": 0}, {"snippet_id": 52378, "code": ".rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not self.dynamic_output: for o in self.output: self._hash ^=o.__hash__() @property def priority(self): return self.dag.priority(self", "label": 0}, {"snippet_id": 8279, "code": ".warning(\"GNU file was not found on the system. \" \"Switching to a weak file extension test.\") if document.lower().endswith(\".pdf\"): return True return False file_output=os.popen('file ' +re.escape(document)", "label": 0}, {"snippet_id": 18010, "code": "=FuturesSession( executor=_EXECUTOR) server_location='http://localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn(", "label": 0}, {"snippet_id": 61354, "code": " the Fock space truncation. Must be specified before applying a qfunc. hbar(float): the convention chosen in the canonical commutation relation[x, p]=i hbar. The default value is hbar=2. \"\"\" name='Default", "label": 0}, {"snippet_id": 95752, "code": "=path_leaf(path_temp_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.move(path_temp_str, path_vcf_str) remove_directory_tree(temp_dir) pathlist_vcf_input=pathlib.Path(input_dir).glob(\"**/", "label": 0}, {"snippet_id": 48455, "code": "._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance", "label": 0}, {"snippet_id": 26560, "code": "'Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self._state=data['Noise'] elif self.type=='co2", "label": 0}, {"snippet_id": 36753, "code": ".rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern,", "label": 0}, {"snippet_id": 56818, "code": " :param tag_name: The name of the tag to be manipulated :type tag_name: str \"\"\" self.obj=obj self.tag_name=tag_name def add(self): tag, _=Tag.objects.get_or_create(name=self.tag_name) self.obj.add_tag(tag", "label": 0}, {"snippet_id": 28352, "code": "): _LOGGER.error('Module name: \"%s\" not found', module_name) continue for variable in monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names", "label": 1}, {"snippet_id": 94110, "code": ".check_mode=check_mode self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.config=None self.session=None if kill_mode: self.logger.info(\"started slave with kill mode\") if check_mode", "label": 0}, {"snippet_id": 19198, "code": " return response=normalize_response(raw_response, raw_request) try: validate_response( response=response, request_method=request.method, schema=schema ) except ValidationError as err: errors['response']", "label": 0}, {"snippet_id": 74248, "code": "\"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config", "label": 0}, {"snippet_id": 40778, "code": " comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards)", "label": 0}, {"snippet_id": 39288, "code": ")) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code, linemap=parse(snakefile, overwrite_shellcmd=self.overwrite_shellcmd", "label": 0}, {"snippet_id": 60413, "code": " var=self.state.quad_expectation(reg, 0) elif self._observe.name=='P': ex, var=self.state.quad_expectation(reg, np.pi/2) elif self._observe.name=='Homodyne': ex, var=self.state.quad_expectation(reg, *self", "label": 0}, {"snippet_id": 75024, "code": " with open(output_location, 'wb') as output_file: output_file.write(default_config_file_data) if os.path.exists(output_location): print(\"[Config] Configuration file has been generated successfully.\") else:", "label": 0}, {"snippet_id": 40147, "code": " in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise", "label": 1}, {"snippet_id": 14034, "code": " query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ 'filetypes': vimsupport.CurrentFiletypes(), 'line_num", "label": 0}, {"snippet_id": 1771, "code": "() print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append", "label": 0}, {"snippet_id": 11940, "code": "-line-length\": 79, \"count\": False, \"first\": False, \"show-pep8\": False, \"filename\":[], \"exclude\":[], \"select\":[], \"show-source\": False, \"statistics\": False, \"hang-closing\": False, }, \"no_blank_comment\":", "label": 0}, {"snippet_id": 27638, "code": " self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp']", "label": 0}, {"snippet_id": 14988, "code": " requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if method=='GET': return requests.get( _BuildUri( handler), headers=_HEADERS) if not _CheckServerIsHealthyWithCache(): return", "label": 0}, {"snippet_id": 78418, "code": " except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10) except exc.UnknownAnswer as e: self.log.warning('%s: %s', e, e.answer) self.w.sleep(self.errortimeout) except", "label": 0}, {"snippet_id": 54251, "code": " concrete ones. Arguments wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match", "label": 0}, {"snippet_id": 68510, "code": ")\" % c_ign) if c_offline > 0: status.append(\"offline(%d)\" % c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted", "label": 0}, {"snippet_id": 6764, "code": ".cut_references(text_lines) fulltext=normalizer.normalize_fulltext(\"\\n\".join(text_lines)) if match_mode==\"partial\": fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords", "label": 0}, {"snippet_id": 11448, "code": " detected for host name %r\" raise Exception(msg % hostname) return name def generate(self): file_name=None raw_yaml_config, header_source=read_config(self.source) if raw_yaml_config is None: raise SystemExit", "label": 0}, {"snippet_id": 38545, "code": ", dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall=False, forcerun=None, prioritytargets=None, quiet=False, keepgoing=False, printshellcmds=False, printreason=False", "label": 0}, {"snippet_id": 77305, "code": "'): self.init_th_sock() if not hasattr(self, 'th_back_sock'): self.init_th_back_sock() elif issubclass(wclass, workers.WZWorkerProcess): type_=1 if not hasattr(self, 'pr_sock'): self.init_pr_sock() if not", "label": 0}, {"snippet_id": 66294, "code": " AsciiTableLayout.RIGHT, \"journal device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"type\", i, AsciiTableLayout.LEFT, \"type\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"index\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 34708, "code": "(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for", "label": 0}, {"snippet_id": 74521, "code": "\"] if \"username\" in runtime_config.ftp: self.username=runtime_config.ftp[\"username\"] if \"password\" in runtime_config.ftp: self.password=runtime_config.ftp[\"password\"] if \"use_tls\" in runtime_config.ftp", "label": 0}, {"snippet_id": 69484, "code": ".cmd_list) def __iter__(self): \"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self", "label": 0}, {"snippet_id": 7234, "code": ") def _output_marc(output_complete, categories, kw_field=bconfig.CFG_MAIN_FIELD, auth_field=bconfig.CFG_AUTH_FIELD, acro_field=bconfig.CFG_ACRON_FIELD, provenience='BibClassify'): \"\"\"Output the keywords", "label": 0}, {"snippet_id": 75222, "code": ".req_handlers[(interface, method)]=fun def set_response_handler(self, reqid, fun): self.response_handlers[reqid]=fun def set_sig_handler(self, interface, method, fun): self.sig_handlers[(interface, method", "label": 0}, {"snippet_id": 1738, "code": ") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall() print(rows) return JsonResponse(rows, safe=False) elif action=='getDashboardChart': print(action) con=sqlite3.connect", "label": 0}, {"snippet_id": 20937, "code": " warnings.warn('session listener still running') self._check_handlers() def _listen(self): try: for msg in self._conn.iter_messages(): if self.VERBOSE: print(' ->', msg) self._receive_message(msg) except", "label": 1}, {"snippet_id": 74686, "code": "\"auto\\\" or integer value\") if \"chunk_length\" in runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint", "label": 0}, {"snippet_id": 46189, "code": "*comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, ", "label": 0}, {"snippet_id": 71484, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_stopclient_start(self, node, client): if self.verbose > 1: print \"%s: Unmounting %s on %s...\" %(node, client", "label": 0}, {"snippet_id": 57557, "code": "._update_objects def get_plan(self, pk_enough=True): try: return plan_from_request_or_none(self.request, pk_enough) except Http404: return None def _sendmail(self): mail_context=TestCase.mail_scene(objects", "label": 0}, {"snippet_id": 89454, "code": " API, its not reasonably useful with no methods exposed. Expose reasonable methods: https://github.com/pantsbuild/pants/issues/3263 \"\"\" class Error(Exception): \"\"\"Indicates an invalid java distribution.\"\"", "label": 0}, {"snippet_id": 7919, "code": " for c in ckw.getComponents(): if c.core: output[c.output(spires)]=info[1][i] i +=1 return output def _filter_core_keywors(keywords): matches={} for kw, info in keywords.items(): if kw.core: matches[kw", "label": 0}, {"snippet_id": 29276, "code": " len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat", "label": 0}, {"snippet_id": 30051, "code": " _wildcard_regex.finditer(pattern)] Wildcards=namedtuple(\"Wildcards\", names) wildcards=Wildcards(*[list() for name in names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk", "label": 0}, {"snippet_id": 9139, "code": "\"Returns a list of composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to", "label": 0}, {"snippet_id": 31342, "code": " return self._hash @staticmethod def expand_dynamic(pattern, restriction=None, omit_value=None): \"\"\" Expand dynamic files. \"\"\" return list(listfiles(pattern, restriction=restriction, omit_value=omit_value)", "label": 0}, {"snippet_id": 85786, "code": "._zinc_factory.options_scope) def compile_classpath_entries(self, classpath_product_key, target, extra_cp_entries=None): classpath_product=self._products.get_data(classpath_product_key) if DependencyContext", "label": 0}, {"snippet_id": 28274, "code": " None], 'rf_status':['Radio', '', 'mdi:signal', None], 'rf_status_lvl':['Radio_lvl', '', 'mdi:signal', None], 'wifi_status':['Wifi', '', 'mdi:wifi', None], 'wifi_status_lvl':['Wifi_lvl', 'dBm', 'mdi:wifi',", "label": 1}, {"snippet_id": 92511, "code": "), os.getcwd()) self.assertEqual(os.path.realpath(tempdir1), os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) self.assertEqual(pre_cwd, os.getcwd()) def test_temporary_file_no_args(self): with temporary_file", "label": 0}, {"snippet_id": 22088, "code": " self.loader=dataloader.DataLoader() self.variable_manager=vars.VariableManager() self.inventory=inventory.Inventory( loader=self.loader, variable_manager=self.variable_manager, host_list='/etc/ansible", "label": 0}, {"snippet_id": 91155, "code": ".python.python_requirements import PythonRequirements from pants.backend.python.rules import inject_init, python_test_runner from pants.backend.python.targets.python_app import PythonApp from pants.backend", "label": 0}, {"snippet_id": 38611, "code": " wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False, allowed_rules=None, greediness=1.0", "label": 0}, {"snippet_id": 32626, "code": ") if not bestmatch or bestmatchlen > l: bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments", "label": 0}, {"snippet_id": 11244, "code": "-checks][URL] monconfgenerator -h Options: -h Show this message. --debug Print additional information. --targetdir=DIR The generated Icinga monitoring configuration is written into this directory. If no", "label": 0}, {"snippet_id": 53908, "code": ": try: start=len(self.log) for i in item: self._set_log_item(i) if name: self.log.set_name(name, start, end=len(self.log)) except TypeError: raise SyntaxError(\"Log files have to be specified as strings", "label": 0}, {"snippet_id": 39596, "code": ": ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, ", "label": 0}, {"snippet_id": 87694, "code": "(analysis_cache,), output_directories=(classes_dir,), description=\"zinc compile for{}\".format(ctx.target.address.spec), jdk_home=text_type(self._zinc.dist.home), ) res=self.context.execute_process_synchronously(req", "label": 1}, {"snippet_id": 16722, "code": "}\\n {1}'.format( self._server_stdout, self._server_stderr) return debug_info def CurrentFiletypeCompletionEnabled( self): filetypes=vimsupport.CurrentFiletypes() filetype_to_disable=self._user_options[", "label": 0}, {"snippet_id": 79726, "code": ") parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument", "label": 0}, {"snippet_id": 74658, "code": "]) if \"alt_number\" in runtime_config.vcf_to_zarr: alt_number_str=runtime_config.vcf_to_zarr[\"alt_number\"] if str(alt_number_str).lower()==\"auto\": self.alt_number=None elif isint(alt_number_str): self.alt_number", "label": 0}, {"snippet_id": 55520, "code": " logger.info(\"Multiple include of{} ignored\".format(snakefile)) return self.included.append(snakefile) self.included_stack.append(snakefile) global workflow workflow=self first_rule=self.first_rule code,", "label": 0}, {"snippet_id": 27500, "code": " any.\"\"\" return self._unit_of_measurement def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name", "label": 0}, {"snippet_id": 23197, "code": ".architecture()[0] if python_arc=='64bit': struct_size=40 else: struct_size=32 sock=socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)", "label": 0}, {"snippet_id": 67805, "code": ".fs_support.iter_fsname(): eh=self.install_eventhandler(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes", "label": 0}, {"snippet_id": 70702, "code": "(status_flags) if RUNTIME_ERROR in statusdict: defect_targets=statusdict[RUNTIME_ERROR] for nodes, msg in fs.proxy_errors: print nodes print '-' * 15 print msg print else: defect_targets=[] rc=self.fs_status_to_rc", "label": 0}, {"snippet_id": 27051, "code": ".\"\"\" def __init__(self, auth, station): \"\"\"Initialize the data object.\"\"\" self.auth=auth self.data=None self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available", "label": 0}, {"snippet_id": 14684, "code": " 'message']) except ServerError as e: vimsupport.PostVimMessage( str( e)) def DebugInfo( self): if self._IsServerAlive(): debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else", "label": 0}, {"snippet_id": 68357, "code": ", show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes=NodeSet() t_offline=[] t_error=[] t_recovering=[] t_online=[] t_runtime=[] t_unknown", "label": 0}, {"snippet_id": 29875, "code": "*wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools", "label": 0}, {"snippet_id": 84093, "code": " job_wrapper) client_outputs=ClientOutputs( working_directory=job_wrapper.working_directory, work_dir_outputs=work_dir_outputs, output_files=output_files, version_file=job_wrapper.get_version_string_path()", "label": 0}, {"snippet_id": 30375, "code": "(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass", "label": 0}, {"snippet_id": 41187, "code": ": try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist", "label": 0}, {"snippet_id": 42968, "code": " be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item", "label": 0}, {"snippet_id": 9931, "code": " formatted keywords \"\"\" output={} for composite_keyword, info in ckw_matches: output[composite_keyword.output(spires)]={\"numbers\": len(info[0]), \"details\": info[1]} return output def _get_acronyms(acronyms): ", "label": 0}, {"snippet_id": 41726, "code": "\"\" Return all wildcard values determined from dynamic output. \"\"\" combinations=set() for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: for f, w in self.expand_dynamic( f_, restriction", "label": 0}, {"snippet_id": 5674, "code": "\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a clean copy of the keywords data structure. Stripped off the standalone", "label": 0}, {"snippet_id": 79837, "code": ".add_argument(\"-r\",\"--regex-override\",metavar=\"regex\",nargs=1,dest=\"regexOverride\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the", "label": 0}, {"snippet_id": 66172, "code": " jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled=True tag=target.tag else: tag=\"\" flags=[] if target.has_need_index_flag(): flags.append(\"need_index\") if target.has_first_time_flag", "label": 0}, {"snippet_id": 8688, "code": " text_extractor as extractor import text_normalizer as normalizer import keyword_analyzer as keyworder import acronym_analyzer as acronymer from invenio.utils.url import make_user_agent_string from invenio", "label": 1}, {"snippet_id": 24516, "code": " from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self", "label": 0}, {"snippet_id": 47759, "code": "-the name of the rule \"\"\" if len(args)==2: name, workflow=args self.name=name self.workflow=workflow self.docstring=None self.message=None self._input=InputFiles() self._output=OutputFiles() self._params", "label": 0}, {"snippet_id": 26598, "code": ") elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self", "label": 0}, {"snippet_id": 24523, "code": "() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state", "label": 0}, {"snippet_id": 66220, "code": ".has_param_flag(): flags.append(\"conf_param\") ldic.append(target_dict([\\ [\"nodes\", NodeSet.fromlist(target.servers)], [\"dev\", target.dev], [\"size\", dev_size], [\"jdev\", jdev], [\"type\", target.type.upper()], [\"index", "label": 0}, {"snippet_id": 8455, "code": " words.\" %(line_nb, word_nb)) return lines def _is_english_text(text): \"\"\" Checks if a text is correct english. Computes the number of words in the text and compares it to the expected number of words(based", "label": 1}, {"snippet_id": 31948, "code": " output files.\") wildcards=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self", "label": 0}, {"snippet_id": 10497, "code": " file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else", "label": 1}, {"snippet_id": 12302, "code": "(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(repository, after_commit_hash, file) os.remove(", "label": 0}, {"snippet_id": 48283, "code": ".protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\")", "label": 0}, {"snippet_id": 45165, "code": " return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator(f): return f class", "label": 0}, {"snippet_id": 73719, "code": " \"\"\" def __init__(self, file_name): \"\"\" Initializes the configuration representation with a supplied file. \"\"\" parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise", "label": 0}, {"snippet_id": 32869, "code": "=OrderedDict() self.first_rule=None self._workdir=None self.overwrite_workdir=overwrite_workdir self.workdir_init=os.path.abspath(os.curdir) self._ruleorder=Ruleorder() self._localrules=set() self.linemaps", "label": 0}, {"snippet_id": 30286, "code": " item[1][0]): start, end=index if end is None: end=start +1 if start > next: for item in self[next:start]: yield None, item yield name, getattr(self, name) next=end for item in self[next:]: yield None,", "label": 0}, {"snippet_id": 1333, "code": "+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print", "label": 1}, {"snippet_id": 4644, "code": "(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" acronyms={} K=reader", "label": 0}, {"snippet_id": 76852, "code": " c.router_addr=d.addrs['rpcrouter'] noproxy_rp.useragent=random.choice(d.ua_list) def terminate(): logger.info('Shutdown initiated') send_to_wm([b'GLOBAL', b'WZWorker', b'terminate']) for t in threading", "label": 0}, {"snippet_id": 48638, "code": " newitems.set_name( name, start, end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise", "label": 0}, {"snippet_id": 71908, "code": "(self): \"\"\" Launch FS proxy command. \"\"\" command=[\"%s\" % self.progpath] command.append(self.action) command.append(\"-f %s\" % self.fs.fs_name) command.append(\"-R\") if self.debug: command.append(\"-d\") if", "label": 0}, {"snippet_id": 48522, "code": "=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f", "label": 0}, {"snippet_id": 90368, "code": " raise ValueError('Expected at least 1 java dist dir.') self._java_dist_dirs=java_dist_dirs @property def jvm_locations(self): for java_dist_dir in self._java_dist_dirs: if os.path.isdir(java_dist_dir): for", "label": 0}, {"snippet_id": 6389, "code": " the moment the pieces of the representation code are left in this module. \"\"\" from __future__ import print_function import os from six import iteritems import config as bconfig from invenio.legacy.bibclassify", "label": 0}, {"snippet_id": 81620, "code": " !=True: \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1;32m\\tTrue regex matched the following information: %s\\033[m\",uploadRes) \t\t\tif codeExecRegex and valid_regex(codeExecRegex) and(self.uploadsFolder", "label": 0}, {"snippet_id": 93757, "code": " or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start\" % comp['name']) else: self.start_component_without_deps(comp) return True def start_component_without_deps", "label": 0}, {"snippet_id": 32229, "code": "(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item)", "label": 0}, {"snippet_id": 83183, "code": " the job runner \"\"\" super( LwrJobRunner, self).__init__( app, nworkers) self.async_status_updates=dict() self._init_monitor_thread() self._init_worker_threads() client_manager_kwargs={'transport_type':", "label": 0}, {"snippet_id": 2297, "code": ", 'reqtype': 'editwifi', 'endpoint': wifi_name}], safe=False) return JsonResponse(serializer.errors, status=400) def index(request): return render(request, 'index.html') class BoxDetailsViewSet(viewsets", "label": 0}, {"snippet_id": 62659, "code": ": \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator", "label": 0}, {"snippet_id": 15656, "code": ".DiagnosticsForCurrentFileReady(): return self._diag_interface.UpdateWithNewDiagnostics( self.GetDiagnosticsFromStoredRequest()) def ShowDetailedDiagnostic( self): if not self._IsServerAlive(): return try:", "label": 0}, {"snippet_id": 75152, "code": ".p.log.warn('Keepalive status{0}'. format(wzrpc.name_status(status))) def __call__(self, parent): self.p=parent self.p.wz_connect() self.p.wz_auth_requests=[ (b'Router', b'auth-bind-route'), (b'Router',", "label": 0}, {"snippet_id": 38608, "code": " benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp=False, nodeps=False, cleanup_metadata=None, subsnakemake=None, updated_files=None, keep_target_files=False,", "label": 0}, {"snippet_id": 93891, "code": ".get(comp['name']) res=[] unres=[] dep_resolve(node, res, unres) res.remove(node) return res def is_localhost(self, hostname): try: hn_out=socket.gethostbyname(hostname) if hn_out=='127.0.0.1' or hn_out", "label": 0}, {"snippet_id": 55941, "code": " decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority return ruleinfo return decorate def version(self, version): def decorate(ruleinfo): ruleinfo.version=version return", "label": 0}, {"snippet_id": 57362, "code": "(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if hasattr(model, 'mail_scene'): from tcms.core.utils.mailto import mailto mail_context=model.mail_scene( objects=targets", "label": 0}, {"snippet_id": 84725, "code": " exec_result=self.context.execute_process_synchronously(req, 'cloc',(WorkUnitLabel.TOOL,)) files_content_tuple=self.context._scheduler.product_request( FilesContent, [exec_result.output_directory_digest] )[0", "label": 1}, {"snippet_id": 67661, "code": " LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s ", "label": 0}, {"snippet_id": 37925, "code": " params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:\\n{", "label": 0}, {"snippet_id": 42009, "code": ".remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input", "label": 0}, {"snippet_id": 82844, "code": "=datetime.datetime.now() print(\"Extensions detection: \"+str(b-a)) cont=input(\"Start uploading payloads ?[Y/n]: \") up.shouldLog=True if cont.lower().startswith(\"y\") or cont==\"\": \tpass else: \texit(\"Exiting.", "label": 0}, {"snippet_id": 43055, "code": "(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable(item): self.log.append(IOFile(item, rule=self) if isinstance(item, str) else item)", "label": 0}, {"snippet_id": 40029, "code": ".\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return lstat(self.file", "label": 1}, {"snippet_id": 31092, "code": "\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of", "label": 0}, {"snippet_id": 66347, "code": "\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout.LEFT, \"status\", AsciiTableLayout.CENTER) AsciiTable().print_from_list_of_dict", "label": 0}, {"snippet_id": 64670, "code": ".FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1)", "label": 0}, {"snippet_id": 5516, "code": ", set()).add(skw.output(spires)) for ckw, _ in ckw_matches: if len(ckw.fieldcodes): for fieldcode in ckw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add(ckw.output(spires)) else: for kw in ckw.getComponents", "label": 0}, {"snippet_id": 6703, "code": " beginning of the fulltext is searched. :param no_cache: boolean, means loaded definitions will not be saved. :param with_author_keywords: boolean, extract keywords from the pdfs. :param rebuild_cache: boolean", "label": 0}, {"snippet_id": 53027, "code": " self.incomplete_output=set() self.forced=False self.noio=False self.nooutput=False self.derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(", "label": 0}, {"snippet_id": 81070, "code": "),e) \t\t\t\texit() \t\t \t\tdetectedForms=detectForms(initGet.text) \t\tif len(detectedForms)==0: \t\t\tself.logger.critical(\"No HTML form found here\") \t\t\texit() \t\tif len(detectedForms) > 1: \t\t\tself.logger.critical", "label": 0}, {"snippet_id": 18364, "code": "[ 'server_keep_logfiles']: args.append('--keep_logfiles') self._server_popen=utils.SafePopen( args, stdout=PIPE, stderr=PIPE) BaseRequest.server_location='http://localhost:' +str( server_port) self._NotifyUserIfServerCrashed", "label": 0}, {"snippet_id": 84449, "code": " input_paths( self): local_input_paths=self._wrapper_input_paths results=[] for local_input_path in local_input_paths: wrapper_path=str( local_input_path) remote_path=self.path_mapper.remote_input_path_rewrite", "label": 0}, {"snippet_id": 28100, "code": " details about this platform, please refer to the documentation at https://home-assistant.io/components/sensor.netatmo/ \"\"\" import logging from datetime import timedelta import voluptuous as vol from homeassistant", "label": 1}, {"snippet_id": 30232, "code": ") pairs. \"\"\" for name, index in self._names.items(): yield name, index def take_names(self, names): \"\"\" Take over the given names. Arguments names --the given names as(name, index) pairs \"\"\" for name,(i", "label": 0}, {"snippet_id": 50132, "code": " overwrite_shellcmd=self.overwrite_shellcmd) if print_compilation: print(code) sys.path.insert(0, os.path.dirname(snakefile)) self.linemaps[snakefile]=linemap exec(compile(code, snakefile, \"exec\"), self.globals) if not", "label": 0}, {"snippet_id": 21720, "code": " set)') plt.xlabel('Age') plt.ylabel('Estimated Salary') plt.legend() plt.show() from matplotlib.colors import ListedColormap X_set, y_set=X_test, y_test X1, X2=np.meshgrid(np.arange(start=X_set[:, 0].min", "label": 0}, {"snippet_id": 78233, "code": " self.dologin() def comment_loop(self): for t in self.targets: self.schedule(self.add_comment,(t, self.msgfun())) if len(self.targets)==0: self.schedule(self.scan_targets_loop) else: self.schedule(self", "label": 0}, {"snippet_id": 74290, "code": " generate_default_config_file(output_location, overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None", "label": 0}, {"snippet_id": 39805, "code": " __init__(self, workflow, name, snakefile, workdir): self.workflow=workflow self.name=name self._snakefile=snakefile self._workdir=workdir @property def snakefile(self): if self._snakefile is None: return os", "label": 0}, {"snippet_id": 84231, "code": " will contain all the datatypes available to this Galaxy. \"\"\" use_remote_datatypes=string_as_bool_or_none( lwr_client.destination_params.get( \"use_remote_datatypes\", False)) return use_remote_datatypes", "label": 0}, {"snippet_id": 33121, "code": "(resource) def is_local(self, rule): return rule.name in self._localrules or rule.norun def execute(self, targets=None, dryrun=False, touch=False, cores=1, nodes=1, local_cores=1, forcetargets=False, forceall", "label": 0}, {"snippet_id": 20989, "code": " break self._received.append(msg) def _add_handler(self, handle_msg, handlername=None, required=True): self._handlers.append( (handle_msg, handlername, required)) def _check_handlers(self): unhandled=[]", "label": 0}, {"snippet_id": 19783, "code": " Address from ptvsd._util import new_hidden_thread, Closeable, ClosedError from.debugadapter import DebugAdapter, wait_for_socket_server from.debugsession import DebugSession class _LifecycleClient(Closeable)", "label": 0}, {"snippet_id": 95147, "code": ".VCFtoZarrConfigurationRepresentation(runtime_config) if vcf_to_zarr_config.enabled: data_service.setup_vcf_to_zarr(input_vcf_dir=vcf_directory, output_zarr_dir=zarr_directory_setup, conversion_config=vcf_to_zarr_config) elif command", "label": 1}, {"snippet_id": 46376, "code": " dict that shall be converted to a Namedlist(keys become names) \"\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist", "label": 0}, {"snippet_id": 71857, "code": "* from ClusterShell.NodeSet import NodeSet class FSProxyAction(ProxyAction): \"\"\" Generic file system command proxy action class. \"\"\" def __init__(self, fs, action, nodes, debug, targets_type=None, targets_indexes", "label": 0}, {"snippet_id": 80777, "code": "(extensions,legitExt) \t\t\t\tmime=legitMime if t[\"mime\"]==\"legit\" else nastyMime \t\t\t\tsuffix=t[\"suffix\"].replace(\"$legitExt$\",legitExt).replace(\"$nastyExt$\",nastyVariant) \t\t\t\tattempts.append({\"suffix\":suffix,\"mime", "label": 1}, {"snippet_id": 66979, "code": " isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string[i] if c==':': continue has_arg=not(i==opt_len ", "label": 0}, {"snippet_id": 68966, "code": " client.fs.fs_name, client.mount_path) def ev_stopclient_done(self, node, client): if self.verbose > 1: if client.status_info: print \"%s: Umount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully", "label": 1}, {"snippet_id": 13735, "code": " __init__(self, safe_globals=_safe_globals, safe_locals=_safe_locals): self.globals=safe_globals.copy() self.globals.update(safe_locals) self.locals={} def __setitem__(self, key, value): self.locals[key", "label": 0}, {"snippet_id": 38118, "code": "*rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames)) def compare(self, rule1, rule2): \"\"\" Return whether rule2 has a higher priority than rule1. ", "label": 0}, {"snippet_id": 70855, "code": " AsciiTableLayout.CENTER) layout.set_column(\"index\", 2, AsciiTableLayout.RIGHT, \"idx\", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(", "label": 0}, {"snippet_id": 44450, "code": " list_version_changes: items=list( chain(*map(self.persistence.version_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_code_changes: items=list(chain(*map(self.persistence.code_changed,", "label": 0}, {"snippet_id": 89472, "code": "\" @staticmethod def _is_executable(path): return os.path.isfile(path) and os.access(path, os.X_OK) def __init__(self, home_path=None, bin_path=None, minimum_version=None, maximum_version=None, jdk=False", "label": 0}, {"snippet_id": 27200, "code": "'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', ", "label": 0}, {"snippet_id": 49844, "code": " return True elif summary: print(\"\\n\".join(dag.summary(detailed=False))) return True elif detailed_summary: print(\"\\n\".join(dag.summary(detailed=True))) return True elif list_version_changes: items=list", "label": 0}, {"snippet_id": 87601, "code": " arg in zinc_args: fp.write(arg) fp.write(b'\\n') if self.execution_strategy==self.HERMETIC: zinc_relpath=fast_relpath(self._zinc.zinc, get_buildroot()) snapshots=[ self._zinc.snapshot(self.context._scheduler", "label": 0}, {"snippet_id": 14824, "code": ": dir_of_current_script=os.path.dirname( os.path.abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA:", "label": 0}, {"snippet_id": 21445, "code": "% sr_dir) os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump", "label": 0}, {"snippet_id": 85183, "code": " using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not specified, then the version specified in ' '--scala-suffix-version is used. For example", "label": 0}, {"snippet_id": 72367, "code": ".account='' @utils.add_cmd def reloadproto(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network", "label": 0}, {"snippet_id": 41748, "code": ".dynamic_fill): combinations.add(tuple(w.items())) wildcards=defaultdict(list) for combination in combinations: for name, value in combination: wildcards[name].append(value) return wildcards @property def", "label": 0}, {"snippet_id": 30327, "code": "._names.items(): if i > index: self._names[name]=(i +add, j +add) elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__", "label": 0}, {"snippet_id": 89046, "code": " returned. :param bool postorder: `True` to gather transitive dependencies with a postorder traversal; `False` or preorder by default. :returns: A list of matching targets. \"\"\" target_set=self._collect_targets", "label": 0}, {"snippet_id": 11070, "code": ") raise MonitoringConfigGeneratorException(msg) return yaml_config, Header(etag=etag, mtime=mtime) class Header(object): MON_CONF_GEN_COMMENT=' ETAG_COMMENT=' MTIME_COMMMENT=' def __init__(self, etag=None", "label": 0}, {"snippet_id": 15502, "code": "._IsServerAlive(): return SendCommandRequest( arguments, completer) def GetDefinedSubcommands( self): if self._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands')", "label": 0}, {"snippet_id": 18117, "code": " data[ 'exception'][ 'TYPE']==UnknownExtraConf.__name__: raise UnknownExtraConf( data[ 'exception'][ 'extra_conf_file']) raise ServerError( '{0}:{1}'.format( data[ 'exception'][ 'TYPE'], data[ 'message'", "label": 0}, {"snippet_id": 472, "code": "\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\", \"\",", "label": 0}, {"snippet_id": 10957, "code": ".getmtime(path) return yaml_config, Header(etag=etag, mtime=mtime) def read_config_from_host(url): try: response=requests.get(url) except socket.error as e: msg=\"Could not open socket for '%s', error: ", "label": 0}, {"snippet_id": 22350, "code": " the DVD mounting call). This ensures that the rest of the provisioning does not need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError", "label": 0}, {"snippet_id": 65757, "code": "\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"target\", 0, AsciiTableLayout.LEFT, \"target id\", AsciiTableLayout.CENTER) layout.set_column(\"type\", 1", "label": 0}, {"snippet_id": 55683, "code": " ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if not isinstance(ruleinfo", "label": 0}, {"snippet_id": 53739, "code": "\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified", "label": 0}, {"snippet_id": 65405, "code": " RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine.Lustre.Disk import", "label": 0}, {"snippet_id": 87007, "code": "(BaseZincCompile, cls).prepare(options, round_manager) ScalaPlatform.prepare_tools(round_manager) @property def incremental(self): \"\"\"Zinc implements incremental compilation. Setting this property causes the", "label": 0}, {"snippet_id": 24602, "code": ") elif self.type=='battery_lvl': self._state=data['battery_vp'] elif self.type=='battery_vp' and self.module_id=='6': if data['battery_vp'] >=5590: self._state=\"Full\" elif data['battery_vp'] >=5180: self", "label": 0}, {"snippet_id": 67212, "code": " open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def", "label": 0}, {"snippet_id": 1381, "code": " nmcli connection delete id <connection name> \"\"\" ps=subprocess.Popen(['nmcli', 'connection','delete','id',wifiap], stdout=subprocess.PIPE) print(ps) def edit_WifiConn(wifiname, wifipass): ps=subprocess", "label": 0}, {"snippet_id": 43716, "code": "=dict() self.rule_count=0 self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript", "label": 0}, {"snippet_id": 77496, "code": ".log.info('Initializing Evaluator') from evproxy import EvaluatorProxy def ev_init(): from lib.evaluators.PyQt4Evaluator import Evaluator return Evaluator() return self.spawn_nworkers(1, EvaluatorProxy", "label": 0}, {"snippet_id": 10864, "code": "%d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if os", "label": 1}, {"snippet_id": 29989, "code": " wildcard: \"{{{},{}}}\".format(wildcard, \"|\".join(values)) for wildcard, values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the", "label": 0}, {"snippet_id": 1207, "code": " import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager wlans=[d for d in nm.Devices if isinstance(d, NetworkManager.Wireless)] def get_osversion(", "label": 1}, {"snippet_id": 60655, "code": ".wires] else: op |[q[i] for i in operation.wires] self.state=self.eng.run('gaussian') reg=self._observe.wires if self._observe.name=='Fock': ex=self.state.mean_photon(reg) var=0 elif self._observe.name", "label": 0}, {"snippet_id": 37687, "code": " have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if", "label": 0}, {"snippet_id": 47202, "code": " file. \"\"\" existing=[f.mtime for f in self.expanded_output if f.exists] if self.benchmark and self.benchmark.exists: existing.append(self.benchmark.mtime) if existing: return min(existing) return None @property", "label": 0}, {"snippet_id": 37752, "code": " InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.", "label": 0}, {"snippet_id": 95381, "code": ") for remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file", "label": 0}, {"snippet_id": 90209, "code": " from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent directory. :param string bin_path: The parent path of the `java` executable. :returns: The java distribution location. \"\"\"", "label": 0}, {"snippet_id": 2011, "code": " stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes[0].split()) -1 for p in processes[1:]: datasets.append(p.split(None, nfields)) data={'container_id': i[0]", "label": 0}, {"snippet_id": 90822, "code": "{}, ' 'maximum_version{}') raise self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a", "label": 0}, {"snippet_id": 48068, "code": "): return self._benchmark @benchmark.setter def benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput", "label": 0}, {"snippet_id": 1329, "code": " -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname", "label": 1}, {"snippet_id": 82553, "code": " the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\") if args", "label": 0}, {"snippet_id": 6106, "code": "-enc UTF-8 %s -\" % re.escape(document) filestream=os.popen(cmd) else: filestream=open(document, \"r\") except IOError as ex1: log.error(\"Unable to read from file %s.(%s)\" %(document, ex1.strerror)) return", "label": 0}, {"snippet_id": 73034, "code": "+remote_directory +\"/\" +remote_path_relative +\"/\" else: remote_subdirs_list=[] remote_path_relative=\"\" remote_path_absolute=\"/\" +remote_directory +\"/\" try: local_path=local_directory +\"/\" +remote_path_relative", "label": 0}, {"snippet_id": 37510, "code": ") if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name: inoutput.add_name(name) else: try:", "label": 0}, {"snippet_id": 61277, "code": "(array): square hermitian matrix. Returns: array: square hermitian matrix. \"\"\" A=np.asarray(args[0]) if A.shape[0] !=A.shape[1]: raise ValueError(\"Observable must be a square matrix.\") if not np.allclose(A,", "label": 0}, {"snippet_id": 36479, "code": " check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self): \"\"\" Prepare execution of job. This", "label": 0}, {"snippet_id": 17607, "code": " OnCurrentIdentifierFinished( self): if not self._IsServerAlive(): return SendEventNotificationAsync( 'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self", "label": 0}, {"snippet_id": 83862, "code": " os.kill( pid, 0) return True except OSError, e: if e.errno==errno.ESRCH: log.debug( \"check_pid(): PID %d is dead\" % pid) else: log.warning( \"check_pid(): Got errno %s when attempting to check PID %d: %s", "label": 0}, {"snippet_id": 66594, "code": " ModelFileException from Configuration.ModelFile import ModelFileIOError from Configuration.Exceptions import ConfigException from Commands.Exceptions import * from Commands.Base.CommandRCDefs import * from Lustre", "label": 0}, {"snippet_id": 28792, "code": " data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data", "label": 0}, {"snippet_id": 93342, "code": " Config not loaded yet!\") else: for group in self.config['groups']: for comp in group['components']: self.logger.debug(\"Checking component '%s' in group '%s' on host '%s'\" % (comp['name'], group['name'],", "label": 0}, {"snippet_id": 22025, "code": " self.become_ask_pass=become_ask_pass self.ask_pass=ask_pass self.private_key_file=private_key_file self.remote_user=remote_user self.connection=connection self.timeout=timeout self.ssh_common_args=ssh_common_args", "label": 0}, {"snippet_id": 48691, "code": " params=Params() _apply_wildcards(params, self.params, wildcards, wildcards_obj) output=OutputFiles(o.apply_wildcards(wildcards) for o in self.output) output.take_names(self.output.get_names()) dependencies", "label": 0}, {"snippet_id": 47022, "code": " def message(self): \"\"\" Return the message for this job. \"\"\" try: return(self.format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex", "label": 0}, {"snippet_id": 36411, "code": "] if existing: return max(existing) return None def missing_output(self, requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested", "label": 0}, {"snippet_id": 38671, "code": " not targets: targets=[self.first_rule ] if self.first_rule is not None else list() if prioritytargets is None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets", "label": 0}, {"snippet_id": 4713, "code": ",....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for k, v in keyworder.get_author_keywords(skw_db, ckw_db, fulltext).items(): akw[K(k, type='author-kw')]=v return akw def get_keywords_output(single_keywords", "label": 0}, {"snippet_id": 78149, "code": " send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name']) if c.no_shell: while True: time.sleep(1) else: try: import IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except", "label": 1}, {"snippet_id": 60783, "code": " class DeviceError(Exception): \"\"\"Exception raised by a:class:`Device` when it encounters an illegal operation in the quantum circuit. \"\"\" pass class Device(abc.ABC): \"\"\"Abstract base class for devices.\"", "label": 0}, {"snippet_id": 42971, "code": " @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item", "label": 0}, {"snippet_id": 11685, "code": "=EXIT_CODE_ERROR except SystemExit as e: exit_code=e.code except BaseException as e: LOG.error(e) exit_code=EXIT_CODE_ERROR finally: stop_time=datetime.now() LOG.info(\"finished in %s\" %(stop_time -start_time", "label": 0}, {"snippet_id": 55166, "code": " f in updated) else: logger.info(\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete", "label": 0}, {"snippet_id": 90728, "code": " have a jdk. :return: the located Distribution. :rtype::class:`Distribution` :raises::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" for location in itertools.chain(self", "label": 0}, {"snippet_id": 17546, "code": "._NotifyUserIfServerCrashed() extra_data={} self._AddTagsFilesIfNeeded( extra_data) self._AddSyntaxDataIfNeeded( extra_data) self._AddExtraConfDataIfNeeded( extra_data) self._latest_file_parse_request=EventNotification(", "label": 0}, {"snippet_id": 88457, "code": "=OwnerPrintingInterProcessFileLock(os.path.join(self._buildroot, '.pants.workdir.file_lock')) self._java_sysprops=None self.requested_goals=requested_goals or[] self._console_outstream=console_outstream or sys.stdout", "label": 0}, {"snippet_id": 85438, "code": ").register_options(register) zinc_rev='1.0.3' shader_rules=[ Shader.exclude_package('scala', recursive=True), Shader.exclude_package('xsbt', recursive=True), Shader.exclude_package('xsbti', recursive=True", "label": 0}, {"snippet_id": 43664, "code": " from snakemake.utils import update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None", "label": 0}, {"snippet_id": 23207, "code": "(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP) buff=array.array('B', b'\\0' *(expected * struct_size)) param=struct.pack('iL', expected*struct_size, buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno", "label": 0}, {"snippet_id": 55625, "code": ": self._ruleorder.add(*rulenames) def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules", "label": 0}, {"snippet_id": 16944, "code": " method, timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri", "label": 1}, {"snippet_id": 67382, "code": ".get_client_nodes(), fsname)) fs.set_debug(self.debug_support.has_debug()) status=fs.mount(mount_options=fs_conf.get_mount_options()) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK", "label": 1}, {"snippet_id": 78405, "code": ", topic_successtimeout +0.1, cur: %f', self.topic_successtimeout) self.w.sleep(self.topic_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.long_sleep(10", "label": 0}, {"snippet_id": 52466, "code": "\"Unknown variable in message \" \"of shell command:{}\".format(str(ex)), rule=self.rule) @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd)", "label": 0}, {"snippet_id": 15896, "code": " GetDataFromHandler( handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest._TalkToHandlerAsync( '', handler, 'GET', timeout)) @staticmethod def PostDataToHandler( data, handler, timeout", "label": 0}, {"snippet_id": 59336, "code": " Quantum Experience user name password(string): IBM Quantum Experience password device(string): Device to use(\u2018ibmqx4\u2019, or \u2018ibmqx5\u2019) if use_hardware is set to True. Default is ibmqx4. retrieve_execution(int)", "label": 0}, {"snippet_id": 82551, "code": " illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse or damage caused by this program \t\"\"\"", "label": 0}, {"snippet_id": 29899, "code": "**wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns", "label": 0}, {"snippet_id": 27712, "code": "._state=\"Low\" elif data['battery_vp'] < 4560: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000", "label": 0}, {"snippet_id": 29099, "code": ".harvard.edu\" __license__=\"MIT\" import os import re import stat import time import json from itertools import product, chain from collections import Iterable, namedtuple from snakemake.exceptions import", "label": 1}, {"snippet_id": 85628, "code": "\"Return the distribution selected for Zinc. :rtype: list of str \"\"\" return self._zinc_factory.dist @memoized_property def compiler_bridge(self): \"\"\"Return the path to the Zinc compiler-bridge jar. :rtype", "label": 0}, {"snippet_id": 51963, "code": " for item in self[next:]: yield None, item def insert_items(self, index, items): self[index:index +1]=items add=len(items) -1 for name,(i, j) in self._names.items(): if i > index: self._names[name]=(i ", "label": 0}, {"snippet_id": 76942, "code": " net def upload_avatar(self, ud): if('avatar_uploaded' in ud[0] and ud[0]['avatar_uploaded'] is True): return files=[] for sd in os.walk(c.av_dir): files.extend(sd[2]) av=os.path.join(sd[0], random.choice", "label": 0}, {"snippet_id": 34311, "code": "=version return ruleinfo return decorate def log(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo)", "label": 0}, {"snippet_id": 71014, "code": "%d)\" % len(t_unknown)) if len(t_unknown) < len(a_targets): ldic.append(dict([[\"type\", \"%s\" % type.upper()], [\"count\", len(a_targets)],[\"nodes\", nodes], [\"status\", ', '.join(status)]])) if show_clients:", "label": 0}, {"snippet_id": 35173, "code": ".flags return False def temp(value): \"\"\" A flag for an input or output file that shall be removed after usage. \"\"\" if is_flagged(value, \"protected\"): raise SyntaxError( \"Protected and temporary flags are", "label": 1}, {"snippet_id": 45651, "code": " contains_wildcard(self.file) def regex(self): if self._regex is None: self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file", "label": 0}, {"snippet_id": 4034, "code": ".set_dependencies(True) elif args.cmd=='slave': logger.debug(\"Launching slave mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center)", "label": 0}, {"snippet_id": 90011, "code": " open(os.path.join(classpath, 'SystemProperties.class'), 'w+b') as fp: fp.write(pkgutil.get_data(__name__, 'SystemProperties.class')) cmd=[java, '-cp', classpath, 'SystemProperties'] process=subprocess", "label": 0}, {"snippet_id": 25424, "code": "'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self", "label": 0}, {"snippet_id": 34748, "code": "(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output file{} of rule{} shall be touched but \" \"does not exist.\".format(self.file, self.rule.name", "label": 1}, {"snippet_id": 78213, "code": " **kvargs) def on_caprate_limit(self, rate): if not self.logined: self._capdata=(0, 0) return self.log.warning('Caprate limit reached, calling dologin() for now') self.dologin() def comment_loop(self):", "label": 0}, {"snippet_id": 55727, "code": ".resources if args: raise RuleException(\"Resources have to be named.\") if not all(map(lambda r: isinstance(r, int), resources.values())): raise RuleException( \"Resources values have to be integers.\", rule=rule", "label": 0}, {"snippet_id": 67005, "code": ".cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]=has_arg def execute(self, args): \"\"\" Execute a shine script command. \"\"\" command=None new_args=", "label": 0}, {"snippet_id": 78291, "code": ": pass self.w.sleep(self.comment_successtimeout) except exc.Captcha as e: self.log.error('Too many wrong answers to CAPTCHA') self.schedule(self.add_comment,(t, msg)) except exc.UnknownAnswer as e: self", "label": 0}, {"snippet_id": 59469, "code": "=self.execute_queued() def execute_queued(self): \"\"\"Apply the queued operations to the device, and measure the expectation.\"\"\" for operation in self._queue: if operation.name not in operator_map: raise", "label": 1}, {"snippet_id": 10145, "code": " set of formatted core keywords \"\"\" output={} category={} def _get_value_kw(kw): \"\"\"Help to sort the Core keywords.\"\"\" i=0 while kw[i].isdigit(): i +=1 if i > 0: return int(kw[:i]) else: return 0 for skw", "label": 0}, {"snippet_id": 17099, "code": "'healthy')) response.raise_for_status() return response.json() if SERVER_HEALTHY: return True try: SERVER_HEALTHY=_ServerIsHealthy() return SERVER_HEALTHY except: return False def _RaiseExceptionForData", "label": 1}, {"snippet_id": 43773, "code": " @property def subworkflows(self): return self._subworkflows.values() @property def rules(self): return self._rules.values() @property def concrete_files(self): return( file for rule in self.rules for file", "label": 0}, {"snippet_id": 76127, "code": "', i, m, t) def accept(that, reqid, seqnum, status, data): if status==wzrpc.status.success: self.log.debug('Succesfully set route type for(%s, %s) to %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc", "label": 0}, {"snippet_id": 78156, "code": "']) if c.no_shell: while True: time.sleep(1) else: try: import IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except KeyboardInterrupt: print(\"KeyboardInterrupt\") except", "label": 1}, {"snippet_id": 29295, "code": "(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for", "label": 0}, {"snippet_id": 63268, "code": "%d\" % job_wrapper.job_id) return lwr_job_state=AsynchronousJobState() lwr_job_state.job_wrapper=job_wrapper lwr_job_state.job_id=job_id lwr_job_state.old_state=True lwr_job_state.running=False lwr_job_state", "label": 0}, {"snippet_id": 71986, "code": " worker.iter_buffers(nodes): self.fs._handle_shine_proxy_error(nodes, \"Remote action %s failed: %s\" % \\ (self.action, buffer)) self.fs.action_refcnt -=1 if self.fs.action_refcnt==0: worker.task.abort()", "label": 0}, {"snippet_id": 49471, "code": "]=nodes def rules(items): return map(self._rules.__getitem__, filter(self.is_rule, items)) if keep_target_files: def files(items): return filterfalse(self.is_rule, items) else: def files(items): return", "label": 0}, {"snippet_id": 66702, "code": " %s %s\" %(cmd.get_name(), cmd.get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s", "label": 0}, {"snippet_id": 61690, "code": "\"\" if U.shape !=(2, 2): raise ValueError('2x2 matrix required.') if len(wires) !=1: raise ValueError('One target subsystem required.') wires=wires[0] before=2**wires after =2**(self.wires-wires-1) U=np", "label": 0}, {"snippet_id": 40206, "code": "=False, fail_dynamic=False): f=self._file if self._is_function: f=self._file(Namedlist(fromdict=wildcards)) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic", "label": 1}, {"snippet_id": 88635, "code": "(ident, self.targets()) @contextmanager def executing(self): \"\"\"A contextmanager that sets metrics in the context of a(v1) engine execution.\"\"\" self._set_target_root_count_in_runtracker() yield self.run_tracker", "label": 0}, {"snippet_id": 85791, "code": "(self, classpath_product_key, target, extra_cp_entries=None): classpath_product=self._products.get_data(classpath_product_key) if DependencyContext.global_instance().defaulted_property(target, lambda x: x", "label": 0}, {"snippet_id": 54158, "code": " if self.benchmark else None return input, output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule", "label": 0}, {"snippet_id": 24184, "code": "'mdi:gauge', None], 'noise':['Noise', 'dB', 'mdi:volume-high', None], 'humidity':['Humidity', '%', None, DEVICE_CLASS_HUMIDITY], 'rain':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1", "label": 0}, {"snippet_id": 73986, "code": "\"auto\\\" or integer value\") if \"chunk_length\" in runtime_config.vcf_to_zarr: chunk_length_str=runtime_config.vcf_to_zarr[\"chunk_length\"] if chunk_length_str==\"default\": self.chunk_length=None elif isint", "label": 0}, {"snippet_id": 90302, "code": "): return cls(cls._OSX_JAVA_HOME_EXE) def __init__(self, osx_java_home_exe): self._osx_java_home_exe=osx_java_home_exe @property def jvm_locations(self): if os.path.exists(self._osx_java_home_exe): try", "label": 0}, {"snippet_id": 9188, "code": " extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"", "label": 0}, {"snippet_id": 84871, "code": " @classmethod def _key_for_tool_version(cls, tool, version): if version=='custom': return tool else: return '{}_{}'.format(tool, version.replace('.', '_')) @classmethod def register_options(cls, register", "label": 0}, {"snippet_id": 24372, "code": "(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable in SENSOR_TYPES.keys(): dev.append", "label": 1}, {"snippet_id": 24022, "code": " cmd_search_blkvsc=\"camcontrol devlist -b | grep blkvsc{0} | awk '{{print $1}}'\".format(output) err, output=shellutil.run_get_output(cmd_search_blkvsc) if err==0: output=output.rstrip() cmd_search_dev=", "label": 0}, {"snippet_id": 58422, "code": "=reverse('ajax-comment_case_runs') def test_refuse_if_missing_comment(self): self.client.login( username=self.tester.username, password='password') response=self.client.post(self.many_comments_url, {'run", "label": 0}, {"snippet_id": 37505, "code": "[\"subworkflow\"] inoutput.append(_item) if name: inoutput.add_name(name) elif callable(item): if output: raise SyntaxError( \"Only input files can be specified as functions\") inoutput.append(item) if name", "label": 0}, {"snippet_id": 25229, "code": "['Min Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'max_temp':['Max Temp.', TEMP_CELSIUS, 'mdi:thermometer', None], 'windangle':['Angle', '', 'mdi:compass', None], 'windangle_value':['Angle Value', ", "label": 0}, {"snippet_id": 70497, "code": " import Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824", "label": 0}, {"snippet_id": 35359, "code": " return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format", "label": 0}, {"snippet_id": 52830, "code": " \", \".join(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule", "label": 0}, {"snippet_id": 89075, "code": "(synthetic_address) in target_set: synthetics.add(self.build_graph.get_target(synthetic_address)) target_set.update(self._collect_targets(synthetics, **kwargs)) return list(filter(predicate, target_set))", "label": 0}, {"snippet_id": 51717, "code": " names]) pattern=re.compile(regex(pattern)) for dirpath, dirnames, filenames in os.walk(dirname): for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern", "label": 0}, {"snippet_id": 33713, "code": " benchmark_repeats=benchmark_repeats, greediness=greediness) if not dryrun and not quiet: if len(dag): if cluster or cluster_sync or drmaa: logger.resources_info( \"Provided cluster nodes:{}\".format(nodes)) else:", "label": 0}, {"snippet_id": 39241, "code": "._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse", "label": 0}, {"snippet_id": 62000, "code": ", 'CNOT': CNOT, 'CZ': CZ, 'SWAP': SwapGate, 'RX': Rx, 'RY': Ry, 'RZ': Rz, 'Rot': Rot, } class ProjectQDevice(Device): \"\"\"ProjectQ device for OpenQML. Args: wires(int): The number of qubits of the device", "label": 0}, {"snippet_id": 91529, "code": " BuildFileAddresses, TransitiveHydratedTargets from pants.engine.legacy.structs import PythonTestsAdaptor from pants.engine.rules import UnionRule, optionable_rule, rule from pants.engine.selectors import Get", "label": 0}, {"snippet_id": 70411, "code": "(fs_conf) status=fs.tune(tuning) if status==RUNTIME_ERROR: rc=RC_RUNTIME_ERROR if rc==RC_RUNTIME_ERROR: for nodes, msg in fs.proxy_errors: print \"%s: %s\" %(nodes, msg) if hasattr(eh, 'post'): eh.post(fs)", "label": 0}, {"snippet_id": 76143, "code": " %s', i, m, wzrpc.name_route_type(t)) elif status==wzrpc.status.e_req_denied: self.log.warn('Status{0}, reauthentificating'.\\ format(wzrpc.name_status(status))) self.auth_requests() else: self.log.warn", "label": 0}, {"snippet_id": 38846, "code": " process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that no other \" \"instances of snakemake are running on this directory, \" \"the remaining lock was likely", "label": 0}, {"snippet_id": 6549, "code": " if text_lines: source=filename process_lines() elif os.path.isfile(entry): text_lines=extractor.text_lines_from_local_file(entry) if text_lines: source=os.path.basename(entry) process_lines() else: text_lines", "label": 1}, {"snippet_id": 74473, "code": " username=\"\" password=\"\" use_tls=False directory=\"\" files=[] def __init__(self, runtime_config=None): \"\"\" Creates an object representation of FTP module configuration data. :param runtime_config: runtime_config", "label": 0}, {"snippet_id": 23216, "code": "\\0' *(expected * struct_size)) param=struct.pack('iL', expected*struct_size, buff.buffer_info()[0]) ret=fcntl.ioctl(sock.fileno(), 0x8912, param) retsize=(struct.unpack('iL', ret)[0]) if retsize==(expected", "label": 0}, {"snippet_id": 36418, "code": " requested=None): \"\"\" Return missing output files. \"\"\" files=set() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_", "label": 0}, {"snippet_id": 39204, "code": "\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not", "label": 0}, {"snippet_id": 87890, "code": "(self, scalac_plugin_map, classpath): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map.keys()), classpath) ret=[] for name, cp_entries in plugin_jar_map", "label": 0}, {"snippet_id": 58806, "code": "(TestCaseRunStatus.objects.get(name='PAUSED').pk), 'value_type': 'int', }) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) self.assertEqual( ", "label": 0}, {"snippet_id": 25472, "code": "\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of the sensor.\"\"\" return self._device_class @property def state(self): \"\"\"Return the", "label": 0}, {"snippet_id": 62951, "code": " import submit_job as lwr_submit_job from.lwr_client import ClientJobDescription from.lwr_client import LwrOutputs from.lwr_client import ClientOutputs from.lwr_client import PathMapper log=logging.getLogger", "label": 0}, {"snippet_id": 29721, "code": ": if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value): value=AnnotatedString(value) value.flags[flag_type]=flag_value return value return[flag(v", "label": 0}, {"snippet_id": 27067, "code": ".station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the", "label": 1}, {"snippet_id": 22522, "code": " the hostname for the system. For our purposes at this time though, I would hesitate to trust this function. Azure(Stack) uses the name that you provide in the Web UI or ARM(for example) as the value of", "label": 0}, {"snippet_id": 88762, "code": "(self, f, items): \"\"\"Map function `f` over `items` in subprocesses and return the result. :API: public :param f: A multiproc-friendly(importable) work function. :param items: A iterable of pickleable arguments", "label": 0}, {"snippet_id": 44951, "code": " ruleinfo.log: rule.set_log(*ruleinfo.log[0], **ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule", "label": 0}, {"snippet_id": 68008, "code": ": print \"%s: Failed to status %s %s(%s)\" %(node, target.type.upper(), \\ target.get_id(), target.dev) print \">> %s\" % message def ev_statusclient_start(self, node, client): pass def ev_statusclient_done", "label": 0}, {"snippet_id": 86064, "code": ", source_file_path): return source_file_path.endswith('.java') def javac_classpath(self): return Java.global_javac_classpath(self.context.products) def write_extra_resources(self, compile_context): \"\"\"Override", "label": 0}, {"snippet_id": 26544, "code": "['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type", "label": 0}, {"snippet_id": 2906, "code": "%s resulted in checkstate %s\" %(node.comp_name, state)) state=self.check_component(node.component) if(state is not CheckState.RUNNING or state is not CheckState.STOPPED_BUT_SUCCESSFUL): break if tries ", "label": 0}, {"snippet_id": 66992, "code": " if c==':': continue has_arg=not(i==opt_len -1) and(cmd.getopt_string[i+1]==':') if c in self.cmd_optargs: assert self.cmd_optargs[c]==has_arg, \"Incoherency in option arguments\" else: self.cmd_optargs[c]", "label": 0}, {"snippet_id": 82343, "code": " open(\"user-agents.txt\",\"r\") as fd: \t\tnb=0 \t\tfor l in fd: \t\t\tnb +=1 \t\tfd.seek(0) \t\tnb=random.randint(0,nb) \t\tfor i in range(0,nb): \t\t\targs.userAgent=fd.readline()[:-1] if args.template: \targs.template=args", "label": 0}, {"snippet_id": 25731, "code": "._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='min_temp': self", "label": 0}, {"snippet_id": 77601, "code": ".log.info('Saved users') def get_userqueue(self, domain): try: uq=self.userqueues[domain] except KeyError: self.log.info('Created userqueue for %s', domain) uq=Queue() self.userqueues[domain]=uq return uq", "label": 0}, {"snippet_id": 93745, "code": "'\" %(comp['name'])) state=self.check_component(node.component) if(state is CheckState.STARTED_BY_HAND or state is CheckState.RUNNING): self.logger.debug(\"Component %s is already running. Skipping start", "label": 0}, {"snippet_id": 23741, "code": ".run_get_output(cmd) if ret: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) try: return int(output)/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)", "label": 0}, {"snippet_id": 19133, "code": " if raw_response is not None: response=normalize_response(raw_response, request=request) if response is not None: validate_response( response=response, request_method=request_method, schema=schema ) def", "label": 0}, {"snippet_id": 57732, "code": ".review_case=plan.case.exclude(case_status__name=confirm_status_name) run_case_count=plan.run_case.count() case_count=plan.case.count() review_case_count=plan.review_case.count() return http.JsonResponse(", "label": 0}, {"snippet_id": 95810, "code": ": with open(local_filepath) as f: data=f.read() return data else: return None def setup_vcf_to_zarr(input_vcf_dir, output_zarr_dir, conversion_config): \"\"\" Converts all VCF files in input directory to Zarr", "label": 0}, {"snippet_id": 31951, "code": "=item.get_wildcard_names() if self.wildcard_names: if self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names", "label": 0}, {"snippet_id": 61826, "code": ".kron(np.kron(np.eye(before), U), np.eye(after)) return U dev=DefaultQubit(wires=2) def node(x, y, z): qm.RX(x,[0]) qm.CNOT([0, 1]) qm.RY(-1.6,[0]) qm.RY(y,[1]) qm.CNOT([1, 0]) qm.RX(z,[0]) qm.CNOT([0, 1]", "label": 0}, {"snippet_id": 85804, "code": ": dependencies=target.strict_dependencies(DependencyContext.global_instance()) else: dependencies=DependencyContext.global_instance().all_dependencies(target) all_extra_cp_entries=list(self._compiler_plugins_cp_entries", "label": 0}, {"snippet_id": 36592, "code": "(to_remove))) for f in to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow", "label": 0}, {"snippet_id": 73905, "code": " alt_number=None chunk_length=None chunk_width=None compressor=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): ", "label": 0}, {"snippet_id": 14512, "code": "._IsServerAlive(): return BaseRequest.PostDataToHandler( BuildRequestData(), 'defined_subcommands') else: return[] def GetCurrentCompletionRequest( self): return self._latest_completion_request def GetOmniCompleter", "label": 0}, {"snippet_id": 81882, "code": "?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"]", "label": 0}, {"snippet_id": 73643, "code": " from numcodecs import Blosc def config_str_to_bool(input_str): \"\"\" :param input_str: The input string to convert to bool value :type input_str: str :return: bool \"\"\" return input_str.lower() in['true',", "label": 0}, {"snippet_id": 3041, "code": " start_window(window, comp['cmd'][0]['start'], log_file, comp['name']) def start_remote_component(self, comp_name, host): cmd=(\"ssh %s 'hyperion --config %s/%s.yaml slave'\" %(host, TMP_SLAVE_DIR, comp_name", "label": 0}, {"snippet_id": 72972, "code": "[Setup][FTP]({}/{}) Error downloading file. Skipping:{}\".format(file_counter, file_list_total, filepath)) local_file.close() os.remove(filepath) else: print(\"[Setup][FTP]({}/{}) File already exists. Skipping", "label": 0}, {"snippet_id": 58477, "code": "( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No runs selected.'}) response=self.client.post(self.many_comments_url, {'comment': 'new comment'}) self.assertJSONEqual", "label": 0}, {"snippet_id": 61661, "code": " device\"\"\" self._state =None self._out=None def expand_one(self, U, wires): \"\"\"Expand a one-qubit operator into a full system operator. Args: U(array): 2*2 matrix wires(Sequence[int]): target subsystem", "label": 0}, {"snippet_id": 33268, "code": " None: prioritytargets=list() if forcerun is None: forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files", "label": 0}, {"snippet_id": 33285, "code": "(forcerun)) targetrules=set(chain(rules(targets), filterfalse(Rule.has_wildcards, priorityrules), filterfalse(Rule.has_wildcards, forcerules))) targetfiles=set(chain(files(targets), priorityfiles, forcefiles", "label": 0}, {"snippet_id": 28151, "code": " CONF_STATION='station' DEPENDENCIES=['netatmo'] MIN_TIME_BETWEEN_UPDATES=timedelta(seconds=600) SENSOR_TYPES={ 'temperature':['Temperature', TEMP_CELSIUS, None, DEVICE_CLASS_TEMPERATURE], 'co2':['CO2', 'ppm', ", "label": 1}, {"snippet_id": 48220, "code": " an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if", "label": 0}, {"snippet_id": 14140, "code": " subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all.omni_completer import OmniCompleter from ycm.completers", "label": 0}, {"snippet_id": 50555, "code": "*logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return decorate", "label": 0}, {"snippet_id": 48254, "code": "=IOFile(item, rule=self) if is_flagged(item, \"temp\"): if not output: raise SyntaxError(\"Only output files may be temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output:", "label": 0}, {"snippet_id": 3139, "code": " % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host, name) send_main_session_command", "label": 0}, {"snippet_id": 13152, "code": "=headers, auth=auth) ATTEMPT +=1 if ATTEMPT > 10: data[\"error\"]=\"Forking is taking more than usual time\" break full_name=data[\"target_repo_fullname\"] author, name=full_name.split(\"/\") request_json={ \"name\"", "label": 0}, {"snippet_id": 28361, "code": " monitored_conditions: dev.append(NetAtmoSensor(data, module_name, variable)) else: for module_name in data.get_module_names(): for variable in\\ data.station_data.monitoredConditions(module_name): if variable", "label": 1}, {"snippet_id": 92839, "code": "=os.path.join(tempdir, 'foo') os.symlink(not_zip.name, file_symlink) self.assertEqual(os.path.realpath(file_symlink), os.path.realpath(not_zip.name)) with self.assertRaisesRegexp(zipfile.BadZipfile, r'{", "label": 0}, {"snippet_id": 50423, "code": " ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo.input=(paths, kwpaths) return ruleinfo return decorate def output(self, *paths", "label": 0}, {"snippet_id": 67809, "code": "(LocalStartEventHandler(vlevel), GlobalStartEventHandler(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh", "label": 0}, {"snippet_id": 55010, "code": "=force_incomplete, ignore_incomplete=ignore_incomplete or printdag or printrulegraph, notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag", "label": 0}, {"snippet_id": 74611, "code": "=\"Blosc\" blosc_compression_algorithm=\"zstd\" blosc_compression_level=1 blosc_shuffle_mode=Blosc.AUTOSHUFFLE def __init__(self, runtime_config=None): \"\"\" Creates an object representation of VCF to Zarr Conversion", "label": 0}, {"snippet_id": 64610, "code": "(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs.mgt_servers) print \"\\t%d MDT on %s\" %(fs.mdt_count, fs.mdt_servers)", "label": 0}, {"snippet_id": 2925, "code": " CheckState.STOPPED_BUT_SUCCESSFUL): break if tries > 100: return False tries=tries +1 sleep(.5) self.logger.debug(\"All dependencies satisfied, starting '%s'\" %(comp['name'])) state=self.check_component", "label": 0}, {"snippet_id": 26406, "code": " add_devices(dev, True) class NetAtmoSensor(Entity): \"\"\"Implementation of a Netatmo sensor.\"\"\" def __init__(self, netatmo_data, module_name, sensor_type): \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'", "label": 0}, {"snippet_id": 8211, "code": " text_lines_from_local_file and text_lines_from_url. This module also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import", "label": 0}, {"snippet_id": 66340, "code": " AsciiTableLayout.LEFT, \"ldd flags\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"fsname\", i, AsciiTableLayout.LEFT, \"fsname\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"status\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 65742, "code": ", [\"type\", target.type.upper()], [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header", "label": 0}, {"snippet_id": 17818, "code": ".abspath( __file__)) return os.path.join( dir_of_current_script, 'server/ycmd.py') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( ", "label": 0}, {"snippet_id": 60314, "code": " shots=0, cutoff=None, hbar=2): self.wires=wires self.cutoff=cutoff self.hbar=hbar self.eng=None self.state=None super().__init__(self.short_name, shots) def execute(self): \"\"\"Apply the queued operations", "label": 1}, {"snippet_id": 28838, "code": "% data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['WindAngle'] elif self.type=='windstrength': self", "label": 0}, {"snippet_id": 43337, "code": " output, params, log, benchmark, ruleio, dependencies except WildcardError as ex: raise RuleException( \"Wildcards in input, params, log or benchmark file of rule{} cannot be \" \"determined from output files:", "label": 0}, {"snippet_id": 25426, "code": ", SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None self._device_class=SENSOR_TYPES[self.type][3] self._icon=SENSOR_TYPES[self", "label": 0}, {"snippet_id": 28026, "code": " elif data['wifi_status'] >=71: self._state=\"Medium\" elif data['wifi_status'] >=56: self._state=\"High\" elif data['wifi_status'] <=55: self._state=\"Full\" class NetAtmoData(object): \"\"\"Get the latest data", "label": 0}, {"snippet_id": 94672, "code": ") logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help=\"YAML config file. see sample-config.yaml. Default: test.yaml", "label": 0}, {"snippet_id": 68694, "code": ") elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev=\"\" if target.tag: tag_col_enabled", "label": 0}, {"snippet_id": 28638, "code": "\"Very Low\" elif self.type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self", "label": 0}, {"snippet_id": 38109, "code": ".name==other.name class Ruleorder: def __init__(self): self.order=list() def add(self, *rulenames): \"\"\" Records the order of given rules as rule1 > rule2 > rule3,... \"\"\" self.order.append(list(rulenames))", "label": 0}, {"snippet_id": 10029, "code": "\"\"\"Return the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes", "label": 0}, {"snippet_id": 70915, "code": "[] for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering", "label": 0}, {"snippet_id": 30190, "code": ") def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self, name, self[index", "label": 0}, {"snippet_id": 63981, "code": " __dependency_resolution( lwr_client): dependency_resolution=lwr_client.destination_params.get( \"dependency_resolution\", \"local\") if dependency_resolution not in[\"none\", \"local\", \"remote\"]: raise Exception(", "label": 0}, {"snippet_id": 18271, "code": "._temp_options_filename=None self._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete", "label": 1}, {"snippet_id": 25557, "code": " elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise': self", "label": 0}, {"snippet_id": 11559, "code": "=section_data.keys() sorted_keys.sort() for key in sorted_keys: value=section_data[key] self.icinga_lines.append((\"%s%-45s%s\" %(self.indent, key, self.value_to_icinga(value)))) self.write_line(\"}\") @staticmethod", "label": 1}, {"snippet_id": 35565, "code": "(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def", "label": 0}, {"snippet_id": 25894, "code": " data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" %", "label": 0}, {"snippet_id": 41806, "code": ".benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return", "label": 0}, {"snippet_id": 3800, "code": " send_main_session_command(session, cmd): window=find_window(session, \"Main\") window.cmd(\"send-keys\", cmd, \"Enter\") def setup_log(window, file, comp_name): clear_log(file) window.cmd(\"send-keys\", \"exec 2> >(exec tee -i", "label": 0}, {"snippet_id": 33800, "code": " and len(dag): logger.run_info(\"\\n\".join(dag.stats())) elif stats: scheduler.stats.to_json(stats) if not dryrun and not no_hooks: self._onsuccess(logger.get_logfile()) return True else: if not dryrun and", "label": 0}, {"snippet_id": 92400, "code": ".assertIn('USER', os.environ) self.assertNotIn('AAA', os.environ) def test_hermetic_environment_unicode(self): UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output=UNICODE_CHAR if", "label": 1}, {"snippet_id": 52401, "code": ".priority(self) @property def b64id(self): return base64.b64encode((self.rule.name +\"\".join(self.output) ).encode(\"utf-8\")).decode(\"utf-8\") @property def inputsize(self): \"\"\" Return the size of the input files", "label": 0}, {"snippet_id": 9863, "code": " generated keywords by bibclassify</title> </head> <body> {0} </body> </html>\"\"\".format( _output_text(complete_output).replace('\\n', '<br>') ).replace('\\n', '') def _get_singlekws(skw_matches, spires=False): ", "label": 0}, {"snippet_id": 53535, "code": " self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output", "label": 0}, {"snippet_id": 90981, "code": " searched before ' 'everything else(before the JDK_HOME, JAVA_HOME, PATH environment variables) ' 'when locating a jvm to use. The same OS can be specified via several different ' 'aliases, according to", "label": 0}, {"snippet_id": 43181, "code": " raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else:", "label": 0}, {"snippet_id": 46618, "code": "(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass class Resources(Namedlist): pass class Log(Namedlist", "label": 0}, {"snippet_id": 51359, "code": " Iterable) class AnnotatedString(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return", "label": 0}, {"snippet_id": 41925, "code": ".reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning: the following output files of rule{} were not \" \"present when the DAG was created:\\n{}\".format", "label": 0}, {"snippet_id": 785, "code": " safe=False) elif action=='getThreads': print(action) rows=[] ps=subprocess.Popen(['top', '-b','-n','1'], stdout=subprocess.PIPE).communicate()[0] processes=ps.decode().split('\\n') nfields=len(processes", "label": 0}, {"snippet_id": 38801, "code": ".init() dag.check_dynamic() if unlock: try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed", "label": 0}, {"snippet_id": 87301, "code": ": \"\"\"A directory where zinc can store compiled copies of the `compiler-bridge`. The compiler-bridge is specific to each scala version, and is lazily computed by zinc if the appropriate version does not", "label": 1}, {"snippet_id": 47448, "code": " wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self.rule.version, rule=self.rule.name,)) _variables.update(variables) try: return format(string,", "label": 0}, {"snippet_id": 15486, "code": "']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if", "label": 0}, {"snippet_id": 71276, "code": "(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag(): flags.append(\"conf_param\"", "label": 0}, {"snippet_id": 12386, "code": " comment_header=config[\"message\"][\"updated\"][\"header\"] +\"\\n\\n\" ERROR=False comment_body=[] for file, issues in data[\"results\"].items(): if len(issues)==0: if not config[\"only_mention_files_with_errors\"]", "label": 0}, {"snippet_id": 85688, "code": "), buildroot, ), ))[0] @memoized_property def rebase_map_args(self): \"\"\"We rebase known stable paths in zinc analysis to make it portable across machines.\"\"\" rebases={ self.dist.real_home: '/dev/null/remapped_by_pants", "label": 0}, {"snippet_id": 63206, "code": ": unstructured_path_rewrites=compute_environment.unstructured_path_rewrites client_job_description=ClientJobDescription( command_line=command_line, input_files=self.get_input_files(job_wrapper), client_outputs", "label": 0}, {"snippet_id": 54228, "code": " IOFileException(\"{}\".format(ex), snakefile=self.snakefile, lineno=self.lineno) def get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files", "label": 0}, {"snippet_id": 88609, "code": "(self): \"\"\"Returns the current workspace, if any.\"\"\" return self._workspace @property def invalidation_report(self): return self._invalidation_report def __str__(self): ident=Target.identify(self.targets", "label": 0}, {"snippet_id": 64376, "code": " import Command from Shine.Commands import commandList from Exceptions import * class CommandRegistry: \"\"\"Container object to deal with commands.\"\"\" def __init__(self): self.cmd_list=[] self.cmd_dict={", "label": 0}, {"snippet_id": 12940, "code": "\"\"\"Create gists for diff files\"\"\" REQUEST_JSON={} REQUEST_JSON[\"public\"]=True REQUEST_JSON[\"files\"]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url", "label": 0}, {"snippet_id": 77213, "code": ") continue if len(proxypair) > 2: self.log.debug('Line %s has too much spaces', line) proxypair=(proxypair[0], proxypair[1]) newproxies.add(proxypair) except Exception as e: self.log.exception('Line %s", "label": 0}, {"snippet_id": 19327, "code": "(yaml_file) assert result==native def test_yaml_file_path(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush()", "label": 0}, {"snippet_id": 58483, "code": "'response': 'No runs selected.'}) response=self.client.post(self.many_comments_url, {'comment': 'new comment'}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1,", "label": 0}, {"snippet_id": 81862, "code": "\"proxy\", help=\"Proxy information. Example: --proxy \\\"user:password@proxy.host:8080\\\"\", type=valid_proxyString) parser.add_argument(\"--proxy-creds\",metavar=\"credentials\",nargs='?',const=True,dest=\"proxyCreds", "label": 0}, {"snippet_id": 39001, "code": " for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True elif printdag: print(dag) return True elif printrulegraph: print(dag.rule_dot()) return True elif summary: print", "label": 0}, {"snippet_id": 74431, "code": " parser=ConfigParser() parser.optionxform=str found=parser.read(file_name) if not found: raise ValueError(\"Configuration file{0} not found\".format(file_name)) for name in parser.sections(): dict_section", "label": 0}, {"snippet_id": 60706, "code": ") elif self._observe.name=='Displacement': ex=self.state.displacement(modes=reg) if self.shots !=0: ex=np.random.normal(ex, np.sqrt(var / self.shots)) self._out=ex def reset(self): \"\"\"Reset the device\"", "label": 0}, {"snippet_id": 65840, "code": " for target in a_targets: nodes.add(target.servers[0]) if target.state==OFFLINE: t_offline.append(target) elif target.state==TARGET_ERROR: t_error.append(target) elif target.state==RECOVERING: t_recovering", "label": 0}, {"snippet_id": 17175, "code": ".completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client.event_notification import( SendEventNotificationAsync, EventNotification", "label": 0}, {"snippet_id": 72374, "code": "(irc, source, args): \"\"\"<protocol module name> Reloads the given protocol module without restart. You will have to manually disconnect and reconnect any network using the module for changes to apply.\"\"", "label": 0}, {"snippet_id": 76911, "code": ": net.proxy_type=sup.proxytype.http elif proxytype=='SOCKS4': net.proxy_type=sup.proxytype.socks4 elif proxytype=='SOCKS5': net.proxy_type=sup.proxytype.socks5 else: raise TypeError('Invalid proxytype ", "label": 1}, {"snippet_id": 6632, "code": " only_core_tags=only_core_tags, extract_acronyms=extract_acronyms) def get_keywords_from_text(text_lines, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires=False,", "label": 0}, {"snippet_id": 44239, "code": " have the permissions?\") return False try: self.persistence.lock() except IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create", "label": 0}, {"snippet_id": 91632, "code": ", 'requirement'): all_target_requirements.append(str(maybe_python_req_lib.requirement)) if hasattr(maybe_python_req_lib, 'requirements'): for py_req in maybe_python_req_lib.requirements: all_target_requirements", "label": 0}, {"snippet_id": 39866, "code": ".join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow\", self) return[self.target(path) for path", "label": 0}, {"snippet_id": 7624, "code": " list of formatted keywords \"\"\" output={} for single_keyword, info in skw_matches: output[single_keyword.output(spires)]=len(info[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\"", "label": 0}, {"snippet_id": 68073, "code": " return \"status\" def get_desc(self): return \"Check for file system target status.\" target_status_rc_map={ \\ MOUNTED: RC_ST_ONLINE, RECOVERING: RC_ST_RECOVERING, OFFLINE: RC_ST_OFFLINE, TARGET_ERROR: RC_TARGET_ERROR", "label": 0}, {"snippet_id": 88328, "code": " uses of the context include adding new targets to it for upstream or downstream goals to operate on and mapping of products a goal creates to the targets the products are associated with. :API: public", "label": 0}, {"snippet_id": 15956, "code": " handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS, timeout=timeout) @retries( 5, delay=0.5, backoff", "label": 1}, {"snippet_id": 80836, "code": ".submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not", "label": 1}, {"snippet_id": 91137, "code": " import PantsRequirement from pants.backend.python.python_artifact import PythonArtifact from pants.backend.python.python_requirement import PythonRequirement from pants.backend.python.python_requirements", "label": 0}, {"snippet_id": 60455, "code": " strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix, DisplacedSqueezed, Fock, Ket, Squeezed, Thermal, Gaussian) from strawberryfields.ops import(GaussianTransform", "label": 0}, {"snippet_id": 4099, "code": " MARCXML or HTML). But unfortunately there is a confusion between running in a standalone mode and producing output suitable for printing, and running in a web-based mode where the webtemplate is used. For", "label": 0}, {"snippet_id": 70203, "code": ".Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start(self, node, target): if self.verbose > 1: print \"Starting %s %s(%s)...\" %(target.type.upper(),", "label": 0}, {"snippet_id": 58119, "code": " Category, and Build\\n Return[(id, name),(id, name)] \"\"\" ctypes={ 'component':(Component, 'name'), 'version':(Version, 'value'), 'build':(Build, 'name'), 'category':(Category, 'name'), } results=ctypes", "label": 0}, {"snippet_id": 40766, "code": "(wildcard, value) for value in values] try: return[filepattern.format(**comb) for comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError", "label": 0}, {"snippet_id": 89907, "code": "' got{}'.format(java, self._minimum_version, version)) if self._maximum_version: version=self._get_version(java) if version > self._maximum_version: raise self.Error('The java distribution at{} is too new", "label": 0}, {"snippet_id": 18479, "code": "._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest( self, arguments, completer): if self._IsServerAlive", "label": 0}, {"snippet_id": 96005, "code": "(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length:{}\".format(chunk_length)", "label": 0}, {"snippet_id": 11191, "code": " with open(file_name, 'r') as config_file: for line in config_file.xreadlines(): etag=extract(Header.ETAG_COMMENT, etag) mtime=extract(Header.MTIME_COMMMENT, mtime) if etag and mtime: break except IOError", "label": 0}, {"snippet_id": 682, "code": "} finalset.append(data) return JsonResponse(finalset, safe=False) elif action=='getContainerStats': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID", "label": 0}, {"snippet_id": 17942, "code": " timeout): if method=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri(", "label": 1}, {"snippet_id": 53851, "code": " self.params.set_name(name, start, end=len(self.params)) except TypeError: raise SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, ", "label": 0}, {"snippet_id": 72732, "code": ".VCFtoZarrConfigurationRepresentation(runtime_config) else: print(\"Error: Unexpected command specified. Exiting...\") sys.exit(1) def main(): try: _main() except KeyboardInterrupt: print(\"Program interrupted. Exiting...\") sys.exit(1)", "label": 0}, {"snippet_id": 11116, "code": ", %d)\" %(self.etag, self.mtime) def is_newer_than(self, other): if self.etag !=other.etag or self.etag is None: return cmp(self.mtime, other.mtime) > 0 else: return False def serialize(self): lines=[] time_string", "label": 0}, {"snippet_id": 63633, "code": ", exception=True) log.exception(\"failure finishing job %d\" % job_wrapper.job_id) return if not LwrJobRunner.__remote_metadata( client): self._handle_metadata_externally( job_wrapper, resolve_requirements", "label": 0}, {"snippet_id": 809, "code": " for row in processes[4:]: rows.append(row.split(None, nfields)) return JsonResponse(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor", "label": 0}, {"snippet_id": 73237, "code": " *.vcf files should go :type input_dir: str :type temp_dir: str :type output_dir: str \"\"\" input_dir=str(input_dir) temp_dir=str(temp_dir) output_dir=str(output_dir) create_directory_tree(input_dir) create_directory_tree", "label": 0}, {"snippet_id": 47078, "code": " None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable when printing \" \"shell command:{}\".format(str(ex)), rule=self", "label": 0}, {"snippet_id": 25440, "code": "] self._icon=SENSOR_TYPES[self.type][2] self._unit_of_measurement=SENSOR_TYPES[self.type][1] module_id=self.netatmo_data.\\ station_data.moduleByName(module=module_name)['_id'] self.module_id=module_id[1", "label": 0}, {"snippet_id": 36240, "code": ". \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException", "label": 0}, {"snippet_id": 78594, "code": ".schedule(self.scan_targets_loop) def _run(self): self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError as e: self.log", "label": 0}, {"snippet_id": 45890, "code": " wildcards, fill_missing=False, fail_dynamic=False, dynamic_fill=None, keep_dynamic=False): def format_match(match): name=match.group(\"name\") try: value=wildcards[name] if fail_dynamic and value==dynamic_fill:", "label": 0}, {"snippet_id": 77229, "code": " Exception as e: self.log.exception('Line %s raised exception %s', line, e) return newproxies.difference(self.proxylist) def add_spawns(self, proxypairs): while self.running.is_set(): try: try: proxypair", "label": 0}, {"snippet_id": 12289, "code": "[filename].remove(error) for error in list(data[\"results\"][filename]): if config[\"scanner\"][\"diff_only\"]: if not int(error.split(\":\")[1]) in py_files[file]: data[\"results\"][filename].remove(error) url=\"https:", "label": 0}, {"snippet_id": 64318, "code": " local_dataset_path, remote_path): remote_extra_files_path=None if remote_path: remote_extra_files_path=\"%s_files\" % remote_path[ 0:-len( \".dat\")] return local_dataset_path.with_path_for_job( remote_path", "label": 0}, {"snippet_id": 22357, "code": " not need to wait for mcpd to be available unless it absolutely wants to. :return bool: Returns True upon success :raises OSUtilError: Raises exception if mcpd does not come up within roughly 50 minutes", "label": 0}, {"snippet_id": 9281, "code": " get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords=None, acronyms=None, style=\"text\", output_limit=0, spires=False, only_core_tags=False): \"\"\"Returns a formatted string representing", "label": 0}, {"snippet_id": 61770, "code": "(wires >=self.wires) or wires[0]==wires[1]: raise ValueError('Bad target subsystems.') a=np.min(wires) b=np.max(wires) n_between=b-a-1 before =2**a after =2**(self.wires-b-1) between=2**n_between U=np.kron", "label": 0}, {"snippet_id": 66087, "code": " tag_col_enabled=False for type,(all_targets, enabled_targets) in fs.targets_by_type(): for target in enabled_targets: if target.state==OFFLINE: status=\"offline\" elif target.state==RECOVERING: status=\"recovering %s\"", "label": 0}, {"snippet_id": 50343, "code": " isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule", "label": 0}, {"snippet_id": 10030, "code": " the output for the field codes. :var skw_matches: dict of{keyword:[info,...]} :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: string\"\"\" fieldcodes", "label": 0}, {"snippet_id": 7522, "code": "\".format(result) for element in list_result_sorted: output +=\"\\n{0}{1}\".format(list_result[element], element) output +=\"\\n--\\n{0}\".format(_signature()) return output def _output_html(complete_output, categories", "label": 0}, {"snippet_id": 17798, "code": " expr, vimsupport.VimExpressionToPythonType( expr)) for expr in extra_conf_vim_data) extra_conf_vim_data=self._user_options[ 'extra_conf_vim_data'] if extra_conf_vim_data: extra_data[ 'extra_conf_data']", "label": 0}, {"snippet_id": 84623, "code": ") register('--ignored', type=bool, fingerprint=True, help='Show information about files ignored by cloc.') def console_output(self, targets): if not self.get_options().transitive: targets=self.context.target_roots", "label": 0}, {"snippet_id": 26346, "code": " if CONF_MODULES in config: for module_name, monitored_conditions in\\ config[CONF_MODULES].items(): if module_name not in data.get_module_names(): _LOGGER.error('Module name: \"%s\" not found', module_name", "label": 0}, {"snippet_id": 36803, "code": ".append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s.append(\"Rules with a run or shell declaration but no output", "label": 0}, {"snippet_id": 95350, "code": " ftp_config.password) ftp.prot_p() else: ftp=FTP(ftp_config.server) ftp.login(ftp_config.username, ftp_config.password) if not ftp_config.files: fetch_data_via_ftp_recursive(ftp=ftp, local_directory=local_directory", "label": 0}, {"snippet_id": 75916, "code": " b'') msgdict[rs]=msg s.send_multipart(msg) while self.running.is_set(): flag=0 for rs in rslist: if rs.finished: if not rs.retry: del msgdict[rs] continue s.send_multipart(msgdict[rs]) rs.finished=False", "label": 0}, {"snippet_id": 18067, "code": ".codes.server_error: _RaiseExceptionForData( response.json()) response.raise_for_status() if response.text: return response.json() return None def _BuildUri( handler): return urlparse.urljoin( BaseRequest", "label": 0}, {"snippet_id": 83643, "code": "\"env\",[]) return self.get_client( params, job_id, env) def get_client_from_state(self, job_state): job_destination_params=job_state.job_destination.params job_id=job_state.job_id return self.get_client(", "label": 0}, {"snippet_id": 21407, "code": " os.mkdir(sr_dir) os.system(\"touch %s\" % seen_file) with open(seen_file, 'wb') as f: pickle.dump(seen_links, f) os.system(\"touch %s\" % unseen_file) with open(unseen_file, 'wb') as f: pickle.dump(unseen_links", "label": 0}, {"snippet_id": 95272, "code": " gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path: The path to create dirs/subdirs for :type path: str \"\"\" path=str(path) pathlib.Path(path)", "label": 0}, {"snippet_id": 61130, "code": " \"\"\" return expm(-1j * theta/2 * Y) def frz(theta): r\"\"\"One-qubit rotation about the z axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_z \\theta/2", "label": 0}, {"snippet_id": 91029, "code": " \"\"\"Get all explicitly configured JDK paths. :return: mapping of os name -> list of jdk_paths :rtype: dict of string -> list of string \"\"\" return self._normalized_jdk_paths @memoized_method def _locator", "label": 0}, {"snippet_id": 46383, "code": " list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key,", "label": 0}, {"snippet_id": 50572, "code": ": ruleinfo.shellcmd=cmd return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod", "label": 0}, {"snippet_id": 5952, "code": " This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio.legacy.bibclassify import config as bconfig if bconfig.STANDALONE: from urllib2 import urlopen else: from", "label": 1}, {"snippet_id": 68518, "code": " c_offline) if c_error > 0: status.append(\"ERROR(%d)\" % c_error) if c_runtime > 0: status.append(\"CHECK FAILURE(%d)\" % c_runtime) if c_mounted > 0: status.append(\"mounted(%d)\" % c_mounted) ldic.append(dict", "label": 0}, {"snippet_id": 35091, "code": ": if keep_dynamic: return \"{{{}}}\".format(name) elif fill_missing: return dynamic_fill else: raise WildcardError(str(ex)) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return", "label": 0}, {"snippet_id": 27675, "code": "'battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'] >=5640: self._state=\"Full\" elif data['battery_vp'] >=5280: self._state=\"High\" elif", "label": 0}, {"snippet_id": 46871, "code": " self.ruleio, self.dependencies)=rule.expand_wildcards(self.wildcards_dict) self.resources_dict={ name: min(self.rule.workflow.global_resources.get(name, res), res) for name, res in rule.resources.items()", "label": 0}, {"snippet_id": 68432, "code": ") if len(t_error) > 0: status.append(\"ERROR(%d)\" % len(t_error)) if len(t_recovering) > 0: status.append(\"recovering(%d) for %s\" %(len(t_recovering), t_recovering[0].status_info)) if len(t_online) > 0:", "label": 0}, {"snippet_id": 19679, "code": " action='store_true') parser.add_argument('-V', '--version', action='version') parser.version=__version__ args=parser.parse_args(argv) ns=vars(args) serverhost=ns.pop('server_host', None) clienthost=ns.pop(", "label": 0}, {"snippet_id": 87170, "code": "]=(compile_context.classes_dir, compile_context.jar_file, compile_context.analysis_file) if zinc_args is not None: for compile_context in compile_contexts: with open(compile_context.zinc_args_file, 'r'", "label": 0}, {"snippet_id": 13978, "code": "=timeout) @retries( 5, delay=0.5, backoff=1.5) def DelayedSendRequest( data, handler, method): if method=='POST': return requests.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS) if", "label": 0}, {"snippet_id": 91334, "code": ": return BuildFileAliases( targets={ PythonApp.alias(): PythonApp, PythonBinary.alias(): PythonBinary, PythonLibrary.alias(): PythonLibrary, PythonTests.alias(): PythonTests, PythonDistribution.alias()", "label": 0}, {"snippet_id": 43735, "code": "=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args", "label": 0}, {"snippet_id": 42334, "code": " IOFileException, WildcardError, InputFunctionException class Rule: def __init__(self, *args, lineno=None, snakefile=None): \"\"\" Create a rule Arguments name --the name of the rule \"\"\" if len(args)==2: name, workflow", "label": 0}, {"snippet_id": 30435, "code": " \" \"has not been installed. Please install \" \"PyYAML to use YAML config files.\") try: return yaml.load(f) except yaml.YAMLError: raise WorkflowError(\"Config file is not valid JSON or YAML.\") except FileNotFoundError", "label": 0}, {"snippet_id": 70888, "code": " AsciiTable().print_from_list_of_dict(ldic, layout) def status_view_fs(cls, fs, show_clients=True): \"\"\" View: lustre FS summary \"\"\" ldic=[] for type,(a_targets, e_targets) in fs.targets_by_type(): nodes", "label": 0}, {"snippet_id": 84533, "code": " absolute_import, division, print_function, unicode_literals import os from builtins import open from future.utils import text_type from pants.backend.graph_info.subsystems.cloc_binary import ClocBinary from pants", "label": 0}, {"snippet_id": 89589, "code": ") self._home=home_path self._bin_path=bin_path or(os.path.join(home_path, 'bin') if home_path else '/usr/bin') self._minimum_version=_parse_java_version(\"minimum_version\", minimum_version) self._maximum_version", "label": 0}, {"snippet_id": 45512, "code": "=os.path.dirname(path_until_wildcard) if len(dir) > 0 and not os.path.exists(dir): try: os.makedirs(dir) except OSError as e: if e.errno !=17: raise e def protect(self): mode=(lstat(self.file).st_mode &", "label": 0}, {"snippet_id": 67941, "code": " import RemoteCallEventHandler from Exceptions import CommandBadParameterError from Shine.FSUtils import open_lustrefs from Shine.Utilities.AsciiTable import * import Shine.Lustre.EventHandler from Shine", "label": 0}, {"snippet_id": 43005, "code": " or callable(item): self.params.append(item) if name: self.params.add_name(name) else: try: start=len(self.params) for i in item: self._set_params_item(i) if name: self.params.set_name(name, start, end", "label": 0}, {"snippet_id": 21815, "code": "() X_train=sc.fit_transform(X_train) X_test=sc.transform(X_test) import keras from keras.models import Sequential from keras.layers import Dense classifier=Sequential() classifier.add(Dense(units=6, kernel_initializer", "label": 1}, {"snippet_id": 70991, "code": " len(t_online) > 0: status.append(\"online(%d)\" % len(t_online)) if len(t_runtime) > 0: status.append(\"CHECK FAILURE(%d)\" % len(t_runtime)) if len(t_unknown) > 0: status.append(\"not checked(%d)\" % len(t_unknown", "label": 0}, {"snippet_id": 43237, "code": "() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve wildcards in rule{}:\\n{}\".format( self.name, \"\\n\".join(self.wildcard_names)", "label": 0}, {"snippet_id": 38806, "code": " try: self.persistence.cleanup_locks() logger.info(\"Unlocking working directory.\") return True except IOError: logger.error(\"Error: Unlocking the directory{} failed. Maybe \" \"you don't have the permissions", "label": 0}, {"snippet_id": 65582, "code": "(vlevel)) fs_conf, fs=open_lustrefs(fsname, target, nodes=self.nodes_support.get_nodeset(), indexes=self.indexes_support.get_rangeset(), event_handler=eh) fs.set_debug(self.debug_support.has_debug()) status_flags", "label": 0}, {"snippet_id": 20595, "code": "=None, **kwargs): if addr is None: addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_server(addr, **kwargs) return cls(conn, owned=True, **kwargs) def __init__(self, conn, seq=1000, handlers=(),", "label": 0}, {"snippet_id": 92432, "code": "): self.assertIn('AAA', os.environ) self.assertEqual(os.environ['AAA'], expected_output) self.assertEqual(os.environ['XXX'], expected_output) def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir", "label": 1}, {"snippet_id": 28825, "code": "=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=30: self._state=\"NE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle", "label": 0}, {"snippet_id": 35122, "code": "(str): def __init__(self, value): self.flags=dict() def flag(value, flag_type, flag_value=True): if isinstance(value, AnnotatedString): value.flags[flag_type]=flag_value return value if not_iterable(value", "label": 0}, {"snippet_id": 59013, "code": " EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_os) EnvGroupPropertyMapFactory(group=cls.group_nitrate, property=cls.property_python) EnvGroupPropertyMapFactory(group=cls.group_new, property", "label": 0}, {"snippet_id": 40618, "code": " \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are", "label": 0}, {"snippet_id": 37284, "code": ".items(): self._set_inoutput_item(item, name=name) @property def output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark", "label": 0}, {"snippet_id": 24535, "code": " data found for %s\", self.module_name) self._state=STATE_UNKNOWN return if self.type=='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif", "label": 0}, {"snippet_id": 19331, "code": " test_yaml_file_path(): native={'foo': 'bar'} source=yaml.dump(native) tmp_file=tempfile.NamedTemporaryFile(mode='w', suffix='.yaml') tmp_file.write(source) tmp_file.flush() result=load_source(tmp_file", "label": 0}, {"snippet_id": 26414, "code": ": \"\"\"Initialize the sensor.\"\"\" self._name='Netatmo{}{}'.format(module_name, SENSOR_TYPES[sensor_type][0]) self.netatmo_data=netatmo_data self.module_name=module_name self.type=sensor_type self._state=None", "label": 0}, {"snippet_id": 26660, "code": "'battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self", "label": 0}, {"snippet_id": 16517, "code": " self): return self._latest_completion_request def GetOmniCompleter( self): return self._omnicomp def NativeFiletypeCompletionAvailable( self): return any([ FiletypeCompleterExistsForFiletype( x) for x in", "label": 0}, {"snippet_id": 46782, "code": " import json from collections import defaultdict from itertools import chain from functools import partial from operator import attrgetter from snakemake.io import IOFile, Wildcards, Resources, _IOFile from", "label": 1}, {"snippet_id": 22250, "code": " log_file=self.conf['log_file'] else: log_file=open(os.devnull, 'w') if template: open(playbook, 'w').write( self.generate_ansible_playbook_from_template(template, data) ) runner=Runner(playbook=playbook", "label": 0}, {"snippet_id": 69001, "code": ") else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"\" shine umount ", "label": 0}, {"snippet_id": 36847, "code": "\".join(self.incomplete_output))) updated_input=self.updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run", "label": 0}, {"snippet_id": 87957, "code": " allows us to have in-repo plugins with dependencies(unlike javac, scalac doesn't load plugins or their deps from the regular classpath, so we have to provide these entries separately, in the -Xplugin:", "label": 0}, {"snippet_id": 35488, "code": " dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class", "label": 0}, {"snippet_id": 68263, "code": ": status=\"recovering %s\" % target.status_info elif target.state==MOUNTED: status=\"online\" else: status=\"UNKNOWN\" ldic.append(target_dict([[\"target\", target.get_id()], [\"type\", target.type.upper()], [\"nodes", "label": 0}, {"snippet_id": 48173, "code": " if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names() if self", "label": 0}, {"snippet_id": 69741, "code": " from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler", "label": 0}, {"snippet_id": 2449, "code": "'w') as outfile: dump(self.config, outfile, default_flow_style=False) self.logger.debug(\"Loading config was successful\") self.server=Server() if self.server.has_session(self.session_name): self.session", "label": 0}, {"snippet_id": 9048, "code": " fulltext=_get_partial_text(fulltext) author_keywords=None if with_author_keywords: author_keywords=extract_author_keywords(_skw, _ckw, fulltext) acronyms={} if extract_acronyms: acronyms=extract_abbreviations", "label": 0}, {"snippet_id": 39826, "code": "(os.path.join(self.workdir, \"Snakefile\")) if not os.path.isabs(self._snakefile): return os.path.abspath(os.path.join(self.workflow.basedir, self._snakefile)) return self._snakefile @property def workdir", "label": 0}, {"snippet_id": 23697, "code": " def eject_dvd(self, chk_err=True): dvd=self.get_dvd_device() retcode=shellutil.run(\"cdcontrol -f{0} eject\".format(dvd)) if chk_err and retcode !=0: raise OSUtilError(\"Failed to eject dvd: ret={0}\".format", "label": 0}, {"snippet_id": 85178, "code": " else: raise RuntimeError('Suffix version must be specified if using a custom scala version. ' 'Suffix version is used for bootstrapping jars. If a custom ' 'scala version is not specified, then the version", "label": 0}, {"snippet_id": 69299, "code": " except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except KeyError: print \"Error -Unrecognized action", "label": 1}, {"snippet_id": 91342, "code": " PythonBinary, PythonLibrary.alias(): PythonLibrary, PythonTests.alias(): PythonTests, PythonDistribution.alias(): PythonDistribution, 'python_requirement_library': PythonRequirementLibrary, Resources.alias():", "label": 0}, {"snippet_id": 36243, "code": "(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown", "label": 0}, {"snippet_id": 85516, "code": " main='no.such.main.Main', custom_rules=shader_rules) cls.register_jvm_tool(register, Zinc.ZINC_EXTRACTOR_TOOL_NAME, classpath=[ JarDependency('org.pantsbuild', 'zinc-extractor_2.11', '0.0.4') ]) @classmethod", "label": 1}, {"snippet_id": 80330, "code": "=1024*args.size if not args.notRegex and not args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not-regex or with --true-regex.\") if args.legitExtensions: \targs", "label": 0}, {"snippet_id": 14622, "code": "'CurrentIdentifierFinished') def DiagnosticsForCurrentFileReady( self): return bool( self._latest_file_parse_request and self._latest_file_parse_request.Done()) def GetDiagnosticsFromStoredRequest( self,", "label": 0}, {"snippet_id": 67649, "code": "), target.dev, strerr) if rc: print message self.update() class LocalStartEventHandler(Shine.Lustre.EventHandler.EventHandler): def __init__(self, verbose=1): self.verbose=verbose def ev_starttarget_start", "label": 0}, {"snippet_id": 50074, "code": ", overwrite_shellcmd=None): \"\"\" Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack", "label": 0}, {"snippet_id": 24670, "code": "'battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data", "label": 0}, {"snippet_id": 56776, "code": ".get(pk=self.object_pk) class _TagActions(object): \"\"\" Used for performing the 'add' and 'remove' actions on a given tag \"\"\" def __init__(self, obj, tag_name): \"\"\" :param obj: the object for which the tag", "label": 0}, {"snippet_id": 3735, "code": " is available or it failed: returning false\") return CheckState.STOPPED def get_window_pid(window): r=window.cmd('list-panes', \"-F return[int(p) for p in r.stdout] def kill_session_by_name(server, name):", "label": 0}, {"snippet_id": 26462, "code": "\"Return the name of the sensor.\"\"\" return self._name @property def icon(self): \"\"\"Icon to use in the frontend, if any.\"\"\" return self._icon @property def device_class(self): \"\"\"Return the device class of", "label": 0}, {"snippet_id": 39267, "code": ".path.dirname(self.included_stack[-1]) snakefile=os.path.join(current_path, snakefile) snakefile=os.path.abspath(snakefile) if snakefile in self.included: logger.info(\"Multiple include of{} ignored\".format", "label": 0}, {"snippet_id": 47219, "code": ".benchmark.mtime) if existing: return min(existing) return None @property def input_maxtime(self): \"\"\" Return newest input file. \"\"\" existing=[f.mtime for f in self.input if f.exists] if existing: return", "label": 0}, {"snippet_id": 33330, "code": " as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall=forceall, forcefiles=forcefiles, forcerules=forcerules, priorityfiles", "label": 0}, {"snippet_id": 42600, "code": ".touch_output: branch.touch_output.discard(old) branch.touch_output.update(exp) branch.wildcard_names.clear() non_dynamic_wildcards=dict((name, values[0]) for name, values in wildcards.items() if len(set(values)", "label": 0}, {"snippet_id": 50397, "code": ".shellcmd ruleinfo.func.__name__=\"__{}\".format(name) self.globals[ruleinfo.func.__name__]=ruleinfo.func setattr(rules, name, rule) return ruleinfo.func return decorate def docstring(self, string): def decorate", "label": 0}, {"snippet_id": 14760, "code": ")[ 0] if filetype in self._filetypes_with_keywords_loaded: return self._filetypes_with_keywords_loaded.add( filetype) extra_data[ 'syntax_keywords']=list( syntax_parse.SyntaxKeywordsForCurrentBuffer())", "label": 0}, {"snippet_id": 88816, "code": " name, labels=None, cmd='', log_config=None): \"\"\"Create a new workunit under the calling thread's current workunit. :API: public \"\"\" with self.run_tracker.new_workunit(name=name, labels=labels, cmd=cmd", "label": 0}, {"snippet_id": 92440, "code": " expected_output) self.assertEqual(os.environ['XXX'], expected_output) def test_simple_pushd(self): pre_cwd=os.getcwd() with temporary_dir() as tempdir: with pushd(tempdir) as path: self.assertEqual(tempdir", "label": 0}, {"snippet_id": 92374, "code": " self.assertIn('USER', os.environ) with hermetic_environment_as(**dict(AAA='333')): output=subprocess.check_output('env', shell=True).decode('utf-8') self.assertNotIn('USER=', output) self.assertIn('AAA", "label": 1}, {"snippet_id": 56138, "code": " if job.subworkflow_input[f] is self] class Rules: \"\"\" A namespace for rules so that they can be accessed via dot notation. \"\"\" pass def srcdir(path): \"\"\"Return the absolute path, relative to the source", "label": 0}, {"snippet_id": 78805, "code": "\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself.trueRegex=trueRegex \t\tself.notRegex=notRegex \t\tself", "label": 0}, {"snippet_id": 42805, "code": ": \"\"\" Set an item to be input or output. Arguments item --the item inoutput --either a Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self", "label": 0}, {"snippet_id": 48447, "code": " SyntaxError(\"Params have to be specified as strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items():", "label": 0}, {"snippet_id": 69964, "code": "): \"\"\" shine preinstall -f <filesystem name> -R \"\"\" def __init__(self): RemoteCommand.__init__(self) self.fs_support=FS(self) def get_name(self): return \"preinstall\" def get_desc(self): return \"Preinstall", "label": 0}, {"snippet_id": 3766, "code": ".cmd(\"send-keys\", \"\", \"C-c\") window.kill_window() def start_window(window, cmd, log_file, comp_name): setup_log(window, log_file, comp_name) window.cmd(\"send-keys\", cmd, \"Enter\") def find_window(session,", "label": 0}, {"snippet_id": 27996, "code": "\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if", "label": 0}, {"snippet_id": 64780, "code": ", RECOVERING: RC_FAILURE, OFFLINE: RC_FAILURE, TARGET_ERROR: RC_TARGET_ERROR, CLIENT_ERROR: RC_CLIENT_ERROR, RUNTIME_ERROR: RC_RUNTIME_ERROR} def fs_status_to_rc(self, status): return self.target_status_rc_map", "label": 0}, {"snippet_id": 52473, "code": " @property def shellcmd(self): \"\"\" Return the shell command. \"\"\" try: return(self.format_wildcards(self.rule.shellcmd) if self.rule.shellcmd else None) except AttributeError as ex: raise RuleException(str(ex),", "label": 0}, {"snippet_id": 37300, "code": ": products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened.", "label": 0}, {"snippet_id": 29150, "code": " follow_symlinks=os.chmod not in os.supports_follow_symlinks) def IOFile(file, rule=None): f=_IOFile(file) f.rule=rule return f class _IOFile(str): \"\"\" A file that is either input or output of a rule. \"\"\"", "label": 0}, {"snippet_id": 3434, "code": ": self.logger.error(\" Config not loaded yet!\") elif not self.session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self", "label": 0}, {"snippet_id": 20587, "code": " owned=True, **kwargs) @classmethod def create_server(cls, addr=None, **kwargs): if addr is None: addr=(cls.HOST, cls.PORT) conn=DebugSessionConnection.create_server(addr, **kwargs) return cls(conn, owned", "label": 0}, {"snippet_id": 25071, "code": ".station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES) def update(self): \"\"\"Call the", "label": 1}, {"snippet_id": 85001, "code": "='2.12', choices=['2.10', '2.11', '2.12', 'custom'], fingerprint=True, help='The scala platform version. If --version=custom, the targets ' '//:scala-library, //:scalac, //:scala-repl and //:scalastyle", "label": 0}, {"snippet_id": 22904, "code": " del_account(self, username): \"\"\"Deletes a user account. Note that the default method also checks for a \"system level\" of the user; based on the value of UID_MIN in /etc/login.defs. In our env, all user", "label": 0}, {"snippet_id": 60975, "code": " expectation.\"\"\" raise NotImplementedError @abc.abstractmethod def reset(self): \"\"\"Reset the backend state. After the reset the backend should be as if it was just constructed. Most importantly the quantum", "label": 0}, {"snippet_id": 20087, "code": "**kwargs): if addr is None: addr=self._addr assert addr.host=='localhost' self._session=self.SESSION.create_client(addr, **kwargs) def _detach(self): session=self._session if session is None: return self", "label": 0}, {"snippet_id": 38068, "code": ", wildcards.values())) def __lt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0", "label": 0}, {"snippet_id": 1608, "code": " add_newWifiConn(wifi_name,wifi_pass) return JsonResponse({\"STATUS\":\"SUCCESS\"}, safe=False) elif action=='login': print(action) username=escape(request.POST.get(\"username\")) password=escape(request.POST.get(", "label": 0}, {"snippet_id": 72011, "code": " log from pylinkirc.coremods import control, permissions @utils.add_cmd def disconnect(irc, source, args): \"\"\"<network> Disconnects the network <network>. When all networks are disconnected, PyLink will", "label": 0}, {"snippet_id": 89404, "code": "\"\"Represents a java distribution -either a JRE or a JDK installed on the local system. In particular provides access to the distribution's binaries; ie: java while ensuring basic constraints are met. For", "label": 0}, {"snippet_id": 18405, "code": " error_output=''.join( server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage", "label": 0}, {"snippet_id": 84928, "code": " version), classpath=classpath) def register_style_tool(version): cls.register_jvm_tool(register, cls._key_for_tool_version('scalastyle', version), classpath=[scala_style_jar]) super(ScalaPlatform, cls", "label": 1}, {"snippet_id": 51444, "code": " \"\"\" return temp(value) def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are", "label": 0}, {"snippet_id": 37487, "code": "(_item) if is_flagged(item, \"subworkflow\"): if output: raise SyntaxError( \"Only input files may refer to a subworkflow\") else: self.subworkflow_input[_item]=item.flags[\"subworkflow\"] inoutput.append(_item)", "label": 0}, {"snippet_id": 70051, "code": " import * from Base.RemoteCallEventHandler import RemoteCallEventHandler from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.Actions.Proxies.ProxyAction import * from", "label": 0}, {"snippet_id": 80217, "code": ":-1] if args.template: \targs.template=args.template[0] \tif args.template not in templatesNames: \t\tlogging.warning(\"Unknown template: %s\",args.template) \t\tcont=input(\"Use default templates instead ?[Y/n", "label": 0}, {"snippet_id": 82144, "code": "-vvv\",action=\"store_true\",required=False,dest=\"veryVeryVerbose\",help=\"Much verbose, very log, wow.\") parser.add_argument(\"-s\",\"--skip-recon\",action=\"store_true\",required=False,dest=\"skipRecon\",help=\"Skip", "label": 0}, {"snippet_id": 69496, "code": "(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self, cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list", "label": 0}, {"snippet_id": 95072, "code": "() command=cli_arguments[\"command\"] if command==\"config\": output_config_location=cli_arguments[\"output_config\"] overwrite_mode=cli_arguments[\"f\"] config.generate_default_config_file(output_location=output_config_location", "label": 0}, {"snippet_id": 67689, "code": " ev_starttarget_done(self, node, target): if self.verbose > 1: if target.status_info: print \"Start of %s %s(%s): %s\" %(target.type.upper(), target.get_id(), target.dev, target.status_info) else: print \"Start of %s %s", "label": 0}, {"snippet_id": 39590, "code": ".func return decorate def docstring(self, string): def decorate(ruleinfo): ruleinfo.docstring=string return ruleinfo return decorate def input(self, *paths, **kwpaths): def decorate(ruleinfo): ruleinfo", "label": 0}, {"snippet_id": 76514, "code": ".running.clear() self.wz_sock.close() self.sig_sock.close() def term(self): self.running.clear() class WZWorkerThread(WZWorkerBase, threading.Thread): def start(self, ctx, sig_addr, *args, **kvargs): self", "label": 0}, {"snippet_id": 61106, "code": " return expm(-1j * theta/2 * X) def fry(theta): r\"\"\"One-qubit rotation about the y axis. Args: theta(float): rotation angle Returns: array: unitary 2x2 rotation matrix:math:`e^{-i \\sigma_y \\theta/2}` \"", "label": 0}, {"snippet_id": 88713, "code": ".new_workunit_under_parent( name=parent_workunit_name, labels=[WorkUnitLabel.MULTITOOL], parent=background_root_workunit) workunit_parent=workunit_parent_ctx.__enter__() done_hook=lambda: workunit_parent_ctx.__exit__", "label": 0}, {"snippet_id": 84493, "code": "._working_directory def config_directory( self): return self._config_directory def new_file_path( self): return self.working_directory() def sep( self): return self._sep def version_path( self): return", "label": 0}, {"snippet_id": 9141, "code": " composite keywords bound with the number of occurrences found in the text string. :var ckw_db: list of KewordToken objects(they are supposed to be composite ones) :var fulltext: string to search in :skw_spans", "label": 0}, {"snippet_id": 23713, "code": "\"Failed to eject dvd: ret={0}\".format(retcode)) def restart_if(self, ifname): shellutil.run(\"/etc/rc.d/dhclient restart{0}\".format(ifname), chk_err=False) def get_total_mem(self): cmd=\"sysctl hw.physmem |awk", "label": 0}, {"snippet_id": 81592, "code": "(suffix,mime,payload) \t\tuploadRes=self.isASuccessfulUpload(fu[0].text) \t\tresult={\"uploaded\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"", "label": 1}, {"snippet_id": 89351, "code": ".util.memo import memoized_method, memoized_property from pants.util.meta import AbstractClass from pants.util.osutil import OS_ALIASES, normalize_os_name from pants.util.process_handler import subprocess", "label": 0}, {"snippet_id": 27065, "code": " self.station_data=None self.station=station def get_module_names(self): \"\"\"Return all module available on the API as a list.\"\"\" self.update() return self.data.keys() @Throttle(MIN_TIME_BETWEEN_UPDATES)", "label": 1}, {"snippet_id": 61256, "code": ": raise ValueError(\"Operator must be unitary.\") return U def hermitian(*args): r\"\"\"Input validation for an arbitary Hermitian observable. Args: args(array): square hermitian matrix. Returns: array: square", "label": 0}, {"snippet_id": 94852, "code": ".kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow() ui=hyperGUI.UiMainWindow() ui.ui_init(main_window", "label": 0}, {"snippet_id": 52366, "code": " if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input[f_] self._hash=self.rule.__hash__() if True or not", "label": 0}, {"snippet_id": 82972, "code": " for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent.futures", "label": 1}, {"snippet_id": 78599, "code": " self.schedule(self.dologin) self.schedule(self.wait_loop) self.schedule(self.counter_ticker.tick) try: self.perform_tasks() except NetError as e: self.log.error(e) except WorkerInterrupt as e: self.log", "label": 0}, {"snippet_id": 95264, "code": " import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates directories for the path specified. :param path:", "label": 1}, {"snippet_id": 76703, "code": " default=0, help='EvaluatorProxy count') parser.add_argument('--upload-avatar', action='store_true', default=False, help='Upload random avatar after registration') parser.add_argument('--av-dir', default=", "label": 0}, {"snippet_id": 31088, "code": " previously created dynamic files. \"\"\" self.check_protected_output() unexpected_output=self.dag.reason(self).missing_output.intersection( self.existing_output) if unexpected_output: logger.warning( \"Warning:", "label": 0}, {"snippet_id": 50854, "code": " be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os.access(self.file, os.W_OK) @property def mtime(self): return", "label": 1}, {"snippet_id": 19990, "code": " RuntimeError('not attached') if adapter is None: adapter=self._adapter assert adapter is not None if not self._session.is_client: raise RuntimeError('detach not supported') self._detach() def _close(self)", "label": 0}, {"snippet_id": 81690, "code": ".detectCodeExec(url,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[\"codeExec\"]=True \t\t\t\tif secondUrl: \t\t\t\t\texecutedCode=self.detectCodeExec(secondUrl,codeExecRegex) \t\t\t\t\tif executedCode: \t\t\t\t\t\tresult[", "label": 0}, {"snippet_id": 7157, "code": "\"raw\"]=(single_keywords_p, composite_keywords_p, author_keywords, acronyms) return my_styles def build_marc(recid, single_keywords, composite_keywords, spires=False, author_keywords=None, acronyms=None):", "label": 0}, {"snippet_id": 36821, "code": " s.append(\"Rules with a run or shell declaration but no output \" \"are always executed.\") else: if self.missing_output: s.append(\"Missing output files:{}\".format( \", \".join(self.missing_output))) if self", "label": 0}, {"snippet_id": 78027, "code": "(name): id_=d.bm_id_forum.get_key(name) int(id_, 10) return id_ r_udf=re.compile(regexp.udf_prefix) def affu(urls): for user, domain, forum in r_udf.findall(urls): if domain not in forums: forums[domain]", "label": 0}, {"snippet_id": 84808, "code": " major_version_info(full_version='2.10.6'), '2.11': major_version_info(full_version='2.11.12'), '2.12': major_version_info(full_version='2.12.4'), } scala_style_jar=JarDependency('org.scalastyle', 'scalastyle_2.11", "label": 0}, {"snippet_id": 47890, "code": ".version=other.version self._log=other._log self._benchmark=other._benchmark self.wildcard_names=set(other.wildcard_names) self.lineno=other.lineno self.snakefile=other.snakefile self.run_func=other.run_func", "label": 0}, {"snippet_id": 78179, "code": " exc, regexp import re class UniWipe(WipeSkel): def __init__(self, forums, targets, sbjfun, msgfun, *args, **kvargs): self.sbjfun=sbjfun self.msgfun=msgfun self.forums=forums self.targets=(type(targets)=", "label": 0}, {"snippet_id": 65388, "code": ".Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand from Base.CommandRCDefs import * from Base.Support.View import View from Base.RemoteCallEventHandler import RemoteCallEventHandler", "label": 0}, {"snippet_id": 61332, "code": " frz, 'Rot': fr3 } class DefaultQubit(Device): \"\"\"Default qubit device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation. Must be specified", "label": 0}, {"snippet_id": 34273, "code": "(self, *args, **resources): def decorate(ruleinfo): ruleinfo.resources=(args, resources) return ruleinfo return decorate def priority(self, priority): def decorate(ruleinfo): ruleinfo.priority=priority", "label": 0}, {"snippet_id": 35304, "code": " arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1", "label": 0}, {"snippet_id": 62127, "code": " name='ProjectQ OpenQML plugin' short_name='projectq' api_version='0.1.0' plugin_version=__version__ author='Christian Gogolin' _capabilities={'backend': list([\"Simulator\", \"ClassicalSimulator\", \"IBMBackend", "label": 0}, {"snippet_id": 29354, "code": ".format(self.file, self.rule.name), lineno=self.rule.lineno, snakefile=self.rule.snakefile) else: raise e def touch_or_create(self): try: self.touch() except MissingOutputException: with open(self.file,", "label": 0}, {"snippet_id": 64391, "code": " __init__(self): self.cmd_list=[] self.cmd_dict={} self.cmd_optargs={} self._load() def __len__(self): \"Return the number of commands.\" return len(self.cmd_list) def __iter__(self): \"Iterate over available", "label": 0}, {"snippet_id": 42815, "code": " Namedlist of input or output items name --an optional name for the item \"\"\" inoutput=self.output if output else self.input if isinstance(item, str): if isinstance(item, _IOFile): self.dependencies[item]=item", "label": 0}, {"snippet_id": 25327, "code": " discovery_info=None): \"\"\"Set up the available Netatmo weather sensors.\"\"\" netatmo=hass.components.netatmo data=NetAtmoData(netatmo.NETATMO_AUTH, config.get(CONF_STATION, None)) dev=[] import pyatmo try", "label": 1}, {"snippet_id": 36460, "code": "(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output) def check_protected_output(self): protected", "label": 0}, {"snippet_id": 95927, "code": ". :param input_vcf_path: The input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion :type input_vcf_path: str ", "label": 0}, {"snippet_id": 49902, "code": "*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag", "label": 0}, {"snippet_id": 14954, "code": "': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers=_HEADERS", "label": 1}, {"snippet_id": 15282, "code": "._ycmd_keepalive=YcmdKeepalive() self._SetupServer() self._ycmd_keepalive.Start() def _SetupServer( self): server_port=utils.GetUnusedLocalhostPort() with tempfile.NamedTemporaryFile( delete=False) as options_file", "label": 0}, {"snippet_id": 59969, "code": "'projectq.ibmbackend' _gates=set([ key for(key,val) in operator_map.items() if val in[HGate, XGate, YGate, ZGate, SGate, TGate, SqrtXGate, SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for", "label": 0}, {"snippet_id": 59661, "code": ".backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]) def filter_kwargs_for_backend(self, kwargs): return", "label": 0}, {"snippet_id": 29314, "code": " dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self", "label": 1}, {"snippet_id": 72934, "code": " remote_filename in ftp_config.files: local_filename=remote_filename filepath=os.path.join(local_directory, local_filename) if not os.path.exists(filepath): with open(filepath, \"wb\") as local_file: try:", "label": 0}, {"snippet_id": 48527, "code": " dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self", "label": 0}, {"snippet_id": 26506, "code": " def update(self): \"\"\"Get the latest data from NetAtmo API and updates the states.\"\"\" self.netatmo_data.update() data=self.netatmo_data.data.get(self.module_name) if data is None: _LOGGER.warning(\"No data", "label": 0}, {"snippet_id": 74547, "code": ".directory=runtime_config.ftp[\"directory\"] if \"file_delimiter\" in runtime_config.ftp: delimiter=runtime_config.ftp[\"file_delimiter\"] else: delimiter=\"|\" if \"files\" in runtime_config.ftp: files_str=str(runtime_config", "label": 0}, {"snippet_id": 82971, "code": "\"codeExecRegex\"] for t in templates if t[\"templateName\"]==a[\"templateName\"]][0] \t\t\tf=executor.submit(up.submitTestCase,suffix,mime,payload,codeExecRegex) \t\t\tf.a=a \t\t\tfutures.append(f) \t\tfor future in concurrent", "label": 1}, {"snippet_id": 39252, "code": " Include a snakefile. \"\"\" if not urllib.parse.urlparse(snakefile).scheme: if not os.path.isabs(snakefile) and self.included_stack: current_path=os.path.dirname(self.included_stack[-1]) snakefile=os.path", "label": 0}, {"snippet_id": 72542, "code": "\"setup\", help='Preparation and setting up of the data for the benchmark. It requires a configuration file.') data_setup_parser.add_argument(\"--config_file\", required=True, help=\"Location of the configuration", "label": 0}, {"snippet_id": 67401, "code": " import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Shine.FSUtils import create_lustrefs from Base.RemoteCommand import RemoteCommand", "label": 0}, {"snippet_id": 29302, "code": " ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode) for f in files: lchmod(os.path.join(self.file, f), mode", "label": 0}, {"snippet_id": 30799, "code": ".rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message \" \"of shell command:{}\".format", "label": 0}, {"snippet_id": 901, "code": "')[3].split(',') configuredwifi=get_allconfiguredwifi() wifi_aps=get_allAPs() return JsonResponse([{'users':userlist,'wifi':configuredwifi,'allwifiaps':wifi_aps}], safe=False) elif action=='deleteUser'", "label": 0}, {"snippet_id": 20274, "code": "*argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session is None argv=[ filename, ] ", "label": 0}, {"snippet_id": 56936, "code": ".__next__() except StopIteration: return 0 if tag.pk==self.counter['tag']: return self.counter[self.key] return 0 def get_value_by_type(val, v_type): \"\"\" Exampls: 1. get_value_by_type('True', 'bool') (1,", "label": 0}, {"snippet_id": 18898, "code": " def load_source(source): \"\"\" Common entry point for loading some form of raw swagger schema. Supports: -python object(dictionary-like) -path to yaml file -path to json file -file object(json or yaml). ", "label": 0}, {"snippet_id": 40058, "code": ".getsize(self.file) def check_broken_symlink(self): \"\"\" Raise WorkflowError if file is a broken symlink. \"\"\" if not self.exists and lstat(self.file): raise WorkflowError(\"File{} seems to be a broken symlink.", "label": 1}, {"snippet_id": 79646, "code": "\"[TEMPLATES]\\nTemplates are malicious payloads meant to be uploaded on the scanned remote server. Code execution detection is done based on the expected output of the payload.\" templatesSection +=\"\\n\\tDefault", "label": 0}, {"snippet_id": 19111, "code": ", request_method='get', raw_request=None): \"\"\" Validate the response of an api call against a swagger schema. \"\"\" request=None if raw_request is not None: request=normalize_request(raw_request) response", "label": 0}, {"snippet_id": 13340, "code": "\"GITHUB_TOKEN\"]} auth=(os.environ[\"BOT_USERNAME\"], os.environ[\"BOT_PASSWORD\"]) fullname=data.get(\"fork_fullname\") for file, new_file in data[\"results\"].items(): url=\"https://api.github.com/repos/{}/contents/{", "label": 0}, {"snippet_id": 13401, "code": " content_code, \"sha\": sha_blob, \"branch\": data.get(\"new_branch\"), } r=requests.put(url, json=request_json, headers=headers, auth=auth) def create_pr(data): headers={\"Authorization\": \"token \" +os.environ[", "label": 0}, {"snippet_id": 7604, "code": "('\\n', '') def _get_singlekws(skw_matches, spires=False): \"\"\" :var skw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords \"\"\" output", "label": 0}, {"snippet_id": 55629, "code": " def subworkflow(self, name, snakefile=None, workdir=None): sw=Subworkflow(self, name, snakefile, workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self", "label": 0}, {"snippet_id": 82270, "code": "=\"store_true\",dest=\"manualFormDetection\",help=\"Disable automatic form detection. Useful when automatic detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs", "label": 0}, {"snippet_id": 25983, "code": "['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif data['rf_status", "label": 0}, {"snippet_id": 41013, "code": "(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self", "label": 0}, {"snippet_id": 42151, "code": ".wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self): return self._hash @staticmethod def expand_dynamic", "label": 0}, {"snippet_id": 94668, "code": ".makedirs(directory) def main(): logger=logging.getLogger(__name__) logger.setLevel(logging.DEBUG) parser=argparse.ArgumentParser() parser.add_argument(\"--config\", '-c', type=str, default='test.yaml', help", "label": 0}, {"snippet_id": 66551, "code": ", nodes=nodes, indexes=None, event_handler=eh) if nodes and not nodes.issubset(fs_conf.get_client_nodes()): raise CommandException(\"%s are not client nodes of filesystem '%s'\" % \\ (nodes -fs_conf.get_client_nodes", "label": 0}, {"snippet_id": 1632, "code": "\"password\")) output='' \"\"\"Tries to authenticate a user. Returns True if the authentication succeeds, else the reason (string) is returned.\"\"\" try: enc_pwd=spwd.getspnam(username)[1] if enc_pwd in[\"NP\", \"!\"", "label": 0}, {"snippet_id": 66949, "code": "\"Iterate over available commands.\" for cmd in self.cmd_list: yield cmd def _load(self): for cmdobj in commandList: self.register(cmdobj()) def get(self, name): return self.cmd_dict[name] def register(self", "label": 0}, {"snippet_id": 48449, "code": " strings.\") @property def log(self): return self._log def set_log(self, *logs, **kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name", "label": 0}, {"snippet_id": 44852, "code": ".input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo", "label": 0}, {"snippet_id": 35600, "code": "(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None: setattr(self", "label": 0}, {"snippet_id": 49421, "code": " list_version_changes=False, list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False,", "label": 0}, {"snippet_id": 53767, "code": " inoutput.add_name(name) else: try: start=len(inoutput) for i in item: self._set_inoutput_item(i, output=output) if name: inoutput.set_name(name, start, end=len(inoutput)) except TypeError: raise SyntaxError", "label": 0}, {"snippet_id": 78829, "code": "\tself.uploadsFolder=uploadsFolder \t\tself.size=size \t\tself.validExtensions=[] \t\tself.httpRequests=0 \t\tself.codeExecUrlPattern=None \t\tself.logLock=Lock() \t\tself.stopThreads=False \t\tself.shouldLog=True \t \tdef", "label": 0}, {"snippet_id": 9646, "code": "(auth_field, output_complete[\"Author keywords\"]), (acro_field, output_complete[\"Acronyms\"])): if keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items()", "label": 0}, {"snippet_id": 85349, "code": ".targets.scala_jar_dependency import ScalaJarDependency from pants.backend.jvm.tasks.classpath_products import ClasspathEntry from pants.backend.jvm.tasks.classpath_util import ClasspathUtil from pants", "label": 0}, {"snippet_id": 11625, "code": " open(self.output_file, 'w') as f: for line in lines: f.write(line +\"\\n\") LOG.debug(\"Created %s\" % self.output_file) def generate_config(): arg=docopt(__doc__, version='0.1.0') start_time=datetime.now(", "label": 0}, {"snippet_id": 11378, "code": "(\"MonitoringConfigGenerator start: reading from %s, writing to %s\" % (self.source, self.target_dir)) def _is_newer(self, header_source, hostname): if not hostname: raise NoSuchHostname('hostname not found", "label": 0}, {"snippet_id": 43435, "code": " if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output) if match: l=self.get_wildcard_len(match.groupdict()) if not bestmatch or", "label": 0}, {"snippet_id": 83888, "code": " def stop_job( self, job): job_ext_output_metadata=job.get_external_output_metadata() if job_ext_output_metadata: pid=job_ext_output_metadata[0].job_runner_external_pid if pid in[ None, '']: log.warning", "label": 0}, {"snippet_id": 41197, "code": " hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)) class InputFiles(Namedlist): pass class OutputFiles(Namedlist): pass class Wildcards(Namedlist): pass class Params(Namedlist): pass", "label": 0}, {"snippet_id": 60445, "code": "\"\" import numpy as np from openqml import Device, DeviceError from openqml import Variable import strawberryfields as sf from strawberryfields.ops import(Catstate, Coherent, DensityMatrix, DisplacedSqueezed", "label": 0}, {"snippet_id": 611, "code": " print(rows) finalset=[] for row in rows: cursor.execute(common.Q_GET_DASHBOARD_CHART,[row[0],]) datasets=cursor.fetchall() print(datasets) data={'container_name': row[1], 'data': datasets} finalset.append", "label": 0}, {"snippet_id": 64600, "code": " files for file system %s have been installed \" \\ \"successfully%s.\" %(fs_conf.get_fs_name(), nodestr) if not install_nodes: print print \"Lustre targets summary:\" print \"\\t%d MGT on %s\" %(fs.mgt_count, fs", "label": 0}, {"snippet_id": 9175, "code": "], .. } or empty{} \"\"\" return keyworder.get_composite_keywords(ckw_db, fulltext, skw_spans) or{} def extract_abbreviations(fulltext): \"\"\"Extract acronyms from the fulltext :var fulltext: utf-8 string :return", "label": 0}, {"snippet_id": 67057, "code": " Configuration from Shine.Configuration.Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class", "label": 0}, {"snippet_id": 40700, "code": "*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values", "label": 0}, {"snippet_id": 22008, "code": "=skip_tags self.one_line=one_line self.tree=tree self.ask_sudo_pass=ask_sudo_pass self.ask_su_pass=ask_su_pass self.sudo=sudo self.sudo_user=sudo_user self.become=become self.become_method=become_method", "label": 0}, {"snippet_id": 53981, "code": "(item): try: item=item(wildcards_obj) except(Exception, BaseException) as e: raise InputFunctionException(e, rule=self) if not_iterable(item): item=[item] is_iterable=False for item_ in item: if not isinstance", "label": 0}, {"snippet_id": 76491, "code": " WorkerInterrupt as e: self.log.warn(e) except Exception as e: self.log.exception(e) self.log.info('Terminating') else: self.log.info('Aborted') self.running.set() self.unbind_methods() self.running.clear", "label": 0}, {"snippet_id": 79736, "code": "?',const=True,dest=\"proxyCreds\",help=\"Prompt for proxy credentials at runtime. Format: 'user:pass'\",type=valid_proxyCreds) parser.add_argument(\"-f\",\"--filesize\",metavar=\"integer\",nargs=1,default=[\"10\"]", "label": 0}, {"snippet_id": 54924, "code": ": forcerun=list() priorityrules=set(rules(prioritytargets)) priorityfiles=set(files(prioritytargets)) forcerules=set(rules(forcerun)) forcefiles=set(files(forcerun)) targetrules=set(chain(rules(targets", "label": 0}, {"snippet_id": 39861, "code": ".isabs(workdir): return os.path.abspath(os.path.join(self.workflow.basedir, workdir)) return workdir def target(self, paths): if not_iterable(paths): return flag(os.path.join(self.workdir, paths), \"subworkflow", "label": 0}, {"snippet_id": 82896, "code": "]]=templatefd.read() \ttemplatefd.close() \tnastyExt=template[\"nastyExt\"] \tnastyMime=getMime(extensions,nastyExt) \tnastyExtVariants=template[\"extVariants\"] \tfor t in techniques: \t\tfor nastyVariant in[nastyExt", "label": 1}, {"snippet_id": 44011, "code": " list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False, resources=None, notemp", "label": 0}, {"snippet_id": 72334, "code": " object %s', irc.name, netname) remoteirc.reply=types.MethodType(_remote_reply, remoteirc) world.services[args.service].call_cmd(remoteirc, remoteirc.pseudoclient.uid, ' '.join(args.command)) finally: log", "label": 1}, {"snippet_id": 95065, "code": "/\" zarr_directory_setup=\"./data/zarr/\" zarr_directory_benchmark=\"./data/zarr_benchmark/\" cli_arguments=get_cli_arguments() command=cli_arguments[\"command\"] if command==\"config\": output_config_location=cli_arguments", "label": 1}, {"snippet_id": 42530, "code": " io_, dynamic_io_=get_io(branch) expansion=defaultdict(list) for i, f in enumerate(io): if f in dynamic_io: try: for e in reversed(expand(f, zip, **wildcards)): expansion[i].append(IOFile(e, rule=branch))", "label": 1}, {"snippet_id": 49240, "code": " snakefile=None): \"\"\" Add a rule. \"\"\" if name is None: name=str(len(self._rules) +1) if self.is_rule(name): raise CreateRuleException( \"The name{} is already used by another rule\".format(name)) rule=Rule", "label": 0}, {"snippet_id": 46330, "code": " value in match.groupdict().items(): getattr(wildcards, name).append(value) return wildcards class Namedlist(list): \"\"\" A list that additionally provides functions to name items. Further, it is hashable", "label": 0}, {"snippet_id": 62348, "code": "/ProjectQ/issues/2 Drawback: This is probably rather resource intensive. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': pq.ops.All(pq.ops.Measure) | self.reg def", "label": 0}, {"snippet_id": 25543, "code": "='temperature': self._state=round(data['Temperature'], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state", "label": 0}, {"snippet_id": 67845, "code": ".debug_support.has_debug()) if hasattr(eh, 'pre'): eh.pre(fs) status=fs.start(mount_options=mount_options, mount_paths=mount_paths) rc=self.fs_status_to_rc(status) if rc > result: result=rc if rc==RC_OK: if vlevel ", "label": 0}, {"snippet_id": 59165, "code": " PluginAPI._capabilities['backend'] for a list of backend options. Functions --------- .. autosummary:: init_plugin Classes ------- .. autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as", "label": 0}, {"snippet_id": 47420, "code": " to_remove: f.remove() def format_wildcards(self, string, **variables): \"\"\" Format a string with variables from the job. \"\"\" _variables=dict() _variables.update(self.rule.workflow.globals) _variables.update", "label": 0}, {"snippet_id": 2997, "code": " log_file=(\"%s/%s\" %(TMP_LOG_PATH, comp['name'])) window=find_window(self.session, comp['name']) if window: self.logger.debug(\"Restarting '%s' in old window\" % comp['name']) start_window(window, comp['cmd", "label": 0}, {"snippet_id": 86077, "code": "(self, compile_context): \"\"\"Override write_extra_resources to produce plugin and annotation processor files.\"\"\" target=compile_context.target if isinstance(target, JavacPlugin): self._write_javac_plugin_info", "label": 0}, {"snippet_id": 18407, "code": " server_stderr_file.readlines()[ : -NUM_YCMD_STDERR_LINES_ON_CRASH]) vimsupport.PostMultiLineNotice( SERVER_CRASH_MESSAGE_STDERR_FILE + error_output) else: vimsupport.PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR", "label": 0}, {"snippet_id": 83369, "code": ", input_files=self.get_input_files(job_wrapper), client_outputs=self.__client_outputs(client, job_wrapper), working_directory=job_wrapper.working_directory, tool=job_wrapper.tool, config_files=job_wrapper", "label": 0}, {"snippet_id": 49132, "code": " self.basedir=os.path.dirname(snakefile) self.snakefile=os.path.abspath(snakefile) self.snakemakepath=snakemakepath self.included=[] self.included_stack=[] self.jobscript=jobscript self.persistence=None", "label": 0}, {"snippet_id": 82221, "code": "--user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.\",type=str,default=[requests.utils.default_user_agent()]) exclusiveUserAgentsArgs.add_argument", "label": 0}, {"snippet_id": 92341, "code": ", '-c', 'import os; print(\"HORK\" in os.environ)'], stdout=output).wait() output.seek(0) self.assertEqual('False\\n', output.read()) def test_hermetic_environment(self): self.assertIn('USER', os.environ)", "label": 1}, {"snippet_id": 81401, "code": ".append(ext) \t\t\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the", "label": 0}, {"snippet_id": 6572, "code": " text_lines: source=entry.split(\"/\")[-1] process_lines() def get_keywords_from_local_file(local_file, taxonomy_name, output_mode=\"text\", output_limit=bconfig.CFG_BIBCLASSIFY_DEFAULT_OUTPUT_NUMBER, spires", "label": 0}, {"snippet_id": 45140, "code": "(self, *logs, **kwlogs): def decorate(ruleinfo): ruleinfo.log=(logs, kwlogs) return ruleinfo return decorate def shellcmd(self, cmd): def decorate(ruleinfo): ruleinfo.shellcmd=cmd return ruleinfo return", "label": 0}, {"snippet_id": 15223, "code": " SHUT DOWN(restart with:YcmRestartServer). ' + 'Stderr(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer", "label": 0}, {"snippet_id": 8123, "code": " xml): tmp_dir=os.path.dirname(filename) if not os.path.isdir(tmp_dir): os.mkdir(tmp_dir) file_desc=open(filename, \"w\") file_desc.write(xml) file_desc.close() def get_tmp_file(recid): tmp_directory=\"%s", "label": 0}, {"snippet_id": 46138, "code": "**wildcards --the wildcards as keyword arguments with their values as lists \"\"\" filepatterns=args[0] if len(args)==1: combinator=product elif len(args)==2: combinator=args[1] if isinstance(filepatterns", "label": 0}, {"snippet_id": 41012, "code": " self.set_name(name, len(self) -1) def set_name(self, name, index, end=None): \"\"\" Set the name of an item. Arguments name --a name index --the item index \"\"\" self._names[name]=(index, end) if end is None", "label": 0}, {"snippet_id": 42714, "code": "(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output -", "label": 0}, {"snippet_id": 8755, "code": " output_mode=output_mode, output_limit=output_limit, spires=spires, match_mode=match_mode, no_cache=no_cache, with_author_keywords=with_author_keywords, rebuild_cache=rebuild_cache, only_core_tags=only_core_tags,", "label": 0}, {"snippet_id": 68060, "code": "][-n <nodes>][-qv] \"\"\" def __init__(self): FSLiveCommand.__init__(self) self.view_support=View(self) def get_name(self): return \"status\" def get_desc(self): return \"Check for file system target status.", "label": 0}, {"snippet_id": 63064, "code": "\" return JobDestination( runner=\"lwr\", params=url_to_destination_params( url)) def check_watched_item(self, job_state): try: client=self.get_client_from_state(job_state) if hasattr(self.client_manager,", "label": 0}, {"snippet_id": 52263, "code": "=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is None else Wildcards(fromdict=format_wildcards)) (self.input, self.output, self.params, self.log, self", "label": 0}, {"snippet_id": 22158, "code": " def __init__(self, conf): super(AnsiblePlugin, self).__init__(conf) def generate_ansible_playbook_from_template(self, template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv", "label": 0}, {"snippet_id": 48712, "code": "={ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log", "label": 0}, {"snippet_id": 5626, "code": ".core: output[skw.output(spires)]=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents", "label": 0}, {"snippet_id": 38213, "code": " NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake", "label": 0}, {"snippet_id": 42973, "code": " def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name)", "label": 0}, {"snippet_id": 90619, "code": "::class:`Distribution.Error` if no suitable java distribution could be found. \"\"\" def _get_stricter_version(a, b, name, stricter): version_a=_parse_java_version(name, a) version_b=_parse_java_version(name", "label": 0}, {"snippet_id": 73315, "code": "=pathlib.Path(input_dir).glob(\"**/*.vcf\") for path in pathlist_vcf_input: path_input_str=str(path) filename_str=path_leaf(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy", "label": 0}, {"snippet_id": 5109, "code": " keywords and len(keywords) and field: tag, ind1, ind2=_parse_marc_code(field) for kw, info in keywords.items(): output.append(kw_template %(tag, ind1, ind2, encode_for_xml(provenience), encode_for_xml", "label": 0}, {"snippet_id": 7968, "code": " filtered_kw_matches={} for kw_match, info in iteritems(kw_matches): if not kw_match.nostandalone: filtered_kw_matches[kw_match]=info return filtered_kw_matches def _skw_matches_comparator(kw0, kw1): \"\"\" Compare", "label": 0}, {"snippet_id": 56886, "code": " tag and annotated by key e.g. TestPlanTag, TestCaseTag ot TestRunTag :type test_tags: QuerySet \"\"\" self.key=key self.test_tags=iter(test_tags) self.counter={'tag': 0} def calculate_tag_count(self, tag", "label": 0}, {"snippet_id": 86938, "code": " sub-target incremental compilation, which dramatically ' 'improves compile performance while changing large targets. When unset, ' 'changed targets will be compiled with an empty output directory, as if", "label": 0}, {"snippet_id": 20902, "code": ":{})'.format(command, seq) with self._wait_for_message(match, handlername, **kwargs): yield result def _close(self): if self._owned: try: self._conn.close() except ClosedError: pass if self._listenerthread", "label": 0}, {"snippet_id": 29873, "code": ") def expand(*args, **wildcards): \"\"\" Expand wildcards in given filepatterns. Arguments *args --first arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard", "label": 0}, {"snippet_id": 39076, "code": "*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self.persistence.params_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True scheduler=JobScheduler(self, dag", "label": 0}, {"snippet_id": 73328, "code": "(path_input_str) path_vcf_str=str(pathlib.Path(output_dir, filename_str)) shutil.copy(path_input_str, path_vcf_str) def path_head(path): head, tail=os.path.split(path) return head def path_leaf(path): head", "label": 0}, {"snippet_id": 42209, "code": ".derived=True def __str__(self): s=list() if self.forced: s.append(\"Forced execution\") else: if self.noio: s.append(\"Rules with neither input nor \" \"output files are always executed.\") elif self.nooutput: s", "label": 0}, {"snippet_id": 33363, "code": " notemp=notemp) self.persistence=Persistence( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes", "label": 0}, {"snippet_id": 68410, "code": " elif target.state==MOUNTED: t_online.append(target) elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\"", "label": 0}, {"snippet_id": 65667, "code": ".view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs): \"\"\" View: lustre targets \"\"\" print \"FILESYSTEM TARGETS(%s)\" % fs.fs_name class target_dict(dict): def __lt__", "label": 1}, {"snippet_id": 46946, "code": ".touch_output.add(f) for f in self.input: f_=self.ruleio[f] if f_ in self.rule.dynamic_input: self.dynamic_input.add(f) if f_ in self.rule.subworkflow_input: self.subworkflow_input[f]=self.rule.subworkflow_input", "label": 0}, {"snippet_id": 38400, "code": " clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename, prefix=\"Error in ruleorder definition.\") def add_rule(self, name=None, lineno=None, snakefile=None): \"\"\" Add a rule. \"\"\" if", "label": 0}, {"snippet_id": 30872, "code": ".rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill) if not expansion: yield f_ for f, _ in expansion: yield IOFile(f", "label": 1}, {"snippet_id": 31227, "code": "(variables) try: return format(string, **_variables) except NameError as ex: raise RuleException(\"NameError: \" +str(ex), rule=self.rule) except IndexError as ex: raise RuleException(\"IndexError: \" +str(ex)", "label": 0}, {"snippet_id": 52252, "code": "=dag self.targetfile=targetfile self.wildcards_dict=self.rule.get_wildcards(targetfile) self.wildcards=Wildcards(fromdict=self.wildcards_dict) self._format_wildcards=(self.wildcards if format_wildcards is", "label": 0}, {"snippet_id": 63671, "code": " job\", exception=True) def fail_job( self, job_state): \"\"\" Seperated out so we can use the worker threads for it. \"\"\" self.stop_job( self.sa_session.query( self.app.model.Job).get( job_state.job_wrapper", "label": 0}, {"snippet_id": 51344, "code": ")) return re.sub(_wildcard_regex, format_match, pattern) def not_iterable(value): return isinstance(value, str) or not isinstance(value, Iterable) class AnnotatedString(str): def __init__(self, value):", "label": 0}, {"snippet_id": 22331, "code": " All configuration happens in mcpd so we need to wait that this is available before we go provisioning the system. I call this method at the first opportunity I have(during the DVD mounting call). This", "label": 0}, {"snippet_id": 29132, "code": " os.supports_follow_symlinks) def lutime(f, times): return os.utime(f, times, follow_symlinks=os.utime not in os.supports_follow_symlinks) def lchmod(f, mode): return os.chmod(f, mode, follow_symlinks=os", "label": 0}, {"snippet_id": 52304, "code": ".threads=self.resources_dict[\"_cores\"] self.resources=Resources(fromdict=self.resources_dict) self._inputsize=None self.dynamic_output, self.dynamic_input=set(), set() self.temp_output, self.protected_output", "label": 0}, {"snippet_id": 10211, "code": ".items(): if kw.core: matches[kw]=info return matches def _signature(): \"\"\"Print out the bibclassify signature. return 'bibclassify v%s' %(bconfig.VERSION,) def clean_before_output(kw_matches): \"\"\"Return a", "label": 0}, {"snippet_id": 88572, "code": " wildcard selectors: or::, the targets globbed by the wildcards are considered to be target roots. :API: public \"\"\" return self._target_roots @property def console_outstream(self): \"\"\"Returns the output", "label": 0}, {"snippet_id": 17944, "code": "=='POST': return BaseRequest.session.post( _BuildUri( handler), data=ToUtf8Json( data), headers=_HEADERS, timeout=timeout) if method=='GET': return BaseRequest.session.get( _BuildUri( handler), headers", "label": 1}, {"snippet_id": 23787, "code": ": raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def set_scsi_disks_timeout(self, timeout): if self._scsi_disks_timeout_set: return ret, output=shellutil.run_get_output('sysctl kern", "label": 0}, {"snippet_id": 47099, "code": " expanded_output(self): \"\"\" Iterate over output files while dynamic output is expanded. \"\"\" for f, f_ in zip(self.output, self.rule.output): if f in self.dynamic_output: expansion=self.expand_dynamic( f_, restriction", "label": 0}, {"snippet_id": 53133, "code": " snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles, Wildcards, Params, Log from snakemake.io import apply_wildcards, is_flagged", "label": 0}, {"snippet_id": 7019, "code": "=False, only_core_tags=False): \"\"\"Returns a formatted string representing the keywords according to the chosen style. This is the main routing call, this function will also strip unwanted keywords before", "label": 0}, {"snippet_id": 12314, "code": "/blob/{}{}\" data[filename +\"_link\"]=url.format(repository, after_commit_hash, file) os.remove(\"file_to_check.py\") def prepare_comment(request, data, config): \"\"\"Construct the string of comment i.e. its", "label": 0}, {"snippet_id": 75839, "code": " b'') s.send_multipart(msg) t.tick() while self.running.is_set(): p(timeout*1000) if rs.finished: if rs.retry: msg=self.wz.make_req_msg(interface, method, data, rs.accept, reqid) msg.insert(0, b'') s.send_multipart", "label": 0}, {"snippet_id": 77569, "code": "(self): users={} for d, uq in self.userqueues.items(): uqsize=uq.qsize() uds=[] for i in range(uqsize): uds.append(uq.get(False)) users[d]=uds with open(self.usersfile, 'wb') as f: f.write(pickle.dumps", "label": 0}, {"snippet_id": 36660, "code": ", rule=self.rule) def properties(self, omit_resources=\"_cores _nodes\".split()): resources={ name: res for name, res in self.resources.items() if name not in omit_resources } params={name: value for name", "label": 0}, {"snippet_id": 85549, "code": " @classmethod def _compiler_interface(cls, products): return cls.tool_jar_from_products(products, 'compiler-interface', cls.options_scope) def create(self, products): \"\"\"Create a Zinc instance from products", "label": 0}, {"snippet_id": 79571, "code": "=BeautifulSoup(html,'html.parser') \t\tdetectedForms=soup.find_all(\"form\") \t\treturnForms=[] \t\tif len(detectedForms) > 0: \t\t\tfor f in detectedForms: \t\t\t\tfileInputs=f.findChildren(\"input\",{\"type\":\"file\"}) ", "label": 0}, {"snippet_id": 21099, "code": "(timeout * 10)): time.sleep(0.1) messages=[] not_ready=(a for a in awaitables if a._event is not None and not a._event.is_set()) for awaitable in not_ready: if isinstance(awaitable, AwaitableEvent): messages", "label": 0}, {"snippet_id": 22098, "code": ".Inventory( loader=self.loader, variable_manager=self.variable_manager, host_list='/etc/ansible/hosts' ) self.variable_manager.set_inventory(self.inventory) pb_dir=os.path.abspath('.') playbook_path=\"%s/%s", "label": 0}, {"snippet_id": 64511, "code": ": raise CommandHelpException(\"Syntax error.\", command) else: command=self.get(opt) next_is_arg=False except KeyError, e: raise CommandNotFoundError(opt) command.parse(new_args) return command.execute()", "label": 1}, {"snippet_id": 40217, "code": ")) return IOFile(apply_wildcards(f, wildcards, fill_missing=fill_missing, fail_dynamic=fail_dynamic, dynamic_fill=self.dynamic_fill), rule=self.rule) def get_wildcard_names(self): return get_wildcard_names", "label": 1}, {"snippet_id": 12946, "code": "\"public\"]=True REQUEST_JSON[\"files\"]={} REQUEST_JSON[\"description\"]=\"In response to @{0}'s comment:{1}\".format( data[\"reviewer\"], data[\"review_url\"]) for file, diffs in data[\"diff\"].items(): if len(diffs", "label": 0}, {"snippet_id": 4, "code": " from django.http import HttpResponse, JsonResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from", "label": 0}, {"snippet_id": 84675, "code": " list_file_out.write(input_file) list_file_out.write('\\n') list_file_snapshot=self.context._scheduler.capture_snapshots(( PathGlobsAndRoot( PathGlobs(('input_files_list',)), text_type(tmpdir), ), ))[0]", "label": 0}, {"snippet_id": 28192, "code": "':['Rain', 'mm', 'mdi:weather-rainy', None], 'sum_rain_1':['sum_rain_1', 'mm', 'mdi:weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi", "label": 0}, {"snippet_id": 18983, "code": " else: raw_source=response.content else: raw_source=source try: try: return json.loads(raw_source) except ValueError: pass try: return yaml.load(raw_source) except(yaml.scanner.ScannerError, yaml.parser", "label": 1}, {"snippet_id": 1979, "code": "(rows, safe=False) elif action=='getContainerTop': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_GET_CONTAINER_ID) rows=cursor.fetchall() resultset=", "label": 0}, {"snippet_id": 48535, "code": " _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards", "label": 0}, {"snippet_id": 58561, "code": "','.join([str(self.case_run_1.pk), str(self.case_run_2.pk)])}) self.assertJSONEqual( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 0, 'response': 'ok'}) case_run_ct=ContentType.objects", "label": 0}, {"snippet_id": 8609, "code": ". its two main methods are output_keywords_for_sources and get_keywords_from_text. The first one output keywords for a list of sources(local files or URLs, PDF or text) while the second one outputs the", "label": 0}, {"snippet_id": 48533, "code": " isinstance(f, _IOFile): return IOFile(f, rule=self) else: return f.apply_wildcards(wildcards, fill_missing=f in self.dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems", "label": 0}, {"snippet_id": 67331, "code": " fs_status_to_rc(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh", "label": 0}, {"snippet_id": 11316, "code": " monitoring_config_generator.settings import CONFIG EXIT_CODE_CONFIG_WRITTEN=0 EXIT_CODE_ERROR=1 EXIT_CODE_NOT_WRITTEN=2 LOG=logging.getLogger(\"monconfgenerator\") class MonitoringConfigGenerator(object): def __init__", "label": 0}, {"snippet_id": 75779, "code": " resumehandler(interface, method, data): self.log.info('Resume signal %s recieved', repr((interface, method, data))) raise Resume() self.wz.set_sig_handler(b'WZWorker', b'resume', term_handler) self.running.set(", "label": 1}, {"snippet_id": 74010, "code": " value provided for chunk_length in configuration.\\n\" \"Expected: \\\"default\\\" or integer value\") if \"chunk_width\" in runtime_config.vcf_to_zarr: chunk_width_str=runtime_config.vcf_to_zarr[\"chunk_width\"] if", "label": 0}, {"snippet_id": 42022, "code": "=dict() _variables.update(self.rule.workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self", "label": 0}, {"snippet_id": 63349, "code": " client) metadata_kwds=self.__build_metadata_configuration(client, job_wrapper, remote_metadata, remote_job_config) remote_command_params=dict( working_directory=remote_job_config['working_directory'],", "label": 0}, {"snippet_id": 86564, "code": " _JAVAC_PLUGIN_INFO_FILE='META-INF/services/com.sun.source.util.Plugin' _PROCESSOR_INFO_FILE='META-INF/services/javax.annotation.processing.Processor' logger=logging.getLogger(__name__) class BaseZincCompile(JvmCompile): ", "label": 1}, {"snippet_id": 89606, "code": "._maximum_version=_parse_java_version(\"maximum_version\", maximum_version) self._jdk=jdk self._is_jdk=False self._system_properties=None self._validated_binaries={} @property def jdk(self): self.validate", "label": 0}, {"snippet_id": 59643, "code": "\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self.eng is not None and self.backend==", "label": 0}, {"snippet_id": 73551, "code": "] Alt number:{}\".format(alt_number)) chunk_length=allel.vcf_read.DEFAULT_CHUNK_LENGTH if conversion_config.chunk_length is not None: chunk_length=conversion_config.chunk_length print(\"[VCF-Zarr] Chunk length", "label": 0}, {"snippet_id": 67255, "code": " print \"%s: Mount: %s\" %(node, client.status_info) else: print \"%s: FS %s succesfully mounted on %s\" %(node, client.fs.fs_name, client.mount_path) def ev_startclient_failed(self, node, client, rc, message)", "label": 1}, {"snippet_id": 19934, "code": " RuntimeError('debug client closed') if adapter is None: adapter=self._adapter elif self._adapter is not None: raise RuntimeError('already using managed adapter') if adapter is None: raise RuntimeError('debugger", "label": 0}, {"snippet_id": 67125, "code": "(fs_conf.get_cfg_filename(), nodes=install_nodes) if install_nodes: nodestr=\" on %s\" % install_nodes else: nodestr=\"\" print \"Configuration files for file system %s have been installed \" \\ \"successfully%s", "label": 0}, {"snippet_id": 13914, "code": " def PostDataToHandler( data, handler, timeout=_DEFAULT_TIMEOUT_SEC): return JsonFromFuture( BaseRequest.PostDataToHandlerAsync( data, handler, timeout)) @staticmethod def PostDataToHandlerAsync( data,", "label": 0}, {"snippet_id": 59763, "code": ": \"\"\"Resets the engine and backend After the reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.Simulator", "label": 0}, {"snippet_id": 19395, "code": "-vm_type', } PYDEVD_FLAGS={ '--DEBUG', '--DEBUG_RECORD_SOCKET_READS', '--cmd-line', '--module', '--multiproc', '--multiprocess', '--print-in-debugger-startup', '--save-signatures', '--save-threading', '--save", "label": 0}, {"snippet_id": 76742, "code": "('--conlimit', type=int, default=3, help='http_request conlimit') parser.add_argument('--noproxy-timeout', type=int, default=5, help='noproxy_rp timeout') parser.add_argument('--caprate_minp', type=int", "label": 0}, {"snippet_id": 55673, "code": " if ruleinfo.input: rule.set_input(*ruleinfo.input[0], **ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params", "label": 0}, {"snippet_id": 25556, "code": "'Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24': self._state=data['sum_rain_24'] elif self.type=='noise':", "label": 0}, {"snippet_id": 93085, "code": "(permissions=0o700) as f: self.assertEqual(0o700, os.stat(f.name)[0] & 0o777) with temporary_dir(permissions=0o644) as path: self.assertEqual(0o644, os.stat(path)[0] & 0o777) def test_exception_logging", "label": 0}, {"snippet_id": 71683, "code": ".CommandRCDefs import * from Lustre.FileSystem import FSRemoteError from ClusterShell.Task import * from ClusterShell.NodeSet import * import getopt import logging import re import sys def print_csdebug", "label": 1}, {"snippet_id": 85236, "code": " '{0}_{1}'.format(name, self.version) @property def repl(self): \"\"\"Return the repl tool key.\"\"\" return self._key_for_tool_version('scala-repl', self.version) def injectables(self, build_graph): if self", "label": 1}, {"snippet_id": 80068, "code": " exclusiveUserAgentsArgs=parser.add_mutually_exclusive_group() exclusiveUserAgentsArgs.add_argument(\"-U\",\"--user-agent\",metavar=\"useragent\",nargs=1,dest=\"userAgent\",help=\"User-agent to use while requesting the target.", "label": 0}, {"snippet_id": 87399, "code": " get_buildroot()) scala_path=self.scalac_classpath() compiler_interface=self._zinc.compiler_interface compiler_bridge=self._zinc.compiler_bridge classes_dir=ctx.classes_dir analysis_cache=ctx.analysis_file", "label": 1}, {"snippet_id": 48266, "code": " temporary\") self.temp_output.add(_item) if is_flagged(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"", "label": 0}, {"snippet_id": 3368, "code": ".new_session( session_name=\"slave-session\" ) else: self.logger.info(\"No slave session found on server. Aborting\") exit(CheckState.STOPPED) if configfile: self.load_config(configfile) self.window_name=self.config", "label": 0}, {"snippet_id": 73800, "code": "\" if runtime_config is not None: if hasattr(runtime_config, \"ftp\"): if \"enabled\" in runtime_config.ftp: self.enabled=config_str_to_bool(runtime_config.ftp[\"enabled\"]) if \"server\" in runtime_config.ftp:", "label": 0}, {"snippet_id": 71602, "code": " vlevel=self.verbose_support.get_verbose_level() for fsname in self.fs_support.iter_fsname(): eh=self.install_eventhandler(None, GlobalUmountEventHandler(vlevel)) nodes=self.nodes_support.get_nodeset()", "label": 0}, {"snippet_id": 74991, "code": " overwrite=False): default_config_file_data=resource_string(__name__, 'config/benchmark.conf.default') if overwrite is None: overwrite=False if output_location is not None: if os.path.exists(output_location", "label": 0}, {"snippet_id": 18950, "code": "(source)), 'r') as source_file: raw_source=source_file.read() elif isinstance(source, six.string_types): parts=urlparse.urlparse(source) if parts.scheme and parts.netloc: response=requests.get(source) if", "label": 0}, {"snippet_id": 14177, "code": " from ycm.client.command_request import SendCommandRequest from ycm.client.completion_request import CompletionRequest from ycm.client.omni_completion_request import OmniCompletionRequest from ycm.client", "label": 0}, {"snippet_id": 92627, "code": " self.assertTrue(os.path.isdir(path), 'Temporary dir should be a dir and not a file.') self.assertFalse(os.path.exists(path), 'Temporary dir should not exist outside of the context.') def test_temporary_dir_without_cleanup", "label": 0}, {"snippet_id": 22261, "code": " os import platform import re import socket import struct import time try: import azurelinuxagent.common.logger as logger import azurelinuxagent.common.utils.shellutil as shellutil from azurelinuxagent", "label": 0}, {"snippet_id": 69246, "code": ".get_params_desc()) print print cmd.get_desc() def run_command(self, cmd_args): try: return self.cmds.execute(cmd_args) except getopt.GetoptError, e: print \"Syntax error: %s\" % e except CommandHelpException, e", "label": 0}, {"snippet_id": 3137, "code": "/etc/hosts file!\" % hostname) def run_on_localhost(self, comp): return self.is_localhost(comp['host']) def kill_remote_session_by_name(self, name, host): cmd=\"ssh -t %s 'tmux kill-session -t %s'\" %(host", "label": 0}, {"snippet_id": 73881, "code": "\"zlib\", \"snappy\"] vcf_to_zarr_blosc_shuffle_types=[Blosc.NOSHUFFLE, Blosc.SHUFFLE, Blosc.BITSHUFFLE, Blosc.AUTOSHUFFLE] class VCFtoZarrConfigurationRepresentation: \"\"\" Utility class for object representation", "label": 0}, {"snippet_id": 94848, "code": " mode\") sl=SlaveLauncher(args.config, args.kill, args.check) if args.check: sl.run_check() else: sl.init() def start_gui(control_center): app=QtGui.QApplication(sys.argv) main_window=QtGui.QMainWindow()", "label": 0}, {"snippet_id": 82479, "code": " args.trueRegex: \tparser.error(\"At least one detection method must be provided, either with --not-regex or with --true-regex.\") if args.legitExtensions: \targs.legitExtensions=args.legitExtensions[0].split", "label": 0}, {"snippet_id": 43739, "code": "._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config self.overwrite_configfile=overwrite_configfile self.config_args=config_args self._onsuccess=lambda", "label": 0}, {"snippet_id": 44308, "code": " subworkflow_targets=subworkflow.targets(dag) updated=list() if subworkflow_targets: logger.info( \"Executing subworkflow{}.\".format(subworkflow.name)) if not subsnakemake(subworkflow.snakefile, workdir", "label": 0}, {"snippet_id": 66494, "code": " get_name(self): return \"umount\" def get_desc(self): return \"Unmount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_FAILURE, RECOVERING: RC_FAILURE, OFFLINE: RC_OK, TARGET_ERROR: RC_TARGET_ERROR,", "label": 0}, {"snippet_id": 69420, "code": ".last_read() try: event, params=self._shine_msg_unpack(buf) self.fs._handle_shine_event(event, node, **params) except ProxyActionUnpackError, e: pass def ev_close(self, worker): \"\"\" End of proxy command. ", "label": 0}, {"snippet_id": 24784, "code": "(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle']", "label": 0}, {"snippet_id": 76379, "code": ".elapsed(False) < timeout: try: self.poll(timeout * 1000) except Resume as e: return def poll(self, timeout=None): try: socks=dict(self.poller.poll(timeout if timeout !=None else self.poll_timeout)) except", "label": 1}, {"snippet_id": 36100, "code": ".dynamic_output: self.dynamic_output.add(f) if f_ in self.rule.temp_output: self.temp_output.add(f) if f_ in self.rule.protected_output: self.protected_output.add(f) if f_ in self.rule.touch_output: self", "label": 0}, {"snippet_id": 34132, "code": "**ruleinfo.log[1]) if ruleinfo.message: rule.message=ruleinfo.message if ruleinfo.benchmark: rule.benchmark=ruleinfo.benchmark rule.norun=ruleinfo.norun rule.docstring=ruleinfo.docstring rule.run_func=ruleinfo", "label": 0}, {"snippet_id": 88130, "code": "'plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format( _SCALAC_PLUGIN_INFO_FILE, cp_elem)) return plugin_info.find('name').text if os.path.isdir(classpath_element): try:", "label": 0}, {"snippet_id": 22728, "code": " OSUtilError( \"Failed to create user account:{0}, retcode:{1}, output:{2}\".format(username, retcode, out) ) self._save_sys_config() return retcode def chpasswd(self, username, password, crypt_id=6, salt_len=10", "label": 0}, {"snippet_id": 77132, "code": "', self.th_ba) self.th_back_sock=self.p.ctx.socket(zmq.ROUTER) self.th_back_sock.bind(self.th_ba) def init_pr_sock(self): self.log.info( 'Initializing interprocess signal socket %s', self.pr_sa) self.pr_sock", "label": 0}, {"snippet_id": 37224, "code": " def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def benchmark(self): return self._benchmark @benchmark.setter def benchmark(self, benchmark", "label": 0}, {"snippet_id": 24065, "code": "==0: for possible in output.rstrip().split(','): if not possible.startswith('pass'): return possible cmd_search_storvsc=\"camcontrol devlist -b | grep storvsc{0} | awk '{{print $1}}'\".format(output) err", "label": 0}, {"snippet_id": 69510, "code": ", cmd): \"Register a new command.\" assert isinstance(cmd, Command) self.cmd_list.append(cmd) self.cmd_dict[cmd.get_name()]=cmd opt_len=len(cmd.getopt_string) for i in range(0, opt_len): c=cmd.getopt_string", "label": 0}, {"snippet_id": 4580, "code": "\"\" return keyworder.get_single_keywords(skw_db, fulltext) or{} def extract_composite_keywords(ckw_db, fulltext, skw_spans): \"\"\"Returns a list of composite keywords bound with the number of occurrences found", "label": 0}, {"snippet_id": 54806, "code": ", printreason=False, printdag=False, cluster=None, cluster_config=None, cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None", "label": 0}, {"snippet_id": 986, "code": ".POST.get(\"username\")) password=escape(request.POST.get(\"password\")) add_user(username,password) fetchusers=subprocess.Popen(['grep', '/etc/group','-e','docker'], stdout=subprocess.PIPE).communicate()[0]", "label": 0}, {"snippet_id": 53708, "code": " be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item) if is_flagged(item, \"subworkflow\"):", "label": 0}, {"snippet_id": 35748, "code": " elif i==index: self.set_name(name, i, end=i +len(items)) def keys(self): return self._names def plainstrings(self): return self.__class__.__call__(toclone=self, plainstr=True) def __getitem__(self, key", "label": 0}, {"snippet_id": 63874, "code": "=job_wrapper.job_destination job_wrapper.command_line=job.get_command_line() job_state.job_wrapper=job_wrapper state=job.get_state() if state in[model.Job.states.RUNNING, model.Job.states.QUEUED]: log.debug( ", "label": 0}, {"snippet_id": 7575, "code": ":keyword limit: int, number of printed keywords :return: str, html formatted output \"\"\" return \"\"\"<html> <head> <title>Automatically generated keywords by bibclassify</title> </head> <body> {0} </body> </html", "label": 0}, {"snippet_id": 38043, "code": " bestmatch=match.groupdict() bestmatchlen=l return bestmatch @staticmethod def get_wildcard_len(wildcards): \"\"\" Return the length of the given wildcard values. Arguments wildcards --a dict of wildcards \"", "label": 0}, {"snippet_id": 55076, "code": " IOError: logger.error( \"Error: Directory cannot be locked. Please make \" \"sure that no other Snakemake process is trying to create \" \"the same files in the following directory:\\n{}\\n\" \"If you are sure that", "label": 0}, {"snippet_id": 36433, "code": " requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None or f in requested: if f in self.dynamic_output: if not self.expand_dynamic", "label": 0}, {"snippet_id": 90370, "code": " 1 java dist dir.') self._java_dist_dirs=java_dist_dirs @property def jvm_locations(self): for java_dist_dir in self._java_dist_dirs: if os.path.isdir(java_dist_dir): for path in os.listdir(java_dist_dir", "label": 0}, {"snippet_id": 25009, "code": "=\"High\" elif data['rf_status'] <=59: self._state=\"Full\" elif self.type=='wifi_status_lvl': self._state=data['wifi_status'] elif self.type=='wifi_status': if data['wifi_status'] >=86: self._state=\"Low\" elif", "label": 0}, {"snippet_id": 28976, "code": "._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] >=60: self._state=\"High\" elif", "label": 0}, {"snippet_id": 90825, "code": " self.Error(error_format.format('JDK' if jdk else 'JRE', minimum_version, maximum_version)) class DistributionLocator(Subsystem): \"\"\"Subsystem that knows how to look up a java Distribution. Distributions", "label": 0}, {"snippet_id": 58834, "code": "(test.TestCase): \"\"\"Test case for form\"\"\" def test_get_form(self): response=self.client.get(reverse('ajax-form'), {'app_form': 'testcases.CaseAutomatedForm'}) form=CaseAutomatedForm() self.assertHTMLEqual", "label": 1}, {"snippet_id": 94377, "code": " return True else: return False def check_component(comp, session, logger): logger.debug(\"Running component check for %s\" % comp['name']) check_available=len(comp['cmd']) > 1 and 'check' in comp['cmd']", "label": 0}, {"snippet_id": 42456, "code": ") self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self.priority=other.priority", "label": 0}, {"snippet_id": 90893, "code": " java distribution that meets the given constraints and returns it. :API: public First looks for a cached version that was previously located, otherwise calls locate(). :param minimum_version: minimum jvm", "label": 0}, {"snippet_id": 83777, "code": " outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message, exception=True) log.exception(\"failure finishing job ", "label": 0}, {"snippet_id": 1099, "code": ": wifi_name}], safe=False) elif action=='editWifi': print(action) wifi_name=request.POST.get(\"wifi_ap\") wifi_pass=escape(request.POST.get(\"wifi_password\")) edit_WifiConn(wifi_name,wifi_pass) fetchusers", "label": 0}, {"snippet_id": 5364, "code": "[0]) return output def _get_compositekws(ckw_matches, spires=False): \"\"\" :var ckw_matches: dict of{keyword:[info,...]} :keyword spires: bool, to get the spires output :return: list of formatted keywords", "label": 0}, {"snippet_id": 57004, "code": "'\") \"\"\" value=error=None def get_time(time): date_time=datetime.datetime if time=='NOW': return date_time.now() return date_time.strptime(time, '%Y%m%d %H%M%S') pipes={ 'bool': lambda x: x=='True' and 1", "label": 0}, {"snippet_id": 11188, "code": " return value or current_value try: with open(file_name, 'r') as config_file: for line in config_file.xreadlines(): etag=extract(Header.ETAG_COMMENT, etag) mtime=extract(Header.MTIME_COMMMENT, mtime) if", "label": 0}, {"snippet_id": 56632, "code": "=TestCaseTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_cases=Count('tag')).order_by('tag') test_run_tags=TestRunTag.objects.filter( tag__in=all_tags).values('tag').annotate(num_runs=Count('tag'", "label": 0}, {"snippet_id": 72033, "code": " disconnected using this command, use REHASH to reload the networks list.\"\"\" permissions.checkPermissions(irc, source,['networks.disconnect']) try: netname=args[0] network=world.networkobjects[netname] except", "label": 0}, {"snippet_id": 76091, "code": ".format(data[0])) that.retry=True else: self.log.warn('Status{0}, retrying'.format(wzrpc.name_status(status))) that.retry=True return self.wz_wait_reply(accept, *self.wz.make_auth_bind_route_data(i, m,", "label": 0}, {"snippet_id": 66006, "code": "% fs.get_client_servers()],[\"status\", ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER)", "label": 0}, {"snippet_id": 95044, "code": " a configuration file.\", metavar=\"FILEPATH\") runtime_configuration=vars(parser.parse_args()) return runtime_configuration def _main(): input_directory=\"./data/input/\" download_directory=input_directory ", "label": 1}, {"snippet_id": 92132, "code": " or set them to exactly['current']. Bad targets: {} \"\"\".format('\\n'.join(sorted(target.address.reference() for target in bad_targets))) )) class BuildSetupRequiresPex(ExecutablePexTool): options_scope=", "label": 0}, {"snippet_id": 62208, "code": ".allocate_qureg(self.wires) def __repr__(self): return super().__repr__() +'Backend: ' +self.backend +'\\n' def __str__(self): return super().__str__() +'Backend: ' +self.backend +'\\n' def execute(self): \"\"", "label": 1}, {"snippet_id": 63587, "code": ".DELETED] cleanup_job=self.app.config.cleanup_job client_outputs=self.__client_outputs(client, job_wrapper) finish_args=dict( client=client, job_completed_normally=completed_normally, cleanup_job=cleanup_job", "label": 0}, {"snippet_id": 82020, "code": "-url\", metavar=\"target\", dest=\"url\",required=True, help=\"Web page URL containing the file upload form to be tested. Example: http://test.com/index.html?action=upload\", type=valid_url) requiredNamedArgs", "label": 0}, {"snippet_id": 32601, "code": " wildcards --a dictionary of wildcards requested_output --a concrete filepath \"\"\" if requested_output is None: return dict() bestmatchlen=0 bestmatch=None for o in self.products: match=o.match(requested_output", "label": 0}, {"snippet_id": 57189, "code": ".log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), value ) ) except(AttributeError, User.DoesNotExist): pass objects_update(targets, **{field: value}) if", "label": 0}, {"snippet_id": 83596, "code": " return[ str( o) for o in output_paths] def get_input_files(self, job_wrapper): input_paths=job_wrapper.get_input_paths() return[ str( i) for i in input_paths] def get_client_from_wrapper(self, job_wrapper", "label": 0}, {"snippet_id": 72249, "code": " irc.error('Unknown service %r.' % args.service) return remoteirc.called_in=remoteirc.called_by=remoteirc.pseudoclient.uid remoteirc.pseudoclient.account=irc.users[source].account def _remote_reply(placeholder_self", "label": 0}, {"snippet_id": 67913, "code": ". \"\"\" from Shine.Configuration.Configuration import Configuration from Shine.Configuration.Globals import Globals from Shine.Configuration.Exceptions import * from Base.FSLiveCommand import FSLiveCommand", "label": 0}, {"snippet_id": 18087, "code": ") SERVER_HEALTHY=False def _CheckServerIsHealthyWithCache(): global SERVER_HEALTHY def _ServerIsHealthy(): response=requests.get( _BuildUri( 'healthy')) response.raise_for_status() return response.json", "label": 1}, {"snippet_id": 54315, "code": ".workflow._ruleorder.compare(self, rule) return comp < 0 def __gt__(self, rule): comp=self.workflow._ruleorder.compare(self, rule) return comp > 0 def __str__(self): return self.name def __hash__(self):", "label": 0}, {"snippet_id": 31953, "code": " self.wildcard_names !=wildcards: raise SyntaxError( \"Not all output files of rule{} \" \"contain the same wildcards.\".format(self.name)) else: self.wildcard_names=wildcards def _set_inoutput_item(self, item", "label": 0}, {"snippet_id": 76258, "code": ".status.success: self.log.debug('Auth records on router were cleared') else: self.log.warn('Status %s, passing', wzrpc.name_status(status)) return self.wz_wait_reply(accept, *self.wz.make_auth_clear_data", "label": 0}, {"snippet_id": 69601, "code": " Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine install -f /path", "label": 0}, {"snippet_id": 19882, "code": " not running') if self._session is not None: self._detach() try: self._adapter.close() except ClosedError: pass self._adapter=None def attach_pid(self, pid, **kwargs): if self.closed: raise RuntimeError", "label": 0}, {"snippet_id": 23492, "code": ") shellutil.run('> /var/run/utx.active') shellutil.run('rmuser -y ' +username) self.conf_sudoer(username, remove=True) def chpasswd(self, username, password, crypt_id=6, salt_len=10): if self.is_sys_user", "label": 0}, {"snippet_id": 71229, "code": ".1fM\" %(target.dev_size/MEGA) elif target.dev_size >=KILO: dev_size=\"%.1fK\" %(target.dev_size/KILO) else: dev_size=\"%d\" % target.dev_size if target.jdev: jdev_col_enabled=True jdev=target.jdev else: jdev", "label": 0}, {"snippet_id": 45533, "code": "(lstat(self.file).st_mode & ~stat.S_IWUSR & ~stat.S_IWGRP & ~ stat.S_IWOTH) if os.path.isdir(self.file): for root, dirs, files in os.walk(self.file): for d in dirs: lchmod(os.path.join(self.file, d), mode)", "label": 0}, {"snippet_id": 31438, "code": ".updated_input -self.updated_input_run if updated_input: s.append(\"Updated input files:{}\".format( \", \".join(updated_input))) if self.updated_input_run: s.append(\"Input files updated by another job:{}\".format( \"", "label": 0}, {"snippet_id": 17019, "code": "/localhost:6666' def BuildRequestData( start_column=None, query=None, include_buffer_data=True): line, column=vimsupport.CurrentLineAndColumn() filepath=vimsupport.GetCurrentBufferFilepath() request_data={ ", "label": 0}, {"snippet_id": 53585, "code": ".output: if self.dynamic_output and item not in self.dynamic_output: raise SyntaxError( \"A rule with dynamic output may not define any \" \"non-dynamic output files.\") wildcards=item.get_wildcard_names()", "label": 0}, {"snippet_id": 31287, "code": ".output, \"params\": params, \"threads\": self.threads, \"resources\": resources } return properties def json(self): return json.dumps(self.properties()) def __repr__(self): return self.rule.name def __eq__(self", "label": 0}, {"snippet_id": 91125, "code": "\n from __future__ import absolute_import, division, print_function, unicode_literals from pants.backend.python.pants_requirement import PantsRequirement from pants.backend.python.python_artifact import", "label": 0}, {"snippet_id": 4525, "code": " only_core_tags: single_keywords=clean_before_output(_filter_core_keywors(single_keywords)) composite_keywords=_filter_core_keywors(composite_keywords) else: single_keywords=clean_before_output(single_keywords)", "label": 0}, {"snippet_id": 48394, "code": "*kwparams): for item in params: self._set_params_item(item) for name, item in kwparams.items(): self._set_params_item(item, name=name) def _set_params_item(self, item, name=None): if isinstance(item, str", "label": 0}, {"snippet_id": 73483, "code": " input VCF file location :param output_zarr_path: The desired Zarr output location :param conversion_config: Configuration data for the conversion :type input_vcf_path: str :type output_zarr_path: str :type", "label": 0}, {"snippet_id": 79415, "code": ".verbosity > 1: \t\t\t\tprintSimpleResponseObject(r) \t\t\tif self.logger.verbosity > 2: \t\t\t\tprint(\"\\033[36m\"+r.text+\"\\033[m\") \t\tres=re.search(regex,r.text) \t\tif res: \t\t\treturn True \t\telse: \t\t\treturn False \t \t ", "label": 0}, {"snippet_id": 87443, "code": "-log-level', self.get_options().level, '-analysis-cache', analysis_cache, '-classpath', ':'.join(relative_classpath), '-d', classes_dir, ]) if not self.get_options().colors: zinc_args.append('-no-color'", "label": 0}, {"snippet_id": 83962, "code": " log.debug( \"stop_job(): %s: PID %d successfully killed with signal %d\" %( job.id, pid, sig)) return else: log.warning( \"stop_job(): %s: PID %d refuses to die after signaling TERM/KILL\" %( job.id, pid)", "label": 0}, {"snippet_id": 77637, "code": "'rb') as f: data=pickle.loads(f.read()) if 'targets' in data: self.log.debug('Target list was loaded') targets.update(data['targets']) if 'forums' in data: self.log.debug('Forum set was loaded') forums", "label": 0}, {"snippet_id": 12886, "code": "=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE) stdout, _=proc.communicate() data[\"diff\"][filename]=stdout.decode(r.encoding) data[\"diff\"][filename]=data[\"diff\"][filename", "label": 0}, {"snippet_id": 78699, "code": " e: log.logger.exception(e) if log.logger.getEffectiveLevel() <=logging.DEBUG: if os.getenv('UNITTEST', 'False')=='True': raise if self.options.trace: pdb.post_mortem(sys.exc_info()[2]) else: log.log_error", "label": 1}, {"snippet_id": 55756, "code": " isinstance(ruleinfo.priority, int) and not isinstance(ruleinfo.priority, float)): raise RuleException(\"Priority values have to be numeric.\", rule=rule) rule.priority=ruleinfo.priority if ruleinfo.version: rule", "label": 0}, {"snippet_id": 67293, "code": ".mount_path, strerr) if rc: print message class Mount(FSClientLiveCommand): \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return ", "label": 0}, {"snippet_id": 38739, "code": ".wait_for_files(wait_for_files, latency_wait=latency_wait) except IOError as e: logger.error(str(e)) return False dag=DAG( self, rules, dryrun=dryrun, targetfiles=targetfiles, targetrules=targetrules, forceall", "label": 0}, {"snippet_id": 37459, "code": ".protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output:", "label": 0}, {"snippet_id": 21194, "code": "(AwaitableResponse, self).__init__(req[\"command\"], event) self.req=req self._result_getter=result_getter @property def resp(self): return self._result_getter() class AwaitableEvent(Awaitable): def __init__", "label": 0}, {"snippet_id": 18824, "code": "') def _AddUltiSnipsDataIfNeeded( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger,", "label": 0}, {"snippet_id": 12763, "code": " query=query.format(data[\"repository\"], str(last_comment_id)) response=requests.patch(query, json={\"body\": comment}, headers=headers, auth=auth) def autopep8(data, config): headers={\"Authorization\": \"token", "label": 0}, {"snippet_id": 67204, "code": " import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import * class GlobalMountEventHandler(Shine.Lustre.EventHandler.EventHandler", "label": 0}, {"snippet_id": 71711, "code": ") if m: print \"%s<pickle>\" % m.group(0) else: print s class Controller: def __init__(self): self.logger=logging.getLogger(\"shine\") self.cmds=CommandRegistry() task_self().set_info(\"print_debug\", print_csdebug", "label": 0}, {"snippet_id": 20394, "code": " def connect(addr, timeout): sock=create_client() for _ in range(int(timeout * 10)): try: sock.connect(addr) except(OSError, socket.error): if cls.VERBOSE: print('+', end='') sys.stdout.flush() time.sleep", "label": 0}, {"snippet_id": 62416, "code": " collapse is 0. \"\"\" if self.eng is not None and self.backend=='Simulator' or self.backend=='IBMBackend': self.eng.flush() self.eng.backend.collapse_wavefunction(self.reg,[0 for i in range(len(self.reg))]", "label": 0}, {"snippet_id": 40899, "code": " for f in chain(filenames, dirnames): if dirpath !=\".\": f=os.path.join(dirpath, f) match=re.match(pattern, f) if match: for name, value in match.groupdict().items(): getattr(wildcards, name).append(value", "label": 0}, {"snippet_id": 65877, "code": " elif target.state==RUNTIME_ERROR: t_runtime.append(target) else: t_unknown.append(target) status=[] if len(t_offline) > 0: status.append(\"offline(%d)\" % len(t_offline)) if len(t_error) > 0: status.append", "label": 0}, {"snippet_id": 88676, "code": ".set_target_root_size(target_count) return target_count def _set_affected_target_count_in_runtracker(self): \"\"\"Sets the realized target count in the run tracker's daemon stats object.\"\"\" target_count=len", "label": 0}, {"snippet_id": 39196, "code": "(\"Nothing to be done.\") if dryrun and not len(dag): logger.info(\"Nothing to be done.\") success=scheduler.schedule() if success: if dryrun: if not quiet and len(dag): logger.run_info(\"\\n\".join(dag.stats", "label": 0}, {"snippet_id": 60636, "code": ", self.short_name)) p=[x.val if isinstance(x, Variable) else x for x in operation.params] op=operator_map[operation.name](*p) if isinstance(operation.wires, int): op | q[operation.wires] else: op |[q[i", "label": 0}, {"snippet_id": 32281, "code": " def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards dict. \"\"\" def concretize_iofile(f, wildcards): if not isinstance(f, _IOFile): return", "label": 0}, {"snippet_id": 16480, "code": " force_semantic: extra_data[ 'force_semantic']=True self._latest_completion_request=( CompletionRequest( extra_data) if self._IsServerAlive() else None) return self._latest_completion_request def SendCommandRequest", "label": 0}, {"snippet_id": 53922, "code": ") except TypeError: raise SyntaxError(\"Log files have to be specified as strings.\") def expand_wildcards(self, wildcards=None): \"\"\" Expand wildcards depending on the requested output or given wildcards", "label": 0}, {"snippet_id": 3325, "code": " if check_mode: self.logger.info(\"started slave with check mode\") self.server=Server() if self.server.has_session(\"slave-session\"): self.session=self.server.find_where({ \"session_name\": \"slave-session\"", "label": 0}, {"snippet_id": 6021, "code": "\"): return True return False file_output=os.popen('file ' +re.escape(document)).read() try: filetype=file_output.split(\":\")[1] except IndexError: log.error(\"Your version of the 'file' utility seems to ", "label": 1}, {"snippet_id": 49804, "code": " happens on a cluster, please make sure \" \"that you handle the dependencies yourself or turn of \" \"--immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files", "label": 0}, {"snippet_id": 90576, "code": "). :param minimum_version: minimum jvm version to look for(eg, 1.7). The stricter of this and `--jvm-distributions-minimum-version` is used. :param maximum_version: maximum jvm version to look for(eg, 1", "label": 0}, {"snippet_id": 89576, "code": " ValueError('Exactly one of home path or bin path should be supplied, given: ' 'home_path={} bin_path={}'.format(home_path, bin_path)) self._home=home_path self._bin_path=bin_path or(os.path.join(home_path,", "label": 0}, {"snippet_id": 76477, "code": ".info('Starting') try: self.child=self.call[0](*self.call[1], **self.call[2]) self.child(self) except WorkerInterrupt as e: self.log.warn(e) except Exception as e: self.log.exception(e) self.log.info('Terminating", "label": 0}, {"snippet_id": 83770, "code": ": job_wrapper.fail(\"Failed to find or download one or more job outputs from remote server.\", exception=True) except Exception: message=\"Failed to communicate with remote job server.\" job_wrapper.fail( message", "label": 0}, {"snippet_id": 1480, "code": "=request.POST.get(\"icon\") print(request_name) print(request_address) print(request_icon) setServiceDetails=RegisteredServices.objects.get_or_create(name=request_name,address=request_address,icon=request_icon", "label": 0}, {"snippet_id": 88119, "code": " def process_info_file(cp_elem, info_file): plugin_info=ElementTree.parse(info_file).getroot() if plugin_info.tag !='plugin': raise TaskError('File{} in{} is not a valid scalac plugin descriptor'.format", "label": 0}, {"snippet_id": 7682, "code": " iteritems(acronyms): expansions_str=\", \".join([\"%s(%d)\" % expansion for expansion in expansions]) acronyms_str[acronym]=expansions_str return acronyms def _get_author_keywords(author_keywords, spires=False):", "label": 0}, {"snippet_id": 68794, "code": ".sort() layout=AsciiTableLayout() layout.set_show_header(True) i=0 layout.set_column(\"dev\", i, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER) i +=1 layout.set_column(\"nodes\", i, AsciiTableLayout", "label": 0}, {"snippet_id": 95983, "code": " numalt=callset['variants/numalt'] alt_number=np.max(numalt) else: print(\"[VCF-Zarr] Using alt number provided in configuration.\") alt_number=conversion_config.alt_number print(\"[VCF-Zarr] Alt number:{}\"", "label": 0}, {"snippet_id": 9774, "code": " formatted output \"\"\" output=\"\" for result in complete_output: list_result=complete_output[result] if list_result: list_result_sorted=sorted(list_result, key=lambda x: list_result[x], reverse=True) output +", "label": 0}, {"snippet_id": 79663, "code": " expected output of the payload.\" templatesSection +=\"\\n\\tDefault templates are the following(name -description): \" for t in templates: \ttemplatesSection+=\"\\n\\t * '\"+t[\"templateName\"]+\"' -\"+t[\"description", "label": 0}, {"snippet_id": 79627, "code": ") templatesFolder=\"payloads\" with open(\"templates.json\",\"r\") as fd: \ttemplates=json.loads(fd.read()) templatesNames=[x[\"templateName\"] for x in templates] templatesSection=\"[TEMPLATES]\\nTemplates are malicious", "label": 0}, {"snippet_id": 55680, "code": "*ruleinfo.input[1]) if ruleinfo.output: rule.set_output(*ruleinfo.output[0], **ruleinfo.output[1]) if ruleinfo.params: rule.set_params(*ruleinfo.params[0], **ruleinfo.params[1]) if ruleinfo.threads: if", "label": 0}, {"snippet_id": 54003, "code": " if not isinstance(item_, str): raise RuleException( \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None", "label": 0}, {"snippet_id": 79174, "code": "\t\treturn(fu,filename) \t \tdef isASuccessfulUpload(self,html): \t\tresult=False \t\tvalidExt=False \t\tif self.notRegex: \t\t\tfileUploaded=re.search(self.notRegex,html) \t\t\tif fileUploaded==None: \t\t\t\tresult=True ", "label": 1}, {"snippet_id": 88015, "code": " appears to be the norm, since SBT doesn't support plugins with dependencies anyway). \"\"\" plugin_names={p for val in scalac_plugins for p in val.split(',')} if not plugin_names: return{} active_plugins=", "label": 0}, {"snippet_id": 90231, "code": " bin_path=bin_path) @abstractproperty def jvm_locations(self): \"\"\"Return the jvm locations discovered in this environment. :returns: An iterator over all discovered jvm locations. :rtype: iterator of:class", "label": 0}, {"snippet_id": 75700, "code": " startup''' self.log=logging.getLogger(self.name) self.running=threading.Event() self.sleep_ticker=Ticker() self.poller=zmq.Poller() s=self.ctx.socket(zmq.SUB) self.poller.register(s, zmq.POLLIN) s.setsockopt", "label": 0}, {"snippet_id": 53127, "code": " import inspect import sre_constants from collections import defaultdict from snakemake.io import IOFile, _IOFile, protected, temp, dynamic, Namedlist from snakemake.io import expand, InputFiles, OutputFiles", "label": 0}, {"snippet_id": 16833, "code": "( extra_data): if not USE_ULTISNIPS_DATA: return try: rawsnips=UltiSnips_Manager._snips( '', 1) except: return extra_data[ 'ultisnips_snippets']=[{ 'trigger': x.trigger, 'description': x.description } for", "label": 0}, {"snippet_id": 28972, "code": ".type=='rf_status_lvl': self._state=data['rf_status'] elif self.type=='rf_status': if data['rf_status'] >=90: self._state=\"Low\" elif data['rf_status'] >=76: self._state=\"Medium\" elif data['rf_status'] ", "label": 0}, {"snippet_id": 26667, "code": " self._state=\"Medium\" elif data['battery_vp'] >=4000: self._state=\"Low\" elif data['battery_vp'] < 4000: self._state=\"Very Low\" elif self.type=='battery_vp' and self.module_id=='3': if data['battery_vp'", "label": 0}, {"snippet_id": 78163, "code": " IPython IPython.embed() except ImportError: while True: try: exec(input('> ')) except KeyboardInterrupt: print(\"KeyboardInterrupt\") except SystemExit: break except: print(traceback.format_exc()) terminate()", "label": 1}, {"snippet_id": 86470, "code": " import ScalaPlatform from pants.backend.jvm.subsystems.zinc import Zinc from pants.backend.jvm.targets.annotation_processor import AnnotationProcessor from pants.backend.jvm.targets.javac_plugin import", "label": 0}, {"snippet_id": 26794, "code": "] elif data['WindAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=210: self._state=\"SW(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=150: self._state=\"S(%d\\xb0", "label": 0}, {"snippet_id": 31200, "code": ".workflow.globals) _variables.update(dict(input=self.input, output=self.output, params=self.params, wildcards=self._format_wildcards, threads=self.threads, resources=self.resources, log=self.log, version=self", "label": 0}, {"snippet_id": 58147, "code": "=ctypes[target][1] results=[(r.pk, getattr(r, attr)) for r in results] return results def get_prod_related_obj_json(request): \"\"\" View for updating product drop-down\\n in a Ajax way. \"\"\" data=request.GET", "label": 0}, {"snippet_id": 12760, "code": "{}/issues/comments/{}\" query=query.format(data[\"repository\"], str(last_comment_id)) response=requests.patch(query, json={\"body\": comment}, headers=headers, auth=auth) def autopep8(data, config): headers", "label": 0}, {"snippet_id": 38383, "code": ".output) if not callable(file) and not file.contains_wildcard() ) def check(self): for clause in self._ruleorder: for rulename in clause: if not self.is_rule(rulename): raise UnknownRuleException( rulename", "label": 0}, {"snippet_id": 91320, "code": " pants.build_graph.build_file_aliases import BuildFileAliases from pants.build_graph.resources import Resources from pants.goal.task_registrar import TaskRegistrar as task def build_file_aliases(): return", "label": 0}, {"snippet_id": 43863, "code": ".rule_count +=1 if not self.first_rule: self.first_rule=rule.name return name def is_rule(self, name): \"\"\" Return True if name is the name of a rule. Arguments name --a name \"\"\" return name in self._rules", "label": 0}, {"snippet_id": 95304, "code": " and all subdirectories/files within the path specified. :param path: The path to the directory to remove :type path: str \"\"\" if os.path.exists(path): shutil.rmtree(path, ignore_errors=True) def fetch_data_via_ftp", "label": 0}, {"snippet_id": 180, "code": "(wlans) wlan0=wlans[0] print(wlan0) print(wifiname) for dev in wlans: for ap in dev.AccessPoints: if ap.Ssid==wifiname: currentwifi=ap print(currentwifi) params={ \"802-11-wireless\":{ \"security\": \"802-11", "label": 0}, {"snippet_id": 66110, "code": "%s\" % target.status_info elif target.state==MOUNTED: status=\"online\" elif target.state==TARGET_ERROR: status=\"ERROR\" elif target.state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target", "label": 0}, {"snippet_id": 42507, "code": "(self, wildcards, input=True): def get_io(rule): return(rule.input, rule.dynamic_input) if input else( rule.output, rule.dynamic_output ) io, dynamic_io=get_io(self) branch=Rule(self) io_, dynamic_io_=get_io", "label": 0}, {"snippet_id": 19383, "code": " https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py \"\"\" PYDEVD_OPTS={ '--file', '--client', '", "label": 0}, {"snippet_id": 84263, "code": " if remote_metadata: remote_system_properties=remote_job_config.get(\"system_properties\",{}) remote_galaxy_home=remote_system_properties.get(\"galaxy_home\", None) if not remote_galaxy_home: raise Exception", "label": 0}, {"snippet_id": 32474, "code": "{ None if f is None else f.apply_wildcards(wildcards): rule for f, rule in self.dependencies.items() } ruleio.update(dict((f, f_) for f, f_ in zip(output, self.output))) log=Log() _apply_wildcards(log,", "label": 0}, {"snippet_id": 95257, "code": " import functools import numpy as np import zarr import numcodecs from numcodecs import Blosc, LZ4, LZMA from benchmark import config import gzip import shutil def create_directory_tree(path): \"\"\" Creates", "label": 1}, {"snippet_id": 90849, "code": " the following order by default: 1. Paths listed for this operating system in the `--jvm-distributions-paths` map. 2. JDK_HOME/JAVA_HOME 3. PATH 4. Likely locations on the file system such as `/usr/lib", "label": 0}, {"snippet_id": 86310, "code": ".Popen(javac_cmd, stdout=workunit.output('stdout'), stderr=workunit.output('stderr')) return_code=p.wait() workunit.set_outcome(WorkUnit.FAILURE if return_code else WorkUnit.SUCCESS) if return_code: raise", "label": 0}, {"snippet_id": 78713, "code": "'True': raise if self.options.trace: pdb.post_mortem(sys.exc_info()[2]) else: log.log_error(e) def executer(self, *args): \"\"\"Execute remotely\"\"\" options=self.options try: url='http://{host}:{port}/{path", "label": 1}, {"snippet_id": 93069, "code": "[ mock.call(signal.SIGUSR2, mock_new_handler), mock.call(signal.SIGUSR2, mock_initial_handler) ]) def test_permissions(self): with temporary_file(permissions=0o700) as f: self.assertEqual(0o700, os.stat", "label": 0}, {"snippet_id": 62260, "code": "[x.val if isinstance(x, Variable) else x for x in operation.params] self.apply(operation.name, operation.wires, *par) result=self.expectation(self._observe.name, self._observe.wires) self._deallocate()", "label": 0}, {"snippet_id": 26891, "code": " elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=240: self._state=\"W(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=210: self._state=\"SW(%d\\xb0)\" ", "label": 0}, {"snippet_id": 26747, "code": "._state=\"Very Low\" elif self.type=='min_temp': self._state=data['min_temp'] elif self.type=='max_temp': self._state=data['max_temp'] elif self.type=='windangle_value': self._state=data['WindAngle'] elif", "label": 0}, {"snippet_id": 74450, "code": "): dict_section={name: dict(parser.items(name))} self.__dict__.update(dict_section) class FTPConfigurationRepresentation(object): \"\"\" Utility class for object representation of FTP module configuration", "label": 0}, {"snippet_id": 42860, "code": "(item, \"protected\"): if not output: raise SyntaxError(\"Only output files may be protected\") self.protected_output.add(_item) if is_flagged(item, \"touch\"): if not output: raise SyntaxError( \"Only output", "label": 0}, {"snippet_id": 31896, "code": " set_output(self, *output, **kwoutput): \"\"\" Add a list of output files. Recursive lists are flattened. Arguments output --the list of output files \"\"\" for item in output: self._set_inoutput_item(item, output", "label": 0}, {"snippet_id": 50000, "code": ".needrun_jobs for resource in job.resources_dict if resource not in resources)) if ignored_resources: logger.resources_info( \"Ignored resources: \" +ignored_resources) logger.run_info(\"\\n\".join(dag.stats())", "label": 0}, {"snippet_id": 39234, "code": " else: if not dryrun and not no_hooks: self._onerror(logger.get_logfile()) return False def include(self, snakefile, overwrite_first_rule=False, print_compilation=False, overwrite_shellcmd=None): \"\"\" Include", "label": 0}, {"snippet_id": 87927, "code": "(self, scalac_plugins, classpath): \"\"\"Returns a map from plugin name to list of plugin classpath entries. The first entry in each list is the classpath entry containing the plugin metadata. The rest are", "label": 0}, {"snippet_id": 63514, "code": " job_destination_params, job_id, env=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s", "label": 0}, {"snippet_id": 1825, "code": "'container_id': row[1], 'name': row[2], 'image': row[3], 'running_for': row[4], 'command': row[5], 'ports': row[6], 'status': row[7], 'networks': row[8]} finalset.append(data) return JsonResponse(finalset", "label": 0}, {"snippet_id": 49605, "code": "( nolock=nolock, dag=dag, warn_only=dryrun or printrulegraph or printdag or summary or list_version_changes or list_code_changes or list_input_changes or list_params_changes) if cleanup_metadata: for f", "label": 0}, {"snippet_id": 12017, "code": " if value: if isinstance(value, int): if isinstance(value, bool): arguments.append(\"--{}\".format(key)) else: arguments.append(\"--{}={}\".format(key, value)) elif isinstance(value, list): arguments.append(", "label": 0}, {"snippet_id": 44344, "code": "\"Subworkflow{}: Nothing to be done.\".format( subworkflow.name)) if self.subworkflows: logger.info(\"Executing main workflow.\") self.globals.update(globals_backup) dag.check_incomplete() dag.postprocess()", "label": 0}, {"snippet_id": 67960, "code": " Shine.Lustre.EventHandler from Shine.Lustre.Disk import * from Shine.Lustre.FileSystem import * from ClusterShell.NodeSet import NodeSet import os (KILO, MEGA, GIGA, TERA)=(1024, 1048576, 1073741824, 1099511627776", "label": 0}, {"snippet_id": 38575, "code": " cluster_sync=None, jobname=None, immediate_submit=False, ignore_ambiguity=False, printrulegraph=False, printd3dag=False, drmaa=None, stats=None, force_incomplete=False, ignore_incomplete=False, list_version_changes", "label": 0}, {"snippet_id": 55340, "code": "=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet, keepgoing=keepgoing, drmaa=drmaa, printreason=printreason", "label": 0}, {"snippet_id": 50455, "code": " ruleinfo return decorate def params(self, *params, **kwparams): def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo", "label": 0}, {"snippet_id": 19371, "code": " __author__ \"\"\" For the PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master", "label": 0}, {"snippet_id": 52165, "code": " \"((?P<value>.+)(?P=value){{{min_repeat},{max_repeat}}})$\".format( min_repeat=min_repeat -1, max_repeat=max_repeat -1)) def is_periodic(self, value): \"\"\"Returns the periodic substring or None if not periodic", "label": 0}, {"snippet_id": 75186, "code": " wzrpc.routetype.random)] self.p.auth_requests() self.p.bind_methods() self.ev=self.ev_init() self.bind_kt_ticker.tick() while self.p.running.is_set(): socks=self.p.poll() if self.bind_kt_ticker.elapsed", "label": 1}, {"snippet_id": 4684, "code": " text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db: list of composite kw objects :var fulltext: utf-8", "label": 0}, {"snippet_id": 57085, "code": " a model,\\n based on contenttype. \"\"\" now=datetime.datetime.now() data=request.POST.copy() ctype=data.get(\"content_type\") vtype=data.get('value_type', 'str') object_pk_str=data.get(\"object_pk\") field=data", "label": 0}, {"snippet_id": 69294, "code": " RC_RUNTIME_ERROR except FSRemoteError, e: self.print_error(e) return e.rc except NodeSetParseError, e: self.print_error(\"%s\" % e) return RC_USER_ERROR except RangeSetParseError, e: self.print_error(\"%s\" % e", "label": 1}, {"snippet_id": 76184, "code": " def unbind_route(self, i, m): if not(i, m) in self.wz.req_handlers: self.log.debug('Route %s,%s was not bound', i, m) return self.log.debug('Unbinding route %s,%s', i, m) self.wz.del_req_handler(i, m)", "label": 0}, {"snippet_id": 27543, "code": "], 1) elif self.type=='humidity': self._state=data['Humidity'] elif self.type=='rain': self._state=data['Rain'] elif self.type=='sum_rain_1': self._state=data['sum_rain_1'] elif self.type=='sum_rain_24", "label": 0}, {"snippet_id": 87880, "code": "-Xplugin:{}{}'.format(plugin, ' '.join(args))) return ret def _scalac_plugin_args(self, scalac_plugin_map, classpath): if not scalac_plugin_map: return[] plugin_jar_map=self._find_scalac_plugins(list(scalac_plugin_map", "label": 0}, {"snippet_id": 6975, "code": ": list of composite kw objects :var fulltext: utf-8 string :return: dictionary of matches in a formt{ <keyword object>,[matched skw or ckw object,....] } or empty{} \"\"\" akw={} K=reader.KeywordToken for", "label": 0}, {"snippet_id": 21145, "code": "{}'.format(','.join(messages))) def __init__(self, name, event=None): self._event=event self.name=name def wait(self, timeout=1.0): if self._event is None: return if not self._event.wait(timeout): message", "label": 0}, {"snippet_id": 37466, "code": " SyntaxError( \"Only output files may be marked for touching.\") self.touch_output.add(_item) if is_flagged(item, \"dynamic\"): if output: self.dynamic_output.add(_item) else: self.dynamic_input.add(_item)", "label": 0}, {"snippet_id": 66012, "code": " ', '.join(status)]])) layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column(\"type\", 0, AsciiTableLayout.CENTER, \"type\", AsciiTableLayout.CENTER) layout.set_column(\"count\", 1, AsciiTableLayout", "label": 0}, {"snippet_id": 26206, "code": ":weather-rainy', None], 'sum_rain_24':['sum_rain_24', 'mm', 'mdi:weather-rainy', None], 'battery_vp':['Battery', '', 'mdi:battery', None], 'battery_lvl':['Battery_lvl', '', 'mdi:battery', None], 'min_temp':[", "label": 0}, {"snippet_id": 55640, "code": " workdir) self._subworkflows[name]=sw self.globals[name]=sw.target def localrules(self, *rulenames): self._localrules.update(rulenames) def rule(self, name=None, lineno=None, snakefile=None): name=self", "label": 0}, {"snippet_id": 49814, "code": "-immediate-submit. Missing input files:\\n{}\".format( \"\\n\".join(missing_input))) return False updated_files.extend(f for job in dag.needrun_jobs for f in job.output) if printd3dag: dag.d3dag() return True", "label": 0}, {"snippet_id": 50846, "code": " ValueError(\"This IOFile is specified as a function and \" \"may not be used directly.\") @property def exists(self): return os.path.exists(self.file) @property def protected(self): return self.exists and not os", "label": 1}, {"snippet_id": 25258, "code": ":weather-windy', None], 'gustangle':['Gust Angle', '', 'mdi:compass', None], 'gustangle_value':['Gust Angle Value', '\u00ba', 'mdi:compass', None], 'guststrength':['Gust Strength', 'km/h', 'mdi:weather-windy',", "label": 0}, {"snippet_id": 54009, "code": " \"Input function did not return str or list of str.\", rule=self) concrete=concretize(item_, wildcards) newitems.append(concrete) if ruleio is not None: ruleio[concrete]=item_ else: if not_iterable(item", "label": 0}, {"snippet_id": 85856, "code": " from pants.backend.jvm import argfile from pants.backend.jvm.subsystems.java import Java from pants.backend.jvm.subsystems.jvm_platform import JvmPlatform from pants.backend.jvm.targets.annotation_processor", "label": 0}, {"snippet_id": 57934, "code": " request.user) return say_yes() def clean_bug_form(request): \"\"\" Verify the form data, return a tuple\\n (None, ERROR_MSG) on failure\\n or\\n (data_dict, '') on success.\\n \"\"\" data={} try: data['bugs']=request", "label": 0}, {"snippet_id": 32557, "code": "(requested_output): return True return False except sre_constants.error as ex: raise IOFileException(\"{} in wildcard statement\".format(ex), snakefile=self.snakefile, lineno=self.lineno) except ValueError", "label": 0}, {"snippet_id": 28873, "code": " elif self.type=='gustangle': if data['GustAngle'] >=330: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=300: self._state=\"NW(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >", "label": 0}, {"snippet_id": 18872, "code": ") from flex.http import( normalize_request, normalize_response, ) from flex.validation.common import validate_object from flex.validation.request import validate_request from flex.validation.response import", "label": 0}, {"snippet_id": 31043, "code": " omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files @property def existing_output(self): return filter(lambda f: f.exists, self.expanded_output)", "label": 0}, {"snippet_id": 36531, "code": ".rule, unexpected_output)) if self.dynamic_output: for f, _ in chain(*map(partial(self.expand_dynamic, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill), self.rule.dynamic_output)): os.remove", "label": 0}, {"snippet_id": 94908, "code": ": args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the benchmark run), and config argument for where is the config file. \"\"\" logging.debug('Getting cli", "label": 0}, {"snippet_id": 74246, "code": ") if \"benchmark_PCA\" in runtime_config.benchmark: self.benchmark_PCA=config_str_to_bool(runtime_config.benchmark[\"benchmark_PCA\"]) self.vcf_to_zarr_config=VCFtoZarrConfigurationRepresentation(runtime_config", "label": 1}, {"snippet_id": 19372, "code": " __author__ \"\"\" For the PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd", "label": 0}, {"snippet_id": 46454, "code": "[index]) else: setattr(self, name, Namedlist(toclone=self[index:end])) def get_names(self): \"\"\" Get the defined names as(name, index) pairs. \"\"\" for name, index in self._names.items(): yield name, index def", "label": 0}, {"snippet_id": 83444, "code": "=False lwr_job_state.job_destination=job_destination self.monitor_job(lwr_job_state) def __prepare_job(self, job_wrapper, job_destination): \"\"\" Build command-line and LWR client for this job. \"\"\" command_line", "label": 0}, {"snippet_id": 83673, "code": "=[]): encoded_job_id=self.app.security.encode_id(job_id) job_key=self.app.security.encode_id( job_id, kind=\"jobs_files\") files_endpoint=\"%s/api/jobs/%s/files?job_key=%s\" %( self.galaxy_url, encoded_job_id", "label": 0}, {"snippet_id": 69839, "code": " \"\"\" \"\"\" def __init__(self): FSClientLiveCommand.__init__(self) def get_name(self): return \"mount\" def get_desc(self): return \"Mount file system clients.\" target_status_rc_map={ \\ MOUNTED: RC_OK, RECOVERING", "label": 0}, {"snippet_id": 83573, "code": " not None: for cmd in prepare_input_files_cmds: if 0 !=os.system(cmd): raise Exception('Error running file staging command: %s' % cmd) job_wrapper.prepare_input_files_cmds=None def get_output_files(self,", "label": 0}, {"snippet_id": 12913, "code": "\"diff\"][filename]=data[\"diff\"][filename].replace(\"\\\\\", \"\\\\\\\\\") url=\"https://github.com/{}/blob/{}{}\" data[filename +\"_link\"]=url.format(data[\"repository\"], data[\"sha\"], file) os.remove(\"file_to_fix.py\")", "label": 0}, {"snippet_id": 76974, "code": ") ud[0]['avatar']=av ud[0]['avatar_uploaded']=True from lib.mailinator import Mailinator def create_spawn(proxy, proxytype, pc, uq=None): for domain in domains: if domain in targets: tlist=targets[domain", "label": 0}, {"snippet_id": 13665, "code": ")\r eyesThread=Thread(target=updateEyes)\r eyesThread.start() \r audio=AudioPlayer()\r \r if( consumerKey.find( 'TWITTER') >=0):\r print( \"WARNING: INVALID TWITTER CREDENTIALS. Please read README.md for instructions", "label": 0}, {"snippet_id": 76660, "code": " parser=argparse.ArgumentParser(add_help=True) parser.add_argument('--only-cache', '-C', action='store_true', help=\"Disables any requests in DataLoader(includes Witch)\") parser.add_argument('--no-shell", "label": 0}, {"snippet_id": 78136, "code": ".send_multipart(msg) def drop_users(): send_passthrough([b'WipeSkel', b'WipeSkel', b'drop-user']) def log_spawn_name(): send_passthrough([b'WipeThread', b'WipeThread', b'log-spawn-name']) if c.no_shell", "label": 1}, {"snippet_id": 12601, "code": "\"pr_number\"])) comments=requests.get(url, headers=headers, auth=auth).json() last_comment=\"\" for old_comment in reversed(comments): if old_comment[\"user\"][\"id\"]==24736507: last_comment=old_comment[\"body", "label": 0}, {"snippet_id": 4809, "code": " applies to single and composite keywords separately) :keyword spires: boolen meaning spires output style :keyword only_core_tags: boolean \"\"\" categories={} single_keywords_p=_sort_kw_matches(single_keywords", "label": 0}, {"snippet_id": 79820, "code": "\"template\",help=\"Malicious payload to use for code execution detection. Default is to use every known templates. For a complete list of templates, see the TEMPLATE section.\") parser.add_argument(\"-r\",\"", "label": 0}, {"snippet_id": 46382, "code": "\"\" list.__init__(self) self._names=dict() if toclone: self.extend(map(str, toclone) if plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key", "label": 0}, {"snippet_id": 15211, "code": "'no_proxy']='127.0.0.1,localhost' signal.signal( signal.SIGINT, signal.SIG_IGN) NUM_YCMD_STDERR_LINES_ON_CRASH=30 SERVER_CRASH_MESSAGE_STDERR_FILE=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer)", "label": 0}, {"snippet_id": 29884, "code": " arg: filepatterns as list or one single filepattern, second arg(optional): a function to combine wildcard values (itertools.product per default) **wildcards --the wildcards as keyword arguments with their", "label": 0}, {"snippet_id": 43731, "code": "[] self.jobscript=jobscript self.persistence=None self.global_resources=None self.globals=globals() self._subworkflows=dict() self.overwrite_shellcmd=overwrite_shellcmd self.overwrite_config=overwrite_config", "label": 0}, {"snippet_id": 19373, "code": " \"\"\" For the PyDevd CLI handling see: https://github.com/fabioz/PyDev.Debugger/blob/master/_pydevd_bundle/pydevd_command_line_handling.py https://github.com/fabioz/PyDev.Debugger/blob/master/pydevd.py ", "label": 0}, {"snippet_id": 18219, "code": "(last{0} lines):\\n\\n'.format( NUM_YCMD_STDERR_LINES_ON_CRASH)) SERVER_CRASH_MESSAGE_SAME_STDERR=( 'The ycmd server SHUT DOWN(restart with:YcmRestartServer). ' ' check console output for logs!') SERVER_IDLE_SUICIDE_SECONDS", "label": 0}, {"snippet_id": 51109, "code": "*}\") def __eq__(self, other): f=other._file if isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+", "label": 0}, {"snippet_id": 11189, "code": " value or current_value try: with open(file_name, 'r') as config_file: for line in config_file.xreadlines(): etag=extract(Header.ETAG_COMMENT, etag) mtime=extract(Header.MTIME_COMMMENT, mtime) if etag and", "label": 0}, {"snippet_id": 16690, "code": " debug_info=BaseRequest.PostDataToHandler( BuildRequestData(), 'debug_info') else: debug_info='Server crashed, no debug info from server' debug_info +='\\nServer running at:{0}'.format( BaseRequest.server_location", "label": 0}, {"snippet_id": 87541, "code": " zinc_args.extend(enabled_args) for option_set, disabled_args in self.get_options().compiler_option_sets_disabled_args.items(): if option_set not in compiler_option_sets: if option_set=='fatal_warnings", "label": 0}, {"snippet_id": 70820, "code": ", [\"nodes\", NodeSet.fromlist(target.servers)], [\"device\", target.dev], [\"index\", target.index], [\"status\", status]])) ldic.sort() layout=AsciiTableLayout() layout.set_show_header(True) layout.set_column", "label": 0}, {"snippet_id": 2409, "code": " STARTED_BY_HAND=3 DEP_FAILED=4 class ControlCenter: def __init__(self, configfile=None): self.logger=logging.getLogger(__name__) self.logger.setLevel(logging.DEBUG) self.configfile=configfile self.nodes={} self", "label": 0}, {"snippet_id": 20919, "code": ") except ClosedError: pass if self._listenerthread !=threading.current_thread(): self._listenerthread.join(timeout=1.0) if self._listenerthread.is_alive(): warnings.warn('session listener still running", "label": 0}, {"snippet_id": 62664, "code": " reset the Device should be as if it was just constructed. Most importantly the quantum state is reset to its initial value. \"\"\" backend=pq.backends.ClassicalSimulator(**self.filter_kwargs_for_backend(self", "label": 0}, {"snippet_id": 53280, "code": "=set(other.temp_output) self.protected_output=set(other.protected_output) self.touch_output=set(other.touch_output) self.subworkflow_input=dict(other.subworkflow_input) self.resources=other.resources self", "label": 0}, {"snippet_id": 28948, "code": "] >=30: self._state=\"NE(%d\\xb0)\" % data['GustAngle'] elif data['GustAngle'] >=0: self._state=\"N(%d\\xb0)\" % data['GustAngle'] elif self.type=='guststrength': self._state=data['GustStrength'] elif self.type", "label": 0}, {"snippet_id": 18419, "code": ".PostVimMessage( SERVER_CRASH_MESSAGE_SAME_STDERR) def ServerPid( self): if not self._server_popen: return -1 return self._server_popen.pid def _ServerCleanup( self): if self._IsServerAlive(): self._server_popen", "label": 0}, {"snippet_id": 51119, "code": " isinstance(other, _IOFile) else other return self._file==f def __hash__(self): return self._file.__hash__() _wildcard_regex=re.compile( \"\\{\\s*(?P<name>\\w+?)(\\s*,\\s*(?P<constraint>([^\\{\\}]+|\\{\\d+(,\\d+)?\\})*))", "label": 0}, {"snippet_id": 54236, "code": " get_wildcards(self, requested_output): \"\"\" Update the given wildcard dictionary by matching regular expression output files to the requested concrete ones. Arguments wildcards --a dictionary of wildcards", "label": 0}, {"snippet_id": 56503, "code": ".product_id) @require_GET def form(request): \"\"\"Response get form ajax call, most using in dialog\"\"\" internal_parameters=['app_form', 'format'] parameters=strip_parameters(request.GET, internal_parameters", "label": 1}, {"snippet_id": 61035, "code": " projectors such that:math:`A=\\sum_k a_k P_k`. \"\"\" d, v=eigh(A) P=[] for k in range(2): temp=v[:, k] P.append(np.outer(temp.conj(), temp)) return d, P I=np.eye(2) X=np.array([[0, 1],[1, 0]]) Y=np.array([[0, -1j]", "label": 0}, {"snippet_id": 34832, "code": ": self._regex=re.compile(regex(self.file)) return self._regex def constant_prefix(self): first_wildcard=_wildcard_regex.search(self.file) if first_wildcard: return self.file[:first_wildcard.start()] return", "label": 0}, {"snippet_id": 81991, "code": "\",help=\"Specify a regular expression to detect code execution. Overrides the default code execution detection regex defined in the template in use.\",type=valid_regex) requiredNamedArgs=parser.add_argument_group", "label": 0}, {"snippet_id": 1201, "code": " RegisteredServices from.serializers import BoxDetailsSerializer, RegisteredServicesSerializer import common, sqlite3, subprocess, NetworkManager, os, crypt, pwd, getpass, spwd nm=NetworkManager.NetworkManager", "label": 1}, {"snippet_id": 6597, "code": " extract_acronyms=False, api=False, **kwargs): \"\"\"Outputs keywords reading a local file. Arguments and output are the same as for:see: get_keywords_from_text() \"\"\" log.info(\"Analyzing keywords for local file %s.\" %", "label": 1}, {"snippet_id": 10084, "code": "(spires)) else: for kw in ckw.getComponents(): for fieldcode in kw.fieldcodes: fieldcodes.setdefault(fieldcode, set()).add('%s*' % ckw.output(spires)) fieldcodes.setdefault('*', set()).add(kw.output(spires", "label": 0}, {"snippet_id": 74810, "code": " to integer.\") if \"blosc_shuffle_mode\" in runtime_config.vcf_to_zarr: blosc_shuffle_mode_str=runtime_config.vcf_to_zarr[\"blosc_shuffle_mode\"] if isint(blosc_shuffle_mode_str): blosc_shuffle_mode_int=int", "label": 0}, {"snippet_id": 43133, "code": ".dynamic_input, fail_dynamic=self.dynamic_output) def _apply_wildcards(newitems, olditems, wildcards, wildcards_obj, concretize=apply_wildcards, ruleio=None): for name, item in olditems.allitems(): start", "label": 0}, {"snippet_id": 10177, "code": "=len(info[0]) category[skw.output(spires)]=skw.type for ckw, info in ckw_matches: if ckw.core: output[ckw.output(spires)]=len(info[0]) else: i=0 for c in ckw.getComponents(): if c.core: output[c.output", "label": 0}, {"snippet_id": 11564, "code": ": value=section_data[key] self.icinga_lines.append((\"%s%-45s%s\" %(self.indent, key, self.value_to_icinga(value)))) self.write_line(\"}\") @staticmethod def value_to_icinga(value): \"\"\"Convert a scalar or list", "label": 1}, {"snippet_id": 8155, "code": " recid abs_path=os.path.join(tmp_directory, filename) return abs_path def _parse_marc_code(field): \"\"\"Parse marc field and return default indicators if not filled in.\"\"\" field=str(field) if len(field) ", "label": 0}, {"snippet_id": 23752, "code": " return int(output)/1024/1024 except ValueError: raise OSUtilError(\"Failed to get total memory:{0}\".format(output)) def get_processor_cores(self): ret, output=shellutil.run_get_output(\"sysctl hw.ncpu |awk '", "label": 0}, {"snippet_id": 62398, "code": "(qubit) def _deallocate3(self): \"\"\"Another proposal for how to deallocate all qubits to make ProjectQ happy Unsuitable because: Throws an error if the probability for the given collapse is 0. \"\"\" if self", "label": 0}, {"snippet_id": 48459, "code": "*kwlogs): for item in logs: self._set_log_item(item) for name, item in kwlogs.items(): self._set_log_item(item, name=name) def _set_log_item(self, item, name=None): if isinstance(item, str) or callable", "label": 0}, {"snippet_id": 73130, "code": " with open(file_path_local, \"wb\") as local_file: ftp.retrbinary('RETR{}'.format(file), local_file.write) print(\"[Setup][FTP]({}/{}) File downloaded:{}\".format(file_counter, file_list_total, file_path_local", "label": 0}, {"snippet_id": 8590, "code": " has %d lines and %d words.\" %(line_nb, word_nb)) return lines def executable_exists(executable): \"\"\"Tests if an executable is available on the system.\"\"\" for directory in os.getenv(\"PATH\").split(\":\"): if", "label": 1}, {"snippet_id": 82728, "code": " proxyUser !=None and proxyPass !=None: \t\tproxy +=proxyUser+\":\"+proxyPass+\"@\" \tproxy +=proxyHostname \tif proxyPort !=None: \t\tproxy +=\":\"+proxyPort \tif proxyProtocol==\"https\": \t\tproxies={\"https\":proxy} \telse: \t", "label": 0}, {"snippet_id": 82989, "code": " \t\t\tfutures.append(f) \t\tfor future in concurrent.futures.as_completed(futures): \t\t\tres=future.result() \t\t\tattemptsTested +=1 \t\t\tif not stopThreads: \t\t\t\tif res[\"codeExec\"]: \t\t\t\t\tfoundEntryPoint=future.a", "label": 0}, {"snippet_id": 24730, "code": ".module_id=='2': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif data['battery_vp'] >=4000: self", "label": 0}, {"snippet_id": 27643, "code": ".type=='battery_vp' and self.module_id=='5': if data['battery_vp'] >=5500: self._state=\"Full\" elif data['battery_vp'] >=5000: self._state=\"High\" elif data['battery_vp'] >=4500: self._state=\"Medium\" elif", "label": 0}, {"snippet_id": 82546, "code": " without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable local, state and federal laws. Developers assume no liability and are not responsible for any misuse", "label": 0}, {"snippet_id": 52974, "code": ".dynamic_output or self.wildcards_dict==other.wildcards_dict) def __lt__(self, other): return self.rule.__lt__(other.rule) def __gt__(self, other): return self.rule.__gt__(other.rule) def __hash__(self)", "label": 0}, {"snippet_id": 59095, "code": ".projectq This plugin provides the interface between OpenQML and ProjecQ. It enables OpenQML to optimize quantum circuits simulable with ProjectQ. ProjecQ supports several different backends. Of those, the", "label": 0}, {"snippet_id": 40777, "code": " comb in map(dict, combinator(*flatten(wildcards))) for filepattern in filepatterns] except KeyError as e: raise WildcardError(\"No values given for wildcard{}.\".format(e)) def limit(pattern, **wildcards", "label": 0}, {"snippet_id": 77709, "code": " save_targets(self): data={ 'targets': targets, 'forums': forums, 'domains': domains, 'sets': self.pc.sets, } with open(self.targetsfile, 'wb') as f: f.write(pickle.dumps(data, pickle.HIGHEST_PROTOCOL)) def", "label": 0}, {"snippet_id": 1320, "code": " return wifi def add_user(username, password): encPass=crypt.crypt(password,\"22\") os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username) def add_newWifiConn(wifiname, wifipass): print(wlans) wlan0", "label": 1}, {"snippet_id": 12869, "code": " encoding=r.encoding) as file_to_fix: file_to_fix.write(r.text) cmd='autopep8 file_to_fix.py --diff{arg_to_ignore}'.format( arg_to_ignore=arg_to_ignore) proc=subprocess.Popen(cmd, shell=True, stdout=subprocess", "label": 0}, {"snippet_id": 67198, "code": ".RemoteCallEventHandler import RemoteCallEventHandler from Exceptions import CommandException from Shine.FSUtils import open_lustrefs import Shine.Lustre.EventHandler from Shine.Lustre.FileSystem import", "label": 0}, {"snippet_id": 59178, "code": " autosummary:: Gate Observable PluginAPI ---- \"\"\" import logging as log import numpy as np from numpy.random import(randn,) from openqml import Device, DeviceError from openqml import Variable import projectq as", "label": 0}, {"snippet_id": 67061, "code": ".Globals import Globals from Shine.FSUtils import create_lustrefs from Base.Command import Command from Base.Support.LMF import LMF from Base.Support.Nodes import Nodes class Install(Command): \"\"\" shine", "label": 0}, {"snippet_id": 82186, "code": "=\"store_true\",required=False,dest=\"detectAllEntryPoints\",help=\"Force detection of every entry points. Will not stop at first code exec found.\") parser.add_argument(\"-T\",\"--threads\",metavar=\"Threads\",nargs", "label": 0}, {"snippet_id": 46598, "code": " __getitem__(self, key): try: return super().__getitem__(key) except TypeError: pass return getattr(self, key) def __hash__(self): return hash(tuple(self)) def __str__(self): return \" \".join(map(str, self)", "label": 0}, {"snippet_id": 53793, "code": " have to be specified as strings or lists of strings.\") @property def params(self): return self._params def set_params(self, *params, **kwparams): for item in params: self._set_params_item(item) for name,", "label": 0}, {"snippet_id": 74933, "code": "=runtime_config.benchmark[\"benchmark_dataset\"] if \"benchmark_aggregations\" in runtime_config.benchmark: self.benchmark_aggregations=config_str_to_bool(runtime_config.benchmark[\"benchmark_aggregations\"])", "label": 0}, {"snippet_id": 9466, "code": " use, left for historical reasons :keyword author_keywords: dictionary of extracted keywords :keyword acronyms: dictionary of extracted acronyms :return: str, marxml \"\"\" output=['<collection><record>\\n'", "label": 0}, {"snippet_id": 6951, "code": ", fulltext): \"\"\"Finds out human defined keyowrds in a text string. Searches for the string \"Keywords:\" and its declinations and matches the following words. :var skw_db: list single kw object :var ckw_db", "label": 0}, {"snippet_id": 68736, "code": " if target.has_rewrite_ldd_flag(): flags.append(\"rewrite_ldd\") if target.has_writeconf_flag(): flags.append(\"writeconf\") if target.has_upgrade14_flag(): flags.append(\"upgrade14\") if target.has_param_flag", "label": 0}, {"snippet_id": 90234, "code": "): \"\"\"Return the jvm locations discovered in this environment. :returns: An iterator over all discovered jvm locations. :rtype: iterator of:class:`DistributionEnvironment.Location` \"\"\" class _EnvVarEnvironment", "label": 0}, {"snippet_id": 79009, "code": ".action) \t\tself.logger.debug(\"Using following URL for file upload: %s\",self.uploadUrl) \t\tif not self.uploadsFolder and not self.trueRegex: \t\t\tself.logger.warning(\"No uploads folder nor true regex defined", "label": 0}, {"snippet_id": 49080, "code": " update_config class Workflow: def __init__(self, snakefile=None, snakemakepath=None, jobscript=None, overwrite_shellcmd=None, overwrite_config=dict(), overwrite_workdir=None, overwrite_configfile=None", "label": 0}, {"snippet_id": 87250, "code": "._write_scalac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, JavacPlugin): self._write_javac_plugin_info(compile_context.classes_dir, target) elif isinstance(target, AnnotationProcessor)", "label": 0}, {"snippet_id": 8050, "code": " keywords: r[k]=v return r def _sort_kw_matches(skw_matches, limit=0): \"\"\"Return a resized version of keywords to the given length.\"\"\" sorted_keywords=list(skw_matches.items()) sorted_keywords.sort(_skw_matches_comparator", "label": 0}, {"snippet_id": 50976, "code": ".file, f), mode) else: lchmod(self.file, mode) def remove(self): remove(self.file) def touch(self): try: lutime(self.file, None) except OSError as e: if e.errno==2: raise MissingOutputException( \"Output", "label": 1}, {"snippet_id": 22833, "code": " modify auth user{0} password '{1}'\".format(username, password) ret, output=shellutil.run_get_output(cmd, log_cmd=False, chk_err=True) if ret !=0: raise OSUtilError( \"Failed to set password for{0}:{1}\"", "label": 0}, {"snippet_id": 43638, "code": ".dag import DAG from snakemake.scheduler import JobScheduler from snakemake.parser import parse import snakemake.io from snakemake.io import protected, temp, temporary, expand, dynamic, glob_wildcards,", "label": 1}, {"snippet_id": 86385, "code": ".relpath(f.path.replace('.java', '.class'), ctx.target.target_base) for f in input_snapshot.files if f.path.endswith('.java') ) exec_process_request=ExecuteProcessRequest( argv=tuple(cmd), input_files=input_snapshot", "label": 0}, {"snippet_id": 65175, "code": " succeeded\" %(target.type.upper(), target.get_id(), target.dev) def ev_starttarget_failed(self, node, target, rc, message): if rc: strerr=os.strerror(rc) else: strerr=message print \"Failed to start %s %s(%s):", "label": 0}, {"snippet_id": 1724, "code": ":queryset.username}, safe=False) elif action=='getDashboardCards': print(action) con=sqlite3.connect(\"dashboard.sqlite3\") cursor=con.cursor() cursor.execute(common.Q_DASHBOARD_CARDS) rows=cursor.fetchall", "label": 0}, {"snippet_id": 52689, "code": " f in self.dynamic_output: if not self.expand_dynamic( f_, restriction=self.wildcards, omit_value=_IOFile.dynamic_fill): files.add(\"{}(dynamic)\".format(f_)) elif not f.exists: files.add(f) return files", "label": 0}, {"snippet_id": 71202, "code": ".state==RUNTIME_ERROR: status=\"CHECK FAILURE\" else: status=\"UNKNOWN\" if target.dev_size >=TERA: dev_size=\"%.1fT\" %(target.dev_size/TERA) elif target.dev_size >=GIGA: dev_size=\"%.1fG\" %(target.dev_size/GIGA", "label": 0}, {"snippet_id": 49031, "code": " Ruleorder from snakemake.exceptions import RuleException, CreateRuleException, \\ UnknownRuleException, NoRulesException, print_exception, WorkflowError from snakemake.shell import shell from snakemake.dag", "label": 0}, {"snippet_id": 48641, "code": ", end=len(newitems) if is_iterable else None) if wildcards is None: wildcards=dict() missing_wildcards=self.wildcard_names -set(wildcards.keys()) if missing_wildcards: raise RuleException( \"Could not resolve", "label": 0}, {"snippet_id": 40981, "code": " plainstr else toclone) if isinstance(toclone, Namedlist): self.take_names(toclone.get_names()) if fromdict: for key, item in fromdict.items(): self.append(item) self.add_name(key) def add_name(self, name): \"", "label": 0}, {"snippet_id": 57107, "code": " value=data.get('value') object_pk=[int(a) for a in object_pk_str.split(',')] if not field or not value or not object_pk or not ctype: return say_no( 'Following fields are required -content_type, ' 'object_pk", "label": 0}, {"snippet_id": 83281, "code": " model.Job.states.RUNNING) return job_state def __async_update( self, full_status): job_id=full_status[ \"job_id\"] job_state=self.__find_watched_job( job_id) if not job_state: sleep( 2) job_state=self.__find_watched_job", "label": 0}, {"snippet_id": 41290, "code": ".format(configpath)) def load_configfile(configpath): \"Loads a JSON or YAML configfile as a dict, then checks that it's a dict.\" config=_load_configfile(configpath) if not isinstance(config, dict): raise", "label": 0}, {"snippet_id": 70734, "code": ".status_view_targets(fs) elif view.startswith(\"disk\"): self.status_view_disks(fs) else: raise CommandBadParameterError(self.view_support.get_view(), \"fs, targets, disks\") return result def status_view_targets(self, fs):", "label": 1}, {"snippet_id": 50464, "code": " def decorate(ruleinfo): ruleinfo.params=(params, kwparams) return ruleinfo return decorate def message(self, message): def decorate(ruleinfo): ruleinfo.message=message return ruleinfo return decorate def", "label": 0}, {"snippet_id": 44477, "code": " return True elif list_input_changes: items=list(chain(*map(self.persistence.input_changed, dag.jobs))) if items: print(*items, sep=\"\\n\") return True elif list_params_changes: items=list( chain(*map(self", "label": 0}, {"snippet_id": 41839, "code": "() if self.benchmark and(requested is None or self.benchmark in requested): if not self.benchmark.exists: files.add(self.benchmark) for f, f_ in zip(self.output, self.rule.output): if requested is None", "label": 0}, {"snippet_id": 88989, "code": " dependencies=dependencies, derived_from=derived_from, **kwargs) new_target=self.build_graph.get_target(address) return new_target def targets(self, predicate=None, **kwargs): \"\"\"Selects targets in-play in", "label": 0}, {"snippet_id": 86913, "code": " 'Options not listed here are subject to change/removal. The value of the dict ' 'indicates that an option accepts an argument.') register('--incremental', advanced=True, type=bool, default=True, help=", "label": 0}, {"snippet_id": 58538, "code": " 'No caserun found.'}) def test_add_comment_to_case_runs(self): self.client.login( username=self.tester.username, password='password') new_comment='new comment' response=self.client.post( self.many_comments_url", "label": 0}, {"snippet_id": 13576, "code": ", 0)\r \r def updateEyes():\r while isRunning:\r io.set( EYES_CLOSE, 1)\r io.set( EYES_OPEN, 0)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 0)\r io.set( EYES_OPEN, 1)\r time.sleep(0.4)\r io.set( EYES_CLOSE, 1)\r io.set", "label": 0}, {"snippet_id": 55334, "code": ", cores, local_cores=local_cores, dryrun=dryrun, touch=touch, cluster=cluster, cluster_config=cluster_config, cluster_sync=cluster_sync, jobname=jobname, immediate_submit=immediate_submit, quiet=quiet,", "label": 0}, {"snippet_id": 31807, "code": "(wildcards=non_dynamic_wildcards) return branch, non_dynamic_wildcards return branch def has_wildcards(self): \"\"\" Return True if rule contains wildcards. \"\"\" return bool(self.wildcard_names) @property def", "label": 0}, {"snippet_id": 90189, "code": " given the JAVA_HOME directory. :param string home: The path of the JAVA_HOME directory. :returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None) @classmethod def from_bin(cls", "label": 0}, {"snippet_id": 77964, "code": " targets: targets[domain]=[] tlist=targets[domain] id_=str(id_) tuser=tuser or '' t=(tuser, id_) if t in protected: raise ValueError('%s is protected' % repr(t)) if t not in tlist: logger.info('Appending ", "label": 0}, {"snippet_id": 20270, "code": " launch_script(self, filename, *argv, **kwargs): if self.closed: raise RuntimeError('debug client closed') if self._adapter is not None: raise RuntimeError('debugger already running') assert self._session", "label": 0}, {"snippet_id": 44010, "code": " list_code_changes=False, list_input_changes=False, list_params_changes=False, summary=False, detailed_summary=False, latency_wait=3, benchmark_repeats=3, wait_for_files=None, nolock=False, unlock=False,", "label": 0}, {"snippet_id": 66462, "code": "=os.strerror(rc) else: strerr=message print \"%s: Failed to unmount FS %s from %s: %s\" % \\ (node, client.fs.fs_name, client.mount_path, strerr) if rc: print message class Umount(FSClientLiveCommand): \"\"", "label": 0}, {"snippet_id": 22159, "code": "(self, conf): super(AnsiblePlugin, self).__init__(conf) def generate_ansible_playbook_from_template(self, template_file, data): templateLoader=jinja2.FileSystemLoader( searchpath=\"/\") templateEnv=jinja2", "label": 0}, {"snippet_id": 79256, "code": "\t\tif self.shouldLog: \t\t\t\t\tself.logger.info(\"\\033[1m\\033[42mExtension %s seems valid for this form.\\033[m\", ext) \t\t\t\t\tif r !=True: \t\t\t\t\t\tself.logger.info(\"\\033[1;32mTrue regex matched the following information", "label": 0}, {"snippet_id": 56334, "code": " objects=_InfoObjects(request=request, product_id=request.GET.get('product_id')) info_type=getattr(objects, request.GET.get('info_type')) if not info_type: return HttpResponse('Unrecognizable info-type", "label": 0}, {"snippet_id": 9718, "code": " not only_core_tags: results[\"Author keywords\"]=_get_author_keywords(author_keywords, spires=spires) results[\"Composite keywords\"]=_get_compositekws(resized_ckw, spires=spires) results[\"Single keywords", "label": 0}, {"snippet_id": 53487, "code": " benchmark(self, benchmark): self._benchmark=IOFile(benchmark, rule=self) @property def input(self): return self._input def set_input(self, *input, **kwinput): \"\"\" Add a list of input files. Recursive lists", "label": 0}, {"snippet_id": 61328, "code": " 'RY': fry, 'RZ': frz, 'Rot': fr3 } class DefaultQubit(Device): \"\"\"Default qubit device for OpenQML. wires(int): the number of modes to initialize the device in. cutoff(int): the Fock space truncation.", "label": 0}, {"snippet_id": 79128, "code": "\tfilename=os.path.basename(fd.name) \t\t\tif self.shouldLog: \t\t\t\tself.logger.debug(\"Sending file %s with mime type: %s\",filename,mime) \t\t\tfu=self.session.post(self.uploadUrl,files={self.inputName:(filename,fd", "label": 1}, {"snippet_id": 9086, "code": " get_keywords_output(single_keywords, composite_keywords, taxonomy_name, author_keywords, acronyms, output_mode, output_limit, spires, only_core_tags) def extract_single_keywords(skw_db, fulltext): \"\"\"Find", "label": 1}, {"snippet_id": 41621, "code": ".format_wildcards(self.rule.message) if self.rule.message else None) except AttributeError as ex: raise RuleException(str(ex), rule=self.rule) except KeyError as ex: raise RuleException(\"Unknown variable in message", "label": 0}, {"snippet_id": 29795, "code": " def protected(value): \"\"\" A flag for a file that shall be write protected after creation. \"\"\" if is_flagged(value, \"temp\"): raise SyntaxError( \"Protected and temporary flags are mutually exclusive.\") return", "label": 0}, {"snippet_id": 90198, "code": ":returns: The java distribution location. \"\"\" return cls(home_path=home, bin_path=None) @classmethod def from_bin(cls, bin_path): \"\"\"Creates a location given the `java` executable parent directory. :param", "label": 0}, {"snippet_id": 88751, "code": " which tasks can submit background work. :API: public \"\"\" return self.run_tracker.background_worker_pool() def subproc_map(self, f, items): \"\"\"Map function `f` over `items` in subprocesses and return the", "label": 0}, {"snippet_id": 59821, "code": ": expectation_value=[ self.eng.backend.get_expectation_value(pq.ops.QubitOperator(\"Z\"+'0'),[qubit]) for qubit in self.reg] variance=[1 -e**2 for e in expectation_value] else: raise NotImplementedError(", "label": 0}, {"snippet_id": 59983, "code": " SwapGate, Rx, Ry, Rz, R, CNOT, CZ]]) _observables=set([ key for(key,val) in operator_map.items() if val in[ZGate, AllZGate]]) _circuits={} _backend_kwargs=['use_hardware', 'num_runs', 'verbose', 'user'", "label": 0}, {"snippet_id": 70324, "code": "(self, status): return self.target_status_rc_map[status] def execute(self): result=0 self.init_execute() vlevel=self.verbose_support.get_verbose_level() target=self.target_support.get_target() for fsname", "label": 0}, {"snippet_id": 68323, "code": ", AsciiTableLayout.CENTER) layout.set_column(\"nodes\", 3, AsciiTableLayout.LEFT, \"nodes\", AsciiTableLayout.CENTER) layout.set_column(\"device\", 4, AsciiTableLayout.LEFT, \"device\", AsciiTableLayout.CENTER", "label": 0}, {"snippet_id": 47302, "code": ".expanded_output) def check_protected_output(self): protected=list(filter(lambda f: f.protected, self.expanded_output)) if protected: raise ProtectedOutputException(self.rule, protected) def prepare(self)", "label": 0}, {"snippet_id": 87775, "code": "=self._zinc.dist for path in classpath: if not os.path.isabs(path): raise TaskError('Classpath entries provided to zinc should be absolute. ' '{} is not.'.format(path)) if is_outside(path, self.get_options", "label": 0}, {"snippet_id": 74355, "code": " input_str: str :return: bool \"\"\" return input_str.lower() in['true', '1', 't', 'y', 'yes'] class DataDirectoriesConfigurationRepresentation: input_dir=\"./data/input/\" download_dir=input_dir +\"download", "label": 0}, {"snippet_id": 89156, "code": " return self.build_graph.resolve(spec) def scan(self, root=None): \"\"\"Scans and parses all BUILD files found under ``root``. Only BUILD files found under ``root`` are parsed as roots in the graph, but any", "label": 0}, {"snippet_id": 79455, "code": "\":False,\"codeExec\":False} \t\tif uploadRes: \t\t\tresult[\"uploaded\"]=True \t\t\tif self.shouldLog: \t\t\t\tself.logger.info(\"\\033[1;32mUpload of '%s' with mime type %s successful\\033[m\",fu[1], mime) \t\t\t \t\t\tif uploadRes", "label": 0}, {"snippet_id": 89852, "code": " be a binary name, given{} of type{}'.format(name, type(name))) self.validate() return self._validated_executable(name) def validate(self): \"\"\"Validates this distribution against its configured constraints", "label": 0}, {"snippet_id": 27815, "code": "'WindAngle'] >=150: self._state=\"S(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=120: self._state=\"SE(%d\\xb0)\" % data['WindAngle'] elif data['WindAngle'] >=60: self._state=\"E(%d\\xb0)\" % data['WindAngle", "label": 0}, {"snippet_id": 11700, "code": " datetime import hmac import json import os import re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository): \"\"\"Update", "label": 0}, {"snippet_id": 80944, "code": ") \t\tself.postData=postData \t\tself.formUrl=formUrl \t\turl=urlparse(self.formUrl) \t\tself.schema=url.scheme \t\tself.host=url.netloc \t\tself.uploadUrl=urljoin(formUrl, formAction) \t\tself.session=session \t\tself", "label": 0}, {"snippet_id": 78636, "code": " 'dbgraph': 'grapher', 'dbnav': 'navigator' } class Wrapper(object): def __init__(self, options=None): self.options=options def write(self): try: sys.stdout.write(Writer.write(self.run())) except BaseException", "label": 0}, {"snippet_id": 50574, "code": " return ruleinfo return decorate def norun(self): def decorate(ruleinfo): ruleinfo.norun=True return ruleinfo return decorate def run(self, func): return RuleInfo(func) @staticmethod def _empty_decorator", "label": 0}, {"snippet_id": 72451, "code": ", data_service def get_cli_arguments(): \"\"\" Returns command line arguments. Returns: args object from an ArgumentParses for fetch data(boolean, from a server), label(optional, for naming the benchmark run", "label": 1}, {"snippet_id": 58528, "code": "( str(response.content, encoding=settings.DEFAULT_CHARSET), {'rc': 1, 'response': 'No caserun found.'}) def test_add_comment_to_case_runs(self): self.client.login( username=self.tester.username, password", "label": 0}, {"snippet_id": 8214, "code": " also provides the utility 'is_pdf' that uses GNU file in order to determine if a local file is a PDF file. This module is STANDALONE safe \"\"\" import os import re import tempfile import urllib2 from invenio", "label": 1}, {"snippet_id": 92402, "code": " os.environ) self.assertNotIn('AAA', os.environ) def test_hermetic_environment_unicode(self): UNICODE_CHAR='\u00a1' ENCODED_CHAR=UNICODE_CHAR.encode('utf-8') expected_output=UNICODE_CHAR if PY3 else ENCODED_CHAR", "label": 1}, {"snippet_id": 82112, "code": " exclusiveVerbosityArgs=parser.add_mutually_exclusive_group() exclusiveVerbosityArgs.add_argument(\"-v\",action=\"store_true\",required=False,dest=\"verbose\",help=\"Verbose mode\") exclusiveVerbosityArgs.add_argument(\"-vv\",action", "label": 0}, {"snippet_id": 78337, "code": " try: self.targets.remove(t) except ValueError as e: pass self.w.sleep(self.errortimeout) except exc.TemporaryError as e: self.schedule(self.add_comment,(t, msg)) self.w.sleep(self.errortimeout) except", "label": 0}, {"snippet_id": 80133, "code": " detection fails due to:(1) Form loaded using Javascript(2) Multiple file upload forms in URL.\") manualFormArgs.add_argument(\"--input-name\",metavar=\"image\",dest=\"inputName\",help=\"Name of input for file", "label": 0}, {"snippet_id": 73446, "code": "(\"[Setup][Data] Converting VCF file to Zarr format:{}\".format(path_str)) print(\" -Output:{}\".format(path_zarr_output)) convert_to_zarr(input_vcf_path=path_str, output_zarr_path=path_zarr_output, conversion_config", "label": 0}, {"snippet_id": 29997, "code": " values in wildcards.items() }) def glob_wildcards(pattern): \"\"\" Glob the values of the wildcards by matching the given pattern to the filesystem. Returns a named tuple with a list of values for each wildcard", "label": 0}, {"snippet_id": 61745, "code": ": 2^n*2^n matrix \"\"\" if U.shape !=(4, 4): raise ValueError('4x4 matrix required.') if len(wires) !=2: raise ValueError('Two target subsystems required.') wires=np.asarray(wires) if np.any(wires < 0) or", "label": 0}, {"snippet_id": 11707, "code": " re import subprocess import time import psycopg2 import requests import unidiff import yaml from flask import abort def update_users(repository): \"\"\"Update users of the integration in the database\"\"\" if", "label": 0}, {"snippet_id": 77544, "code": "]: self.log.debug('Loaded user %s:%s', domain, ud['login']) uq.put(ud) self.userqueues[domain]=uq except Exception as e: self.log.exception(e) self.log.error('Failed to load users') def save_users(self", "label": 0}, {"snippet_id": 2431, "code": " self.nodes={} self.server=[] self.host_list=[] if configfile: self.load_config(configfile) self.session_name=self.config[\"name\"] with open('debug-result.yml', 'w') as outfile: dump(self.config, outfile", "label": 0}, {"snippet_id": 3442, "code": ".session: self.logger.error(\" Init aborted. No session was found!\") else: self.logger.debug(self.config) window=find_window(self.session, self.window_name) if window: self.logger.debug(\"window '%s' found", "label": 0}, {"snippet_id": 57251, "code": "': for t in targets: field='close_date' t.log_action( who=request.user, action='Field %s changed from %s to %s.' %( field, getattr(t, field), now ) ) if t.tested_by !=request.user: field='tested_by' t.log_action", "label": 0}, {"snippet_id": 37293, "code": " output(self): return self._output @property def products(self): products=list(self.output) if self.benchmark: products.append(self.benchmark) return products def set_output(self, *output, **kwoutput): \"\"", "label": 0}, {"snippet_id": 13178, "code": " @{}'s{}\".format(author, full_name) } r=requests.patch(url, data=json.dumps(request_json), headers=headers, auth=auth) if r.status_code !=200: data[\"error\"]=\"Could not update description of the fork\" def", "label": 0}, {"snippet_id": 49988, "code": ".resources_info( \"Provided resources: \" +provided_resources) ignored_resources=format_resource_names( set(resource for job in dag.needrun_jobs for resource in job.resources_dict if resource not in resources))", "label": 0}, {"snippet_id": 60934, "code": ": dict[str->Circuit]: circuit templates \"\"\" return self._circuits @property def result(self): \"\"\"Get the circuit result. Returns: float or int \"\"\" return self._out @classmethod def capabilities(cls): \"", "label": 0}, {"snippet_id": 18123, "code": " vim import tempfile import json import signal from subprocess import PIPE from ycm import vimsupport from ycm import utils from ycm.diagnostic_interface import DiagnosticInterface from ycm.completers.all", "label": 0}]