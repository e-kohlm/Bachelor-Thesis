{
  "best_metric": 0.9580279813457695,
  "best_model_checkpoint": "../saved_models/optimized_study2_trial/checkpoint-4422",
  "epoch": 11.0,
  "eval_steps": 500,
  "global_step": 4422,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024875621890547263,
      "grad_norm": 19.64794921875,
      "learning_rate": 6.579710144927535e-08,
      "loss": 0.5815,
      "step": 1
    },
    {
      "epoch": 0.024875621890547265,
      "grad_norm": 63.22893524169922,
      "learning_rate": 6.579710144927536e-07,
      "loss": 0.6121,
      "step": 10
    },
    {
      "epoch": 0.04975124378109453,
      "grad_norm": 19.426000595092773,
      "learning_rate": 1.3159420289855071e-06,
      "loss": 0.538,
      "step": 20
    },
    {
      "epoch": 0.07462686567164178,
      "grad_norm": 13.109743118286133,
      "learning_rate": 1.973913043478261e-06,
      "loss": 0.421,
      "step": 30
    },
    {
      "epoch": 0.09950248756218906,
      "grad_norm": 33.533321380615234,
      "learning_rate": 2.6318840579710143e-06,
      "loss": 0.389,
      "step": 40
    },
    {
      "epoch": 0.12437810945273632,
      "grad_norm": 10.26091480255127,
      "learning_rate": 3.289855072463768e-06,
      "loss": 0.3066,
      "step": 50
    },
    {
      "epoch": 0.14925373134328357,
      "grad_norm": 30.03227996826172,
      "learning_rate": 3.947826086956522e-06,
      "loss": 0.3587,
      "step": 60
    },
    {
      "epoch": 0.17412935323383086,
      "grad_norm": 10.031620979309082,
      "learning_rate": 4.605797101449275e-06,
      "loss": 0.3423,
      "step": 70
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 14.327452659606934,
      "learning_rate": 5.2637681159420285e-06,
      "loss": 0.306,
      "step": 80
    },
    {
      "epoch": 0.22388059701492538,
      "grad_norm": 8.158360481262207,
      "learning_rate": 5.921739130434783e-06,
      "loss": 0.3176,
      "step": 90
    },
    {
      "epoch": 0.24875621890547264,
      "grad_norm": 10.882086753845215,
      "learning_rate": 6.579710144927536e-06,
      "loss": 0.3274,
      "step": 100
    },
    {
      "epoch": 0.2736318407960199,
      "grad_norm": 11.484931945800781,
      "learning_rate": 7.237681159420289e-06,
      "loss": 0.3055,
      "step": 110
    },
    {
      "epoch": 0.29850746268656714,
      "grad_norm": 9.15062141418457,
      "learning_rate": 7.895652173913044e-06,
      "loss": 0.2896,
      "step": 120
    },
    {
      "epoch": 0.32338308457711445,
      "grad_norm": 8.70537281036377,
      "learning_rate": 8.553623188405796e-06,
      "loss": 0.3041,
      "step": 130
    },
    {
      "epoch": 0.3482587064676617,
      "grad_norm": 11.263707160949707,
      "learning_rate": 9.076917854718261e-06,
      "loss": 0.3253,
      "step": 140
    },
    {
      "epoch": 0.373134328358209,
      "grad_norm": 9.089364051818848,
      "learning_rate": 9.061507128309571e-06,
      "loss": 0.3158,
      "step": 150
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 9.158366203308105,
      "learning_rate": 9.046096401900881e-06,
      "loss": 0.3024,
      "step": 160
    },
    {
      "epoch": 0.4228855721393035,
      "grad_norm": 27.09228515625,
      "learning_rate": 9.030685675492193e-06,
      "loss": 0.3059,
      "step": 170
    },
    {
      "epoch": 0.44776119402985076,
      "grad_norm": 6.761977672576904,
      "learning_rate": 9.015274949083503e-06,
      "loss": 0.2904,
      "step": 180
    },
    {
      "epoch": 0.472636815920398,
      "grad_norm": 7.274807929992676,
      "learning_rate": 8.999864222674813e-06,
      "loss": 0.2834,
      "step": 190
    },
    {
      "epoch": 0.4975124378109453,
      "grad_norm": 9.922611236572266,
      "learning_rate": 8.984453496266124e-06,
      "loss": 0.2715,
      "step": 200
    },
    {
      "epoch": 0.5223880597014925,
      "grad_norm": 10.680425643920898,
      "learning_rate": 8.969042769857434e-06,
      "loss": 0.2477,
      "step": 210
    },
    {
      "epoch": 0.5472636815920398,
      "grad_norm": 6.122069358825684,
      "learning_rate": 8.953632043448744e-06,
      "loss": 0.2215,
      "step": 220
    },
    {
      "epoch": 0.572139303482587,
      "grad_norm": 9.106232643127441,
      "learning_rate": 8.938221317040054e-06,
      "loss": 0.2316,
      "step": 230
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 9.866654396057129,
      "learning_rate": 8.922810590631364e-06,
      "loss": 0.26,
      "step": 240
    },
    {
      "epoch": 0.6218905472636815,
      "grad_norm": 8.807905197143555,
      "learning_rate": 8.907399864222674e-06,
      "loss": 0.2453,
      "step": 250
    },
    {
      "epoch": 0.6467661691542289,
      "grad_norm": 8.21251106262207,
      "learning_rate": 8.891989137813984e-06,
      "loss": 0.2146,
      "step": 260
    },
    {
      "epoch": 0.6716417910447762,
      "grad_norm": 6.342051982879639,
      "learning_rate": 8.876578411405294e-06,
      "loss": 0.2261,
      "step": 270
    },
    {
      "epoch": 0.6965174129353234,
      "grad_norm": 6.347724914550781,
      "learning_rate": 8.861167684996605e-06,
      "loss": 0.22,
      "step": 280
    },
    {
      "epoch": 0.7213930348258707,
      "grad_norm": 3.5863683223724365,
      "learning_rate": 8.845756958587915e-06,
      "loss": 0.1886,
      "step": 290
    },
    {
      "epoch": 0.746268656716418,
      "grad_norm": 7.652027130126953,
      "learning_rate": 8.830346232179225e-06,
      "loss": 0.2265,
      "step": 300
    },
    {
      "epoch": 0.7711442786069652,
      "grad_norm": 11.823918342590332,
      "learning_rate": 8.814935505770537e-06,
      "loss": 0.2108,
      "step": 310
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 4.940918922424316,
      "learning_rate": 8.799524779361847e-06,
      "loss": 0.1949,
      "step": 320
    },
    {
      "epoch": 0.8208955223880597,
      "grad_norm": 6.175742149353027,
      "learning_rate": 8.784114052953157e-06,
      "loss": 0.1905,
      "step": 330
    },
    {
      "epoch": 0.845771144278607,
      "grad_norm": 6.682214260101318,
      "learning_rate": 8.768703326544467e-06,
      "loss": 0.1795,
      "step": 340
    },
    {
      "epoch": 0.8706467661691543,
      "grad_norm": 4.676469802856445,
      "learning_rate": 8.753292600135777e-06,
      "loss": 0.2,
      "step": 350
    },
    {
      "epoch": 0.8955223880597015,
      "grad_norm": 5.3237624168396,
      "learning_rate": 8.737881873727087e-06,
      "loss": 0.2151,
      "step": 360
    },
    {
      "epoch": 0.9203980099502488,
      "grad_norm": 8.960389137268066,
      "learning_rate": 8.722471147318397e-06,
      "loss": 0.1521,
      "step": 370
    },
    {
      "epoch": 0.945273631840796,
      "grad_norm": 5.014960289001465,
      "learning_rate": 8.707060420909708e-06,
      "loss": 0.1584,
      "step": 380
    },
    {
      "epoch": 0.9701492537313433,
      "grad_norm": 5.3436055183410645,
      "learning_rate": 8.691649694501018e-06,
      "loss": 0.1442,
      "step": 390
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 4.875133991241455,
      "learning_rate": 8.676238968092328e-06,
      "loss": 0.1578,
      "step": 400
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9464631782945736,
      "eval_f1": 0.65086887835703,
      "eval_loss": 0.14821825921535492,
      "eval_precision": 0.8062622309197651,
      "eval_recall": 0.5456953642384106,
      "eval_runtime": 115.8352,
      "eval_samples_per_second": 71.455,
      "eval_steps_per_second": 2.978,
      "step": 402
    },
    {
      "epoch": 1.0199004975124377,
      "grad_norm": 6.967800140380859,
      "learning_rate": 8.660828241683638e-06,
      "loss": 0.1663,
      "step": 410
    },
    {
      "epoch": 1.044776119402985,
      "grad_norm": 8.205605506896973,
      "learning_rate": 8.645417515274948e-06,
      "loss": 0.1601,
      "step": 420
    },
    {
      "epoch": 1.0696517412935322,
      "grad_norm": 3.7989516258239746,
      "learning_rate": 8.630006788866258e-06,
      "loss": 0.123,
      "step": 430
    },
    {
      "epoch": 1.0945273631840795,
      "grad_norm": 5.255030632019043,
      "learning_rate": 8.614596062457568e-06,
      "loss": 0.131,
      "step": 440
    },
    {
      "epoch": 1.1194029850746268,
      "grad_norm": 6.045576095581055,
      "learning_rate": 8.59918533604888e-06,
      "loss": 0.1466,
      "step": 450
    },
    {
      "epoch": 1.144278606965174,
      "grad_norm": 4.347365379333496,
      "learning_rate": 8.58377460964019e-06,
      "loss": 0.1244,
      "step": 460
    },
    {
      "epoch": 1.1691542288557213,
      "grad_norm": 3.5231754779815674,
      "learning_rate": 8.5683638832315e-06,
      "loss": 0.1028,
      "step": 470
    },
    {
      "epoch": 1.1940298507462686,
      "grad_norm": 5.872034072875977,
      "learning_rate": 8.55295315682281e-06,
      "loss": 0.1353,
      "step": 480
    },
    {
      "epoch": 1.2189054726368158,
      "grad_norm": 3.369835376739502,
      "learning_rate": 8.537542430414121e-06,
      "loss": 0.143,
      "step": 490
    },
    {
      "epoch": 1.243781094527363,
      "grad_norm": 5.644999027252197,
      "learning_rate": 8.522131704005431e-06,
      "loss": 0.132,
      "step": 500
    },
    {
      "epoch": 1.2686567164179103,
      "grad_norm": 5.731727600097656,
      "learning_rate": 8.506720977596741e-06,
      "loss": 0.12,
      "step": 510
    },
    {
      "epoch": 1.2935323383084576,
      "grad_norm": 6.276075839996338,
      "learning_rate": 8.491310251188051e-06,
      "loss": 0.1437,
      "step": 520
    },
    {
      "epoch": 1.3184079601990049,
      "grad_norm": 3.6596975326538086,
      "learning_rate": 8.475899524779361e-06,
      "loss": 0.1162,
      "step": 530
    },
    {
      "epoch": 1.3432835820895521,
      "grad_norm": 4.934922695159912,
      "learning_rate": 8.460488798370671e-06,
      "loss": 0.1125,
      "step": 540
    },
    {
      "epoch": 1.3681592039800994,
      "grad_norm": 4.162049293518066,
      "learning_rate": 8.44507807196198e-06,
      "loss": 0.1153,
      "step": 550
    },
    {
      "epoch": 1.3930348258706466,
      "grad_norm": 4.11759090423584,
      "learning_rate": 8.429667345553292e-06,
      "loss": 0.1044,
      "step": 560
    },
    {
      "epoch": 1.417910447761194,
      "grad_norm": 4.370908260345459,
      "learning_rate": 8.414256619144602e-06,
      "loss": 0.124,
      "step": 570
    },
    {
      "epoch": 1.4427860696517412,
      "grad_norm": 2.895297050476074,
      "learning_rate": 8.398845892735912e-06,
      "loss": 0.0815,
      "step": 580
    },
    {
      "epoch": 1.4676616915422884,
      "grad_norm": 3.515153169631958,
      "learning_rate": 8.383435166327224e-06,
      "loss": 0.0941,
      "step": 590
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 5.33454704284668,
      "learning_rate": 8.368024439918534e-06,
      "loss": 0.1165,
      "step": 600
    },
    {
      "epoch": 1.517412935323383,
      "grad_norm": 7.18100643157959,
      "learning_rate": 8.352613713509844e-06,
      "loss": 0.1064,
      "step": 610
    },
    {
      "epoch": 1.5422885572139302,
      "grad_norm": 6.8240156173706055,
      "learning_rate": 8.337202987101154e-06,
      "loss": 0.118,
      "step": 620
    },
    {
      "epoch": 1.5671641791044775,
      "grad_norm": 3.99238657951355,
      "learning_rate": 8.321792260692464e-06,
      "loss": 0.0968,
      "step": 630
    },
    {
      "epoch": 1.5920398009950247,
      "grad_norm": 2.4041080474853516,
      "learning_rate": 8.306381534283774e-06,
      "loss": 0.0767,
      "step": 640
    },
    {
      "epoch": 1.616915422885572,
      "grad_norm": 5.048937797546387,
      "learning_rate": 8.290970807875084e-06,
      "loss": 0.0731,
      "step": 650
    },
    {
      "epoch": 1.6417910447761193,
      "grad_norm": 3.149474859237671,
      "learning_rate": 8.275560081466394e-06,
      "loss": 0.0594,
      "step": 660
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 5.6875739097595215,
      "learning_rate": 8.260149355057705e-06,
      "loss": 0.0678,
      "step": 670
    },
    {
      "epoch": 1.6915422885572138,
      "grad_norm": 5.308948516845703,
      "learning_rate": 8.244738628649015e-06,
      "loss": 0.0844,
      "step": 680
    },
    {
      "epoch": 1.716417910447761,
      "grad_norm": 3.902500867843628,
      "learning_rate": 8.229327902240325e-06,
      "loss": 0.0745,
      "step": 690
    },
    {
      "epoch": 1.7412935323383083,
      "grad_norm": 4.165699005126953,
      "learning_rate": 8.213917175831635e-06,
      "loss": 0.0924,
      "step": 700
    },
    {
      "epoch": 1.7661691542288556,
      "grad_norm": 6.092475414276123,
      "learning_rate": 8.198506449422947e-06,
      "loss": 0.08,
      "step": 710
    },
    {
      "epoch": 1.7910447761194028,
      "grad_norm": 5.695572853088379,
      "learning_rate": 8.183095723014257e-06,
      "loss": 0.0688,
      "step": 720
    },
    {
      "epoch": 1.81592039800995,
      "grad_norm": 5.5008931159973145,
      "learning_rate": 8.167684996605567e-06,
      "loss": 0.0699,
      "step": 730
    },
    {
      "epoch": 1.8407960199004973,
      "grad_norm": 3.3155009746551514,
      "learning_rate": 8.152274270196877e-06,
      "loss": 0.0661,
      "step": 740
    },
    {
      "epoch": 1.8656716417910446,
      "grad_norm": 5.042843341827393,
      "learning_rate": 8.136863543788187e-06,
      "loss": 0.0658,
      "step": 750
    },
    {
      "epoch": 1.890547263681592,
      "grad_norm": 4.184449672698975,
      "learning_rate": 8.121452817379497e-06,
      "loss": 0.0715,
      "step": 760
    },
    {
      "epoch": 1.9154228855721394,
      "grad_norm": 4.048433780670166,
      "learning_rate": 8.106042090970808e-06,
      "loss": 0.0676,
      "step": 770
    },
    {
      "epoch": 1.9402985074626866,
      "grad_norm": 4.937346935272217,
      "learning_rate": 8.090631364562118e-06,
      "loss": 0.0765,
      "step": 780
    },
    {
      "epoch": 1.9651741293532339,
      "grad_norm": 3.1063220500946045,
      "learning_rate": 8.075220638153428e-06,
      "loss": 0.0842,
      "step": 790
    },
    {
      "epoch": 1.9900497512437811,
      "grad_norm": 4.66568660736084,
      "learning_rate": 8.059809911744738e-06,
      "loss": 0.0702,
      "step": 800
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9842538759689923,
      "eval_f1": 0.9093444909344491,
      "eval_loss": 0.04791456460952759,
      "eval_precision": 0.9602356406480118,
      "eval_recall": 0.8635761589403973,
      "eval_runtime": 116.531,
      "eval_samples_per_second": 71.028,
      "eval_steps_per_second": 2.961,
      "step": 804
    },
    {
      "epoch": 2.014925373134328,
      "grad_norm": 2.857628345489502,
      "learning_rate": 8.044399185336048e-06,
      "loss": 0.0758,
      "step": 810
    },
    {
      "epoch": 2.0398009950248754,
      "grad_norm": 3.8989078998565674,
      "learning_rate": 8.028988458927358e-06,
      "loss": 0.0692,
      "step": 820
    },
    {
      "epoch": 2.0646766169154227,
      "grad_norm": 5.1332478523254395,
      "learning_rate": 8.013577732518668e-06,
      "loss": 0.0507,
      "step": 830
    },
    {
      "epoch": 2.08955223880597,
      "grad_norm": 4.040643692016602,
      "learning_rate": 7.99816700610998e-06,
      "loss": 0.0424,
      "step": 840
    },
    {
      "epoch": 2.1144278606965172,
      "grad_norm": 18.886943817138672,
      "learning_rate": 7.98275627970129e-06,
      "loss": 0.0381,
      "step": 850
    },
    {
      "epoch": 2.1393034825870645,
      "grad_norm": 11.126363754272461,
      "learning_rate": 7.9673455532926e-06,
      "loss": 0.0549,
      "step": 860
    },
    {
      "epoch": 2.1641791044776117,
      "grad_norm": 4.755194664001465,
      "learning_rate": 7.95193482688391e-06,
      "loss": 0.0573,
      "step": 870
    },
    {
      "epoch": 2.189054726368159,
      "grad_norm": 4.427928447723389,
      "learning_rate": 7.936524100475221e-06,
      "loss": 0.0536,
      "step": 880
    },
    {
      "epoch": 2.2139303482587063,
      "grad_norm": 4.5954718589782715,
      "learning_rate": 7.921113374066531e-06,
      "loss": 0.0405,
      "step": 890
    },
    {
      "epoch": 2.2388059701492535,
      "grad_norm": 3.1100029945373535,
      "learning_rate": 7.905702647657841e-06,
      "loss": 0.0466,
      "step": 900
    },
    {
      "epoch": 2.2636815920398012,
      "grad_norm": 1.971436858177185,
      "learning_rate": 7.89029192124915e-06,
      "loss": 0.0533,
      "step": 910
    },
    {
      "epoch": 2.288557213930348,
      "grad_norm": 24.073394775390625,
      "learning_rate": 7.87488119484046e-06,
      "loss": 0.0614,
      "step": 920
    },
    {
      "epoch": 2.3134328358208958,
      "grad_norm": 2.863762378692627,
      "learning_rate": 7.85947046843177e-06,
      "loss": 0.0468,
      "step": 930
    },
    {
      "epoch": 2.3383084577114426,
      "grad_norm": 4.552980899810791,
      "learning_rate": 7.84405974202308e-06,
      "loss": 0.0495,
      "step": 940
    },
    {
      "epoch": 2.3631840796019903,
      "grad_norm": 3.1374006271362305,
      "learning_rate": 7.828649015614392e-06,
      "loss": 0.0666,
      "step": 950
    },
    {
      "epoch": 2.388059701492537,
      "grad_norm": 1.733057975769043,
      "learning_rate": 7.813238289205702e-06,
      "loss": 0.0397,
      "step": 960
    },
    {
      "epoch": 2.412935323383085,
      "grad_norm": 3.2866218090057373,
      "learning_rate": 7.797827562797012e-06,
      "loss": 0.0314,
      "step": 970
    },
    {
      "epoch": 2.4378109452736316,
      "grad_norm": 0.6333186626434326,
      "learning_rate": 7.782416836388324e-06,
      "loss": 0.0314,
      "step": 980
    },
    {
      "epoch": 2.4626865671641793,
      "grad_norm": 4.188263893127441,
      "learning_rate": 7.767006109979634e-06,
      "loss": 0.0404,
      "step": 990
    },
    {
      "epoch": 2.487562189054726,
      "grad_norm": 1.4603006839752197,
      "learning_rate": 7.751595383570944e-06,
      "loss": 0.0454,
      "step": 1000
    },
    {
      "epoch": 2.512437810945274,
      "grad_norm": 4.875211238861084,
      "learning_rate": 7.736184657162254e-06,
      "loss": 0.0458,
      "step": 1010
    },
    {
      "epoch": 2.5373134328358207,
      "grad_norm": 1.8764511346817017,
      "learning_rate": 7.720773930753564e-06,
      "loss": 0.0536,
      "step": 1020
    },
    {
      "epoch": 2.5621890547263684,
      "grad_norm": 5.79665470123291,
      "learning_rate": 7.705363204344874e-06,
      "loss": 0.0534,
      "step": 1030
    },
    {
      "epoch": 2.587064676616915,
      "grad_norm": 1.14104425907135,
      "learning_rate": 7.689952477936184e-06,
      "loss": 0.035,
      "step": 1040
    },
    {
      "epoch": 2.611940298507463,
      "grad_norm": 7.614250659942627,
      "learning_rate": 7.674541751527493e-06,
      "loss": 0.0482,
      "step": 1050
    },
    {
      "epoch": 2.6368159203980097,
      "grad_norm": 4.548539161682129,
      "learning_rate": 7.659131025118805e-06,
      "loss": 0.038,
      "step": 1060
    },
    {
      "epoch": 2.6616915422885574,
      "grad_norm": 5.630373001098633,
      "learning_rate": 7.643720298710115e-06,
      "loss": 0.0576,
      "step": 1070
    },
    {
      "epoch": 2.6865671641791042,
      "grad_norm": 0.3849408030509949,
      "learning_rate": 7.628309572301425e-06,
      "loss": 0.0288,
      "step": 1080
    },
    {
      "epoch": 2.711442786069652,
      "grad_norm": 2.8792099952697754,
      "learning_rate": 7.612898845892735e-06,
      "loss": 0.0493,
      "step": 1090
    },
    {
      "epoch": 2.7363184079601988,
      "grad_norm": 4.277225971221924,
      "learning_rate": 7.597488119484047e-06,
      "loss": 0.0323,
      "step": 1100
    },
    {
      "epoch": 2.7611940298507465,
      "grad_norm": 3.537855625152588,
      "learning_rate": 7.5820773930753566e-06,
      "loss": 0.033,
      "step": 1110
    },
    {
      "epoch": 2.7860696517412933,
      "grad_norm": 2.7075796127319336,
      "learning_rate": 7.5666666666666665e-06,
      "loss": 0.048,
      "step": 1120
    },
    {
      "epoch": 2.810945273631841,
      "grad_norm": 4.275196075439453,
      "learning_rate": 7.5512559402579764e-06,
      "loss": 0.0543,
      "step": 1130
    },
    {
      "epoch": 2.835820895522388,
      "grad_norm": 1.6901181936264038,
      "learning_rate": 7.535845213849287e-06,
      "loss": 0.0491,
      "step": 1140
    },
    {
      "epoch": 2.8606965174129355,
      "grad_norm": 2.765190362930298,
      "learning_rate": 7.520434487440597e-06,
      "loss": 0.0322,
      "step": 1150
    },
    {
      "epoch": 2.8855721393034823,
      "grad_norm": 2.2440145015716553,
      "learning_rate": 7.505023761031907e-06,
      "loss": 0.0555,
      "step": 1160
    },
    {
      "epoch": 2.91044776119403,
      "grad_norm": 4.750284671783447,
      "learning_rate": 7.489613034623217e-06,
      "loss": 0.0371,
      "step": 1170
    },
    {
      "epoch": 2.935323383084577,
      "grad_norm": 7.076899528503418,
      "learning_rate": 7.474202308214528e-06,
      "loss": 0.0326,
      "step": 1180
    },
    {
      "epoch": 2.9601990049751246,
      "grad_norm": 2.7365622520446777,
      "learning_rate": 7.458791581805838e-06,
      "loss": 0.0371,
      "step": 1190
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 4.038753986358643,
      "learning_rate": 7.443380855397148e-06,
      "loss": 0.0326,
      "step": 1200
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9881298449612403,
      "eval_f1": 0.9328767123287671,
      "eval_loss": 0.03788590058684349,
      "eval_precision": 0.9659574468085106,
      "eval_recall": 0.9019867549668874,
      "eval_runtime": 115.0203,
      "eval_samples_per_second": 71.961,
      "eval_steps_per_second": 2.999,
      "step": 1206
    },
    {
      "epoch": 3.009950248756219,
      "grad_norm": 3.1405415534973145,
      "learning_rate": 7.427970128988458e-06,
      "loss": 0.0141,
      "step": 1210
    },
    {
      "epoch": 3.0348258706467663,
      "grad_norm": 7.738598346710205,
      "learning_rate": 7.4125594025797685e-06,
      "loss": 0.0474,
      "step": 1220
    },
    {
      "epoch": 3.0597014925373136,
      "grad_norm": 3.835764169692993,
      "learning_rate": 7.397148676171079e-06,
      "loss": 0.0449,
      "step": 1230
    },
    {
      "epoch": 3.084577114427861,
      "grad_norm": 0.46425727009773254,
      "learning_rate": 7.381737949762389e-06,
      "loss": 0.0279,
      "step": 1240
    },
    {
      "epoch": 3.109452736318408,
      "grad_norm": 0.3320457935333252,
      "learning_rate": 7.3663272233537e-06,
      "loss": 0.0285,
      "step": 1250
    },
    {
      "epoch": 3.1343283582089554,
      "grad_norm": 5.260127544403076,
      "learning_rate": 7.35091649694501e-06,
      "loss": 0.0249,
      "step": 1260
    },
    {
      "epoch": 3.1592039800995027,
      "grad_norm": 4.507414817810059,
      "learning_rate": 7.33550577053632e-06,
      "loss": 0.0515,
      "step": 1270
    },
    {
      "epoch": 3.18407960199005,
      "grad_norm": 2.35420823097229,
      "learning_rate": 7.320095044127631e-06,
      "loss": 0.0382,
      "step": 1280
    },
    {
      "epoch": 3.208955223880597,
      "grad_norm": 0.3795280456542969,
      "learning_rate": 7.304684317718941e-06,
      "loss": 0.0125,
      "step": 1290
    },
    {
      "epoch": 3.2338308457711444,
      "grad_norm": 1.9121066331863403,
      "learning_rate": 7.289273591310251e-06,
      "loss": 0.0282,
      "step": 1300
    },
    {
      "epoch": 3.2587064676616917,
      "grad_norm": 4.945308208465576,
      "learning_rate": 7.273862864901561e-06,
      "loss": 0.0357,
      "step": 1310
    },
    {
      "epoch": 3.283582089552239,
      "grad_norm": 3.1690673828125,
      "learning_rate": 7.258452138492871e-06,
      "loss": 0.0282,
      "step": 1320
    },
    {
      "epoch": 3.308457711442786,
      "grad_norm": 0.7234634160995483,
      "learning_rate": 7.243041412084181e-06,
      "loss": 0.0118,
      "step": 1330
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.275740146636963,
      "learning_rate": 7.227630685675491e-06,
      "loss": 0.0294,
      "step": 1340
    },
    {
      "epoch": 3.3582089552238807,
      "grad_norm": 5.366898059844971,
      "learning_rate": 7.212219959266801e-06,
      "loss": 0.0475,
      "step": 1350
    },
    {
      "epoch": 3.383084577114428,
      "grad_norm": 0.4349980056285858,
      "learning_rate": 7.196809232858112e-06,
      "loss": 0.0392,
      "step": 1360
    },
    {
      "epoch": 3.4079601990049753,
      "grad_norm": 3.4643406867980957,
      "learning_rate": 7.181398506449423e-06,
      "loss": 0.0358,
      "step": 1370
    },
    {
      "epoch": 3.4328358208955225,
      "grad_norm": 1.3029471635818481,
      "learning_rate": 7.165987780040733e-06,
      "loss": 0.0219,
      "step": 1380
    },
    {
      "epoch": 3.45771144278607,
      "grad_norm": 8.980469703674316,
      "learning_rate": 7.1505770536320436e-06,
      "loss": 0.024,
      "step": 1390
    },
    {
      "epoch": 3.482587064676617,
      "grad_norm": 1.6365892887115479,
      "learning_rate": 7.1351663272233535e-06,
      "loss": 0.0278,
      "step": 1400
    },
    {
      "epoch": 3.5074626865671643,
      "grad_norm": 4.668521881103516,
      "learning_rate": 7.1197556008146635e-06,
      "loss": 0.0433,
      "step": 1410
    },
    {
      "epoch": 3.5323383084577116,
      "grad_norm": 4.599516868591309,
      "learning_rate": 7.104344874405974e-06,
      "loss": 0.0294,
      "step": 1420
    },
    {
      "epoch": 3.557213930348259,
      "grad_norm": 2.9182395935058594,
      "learning_rate": 7.088934147997284e-06,
      "loss": 0.0326,
      "step": 1430
    },
    {
      "epoch": 3.582089552238806,
      "grad_norm": 2.045727252960205,
      "learning_rate": 7.073523421588594e-06,
      "loss": 0.0155,
      "step": 1440
    },
    {
      "epoch": 3.6069651741293534,
      "grad_norm": 2.866609573364258,
      "learning_rate": 7.058112695179904e-06,
      "loss": 0.0236,
      "step": 1450
    },
    {
      "epoch": 3.6318407960199006,
      "grad_norm": 2.479602813720703,
      "learning_rate": 7.042701968771215e-06,
      "loss": 0.0138,
      "step": 1460
    },
    {
      "epoch": 3.656716417910448,
      "grad_norm": 0.5325874090194702,
      "learning_rate": 7.027291242362525e-06,
      "loss": 0.0264,
      "step": 1470
    },
    {
      "epoch": 3.681592039800995,
      "grad_norm": 0.3446354866027832,
      "learning_rate": 7.011880515953835e-06,
      "loss": 0.0321,
      "step": 1480
    },
    {
      "epoch": 3.7064676616915424,
      "grad_norm": 1.3428905010223389,
      "learning_rate": 6.996469789545145e-06,
      "loss": 0.0199,
      "step": 1490
    },
    {
      "epoch": 3.7313432835820897,
      "grad_norm": 0.17606143653392792,
      "learning_rate": 6.981059063136456e-06,
      "loss": 0.027,
      "step": 1500
    },
    {
      "epoch": 3.756218905472637,
      "grad_norm": 2.0204007625579834,
      "learning_rate": 6.965648336727766e-06,
      "loss": 0.0263,
      "step": 1510
    },
    {
      "epoch": 3.781094527363184,
      "grad_norm": 2.6673853397369385,
      "learning_rate": 6.950237610319076e-06,
      "loss": 0.0261,
      "step": 1520
    },
    {
      "epoch": 3.8059701492537314,
      "grad_norm": 0.4769124984741211,
      "learning_rate": 6.934826883910387e-06,
      "loss": 0.0167,
      "step": 1530
    },
    {
      "epoch": 3.8308457711442787,
      "grad_norm": 6.6251630783081055,
      "learning_rate": 6.919416157501697e-06,
      "loss": 0.0277,
      "step": 1540
    },
    {
      "epoch": 3.855721393034826,
      "grad_norm": 1.3862169981002808,
      "learning_rate": 6.904005431093007e-06,
      "loss": 0.0206,
      "step": 1550
    },
    {
      "epoch": 3.8805970149253732,
      "grad_norm": 5.641274929046631,
      "learning_rate": 6.888594704684317e-06,
      "loss": 0.0419,
      "step": 1560
    },
    {
      "epoch": 3.9054726368159205,
      "grad_norm": 0.5983162522315979,
      "learning_rate": 6.873183978275628e-06,
      "loss": 0.0289,
      "step": 1570
    },
    {
      "epoch": 3.9303482587064678,
      "grad_norm": 6.238410949707031,
      "learning_rate": 6.857773251866938e-06,
      "loss": 0.036,
      "step": 1580
    },
    {
      "epoch": 3.955223880597015,
      "grad_norm": 1.1332640647888184,
      "learning_rate": 6.842362525458248e-06,
      "loss": 0.0369,
      "step": 1590
    },
    {
      "epoch": 3.9800995024875623,
      "grad_norm": 3.689406633377075,
      "learning_rate": 6.826951799049558e-06,
      "loss": 0.0486,
      "step": 1600
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9900678294573644,
      "eval_f1": 0.944141689373297,
      "eval_loss": 0.030992982909083366,
      "eval_precision": 0.9719495091164095,
      "eval_recall": 0.9178807947019868,
      "eval_runtime": 115.8965,
      "eval_samples_per_second": 71.417,
      "eval_steps_per_second": 2.977,
      "step": 1608
    },
    {
      "epoch": 4.0049751243781095,
      "grad_norm": 1.8808258771896362,
      "learning_rate": 6.811541072640868e-06,
      "loss": 0.0161,
      "step": 1610
    },
    {
      "epoch": 4.029850746268656,
      "grad_norm": 0.7196659445762634,
      "learning_rate": 6.796130346232178e-06,
      "loss": 0.0187,
      "step": 1620
    },
    {
      "epoch": 4.054726368159204,
      "grad_norm": 1.1937110424041748,
      "learning_rate": 6.78071961982349e-06,
      "loss": 0.0206,
      "step": 1630
    },
    {
      "epoch": 4.079601990049751,
      "grad_norm": 0.6512218713760376,
      "learning_rate": 6.7653088934148e-06,
      "loss": 0.017,
      "step": 1640
    },
    {
      "epoch": 4.104477611940299,
      "grad_norm": 2.44219970703125,
      "learning_rate": 6.74989816700611e-06,
      "loss": 0.0229,
      "step": 1650
    },
    {
      "epoch": 4.129353233830845,
      "grad_norm": 10.521256446838379,
      "learning_rate": 6.73448744059742e-06,
      "loss": 0.037,
      "step": 1660
    },
    {
      "epoch": 4.154228855721393,
      "grad_norm": 2.1825616359710693,
      "learning_rate": 6.7190767141887306e-06,
      "loss": 0.016,
      "step": 1670
    },
    {
      "epoch": 4.17910447761194,
      "grad_norm": 2.7559499740600586,
      "learning_rate": 6.7036659877800405e-06,
      "loss": 0.0155,
      "step": 1680
    },
    {
      "epoch": 4.203980099502488,
      "grad_norm": 1.70546555519104,
      "learning_rate": 6.6882552613713505e-06,
      "loss": 0.0321,
      "step": 1690
    },
    {
      "epoch": 4.2288557213930345,
      "grad_norm": 3.5666282176971436,
      "learning_rate": 6.67284453496266e-06,
      "loss": 0.0364,
      "step": 1700
    },
    {
      "epoch": 4.253731343283582,
      "grad_norm": 0.9082943201065063,
      "learning_rate": 6.657433808553971e-06,
      "loss": 0.0265,
      "step": 1710
    },
    {
      "epoch": 4.278606965174129,
      "grad_norm": 1.836905598640442,
      "learning_rate": 6.642023082145281e-06,
      "loss": 0.0295,
      "step": 1720
    },
    {
      "epoch": 4.303482587064677,
      "grad_norm": 1.7458299398422241,
      "learning_rate": 6.626612355736591e-06,
      "loss": 0.0317,
      "step": 1730
    },
    {
      "epoch": 4.3283582089552235,
      "grad_norm": 0.9824329018592834,
      "learning_rate": 6.611201629327901e-06,
      "loss": 0.0148,
      "step": 1740
    },
    {
      "epoch": 4.353233830845771,
      "grad_norm": 2.0270562171936035,
      "learning_rate": 6.595790902919212e-06,
      "loss": 0.0275,
      "step": 1750
    },
    {
      "epoch": 4.378109452736318,
      "grad_norm": 0.9609461426734924,
      "learning_rate": 6.580380176510523e-06,
      "loss": 0.0154,
      "step": 1760
    },
    {
      "epoch": 4.402985074626866,
      "grad_norm": 0.42252489924430847,
      "learning_rate": 6.564969450101833e-06,
      "loss": 0.0234,
      "step": 1770
    },
    {
      "epoch": 4.4278606965174125,
      "grad_norm": 0.2521291971206665,
      "learning_rate": 6.549558723693143e-06,
      "loss": 0.0242,
      "step": 1780
    },
    {
      "epoch": 4.45273631840796,
      "grad_norm": 1.7762532234191895,
      "learning_rate": 6.534147997284453e-06,
      "loss": 0.014,
      "step": 1790
    },
    {
      "epoch": 4.477611940298507,
      "grad_norm": 0.06550105661153793,
      "learning_rate": 6.518737270875763e-06,
      "loss": 0.0353,
      "step": 1800
    },
    {
      "epoch": 4.502487562189055,
      "grad_norm": 5.311624526977539,
      "learning_rate": 6.503326544467074e-06,
      "loss": 0.0231,
      "step": 1810
    },
    {
      "epoch": 4.5273631840796025,
      "grad_norm": 0.26004210114479065,
      "learning_rate": 6.487915818058384e-06,
      "loss": 0.0171,
      "step": 1820
    },
    {
      "epoch": 4.552238805970149,
      "grad_norm": 0.9650487899780273,
      "learning_rate": 6.472505091649694e-06,
      "loss": 0.0245,
      "step": 1830
    },
    {
      "epoch": 4.577114427860696,
      "grad_norm": 4.068159103393555,
      "learning_rate": 6.457094365241004e-06,
      "loss": 0.0421,
      "step": 1840
    },
    {
      "epoch": 4.601990049751244,
      "grad_norm": 0.11123663932085037,
      "learning_rate": 6.441683638832315e-06,
      "loss": 0.0242,
      "step": 1850
    },
    {
      "epoch": 4.6268656716417915,
      "grad_norm": 1.842956781387329,
      "learning_rate": 6.426272912423625e-06,
      "loss": 0.0274,
      "step": 1860
    },
    {
      "epoch": 4.651741293532338,
      "grad_norm": 0.6481873989105225,
      "learning_rate": 6.410862186014935e-06,
      "loss": 0.0193,
      "step": 1870
    },
    {
      "epoch": 4.676616915422885,
      "grad_norm": 2.5238234996795654,
      "learning_rate": 6.3954514596062446e-06,
      "loss": 0.0114,
      "step": 1880
    },
    {
      "epoch": 4.701492537313433,
      "grad_norm": 2.7916176319122314,
      "learning_rate": 6.380040733197556e-06,
      "loss": 0.0213,
      "step": 1890
    },
    {
      "epoch": 4.726368159203981,
      "grad_norm": 3.6060397624969482,
      "learning_rate": 6.364630006788866e-06,
      "loss": 0.021,
      "step": 1900
    },
    {
      "epoch": 4.751243781094527,
      "grad_norm": 0.8670694828033447,
      "learning_rate": 6.349219280380176e-06,
      "loss": 0.0216,
      "step": 1910
    },
    {
      "epoch": 4.776119402985074,
      "grad_norm": 6.069404602050781,
      "learning_rate": 6.333808553971487e-06,
      "loss": 0.0246,
      "step": 1920
    },
    {
      "epoch": 4.800995024875622,
      "grad_norm": 0.3878091871738434,
      "learning_rate": 6.318397827562797e-06,
      "loss": 0.0135,
      "step": 1930
    },
    {
      "epoch": 4.82587064676617,
      "grad_norm": 4.234367847442627,
      "learning_rate": 6.302987101154107e-06,
      "loss": 0.0283,
      "step": 1940
    },
    {
      "epoch": 4.850746268656716,
      "grad_norm": 3.356081962585449,
      "learning_rate": 6.287576374745418e-06,
      "loss": 0.0204,
      "step": 1950
    },
    {
      "epoch": 4.875621890547263,
      "grad_norm": 0.46801167726516724,
      "learning_rate": 6.2721656483367275e-06,
      "loss": 0.022,
      "step": 1960
    },
    {
      "epoch": 4.900497512437811,
      "grad_norm": 0.9984350204467773,
      "learning_rate": 6.2567549219280375e-06,
      "loss": 0.0203,
      "step": 1970
    },
    {
      "epoch": 4.925373134328359,
      "grad_norm": 1.713454246520996,
      "learning_rate": 6.2413441955193474e-06,
      "loss": 0.0215,
      "step": 1980
    },
    {
      "epoch": 4.9502487562189055,
      "grad_norm": 0.08815374970436096,
      "learning_rate": 6.225933469110658e-06,
      "loss": 0.0119,
      "step": 1990
    },
    {
      "epoch": 4.975124378109452,
      "grad_norm": 0.3082297146320343,
      "learning_rate": 6.210522742701968e-06,
      "loss": 0.0393,
      "step": 2000
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.8329832553863525,
      "learning_rate": 6.195112016293278e-06,
      "loss": 0.019,
      "step": 2010
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9909156976744186,
      "eval_f1": 0.9490142760027193,
      "eval_loss": 0.02740410529077053,
      "eval_precision": 0.9748603351955307,
      "eval_recall": 0.9245033112582781,
      "eval_runtime": 114.9671,
      "eval_samples_per_second": 71.995,
      "eval_steps_per_second": 3.001,
      "step": 2010
    },
    {
      "epoch": 5.024875621890548,
      "grad_norm": 0.40786242485046387,
      "learning_rate": 6.17970128988459e-06,
      "loss": 0.0149,
      "step": 2020
    },
    {
      "epoch": 5.0497512437810945,
      "grad_norm": 0.5124303698539734,
      "learning_rate": 6.1642905634759e-06,
      "loss": 0.0096,
      "step": 2030
    },
    {
      "epoch": 5.074626865671641,
      "grad_norm": 1.808087706565857,
      "learning_rate": 6.14887983706721e-06,
      "loss": 0.0182,
      "step": 2040
    },
    {
      "epoch": 5.099502487562189,
      "grad_norm": 0.33733096718788147,
      "learning_rate": 6.13346911065852e-06,
      "loss": 0.0217,
      "step": 2050
    },
    {
      "epoch": 5.124378109452737,
      "grad_norm": 0.037117015570402145,
      "learning_rate": 6.11805838424983e-06,
      "loss": 0.0194,
      "step": 2060
    },
    {
      "epoch": 5.149253731343284,
      "grad_norm": 12.287717819213867,
      "learning_rate": 6.10264765784114e-06,
      "loss": 0.011,
      "step": 2070
    },
    {
      "epoch": 5.174129353233831,
      "grad_norm": 20.98920249938965,
      "learning_rate": 6.08723693143245e-06,
      "loss": 0.0124,
      "step": 2080
    },
    {
      "epoch": 5.199004975124378,
      "grad_norm": 2.9936721324920654,
      "learning_rate": 6.07182620502376e-06,
      "loss": 0.0277,
      "step": 2090
    },
    {
      "epoch": 5.223880597014926,
      "grad_norm": 3.52848482131958,
      "learning_rate": 6.056415478615071e-06,
      "loss": 0.0175,
      "step": 2100
    },
    {
      "epoch": 5.248756218905473,
      "grad_norm": 2.85581636428833,
      "learning_rate": 6.041004752206381e-06,
      "loss": 0.0182,
      "step": 2110
    },
    {
      "epoch": 5.273631840796019,
      "grad_norm": 2.2203030586242676,
      "learning_rate": 6.025594025797691e-06,
      "loss": 0.0083,
      "step": 2120
    },
    {
      "epoch": 5.298507462686567,
      "grad_norm": 3.0877747535705566,
      "learning_rate": 6.010183299389002e-06,
      "loss": 0.0147,
      "step": 2130
    },
    {
      "epoch": 5.323383084577115,
      "grad_norm": 3.002943754196167,
      "learning_rate": 5.994772572980312e-06,
      "loss": 0.0134,
      "step": 2140
    },
    {
      "epoch": 5.348258706467662,
      "grad_norm": 0.3872762620449066,
      "learning_rate": 5.979361846571622e-06,
      "loss": 0.0101,
      "step": 2150
    },
    {
      "epoch": 5.373134328358209,
      "grad_norm": 1.4363651275634766,
      "learning_rate": 5.963951120162933e-06,
      "loss": 0.0083,
      "step": 2160
    },
    {
      "epoch": 5.398009950248756,
      "grad_norm": 1.1768298149108887,
      "learning_rate": 5.948540393754243e-06,
      "loss": 0.0158,
      "step": 2170
    },
    {
      "epoch": 5.422885572139304,
      "grad_norm": 0.13536427915096283,
      "learning_rate": 5.933129667345553e-06,
      "loss": 0.0247,
      "step": 2180
    },
    {
      "epoch": 5.447761194029851,
      "grad_norm": 2.124350070953369,
      "learning_rate": 5.917718940936863e-06,
      "loss": 0.0107,
      "step": 2190
    },
    {
      "epoch": 5.472636815920398,
      "grad_norm": 0.4563988745212555,
      "learning_rate": 5.902308214528174e-06,
      "loss": 0.0101,
      "step": 2200
    },
    {
      "epoch": 5.497512437810945,
      "grad_norm": 0.3485189974308014,
      "learning_rate": 5.886897488119484e-06,
      "loss": 0.0218,
      "step": 2210
    },
    {
      "epoch": 5.522388059701493,
      "grad_norm": 1.4846347570419312,
      "learning_rate": 5.871486761710794e-06,
      "loss": 0.0165,
      "step": 2220
    },
    {
      "epoch": 5.54726368159204,
      "grad_norm": 0.1627727895975113,
      "learning_rate": 5.856076035302104e-06,
      "loss": 0.0162,
      "step": 2230
    },
    {
      "epoch": 5.572139303482587,
      "grad_norm": 19.63100814819336,
      "learning_rate": 5.8406653088934145e-06,
      "loss": 0.0178,
      "step": 2240
    },
    {
      "epoch": 5.597014925373134,
      "grad_norm": 4.380906105041504,
      "learning_rate": 5.8252545824847245e-06,
      "loss": 0.0304,
      "step": 2250
    },
    {
      "epoch": 5.621890547263682,
      "grad_norm": 0.40777406096458435,
      "learning_rate": 5.8098438560760344e-06,
      "loss": 0.0203,
      "step": 2260
    },
    {
      "epoch": 5.646766169154229,
      "grad_norm": 0.291777104139328,
      "learning_rate": 5.794433129667344e-06,
      "loss": 0.0135,
      "step": 2270
    },
    {
      "epoch": 5.6716417910447765,
      "grad_norm": 0.08981546014547348,
      "learning_rate": 5.779022403258655e-06,
      "loss": 0.0051,
      "step": 2280
    },
    {
      "epoch": 5.696517412935323,
      "grad_norm": 2.8444581031799316,
      "learning_rate": 5.763611676849966e-06,
      "loss": 0.0167,
      "step": 2290
    },
    {
      "epoch": 5.721393034825871,
      "grad_norm": 0.06502851098775864,
      "learning_rate": 5.748200950441276e-06,
      "loss": 0.0189,
      "step": 2300
    },
    {
      "epoch": 5.746268656716418,
      "grad_norm": 2.32131290435791,
      "learning_rate": 5.732790224032587e-06,
      "loss": 0.0154,
      "step": 2310
    },
    {
      "epoch": 5.7711442786069655,
      "grad_norm": 3.466226816177368,
      "learning_rate": 5.717379497623897e-06,
      "loss": 0.0182,
      "step": 2320
    },
    {
      "epoch": 5.796019900497512,
      "grad_norm": 1.6193965673446655,
      "learning_rate": 5.701968771215207e-06,
      "loss": 0.0198,
      "step": 2330
    },
    {
      "epoch": 5.82089552238806,
      "grad_norm": 1.6748961210250854,
      "learning_rate": 5.686558044806517e-06,
      "loss": 0.0223,
      "step": 2340
    },
    {
      "epoch": 5.845771144278607,
      "grad_norm": 3.6658332347869873,
      "learning_rate": 5.671147318397827e-06,
      "loss": 0.0244,
      "step": 2350
    },
    {
      "epoch": 5.870646766169155,
      "grad_norm": 0.05724218860268593,
      "learning_rate": 5.655736591989137e-06,
      "loss": 0.0221,
      "step": 2360
    },
    {
      "epoch": 5.895522388059701,
      "grad_norm": 0.10775260627269745,
      "learning_rate": 5.640325865580447e-06,
      "loss": 0.0258,
      "step": 2370
    },
    {
      "epoch": 5.920398009950249,
      "grad_norm": 1.7921643257141113,
      "learning_rate": 5.624915139171758e-06,
      "loss": 0.0211,
      "step": 2380
    },
    {
      "epoch": 5.945273631840796,
      "grad_norm": 0.1804952174425125,
      "learning_rate": 5.609504412763068e-06,
      "loss": 0.0215,
      "step": 2390
    },
    {
      "epoch": 5.970149253731344,
      "grad_norm": 1.0683904886245728,
      "learning_rate": 5.594093686354378e-06,
      "loss": 0.0049,
      "step": 2400
    },
    {
      "epoch": 5.9950248756218905,
      "grad_norm": 0.29262134432792664,
      "learning_rate": 5.578682959945688e-06,
      "loss": 0.0128,
      "step": 2410
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9906734496124031,
      "eval_f1": 0.949771689497717,
      "eval_loss": 0.029728198423981667,
      "eval_precision": 0.9357326478149101,
      "eval_recall": 0.9642384105960264,
      "eval_runtime": 115.3319,
      "eval_samples_per_second": 71.767,
      "eval_steps_per_second": 2.991,
      "step": 2412
    },
    {
      "epoch": 6.019900497512438,
      "grad_norm": 0.5506570339202881,
      "learning_rate": 5.5632722335369995e-06,
      "loss": 0.0126,
      "step": 2420
    },
    {
      "epoch": 6.044776119402985,
      "grad_norm": 2.1220712661743164,
      "learning_rate": 5.5478615071283095e-06,
      "loss": 0.0142,
      "step": 2430
    },
    {
      "epoch": 6.069651741293533,
      "grad_norm": 0.044193390756845474,
      "learning_rate": 5.5324507807196194e-06,
      "loss": 0.0084,
      "step": 2440
    },
    {
      "epoch": 6.0945273631840795,
      "grad_norm": 1.978151559829712,
      "learning_rate": 5.51704005431093e-06,
      "loss": 0.0162,
      "step": 2450
    },
    {
      "epoch": 6.119402985074627,
      "grad_norm": 1.766624093055725,
      "learning_rate": 5.50162932790224e-06,
      "loss": 0.0131,
      "step": 2460
    },
    {
      "epoch": 6.144278606965174,
      "grad_norm": 0.814789891242981,
      "learning_rate": 5.48621860149355e-06,
      "loss": 0.005,
      "step": 2470
    },
    {
      "epoch": 6.169154228855722,
      "grad_norm": 2.501692295074463,
      "learning_rate": 5.47080787508486e-06,
      "loss": 0.0125,
      "step": 2480
    },
    {
      "epoch": 6.1940298507462686,
      "grad_norm": 0.017942331731319427,
      "learning_rate": 5.455397148676171e-06,
      "loss": 0.0083,
      "step": 2490
    },
    {
      "epoch": 6.218905472636816,
      "grad_norm": 2.282860040664673,
      "learning_rate": 5.439986422267481e-06,
      "loss": 0.0096,
      "step": 2500
    },
    {
      "epoch": 6.243781094527363,
      "grad_norm": 0.10544359683990479,
      "learning_rate": 5.424575695858791e-06,
      "loss": 0.0119,
      "step": 2510
    },
    {
      "epoch": 6.268656716417911,
      "grad_norm": 7.943164348602295,
      "learning_rate": 5.4091649694501016e-06,
      "loss": 0.0252,
      "step": 2520
    },
    {
      "epoch": 6.293532338308458,
      "grad_norm": 2.9808194637298584,
      "learning_rate": 5.3937542430414115e-06,
      "loss": 0.0089,
      "step": 2530
    },
    {
      "epoch": 6.318407960199005,
      "grad_norm": 3.371511220932007,
      "learning_rate": 5.3783435166327215e-06,
      "loss": 0.0073,
      "step": 2540
    },
    {
      "epoch": 6.343283582089552,
      "grad_norm": 3.6784145832061768,
      "learning_rate": 5.362932790224033e-06,
      "loss": 0.0208,
      "step": 2550
    },
    {
      "epoch": 6.3681592039801,
      "grad_norm": 2.6405091285705566,
      "learning_rate": 5.347522063815343e-06,
      "loss": 0.0263,
      "step": 2560
    },
    {
      "epoch": 6.393034825870647,
      "grad_norm": 0.24233487248420715,
      "learning_rate": 5.332111337406653e-06,
      "loss": 0.0201,
      "step": 2570
    },
    {
      "epoch": 6.417910447761194,
      "grad_norm": 3.788095712661743,
      "learning_rate": 5.316700610997963e-06,
      "loss": 0.0189,
      "step": 2580
    },
    {
      "epoch": 6.442786069651741,
      "grad_norm": 1.3199436664581299,
      "learning_rate": 5.301289884589274e-06,
      "loss": 0.0088,
      "step": 2590
    },
    {
      "epoch": 6.467661691542289,
      "grad_norm": 0.884976863861084,
      "learning_rate": 5.285879158180584e-06,
      "loss": 0.0193,
      "step": 2600
    },
    {
      "epoch": 6.492537313432836,
      "grad_norm": 2.608837604522705,
      "learning_rate": 5.270468431771894e-06,
      "loss": 0.0138,
      "step": 2610
    },
    {
      "epoch": 6.517412935323383,
      "grad_norm": 2.332972526550293,
      "learning_rate": 5.255057705363204e-06,
      "loss": 0.0176,
      "step": 2620
    },
    {
      "epoch": 6.54228855721393,
      "grad_norm": 1.222530484199524,
      "learning_rate": 5.239646978954514e-06,
      "loss": 0.026,
      "step": 2630
    },
    {
      "epoch": 6.567164179104478,
      "grad_norm": 0.42908230423927307,
      "learning_rate": 5.224236252545824e-06,
      "loss": 0.0138,
      "step": 2640
    },
    {
      "epoch": 6.592039800995025,
      "grad_norm": 2.884669303894043,
      "learning_rate": 5.208825526137134e-06,
      "loss": 0.014,
      "step": 2650
    },
    {
      "epoch": 6.616915422885572,
      "grad_norm": 4.472111225128174,
      "learning_rate": 5.193414799728445e-06,
      "loss": 0.0196,
      "step": 2660
    },
    {
      "epoch": 6.641791044776119,
      "grad_norm": 1.669129490852356,
      "learning_rate": 5.178004073319755e-06,
      "loss": 0.0081,
      "step": 2670
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.2840595245361328,
      "learning_rate": 5.162593346911066e-06,
      "loss": 0.0088,
      "step": 2680
    },
    {
      "epoch": 6.691542288557214,
      "grad_norm": 5.4178876876831055,
      "learning_rate": 5.147182620502377e-06,
      "loss": 0.0105,
      "step": 2690
    },
    {
      "epoch": 6.7164179104477615,
      "grad_norm": 2.4274203777313232,
      "learning_rate": 5.1317718940936866e-06,
      "loss": 0.0085,
      "step": 2700
    },
    {
      "epoch": 6.741293532338308,
      "grad_norm": 0.8913312554359436,
      "learning_rate": 5.1163611676849965e-06,
      "loss": 0.0261,
      "step": 2710
    },
    {
      "epoch": 6.766169154228856,
      "grad_norm": 2.933821201324463,
      "learning_rate": 5.1009504412763064e-06,
      "loss": 0.019,
      "step": 2720
    },
    {
      "epoch": 6.791044776119403,
      "grad_norm": 0.645237147808075,
      "learning_rate": 5.085539714867617e-06,
      "loss": 0.0192,
      "step": 2730
    },
    {
      "epoch": 6.8159203980099505,
      "grad_norm": 1.578393578529358,
      "learning_rate": 5.070128988458927e-06,
      "loss": 0.0172,
      "step": 2740
    },
    {
      "epoch": 6.840796019900497,
      "grad_norm": 0.359468936920166,
      "learning_rate": 5.054718262050237e-06,
      "loss": 0.0162,
      "step": 2750
    },
    {
      "epoch": 6.865671641791045,
      "grad_norm": 0.20223544538021088,
      "learning_rate": 5.039307535641547e-06,
      "loss": 0.0078,
      "step": 2760
    },
    {
      "epoch": 6.890547263681592,
      "grad_norm": 0.8748924732208252,
      "learning_rate": 5.023896809232858e-06,
      "loss": 0.0095,
      "step": 2770
    },
    {
      "epoch": 6.91542288557214,
      "grad_norm": 2.596275568008423,
      "learning_rate": 5.008486082824168e-06,
      "loss": 0.0108,
      "step": 2780
    },
    {
      "epoch": 6.940298507462686,
      "grad_norm": 0.025937139987945557,
      "learning_rate": 4.993075356415478e-06,
      "loss": 0.01,
      "step": 2790
    },
    {
      "epoch": 6.965174129353234,
      "grad_norm": 0.029610147699713707,
      "learning_rate": 4.977664630006788e-06,
      "loss": 0.0162,
      "step": 2800
    },
    {
      "epoch": 6.990049751243781,
      "grad_norm": 0.013285386376082897,
      "learning_rate": 4.962253903598099e-06,
      "loss": 0.008,
      "step": 2810
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9903100775193798,
      "eval_f1": 0.9465954606141521,
      "eval_loss": 0.030045481398701668,
      "eval_precision": 0.9542395693135935,
      "eval_recall": 0.9390728476821192,
      "eval_runtime": 115.4145,
      "eval_samples_per_second": 71.715,
      "eval_steps_per_second": 2.989,
      "step": 2814
    },
    {
      "epoch": 7.014925373134329,
      "grad_norm": 0.39112862944602966,
      "learning_rate": 4.946843177189409e-06,
      "loss": 0.0105,
      "step": 2820
    },
    {
      "epoch": 7.039800995024875,
      "grad_norm": 0.12454606592655182,
      "learning_rate": 4.931432450780719e-06,
      "loss": 0.0065,
      "step": 2830
    },
    {
      "epoch": 7.064676616915423,
      "grad_norm": 0.6129803657531738,
      "learning_rate": 4.91602172437203e-06,
      "loss": 0.0099,
      "step": 2840
    },
    {
      "epoch": 7.08955223880597,
      "grad_norm": 1.1797398328781128,
      "learning_rate": 4.90061099796334e-06,
      "loss": 0.0137,
      "step": 2850
    },
    {
      "epoch": 7.114427860696518,
      "grad_norm": 0.007830391637980938,
      "learning_rate": 4.88520027155465e-06,
      "loss": 0.0056,
      "step": 2860
    },
    {
      "epoch": 7.1393034825870645,
      "grad_norm": 0.49149152636528015,
      "learning_rate": 4.869789545145961e-06,
      "loss": 0.0058,
      "step": 2870
    },
    {
      "epoch": 7.164179104477612,
      "grad_norm": 3.9992270469665527,
      "learning_rate": 4.854378818737271e-06,
      "loss": 0.0105,
      "step": 2880
    },
    {
      "epoch": 7.189054726368159,
      "grad_norm": 1.237426996231079,
      "learning_rate": 4.838968092328581e-06,
      "loss": 0.0109,
      "step": 2890
    },
    {
      "epoch": 7.213930348258707,
      "grad_norm": 1.3798211812973022,
      "learning_rate": 4.823557365919891e-06,
      "loss": 0.0082,
      "step": 2900
    },
    {
      "epoch": 7.2388059701492535,
      "grad_norm": 0.056698624044656754,
      "learning_rate": 4.808146639511201e-06,
      "loss": 0.0092,
      "step": 2910
    },
    {
      "epoch": 7.263681592039801,
      "grad_norm": 0.018871184438467026,
      "learning_rate": 4.792735913102511e-06,
      "loss": 0.0166,
      "step": 2920
    },
    {
      "epoch": 7.288557213930348,
      "grad_norm": 3.163139820098877,
      "learning_rate": 4.777325186693821e-06,
      "loss": 0.0144,
      "step": 2930
    },
    {
      "epoch": 7.313432835820896,
      "grad_norm": 3.41839599609375,
      "learning_rate": 4.761914460285133e-06,
      "loss": 0.0126,
      "step": 2940
    },
    {
      "epoch": 7.338308457711443,
      "grad_norm": 0.08126116544008255,
      "learning_rate": 4.746503733876443e-06,
      "loss": 0.0173,
      "step": 2950
    },
    {
      "epoch": 7.36318407960199,
      "grad_norm": 5.3169355392456055,
      "learning_rate": 4.731093007467753e-06,
      "loss": 0.0203,
      "step": 2960
    },
    {
      "epoch": 7.388059701492537,
      "grad_norm": 1.1038166284561157,
      "learning_rate": 4.715682281059063e-06,
      "loss": 0.0181,
      "step": 2970
    },
    {
      "epoch": 7.412935323383085,
      "grad_norm": 0.009963758289813995,
      "learning_rate": 4.7002715546503736e-06,
      "loss": 0.01,
      "step": 2980
    },
    {
      "epoch": 7.437810945273632,
      "grad_norm": 1.9045112133026123,
      "learning_rate": 4.6848608282416835e-06,
      "loss": 0.0085,
      "step": 2990
    },
    {
      "epoch": 7.462686567164179,
      "grad_norm": 0.11341673880815506,
      "learning_rate": 4.6694501018329935e-06,
      "loss": 0.0191,
      "step": 3000
    },
    {
      "epoch": 7.487562189054726,
      "grad_norm": 1.949729323387146,
      "learning_rate": 4.654039375424303e-06,
      "loss": 0.0084,
      "step": 3010
    },
    {
      "epoch": 7.512437810945274,
      "grad_norm": 0.14362403750419617,
      "learning_rate": 4.638628649015614e-06,
      "loss": 0.0038,
      "step": 3020
    },
    {
      "epoch": 7.537313432835821,
      "grad_norm": 2.6036930084228516,
      "learning_rate": 4.623217922606924e-06,
      "loss": 0.0166,
      "step": 3030
    },
    {
      "epoch": 7.562189054726368,
      "grad_norm": 0.7522117495536804,
      "learning_rate": 4.607807196198234e-06,
      "loss": 0.0186,
      "step": 3040
    },
    {
      "epoch": 7.587064676616915,
      "grad_norm": 0.006380985025316477,
      "learning_rate": 4.592396469789545e-06,
      "loss": 0.025,
      "step": 3050
    },
    {
      "epoch": 7.611940298507463,
      "grad_norm": 2.393179416656494,
      "learning_rate": 4.576985743380855e-06,
      "loss": 0.0074,
      "step": 3060
    },
    {
      "epoch": 7.63681592039801,
      "grad_norm": 1.3429439067840576,
      "learning_rate": 4.561575016972165e-06,
      "loss": 0.0161,
      "step": 3070
    },
    {
      "epoch": 7.661691542288557,
      "grad_norm": 1.7292213439941406,
      "learning_rate": 4.5461642905634764e-06,
      "loss": 0.0171,
      "step": 3080
    },
    {
      "epoch": 7.686567164179104,
      "grad_norm": 2.041476011276245,
      "learning_rate": 4.5307535641547855e-06,
      "loss": 0.006,
      "step": 3090
    },
    {
      "epoch": 7.711442786069652,
      "grad_norm": 3.5815212726593018,
      "learning_rate": 4.515342837746096e-06,
      "loss": 0.015,
      "step": 3100
    },
    {
      "epoch": 7.736318407960199,
      "grad_norm": 3.7801835536956787,
      "learning_rate": 4.499932111337406e-06,
      "loss": 0.0117,
      "step": 3110
    },
    {
      "epoch": 7.7611940298507465,
      "grad_norm": 0.07082263380289078,
      "learning_rate": 4.484521384928717e-06,
      "loss": 0.0088,
      "step": 3120
    },
    {
      "epoch": 7.786069651741293,
      "grad_norm": 0.9196576476097107,
      "learning_rate": 4.469110658520027e-06,
      "loss": 0.0118,
      "step": 3130
    },
    {
      "epoch": 7.810945273631841,
      "grad_norm": 3.6570446491241455,
      "learning_rate": 4.453699932111337e-06,
      "loss": 0.029,
      "step": 3140
    },
    {
      "epoch": 7.835820895522388,
      "grad_norm": 4.4841227531433105,
      "learning_rate": 4.438289205702647e-06,
      "loss": 0.0157,
      "step": 3150
    },
    {
      "epoch": 7.8606965174129355,
      "grad_norm": 2.9325523376464844,
      "learning_rate": 4.422878479293958e-06,
      "loss": 0.0033,
      "step": 3160
    },
    {
      "epoch": 7.885572139303482,
      "grad_norm": 0.5644885897636414,
      "learning_rate": 4.4074677528852685e-06,
      "loss": 0.0051,
      "step": 3170
    },
    {
      "epoch": 7.91044776119403,
      "grad_norm": 0.0404810756444931,
      "learning_rate": 4.3920570264765784e-06,
      "loss": 0.0077,
      "step": 3180
    },
    {
      "epoch": 7.935323383084577,
      "grad_norm": 2.166112184524536,
      "learning_rate": 4.376646300067888e-06,
      "loss": 0.0155,
      "step": 3190
    },
    {
      "epoch": 7.960199004975125,
      "grad_norm": 3.4549009799957275,
      "learning_rate": 4.361235573659198e-06,
      "loss": 0.0173,
      "step": 3200
    },
    {
      "epoch": 7.985074626865671,
      "grad_norm": 2.543510675430298,
      "learning_rate": 4.345824847250509e-06,
      "loss": 0.0205,
      "step": 3210
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9914001937984496,
      "eval_f1": 0.9520594193112761,
      "eval_loss": 0.028054432943463326,
      "eval_precision": 0.9710743801652892,
      "eval_recall": 0.9337748344370861,
      "eval_runtime": 115.9448,
      "eval_samples_per_second": 71.387,
      "eval_steps_per_second": 2.976,
      "step": 3216
    },
    {
      "epoch": 8.009950248756219,
      "grad_norm": 0.5127356648445129,
      "learning_rate": 4.330414120841819e-06,
      "loss": 0.0037,
      "step": 3220
    },
    {
      "epoch": 8.034825870646767,
      "grad_norm": 1.3259663581848145,
      "learning_rate": 4.315003394433129e-06,
      "loss": 0.0089,
      "step": 3230
    },
    {
      "epoch": 8.059701492537313,
      "grad_norm": 3.5632638931274414,
      "learning_rate": 4.29959266802444e-06,
      "loss": 0.0065,
      "step": 3240
    },
    {
      "epoch": 8.08457711442786,
      "grad_norm": 2.8988282680511475,
      "learning_rate": 4.28418194161575e-06,
      "loss": 0.0103,
      "step": 3250
    },
    {
      "epoch": 8.109452736318408,
      "grad_norm": 5.014246463775635,
      "learning_rate": 4.2687712152070606e-06,
      "loss": 0.0116,
      "step": 3260
    },
    {
      "epoch": 8.134328358208956,
      "grad_norm": 0.05625467002391815,
      "learning_rate": 4.2533604887983705e-06,
      "loss": 0.0084,
      "step": 3270
    },
    {
      "epoch": 8.159203980099502,
      "grad_norm": 0.03451701998710632,
      "learning_rate": 4.2379497623896805e-06,
      "loss": 0.0061,
      "step": 3280
    },
    {
      "epoch": 8.18407960199005,
      "grad_norm": 5.0291748046875,
      "learning_rate": 4.22253903598099e-06,
      "loss": 0.0102,
      "step": 3290
    },
    {
      "epoch": 8.208955223880597,
      "grad_norm": 0.4944792687892914,
      "learning_rate": 4.207128309572301e-06,
      "loss": 0.0106,
      "step": 3300
    },
    {
      "epoch": 8.233830845771145,
      "grad_norm": 6.434576988220215,
      "learning_rate": 4.191717583163612e-06,
      "loss": 0.0083,
      "step": 3310
    },
    {
      "epoch": 8.25870646766169,
      "grad_norm": 1.7765275239944458,
      "learning_rate": 4.176306856754922e-06,
      "loss": 0.0155,
      "step": 3320
    },
    {
      "epoch": 8.283582089552239,
      "grad_norm": 4.369102954864502,
      "learning_rate": 4.160896130346232e-06,
      "loss": 0.0097,
      "step": 3330
    },
    {
      "epoch": 8.308457711442786,
      "grad_norm": 0.23799686133861542,
      "learning_rate": 4.145485403937542e-06,
      "loss": 0.0109,
      "step": 3340
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 2.8926408290863037,
      "learning_rate": 4.130074677528853e-06,
      "loss": 0.0168,
      "step": 3350
    },
    {
      "epoch": 8.35820895522388,
      "grad_norm": 0.5572888851165771,
      "learning_rate": 4.114663951120163e-06,
      "loss": 0.0042,
      "step": 3360
    },
    {
      "epoch": 8.383084577114428,
      "grad_norm": 2.4449310302734375,
      "learning_rate": 4.099253224711473e-06,
      "loss": 0.0066,
      "step": 3370
    },
    {
      "epoch": 8.407960199004975,
      "grad_norm": 0.08427995443344116,
      "learning_rate": 4.083842498302783e-06,
      "loss": 0.0152,
      "step": 3380
    },
    {
      "epoch": 8.432835820895523,
      "grad_norm": 1.7295870780944824,
      "learning_rate": 4.068431771894093e-06,
      "loss": 0.0082,
      "step": 3390
    },
    {
      "epoch": 8.457711442786069,
      "grad_norm": 0.8090488314628601,
      "learning_rate": 4.053021045485404e-06,
      "loss": 0.0071,
      "step": 3400
    },
    {
      "epoch": 8.482587064676617,
      "grad_norm": 0.1951834261417389,
      "learning_rate": 4.037610319076714e-06,
      "loss": 0.0108,
      "step": 3410
    },
    {
      "epoch": 8.507462686567164,
      "grad_norm": 2.4471194744110107,
      "learning_rate": 4.022199592668024e-06,
      "loss": 0.0059,
      "step": 3420
    },
    {
      "epoch": 8.532338308457712,
      "grad_norm": 2.4972972869873047,
      "learning_rate": 4.006788866259334e-06,
      "loss": 0.0193,
      "step": 3430
    },
    {
      "epoch": 8.557213930348258,
      "grad_norm": 0.16242018342018127,
      "learning_rate": 3.991378139850645e-06,
      "loss": 0.0164,
      "step": 3440
    },
    {
      "epoch": 8.582089552238806,
      "grad_norm": 5.582426071166992,
      "learning_rate": 3.975967413441955e-06,
      "loss": 0.015,
      "step": 3450
    },
    {
      "epoch": 8.606965174129353,
      "grad_norm": 0.6410492062568665,
      "learning_rate": 3.9605566870332655e-06,
      "loss": 0.0158,
      "step": 3460
    },
    {
      "epoch": 8.631840796019901,
      "grad_norm": 1.5332281589508057,
      "learning_rate": 3.945145960624575e-06,
      "loss": 0.0111,
      "step": 3470
    },
    {
      "epoch": 8.656716417910447,
      "grad_norm": 1.5555187463760376,
      "learning_rate": 3.929735234215885e-06,
      "loss": 0.0063,
      "step": 3480
    },
    {
      "epoch": 8.681592039800995,
      "grad_norm": 0.6861915588378906,
      "learning_rate": 3.914324507807196e-06,
      "loss": 0.0106,
      "step": 3490
    },
    {
      "epoch": 8.706467661691542,
      "grad_norm": 6.322965621948242,
      "learning_rate": 3.898913781398506e-06,
      "loss": 0.0176,
      "step": 3500
    },
    {
      "epoch": 8.73134328358209,
      "grad_norm": 0.7496024966239929,
      "learning_rate": 3.883503054989817e-06,
      "loss": 0.0115,
      "step": 3510
    },
    {
      "epoch": 8.756218905472636,
      "grad_norm": 0.00591224106028676,
      "learning_rate": 3.868092328581127e-06,
      "loss": 0.0063,
      "step": 3520
    },
    {
      "epoch": 8.781094527363184,
      "grad_norm": 2.543020248413086,
      "learning_rate": 3.852681602172437e-06,
      "loss": 0.0147,
      "step": 3530
    },
    {
      "epoch": 8.805970149253731,
      "grad_norm": 1.989740252494812,
      "learning_rate": 3.837270875763747e-06,
      "loss": 0.0079,
      "step": 3540
    },
    {
      "epoch": 8.83084577114428,
      "grad_norm": 4.869475841522217,
      "learning_rate": 3.8218601493550575e-06,
      "loss": 0.0157,
      "step": 3550
    },
    {
      "epoch": 8.855721393034825,
      "grad_norm": 0.3984147012233734,
      "learning_rate": 3.8064494229463675e-06,
      "loss": 0.024,
      "step": 3560
    },
    {
      "epoch": 8.880597014925373,
      "grad_norm": 1.684017300605774,
      "learning_rate": 3.7910386965376783e-06,
      "loss": 0.0057,
      "step": 3570
    },
    {
      "epoch": 8.90547263681592,
      "grad_norm": 3.2745156288146973,
      "learning_rate": 3.7756279701289882e-06,
      "loss": 0.0114,
      "step": 3580
    },
    {
      "epoch": 8.930348258706468,
      "grad_norm": 2.444610595703125,
      "learning_rate": 3.7602172437202986e-06,
      "loss": 0.0045,
      "step": 3590
    },
    {
      "epoch": 8.955223880597014,
      "grad_norm": 0.7507184743881226,
      "learning_rate": 3.7448065173116085e-06,
      "loss": 0.004,
      "step": 3600
    },
    {
      "epoch": 8.980099502487562,
      "grad_norm": 0.4327292740345001,
      "learning_rate": 3.729395790902919e-06,
      "loss": 0.0195,
      "step": 3610
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9909156976744186,
      "eval_f1": 0.9506254114549045,
      "eval_loss": 0.03259147331118584,
      "eval_precision": 0.9450261780104712,
      "eval_recall": 0.9562913907284768,
      "eval_runtime": 114.4401,
      "eval_samples_per_second": 72.326,
      "eval_steps_per_second": 3.015,
      "step": 3618
    },
    {
      "epoch": 9.00497512437811,
      "grad_norm": 1.4517320394515991,
      "learning_rate": 3.713985064494229e-06,
      "loss": 0.0109,
      "step": 3620
    },
    {
      "epoch": 9.029850746268657,
      "grad_norm": 1.6002358198165894,
      "learning_rate": 3.6985743380855397e-06,
      "loss": 0.0205,
      "step": 3630
    },
    {
      "epoch": 9.054726368159203,
      "grad_norm": 3.9134068489074707,
      "learning_rate": 3.68316361167685e-06,
      "loss": 0.0133,
      "step": 3640
    },
    {
      "epoch": 9.07960199004975,
      "grad_norm": 2.3313965797424316,
      "learning_rate": 3.66775288526816e-06,
      "loss": 0.019,
      "step": 3650
    },
    {
      "epoch": 9.104477611940299,
      "grad_norm": 0.011796876788139343,
      "learning_rate": 3.6523421588594703e-06,
      "loss": 0.0089,
      "step": 3660
    },
    {
      "epoch": 9.129353233830846,
      "grad_norm": 2.2670464515686035,
      "learning_rate": 3.6369314324507803e-06,
      "loss": 0.0106,
      "step": 3670
    },
    {
      "epoch": 9.154228855721392,
      "grad_norm": 1.4718798398971558,
      "learning_rate": 3.6215207060420907e-06,
      "loss": 0.0069,
      "step": 3680
    },
    {
      "epoch": 9.17910447761194,
      "grad_norm": 1.2271476984024048,
      "learning_rate": 3.6061099796334006e-06,
      "loss": 0.0084,
      "step": 3690
    },
    {
      "epoch": 9.203980099502488,
      "grad_norm": 3.127293825149536,
      "learning_rate": 3.5906992532247114e-06,
      "loss": 0.0103,
      "step": 3700
    },
    {
      "epoch": 9.228855721393035,
      "grad_norm": 1.8398102521896362,
      "learning_rate": 3.5752885268160218e-06,
      "loss": 0.0106,
      "step": 3710
    },
    {
      "epoch": 9.253731343283581,
      "grad_norm": 0.024314552545547485,
      "learning_rate": 3.5598778004073317e-06,
      "loss": 0.007,
      "step": 3720
    },
    {
      "epoch": 9.278606965174129,
      "grad_norm": 1.209571361541748,
      "learning_rate": 3.544467073998642e-06,
      "loss": 0.0315,
      "step": 3730
    },
    {
      "epoch": 9.303482587064677,
      "grad_norm": 2.3998000621795654,
      "learning_rate": 3.529056347589952e-06,
      "loss": 0.0101,
      "step": 3740
    },
    {
      "epoch": 9.328358208955224,
      "grad_norm": 2.090447425842285,
      "learning_rate": 3.5136456211812624e-06,
      "loss": 0.0022,
      "step": 3750
    },
    {
      "epoch": 9.35323383084577,
      "grad_norm": 0.1274603009223938,
      "learning_rate": 3.4982348947725724e-06,
      "loss": 0.0068,
      "step": 3760
    },
    {
      "epoch": 9.378109452736318,
      "grad_norm": 0.05992814898490906,
      "learning_rate": 3.482824168363883e-06,
      "loss": 0.0227,
      "step": 3770
    },
    {
      "epoch": 9.402985074626866,
      "grad_norm": 4.101009368896484,
      "learning_rate": 3.4674134419551935e-06,
      "loss": 0.0205,
      "step": 3780
    },
    {
      "epoch": 9.427860696517413,
      "grad_norm": 0.4624897241592407,
      "learning_rate": 3.4520027155465035e-06,
      "loss": 0.0101,
      "step": 3790
    },
    {
      "epoch": 9.45273631840796,
      "grad_norm": 6.65974235534668,
      "learning_rate": 3.436591989137814e-06,
      "loss": 0.0062,
      "step": 3800
    },
    {
      "epoch": 9.477611940298507,
      "grad_norm": 2.8291025161743164,
      "learning_rate": 3.421181262729124e-06,
      "loss": 0.0083,
      "step": 3810
    },
    {
      "epoch": 9.502487562189055,
      "grad_norm": 0.8585681319236755,
      "learning_rate": 3.405770536320434e-06,
      "loss": 0.0078,
      "step": 3820
    },
    {
      "epoch": 9.527363184079602,
      "grad_norm": 8.46120548248291,
      "learning_rate": 3.390359809911745e-06,
      "loss": 0.0168,
      "step": 3830
    },
    {
      "epoch": 9.552238805970148,
      "grad_norm": 0.31228259205818176,
      "learning_rate": 3.374949083503055e-06,
      "loss": 0.0139,
      "step": 3840
    },
    {
      "epoch": 9.577114427860696,
      "grad_norm": 10.074338912963867,
      "learning_rate": 3.3595383570943653e-06,
      "loss": 0.0118,
      "step": 3850
    },
    {
      "epoch": 9.601990049751244,
      "grad_norm": 0.016590381041169167,
      "learning_rate": 3.3441276306856752e-06,
      "loss": 0.0092,
      "step": 3860
    },
    {
      "epoch": 9.626865671641792,
      "grad_norm": 1.086224913597107,
      "learning_rate": 3.3287169042769856e-06,
      "loss": 0.0181,
      "step": 3870
    },
    {
      "epoch": 9.65174129353234,
      "grad_norm": 0.18159401416778564,
      "learning_rate": 3.3133061778682956e-06,
      "loss": 0.0045,
      "step": 3880
    },
    {
      "epoch": 9.676616915422885,
      "grad_norm": 0.07390695065259933,
      "learning_rate": 3.297895451459606e-06,
      "loss": 0.0086,
      "step": 3890
    },
    {
      "epoch": 9.701492537313433,
      "grad_norm": 1.0686975717544556,
      "learning_rate": 3.2824847250509163e-06,
      "loss": 0.0088,
      "step": 3900
    },
    {
      "epoch": 9.72636815920398,
      "grad_norm": 1.5055724382400513,
      "learning_rate": 3.2670739986422267e-06,
      "loss": 0.005,
      "step": 3910
    },
    {
      "epoch": 9.751243781094526,
      "grad_norm": 3.923398733139038,
      "learning_rate": 3.251663272233537e-06,
      "loss": 0.0036,
      "step": 3920
    },
    {
      "epoch": 9.776119402985074,
      "grad_norm": 0.16535122692584991,
      "learning_rate": 3.236252545824847e-06,
      "loss": 0.0067,
      "step": 3930
    },
    {
      "epoch": 9.800995024875622,
      "grad_norm": 0.40373942255973816,
      "learning_rate": 3.2208418194161574e-06,
      "loss": 0.0111,
      "step": 3940
    },
    {
      "epoch": 9.82587064676617,
      "grad_norm": 2.1107256412506104,
      "learning_rate": 3.2054310930074673e-06,
      "loss": 0.0077,
      "step": 3950
    },
    {
      "epoch": 9.850746268656717,
      "grad_norm": 0.67034912109375,
      "learning_rate": 3.190020366598778e-06,
      "loss": 0.0137,
      "step": 3960
    },
    {
      "epoch": 9.875621890547263,
      "grad_norm": 0.17332051694393158,
      "learning_rate": 3.174609640190088e-06,
      "loss": 0.0098,
      "step": 3970
    },
    {
      "epoch": 9.900497512437811,
      "grad_norm": 0.12130055576562881,
      "learning_rate": 3.1591989137813984e-06,
      "loss": 0.0112,
      "step": 3980
    },
    {
      "epoch": 9.925373134328359,
      "grad_norm": 0.008847369812428951,
      "learning_rate": 3.143788187372709e-06,
      "loss": 0.0103,
      "step": 3990
    },
    {
      "epoch": 9.950248756218905,
      "grad_norm": 0.01241744589060545,
      "learning_rate": 3.1283774609640187e-06,
      "loss": 0.0057,
      "step": 4000
    },
    {
      "epoch": 9.975124378109452,
      "grad_norm": 0.03145039081573486,
      "learning_rate": 3.112966734555329e-06,
      "loss": 0.0102,
      "step": 4010
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.8490943312644958,
      "learning_rate": 3.097556008146639e-06,
      "loss": 0.0086,
      "step": 4020
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9911579457364341,
      "eval_f1": 0.9513008672448299,
      "eval_loss": 0.029387516900897026,
      "eval_precision": 0.9583333333333334,
      "eval_recall": 0.9443708609271523,
      "eval_runtime": 114.8042,
      "eval_samples_per_second": 72.097,
      "eval_steps_per_second": 3.005,
      "step": 4020
    },
    {
      "epoch": 10.024875621890548,
      "grad_norm": 2.230039119720459,
      "learning_rate": 3.08214528173795e-06,
      "loss": 0.0076,
      "step": 4030
    },
    {
      "epoch": 10.049751243781095,
      "grad_norm": 1.5155946016311646,
      "learning_rate": 3.06673455532926e-06,
      "loss": 0.0045,
      "step": 4040
    },
    {
      "epoch": 10.074626865671641,
      "grad_norm": 0.3100779950618744,
      "learning_rate": 3.05132382892057e-06,
      "loss": 0.005,
      "step": 4050
    },
    {
      "epoch": 10.099502487562189,
      "grad_norm": 0.36893966794013977,
      "learning_rate": 3.03591310251188e-06,
      "loss": 0.0013,
      "step": 4060
    },
    {
      "epoch": 10.124378109452737,
      "grad_norm": 0.043843887746334076,
      "learning_rate": 3.0205023761031905e-06,
      "loss": 0.0065,
      "step": 4070
    },
    {
      "epoch": 10.149253731343283,
      "grad_norm": 0.015347346663475037,
      "learning_rate": 3.005091649694501e-06,
      "loss": 0.0032,
      "step": 4080
    },
    {
      "epoch": 10.17412935323383,
      "grad_norm": 0.02993454597890377,
      "learning_rate": 2.989680923285811e-06,
      "loss": 0.0059,
      "step": 4090
    },
    {
      "epoch": 10.199004975124378,
      "grad_norm": 0.1164097860455513,
      "learning_rate": 2.9742701968771216e-06,
      "loss": 0.0106,
      "step": 4100
    },
    {
      "epoch": 10.223880597014926,
      "grad_norm": 1.75498366355896,
      "learning_rate": 2.9588594704684316e-06,
      "loss": 0.0076,
      "step": 4110
    },
    {
      "epoch": 10.248756218905474,
      "grad_norm": 0.49556735157966614,
      "learning_rate": 2.943448744059742e-06,
      "loss": 0.0136,
      "step": 4120
    },
    {
      "epoch": 10.27363184079602,
      "grad_norm": 9.03893756866455,
      "learning_rate": 2.928038017651052e-06,
      "loss": 0.0065,
      "step": 4130
    },
    {
      "epoch": 10.298507462686567,
      "grad_norm": 2.565657377243042,
      "learning_rate": 2.9126272912423622e-06,
      "loss": 0.0074,
      "step": 4140
    },
    {
      "epoch": 10.323383084577115,
      "grad_norm": 0.19370141625404358,
      "learning_rate": 2.897216564833672e-06,
      "loss": 0.0073,
      "step": 4150
    },
    {
      "epoch": 10.348258706467663,
      "grad_norm": 0.2340070903301239,
      "learning_rate": 2.881805838424983e-06,
      "loss": 0.0072,
      "step": 4160
    },
    {
      "epoch": 10.373134328358208,
      "grad_norm": 0.3061025142669678,
      "learning_rate": 2.8663951120162934e-06,
      "loss": 0.006,
      "step": 4170
    },
    {
      "epoch": 10.398009950248756,
      "grad_norm": 2.1595537662506104,
      "learning_rate": 2.8509843856076033e-06,
      "loss": 0.0085,
      "step": 4180
    },
    {
      "epoch": 10.422885572139304,
      "grad_norm": 2.5017383098602295,
      "learning_rate": 2.8355736591989137e-06,
      "loss": 0.0082,
      "step": 4190
    },
    {
      "epoch": 10.447761194029852,
      "grad_norm": 0.05031578987836838,
      "learning_rate": 2.8201629327902236e-06,
      "loss": 0.0029,
      "step": 4200
    },
    {
      "epoch": 10.472636815920398,
      "grad_norm": 1.4838119745254517,
      "learning_rate": 2.804752206381534e-06,
      "loss": 0.0178,
      "step": 4210
    },
    {
      "epoch": 10.497512437810945,
      "grad_norm": 0.010651612654328346,
      "learning_rate": 2.789341479972844e-06,
      "loss": 0.0113,
      "step": 4220
    },
    {
      "epoch": 10.522388059701493,
      "grad_norm": 0.007479758933186531,
      "learning_rate": 2.7739307535641547e-06,
      "loss": 0.0117,
      "step": 4230
    },
    {
      "epoch": 10.547263681592039,
      "grad_norm": 0.0848594456911087,
      "learning_rate": 2.758520027155465e-06,
      "loss": 0.0092,
      "step": 4240
    },
    {
      "epoch": 10.572139303482587,
      "grad_norm": 1.3248562812805176,
      "learning_rate": 2.743109300746775e-06,
      "loss": 0.0032,
      "step": 4250
    },
    {
      "epoch": 10.597014925373134,
      "grad_norm": 0.9439293146133423,
      "learning_rate": 2.7276985743380854e-06,
      "loss": 0.0087,
      "step": 4260
    },
    {
      "epoch": 10.621890547263682,
      "grad_norm": 0.0017685153288766742,
      "learning_rate": 2.7122878479293954e-06,
      "loss": 0.0239,
      "step": 4270
    },
    {
      "epoch": 10.64676616915423,
      "grad_norm": 0.1627432256937027,
      "learning_rate": 2.6968771215207058e-06,
      "loss": 0.009,
      "step": 4280
    },
    {
      "epoch": 10.671641791044776,
      "grad_norm": 0.17876295745372772,
      "learning_rate": 2.6814663951120165e-06,
      "loss": 0.0049,
      "step": 4290
    },
    {
      "epoch": 10.696517412935323,
      "grad_norm": 0.8830393552780151,
      "learning_rate": 2.6660556687033265e-06,
      "loss": 0.0165,
      "step": 4300
    },
    {
      "epoch": 10.721393034825871,
      "grad_norm": 0.9193994998931885,
      "learning_rate": 2.650644942294637e-06,
      "loss": 0.0083,
      "step": 4310
    },
    {
      "epoch": 10.746268656716419,
      "grad_norm": 0.03414333984255791,
      "learning_rate": 2.635234215885947e-06,
      "loss": 0.009,
      "step": 4320
    },
    {
      "epoch": 10.771144278606965,
      "grad_norm": 0.30423131585121155,
      "learning_rate": 2.619823489477257e-06,
      "loss": 0.004,
      "step": 4330
    },
    {
      "epoch": 10.796019900497512,
      "grad_norm": 0.00524104805663228,
      "learning_rate": 2.604412763068567e-06,
      "loss": 0.0159,
      "step": 4340
    },
    {
      "epoch": 10.82089552238806,
      "grad_norm": 2.1396729946136475,
      "learning_rate": 2.5890020366598775e-06,
      "loss": 0.0081,
      "step": 4350
    },
    {
      "epoch": 10.845771144278608,
      "grad_norm": 1.194216012954712,
      "learning_rate": 2.5735913102511883e-06,
      "loss": 0.0171,
      "step": 4360
    },
    {
      "epoch": 10.870646766169154,
      "grad_norm": 0.776901125907898,
      "learning_rate": 2.5581805838424982e-06,
      "loss": 0.0108,
      "step": 4370
    },
    {
      "epoch": 10.895522388059701,
      "grad_norm": 2.593575954437256,
      "learning_rate": 2.5427698574338086e-06,
      "loss": 0.0142,
      "step": 4380
    },
    {
      "epoch": 10.92039800995025,
      "grad_norm": 0.022378597408533096,
      "learning_rate": 2.5273591310251186e-06,
      "loss": 0.0128,
      "step": 4390
    },
    {
      "epoch": 10.945273631840797,
      "grad_norm": 0.05221765488386154,
      "learning_rate": 2.511948404616429e-06,
      "loss": 0.0137,
      "step": 4400
    },
    {
      "epoch": 10.970149253731343,
      "grad_norm": 1.4257687330245972,
      "learning_rate": 2.496537678207739e-06,
      "loss": 0.0077,
      "step": 4410
    },
    {
      "epoch": 10.99502487562189,
      "grad_norm": 0.10904188454151154,
      "learning_rate": 2.4811269517990497e-06,
      "loss": 0.0044,
      "step": 4420
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.9923691860465116,
      "eval_f1": 0.9580279813457695,
      "eval_loss": 0.025751443579792976,
      "eval_precision": 0.9638069705093834,
      "eval_recall": 0.952317880794702,
      "eval_runtime": 115.7937,
      "eval_samples_per_second": 71.481,
      "eval_steps_per_second": 2.979,
      "step": 4422
    }
  ],
  "logging_steps": 10,
  "max_steps": 6030,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.567033981280128e+16,
  "train_batch_size": 96,
  "trial_name": null,
  "trial_params": null
}
