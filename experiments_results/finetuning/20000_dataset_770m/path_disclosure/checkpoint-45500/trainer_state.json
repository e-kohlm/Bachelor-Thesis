{
  "best_metric": 0.8602484472049688,
  "best_model_checkpoint": "../saved_models/path_disclosure_770/checkpoint-45500",
  "epoch": 13.0,
  "eval_steps": 500,
  "global_step": 45500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00028571428571428574,
      "grad_norm": 86.0749282836914,
      "learning_rate": 1.999961904761905e-05,
      "loss": 0.8109,
      "step": 1
    },
    {
      "epoch": 0.002857142857142857,
      "grad_norm": 12.759336471557617,
      "learning_rate": 1.9996190476190477e-05,
      "loss": 0.4557,
      "step": 10
    },
    {
      "epoch": 0.005714285714285714,
      "grad_norm": 3.203111410140991,
      "learning_rate": 1.9992380952380953e-05,
      "loss": 0.5097,
      "step": 20
    },
    {
      "epoch": 0.008571428571428572,
      "grad_norm": 1.2773874998092651,
      "learning_rate": 1.9988571428571432e-05,
      "loss": 0.4367,
      "step": 30
    },
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 73.08857727050781,
      "learning_rate": 1.9984761904761907e-05,
      "loss": 0.8725,
      "step": 40
    },
    {
      "epoch": 0.014285714285714285,
      "grad_norm": 0.34195393323898315,
      "learning_rate": 1.9980952380952383e-05,
      "loss": 0.7428,
      "step": 50
    },
    {
      "epoch": 0.017142857142857144,
      "grad_norm": 1.3854069709777832,
      "learning_rate": 1.997714285714286e-05,
      "loss": 0.6946,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.2633458375930786,
      "learning_rate": 1.9973333333333334e-05,
      "loss": 0.4895,
      "step": 70
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 0.4563247859477997,
      "learning_rate": 1.9969523809523813e-05,
      "loss": 0.4769,
      "step": 80
    },
    {
      "epoch": 0.025714285714285714,
      "grad_norm": 0.11316660046577454,
      "learning_rate": 1.996571428571429e-05,
      "loss": 0.5726,
      "step": 90
    },
    {
      "epoch": 0.02857142857142857,
      "grad_norm": 69.9546890258789,
      "learning_rate": 1.9961904761904764e-05,
      "loss": 0.529,
      "step": 100
    },
    {
      "epoch": 0.03142857142857143,
      "grad_norm": 48.23080825805664,
      "learning_rate": 1.995809523809524e-05,
      "loss": 0.6668,
      "step": 110
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 0.47008952498435974,
      "learning_rate": 1.9954285714285715e-05,
      "loss": 0.722,
      "step": 120
    },
    {
      "epoch": 0.037142857142857144,
      "grad_norm": 0.16506092250347137,
      "learning_rate": 1.995047619047619e-05,
      "loss": 0.4718,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 42.02726364135742,
      "learning_rate": 1.9946666666666667e-05,
      "loss": 1.1517,
      "step": 140
    },
    {
      "epoch": 0.04285714285714286,
      "grad_norm": 0.19519373774528503,
      "learning_rate": 1.9942857142857142e-05,
      "loss": 0.5001,
      "step": 150
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 52.493289947509766,
      "learning_rate": 1.993904761904762e-05,
      "loss": 0.7948,
      "step": 160
    },
    {
      "epoch": 0.04857142857142857,
      "grad_norm": 0.8540410995483398,
      "learning_rate": 1.9935238095238097e-05,
      "loss": 1.0709,
      "step": 170
    },
    {
      "epoch": 0.05142857142857143,
      "grad_norm": 0.36677736043930054,
      "learning_rate": 1.9931428571428572e-05,
      "loss": 0.5025,
      "step": 180
    },
    {
      "epoch": 0.054285714285714284,
      "grad_norm": 34.67249298095703,
      "learning_rate": 1.9927619047619048e-05,
      "loss": 0.6424,
      "step": 190
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 30.46458625793457,
      "learning_rate": 1.9923809523809527e-05,
      "loss": 0.557,
      "step": 200
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8974782824516296,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.6256,
      "step": 210
    },
    {
      "epoch": 0.06285714285714286,
      "grad_norm": 0.08935113996267319,
      "learning_rate": 1.9916190476190478e-05,
      "loss": 0.3128,
      "step": 220
    },
    {
      "epoch": 0.06571428571428571,
      "grad_norm": 33.400638580322266,
      "learning_rate": 1.9912380952380954e-05,
      "loss": 0.4165,
      "step": 230
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 41.56135940551758,
      "learning_rate": 1.990857142857143e-05,
      "loss": 0.7485,
      "step": 240
    },
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 0.6341456174850464,
      "learning_rate": 1.9904761904761908e-05,
      "loss": 0.9031,
      "step": 250
    },
    {
      "epoch": 0.07428571428571429,
      "grad_norm": 1.1419092416763306,
      "learning_rate": 1.9900952380952384e-05,
      "loss": 0.2208,
      "step": 260
    },
    {
      "epoch": 0.07714285714285714,
      "grad_norm": 0.06165846437215805,
      "learning_rate": 1.989714285714286e-05,
      "loss": 0.2698,
      "step": 270
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.07995054125785828,
      "learning_rate": 1.9893333333333335e-05,
      "loss": 1.031,
      "step": 280
    },
    {
      "epoch": 0.08285714285714285,
      "grad_norm": 0.4814751446247101,
      "learning_rate": 1.988952380952381e-05,
      "loss": 0.6189,
      "step": 290
    },
    {
      "epoch": 0.08571428571428572,
      "grad_norm": 30.510324478149414,
      "learning_rate": 1.988571428571429e-05,
      "loss": 0.5182,
      "step": 300
    },
    {
      "epoch": 0.08857142857142856,
      "grad_norm": 0.24071475863456726,
      "learning_rate": 1.9881904761904765e-05,
      "loss": 0.7809,
      "step": 310
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.342053085565567,
      "learning_rate": 1.987809523809524e-05,
      "loss": 0.4902,
      "step": 320
    },
    {
      "epoch": 0.09428571428571429,
      "grad_norm": 26.50996208190918,
      "learning_rate": 1.9874285714285716e-05,
      "loss": 0.8237,
      "step": 330
    },
    {
      "epoch": 0.09714285714285714,
      "grad_norm": 0.3699360489845276,
      "learning_rate": 1.9870476190476192e-05,
      "loss": 0.3876,
      "step": 340
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.5942488312721252,
      "learning_rate": 1.9866666666666667e-05,
      "loss": 0.7549,
      "step": 350
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 31.755050659179688,
      "learning_rate": 1.9862857142857143e-05,
      "loss": 0.7486,
      "step": 360
    },
    {
      "epoch": 0.10571428571428572,
      "grad_norm": 33.31279754638672,
      "learning_rate": 1.985904761904762e-05,
      "loss": 0.4255,
      "step": 370
    },
    {
      "epoch": 0.10857142857142857,
      "grad_norm": 44.32960891723633,
      "learning_rate": 1.9855238095238097e-05,
      "loss": 0.6512,
      "step": 380
    },
    {
      "epoch": 0.11142857142857143,
      "grad_norm": 0.13044418394565582,
      "learning_rate": 1.9851428571428573e-05,
      "loss": 0.4712,
      "step": 390
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 0.22238574922084808,
      "learning_rate": 1.984761904761905e-05,
      "loss": 0.2894,
      "step": 400
    },
    {
      "epoch": 0.11714285714285715,
      "grad_norm": 0.1682286262512207,
      "learning_rate": 1.9843809523809524e-05,
      "loss": 0.3133,
      "step": 410
    },
    {
      "epoch": 0.12,
      "grad_norm": 41.723514556884766,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.7547,
      "step": 420
    },
    {
      "epoch": 0.12285714285714286,
      "grad_norm": 2.319145917892456,
      "learning_rate": 1.983619047619048e-05,
      "loss": 0.942,
      "step": 430
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 0.34098395705223083,
      "learning_rate": 1.9832380952380954e-05,
      "loss": 0.3932,
      "step": 440
    },
    {
      "epoch": 0.12857142857142856,
      "grad_norm": 23.409114837646484,
      "learning_rate": 1.982857142857143e-05,
      "loss": 0.8073,
      "step": 450
    },
    {
      "epoch": 0.13142857142857142,
      "grad_norm": 0.41799360513687134,
      "learning_rate": 1.9824761904761905e-05,
      "loss": 0.4166,
      "step": 460
    },
    {
      "epoch": 0.13428571428571429,
      "grad_norm": 21.497356414794922,
      "learning_rate": 1.9820952380952384e-05,
      "loss": 0.8559,
      "step": 470
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 21.74665069580078,
      "learning_rate": 1.981714285714286e-05,
      "loss": 0.1343,
      "step": 480
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.14958716928958893,
      "learning_rate": 1.9813333333333336e-05,
      "loss": 0.5069,
      "step": 490
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 0.9635583162307739,
      "learning_rate": 1.980952380952381e-05,
      "loss": 0.9009,
      "step": 500
    },
    {
      "epoch": 0.1457142857142857,
      "grad_norm": 0.8291277885437012,
      "learning_rate": 1.9805714285714287e-05,
      "loss": 0.6587,
      "step": 510
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 21.12747573852539,
      "learning_rate": 1.9801904761904766e-05,
      "loss": 0.5098,
      "step": 520
    },
    {
      "epoch": 0.15142857142857144,
      "grad_norm": 0.21618670225143433,
      "learning_rate": 1.979809523809524e-05,
      "loss": 0.9215,
      "step": 530
    },
    {
      "epoch": 0.15428571428571428,
      "grad_norm": 34.42506408691406,
      "learning_rate": 1.9794285714285717e-05,
      "loss": 1.3307,
      "step": 540
    },
    {
      "epoch": 0.15714285714285714,
      "grad_norm": 1.173480749130249,
      "learning_rate": 1.9790476190476193e-05,
      "loss": 0.1967,
      "step": 550
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.07430510222911835,
      "learning_rate": 1.9786666666666668e-05,
      "loss": 0.7601,
      "step": 560
    },
    {
      "epoch": 0.16285714285714287,
      "grad_norm": 0.4122089445590973,
      "learning_rate": 1.9782857142857144e-05,
      "loss": 1.3271,
      "step": 570
    },
    {
      "epoch": 0.1657142857142857,
      "grad_norm": 1.0724403858184814,
      "learning_rate": 1.977904761904762e-05,
      "loss": 0.5467,
      "step": 580
    },
    {
      "epoch": 0.16857142857142857,
      "grad_norm": 30.087509155273438,
      "learning_rate": 1.9775238095238095e-05,
      "loss": 0.5784,
      "step": 590
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.09390363097190857,
      "learning_rate": 1.9771428571428574e-05,
      "loss": 0.9172,
      "step": 600
    },
    {
      "epoch": 0.1742857142857143,
      "grad_norm": 0.375957190990448,
      "learning_rate": 1.976761904761905e-05,
      "loss": 0.3854,
      "step": 610
    },
    {
      "epoch": 0.17714285714285713,
      "grad_norm": 0.38019728660583496,
      "learning_rate": 1.9763809523809525e-05,
      "loss": 0.6963,
      "step": 620
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.45080193877220154,
      "learning_rate": 1.976e-05,
      "loss": 0.3433,
      "step": 630
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 29.18952178955078,
      "learning_rate": 1.9756190476190476e-05,
      "loss": 1.0207,
      "step": 640
    },
    {
      "epoch": 0.18571428571428572,
      "grad_norm": 26.69594955444336,
      "learning_rate": 1.9752380952380955e-05,
      "loss": 0.6359,
      "step": 650
    },
    {
      "epoch": 0.18857142857142858,
      "grad_norm": 3.358771800994873,
      "learning_rate": 1.974857142857143e-05,
      "loss": 1.1953,
      "step": 660
    },
    {
      "epoch": 0.19142857142857142,
      "grad_norm": 26.258302688598633,
      "learning_rate": 1.9744761904761906e-05,
      "loss": 0.5428,
      "step": 670
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 0.31142497062683105,
      "learning_rate": 1.9740952380952382e-05,
      "loss": 0.4413,
      "step": 680
    },
    {
      "epoch": 0.19714285714285715,
      "grad_norm": 0.14846482872962952,
      "learning_rate": 1.973714285714286e-05,
      "loss": 0.4518,
      "step": 690
    },
    {
      "epoch": 0.2,
      "grad_norm": 22.090961456298828,
      "learning_rate": 1.9733333333333336e-05,
      "loss": 0.8603,
      "step": 700
    },
    {
      "epoch": 0.20285714285714285,
      "grad_norm": 20.212844848632812,
      "learning_rate": 1.9729523809523812e-05,
      "loss": 0.8176,
      "step": 710
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 42.303794860839844,
      "learning_rate": 1.9725714285714288e-05,
      "loss": 0.3972,
      "step": 720
    },
    {
      "epoch": 0.20857142857142857,
      "grad_norm": 0.39020276069641113,
      "learning_rate": 1.9721904761904763e-05,
      "loss": 1.0839,
      "step": 730
    },
    {
      "epoch": 0.21142857142857144,
      "grad_norm": 1.9535088539123535,
      "learning_rate": 1.9718095238095242e-05,
      "loss": 0.4228,
      "step": 740
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 0.17687179148197174,
      "learning_rate": 1.9714285714285718e-05,
      "loss": 0.8577,
      "step": 750
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 27.910890579223633,
      "learning_rate": 1.971047619047619e-05,
      "loss": 0.5911,
      "step": 760
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.020642876625061,
      "learning_rate": 1.970666666666667e-05,
      "loss": 0.8094,
      "step": 770
    },
    {
      "epoch": 0.22285714285714286,
      "grad_norm": 0.8412623405456543,
      "learning_rate": 1.9702857142857144e-05,
      "loss": 0.2562,
      "step": 780
    },
    {
      "epoch": 0.2257142857142857,
      "grad_norm": 0.04772534221410751,
      "learning_rate": 1.969904761904762e-05,
      "loss": 0.6902,
      "step": 790
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.10536428540945053,
      "learning_rate": 1.9695238095238096e-05,
      "loss": 1.1838,
      "step": 800
    },
    {
      "epoch": 0.23142857142857143,
      "grad_norm": 1.2560374736785889,
      "learning_rate": 1.969142857142857e-05,
      "loss": 0.5942,
      "step": 810
    },
    {
      "epoch": 0.2342857142857143,
      "grad_norm": 0.3674640357494354,
      "learning_rate": 1.968761904761905e-05,
      "loss": 0.4865,
      "step": 820
    },
    {
      "epoch": 0.23714285714285716,
      "grad_norm": 2.4636590480804443,
      "learning_rate": 1.9683809523809526e-05,
      "loss": 0.9035,
      "step": 830
    },
    {
      "epoch": 0.24,
      "grad_norm": 33.64129638671875,
      "learning_rate": 1.968e-05,
      "loss": 0.5025,
      "step": 840
    },
    {
      "epoch": 0.24285714285714285,
      "grad_norm": 0.3685813844203949,
      "learning_rate": 1.9676190476190477e-05,
      "loss": 0.574,
      "step": 850
    },
    {
      "epoch": 0.24571428571428572,
      "grad_norm": 39.21268844604492,
      "learning_rate": 1.9672380952380952e-05,
      "loss": 1.102,
      "step": 860
    },
    {
      "epoch": 0.24857142857142858,
      "grad_norm": 25.199913024902344,
      "learning_rate": 1.966857142857143e-05,
      "loss": 0.4531,
      "step": 870
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 27.429351806640625,
      "learning_rate": 1.9664761904761907e-05,
      "loss": 0.7799,
      "step": 880
    },
    {
      "epoch": 0.2542857142857143,
      "grad_norm": 1.1671087741851807,
      "learning_rate": 1.9660952380952383e-05,
      "loss": 0.6211,
      "step": 890
    },
    {
      "epoch": 0.2571428571428571,
      "grad_norm": 23.82787322998047,
      "learning_rate": 1.9657142857142858e-05,
      "loss": 0.4587,
      "step": 900
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.19631332159042358,
      "learning_rate": 1.9653333333333334e-05,
      "loss": 0.5526,
      "step": 910
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 27.062536239624023,
      "learning_rate": 1.9649523809523813e-05,
      "loss": 0.9508,
      "step": 920
    },
    {
      "epoch": 0.26571428571428574,
      "grad_norm": 2.5084972381591797,
      "learning_rate": 1.964571428571429e-05,
      "loss": 0.5238,
      "step": 930
    },
    {
      "epoch": 0.26857142857142857,
      "grad_norm": 22.125062942504883,
      "learning_rate": 1.9641904761904764e-05,
      "loss": 0.6427,
      "step": 940
    },
    {
      "epoch": 0.2714285714285714,
      "grad_norm": 0.16097362339496613,
      "learning_rate": 1.963809523809524e-05,
      "loss": 0.3849,
      "step": 950
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 0.1265745759010315,
      "learning_rate": 1.963428571428572e-05,
      "loss": 0.8735,
      "step": 960
    },
    {
      "epoch": 0.27714285714285714,
      "grad_norm": 0.3568515479564667,
      "learning_rate": 1.9630476190476194e-05,
      "loss": 0.3889,
      "step": 970
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3924552798271179,
      "learning_rate": 1.9626666666666666e-05,
      "loss": 0.8683,
      "step": 980
    },
    {
      "epoch": 0.28285714285714286,
      "grad_norm": 0.7777354121208191,
      "learning_rate": 1.9622857142857142e-05,
      "loss": 0.4866,
      "step": 990
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.22247207164764404,
      "learning_rate": 1.961904761904762e-05,
      "loss": 0.3516,
      "step": 1000
    },
    {
      "epoch": 0.2885714285714286,
      "grad_norm": 0.11269408464431763,
      "learning_rate": 1.9615238095238096e-05,
      "loss": 0.2875,
      "step": 1010
    },
    {
      "epoch": 0.2914285714285714,
      "grad_norm": 22.933971405029297,
      "learning_rate": 1.9611428571428572e-05,
      "loss": 0.9242,
      "step": 1020
    },
    {
      "epoch": 0.29428571428571426,
      "grad_norm": 23.60138511657715,
      "learning_rate": 1.9607619047619048e-05,
      "loss": 0.5486,
      "step": 1030
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 20.261898040771484,
      "learning_rate": 1.9603809523809526e-05,
      "loss": 0.6928,
      "step": 1040
    },
    {
      "epoch": 0.3,
      "grad_norm": 18.986759185791016,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.5879,
      "step": 1050
    },
    {
      "epoch": 0.3028571428571429,
      "grad_norm": 21.624427795410156,
      "learning_rate": 1.9596190476190478e-05,
      "loss": 0.3797,
      "step": 1060
    },
    {
      "epoch": 0.3057142857142857,
      "grad_norm": 0.08381322026252747,
      "learning_rate": 1.9592380952380953e-05,
      "loss": 0.2638,
      "step": 1070
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 20.81423568725586,
      "learning_rate": 1.958857142857143e-05,
      "loss": 0.6189,
      "step": 1080
    },
    {
      "epoch": 0.31142857142857144,
      "grad_norm": 19.536867141723633,
      "learning_rate": 1.9584761904761908e-05,
      "loss": 0.4134,
      "step": 1090
    },
    {
      "epoch": 0.3142857142857143,
      "grad_norm": 0.4484236240386963,
      "learning_rate": 1.9580952380952383e-05,
      "loss": 0.1716,
      "step": 1100
    },
    {
      "epoch": 0.3171428571428571,
      "grad_norm": 0.07384796440601349,
      "learning_rate": 1.957714285714286e-05,
      "loss": 0.1186,
      "step": 1110
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.43420758843421936,
      "learning_rate": 1.9573333333333335e-05,
      "loss": 0.1043,
      "step": 1120
    },
    {
      "epoch": 0.32285714285714284,
      "grad_norm": 0.02129349112510681,
      "learning_rate": 1.956952380952381e-05,
      "loss": 1.2053,
      "step": 1130
    },
    {
      "epoch": 0.32571428571428573,
      "grad_norm": 0.2972997725009918,
      "learning_rate": 1.956571428571429e-05,
      "loss": 0.6464,
      "step": 1140
    },
    {
      "epoch": 0.32857142857142857,
      "grad_norm": 0.1439475119113922,
      "learning_rate": 1.9561904761904765e-05,
      "loss": 0.2239,
      "step": 1150
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 0.9322340488433838,
      "learning_rate": 1.955809523809524e-05,
      "loss": 0.6402,
      "step": 1160
    },
    {
      "epoch": 0.3342857142857143,
      "grad_norm": 0.9571306109428406,
      "learning_rate": 1.9554285714285716e-05,
      "loss": 0.8984,
      "step": 1170
    },
    {
      "epoch": 0.33714285714285713,
      "grad_norm": 0.5758975148200989,
      "learning_rate": 1.955047619047619e-05,
      "loss": 0.4093,
      "step": 1180
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.16965386271476746,
      "learning_rate": 1.954666666666667e-05,
      "loss": 0.4572,
      "step": 1190
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 15.772514343261719,
      "learning_rate": 1.9542857142857143e-05,
      "loss": 0.3058,
      "step": 1200
    },
    {
      "epoch": 0.3457142857142857,
      "grad_norm": 0.11909361183643341,
      "learning_rate": 1.9539047619047618e-05,
      "loss": 0.599,
      "step": 1210
    },
    {
      "epoch": 0.3485714285714286,
      "grad_norm": 17.013439178466797,
      "learning_rate": 1.9535238095238097e-05,
      "loss": 0.7535,
      "step": 1220
    },
    {
      "epoch": 0.3514285714285714,
      "grad_norm": 0.9468905329704285,
      "learning_rate": 1.9531428571428573e-05,
      "loss": 0.3545,
      "step": 1230
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 0.16588948667049408,
      "learning_rate": 1.9527619047619048e-05,
      "loss": 0.1324,
      "step": 1240
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.13684996962547302,
      "learning_rate": 1.9523809523809524e-05,
      "loss": 0.516,
      "step": 1250
    },
    {
      "epoch": 0.36,
      "grad_norm": 19.24872398376465,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.5956,
      "step": 1260
    },
    {
      "epoch": 0.3628571428571429,
      "grad_norm": 16.776491165161133,
      "learning_rate": 1.951619047619048e-05,
      "loss": 0.9842,
      "step": 1270
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 1.3037221431732178,
      "learning_rate": 1.9512380952380954e-05,
      "loss": 0.2811,
      "step": 1280
    },
    {
      "epoch": 0.36857142857142855,
      "grad_norm": 0.3010929226875305,
      "learning_rate": 1.950857142857143e-05,
      "loss": 0.4501,
      "step": 1290
    },
    {
      "epoch": 0.37142857142857144,
      "grad_norm": 0.13142317533493042,
      "learning_rate": 1.9504761904761905e-05,
      "loss": 0.5531,
      "step": 1300
    },
    {
      "epoch": 0.3742857142857143,
      "grad_norm": 27.178884506225586,
      "learning_rate": 1.9500952380952384e-05,
      "loss": 0.4454,
      "step": 1310
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 32.07109832763672,
      "learning_rate": 1.949714285714286e-05,
      "loss": 0.5283,
      "step": 1320
    },
    {
      "epoch": 0.38,
      "grad_norm": 32.48602294921875,
      "learning_rate": 1.9493333333333335e-05,
      "loss": 0.4564,
      "step": 1330
    },
    {
      "epoch": 0.38285714285714284,
      "grad_norm": 17.932968139648438,
      "learning_rate": 1.948952380952381e-05,
      "loss": 0.2746,
      "step": 1340
    },
    {
      "epoch": 0.38571428571428573,
      "grad_norm": 0.14104442298412323,
      "learning_rate": 1.9485714285714286e-05,
      "loss": 0.7758,
      "step": 1350
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 22.1744327545166,
      "learning_rate": 1.9481904761904765e-05,
      "loss": 0.6111,
      "step": 1360
    },
    {
      "epoch": 0.3914285714285714,
      "grad_norm": 10.120503425598145,
      "learning_rate": 1.947809523809524e-05,
      "loss": 0.5118,
      "step": 1370
    },
    {
      "epoch": 0.3942857142857143,
      "grad_norm": 9.010409355163574,
      "learning_rate": 1.9474285714285717e-05,
      "loss": 0.4126,
      "step": 1380
    },
    {
      "epoch": 0.39714285714285713,
      "grad_norm": 0.1351870596408844,
      "learning_rate": 1.9470476190476192e-05,
      "loss": 0.2726,
      "step": 1390
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.026582596823573112,
      "learning_rate": 1.9466666666666668e-05,
      "loss": 0.362,
      "step": 1400
    },
    {
      "epoch": 0.40285714285714286,
      "grad_norm": 22.066953659057617,
      "learning_rate": 1.9462857142857147e-05,
      "loss": 0.9324,
      "step": 1410
    },
    {
      "epoch": 0.4057142857142857,
      "grad_norm": 22.73859405517578,
      "learning_rate": 1.945904761904762e-05,
      "loss": 0.4089,
      "step": 1420
    },
    {
      "epoch": 0.4085714285714286,
      "grad_norm": 0.08613079786300659,
      "learning_rate": 1.9455238095238095e-05,
      "loss": 0.3985,
      "step": 1430
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 0.1719680279493332,
      "learning_rate": 1.9451428571428573e-05,
      "loss": 0.7554,
      "step": 1440
    },
    {
      "epoch": 0.4142857142857143,
      "grad_norm": 0.5782681703567505,
      "learning_rate": 1.944761904761905e-05,
      "loss": 0.429,
      "step": 1450
    },
    {
      "epoch": 0.41714285714285715,
      "grad_norm": 20.84531593322754,
      "learning_rate": 1.9443809523809525e-05,
      "loss": 0.4746,
      "step": 1460
    },
    {
      "epoch": 0.42,
      "grad_norm": 20.478670120239258,
      "learning_rate": 1.944e-05,
      "loss": 0.3952,
      "step": 1470
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 0.08311644941568375,
      "learning_rate": 1.9436190476190476e-05,
      "loss": 0.5301,
      "step": 1480
    },
    {
      "epoch": 0.4257142857142857,
      "grad_norm": 0.4060155153274536,
      "learning_rate": 1.9432380952380955e-05,
      "loss": 0.8666,
      "step": 1490
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 44.820762634277344,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.6823,
      "step": 1500
    },
    {
      "epoch": 0.43142857142857144,
      "grad_norm": 1.337774634361267,
      "learning_rate": 1.9424761904761906e-05,
      "loss": 0.5778,
      "step": 1510
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 0.7088450193405151,
      "learning_rate": 1.942095238095238e-05,
      "loss": 0.6157,
      "step": 1520
    },
    {
      "epoch": 0.43714285714285717,
      "grad_norm": 17.982460021972656,
      "learning_rate": 1.941714285714286e-05,
      "loss": 0.5303,
      "step": 1530
    },
    {
      "epoch": 0.44,
      "grad_norm": 18.505098342895508,
      "learning_rate": 1.9413333333333336e-05,
      "loss": 0.712,
      "step": 1540
    },
    {
      "epoch": 0.44285714285714284,
      "grad_norm": 0.03655838221311569,
      "learning_rate": 1.940952380952381e-05,
      "loss": 0.1672,
      "step": 1550
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 0.41865313053131104,
      "learning_rate": 1.9405714285714287e-05,
      "loss": 0.932,
      "step": 1560
    },
    {
      "epoch": 0.44857142857142857,
      "grad_norm": 18.103723526000977,
      "learning_rate": 1.9401904761904763e-05,
      "loss": 0.626,
      "step": 1570
    },
    {
      "epoch": 0.4514285714285714,
      "grad_norm": 2.7541019916534424,
      "learning_rate": 1.9398095238095242e-05,
      "loss": 0.5042,
      "step": 1580
    },
    {
      "epoch": 0.4542857142857143,
      "grad_norm": 1.6510553359985352,
      "learning_rate": 1.9394285714285717e-05,
      "loss": 0.2633,
      "step": 1590
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.0749952644109726,
      "learning_rate": 1.9390476190476193e-05,
      "loss": 0.2765,
      "step": 1600
    },
    {
      "epoch": 0.46,
      "grad_norm": 32.13740158081055,
      "learning_rate": 1.938666666666667e-05,
      "loss": 0.1684,
      "step": 1610
    },
    {
      "epoch": 0.46285714285714286,
      "grad_norm": 1.5224121809005737,
      "learning_rate": 1.9382857142857144e-05,
      "loss": 0.8345,
      "step": 1620
    },
    {
      "epoch": 0.4657142857142857,
      "grad_norm": 30.122072219848633,
      "learning_rate": 1.937904761904762e-05,
      "loss": 0.5227,
      "step": 1630
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 3.722212553024292,
      "learning_rate": 1.9375238095238095e-05,
      "loss": 0.4019,
      "step": 1640
    },
    {
      "epoch": 0.4714285714285714,
      "grad_norm": 0.0822119191288948,
      "learning_rate": 1.937142857142857e-05,
      "loss": 0.1944,
      "step": 1650
    },
    {
      "epoch": 0.4742857142857143,
      "grad_norm": 0.022781170904636383,
      "learning_rate": 1.936761904761905e-05,
      "loss": 0.6303,
      "step": 1660
    },
    {
      "epoch": 0.47714285714285715,
      "grad_norm": 19.318523406982422,
      "learning_rate": 1.9363809523809525e-05,
      "loss": 1.4726,
      "step": 1670
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.02739417552948,
      "learning_rate": 1.936e-05,
      "loss": 0.3196,
      "step": 1680
    },
    {
      "epoch": 0.4828571428571429,
      "grad_norm": 0.10985518991947174,
      "learning_rate": 1.9356190476190477e-05,
      "loss": 0.3368,
      "step": 1690
    },
    {
      "epoch": 0.4857142857142857,
      "grad_norm": 36.368675231933594,
      "learning_rate": 1.9352380952380952e-05,
      "loss": 0.9892,
      "step": 1700
    },
    {
      "epoch": 0.48857142857142855,
      "grad_norm": 1.9066355228424072,
      "learning_rate": 1.934857142857143e-05,
      "loss": 0.8908,
      "step": 1710
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 0.40636104345321655,
      "learning_rate": 1.9344761904761907e-05,
      "loss": 0.2252,
      "step": 1720
    },
    {
      "epoch": 0.4942857142857143,
      "grad_norm": 18.274423599243164,
      "learning_rate": 1.9340952380952382e-05,
      "loss": 0.7441,
      "step": 1730
    },
    {
      "epoch": 0.49714285714285716,
      "grad_norm": 0.3337440490722656,
      "learning_rate": 1.9337142857142858e-05,
      "loss": 0.7219,
      "step": 1740
    },
    {
      "epoch": 0.5,
      "grad_norm": 13.820929527282715,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 0.5545,
      "step": 1750
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 25.844337463378906,
      "learning_rate": 1.9329523809523812e-05,
      "loss": 0.5328,
      "step": 1760
    },
    {
      "epoch": 0.5057142857142857,
      "grad_norm": 5.533290863037109,
      "learning_rate": 1.9325714285714288e-05,
      "loss": 0.3319,
      "step": 1770
    },
    {
      "epoch": 0.5085714285714286,
      "grad_norm": 0.32718268036842346,
      "learning_rate": 1.9321904761904764e-05,
      "loss": 0.1997,
      "step": 1780
    },
    {
      "epoch": 0.5114285714285715,
      "grad_norm": 0.1922750174999237,
      "learning_rate": 1.931809523809524e-05,
      "loss": 0.3918,
      "step": 1790
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.15603935718536377,
      "learning_rate": 1.9314285714285718e-05,
      "loss": 0.5595,
      "step": 1800
    },
    {
      "epoch": 0.5171428571428571,
      "grad_norm": 2.410292148590088,
      "learning_rate": 1.9310476190476194e-05,
      "loss": 0.5703,
      "step": 1810
    },
    {
      "epoch": 0.52,
      "grad_norm": 19.577007293701172,
      "learning_rate": 1.930666666666667e-05,
      "loss": 0.5165,
      "step": 1820
    },
    {
      "epoch": 0.5228571428571429,
      "grad_norm": 1.006064772605896,
      "learning_rate": 1.9302857142857145e-05,
      "loss": 0.2029,
      "step": 1830
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 0.058156099170446396,
      "learning_rate": 1.929904761904762e-05,
      "loss": 0.4423,
      "step": 1840
    },
    {
      "epoch": 0.5285714285714286,
      "grad_norm": 17.6290225982666,
      "learning_rate": 1.9295238095238096e-05,
      "loss": 0.7617,
      "step": 1850
    },
    {
      "epoch": 0.5314285714285715,
      "grad_norm": 0.8309801816940308,
      "learning_rate": 1.929142857142857e-05,
      "loss": 0.6746,
      "step": 1860
    },
    {
      "epoch": 0.5342857142857143,
      "grad_norm": 15.45004940032959,
      "learning_rate": 1.9287619047619047e-05,
      "loss": 0.428,
      "step": 1870
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 16.688640594482422,
      "learning_rate": 1.9283809523809526e-05,
      "loss": 0.3418,
      "step": 1880
    },
    {
      "epoch": 0.54,
      "grad_norm": 11.455037117004395,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.6354,
      "step": 1890
    },
    {
      "epoch": 0.5428571428571428,
      "grad_norm": 5.604225158691406,
      "learning_rate": 1.9276190476190477e-05,
      "loss": 0.1904,
      "step": 1900
    },
    {
      "epoch": 0.5457142857142857,
      "grad_norm": 0.02557082287967205,
      "learning_rate": 1.9272380952380953e-05,
      "loss": 0.2538,
      "step": 1910
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 0.30963367223739624,
      "learning_rate": 1.926857142857143e-05,
      "loss": 1.142,
      "step": 1920
    },
    {
      "epoch": 0.5514285714285714,
      "grad_norm": 16.03792953491211,
      "learning_rate": 1.9264761904761907e-05,
      "loss": 0.5704,
      "step": 1930
    },
    {
      "epoch": 0.5542857142857143,
      "grad_norm": 1.3901249170303345,
      "learning_rate": 1.9260952380952383e-05,
      "loss": 0.5561,
      "step": 1940
    },
    {
      "epoch": 0.5571428571428572,
      "grad_norm": 16.75516700744629,
      "learning_rate": 1.925714285714286e-05,
      "loss": 0.2517,
      "step": 1950
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.48632124066352844,
      "learning_rate": 1.9253333333333334e-05,
      "loss": 0.3083,
      "step": 1960
    },
    {
      "epoch": 0.5628571428571428,
      "grad_norm": 0.05538409203290939,
      "learning_rate": 1.924952380952381e-05,
      "loss": 0.3552,
      "step": 1970
    },
    {
      "epoch": 0.5657142857142857,
      "grad_norm": 19.274690628051758,
      "learning_rate": 1.924571428571429e-05,
      "loss": 0.1306,
      "step": 1980
    },
    {
      "epoch": 0.5685714285714286,
      "grad_norm": 0.07076285034418106,
      "learning_rate": 1.9241904761904764e-05,
      "loss": 0.3076,
      "step": 1990
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 24.556140899658203,
      "learning_rate": 1.923809523809524e-05,
      "loss": 0.5554,
      "step": 2000
    },
    {
      "epoch": 0.5742857142857143,
      "grad_norm": 19.043542861938477,
      "learning_rate": 1.9234285714285716e-05,
      "loss": 1.0123,
      "step": 2010
    },
    {
      "epoch": 0.5771428571428572,
      "grad_norm": 0.9511781930923462,
      "learning_rate": 1.923047619047619e-05,
      "loss": 0.3012,
      "step": 2020
    },
    {
      "epoch": 0.58,
      "grad_norm": 22.425813674926758,
      "learning_rate": 1.922666666666667e-05,
      "loss": 0.3932,
      "step": 2030
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.17186778783798218,
      "learning_rate": 1.9222857142857146e-05,
      "loss": 0.4417,
      "step": 2040
    },
    {
      "epoch": 0.5857142857142857,
      "grad_norm": 0.13659974932670593,
      "learning_rate": 1.921904761904762e-05,
      "loss": 0.632,
      "step": 2050
    },
    {
      "epoch": 0.5885714285714285,
      "grad_norm": 24.874650955200195,
      "learning_rate": 1.9215238095238097e-05,
      "loss": 0.2655,
      "step": 2060
    },
    {
      "epoch": 0.5914285714285714,
      "grad_norm": 0.174540713429451,
      "learning_rate": 1.9211428571428572e-05,
      "loss": 0.272,
      "step": 2070
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 0.16804389655590057,
      "learning_rate": 1.9207619047619048e-05,
      "loss": 0.5862,
      "step": 2080
    },
    {
      "epoch": 0.5971428571428572,
      "grad_norm": 0.12810665369033813,
      "learning_rate": 1.9203809523809524e-05,
      "loss": 0.5146,
      "step": 2090
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.3396080434322357,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.3292,
      "step": 2100
    },
    {
      "epoch": 0.6028571428571429,
      "grad_norm": 0.05898735299706459,
      "learning_rate": 1.9196190476190478e-05,
      "loss": 0.69,
      "step": 2110
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 0.6695833802223206,
      "learning_rate": 1.9192380952380954e-05,
      "loss": 0.4692,
      "step": 2120
    },
    {
      "epoch": 0.6085714285714285,
      "grad_norm": 24.364864349365234,
      "learning_rate": 1.918857142857143e-05,
      "loss": 0.4633,
      "step": 2130
    },
    {
      "epoch": 0.6114285714285714,
      "grad_norm": 20.503498077392578,
      "learning_rate": 1.9184761904761905e-05,
      "loss": 0.3642,
      "step": 2140
    },
    {
      "epoch": 0.6142857142857143,
      "grad_norm": 1.3536961078643799,
      "learning_rate": 1.9180952380952384e-05,
      "loss": 0.2907,
      "step": 2150
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 1.1505483388900757,
      "learning_rate": 1.917714285714286e-05,
      "loss": 1.4994,
      "step": 2160
    },
    {
      "epoch": 0.62,
      "grad_norm": 8.91714859008789,
      "learning_rate": 1.9173333333333335e-05,
      "loss": 0.2701,
      "step": 2170
    },
    {
      "epoch": 0.6228571428571429,
      "grad_norm": 18.830137252807617,
      "learning_rate": 1.916952380952381e-05,
      "loss": 0.3588,
      "step": 2180
    },
    {
      "epoch": 0.6257142857142857,
      "grad_norm": 0.3863840401172638,
      "learning_rate": 1.9165714285714286e-05,
      "loss": 0.9674,
      "step": 2190
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.5344435572624207,
      "learning_rate": 1.9161904761904765e-05,
      "loss": 0.1929,
      "step": 2200
    },
    {
      "epoch": 0.6314285714285715,
      "grad_norm": 1.2031880617141724,
      "learning_rate": 1.915809523809524e-05,
      "loss": 0.6356,
      "step": 2210
    },
    {
      "epoch": 0.6342857142857142,
      "grad_norm": 20.440099716186523,
      "learning_rate": 1.9154285714285716e-05,
      "loss": 0.621,
      "step": 2220
    },
    {
      "epoch": 0.6371428571428571,
      "grad_norm": 0.1513717621564865,
      "learning_rate": 1.9150476190476192e-05,
      "loss": 0.4164,
      "step": 2230
    },
    {
      "epoch": 0.64,
      "grad_norm": 35.419254302978516,
      "learning_rate": 1.9146666666666667e-05,
      "loss": 1.1004,
      "step": 2240
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 0.6480573415756226,
      "learning_rate": 1.9142857142857146e-05,
      "loss": 0.3327,
      "step": 2250
    },
    {
      "epoch": 0.6457142857142857,
      "grad_norm": 35.705570220947266,
      "learning_rate": 1.9139047619047622e-05,
      "loss": 0.1701,
      "step": 2260
    },
    {
      "epoch": 0.6485714285714286,
      "grad_norm": 9.326864242553711,
      "learning_rate": 1.9135238095238098e-05,
      "loss": 1.0135,
      "step": 2270
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 14.606614112854004,
      "learning_rate": 1.9131428571428573e-05,
      "loss": 0.1714,
      "step": 2280
    },
    {
      "epoch": 0.6542857142857142,
      "grad_norm": 23.100791931152344,
      "learning_rate": 1.912761904761905e-05,
      "loss": 0.5552,
      "step": 2290
    },
    {
      "epoch": 0.6571428571428571,
      "grad_norm": 26.4501895904541,
      "learning_rate": 1.9123809523809524e-05,
      "loss": 0.5943,
      "step": 2300
    },
    {
      "epoch": 0.66,
      "grad_norm": 26.913476943969727,
      "learning_rate": 1.912e-05,
      "loss": 0.3287,
      "step": 2310
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 20.77043342590332,
      "learning_rate": 1.9116190476190475e-05,
      "loss": 0.4099,
      "step": 2320
    },
    {
      "epoch": 0.6657142857142857,
      "grad_norm": 35.73828125,
      "learning_rate": 1.9112380952380954e-05,
      "loss": 0.4922,
      "step": 2330
    },
    {
      "epoch": 0.6685714285714286,
      "grad_norm": 0.2898947298526764,
      "learning_rate": 1.910857142857143e-05,
      "loss": 0.1286,
      "step": 2340
    },
    {
      "epoch": 0.6714285714285714,
      "grad_norm": 2.6112687587738037,
      "learning_rate": 1.9104761904761906e-05,
      "loss": 0.3007,
      "step": 2350
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 29.302711486816406,
      "learning_rate": 1.910095238095238e-05,
      "loss": 1.0531,
      "step": 2360
    },
    {
      "epoch": 0.6771428571428572,
      "grad_norm": 1.5191400051116943,
      "learning_rate": 1.909714285714286e-05,
      "loss": 0.56,
      "step": 2370
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.7579320669174194,
      "learning_rate": 1.9093333333333336e-05,
      "loss": 0.6128,
      "step": 2380
    },
    {
      "epoch": 0.6828571428571428,
      "grad_norm": 0.16539320349693298,
      "learning_rate": 1.908952380952381e-05,
      "loss": 0.5817,
      "step": 2390
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 32.1530876159668,
      "learning_rate": 1.9085714285714287e-05,
      "loss": 0.3662,
      "step": 2400
    },
    {
      "epoch": 0.6885714285714286,
      "grad_norm": 23.051837921142578,
      "learning_rate": 1.9081904761904762e-05,
      "loss": 0.3985,
      "step": 2410
    },
    {
      "epoch": 0.6914285714285714,
      "grad_norm": 0.21732768416404724,
      "learning_rate": 1.907809523809524e-05,
      "loss": 0.177,
      "step": 2420
    },
    {
      "epoch": 0.6942857142857143,
      "grad_norm": 0.2587050795555115,
      "learning_rate": 1.9074285714285717e-05,
      "loss": 0.6082,
      "step": 2430
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 1.4919304847717285,
      "learning_rate": 1.9070476190476193e-05,
      "loss": 0.8104,
      "step": 2440
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.0985347032546997,
      "learning_rate": 1.9066666666666668e-05,
      "loss": 0.2251,
      "step": 2450
    },
    {
      "epoch": 0.7028571428571428,
      "grad_norm": 0.059508565813302994,
      "learning_rate": 1.9062857142857144e-05,
      "loss": 0.5395,
      "step": 2460
    },
    {
      "epoch": 0.7057142857142857,
      "grad_norm": 0.08016586303710938,
      "learning_rate": 1.9059047619047623e-05,
      "loss": 0.3332,
      "step": 2470
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 27.54119873046875,
      "learning_rate": 1.90552380952381e-05,
      "loss": 0.2999,
      "step": 2480
    },
    {
      "epoch": 0.7114285714285714,
      "grad_norm": 21.48889923095703,
      "learning_rate": 1.9051428571428574e-05,
      "loss": 0.3807,
      "step": 2490
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.18021930754184723,
      "learning_rate": 1.904761904761905e-05,
      "loss": 0.0996,
      "step": 2500
    },
    {
      "epoch": 0.7171428571428572,
      "grad_norm": 46.085445404052734,
      "learning_rate": 1.9043809523809525e-05,
      "loss": 0.2816,
      "step": 2510
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.22392384707927704,
      "learning_rate": 1.904e-05,
      "loss": 0.3987,
      "step": 2520
    },
    {
      "epoch": 0.7228571428571429,
      "grad_norm": 0.10794401913881302,
      "learning_rate": 1.9036190476190476e-05,
      "loss": 0.3847,
      "step": 2530
    },
    {
      "epoch": 0.7257142857142858,
      "grad_norm": 10.788534164428711,
      "learning_rate": 1.9032380952380952e-05,
      "loss": 0.7201,
      "step": 2540
    },
    {
      "epoch": 0.7285714285714285,
      "grad_norm": 4.7450079917907715,
      "learning_rate": 1.902857142857143e-05,
      "loss": 0.2217,
      "step": 2550
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 0.12548795342445374,
      "learning_rate": 1.9024761904761906e-05,
      "loss": 0.1749,
      "step": 2560
    },
    {
      "epoch": 0.7342857142857143,
      "grad_norm": 0.08205851912498474,
      "learning_rate": 1.9020952380952382e-05,
      "loss": 0.445,
      "step": 2570
    },
    {
      "epoch": 0.7371428571428571,
      "grad_norm": 5.087615013122559,
      "learning_rate": 1.9017142857142858e-05,
      "loss": 0.2521,
      "step": 2580
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.34927237033843994,
      "learning_rate": 1.9013333333333333e-05,
      "loss": 0.2831,
      "step": 2590
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.1146945208311081,
      "learning_rate": 1.9009523809523812e-05,
      "loss": 0.2411,
      "step": 2600
    },
    {
      "epoch": 0.7457142857142857,
      "grad_norm": 0.034705471247434616,
      "learning_rate": 1.9005714285714288e-05,
      "loss": 0.2613,
      "step": 2610
    },
    {
      "epoch": 0.7485714285714286,
      "grad_norm": 27.283023834228516,
      "learning_rate": 1.9001904761904763e-05,
      "loss": 0.7244,
      "step": 2620
    },
    {
      "epoch": 0.7514285714285714,
      "grad_norm": 25.736507415771484,
      "learning_rate": 1.899809523809524e-05,
      "loss": 0.2225,
      "step": 2630
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 0.26146525144577026,
      "learning_rate": 1.8994285714285718e-05,
      "loss": 0.1763,
      "step": 2640
    },
    {
      "epoch": 0.7571428571428571,
      "grad_norm": 0.04212594032287598,
      "learning_rate": 1.8990476190476193e-05,
      "loss": 0.3062,
      "step": 2650
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.0127389430999756,
      "learning_rate": 1.898666666666667e-05,
      "loss": 0.0086,
      "step": 2660
    },
    {
      "epoch": 0.7628571428571429,
      "grad_norm": 29.238893508911133,
      "learning_rate": 1.8982857142857145e-05,
      "loss": 0.5543,
      "step": 2670
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 0.1477646827697754,
      "learning_rate": 1.897904761904762e-05,
      "loss": 0.5476,
      "step": 2680
    },
    {
      "epoch": 0.7685714285714286,
      "grad_norm": 0.16588008403778076,
      "learning_rate": 1.89752380952381e-05,
      "loss": 0.0025,
      "step": 2690
    },
    {
      "epoch": 0.7714285714285715,
      "grad_norm": 0.07661057263612747,
      "learning_rate": 1.8971428571428575e-05,
      "loss": 0.2361,
      "step": 2700
    },
    {
      "epoch": 0.7742857142857142,
      "grad_norm": 0.09689254313707352,
      "learning_rate": 1.896761904761905e-05,
      "loss": 0.4351,
      "step": 2710
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 62.650020599365234,
      "learning_rate": 1.8963809523809526e-05,
      "loss": 0.5002,
      "step": 2720
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.16264374554157257,
      "learning_rate": 1.896e-05,
      "loss": 0.1641,
      "step": 2730
    },
    {
      "epoch": 0.7828571428571428,
      "grad_norm": 25.989858627319336,
      "learning_rate": 1.8956190476190477e-05,
      "loss": 0.3724,
      "step": 2740
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 0.5236279964447021,
      "learning_rate": 1.8952380952380953e-05,
      "loss": 0.3543,
      "step": 2750
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 0.4128420054912567,
      "learning_rate": 1.8948571428571428e-05,
      "loss": 0.4359,
      "step": 2760
    },
    {
      "epoch": 0.7914285714285715,
      "grad_norm": 0.7340380549430847,
      "learning_rate": 1.8944761904761907e-05,
      "loss": 0.67,
      "step": 2770
    },
    {
      "epoch": 0.7942857142857143,
      "grad_norm": 0.7982595562934875,
      "learning_rate": 1.8940952380952383e-05,
      "loss": 0.278,
      "step": 2780
    },
    {
      "epoch": 0.7971428571428572,
      "grad_norm": 49.06161117553711,
      "learning_rate": 1.893714285714286e-05,
      "loss": 0.1805,
      "step": 2790
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.09400499612092972,
      "learning_rate": 1.8933333333333334e-05,
      "loss": 0.8523,
      "step": 2800
    },
    {
      "epoch": 0.8028571428571428,
      "grad_norm": 0.24280057847499847,
      "learning_rate": 1.892952380952381e-05,
      "loss": 0.3121,
      "step": 2810
    },
    {
      "epoch": 0.8057142857142857,
      "grad_norm": 0.2275335192680359,
      "learning_rate": 1.892571428571429e-05,
      "loss": 0.3222,
      "step": 2820
    },
    {
      "epoch": 0.8085714285714286,
      "grad_norm": 25.856882095336914,
      "learning_rate": 1.8921904761904764e-05,
      "loss": 0.4879,
      "step": 2830
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 0.05689466744661331,
      "learning_rate": 1.891809523809524e-05,
      "loss": 0.2927,
      "step": 2840
    },
    {
      "epoch": 0.8142857142857143,
      "grad_norm": 0.039317384362220764,
      "learning_rate": 1.8914285714285715e-05,
      "loss": 0.4444,
      "step": 2850
    },
    {
      "epoch": 0.8171428571428572,
      "grad_norm": 0.08166545629501343,
      "learning_rate": 1.891047619047619e-05,
      "loss": 0.5449,
      "step": 2860
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.05754232406616211,
      "learning_rate": 1.890666666666667e-05,
      "loss": 0.1456,
      "step": 2870
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 0.412675678730011,
      "learning_rate": 1.8902857142857145e-05,
      "loss": 0.397,
      "step": 2880
    },
    {
      "epoch": 0.8257142857142857,
      "grad_norm": 30.74620246887207,
      "learning_rate": 1.889904761904762e-05,
      "loss": 0.5234,
      "step": 2890
    },
    {
      "epoch": 0.8285714285714286,
      "grad_norm": 0.7725306153297424,
      "learning_rate": 1.8895238095238096e-05,
      "loss": 0.2253,
      "step": 2900
    },
    {
      "epoch": 0.8314285714285714,
      "grad_norm": 0.07589877396821976,
      "learning_rate": 1.8891428571428575e-05,
      "loss": 0.2663,
      "step": 2910
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 0.03706730902194977,
      "learning_rate": 1.888761904761905e-05,
      "loss": 0.4867,
      "step": 2920
    },
    {
      "epoch": 0.8371428571428572,
      "grad_norm": 0.04405926167964935,
      "learning_rate": 1.8883809523809523e-05,
      "loss": 0.5505,
      "step": 2930
    },
    {
      "epoch": 0.84,
      "grad_norm": 22.533164978027344,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.4703,
      "step": 2940
    },
    {
      "epoch": 0.8428571428571429,
      "grad_norm": 21.881412506103516,
      "learning_rate": 1.8876190476190478e-05,
      "loss": 0.4275,
      "step": 2950
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 0.25717368721961975,
      "learning_rate": 1.8872380952380953e-05,
      "loss": 0.2576,
      "step": 2960
    },
    {
      "epoch": 0.8485714285714285,
      "grad_norm": 0.0856236144900322,
      "learning_rate": 1.886857142857143e-05,
      "loss": 0.2855,
      "step": 2970
    },
    {
      "epoch": 0.8514285714285714,
      "grad_norm": 0.0866013690829277,
      "learning_rate": 1.8864761904761905e-05,
      "loss": 0.2818,
      "step": 2980
    },
    {
      "epoch": 0.8542857142857143,
      "grad_norm": 0.04947061464190483,
      "learning_rate": 1.8860952380952383e-05,
      "loss": 0.2181,
      "step": 2990
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 19.309673309326172,
      "learning_rate": 1.885714285714286e-05,
      "loss": 0.7442,
      "step": 3000
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.10166025161743164,
      "learning_rate": 1.8853333333333335e-05,
      "loss": 0.3043,
      "step": 3010
    },
    {
      "epoch": 0.8628571428571429,
      "grad_norm": 0.024457624182105064,
      "learning_rate": 1.884952380952381e-05,
      "loss": 0.1206,
      "step": 3020
    },
    {
      "epoch": 0.8657142857142858,
      "grad_norm": 0.6049577593803406,
      "learning_rate": 1.8845714285714286e-05,
      "loss": 0.3379,
      "step": 3030
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 29.368661880493164,
      "learning_rate": 1.8841904761904765e-05,
      "loss": 0.2615,
      "step": 3040
    },
    {
      "epoch": 0.8714285714285714,
      "grad_norm": 7.577649116516113,
      "learning_rate": 1.883809523809524e-05,
      "loss": 0.4356,
      "step": 3050
    },
    {
      "epoch": 0.8742857142857143,
      "grad_norm": 0.03531026095151901,
      "learning_rate": 1.8834285714285716e-05,
      "loss": 0.2778,
      "step": 3060
    },
    {
      "epoch": 0.8771428571428571,
      "grad_norm": 0.005464555695652962,
      "learning_rate": 1.883047619047619e-05,
      "loss": 0.5322,
      "step": 3070
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.054119501262903214,
      "learning_rate": 1.8826666666666667e-05,
      "loss": 0.435,
      "step": 3080
    },
    {
      "epoch": 0.8828571428571429,
      "grad_norm": 0.1169266551733017,
      "learning_rate": 1.8822857142857146e-05,
      "loss": 0.2894,
      "step": 3090
    },
    {
      "epoch": 0.8857142857142857,
      "grad_norm": 0.11789794266223907,
      "learning_rate": 1.881904761904762e-05,
      "loss": 0.2484,
      "step": 3100
    },
    {
      "epoch": 0.8885714285714286,
      "grad_norm": 0.13448213040828705,
      "learning_rate": 1.8815238095238097e-05,
      "loss": 0.5519,
      "step": 3110
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 21.484416961669922,
      "learning_rate": 1.8811428571428573e-05,
      "loss": 0.5443,
      "step": 3120
    },
    {
      "epoch": 0.8942857142857142,
      "grad_norm": 0.26539304852485657,
      "learning_rate": 1.8807619047619052e-05,
      "loss": 0.3142,
      "step": 3130
    },
    {
      "epoch": 0.8971428571428571,
      "grad_norm": 0.06387007236480713,
      "learning_rate": 1.8803809523809527e-05,
      "loss": 0.1903,
      "step": 3140
    },
    {
      "epoch": 0.9,
      "grad_norm": 24.66286277770996,
      "learning_rate": 1.88e-05,
      "loss": 0.553,
      "step": 3150
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 0.4481446444988251,
      "learning_rate": 1.8796190476190475e-05,
      "loss": 0.4676,
      "step": 3160
    },
    {
      "epoch": 0.9057142857142857,
      "grad_norm": 0.5218940377235413,
      "learning_rate": 1.8792380952380954e-05,
      "loss": 0.5579,
      "step": 3170
    },
    {
      "epoch": 0.9085714285714286,
      "grad_norm": 0.4091651141643524,
      "learning_rate": 1.878857142857143e-05,
      "loss": 0.1891,
      "step": 3180
    },
    {
      "epoch": 0.9114285714285715,
      "grad_norm": 0.036135781556367874,
      "learning_rate": 1.8784761904761905e-05,
      "loss": 0.172,
      "step": 3190
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 29.072139739990234,
      "learning_rate": 1.878095238095238e-05,
      "loss": 0.222,
      "step": 3200
    },
    {
      "epoch": 0.9171428571428571,
      "grad_norm": 0.04041809216141701,
      "learning_rate": 1.877714285714286e-05,
      "loss": 0.7396,
      "step": 3210
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.084009550511837,
      "learning_rate": 1.8773333333333335e-05,
      "loss": 0.4456,
      "step": 3220
    },
    {
      "epoch": 0.9228571428571428,
      "grad_norm": 0.0654289647936821,
      "learning_rate": 1.876952380952381e-05,
      "loss": 0.0018,
      "step": 3230
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 0.0900077223777771,
      "learning_rate": 1.8765714285714287e-05,
      "loss": 0.3703,
      "step": 3240
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 0.19006898999214172,
      "learning_rate": 1.8761904761904762e-05,
      "loss": 0.3987,
      "step": 3250
    },
    {
      "epoch": 0.9314285714285714,
      "grad_norm": 0.2284264713525772,
      "learning_rate": 1.875809523809524e-05,
      "loss": 0.3977,
      "step": 3260
    },
    {
      "epoch": 0.9342857142857143,
      "grad_norm": 15.426933288574219,
      "learning_rate": 1.8754285714285717e-05,
      "loss": 0.3167,
      "step": 3270
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 45.40625,
      "learning_rate": 1.8750476190476192e-05,
      "loss": 0.2657,
      "step": 3280
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2398415058851242,
      "learning_rate": 1.8746666666666668e-05,
      "loss": 0.5936,
      "step": 3290
    },
    {
      "epoch": 0.9428571428571428,
      "grad_norm": 23.263275146484375,
      "learning_rate": 1.8742857142857143e-05,
      "loss": 0.3007,
      "step": 3300
    },
    {
      "epoch": 0.9457142857142857,
      "grad_norm": 0.03832622617483139,
      "learning_rate": 1.8739047619047622e-05,
      "loss": 0.3304,
      "step": 3310
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 0.07669048756361008,
      "learning_rate": 1.8735238095238098e-05,
      "loss": 0.2089,
      "step": 3320
    },
    {
      "epoch": 0.9514285714285714,
      "grad_norm": 0.029419763013720512,
      "learning_rate": 1.8731428571428574e-05,
      "loss": 0.5032,
      "step": 3330
    },
    {
      "epoch": 0.9542857142857143,
      "grad_norm": 23.082002639770508,
      "learning_rate": 1.872761904761905e-05,
      "loss": 1.1553,
      "step": 3340
    },
    {
      "epoch": 0.9571428571428572,
      "grad_norm": 4.1136956214904785,
      "learning_rate": 1.8723809523809525e-05,
      "loss": 0.2592,
      "step": 3350
    },
    {
      "epoch": 0.96,
      "grad_norm": 19.474390029907227,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.3472,
      "step": 3360
    },
    {
      "epoch": 0.9628571428571429,
      "grad_norm": 0.7994656562805176,
      "learning_rate": 1.8716190476190476e-05,
      "loss": 0.1114,
      "step": 3370
    },
    {
      "epoch": 0.9657142857142857,
      "grad_norm": 0.051028478890657425,
      "learning_rate": 1.871238095238095e-05,
      "loss": 0.5583,
      "step": 3380
    },
    {
      "epoch": 0.9685714285714285,
      "grad_norm": 0.08989201486110687,
      "learning_rate": 1.870857142857143e-05,
      "loss": 0.5034,
      "step": 3390
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.13544583320617676,
      "learning_rate": 1.8704761904761906e-05,
      "loss": 0.4373,
      "step": 3400
    },
    {
      "epoch": 0.9742857142857143,
      "grad_norm": 0.1810600757598877,
      "learning_rate": 1.870095238095238e-05,
      "loss": 0.2142,
      "step": 3410
    },
    {
      "epoch": 0.9771428571428571,
      "grad_norm": 8.278867721557617,
      "learning_rate": 1.8697142857142857e-05,
      "loss": 0.1588,
      "step": 3420
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.1580524891614914,
      "learning_rate": 1.8693333333333333e-05,
      "loss": 0.5214,
      "step": 3430
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 43.69389343261719,
      "learning_rate": 1.8689523809523812e-05,
      "loss": 0.8273,
      "step": 3440
    },
    {
      "epoch": 0.9857142857142858,
      "grad_norm": 0.6930151581764221,
      "learning_rate": 1.8685714285714287e-05,
      "loss": 0.0398,
      "step": 3450
    },
    {
      "epoch": 0.9885714285714285,
      "grad_norm": 0.06322737038135529,
      "learning_rate": 1.8681904761904763e-05,
      "loss": 0.1538,
      "step": 3460
    },
    {
      "epoch": 0.9914285714285714,
      "grad_norm": 1.816310167312622,
      "learning_rate": 1.867809523809524e-05,
      "loss": 0.2707,
      "step": 3470
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 0.0836680606007576,
      "learning_rate": 1.8674285714285717e-05,
      "loss": 0.0563,
      "step": 3480
    },
    {
      "epoch": 0.9971428571428571,
      "grad_norm": 0.042846981436014175,
      "learning_rate": 1.8670476190476193e-05,
      "loss": 0.5505,
      "step": 3490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.09261211007833481,
      "learning_rate": 1.866666666666667e-05,
      "loss": 0.751,
      "step": 3500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9273333333333333,
      "eval_f1": 0.5992647058823528,
      "eval_loss": 0.3418782651424408,
      "eval_precision": 0.7688679245283019,
      "eval_recall": 0.49096385542168675,
      "eval_runtime": 259.0104,
      "eval_samples_per_second": 11.583,
      "eval_steps_per_second": 2.896,
      "step": 3500
    },
    {
      "epoch": 1.002857142857143,
      "grad_norm": 32.083587646484375,
      "learning_rate": 1.8662857142857144e-05,
      "loss": 0.2048,
      "step": 3510
    },
    {
      "epoch": 1.0057142857142858,
      "grad_norm": 20.737079620361328,
      "learning_rate": 1.865904761904762e-05,
      "loss": 0.3392,
      "step": 3520
    },
    {
      "epoch": 1.0085714285714287,
      "grad_norm": 0.3823759853839874,
      "learning_rate": 1.86552380952381e-05,
      "loss": 0.2967,
      "step": 3530
    },
    {
      "epoch": 1.0114285714285713,
      "grad_norm": 36.97966003417969,
      "learning_rate": 1.8651428571428574e-05,
      "loss": 0.2411,
      "step": 3540
    },
    {
      "epoch": 1.0142857142857142,
      "grad_norm": 34.51325225830078,
      "learning_rate": 1.864761904761905e-05,
      "loss": 0.4528,
      "step": 3550
    },
    {
      "epoch": 1.0171428571428571,
      "grad_norm": 0.016796555370092392,
      "learning_rate": 1.8643809523809526e-05,
      "loss": 0.0043,
      "step": 3560
    },
    {
      "epoch": 1.02,
      "grad_norm": 45.8231315612793,
      "learning_rate": 1.864e-05,
      "loss": 0.2287,
      "step": 3570
    },
    {
      "epoch": 1.022857142857143,
      "grad_norm": 1.0899008512496948,
      "learning_rate": 1.8636190476190477e-05,
      "loss": 0.5853,
      "step": 3580
    },
    {
      "epoch": 1.0257142857142858,
      "grad_norm": 19.44029998779297,
      "learning_rate": 1.8632380952380952e-05,
      "loss": 0.6995,
      "step": 3590
    },
    {
      "epoch": 1.0285714285714285,
      "grad_norm": 0.9254756569862366,
      "learning_rate": 1.8628571428571428e-05,
      "loss": 0.2744,
      "step": 3600
    },
    {
      "epoch": 1.0314285714285714,
      "grad_norm": 0.068888820707798,
      "learning_rate": 1.8624761904761907e-05,
      "loss": 0.1404,
      "step": 3610
    },
    {
      "epoch": 1.0342857142857143,
      "grad_norm": 0.04156975820660591,
      "learning_rate": 1.8620952380952382e-05,
      "loss": 0.1904,
      "step": 3620
    },
    {
      "epoch": 1.0371428571428571,
      "grad_norm": 1.2779661417007446,
      "learning_rate": 1.8617142857142858e-05,
      "loss": 0.517,
      "step": 3630
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.23442143201828003,
      "learning_rate": 1.8613333333333334e-05,
      "loss": 0.264,
      "step": 3640
    },
    {
      "epoch": 1.042857142857143,
      "grad_norm": 0.27958133816719055,
      "learning_rate": 1.860952380952381e-05,
      "loss": 0.6865,
      "step": 3650
    },
    {
      "epoch": 1.0457142857142858,
      "grad_norm": 9.849526405334473,
      "learning_rate": 1.8605714285714288e-05,
      "loss": 0.1786,
      "step": 3660
    },
    {
      "epoch": 1.0485714285714285,
      "grad_norm": 25.073637008666992,
      "learning_rate": 1.8601904761904764e-05,
      "loss": 0.9131,
      "step": 3670
    },
    {
      "epoch": 1.0514285714285714,
      "grad_norm": 1.4544639587402344,
      "learning_rate": 1.859809523809524e-05,
      "loss": 0.1733,
      "step": 3680
    },
    {
      "epoch": 1.0542857142857143,
      "grad_norm": 0.3343904912471771,
      "learning_rate": 1.8594285714285715e-05,
      "loss": 0.2051,
      "step": 3690
    },
    {
      "epoch": 1.0571428571428572,
      "grad_norm": 22.787139892578125,
      "learning_rate": 1.859047619047619e-05,
      "loss": 0.5495,
      "step": 3700
    },
    {
      "epoch": 1.06,
      "grad_norm": 45.32278060913086,
      "learning_rate": 1.858666666666667e-05,
      "loss": 0.2473,
      "step": 3710
    },
    {
      "epoch": 1.062857142857143,
      "grad_norm": 2.945871591567993,
      "learning_rate": 1.8582857142857145e-05,
      "loss": 0.366,
      "step": 3720
    },
    {
      "epoch": 1.0657142857142856,
      "grad_norm": 6.6624040603637695,
      "learning_rate": 1.857904761904762e-05,
      "loss": 0.278,
      "step": 3730
    },
    {
      "epoch": 1.0685714285714285,
      "grad_norm": 25.552579879760742,
      "learning_rate": 1.8575238095238096e-05,
      "loss": 0.9941,
      "step": 3740
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.9163156747817993,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 0.1145,
      "step": 3750
    },
    {
      "epoch": 1.0742857142857143,
      "grad_norm": 19.864429473876953,
      "learning_rate": 1.856761904761905e-05,
      "loss": 0.161,
      "step": 3760
    },
    {
      "epoch": 1.0771428571428572,
      "grad_norm": 0.2050407975912094,
      "learning_rate": 1.8563809523809526e-05,
      "loss": 0.1641,
      "step": 3770
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.08627714961767197,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.306,
      "step": 3780
    },
    {
      "epoch": 1.0828571428571427,
      "grad_norm": 29.183618545532227,
      "learning_rate": 1.8556190476190477e-05,
      "loss": 0.8962,
      "step": 3790
    },
    {
      "epoch": 1.0857142857142856,
      "grad_norm": 0.357610285282135,
      "learning_rate": 1.8552380952380953e-05,
      "loss": 0.3426,
      "step": 3800
    },
    {
      "epoch": 1.0885714285714285,
      "grad_norm": 0.33921870589256287,
      "learning_rate": 1.854857142857143e-05,
      "loss": 0.3702,
      "step": 3810
    },
    {
      "epoch": 1.0914285714285714,
      "grad_norm": 0.14386333525180817,
      "learning_rate": 1.8544761904761904e-05,
      "loss": 0.4895,
      "step": 3820
    },
    {
      "epoch": 1.0942857142857143,
      "grad_norm": 0.5447583794593811,
      "learning_rate": 1.8540952380952383e-05,
      "loss": 0.4503,
      "step": 3830
    },
    {
      "epoch": 1.0971428571428572,
      "grad_norm": 0.24755392968654633,
      "learning_rate": 1.853714285714286e-05,
      "loss": 0.4342,
      "step": 3840
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.19051982462406158,
      "learning_rate": 1.8533333333333334e-05,
      "loss": 0.0148,
      "step": 3850
    },
    {
      "epoch": 1.1028571428571428,
      "grad_norm": 10.160234451293945,
      "learning_rate": 1.852952380952381e-05,
      "loss": 0.5446,
      "step": 3860
    },
    {
      "epoch": 1.1057142857142856,
      "grad_norm": 18.612255096435547,
      "learning_rate": 1.8525714285714285e-05,
      "loss": 0.8357,
      "step": 3870
    },
    {
      "epoch": 1.1085714285714285,
      "grad_norm": 26.523975372314453,
      "learning_rate": 1.8521904761904764e-05,
      "loss": 0.2524,
      "step": 3880
    },
    {
      "epoch": 1.1114285714285714,
      "grad_norm": 0.35894960165023804,
      "learning_rate": 1.851809523809524e-05,
      "loss": 0.1898,
      "step": 3890
    },
    {
      "epoch": 1.1142857142857143,
      "grad_norm": 0.156733438372612,
      "learning_rate": 1.8514285714285716e-05,
      "loss": 0.3535,
      "step": 3900
    },
    {
      "epoch": 1.1171428571428572,
      "grad_norm": 0.14110343158245087,
      "learning_rate": 1.851047619047619e-05,
      "loss": 0.1968,
      "step": 3910
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.6293803453445435,
      "learning_rate": 1.8506666666666667e-05,
      "loss": 0.141,
      "step": 3920
    },
    {
      "epoch": 1.1228571428571428,
      "grad_norm": 18.914724349975586,
      "learning_rate": 1.8502857142857146e-05,
      "loss": 0.3678,
      "step": 3930
    },
    {
      "epoch": 1.1257142857142857,
      "grad_norm": 42.22867202758789,
      "learning_rate": 1.849904761904762e-05,
      "loss": 0.4057,
      "step": 3940
    },
    {
      "epoch": 1.1285714285714286,
      "grad_norm": 0.08720497786998749,
      "learning_rate": 1.8495238095238097e-05,
      "loss": 0.3433,
      "step": 3950
    },
    {
      "epoch": 1.1314285714285715,
      "grad_norm": 89.74164581298828,
      "learning_rate": 1.8491428571428573e-05,
      "loss": 0.5607,
      "step": 3960
    },
    {
      "epoch": 1.1342857142857143,
      "grad_norm": 0.062025364488363266,
      "learning_rate": 1.848761904761905e-05,
      "loss": 0.1045,
      "step": 3970
    },
    {
      "epoch": 1.1371428571428572,
      "grad_norm": 29.774362564086914,
      "learning_rate": 1.8483809523809527e-05,
      "loss": 0.5079,
      "step": 3980
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 20.83995819091797,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.3702,
      "step": 3990
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.060095593333244324,
      "learning_rate": 1.8476190476190478e-05,
      "loss": 0.2518,
      "step": 4000
    },
    {
      "epoch": 1.1457142857142857,
      "grad_norm": 0.09101489186286926,
      "learning_rate": 1.8472380952380954e-05,
      "loss": 0.5595,
      "step": 4010
    },
    {
      "epoch": 1.1485714285714286,
      "grad_norm": 0.20152784883975983,
      "learning_rate": 1.846857142857143e-05,
      "loss": 0.1138,
      "step": 4020
    },
    {
      "epoch": 1.1514285714285715,
      "grad_norm": 0.1261056363582611,
      "learning_rate": 1.8464761904761905e-05,
      "loss": 0.228,
      "step": 4030
    },
    {
      "epoch": 1.1542857142857144,
      "grad_norm": 0.4805780351161957,
      "learning_rate": 1.846095238095238e-05,
      "loss": 0.1238,
      "step": 4040
    },
    {
      "epoch": 1.157142857142857,
      "grad_norm": 0.2031574547290802,
      "learning_rate": 1.845714285714286e-05,
      "loss": 0.0033,
      "step": 4050
    },
    {
      "epoch": 1.16,
      "grad_norm": 34.569427490234375,
      "learning_rate": 1.8453333333333335e-05,
      "loss": 0.5924,
      "step": 4060
    },
    {
      "epoch": 1.1628571428571428,
      "grad_norm": 0.11313742399215698,
      "learning_rate": 1.844952380952381e-05,
      "loss": 0.23,
      "step": 4070
    },
    {
      "epoch": 1.1657142857142857,
      "grad_norm": 0.07489243894815445,
      "learning_rate": 1.8445714285714286e-05,
      "loss": 0.0966,
      "step": 4080
    },
    {
      "epoch": 1.1685714285714286,
      "grad_norm": 0.04827113449573517,
      "learning_rate": 1.8441904761904762e-05,
      "loss": 0.0949,
      "step": 4090
    },
    {
      "epoch": 1.1714285714285715,
      "grad_norm": 1.1087791919708252,
      "learning_rate": 1.843809523809524e-05,
      "loss": 0.4144,
      "step": 4100
    },
    {
      "epoch": 1.1742857142857144,
      "grad_norm": 0.014655825681984425,
      "learning_rate": 1.8434285714285716e-05,
      "loss": 0.0037,
      "step": 4110
    },
    {
      "epoch": 1.177142857142857,
      "grad_norm": 21.77234649658203,
      "learning_rate": 1.8430476190476192e-05,
      "loss": 0.6259,
      "step": 4120
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.102874517440796,
      "learning_rate": 1.8426666666666668e-05,
      "loss": 0.4649,
      "step": 4130
    },
    {
      "epoch": 1.1828571428571428,
      "grad_norm": 15.70600414276123,
      "learning_rate": 1.8422857142857143e-05,
      "loss": 0.3691,
      "step": 4140
    },
    {
      "epoch": 1.1857142857142857,
      "grad_norm": 0.1309225857257843,
      "learning_rate": 1.8419047619047622e-05,
      "loss": 0.2719,
      "step": 4150
    },
    {
      "epoch": 1.1885714285714286,
      "grad_norm": 22.074748992919922,
      "learning_rate": 1.8415238095238098e-05,
      "loss": 0.2041,
      "step": 4160
    },
    {
      "epoch": 1.1914285714285715,
      "grad_norm": 0.31763800978660583,
      "learning_rate": 1.8411428571428573e-05,
      "loss": 0.3051,
      "step": 4170
    },
    {
      "epoch": 1.1942857142857144,
      "grad_norm": 0.06838932633399963,
      "learning_rate": 1.840761904761905e-05,
      "loss": 0.167,
      "step": 4180
    },
    {
      "epoch": 1.197142857142857,
      "grad_norm": 0.605617344379425,
      "learning_rate": 1.8403809523809524e-05,
      "loss": 0.0972,
      "step": 4190
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.23460091650485992,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.4723,
      "step": 4200
    },
    {
      "epoch": 1.2028571428571428,
      "grad_norm": 30.713232040405273,
      "learning_rate": 1.839619047619048e-05,
      "loss": 0.1836,
      "step": 4210
    },
    {
      "epoch": 1.2057142857142857,
      "grad_norm": 1.7257007360458374,
      "learning_rate": 1.8392380952380955e-05,
      "loss": 0.2072,
      "step": 4220
    },
    {
      "epoch": 1.2085714285714286,
      "grad_norm": 0.1777569204568863,
      "learning_rate": 1.838857142857143e-05,
      "loss": 0.5278,
      "step": 4230
    },
    {
      "epoch": 1.2114285714285715,
      "grad_norm": 0.26214584708213806,
      "learning_rate": 1.8384761904761906e-05,
      "loss": 0.4036,
      "step": 4240
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 0.5137707591056824,
      "learning_rate": 1.838095238095238e-05,
      "loss": 0.4574,
      "step": 4250
    },
    {
      "epoch": 1.217142857142857,
      "grad_norm": 0.042492859065532684,
      "learning_rate": 1.8377142857142857e-05,
      "loss": 0.163,
      "step": 4260
    },
    {
      "epoch": 1.22,
      "grad_norm": 43.652366638183594,
      "learning_rate": 1.8373333333333332e-05,
      "loss": 0.0932,
      "step": 4270
    },
    {
      "epoch": 1.2228571428571429,
      "grad_norm": 0.37995025515556335,
      "learning_rate": 1.836952380952381e-05,
      "loss": 0.1245,
      "step": 4280
    },
    {
      "epoch": 1.2257142857142858,
      "grad_norm": 0.02146918885409832,
      "learning_rate": 1.8365714285714287e-05,
      "loss": 0.4553,
      "step": 4290
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 58.578006744384766,
      "learning_rate": 1.8361904761904763e-05,
      "loss": 0.3991,
      "step": 4300
    },
    {
      "epoch": 1.2314285714285713,
      "grad_norm": 0.04819543659687042,
      "learning_rate": 1.8358095238095238e-05,
      "loss": 0.6782,
      "step": 4310
    },
    {
      "epoch": 1.2342857142857142,
      "grad_norm": 30.772193908691406,
      "learning_rate": 1.8354285714285717e-05,
      "loss": 0.2141,
      "step": 4320
    },
    {
      "epoch": 1.237142857142857,
      "grad_norm": 30.09088897705078,
      "learning_rate": 1.8350476190476193e-05,
      "loss": 0.6318,
      "step": 4330
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.6829252243041992,
      "learning_rate": 1.834666666666667e-05,
      "loss": 0.284,
      "step": 4340
    },
    {
      "epoch": 1.2428571428571429,
      "grad_norm": 0.05694005638360977,
      "learning_rate": 1.8342857142857144e-05,
      "loss": 0.2615,
      "step": 4350
    },
    {
      "epoch": 1.2457142857142858,
      "grad_norm": 20.716808319091797,
      "learning_rate": 1.833904761904762e-05,
      "loss": 0.5168,
      "step": 4360
    },
    {
      "epoch": 1.2485714285714287,
      "grad_norm": 17.5230770111084,
      "learning_rate": 1.83352380952381e-05,
      "loss": 0.3036,
      "step": 4370
    },
    {
      "epoch": 1.2514285714285713,
      "grad_norm": 31.06649398803711,
      "learning_rate": 1.8331428571428574e-05,
      "loss": 0.474,
      "step": 4380
    },
    {
      "epoch": 1.2542857142857142,
      "grad_norm": 2.0371155738830566,
      "learning_rate": 1.832761904761905e-05,
      "loss": 0.3378,
      "step": 4390
    },
    {
      "epoch": 1.2571428571428571,
      "grad_norm": 0.02915019541978836,
      "learning_rate": 1.8323809523809525e-05,
      "loss": 0.1915,
      "step": 4400
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.08680488169193268,
      "learning_rate": 1.832e-05,
      "loss": 0.2383,
      "step": 4410
    },
    {
      "epoch": 1.262857142857143,
      "grad_norm": 0.052012234926223755,
      "learning_rate": 1.831619047619048e-05,
      "loss": 0.194,
      "step": 4420
    },
    {
      "epoch": 1.2657142857142858,
      "grad_norm": 0.12893521785736084,
      "learning_rate": 1.8312380952380955e-05,
      "loss": 0.404,
      "step": 4430
    },
    {
      "epoch": 1.2685714285714287,
      "grad_norm": 0.036419741809368134,
      "learning_rate": 1.830857142857143e-05,
      "loss": 0.1836,
      "step": 4440
    },
    {
      "epoch": 1.2714285714285714,
      "grad_norm": 21.39727210998535,
      "learning_rate": 1.8304761904761906e-05,
      "loss": 0.5277,
      "step": 4450
    },
    {
      "epoch": 1.2742857142857142,
      "grad_norm": 0.515501081943512,
      "learning_rate": 1.8300952380952382e-05,
      "loss": 0.006,
      "step": 4460
    },
    {
      "epoch": 1.2771428571428571,
      "grad_norm": 0.10493829846382141,
      "learning_rate": 1.8297142857142858e-05,
      "loss": 0.3267,
      "step": 4470
    },
    {
      "epoch": 1.28,
      "grad_norm": 21.137834548950195,
      "learning_rate": 1.8293333333333333e-05,
      "loss": 0.413,
      "step": 4480
    },
    {
      "epoch": 1.282857142857143,
      "grad_norm": 0.26434198021888733,
      "learning_rate": 1.828952380952381e-05,
      "loss": 0.3934,
      "step": 4490
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 15.793427467346191,
      "learning_rate": 1.8285714285714288e-05,
      "loss": 0.5294,
      "step": 4500
    },
    {
      "epoch": 1.2885714285714287,
      "grad_norm": 0.09752381592988968,
      "learning_rate": 1.8281904761904763e-05,
      "loss": 0.1567,
      "step": 4510
    },
    {
      "epoch": 1.2914285714285714,
      "grad_norm": 28.90725326538086,
      "learning_rate": 1.827809523809524e-05,
      "loss": 0.4677,
      "step": 4520
    },
    {
      "epoch": 1.2942857142857143,
      "grad_norm": 0.4908227324485779,
      "learning_rate": 1.8274285714285715e-05,
      "loss": 0.1885,
      "step": 4530
    },
    {
      "epoch": 1.2971428571428572,
      "grad_norm": 0.6416726112365723,
      "learning_rate": 1.827047619047619e-05,
      "loss": 0.1422,
      "step": 4540
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.07281698286533356,
      "learning_rate": 1.826666666666667e-05,
      "loss": 0.1877,
      "step": 4550
    },
    {
      "epoch": 1.302857142857143,
      "grad_norm": 0.054917268455028534,
      "learning_rate": 1.8262857142857145e-05,
      "loss": 0.2275,
      "step": 4560
    },
    {
      "epoch": 1.3057142857142856,
      "grad_norm": 0.03733436390757561,
      "learning_rate": 1.825904761904762e-05,
      "loss": 0.0307,
      "step": 4570
    },
    {
      "epoch": 1.3085714285714285,
      "grad_norm": 0.01759161613881588,
      "learning_rate": 1.8255238095238096e-05,
      "loss": 0.0006,
      "step": 4580
    },
    {
      "epoch": 1.3114285714285714,
      "grad_norm": 19.734703063964844,
      "learning_rate": 1.8251428571428575e-05,
      "loss": 0.5279,
      "step": 4590
    },
    {
      "epoch": 1.3142857142857143,
      "grad_norm": 77.6090316772461,
      "learning_rate": 1.824761904761905e-05,
      "loss": 0.4132,
      "step": 4600
    },
    {
      "epoch": 1.3171428571428572,
      "grad_norm": 29.218040466308594,
      "learning_rate": 1.8243809523809526e-05,
      "loss": 0.742,
      "step": 4610
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.3214612007141113,
      "learning_rate": 1.824e-05,
      "loss": 0.4887,
      "step": 4620
    },
    {
      "epoch": 1.322857142857143,
      "grad_norm": 21.412927627563477,
      "learning_rate": 1.8236190476190477e-05,
      "loss": 0.3293,
      "step": 4630
    },
    {
      "epoch": 1.3257142857142856,
      "grad_norm": 1.0042985677719116,
      "learning_rate": 1.8232380952380956e-05,
      "loss": 0.1984,
      "step": 4640
    },
    {
      "epoch": 1.3285714285714285,
      "grad_norm": 24.733570098876953,
      "learning_rate": 1.822857142857143e-05,
      "loss": 0.1987,
      "step": 4650
    },
    {
      "epoch": 1.3314285714285714,
      "grad_norm": 0.022460224106907845,
      "learning_rate": 1.8224761904761907e-05,
      "loss": 0.1272,
      "step": 4660
    },
    {
      "epoch": 1.3342857142857143,
      "grad_norm": 0.04336734861135483,
      "learning_rate": 1.8220952380952383e-05,
      "loss": 0.4223,
      "step": 4670
    },
    {
      "epoch": 1.3371428571428572,
      "grad_norm": 17.83588409423828,
      "learning_rate": 1.821714285714286e-05,
      "loss": 0.5036,
      "step": 4680
    },
    {
      "epoch": 1.34,
      "grad_norm": 20.19054412841797,
      "learning_rate": 1.8213333333333334e-05,
      "loss": 0.2016,
      "step": 4690
    },
    {
      "epoch": 1.342857142857143,
      "grad_norm": 0.3701933026313782,
      "learning_rate": 1.820952380952381e-05,
      "loss": 0.4821,
      "step": 4700
    },
    {
      "epoch": 1.3457142857142856,
      "grad_norm": 25.51021385192871,
      "learning_rate": 1.8205714285714285e-05,
      "loss": 0.3226,
      "step": 4710
    },
    {
      "epoch": 1.3485714285714285,
      "grad_norm": 0.31696617603302,
      "learning_rate": 1.8201904761904764e-05,
      "loss": 0.1857,
      "step": 4720
    },
    {
      "epoch": 1.3514285714285714,
      "grad_norm": 24.83074378967285,
      "learning_rate": 1.819809523809524e-05,
      "loss": 0.4419,
      "step": 4730
    },
    {
      "epoch": 1.3542857142857143,
      "grad_norm": 0.03105928935110569,
      "learning_rate": 1.8194285714285715e-05,
      "loss": 0.2729,
      "step": 4740
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 0.8301174640655518,
      "learning_rate": 1.819047619047619e-05,
      "loss": 0.2199,
      "step": 4750
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 11.667036056518555,
      "learning_rate": 1.8186666666666666e-05,
      "loss": 0.005,
      "step": 4760
    },
    {
      "epoch": 1.362857142857143,
      "grad_norm": 0.03486696258187294,
      "learning_rate": 1.8182857142857145e-05,
      "loss": 0.2459,
      "step": 4770
    },
    {
      "epoch": 1.3657142857142857,
      "grad_norm": 0.028826404362916946,
      "learning_rate": 1.817904761904762e-05,
      "loss": 0.0804,
      "step": 4780
    },
    {
      "epoch": 1.3685714285714285,
      "grad_norm": 0.03126780316233635,
      "learning_rate": 1.8175238095238097e-05,
      "loss": 0.0072,
      "step": 4790
    },
    {
      "epoch": 1.3714285714285714,
      "grad_norm": 7.7401323318481445,
      "learning_rate": 1.8171428571428572e-05,
      "loss": 0.005,
      "step": 4800
    },
    {
      "epoch": 1.3742857142857143,
      "grad_norm": 164.1072540283203,
      "learning_rate": 1.816761904761905e-05,
      "loss": 0.6098,
      "step": 4810
    },
    {
      "epoch": 1.3771428571428572,
      "grad_norm": 0.028316235169768333,
      "learning_rate": 1.8163809523809527e-05,
      "loss": 0.0018,
      "step": 4820
    },
    {
      "epoch": 1.38,
      "grad_norm": 30.205812454223633,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.5191,
      "step": 4830
    },
    {
      "epoch": 1.3828571428571428,
      "grad_norm": 0.0945187583565712,
      "learning_rate": 1.8156190476190478e-05,
      "loss": 0.5178,
      "step": 4840
    },
    {
      "epoch": 1.3857142857142857,
      "grad_norm": 61.76112747192383,
      "learning_rate": 1.8152380952380953e-05,
      "loss": 0.2932,
      "step": 4850
    },
    {
      "epoch": 1.3885714285714286,
      "grad_norm": 0.29523366689682007,
      "learning_rate": 1.8148571428571432e-05,
      "loss": 0.3919,
      "step": 4860
    },
    {
      "epoch": 1.3914285714285715,
      "grad_norm": 0.04019315913319588,
      "learning_rate": 1.8144761904761908e-05,
      "loss": 0.1272,
      "step": 4870
    },
    {
      "epoch": 1.3942857142857144,
      "grad_norm": 19.258529663085938,
      "learning_rate": 1.8140952380952384e-05,
      "loss": 0.3383,
      "step": 4880
    },
    {
      "epoch": 1.3971428571428572,
      "grad_norm": 0.053862765431404114,
      "learning_rate": 1.813714285714286e-05,
      "loss": 0.3048,
      "step": 4890
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.13809381425380707,
      "learning_rate": 1.8133333333333335e-05,
      "loss": 0.1474,
      "step": 4900
    },
    {
      "epoch": 1.4028571428571428,
      "grad_norm": 30.138608932495117,
      "learning_rate": 1.812952380952381e-05,
      "loss": 0.1547,
      "step": 4910
    },
    {
      "epoch": 1.4057142857142857,
      "grad_norm": 30.279909133911133,
      "learning_rate": 1.8125714285714286e-05,
      "loss": 0.2236,
      "step": 4920
    },
    {
      "epoch": 1.4085714285714286,
      "grad_norm": 0.3499349355697632,
      "learning_rate": 1.812190476190476e-05,
      "loss": 0.4799,
      "step": 4930
    },
    {
      "epoch": 1.4114285714285715,
      "grad_norm": 0.0377533845603466,
      "learning_rate": 1.811809523809524e-05,
      "loss": 0.2829,
      "step": 4940
    },
    {
      "epoch": 1.4142857142857144,
      "grad_norm": 0.022734254598617554,
      "learning_rate": 1.8114285714285716e-05,
      "loss": 0.4772,
      "step": 4950
    },
    {
      "epoch": 1.4171428571428573,
      "grad_norm": 19.296804428100586,
      "learning_rate": 1.811047619047619e-05,
      "loss": 0.2713,
      "step": 4960
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.12839429080486298,
      "learning_rate": 1.8106666666666667e-05,
      "loss": 0.0033,
      "step": 4970
    },
    {
      "epoch": 1.4228571428571428,
      "grad_norm": 0.22438552975654602,
      "learning_rate": 1.8102857142857143e-05,
      "loss": 0.0071,
      "step": 4980
    },
    {
      "epoch": 1.4257142857142857,
      "grad_norm": 5.3649725914001465,
      "learning_rate": 1.8099047619047622e-05,
      "loss": 0.006,
      "step": 4990
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.08097740262746811,
      "learning_rate": 1.8095238095238097e-05,
      "loss": 0.5772,
      "step": 5000
    },
    {
      "epoch": 1.4314285714285715,
      "grad_norm": 22.934268951416016,
      "learning_rate": 1.8091428571428573e-05,
      "loss": 0.3345,
      "step": 5010
    },
    {
      "epoch": 1.4342857142857142,
      "grad_norm": 0.4455523192882538,
      "learning_rate": 1.808761904761905e-05,
      "loss": 0.4494,
      "step": 5020
    },
    {
      "epoch": 1.4371428571428573,
      "grad_norm": 0.12711253762245178,
      "learning_rate": 1.8083809523809524e-05,
      "loss": 0.113,
      "step": 5030
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.06207140535116196,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.3588,
      "step": 5040
    },
    {
      "epoch": 1.4428571428571428,
      "grad_norm": 0.040162861347198486,
      "learning_rate": 1.807619047619048e-05,
      "loss": 0.3819,
      "step": 5050
    },
    {
      "epoch": 1.4457142857142857,
      "grad_norm": 58.89982986450195,
      "learning_rate": 1.8072380952380954e-05,
      "loss": 0.2993,
      "step": 5060
    },
    {
      "epoch": 1.4485714285714286,
      "grad_norm": 0.17101149260997772,
      "learning_rate": 1.806857142857143e-05,
      "loss": 0.0016,
      "step": 5070
    },
    {
      "epoch": 1.4514285714285715,
      "grad_norm": 22.195423126220703,
      "learning_rate": 1.806476190476191e-05,
      "loss": 0.4031,
      "step": 5080
    },
    {
      "epoch": 1.4542857142857142,
      "grad_norm": 0.02301787957549095,
      "learning_rate": 1.8060952380952384e-05,
      "loss": 0.2645,
      "step": 5090
    },
    {
      "epoch": 1.457142857142857,
      "grad_norm": 0.1601516604423523,
      "learning_rate": 1.8057142857142857e-05,
      "loss": 0.102,
      "step": 5100
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.2614265978336334,
      "learning_rate": 1.8053333333333332e-05,
      "loss": 0.1234,
      "step": 5110
    },
    {
      "epoch": 1.4628571428571429,
      "grad_norm": 0.016120007261633873,
      "learning_rate": 1.804952380952381e-05,
      "loss": 0.2669,
      "step": 5120
    },
    {
      "epoch": 1.4657142857142857,
      "grad_norm": 0.03191816806793213,
      "learning_rate": 1.8045714285714287e-05,
      "loss": 0.193,
      "step": 5130
    },
    {
      "epoch": 1.4685714285714286,
      "grad_norm": 25.8150634765625,
      "learning_rate": 1.8041904761904762e-05,
      "loss": 0.5241,
      "step": 5140
    },
    {
      "epoch": 1.4714285714285715,
      "grad_norm": 0.0732002928853035,
      "learning_rate": 1.8038095238095238e-05,
      "loss": 0.0017,
      "step": 5150
    },
    {
      "epoch": 1.4742857142857142,
      "grad_norm": 0.035219162702560425,
      "learning_rate": 1.8034285714285717e-05,
      "loss": 0.2959,
      "step": 5160
    },
    {
      "epoch": 1.477142857142857,
      "grad_norm": 0.0525236651301384,
      "learning_rate": 1.8030476190476192e-05,
      "loss": 0.4648,
      "step": 5170
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.18836967647075653,
      "learning_rate": 1.8026666666666668e-05,
      "loss": 0.3064,
      "step": 5180
    },
    {
      "epoch": 1.4828571428571429,
      "grad_norm": 20.391263961791992,
      "learning_rate": 1.8022857142857144e-05,
      "loss": 0.2582,
      "step": 5190
    },
    {
      "epoch": 1.4857142857142858,
      "grad_norm": 0.08605379611253738,
      "learning_rate": 1.801904761904762e-05,
      "loss": 0.2473,
      "step": 5200
    },
    {
      "epoch": 1.4885714285714284,
      "grad_norm": 0.017192594707012177,
      "learning_rate": 1.8015238095238098e-05,
      "loss": 0.1594,
      "step": 5210
    },
    {
      "epoch": 1.4914285714285715,
      "grad_norm": 26.702184677124023,
      "learning_rate": 1.8011428571428574e-05,
      "loss": 0.3756,
      "step": 5220
    },
    {
      "epoch": 1.4942857142857142,
      "grad_norm": 0.3492838442325592,
      "learning_rate": 1.800761904761905e-05,
      "loss": 0.2023,
      "step": 5230
    },
    {
      "epoch": 1.497142857142857,
      "grad_norm": 0.03944399207830429,
      "learning_rate": 1.8003809523809525e-05,
      "loss": 0.4487,
      "step": 5240
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7123563289642334,
      "learning_rate": 1.8e-05,
      "loss": 0.1524,
      "step": 5250
    },
    {
      "epoch": 1.502857142857143,
      "grad_norm": 0.05138496682047844,
      "learning_rate": 1.799619047619048e-05,
      "loss": 0.2317,
      "step": 5260
    },
    {
      "epoch": 1.5057142857142858,
      "grad_norm": 0.11932364106178284,
      "learning_rate": 1.7992380952380955e-05,
      "loss": 0.1184,
      "step": 5270
    },
    {
      "epoch": 1.5085714285714285,
      "grad_norm": 0.22063006460666656,
      "learning_rate": 1.798857142857143e-05,
      "loss": 0.0763,
      "step": 5280
    },
    {
      "epoch": 1.5114285714285716,
      "grad_norm": 0.0298517644405365,
      "learning_rate": 1.7984761904761906e-05,
      "loss": 0.1411,
      "step": 5290
    },
    {
      "epoch": 1.5142857142857142,
      "grad_norm": 17.840757369995117,
      "learning_rate": 1.7980952380952382e-05,
      "loss": 0.3509,
      "step": 5300
    },
    {
      "epoch": 1.5171428571428571,
      "grad_norm": 0.007937615737318993,
      "learning_rate": 1.797714285714286e-05,
      "loss": 0.1729,
      "step": 5310
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.14982710778713226,
      "learning_rate": 1.7973333333333333e-05,
      "loss": 0.4459,
      "step": 5320
    },
    {
      "epoch": 1.522857142857143,
      "grad_norm": 0.10925044119358063,
      "learning_rate": 1.796952380952381e-05,
      "loss": 0.7648,
      "step": 5330
    },
    {
      "epoch": 1.5257142857142858,
      "grad_norm": 23.917219161987305,
      "learning_rate": 1.7965714285714287e-05,
      "loss": 0.7848,
      "step": 5340
    },
    {
      "epoch": 1.5285714285714285,
      "grad_norm": 0.2737005949020386,
      "learning_rate": 1.7961904761904763e-05,
      "loss": 0.4237,
      "step": 5350
    },
    {
      "epoch": 1.5314285714285716,
      "grad_norm": 0.1644907295703888,
      "learning_rate": 1.795809523809524e-05,
      "loss": 0.2147,
      "step": 5360
    },
    {
      "epoch": 1.5342857142857143,
      "grad_norm": 0.05299555882811546,
      "learning_rate": 1.7954285714285714e-05,
      "loss": 0.1951,
      "step": 5370
    },
    {
      "epoch": 1.5371428571428571,
      "grad_norm": 0.06688441336154938,
      "learning_rate": 1.7950476190476193e-05,
      "loss": 0.1418,
      "step": 5380
    },
    {
      "epoch": 1.54,
      "grad_norm": 0.064280204474926,
      "learning_rate": 1.794666666666667e-05,
      "loss": 0.38,
      "step": 5390
    },
    {
      "epoch": 1.5428571428571427,
      "grad_norm": 0.8904953002929688,
      "learning_rate": 1.7942857142857144e-05,
      "loss": 0.3175,
      "step": 5400
    },
    {
      "epoch": 1.5457142857142858,
      "grad_norm": 0.06543004512786865,
      "learning_rate": 1.793904761904762e-05,
      "loss": 0.1125,
      "step": 5410
    },
    {
      "epoch": 1.5485714285714285,
      "grad_norm": 0.051135558634996414,
      "learning_rate": 1.7935238095238096e-05,
      "loss": 0.2139,
      "step": 5420
    },
    {
      "epoch": 1.5514285714285714,
      "grad_norm": 0.018874747678637505,
      "learning_rate": 1.7931428571428574e-05,
      "loss": 0.3895,
      "step": 5430
    },
    {
      "epoch": 1.5542857142857143,
      "grad_norm": 0.2602692246437073,
      "learning_rate": 1.792761904761905e-05,
      "loss": 0.1015,
      "step": 5440
    },
    {
      "epoch": 1.5571428571428572,
      "grad_norm": 0.02756737358868122,
      "learning_rate": 1.7923809523809526e-05,
      "loss": 0.2577,
      "step": 5450
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.007728543132543564,
      "learning_rate": 1.792e-05,
      "loss": 0.1456,
      "step": 5460
    },
    {
      "epoch": 1.5628571428571427,
      "grad_norm": 0.8984980583190918,
      "learning_rate": 1.7916190476190477e-05,
      "loss": 0.2774,
      "step": 5470
    },
    {
      "epoch": 1.5657142857142858,
      "grad_norm": 2.0901496410369873,
      "learning_rate": 1.7912380952380956e-05,
      "loss": 0.4139,
      "step": 5480
    },
    {
      "epoch": 1.5685714285714285,
      "grad_norm": 0.16062888503074646,
      "learning_rate": 1.790857142857143e-05,
      "loss": 0.2093,
      "step": 5490
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 0.10943111777305603,
      "learning_rate": 1.7904761904761907e-05,
      "loss": 0.222,
      "step": 5500
    },
    {
      "epoch": 1.5742857142857143,
      "grad_norm": 37.3206901550293,
      "learning_rate": 1.7900952380952383e-05,
      "loss": 0.2486,
      "step": 5510
    },
    {
      "epoch": 1.5771428571428572,
      "grad_norm": 0.03301725909113884,
      "learning_rate": 1.7897142857142858e-05,
      "loss": 0.0808,
      "step": 5520
    },
    {
      "epoch": 1.58,
      "grad_norm": 20.643033981323242,
      "learning_rate": 1.7893333333333337e-05,
      "loss": 0.4205,
      "step": 5530
    },
    {
      "epoch": 1.5828571428571427,
      "grad_norm": 20.88456916809082,
      "learning_rate": 1.788952380952381e-05,
      "loss": 0.2303,
      "step": 5540
    },
    {
      "epoch": 1.5857142857142859,
      "grad_norm": 0.17979024350643158,
      "learning_rate": 1.7885714285714285e-05,
      "loss": 0.3964,
      "step": 5550
    },
    {
      "epoch": 1.5885714285714285,
      "grad_norm": 2.134812831878662,
      "learning_rate": 1.7881904761904764e-05,
      "loss": 0.1141,
      "step": 5560
    },
    {
      "epoch": 1.5914285714285714,
      "grad_norm": 1.4358477592468262,
      "learning_rate": 1.787809523809524e-05,
      "loss": 0.3537,
      "step": 5570
    },
    {
      "epoch": 1.5942857142857143,
      "grad_norm": 0.0076517690904438496,
      "learning_rate": 1.7874285714285715e-05,
      "loss": 0.0232,
      "step": 5580
    },
    {
      "epoch": 1.5971428571428572,
      "grad_norm": 0.4154149293899536,
      "learning_rate": 1.787047619047619e-05,
      "loss": 0.2074,
      "step": 5590
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.12963321805000305,
      "learning_rate": 1.7866666666666666e-05,
      "loss": 0.1856,
      "step": 5600
    },
    {
      "epoch": 1.6028571428571428,
      "grad_norm": 0.017521249130368233,
      "learning_rate": 1.7862857142857145e-05,
      "loss": 0.059,
      "step": 5610
    },
    {
      "epoch": 1.6057142857142859,
      "grad_norm": 0.03730437532067299,
      "learning_rate": 1.785904761904762e-05,
      "loss": 0.2258,
      "step": 5620
    },
    {
      "epoch": 1.6085714285714285,
      "grad_norm": 30.425479888916016,
      "learning_rate": 1.7855238095238096e-05,
      "loss": 0.55,
      "step": 5630
    },
    {
      "epoch": 1.6114285714285714,
      "grad_norm": 0.364270955324173,
      "learning_rate": 1.7851428571428572e-05,
      "loss": 0.3448,
      "step": 5640
    },
    {
      "epoch": 1.6142857142857143,
      "grad_norm": 29.697721481323242,
      "learning_rate": 1.784761904761905e-05,
      "loss": 0.3564,
      "step": 5650
    },
    {
      "epoch": 1.617142857142857,
      "grad_norm": 6.228797912597656,
      "learning_rate": 1.7843809523809526e-05,
      "loss": 0.3867,
      "step": 5660
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.037041276693344116,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.1088,
      "step": 5670
    },
    {
      "epoch": 1.6228571428571428,
      "grad_norm": 0.05012175440788269,
      "learning_rate": 1.7836190476190478e-05,
      "loss": 0.4639,
      "step": 5680
    },
    {
      "epoch": 1.6257142857142857,
      "grad_norm": 25.037832260131836,
      "learning_rate": 1.7832380952380953e-05,
      "loss": 0.5008,
      "step": 5690
    },
    {
      "epoch": 1.6285714285714286,
      "grad_norm": 37.29590606689453,
      "learning_rate": 1.7828571428571432e-05,
      "loss": 0.1649,
      "step": 5700
    },
    {
      "epoch": 1.6314285714285715,
      "grad_norm": 0.016583731397986412,
      "learning_rate": 1.7824761904761908e-05,
      "loss": 0.3547,
      "step": 5710
    },
    {
      "epoch": 1.6342857142857143,
      "grad_norm": 0.050818197429180145,
      "learning_rate": 1.7820952380952383e-05,
      "loss": 0.4632,
      "step": 5720
    },
    {
      "epoch": 1.637142857142857,
      "grad_norm": 0.03873176500201225,
      "learning_rate": 1.781714285714286e-05,
      "loss": 0.1472,
      "step": 5730
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.035482265055179596,
      "learning_rate": 1.7813333333333334e-05,
      "loss": 0.3011,
      "step": 5740
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 26.8558349609375,
      "learning_rate": 1.780952380952381e-05,
      "loss": 0.5303,
      "step": 5750
    },
    {
      "epoch": 1.6457142857142857,
      "grad_norm": 0.04170844703912735,
      "learning_rate": 1.7805714285714286e-05,
      "loss": 0.1458,
      "step": 5760
    },
    {
      "epoch": 1.6485714285714286,
      "grad_norm": 22.595548629760742,
      "learning_rate": 1.780190476190476e-05,
      "loss": 0.9917,
      "step": 5770
    },
    {
      "epoch": 1.6514285714285715,
      "grad_norm": 0.4305368661880493,
      "learning_rate": 1.779809523809524e-05,
      "loss": 0.3863,
      "step": 5780
    },
    {
      "epoch": 1.6542857142857144,
      "grad_norm": 0.27707648277282715,
      "learning_rate": 1.7794285714285716e-05,
      "loss": 0.1565,
      "step": 5790
    },
    {
      "epoch": 1.657142857142857,
      "grad_norm": 0.032845690846443176,
      "learning_rate": 1.779047619047619e-05,
      "loss": 0.06,
      "step": 5800
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 0.09522216767072678,
      "learning_rate": 1.7786666666666667e-05,
      "loss": 0.2646,
      "step": 5810
    },
    {
      "epoch": 1.6628571428571428,
      "grad_norm": 30.312406539916992,
      "learning_rate": 1.7782857142857142e-05,
      "loss": 0.4612,
      "step": 5820
    },
    {
      "epoch": 1.6657142857142857,
      "grad_norm": 18.331626892089844,
      "learning_rate": 1.777904761904762e-05,
      "loss": 0.4117,
      "step": 5830
    },
    {
      "epoch": 1.6685714285714286,
      "grad_norm": 17.286460876464844,
      "learning_rate": 1.7775238095238097e-05,
      "loss": 0.4225,
      "step": 5840
    },
    {
      "epoch": 1.6714285714285713,
      "grad_norm": 0.07049213349819183,
      "learning_rate": 1.7771428571428573e-05,
      "loss": 0.2007,
      "step": 5850
    },
    {
      "epoch": 1.6742857142857144,
      "grad_norm": 25.428592681884766,
      "learning_rate": 1.7767619047619048e-05,
      "loss": 0.7237,
      "step": 5860
    },
    {
      "epoch": 1.677142857142857,
      "grad_norm": 0.5935980677604675,
      "learning_rate": 1.7763809523809524e-05,
      "loss": 0.3967,
      "step": 5870
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 6.361209869384766,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.29,
      "step": 5880
    },
    {
      "epoch": 1.6828571428571428,
      "grad_norm": 41.292816162109375,
      "learning_rate": 1.775619047619048e-05,
      "loss": 0.1627,
      "step": 5890
    },
    {
      "epoch": 1.6857142857142857,
      "grad_norm": 0.016685692593455315,
      "learning_rate": 1.7752380952380954e-05,
      "loss": 0.0019,
      "step": 5900
    },
    {
      "epoch": 1.6885714285714286,
      "grad_norm": 23.23048973083496,
      "learning_rate": 1.774857142857143e-05,
      "loss": 0.4727,
      "step": 5910
    },
    {
      "epoch": 1.6914285714285713,
      "grad_norm": 1.8015737533569336,
      "learning_rate": 1.774476190476191e-05,
      "loss": 0.4303,
      "step": 5920
    },
    {
      "epoch": 1.6942857142857144,
      "grad_norm": 20.939746856689453,
      "learning_rate": 1.7740952380952384e-05,
      "loss": 0.2545,
      "step": 5930
    },
    {
      "epoch": 1.697142857142857,
      "grad_norm": 18.679317474365234,
      "learning_rate": 1.773714285714286e-05,
      "loss": 0.1505,
      "step": 5940
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.008176865056157112,
      "learning_rate": 1.7733333333333335e-05,
      "loss": 0.0029,
      "step": 5950
    },
    {
      "epoch": 1.7028571428571428,
      "grad_norm": 0.06590794026851654,
      "learning_rate": 1.772952380952381e-05,
      "loss": 0.0419,
      "step": 5960
    },
    {
      "epoch": 1.7057142857142857,
      "grad_norm": 0.023293165490031242,
      "learning_rate": 1.7725714285714286e-05,
      "loss": 0.1397,
      "step": 5970
    },
    {
      "epoch": 1.7085714285714286,
      "grad_norm": 25.888124465942383,
      "learning_rate": 1.7721904761904762e-05,
      "loss": 0.1185,
      "step": 5980
    },
    {
      "epoch": 1.7114285714285713,
      "grad_norm": 0.04990912601351738,
      "learning_rate": 1.7718095238095238e-05,
      "loss": 0.2118,
      "step": 5990
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 3.0185296535491943,
      "learning_rate": 1.7714285714285717e-05,
      "loss": 0.0437,
      "step": 6000
    },
    {
      "epoch": 1.717142857142857,
      "grad_norm": 1.9565880298614502,
      "learning_rate": 1.7710476190476192e-05,
      "loss": 0.005,
      "step": 6010
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.0083407461643219,
      "learning_rate": 1.7706666666666668e-05,
      "loss": 0.3793,
      "step": 6020
    },
    {
      "epoch": 1.7228571428571429,
      "grad_norm": 0.02099101059138775,
      "learning_rate": 1.7702857142857143e-05,
      "loss": 0.4065,
      "step": 6030
    },
    {
      "epoch": 1.7257142857142858,
      "grad_norm": 0.021874651312828064,
      "learning_rate": 1.769904761904762e-05,
      "loss": 0.3585,
      "step": 6040
    },
    {
      "epoch": 1.7285714285714286,
      "grad_norm": 0.10276719182729721,
      "learning_rate": 1.7695238095238098e-05,
      "loss": 0.0017,
      "step": 6050
    },
    {
      "epoch": 1.7314285714285713,
      "grad_norm": 0.11948078870773315,
      "learning_rate": 1.7691428571428573e-05,
      "loss": 0.0167,
      "step": 6060
    },
    {
      "epoch": 1.7342857142857144,
      "grad_norm": 0.37201741337776184,
      "learning_rate": 1.768761904761905e-05,
      "loss": 0.1793,
      "step": 6070
    },
    {
      "epoch": 1.737142857142857,
      "grad_norm": 0.02158684842288494,
      "learning_rate": 1.7683809523809525e-05,
      "loss": 0.1284,
      "step": 6080
    },
    {
      "epoch": 1.74,
      "grad_norm": 0.007168513722717762,
      "learning_rate": 1.768e-05,
      "loss": 0.0389,
      "step": 6090
    },
    {
      "epoch": 1.7428571428571429,
      "grad_norm": 0.053094394505023956,
      "learning_rate": 1.767619047619048e-05,
      "loss": 0.1298,
      "step": 6100
    },
    {
      "epoch": 1.7457142857142856,
      "grad_norm": 0.07613467425107956,
      "learning_rate": 1.7672380952380955e-05,
      "loss": 0.5118,
      "step": 6110
    },
    {
      "epoch": 1.7485714285714287,
      "grad_norm": 0.14971543848514557,
      "learning_rate": 1.766857142857143e-05,
      "loss": 0.3601,
      "step": 6120
    },
    {
      "epoch": 1.7514285714285713,
      "grad_norm": 0.0421755425632,
      "learning_rate": 1.7664761904761906e-05,
      "loss": 0.1313,
      "step": 6130
    },
    {
      "epoch": 1.7542857142857144,
      "grad_norm": 0.02825164422392845,
      "learning_rate": 1.766095238095238e-05,
      "loss": 0.1594,
      "step": 6140
    },
    {
      "epoch": 1.7571428571428571,
      "grad_norm": 0.019005421549081802,
      "learning_rate": 1.765714285714286e-05,
      "loss": 0.0009,
      "step": 6150
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.03918788954615593,
      "learning_rate": 1.7653333333333336e-05,
      "loss": 0.0294,
      "step": 6160
    },
    {
      "epoch": 1.762857142857143,
      "grad_norm": 0.3516090214252472,
      "learning_rate": 1.764952380952381e-05,
      "loss": 0.0894,
      "step": 6170
    },
    {
      "epoch": 1.7657142857142856,
      "grad_norm": 0.003607220947742462,
      "learning_rate": 1.7645714285714287e-05,
      "loss": 0.206,
      "step": 6180
    },
    {
      "epoch": 1.7685714285714287,
      "grad_norm": 41.93782424926758,
      "learning_rate": 1.7641904761904763e-05,
      "loss": 0.3171,
      "step": 6190
    },
    {
      "epoch": 1.7714285714285714,
      "grad_norm": 0.027082866057753563,
      "learning_rate": 1.7638095238095238e-05,
      "loss": 0.2101,
      "step": 6200
    },
    {
      "epoch": 1.7742857142857142,
      "grad_norm": 0.0892392098903656,
      "learning_rate": 1.7634285714285714e-05,
      "loss": 0.2482,
      "step": 6210
    },
    {
      "epoch": 1.7771428571428571,
      "grad_norm": 0.1379757523536682,
      "learning_rate": 1.7630476190476193e-05,
      "loss": 0.3794,
      "step": 6220
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.08273861557245255,
      "learning_rate": 1.762666666666667e-05,
      "loss": 0.0026,
      "step": 6230
    },
    {
      "epoch": 1.782857142857143,
      "grad_norm": 0.05526532605290413,
      "learning_rate": 1.7622857142857144e-05,
      "loss": 0.1938,
      "step": 6240
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.08005941659212112,
      "learning_rate": 1.761904761904762e-05,
      "loss": 0.1493,
      "step": 6250
    },
    {
      "epoch": 1.7885714285714287,
      "grad_norm": 0.1065749004483223,
      "learning_rate": 1.7615238095238095e-05,
      "loss": 0.2037,
      "step": 6260
    },
    {
      "epoch": 1.7914285714285714,
      "grad_norm": 0.17374397814273834,
      "learning_rate": 1.7611428571428574e-05,
      "loss": 0.2757,
      "step": 6270
    },
    {
      "epoch": 1.7942857142857143,
      "grad_norm": 0.022354887798428535,
      "learning_rate": 1.760761904761905e-05,
      "loss": 0.0466,
      "step": 6280
    },
    {
      "epoch": 1.7971428571428572,
      "grad_norm": 23.709745407104492,
      "learning_rate": 1.7603809523809525e-05,
      "loss": 0.5494,
      "step": 6290
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.055755723267793655,
      "learning_rate": 1.76e-05,
      "loss": 0.1863,
      "step": 6300
    },
    {
      "epoch": 1.802857142857143,
      "grad_norm": 0.033973515033721924,
      "learning_rate": 1.7596190476190476e-05,
      "loss": 0.205,
      "step": 6310
    },
    {
      "epoch": 1.8057142857142856,
      "grad_norm": 0.12735258042812347,
      "learning_rate": 1.7592380952380955e-05,
      "loss": 0.2382,
      "step": 6320
    },
    {
      "epoch": 1.8085714285714287,
      "grad_norm": 0.07654628157615662,
      "learning_rate": 1.758857142857143e-05,
      "loss": 0.5835,
      "step": 6330
    },
    {
      "epoch": 1.8114285714285714,
      "grad_norm": 0.3163726031780243,
      "learning_rate": 1.7584761904761907e-05,
      "loss": 0.2604,
      "step": 6340
    },
    {
      "epoch": 1.8142857142857143,
      "grad_norm": 0.03453354164958,
      "learning_rate": 1.7580952380952382e-05,
      "loss": 0.1321,
      "step": 6350
    },
    {
      "epoch": 1.8171428571428572,
      "grad_norm": 0.11587609350681305,
      "learning_rate": 1.7577142857142858e-05,
      "loss": 0.3105,
      "step": 6360
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 0.023984214290976524,
      "learning_rate": 1.7573333333333337e-05,
      "loss": 0.0109,
      "step": 6370
    },
    {
      "epoch": 1.822857142857143,
      "grad_norm": 29.434843063354492,
      "learning_rate": 1.7569523809523812e-05,
      "loss": 0.323,
      "step": 6380
    },
    {
      "epoch": 1.8257142857142856,
      "grad_norm": 0.024628695100545883,
      "learning_rate": 1.7565714285714288e-05,
      "loss": 0.0166,
      "step": 6390
    },
    {
      "epoch": 1.8285714285714287,
      "grad_norm": 0.03906583786010742,
      "learning_rate": 1.7561904761904763e-05,
      "loss": 0.3442,
      "step": 6400
    },
    {
      "epoch": 1.8314285714285714,
      "grad_norm": 0.05044776573777199,
      "learning_rate": 1.755809523809524e-05,
      "loss": 0.1693,
      "step": 6410
    },
    {
      "epoch": 1.8342857142857143,
      "grad_norm": 24.078617095947266,
      "learning_rate": 1.7554285714285715e-05,
      "loss": 0.3288,
      "step": 6420
    },
    {
      "epoch": 1.8371428571428572,
      "grad_norm": 0.018137598410248756,
      "learning_rate": 1.755047619047619e-05,
      "loss": 0.2376,
      "step": 6430
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.039961766451597214,
      "learning_rate": 1.7546666666666666e-05,
      "loss": 0.3387,
      "step": 6440
    },
    {
      "epoch": 1.842857142857143,
      "grad_norm": 0.20107902586460114,
      "learning_rate": 1.7542857142857145e-05,
      "loss": 0.2257,
      "step": 6450
    },
    {
      "epoch": 1.8457142857142856,
      "grad_norm": 0.13816289603710175,
      "learning_rate": 1.753904761904762e-05,
      "loss": 0.1775,
      "step": 6460
    },
    {
      "epoch": 1.8485714285714285,
      "grad_norm": 0.07262036949396133,
      "learning_rate": 1.7535238095238096e-05,
      "loss": 0.1223,
      "step": 6470
    },
    {
      "epoch": 1.8514285714285714,
      "grad_norm": 23.571842193603516,
      "learning_rate": 1.753142857142857e-05,
      "loss": 0.3534,
      "step": 6480
    },
    {
      "epoch": 1.8542857142857143,
      "grad_norm": 36.82338333129883,
      "learning_rate": 1.752761904761905e-05,
      "loss": 0.0148,
      "step": 6490
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 0.03499981388449669,
      "learning_rate": 1.7523809523809526e-05,
      "loss": 0.2108,
      "step": 6500
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 0.8531159162521362,
      "learning_rate": 1.752e-05,
      "loss": 0.3297,
      "step": 6510
    },
    {
      "epoch": 1.862857142857143,
      "grad_norm": 1.5732629299163818,
      "learning_rate": 1.7516190476190477e-05,
      "loss": 0.1751,
      "step": 6520
    },
    {
      "epoch": 1.8657142857142857,
      "grad_norm": 0.09659504145383835,
      "learning_rate": 1.7512380952380953e-05,
      "loss": 0.5585,
      "step": 6530
    },
    {
      "epoch": 1.8685714285714285,
      "grad_norm": 15.995137214660645,
      "learning_rate": 1.7508571428571432e-05,
      "loss": 0.8077,
      "step": 6540
    },
    {
      "epoch": 1.8714285714285714,
      "grad_norm": 38.836177825927734,
      "learning_rate": 1.7504761904761907e-05,
      "loss": 0.9153,
      "step": 6550
    },
    {
      "epoch": 1.8742857142857143,
      "grad_norm": 32.18263626098633,
      "learning_rate": 1.7500952380952383e-05,
      "loss": 0.7161,
      "step": 6560
    },
    {
      "epoch": 1.8771428571428572,
      "grad_norm": 2.805737257003784,
      "learning_rate": 1.749714285714286e-05,
      "loss": 0.4633,
      "step": 6570
    },
    {
      "epoch": 1.88,
      "grad_norm": 13.85295581817627,
      "learning_rate": 1.7493333333333334e-05,
      "loss": 0.6538,
      "step": 6580
    },
    {
      "epoch": 1.882857142857143,
      "grad_norm": 15.356215476989746,
      "learning_rate": 1.7489523809523813e-05,
      "loss": 0.1751,
      "step": 6590
    },
    {
      "epoch": 1.8857142857142857,
      "grad_norm": 15.62691879272461,
      "learning_rate": 1.748571428571429e-05,
      "loss": 0.1988,
      "step": 6600
    },
    {
      "epoch": 1.8885714285714286,
      "grad_norm": 15.367012977600098,
      "learning_rate": 1.7481904761904764e-05,
      "loss": 0.9269,
      "step": 6610
    },
    {
      "epoch": 1.8914285714285715,
      "grad_norm": 15.312548637390137,
      "learning_rate": 1.747809523809524e-05,
      "loss": 0.4163,
      "step": 6620
    },
    {
      "epoch": 1.8942857142857141,
      "grad_norm": 15.541337966918945,
      "learning_rate": 1.7474285714285715e-05,
      "loss": 0.7378,
      "step": 6630
    },
    {
      "epoch": 1.8971428571428572,
      "grad_norm": 0.7444820404052734,
      "learning_rate": 1.747047619047619e-05,
      "loss": 0.6338,
      "step": 6640
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.4313966035842896,
      "learning_rate": 1.7466666666666667e-05,
      "loss": 0.6331,
      "step": 6650
    },
    {
      "epoch": 1.9028571428571428,
      "grad_norm": 0.7977095246315002,
      "learning_rate": 1.7462857142857142e-05,
      "loss": 0.3078,
      "step": 6660
    },
    {
      "epoch": 1.9057142857142857,
      "grad_norm": 11.906251907348633,
      "learning_rate": 1.745904761904762e-05,
      "loss": 1.0876,
      "step": 6670
    },
    {
      "epoch": 1.9085714285714286,
      "grad_norm": 12.8117094039917,
      "learning_rate": 1.7455238095238097e-05,
      "loss": 0.2658,
      "step": 6680
    },
    {
      "epoch": 1.9114285714285715,
      "grad_norm": 0.37851032614707947,
      "learning_rate": 1.7451428571428572e-05,
      "loss": 0.8076,
      "step": 6690
    },
    {
      "epoch": 1.9142857142857141,
      "grad_norm": 0.23081913590431213,
      "learning_rate": 1.7447619047619048e-05,
      "loss": 0.1273,
      "step": 6700
    },
    {
      "epoch": 1.9171428571428573,
      "grad_norm": 12.891280174255371,
      "learning_rate": 1.7443809523809523e-05,
      "loss": 0.7136,
      "step": 6710
    },
    {
      "epoch": 1.92,
      "grad_norm": 12.839683532714844,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.8536,
      "step": 6720
    },
    {
      "epoch": 1.9228571428571428,
      "grad_norm": 0.5809319019317627,
      "learning_rate": 1.7436190476190478e-05,
      "loss": 0.224,
      "step": 6730
    },
    {
      "epoch": 1.9257142857142857,
      "grad_norm": 0.2781889736652374,
      "learning_rate": 1.7432380952380954e-05,
      "loss": 0.25,
      "step": 6740
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 0.48495104908943176,
      "learning_rate": 1.742857142857143e-05,
      "loss": 0.8896,
      "step": 6750
    },
    {
      "epoch": 1.9314285714285715,
      "grad_norm": 0.5685098171234131,
      "learning_rate": 1.7424761904761908e-05,
      "loss": 0.5955,
      "step": 6760
    },
    {
      "epoch": 1.9342857142857142,
      "grad_norm": 12.836291313171387,
      "learning_rate": 1.7420952380952384e-05,
      "loss": 0.2405,
      "step": 6770
    },
    {
      "epoch": 1.9371428571428573,
      "grad_norm": 0.3907451033592224,
      "learning_rate": 1.741714285714286e-05,
      "loss": 0.7108,
      "step": 6780
    },
    {
      "epoch": 1.94,
      "grad_norm": 11.893219947814941,
      "learning_rate": 1.7413333333333335e-05,
      "loss": 0.5544,
      "step": 6790
    },
    {
      "epoch": 1.9428571428571428,
      "grad_norm": 12.954781532287598,
      "learning_rate": 1.740952380952381e-05,
      "loss": 0.3345,
      "step": 6800
    },
    {
      "epoch": 1.9457142857142857,
      "grad_norm": 0.54591965675354,
      "learning_rate": 1.740571428571429e-05,
      "loss": 0.5775,
      "step": 6810
    },
    {
      "epoch": 1.9485714285714286,
      "grad_norm": 1.1618142127990723,
      "learning_rate": 1.7401904761904765e-05,
      "loss": 0.8318,
      "step": 6820
    },
    {
      "epoch": 1.9514285714285715,
      "grad_norm": 34.54563522338867,
      "learning_rate": 1.739809523809524e-05,
      "loss": 0.4903,
      "step": 6830
    },
    {
      "epoch": 1.9542857142857142,
      "grad_norm": 0.8722034692764282,
      "learning_rate": 1.7394285714285716e-05,
      "loss": 0.7134,
      "step": 6840
    },
    {
      "epoch": 1.9571428571428573,
      "grad_norm": 0.994698703289032,
      "learning_rate": 1.7390476190476192e-05,
      "loss": 0.6317,
      "step": 6850
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5094720721244812,
      "learning_rate": 1.7386666666666667e-05,
      "loss": 0.2206,
      "step": 6860
    },
    {
      "epoch": 1.9628571428571429,
      "grad_norm": 12.322038650512695,
      "learning_rate": 1.7382857142857143e-05,
      "loss": 0.4743,
      "step": 6870
    },
    {
      "epoch": 1.9657142857142857,
      "grad_norm": 0.30814555287361145,
      "learning_rate": 1.737904761904762e-05,
      "loss": 0.1273,
      "step": 6880
    },
    {
      "epoch": 1.9685714285714284,
      "grad_norm": 11.869929313659668,
      "learning_rate": 1.7375238095238097e-05,
      "loss": 0.515,
      "step": 6890
    },
    {
      "epoch": 1.9714285714285715,
      "grad_norm": 0.3372659981250763,
      "learning_rate": 1.7371428571428573e-05,
      "loss": 0.3724,
      "step": 6900
    },
    {
      "epoch": 1.9742857142857142,
      "grad_norm": 23.486852645874023,
      "learning_rate": 1.736761904761905e-05,
      "loss": 0.6373,
      "step": 6910
    },
    {
      "epoch": 1.977142857142857,
      "grad_norm": 0.29633834958076477,
      "learning_rate": 1.7363809523809524e-05,
      "loss": 0.3968,
      "step": 6920
    },
    {
      "epoch": 1.98,
      "grad_norm": 0.38878512382507324,
      "learning_rate": 1.736e-05,
      "loss": 0.1268,
      "step": 6930
    },
    {
      "epoch": 1.9828571428571429,
      "grad_norm": 0.6912248134613037,
      "learning_rate": 1.735619047619048e-05,
      "loss": 1.2129,
      "step": 6940
    },
    {
      "epoch": 1.9857142857142858,
      "grad_norm": 10.626595497131348,
      "learning_rate": 1.7352380952380954e-05,
      "loss": 0.6052,
      "step": 6950
    },
    {
      "epoch": 1.9885714285714284,
      "grad_norm": 0.8426077961921692,
      "learning_rate": 1.734857142857143e-05,
      "loss": 0.3131,
      "step": 6960
    },
    {
      "epoch": 1.9914285714285715,
      "grad_norm": 11.898359298706055,
      "learning_rate": 1.7344761904761906e-05,
      "loss": 0.8476,
      "step": 6970
    },
    {
      "epoch": 1.9942857142857142,
      "grad_norm": 23.19304847717285,
      "learning_rate": 1.734095238095238e-05,
      "loss": 0.8204,
      "step": 6980
    },
    {
      "epoch": 1.997142857142857,
      "grad_norm": 11.480360984802246,
      "learning_rate": 1.733714285714286e-05,
      "loss": 0.5279,
      "step": 6990
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5979990363121033,
      "learning_rate": 1.7333333333333336e-05,
      "loss": 0.3428,
      "step": 7000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8893333333333333,
      "eval_f1": 0.0,
      "eval_loss": 0.4801076650619507,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 260.4797,
      "eval_samples_per_second": 11.517,
      "eval_steps_per_second": 2.879,
      "step": 7000
    },
    {
      "epoch": 2.0028571428571427,
      "grad_norm": 11.632675170898438,
      "learning_rate": 1.732952380952381e-05,
      "loss": 0.3433,
      "step": 7010
    },
    {
      "epoch": 2.005714285714286,
      "grad_norm": 0.47241419553756714,
      "learning_rate": 1.7325714285714287e-05,
      "loss": 0.8332,
      "step": 7020
    },
    {
      "epoch": 2.0085714285714285,
      "grad_norm": 0.5903971791267395,
      "learning_rate": 1.7321904761904766e-05,
      "loss": 0.6888,
      "step": 7030
    },
    {
      "epoch": 2.0114285714285716,
      "grad_norm": 0.6170697212219238,
      "learning_rate": 1.731809523809524e-05,
      "loss": 0.5586,
      "step": 7040
    },
    {
      "epoch": 2.0142857142857142,
      "grad_norm": 10.888769149780273,
      "learning_rate": 1.7314285714285717e-05,
      "loss": 0.7726,
      "step": 7050
    },
    {
      "epoch": 2.0171428571428573,
      "grad_norm": 0.6262578964233398,
      "learning_rate": 1.7310476190476193e-05,
      "loss": 0.3353,
      "step": 7060
    },
    {
      "epoch": 2.02,
      "grad_norm": 0.5572074055671692,
      "learning_rate": 1.7306666666666668e-05,
      "loss": 0.5574,
      "step": 7070
    },
    {
      "epoch": 2.0228571428571427,
      "grad_norm": 0.6149168610572815,
      "learning_rate": 1.7302857142857144e-05,
      "loss": 0.7997,
      "step": 7080
    },
    {
      "epoch": 2.025714285714286,
      "grad_norm": 0.4577133357524872,
      "learning_rate": 1.729904761904762e-05,
      "loss": 0.2356,
      "step": 7090
    },
    {
      "epoch": 2.0285714285714285,
      "grad_norm": 11.60091495513916,
      "learning_rate": 1.7295238095238095e-05,
      "loss": 0.6986,
      "step": 7100
    },
    {
      "epoch": 2.0314285714285716,
      "grad_norm": 22.69598960876465,
      "learning_rate": 1.7291428571428574e-05,
      "loss": 0.466,
      "step": 7110
    },
    {
      "epoch": 2.0342857142857143,
      "grad_norm": 0.6450737714767456,
      "learning_rate": 1.728761904761905e-05,
      "loss": 0.8911,
      "step": 7120
    },
    {
      "epoch": 2.0371428571428574,
      "grad_norm": 0.7181540131568909,
      "learning_rate": 1.7283809523809525e-05,
      "loss": 0.5339,
      "step": 7130
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5193482041358948,
      "learning_rate": 1.728e-05,
      "loss": 0.3359,
      "step": 7140
    },
    {
      "epoch": 2.0428571428571427,
      "grad_norm": 0.6008623242378235,
      "learning_rate": 1.7276190476190476e-05,
      "loss": 0.5654,
      "step": 7150
    },
    {
      "epoch": 2.045714285714286,
      "grad_norm": 0.7264899611473083,
      "learning_rate": 1.7272380952380955e-05,
      "loss": 0.6689,
      "step": 7160
    },
    {
      "epoch": 2.0485714285714285,
      "grad_norm": 11.656248092651367,
      "learning_rate": 1.726857142857143e-05,
      "loss": 0.7326,
      "step": 7170
    },
    {
      "epoch": 2.0514285714285716,
      "grad_norm": 0.9627655148506165,
      "learning_rate": 1.7264761904761906e-05,
      "loss": 0.4138,
      "step": 7180
    },
    {
      "epoch": 2.0542857142857143,
      "grad_norm": 0.8051662445068359,
      "learning_rate": 1.7260952380952382e-05,
      "loss": 0.4163,
      "step": 7190
    },
    {
      "epoch": 2.057142857142857,
      "grad_norm": 11.109718322753906,
      "learning_rate": 1.7257142857142857e-05,
      "loss": 0.9666,
      "step": 7200
    },
    {
      "epoch": 2.06,
      "grad_norm": 0.5870226621627808,
      "learning_rate": 1.7253333333333336e-05,
      "loss": 0.2191,
      "step": 7210
    },
    {
      "epoch": 2.0628571428571427,
      "grad_norm": 11.28670883178711,
      "learning_rate": 1.7249523809523812e-05,
      "loss": 0.5862,
      "step": 7220
    },
    {
      "epoch": 2.065714285714286,
      "grad_norm": 0.6958208680152893,
      "learning_rate": 1.7245714285714288e-05,
      "loss": 0.4606,
      "step": 7230
    },
    {
      "epoch": 2.0685714285714285,
      "grad_norm": 10.941312789916992,
      "learning_rate": 1.7241904761904763e-05,
      "loss": 0.5451,
      "step": 7240
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 0.6555933952331543,
      "learning_rate": 1.723809523809524e-05,
      "loss": 0.5476,
      "step": 7250
    },
    {
      "epoch": 2.0742857142857143,
      "grad_norm": 11.427648544311523,
      "learning_rate": 1.7234285714285718e-05,
      "loss": 0.3378,
      "step": 7260
    },
    {
      "epoch": 2.077142857142857,
      "grad_norm": 0.6198400855064392,
      "learning_rate": 1.723047619047619e-05,
      "loss": 0.5599,
      "step": 7270
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.5685834884643555,
      "learning_rate": 1.7226666666666665e-05,
      "loss": 0.3325,
      "step": 7280
    },
    {
      "epoch": 2.0828571428571427,
      "grad_norm": 11.65532398223877,
      "learning_rate": 1.7222857142857144e-05,
      "loss": 0.3405,
      "step": 7290
    },
    {
      "epoch": 2.085714285714286,
      "grad_norm": 0.4675883650779724,
      "learning_rate": 1.721904761904762e-05,
      "loss": 0.7041,
      "step": 7300
    },
    {
      "epoch": 2.0885714285714285,
      "grad_norm": 0.33838748931884766,
      "learning_rate": 1.7215238095238096e-05,
      "loss": 0.2503,
      "step": 7310
    },
    {
      "epoch": 2.0914285714285716,
      "grad_norm": 0.43153679370880127,
      "learning_rate": 1.721142857142857e-05,
      "loss": 0.4899,
      "step": 7320
    },
    {
      "epoch": 2.0942857142857143,
      "grad_norm": 0.6878977417945862,
      "learning_rate": 1.720761904761905e-05,
      "loss": 0.5696,
      "step": 7330
    },
    {
      "epoch": 2.097142857142857,
      "grad_norm": 0.7182958126068115,
      "learning_rate": 1.7203809523809526e-05,
      "loss": 0.5729,
      "step": 7340
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5187578797340393,
      "learning_rate": 1.72e-05,
      "loss": 0.4465,
      "step": 7350
    },
    {
      "epoch": 2.1028571428571428,
      "grad_norm": 0.5309321284294128,
      "learning_rate": 1.7196190476190477e-05,
      "loss": 0.3486,
      "step": 7360
    },
    {
      "epoch": 2.105714285714286,
      "grad_norm": 0.716419517993927,
      "learning_rate": 1.7192380952380953e-05,
      "loss": 0.9152,
      "step": 7370
    },
    {
      "epoch": 2.1085714285714285,
      "grad_norm": 11.045605659484863,
      "learning_rate": 1.718857142857143e-05,
      "loss": 0.8597,
      "step": 7380
    },
    {
      "epoch": 2.111428571428571,
      "grad_norm": 0.9231361746788025,
      "learning_rate": 1.7184761904761907e-05,
      "loss": 0.4187,
      "step": 7390
    },
    {
      "epoch": 2.1142857142857143,
      "grad_norm": 11.122148513793945,
      "learning_rate": 1.7180952380952383e-05,
      "loss": 0.7948,
      "step": 7400
    },
    {
      "epoch": 2.117142857142857,
      "grad_norm": 0.9511992931365967,
      "learning_rate": 1.7177142857142858e-05,
      "loss": 0.3108,
      "step": 7410
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5178017020225525,
      "learning_rate": 1.7173333333333334e-05,
      "loss": 0.3157,
      "step": 7420
    },
    {
      "epoch": 2.1228571428571428,
      "grad_norm": 0.3290766775608063,
      "learning_rate": 1.7169523809523813e-05,
      "loss": 0.3871,
      "step": 7430
    },
    {
      "epoch": 2.125714285714286,
      "grad_norm": 0.4041074216365814,
      "learning_rate": 1.716571428571429e-05,
      "loss": 0.7453,
      "step": 7440
    },
    {
      "epoch": 2.1285714285714286,
      "grad_norm": 12.657111167907715,
      "learning_rate": 1.7161904761904764e-05,
      "loss": 0.5833,
      "step": 7450
    },
    {
      "epoch": 2.1314285714285712,
      "grad_norm": 0.5886556506156921,
      "learning_rate": 1.715809523809524e-05,
      "loss": 0.4465,
      "step": 7460
    },
    {
      "epoch": 2.1342857142857143,
      "grad_norm": 0.6400343179702759,
      "learning_rate": 1.7154285714285715e-05,
      "loss": 0.4493,
      "step": 7470
    },
    {
      "epoch": 2.137142857142857,
      "grad_norm": 0.5371996164321899,
      "learning_rate": 1.7150476190476194e-05,
      "loss": 0.4467,
      "step": 7480
    },
    {
      "epoch": 2.14,
      "grad_norm": 22.90131378173828,
      "learning_rate": 1.7146666666666666e-05,
      "loss": 0.7911,
      "step": 7490
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.5735191702842712,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 0.6714,
      "step": 7500
    },
    {
      "epoch": 2.145714285714286,
      "grad_norm": 10.691010475158691,
      "learning_rate": 1.713904761904762e-05,
      "loss": 0.7681,
      "step": 7510
    },
    {
      "epoch": 2.1485714285714286,
      "grad_norm": 22.553142547607422,
      "learning_rate": 1.7135238095238096e-05,
      "loss": 0.7225,
      "step": 7520
    },
    {
      "epoch": 2.1514285714285712,
      "grad_norm": 0.7013826370239258,
      "learning_rate": 1.7131428571428572e-05,
      "loss": 0.321,
      "step": 7530
    },
    {
      "epoch": 2.1542857142857144,
      "grad_norm": 0.7036268711090088,
      "learning_rate": 1.7127619047619048e-05,
      "loss": 0.7487,
      "step": 7540
    },
    {
      "epoch": 2.157142857142857,
      "grad_norm": 21.780536651611328,
      "learning_rate": 1.7123809523809523e-05,
      "loss": 0.6524,
      "step": 7550
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.6474620699882507,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.3254,
      "step": 7560
    },
    {
      "epoch": 2.162857142857143,
      "grad_norm": 11.014777183532715,
      "learning_rate": 1.7116190476190478e-05,
      "loss": 0.4472,
      "step": 7570
    },
    {
      "epoch": 2.1657142857142855,
      "grad_norm": 0.4946335256099701,
      "learning_rate": 1.7112380952380953e-05,
      "loss": 0.3502,
      "step": 7580
    },
    {
      "epoch": 2.1685714285714286,
      "grad_norm": 11.288015365600586,
      "learning_rate": 1.710857142857143e-05,
      "loss": 0.3611,
      "step": 7590
    },
    {
      "epoch": 2.1714285714285713,
      "grad_norm": 0.4962950050830841,
      "learning_rate": 1.7104761904761908e-05,
      "loss": 0.5913,
      "step": 7600
    },
    {
      "epoch": 2.1742857142857144,
      "grad_norm": 0.6061696410179138,
      "learning_rate": 1.7100952380952383e-05,
      "loss": 0.7867,
      "step": 7610
    },
    {
      "epoch": 2.177142857142857,
      "grad_norm": 0.6144834756851196,
      "learning_rate": 1.709714285714286e-05,
      "loss": 0.3289,
      "step": 7620
    },
    {
      "epoch": 2.18,
      "grad_norm": 0.7638327479362488,
      "learning_rate": 1.7093333333333335e-05,
      "loss": 0.3282,
      "step": 7630
    },
    {
      "epoch": 2.182857142857143,
      "grad_norm": 12.817399024963379,
      "learning_rate": 1.708952380952381e-05,
      "loss": 0.4726,
      "step": 7640
    },
    {
      "epoch": 2.185714285714286,
      "grad_norm": 12.822160720825195,
      "learning_rate": 1.708571428571429e-05,
      "loss": 1.2329,
      "step": 7650
    },
    {
      "epoch": 2.1885714285714286,
      "grad_norm": 0.8358414173126221,
      "learning_rate": 1.7081904761904765e-05,
      "loss": 0.5398,
      "step": 7660
    },
    {
      "epoch": 2.1914285714285713,
      "grad_norm": 0.9806687235832214,
      "learning_rate": 1.707809523809524e-05,
      "loss": 0.4134,
      "step": 7670
    },
    {
      "epoch": 2.1942857142857144,
      "grad_norm": 0.5941669344902039,
      "learning_rate": 1.7074285714285716e-05,
      "loss": 0.3196,
      "step": 7680
    },
    {
      "epoch": 2.197142857142857,
      "grad_norm": 0.39573055505752563,
      "learning_rate": 1.707047619047619e-05,
      "loss": 0.8266,
      "step": 7690
    },
    {
      "epoch": 2.2,
      "grad_norm": 11.424654960632324,
      "learning_rate": 1.706666666666667e-05,
      "loss": 0.3746,
      "step": 7700
    },
    {
      "epoch": 2.202857142857143,
      "grad_norm": 0.27630892395973206,
      "learning_rate": 1.7062857142857143e-05,
      "loss": 0.1307,
      "step": 7710
    },
    {
      "epoch": 2.2057142857142855,
      "grad_norm": 0.2681018114089966,
      "learning_rate": 1.7059047619047618e-05,
      "loss": 0.3879,
      "step": 7720
    },
    {
      "epoch": 2.2085714285714286,
      "grad_norm": 0.2390391230583191,
      "learning_rate": 1.7055238095238097e-05,
      "loss": 0.1381,
      "step": 7730
    },
    {
      "epoch": 2.2114285714285713,
      "grad_norm": 11.499115943908691,
      "learning_rate": 1.7051428571428573e-05,
      "loss": 0.6552,
      "step": 7740
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 0.37731900811195374,
      "learning_rate": 1.704761904761905e-05,
      "loss": 0.6186,
      "step": 7750
    },
    {
      "epoch": 2.217142857142857,
      "grad_norm": 0.46132752299308777,
      "learning_rate": 1.7043809523809524e-05,
      "loss": 0.3586,
      "step": 7760
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.35099825263023376,
      "learning_rate": 1.704e-05,
      "loss": 0.3718,
      "step": 7770
    },
    {
      "epoch": 2.222857142857143,
      "grad_norm": 12.037199020385742,
      "learning_rate": 1.703619047619048e-05,
      "loss": 0.1366,
      "step": 7780
    },
    {
      "epoch": 2.2257142857142855,
      "grad_norm": 12.057619094848633,
      "learning_rate": 1.7032380952380954e-05,
      "loss": 0.2779,
      "step": 7790
    },
    {
      "epoch": 2.2285714285714286,
      "grad_norm": 0.22414937615394592,
      "learning_rate": 1.702857142857143e-05,
      "loss": 0.6736,
      "step": 7800
    },
    {
      "epoch": 2.2314285714285713,
      "grad_norm": 0.2578069567680359,
      "learning_rate": 1.7024761904761905e-05,
      "loss": 0.6473,
      "step": 7810
    },
    {
      "epoch": 2.2342857142857144,
      "grad_norm": 0.3959170877933502,
      "learning_rate": 1.702095238095238e-05,
      "loss": 0.758,
      "step": 7820
    },
    {
      "epoch": 2.237142857142857,
      "grad_norm": 0.49017131328582764,
      "learning_rate": 1.701714285714286e-05,
      "loss": 0.6865,
      "step": 7830
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.0265979766845703,
      "learning_rate": 1.7013333333333335e-05,
      "loss": 1.1902,
      "step": 7840
    },
    {
      "epoch": 2.242857142857143,
      "grad_norm": 11.48239803314209,
      "learning_rate": 1.700952380952381e-05,
      "loss": 0.4657,
      "step": 7850
    },
    {
      "epoch": 2.2457142857142856,
      "grad_norm": 22.068201065063477,
      "learning_rate": 1.7005714285714286e-05,
      "loss": 0.3778,
      "step": 7860
    },
    {
      "epoch": 2.2485714285714287,
      "grad_norm": 10.921528816223145,
      "learning_rate": 1.7001904761904765e-05,
      "loss": 0.7045,
      "step": 7870
    },
    {
      "epoch": 2.2514285714285713,
      "grad_norm": 0.8217891454696655,
      "learning_rate": 1.699809523809524e-05,
      "loss": 0.5133,
      "step": 7880
    },
    {
      "epoch": 2.2542857142857144,
      "grad_norm": 11.054469108581543,
      "learning_rate": 1.6994285714285717e-05,
      "loss": 0.2209,
      "step": 7890
    },
    {
      "epoch": 2.257142857142857,
      "grad_norm": 11.53518295288086,
      "learning_rate": 1.6990476190476192e-05,
      "loss": 0.8762,
      "step": 7900
    },
    {
      "epoch": 2.26,
      "grad_norm": 0.6543729305267334,
      "learning_rate": 1.6986666666666668e-05,
      "loss": 0.335,
      "step": 7910
    },
    {
      "epoch": 2.262857142857143,
      "grad_norm": 0.414997398853302,
      "learning_rate": 1.6982857142857143e-05,
      "loss": 0.23,
      "step": 7920
    },
    {
      "epoch": 2.2657142857142856,
      "grad_norm": 0.3473951518535614,
      "learning_rate": 1.697904761904762e-05,
      "loss": 0.4813,
      "step": 7930
    },
    {
      "epoch": 2.2685714285714287,
      "grad_norm": 0.37351396679878235,
      "learning_rate": 1.6975238095238095e-05,
      "loss": 0.491,
      "step": 7940
    },
    {
      "epoch": 2.2714285714285714,
      "grad_norm": 0.4432970881462097,
      "learning_rate": 1.6971428571428574e-05,
      "loss": 0.6053,
      "step": 7950
    },
    {
      "epoch": 2.2742857142857145,
      "grad_norm": 11.389739036560059,
      "learning_rate": 1.696761904761905e-05,
      "loss": 0.5777,
      "step": 7960
    },
    {
      "epoch": 2.277142857142857,
      "grad_norm": 0.638237714767456,
      "learning_rate": 1.6963809523809525e-05,
      "loss": 0.6835,
      "step": 7970
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.8327764272689819,
      "learning_rate": 1.696e-05,
      "loss": 0.536,
      "step": 7980
    },
    {
      "epoch": 2.282857142857143,
      "grad_norm": 12.446434020996094,
      "learning_rate": 1.6956190476190476e-05,
      "loss": 0.5559,
      "step": 7990
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.6903744339942932,
      "learning_rate": 1.6952380952380955e-05,
      "loss": 0.5599,
      "step": 8000
    },
    {
      "epoch": 2.2885714285714287,
      "grad_norm": 0.457464337348938,
      "learning_rate": 1.694857142857143e-05,
      "loss": 0.2395,
      "step": 8010
    },
    {
      "epoch": 2.2914285714285714,
      "grad_norm": 0.38577431440353394,
      "learning_rate": 1.6944761904761906e-05,
      "loss": 0.3701,
      "step": 8020
    },
    {
      "epoch": 2.2942857142857145,
      "grad_norm": 0.36353158950805664,
      "learning_rate": 1.694095238095238e-05,
      "loss": 0.7217,
      "step": 8030
    },
    {
      "epoch": 2.297142857142857,
      "grad_norm": 11.684937477111816,
      "learning_rate": 1.6937142857142857e-05,
      "loss": 0.8086,
      "step": 8040
    },
    {
      "epoch": 2.3,
      "grad_norm": 10.83754825592041,
      "learning_rate": 1.6933333333333336e-05,
      "loss": 0.2294,
      "step": 8050
    },
    {
      "epoch": 2.302857142857143,
      "grad_norm": 12.606110572814941,
      "learning_rate": 1.692952380952381e-05,
      "loss": 0.4505,
      "step": 8060
    },
    {
      "epoch": 2.3057142857142856,
      "grad_norm": 13.087650299072266,
      "learning_rate": 1.6925714285714287e-05,
      "loss": 0.3629,
      "step": 8070
    },
    {
      "epoch": 2.3085714285714287,
      "grad_norm": 0.5311357975006104,
      "learning_rate": 1.6921904761904763e-05,
      "loss": 0.5737,
      "step": 8080
    },
    {
      "epoch": 2.3114285714285714,
      "grad_norm": 0.7140410542488098,
      "learning_rate": 1.6918095238095242e-05,
      "loss": 0.7834,
      "step": 8090
    },
    {
      "epoch": 2.314285714285714,
      "grad_norm": 1.0783668756484985,
      "learning_rate": 1.6914285714285717e-05,
      "loss": 0.9203,
      "step": 8100
    },
    {
      "epoch": 2.317142857142857,
      "grad_norm": 11.277817726135254,
      "learning_rate": 1.6910476190476193e-05,
      "loss": 0.4819,
      "step": 8110
    },
    {
      "epoch": 2.32,
      "grad_norm": 10.549686431884766,
      "learning_rate": 1.690666666666667e-05,
      "loss": 0.488,
      "step": 8120
    },
    {
      "epoch": 2.322857142857143,
      "grad_norm": 0.941738486289978,
      "learning_rate": 1.6902857142857144e-05,
      "loss": 0.5059,
      "step": 8130
    },
    {
      "epoch": 2.3257142857142856,
      "grad_norm": 0.7728911638259888,
      "learning_rate": 1.689904761904762e-05,
      "loss": 0.3162,
      "step": 8140
    },
    {
      "epoch": 2.3285714285714287,
      "grad_norm": 0.8629781603813171,
      "learning_rate": 1.6895238095238095e-05,
      "loss": 1.0341,
      "step": 8150
    },
    {
      "epoch": 2.3314285714285714,
      "grad_norm": 0.7728316783905029,
      "learning_rate": 1.689142857142857e-05,
      "loss": 0.316,
      "step": 8160
    },
    {
      "epoch": 2.3342857142857145,
      "grad_norm": 0.5731146931648254,
      "learning_rate": 1.688761904761905e-05,
      "loss": 0.224,
      "step": 8170
    },
    {
      "epoch": 2.337142857142857,
      "grad_norm": 11.284674644470215,
      "learning_rate": 1.6883809523809525e-05,
      "loss": 0.3489,
      "step": 8180
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.40921682119369507,
      "learning_rate": 1.688e-05,
      "loss": 0.5826,
      "step": 8190
    },
    {
      "epoch": 2.342857142857143,
      "grad_norm": 0.6169980764389038,
      "learning_rate": 1.6876190476190477e-05,
      "loss": 0.4689,
      "step": 8200
    },
    {
      "epoch": 2.3457142857142856,
      "grad_norm": 13.251067161560059,
      "learning_rate": 1.6872380952380952e-05,
      "loss": 0.6633,
      "step": 8210
    },
    {
      "epoch": 2.3485714285714288,
      "grad_norm": 0.7098477482795715,
      "learning_rate": 1.686857142857143e-05,
      "loss": 0.7607,
      "step": 8220
    },
    {
      "epoch": 2.3514285714285714,
      "grad_norm": 10.956915855407715,
      "learning_rate": 1.6864761904761907e-05,
      "loss": 0.662,
      "step": 8230
    },
    {
      "epoch": 2.354285714285714,
      "grad_norm": 0.6115313768386841,
      "learning_rate": 1.6860952380952382e-05,
      "loss": 0.2276,
      "step": 8240
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 0.4474650025367737,
      "learning_rate": 1.6857142857142858e-05,
      "loss": 0.3506,
      "step": 8250
    },
    {
      "epoch": 2.36,
      "grad_norm": 11.00294017791748,
      "learning_rate": 1.6853333333333333e-05,
      "loss": 0.3728,
      "step": 8260
    },
    {
      "epoch": 2.362857142857143,
      "grad_norm": 11.428618431091309,
      "learning_rate": 1.6849523809523812e-05,
      "loss": 0.3696,
      "step": 8270
    },
    {
      "epoch": 2.3657142857142857,
      "grad_norm": 0.43351221084594727,
      "learning_rate": 1.6845714285714288e-05,
      "loss": 0.8432,
      "step": 8280
    },
    {
      "epoch": 2.3685714285714283,
      "grad_norm": 0.5367809534072876,
      "learning_rate": 1.6841904761904764e-05,
      "loss": 0.5692,
      "step": 8290
    },
    {
      "epoch": 2.3714285714285714,
      "grad_norm": 0.6071076989173889,
      "learning_rate": 1.683809523809524e-05,
      "loss": 0.5524,
      "step": 8300
    },
    {
      "epoch": 2.374285714285714,
      "grad_norm": 0.6218230724334717,
      "learning_rate": 1.6834285714285715e-05,
      "loss": 0.3334,
      "step": 8310
    },
    {
      "epoch": 2.3771428571428572,
      "grad_norm": 23.00596809387207,
      "learning_rate": 1.6830476190476194e-05,
      "loss": 0.7825,
      "step": 8320
    },
    {
      "epoch": 2.38,
      "grad_norm": 0.6776195764541626,
      "learning_rate": 1.682666666666667e-05,
      "loss": 0.5496,
      "step": 8330
    },
    {
      "epoch": 2.382857142857143,
      "grad_norm": 0.9164609313011169,
      "learning_rate": 1.6822857142857145e-05,
      "loss": 0.7371,
      "step": 8340
    },
    {
      "epoch": 2.3857142857142857,
      "grad_norm": 22.53629493713379,
      "learning_rate": 1.681904761904762e-05,
      "loss": 0.4277,
      "step": 8350
    },
    {
      "epoch": 2.388571428571429,
      "grad_norm": 0.7502214312553406,
      "learning_rate": 1.6815238095238096e-05,
      "loss": 0.3167,
      "step": 8360
    },
    {
      "epoch": 2.3914285714285715,
      "grad_norm": 0.6114787459373474,
      "learning_rate": 1.681142857142857e-05,
      "loss": 0.2263,
      "step": 8370
    },
    {
      "epoch": 2.394285714285714,
      "grad_norm": 12.220664024353027,
      "learning_rate": 1.6807619047619047e-05,
      "loss": 0.4524,
      "step": 8380
    },
    {
      "epoch": 2.3971428571428572,
      "grad_norm": 0.6789743304252625,
      "learning_rate": 1.6803809523809523e-05,
      "loss": 0.6737,
      "step": 8390
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6390244364738464,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.2254,
      "step": 8400
    },
    {
      "epoch": 2.402857142857143,
      "grad_norm": 0.564583420753479,
      "learning_rate": 1.6796190476190477e-05,
      "loss": 0.5606,
      "step": 8410
    },
    {
      "epoch": 2.4057142857142857,
      "grad_norm": 23.310882568359375,
      "learning_rate": 1.6792380952380953e-05,
      "loss": 0.6612,
      "step": 8420
    },
    {
      "epoch": 2.4085714285714284,
      "grad_norm": 0.5818997621536255,
      "learning_rate": 1.678857142857143e-05,
      "loss": 0.1184,
      "step": 8430
    },
    {
      "epoch": 2.4114285714285715,
      "grad_norm": 11.019933700561523,
      "learning_rate": 1.6784761904761907e-05,
      "loss": 0.6814,
      "step": 8440
    },
    {
      "epoch": 2.414285714285714,
      "grad_norm": 0.5779315233230591,
      "learning_rate": 1.6780952380952383e-05,
      "loss": 0.4583,
      "step": 8450
    },
    {
      "epoch": 2.4171428571428573,
      "grad_norm": 0.6505897641181946,
      "learning_rate": 1.677714285714286e-05,
      "loss": 0.7665,
      "step": 8460
    },
    {
      "epoch": 2.42,
      "grad_norm": 10.694784164428711,
      "learning_rate": 1.6773333333333334e-05,
      "loss": 0.7327,
      "step": 8470
    },
    {
      "epoch": 2.422857142857143,
      "grad_norm": 10.707112312316895,
      "learning_rate": 1.676952380952381e-05,
      "loss": 0.4239,
      "step": 8480
    },
    {
      "epoch": 2.4257142857142857,
      "grad_norm": 10.776844024658203,
      "learning_rate": 1.676571428571429e-05,
      "loss": 0.6097,
      "step": 8490
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 0.7935185432434082,
      "learning_rate": 1.6761904761904764e-05,
      "loss": 0.3098,
      "step": 8500
    },
    {
      "epoch": 2.4314285714285715,
      "grad_norm": 0.5124439001083374,
      "learning_rate": 1.675809523809524e-05,
      "loss": 0.4618,
      "step": 8510
    },
    {
      "epoch": 2.434285714285714,
      "grad_norm": 10.89366340637207,
      "learning_rate": 1.6754285714285716e-05,
      "loss": 0.8011,
      "step": 8520
    },
    {
      "epoch": 2.4371428571428573,
      "grad_norm": 0.5372994542121887,
      "learning_rate": 1.675047619047619e-05,
      "loss": 0.232,
      "step": 8530
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.5499999523162842,
      "learning_rate": 1.674666666666667e-05,
      "loss": 0.3424,
      "step": 8540
    },
    {
      "epoch": 2.442857142857143,
      "grad_norm": 0.6554334759712219,
      "learning_rate": 1.6742857142857146e-05,
      "loss": 0.4503,
      "step": 8550
    },
    {
      "epoch": 2.4457142857142857,
      "grad_norm": 0.6189156770706177,
      "learning_rate": 1.673904761904762e-05,
      "loss": 0.5531,
      "step": 8560
    },
    {
      "epoch": 2.4485714285714284,
      "grad_norm": 0.5129944086074829,
      "learning_rate": 1.6735238095238097e-05,
      "loss": 0.4651,
      "step": 8570
    },
    {
      "epoch": 2.4514285714285715,
      "grad_norm": 0.3519499599933624,
      "learning_rate": 1.6731428571428572e-05,
      "loss": 0.1265,
      "step": 8580
    },
    {
      "epoch": 2.454285714285714,
      "grad_norm": 11.653691291809082,
      "learning_rate": 1.6727619047619048e-05,
      "loss": 0.8552,
      "step": 8590
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 0.570468008518219,
      "learning_rate": 1.6723809523809524e-05,
      "loss": 0.5836,
      "step": 8600
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.5625223517417908,
      "learning_rate": 1.672e-05,
      "loss": 0.3362,
      "step": 8610
    },
    {
      "epoch": 2.4628571428571426,
      "grad_norm": 0.6424278616905212,
      "learning_rate": 1.6716190476190478e-05,
      "loss": 0.9901,
      "step": 8620
    },
    {
      "epoch": 2.4657142857142857,
      "grad_norm": 0.6413211822509766,
      "learning_rate": 1.6712380952380954e-05,
      "loss": 0.4338,
      "step": 8630
    },
    {
      "epoch": 2.4685714285714284,
      "grad_norm": 0.553088366985321,
      "learning_rate": 1.670857142857143e-05,
      "loss": 0.3319,
      "step": 8640
    },
    {
      "epoch": 2.4714285714285715,
      "grad_norm": 0.7441272139549255,
      "learning_rate": 1.6704761904761905e-05,
      "loss": 0.8827,
      "step": 8650
    },
    {
      "epoch": 2.474285714285714,
      "grad_norm": 0.8492759466171265,
      "learning_rate": 1.670095238095238e-05,
      "loss": 0.5196,
      "step": 8660
    },
    {
      "epoch": 2.4771428571428573,
      "grad_norm": 0.7834354639053345,
      "learning_rate": 1.669714285714286e-05,
      "loss": 0.3116,
      "step": 8670
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5368080735206604,
      "learning_rate": 1.6693333333333335e-05,
      "loss": 0.3309,
      "step": 8680
    },
    {
      "epoch": 2.482857142857143,
      "grad_norm": 10.756223678588867,
      "learning_rate": 1.668952380952381e-05,
      "loss": 1.4257,
      "step": 8690
    },
    {
      "epoch": 2.4857142857142858,
      "grad_norm": 0.748536229133606,
      "learning_rate": 1.6685714285714286e-05,
      "loss": 0.3255,
      "step": 8700
    },
    {
      "epoch": 2.4885714285714284,
      "grad_norm": 0.5984383225440979,
      "learning_rate": 1.6681904761904765e-05,
      "loss": 0.4397,
      "step": 8710
    },
    {
      "epoch": 2.4914285714285715,
      "grad_norm": 0.697219967842102,
      "learning_rate": 1.667809523809524e-05,
      "loss": 0.5481,
      "step": 8720
    },
    {
      "epoch": 2.494285714285714,
      "grad_norm": 10.728705406188965,
      "learning_rate": 1.6674285714285716e-05,
      "loss": 0.7469,
      "step": 8730
    },
    {
      "epoch": 2.4971428571428573,
      "grad_norm": 10.757943153381348,
      "learning_rate": 1.6670476190476192e-05,
      "loss": 0.337,
      "step": 8740
    },
    {
      "epoch": 2.5,
      "grad_norm": 11.94881534576416,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.4556,
      "step": 8750
    },
    {
      "epoch": 2.5028571428571427,
      "grad_norm": 0.4404924213886261,
      "learning_rate": 1.6662857142857146e-05,
      "loss": 0.1234,
      "step": 8760
    },
    {
      "epoch": 2.505714285714286,
      "grad_norm": 0.40444886684417725,
      "learning_rate": 1.6659047619047622e-05,
      "loss": 0.4842,
      "step": 8770
    },
    {
      "epoch": 2.5085714285714285,
      "grad_norm": 0.33231377601623535,
      "learning_rate": 1.6655238095238098e-05,
      "loss": 0.3704,
      "step": 8780
    },
    {
      "epoch": 2.5114285714285716,
      "grad_norm": 10.952231407165527,
      "learning_rate": 1.6651428571428573e-05,
      "loss": 0.7388,
      "step": 8790
    },
    {
      "epoch": 2.5142857142857142,
      "grad_norm": 0.3825156092643738,
      "learning_rate": 1.664761904761905e-05,
      "loss": 0.0086,
      "step": 8800
    },
    {
      "epoch": 2.517142857142857,
      "grad_norm": 0.3111182153224945,
      "learning_rate": 1.6643809523809524e-05,
      "loss": 0.4921,
      "step": 8810
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.4032742381095886,
      "learning_rate": 1.664e-05,
      "loss": 0.8527,
      "step": 8820
    },
    {
      "epoch": 2.522857142857143,
      "grad_norm": 22.266685485839844,
      "learning_rate": 1.6636190476190476e-05,
      "loss": 0.813,
      "step": 8830
    },
    {
      "epoch": 2.525714285714286,
      "grad_norm": 10.798443794250488,
      "learning_rate": 1.6632380952380954e-05,
      "loss": 0.561,
      "step": 8840
    },
    {
      "epoch": 2.5285714285714285,
      "grad_norm": 0.5995010733604431,
      "learning_rate": 1.662857142857143e-05,
      "loss": 0.4433,
      "step": 8850
    },
    {
      "epoch": 2.5314285714285716,
      "grad_norm": 0.7586436867713928,
      "learning_rate": 1.6624761904761906e-05,
      "loss": 0.7565,
      "step": 8860
    },
    {
      "epoch": 2.5342857142857143,
      "grad_norm": 0.9838625192642212,
      "learning_rate": 1.662095238095238e-05,
      "loss": 0.6195,
      "step": 8870
    },
    {
      "epoch": 2.5371428571428574,
      "grad_norm": 10.453765869140625,
      "learning_rate": 1.6617142857142857e-05,
      "loss": 0.5129,
      "step": 8880
    },
    {
      "epoch": 2.54,
      "grad_norm": 10.514472961425781,
      "learning_rate": 1.6613333333333336e-05,
      "loss": 0.509,
      "step": 8890
    },
    {
      "epoch": 2.5428571428571427,
      "grad_norm": 0.9566623568534851,
      "learning_rate": 1.660952380952381e-05,
      "loss": 0.4084,
      "step": 8900
    },
    {
      "epoch": 2.545714285714286,
      "grad_norm": 10.877822875976562,
      "learning_rate": 1.6605714285714287e-05,
      "loss": 0.2269,
      "step": 8910
    },
    {
      "epoch": 2.5485714285714285,
      "grad_norm": 0.6761630773544312,
      "learning_rate": 1.6601904761904763e-05,
      "loss": 0.9848,
      "step": 8920
    },
    {
      "epoch": 2.5514285714285716,
      "grad_norm": 0.46512702107429504,
      "learning_rate": 1.659809523809524e-05,
      "loss": 0.0126,
      "step": 8930
    },
    {
      "epoch": 2.5542857142857143,
      "grad_norm": 11.43159008026123,
      "learning_rate": 1.6594285714285717e-05,
      "loss": 0.8326,
      "step": 8940
    },
    {
      "epoch": 2.557142857142857,
      "grad_norm": 0.48677530884742737,
      "learning_rate": 1.6590476190476193e-05,
      "loss": 0.3574,
      "step": 8950
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.4765090048313141,
      "learning_rate": 1.6586666666666668e-05,
      "loss": 0.5828,
      "step": 8960
    },
    {
      "epoch": 2.5628571428571427,
      "grad_norm": 11.2376127243042,
      "learning_rate": 1.6582857142857144e-05,
      "loss": 0.6947,
      "step": 8970
    },
    {
      "epoch": 2.565714285714286,
      "grad_norm": 0.6513447165489197,
      "learning_rate": 1.6579047619047623e-05,
      "loss": 0.3381,
      "step": 8980
    },
    {
      "epoch": 2.5685714285714285,
      "grad_norm": 0.569475531578064,
      "learning_rate": 1.65752380952381e-05,
      "loss": 0.3395,
      "step": 8990
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 0.5146864056587219,
      "learning_rate": 1.6571428571428574e-05,
      "loss": 0.5667,
      "step": 9000
    },
    {
      "epoch": 2.5742857142857143,
      "grad_norm": 10.944260597229004,
      "learning_rate": 1.656761904761905e-05,
      "loss": 0.3468,
      "step": 9010
    },
    {
      "epoch": 2.5771428571428574,
      "grad_norm": 0.5301253199577332,
      "learning_rate": 1.6563809523809525e-05,
      "loss": 0.6927,
      "step": 9020
    },
    {
      "epoch": 2.58,
      "grad_norm": 0.5171735286712646,
      "learning_rate": 1.656e-05,
      "loss": 0.3447,
      "step": 9030
    },
    {
      "epoch": 2.5828571428571427,
      "grad_norm": 11.279632568359375,
      "learning_rate": 1.6556190476190476e-05,
      "loss": 0.5722,
      "step": 9040
    },
    {
      "epoch": 2.585714285714286,
      "grad_norm": 11.16855239868164,
      "learning_rate": 1.6552380952380952e-05,
      "loss": 0.3431,
      "step": 9050
    },
    {
      "epoch": 2.5885714285714285,
      "grad_norm": 0.4890799820423126,
      "learning_rate": 1.654857142857143e-05,
      "loss": 0.5732,
      "step": 9060
    },
    {
      "epoch": 2.5914285714285716,
      "grad_norm": 0.49775922298431396,
      "learning_rate": 1.6544761904761906e-05,
      "loss": 0.5804,
      "step": 9070
    },
    {
      "epoch": 2.5942857142857143,
      "grad_norm": 0.5335886478424072,
      "learning_rate": 1.6540952380952382e-05,
      "loss": 0.4552,
      "step": 9080
    },
    {
      "epoch": 2.597142857142857,
      "grad_norm": 0.5291659235954285,
      "learning_rate": 1.6537142857142858e-05,
      "loss": 0.3469,
      "step": 9090
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5389471054077148,
      "learning_rate": 1.6533333333333333e-05,
      "loss": 0.4533,
      "step": 9100
    },
    {
      "epoch": 2.6028571428571428,
      "grad_norm": 0.5166846513748169,
      "learning_rate": 1.6529523809523812e-05,
      "loss": 0.571,
      "step": 9110
    },
    {
      "epoch": 2.605714285714286,
      "grad_norm": 0.5538206696510315,
      "learning_rate": 1.6525714285714288e-05,
      "loss": 0.5676,
      "step": 9120
    },
    {
      "epoch": 2.6085714285714285,
      "grad_norm": 10.717747688293457,
      "learning_rate": 1.6521904761904763e-05,
      "loss": 0.5583,
      "step": 9130
    },
    {
      "epoch": 2.611428571428571,
      "grad_norm": 0.6230908036231995,
      "learning_rate": 1.651809523809524e-05,
      "loss": 0.3393,
      "step": 9140
    },
    {
      "epoch": 2.6142857142857143,
      "grad_norm": 22.04818344116211,
      "learning_rate": 1.6514285714285714e-05,
      "loss": 0.5431,
      "step": 9150
    },
    {
      "epoch": 2.617142857142857,
      "grad_norm": 11.00623893737793,
      "learning_rate": 1.6510476190476193e-05,
      "loss": 0.5479,
      "step": 9160
    },
    {
      "epoch": 2.62,
      "grad_norm": 0.5704330205917358,
      "learning_rate": 1.650666666666667e-05,
      "loss": 0.3399,
      "step": 9170
    },
    {
      "epoch": 2.6228571428571428,
      "grad_norm": 0.500281035900116,
      "learning_rate": 1.6502857142857145e-05,
      "loss": 0.6803,
      "step": 9180
    },
    {
      "epoch": 2.6257142857142854,
      "grad_norm": 0.5131048560142517,
      "learning_rate": 1.649904761904762e-05,
      "loss": 0.6869,
      "step": 9190
    },
    {
      "epoch": 2.6285714285714286,
      "grad_norm": 10.888687133789062,
      "learning_rate": 1.64952380952381e-05,
      "loss": 0.4533,
      "step": 9200
    },
    {
      "epoch": 2.6314285714285717,
      "grad_norm": 10.987911224365234,
      "learning_rate": 1.6491428571428575e-05,
      "loss": 0.2395,
      "step": 9210
    },
    {
      "epoch": 2.6342857142857143,
      "grad_norm": 0.550995945930481,
      "learning_rate": 1.648761904761905e-05,
      "loss": 0.703,
      "step": 9220
    },
    {
      "epoch": 2.637142857142857,
      "grad_norm": 0.5708328485488892,
      "learning_rate": 1.6483809523809522e-05,
      "loss": 0.4567,
      "step": 9230
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.5382339358329773,
      "learning_rate": 1.648e-05,
      "loss": 0.3453,
      "step": 9240
    },
    {
      "epoch": 2.642857142857143,
      "grad_norm": 0.5170213580131531,
      "learning_rate": 1.6476190476190477e-05,
      "loss": 0.6818,
      "step": 9250
    },
    {
      "epoch": 2.645714285714286,
      "grad_norm": 10.94387435913086,
      "learning_rate": 1.6472380952380953e-05,
      "loss": 0.6711,
      "step": 9260
    },
    {
      "epoch": 2.6485714285714286,
      "grad_norm": 0.7167933583259583,
      "learning_rate": 1.6468571428571428e-05,
      "loss": 0.5433,
      "step": 9270
    },
    {
      "epoch": 2.6514285714285712,
      "grad_norm": 11.802412986755371,
      "learning_rate": 1.6464761904761907e-05,
      "loss": 0.5155,
      "step": 9280
    },
    {
      "epoch": 2.6542857142857144,
      "grad_norm": 10.32524299621582,
      "learning_rate": 1.6460952380952383e-05,
      "loss": 0.8875,
      "step": 9290
    },
    {
      "epoch": 2.657142857142857,
      "grad_norm": 1.226469874382019,
      "learning_rate": 1.645714285714286e-05,
      "loss": 0.2906,
      "step": 9300
    },
    {
      "epoch": 2.66,
      "grad_norm": 21.774127960205078,
      "learning_rate": 1.6453333333333334e-05,
      "loss": 0.5895,
      "step": 9310
    },
    {
      "epoch": 2.662857142857143,
      "grad_norm": 0.7569006085395813,
      "learning_rate": 1.644952380952381e-05,
      "loss": 0.4154,
      "step": 9320
    },
    {
      "epoch": 2.6657142857142855,
      "grad_norm": 22.795778274536133,
      "learning_rate": 1.644571428571429e-05,
      "loss": 0.4422,
      "step": 9330
    },
    {
      "epoch": 2.6685714285714286,
      "grad_norm": 0.5977811813354492,
      "learning_rate": 1.6441904761904764e-05,
      "loss": 0.676,
      "step": 9340
    },
    {
      "epoch": 2.6714285714285713,
      "grad_norm": 0.5001989603042603,
      "learning_rate": 1.643809523809524e-05,
      "loss": 0.6906,
      "step": 9350
    },
    {
      "epoch": 2.6742857142857144,
      "grad_norm": 10.8114595413208,
      "learning_rate": 1.6434285714285715e-05,
      "loss": 0.4568,
      "step": 9360
    },
    {
      "epoch": 2.677142857142857,
      "grad_norm": 11.191290855407715,
      "learning_rate": 1.643047619047619e-05,
      "loss": 0.5711,
      "step": 9370
    },
    {
      "epoch": 2.68,
      "grad_norm": 10.829442977905273,
      "learning_rate": 1.642666666666667e-05,
      "loss": 0.235,
      "step": 9380
    },
    {
      "epoch": 2.682857142857143,
      "grad_norm": 0.47373276948928833,
      "learning_rate": 1.6422857142857145e-05,
      "loss": 0.2417,
      "step": 9390
    },
    {
      "epoch": 2.685714285714286,
      "grad_norm": 0.3453316390514374,
      "learning_rate": 1.641904761904762e-05,
      "loss": 0.1317,
      "step": 9400
    },
    {
      "epoch": 2.6885714285714286,
      "grad_norm": 0.30733683705329895,
      "learning_rate": 1.6415238095238097e-05,
      "loss": 0.5074,
      "step": 9410
    },
    {
      "epoch": 2.6914285714285713,
      "grad_norm": 0.3453972637653351,
      "learning_rate": 1.6411428571428572e-05,
      "loss": 0.9872,
      "step": 9420
    },
    {
      "epoch": 2.6942857142857144,
      "grad_norm": 0.5104478597640991,
      "learning_rate": 1.640761904761905e-05,
      "loss": 0.9505,
      "step": 9430
    },
    {
      "epoch": 2.697142857142857,
      "grad_norm": 0.5820491313934326,
      "learning_rate": 1.6403809523809523e-05,
      "loss": 0.4498,
      "step": 9440
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.6104084253311157,
      "learning_rate": 1.64e-05,
      "loss": 0.6618,
      "step": 9450
    },
    {
      "epoch": 2.702857142857143,
      "grad_norm": 10.722606658935547,
      "learning_rate": 1.6396190476190478e-05,
      "loss": 0.3356,
      "step": 9460
    },
    {
      "epoch": 2.7057142857142855,
      "grad_norm": 10.935546875,
      "learning_rate": 1.6392380952380953e-05,
      "loss": 0.673,
      "step": 9470
    },
    {
      "epoch": 2.7085714285714286,
      "grad_norm": 0.5585514903068542,
      "learning_rate": 1.638857142857143e-05,
      "loss": 0.2337,
      "step": 9480
    },
    {
      "epoch": 2.7114285714285713,
      "grad_norm": 0.4914800822734833,
      "learning_rate": 1.6384761904761905e-05,
      "loss": 0.4527,
      "step": 9490
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 10.99062728881836,
      "learning_rate": 1.6380952380952384e-05,
      "loss": 0.5759,
      "step": 9500
    },
    {
      "epoch": 2.717142857142857,
      "grad_norm": 0.4072802662849426,
      "learning_rate": 1.637714285714286e-05,
      "loss": 0.4716,
      "step": 9510
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.415391743183136,
      "learning_rate": 1.6373333333333335e-05,
      "loss": 0.3608,
      "step": 9520
    },
    {
      "epoch": 2.722857142857143,
      "grad_norm": 0.4074466824531555,
      "learning_rate": 1.636952380952381e-05,
      "loss": 0.3599,
      "step": 9530
    },
    {
      "epoch": 2.725714285714286,
      "grad_norm": 22.257946014404297,
      "learning_rate": 1.6365714285714286e-05,
      "loss": 0.4845,
      "step": 9540
    },
    {
      "epoch": 2.7285714285714286,
      "grad_norm": 0.4514903128147125,
      "learning_rate": 1.6361904761904765e-05,
      "loss": 0.8354,
      "step": 9550
    },
    {
      "epoch": 2.7314285714285713,
      "grad_norm": 0.5383499264717102,
      "learning_rate": 1.635809523809524e-05,
      "loss": 0.3522,
      "step": 9560
    },
    {
      "epoch": 2.7342857142857144,
      "grad_norm": 13.06038761138916,
      "learning_rate": 1.6354285714285716e-05,
      "loss": 0.3506,
      "step": 9570
    },
    {
      "epoch": 2.737142857142857,
      "grad_norm": 0.5865683555603027,
      "learning_rate": 1.635047619047619e-05,
      "loss": 0.3433,
      "step": 9580
    },
    {
      "epoch": 2.74,
      "grad_norm": 0.48699596524238586,
      "learning_rate": 1.6346666666666667e-05,
      "loss": 0.2335,
      "step": 9590
    },
    {
      "epoch": 2.742857142857143,
      "grad_norm": 22.228593826293945,
      "learning_rate": 1.6342857142857146e-05,
      "loss": 0.917,
      "step": 9600
    },
    {
      "epoch": 2.7457142857142856,
      "grad_norm": 10.88218879699707,
      "learning_rate": 1.633904761904762e-05,
      "loss": 0.4562,
      "step": 9610
    },
    {
      "epoch": 2.7485714285714287,
      "grad_norm": 0.5861468315124512,
      "learning_rate": 1.6335238095238097e-05,
      "loss": 0.5645,
      "step": 9620
    },
    {
      "epoch": 2.7514285714285713,
      "grad_norm": 0.5976998805999756,
      "learning_rate": 1.6331428571428573e-05,
      "loss": 0.4534,
      "step": 9630
    },
    {
      "epoch": 2.7542857142857144,
      "grad_norm": 10.63790512084961,
      "learning_rate": 1.632761904761905e-05,
      "loss": 0.975,
      "step": 9640
    },
    {
      "epoch": 2.757142857142857,
      "grad_norm": 10.778877258300781,
      "learning_rate": 1.6323809523809527e-05,
      "loss": 0.431,
      "step": 9650
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.637293815612793,
      "learning_rate": 1.632e-05,
      "loss": 0.1203,
      "step": 9660
    },
    {
      "epoch": 2.762857142857143,
      "grad_norm": 11.273761749267578,
      "learning_rate": 1.6316190476190475e-05,
      "loss": 0.6746,
      "step": 9670
    },
    {
      "epoch": 2.7657142857142856,
      "grad_norm": 11.631277084350586,
      "learning_rate": 1.6312380952380954e-05,
      "loss": 0.6754,
      "step": 9680
    },
    {
      "epoch": 2.7685714285714287,
      "grad_norm": 0.753779411315918,
      "learning_rate": 1.630857142857143e-05,
      "loss": 0.3254,
      "step": 9690
    },
    {
      "epoch": 2.7714285714285714,
      "grad_norm": 10.909960746765137,
      "learning_rate": 1.6304761904761905e-05,
      "loss": 0.4307,
      "step": 9700
    },
    {
      "epoch": 2.774285714285714,
      "grad_norm": 11.088881492614746,
      "learning_rate": 1.630095238095238e-05,
      "loss": 0.6662,
      "step": 9710
    },
    {
      "epoch": 2.777142857142857,
      "grad_norm": 0.5930478572845459,
      "learning_rate": 1.6297142857142856e-05,
      "loss": 0.4474,
      "step": 9720
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 0.5865936279296875,
      "learning_rate": 1.6293333333333335e-05,
      "loss": 0.4443,
      "step": 9730
    },
    {
      "epoch": 2.782857142857143,
      "grad_norm": 0.7084605097770691,
      "learning_rate": 1.628952380952381e-05,
      "loss": 0.7622,
      "step": 9740
    },
    {
      "epoch": 2.7857142857142856,
      "grad_norm": 0.6009750366210938,
      "learning_rate": 1.6285714285714287e-05,
      "loss": 0.2291,
      "step": 9750
    },
    {
      "epoch": 2.7885714285714287,
      "grad_norm": 0.4994572103023529,
      "learning_rate": 1.6281904761904762e-05,
      "loss": 0.3505,
      "step": 9760
    },
    {
      "epoch": 2.7914285714285714,
      "grad_norm": 12.25246524810791,
      "learning_rate": 1.627809523809524e-05,
      "loss": 0.8932,
      "step": 9770
    },
    {
      "epoch": 2.7942857142857145,
      "grad_norm": 0.8556231260299683,
      "learning_rate": 1.6274285714285717e-05,
      "loss": 0.4185,
      "step": 9780
    },
    {
      "epoch": 2.797142857142857,
      "grad_norm": 0.6910089254379272,
      "learning_rate": 1.6270476190476192e-05,
      "loss": 0.4369,
      "step": 9790
    },
    {
      "epoch": 2.8,
      "grad_norm": 10.831052780151367,
      "learning_rate": 1.6266666666666668e-05,
      "loss": 0.4452,
      "step": 9800
    },
    {
      "epoch": 2.802857142857143,
      "grad_norm": 0.6321988105773926,
      "learning_rate": 1.6262857142857143e-05,
      "loss": 0.8828,
      "step": 9810
    },
    {
      "epoch": 2.8057142857142856,
      "grad_norm": 10.745348930358887,
      "learning_rate": 1.6259047619047622e-05,
      "loss": 0.4386,
      "step": 9820
    },
    {
      "epoch": 2.8085714285714287,
      "grad_norm": 0.7606341242790222,
      "learning_rate": 1.6255238095238098e-05,
      "loss": 0.534,
      "step": 9830
    },
    {
      "epoch": 2.8114285714285714,
      "grad_norm": 10.80136775970459,
      "learning_rate": 1.6251428571428574e-05,
      "loss": 0.5345,
      "step": 9840
    },
    {
      "epoch": 2.814285714285714,
      "grad_norm": 0.9010722637176514,
      "learning_rate": 1.624761904761905e-05,
      "loss": 1.0189,
      "step": 9850
    },
    {
      "epoch": 2.817142857142857,
      "grad_norm": 0.7582260370254517,
      "learning_rate": 1.6243809523809525e-05,
      "loss": 0.1207,
      "step": 9860
    },
    {
      "epoch": 2.82,
      "grad_norm": 0.6506161093711853,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.5357,
      "step": 9870
    },
    {
      "epoch": 2.822857142857143,
      "grad_norm": 10.778547286987305,
      "learning_rate": 1.6236190476190476e-05,
      "loss": 0.5489,
      "step": 9880
    },
    {
      "epoch": 2.8257142857142856,
      "grad_norm": 0.5576785802841187,
      "learning_rate": 1.623238095238095e-05,
      "loss": 0.4524,
      "step": 9890
    },
    {
      "epoch": 2.8285714285714287,
      "grad_norm": 21.994165420532227,
      "learning_rate": 1.622857142857143e-05,
      "loss": 0.7812,
      "step": 9900
    },
    {
      "epoch": 2.8314285714285714,
      "grad_norm": 0.5534052848815918,
      "learning_rate": 1.6224761904761906e-05,
      "loss": 0.4456,
      "step": 9910
    },
    {
      "epoch": 2.8342857142857145,
      "grad_norm": 0.5262229442596436,
      "learning_rate": 1.622095238095238e-05,
      "loss": 0.234,
      "step": 9920
    },
    {
      "epoch": 2.837142857142857,
      "grad_norm": 10.96417236328125,
      "learning_rate": 1.6217142857142857e-05,
      "loss": 0.8179,
      "step": 9930
    },
    {
      "epoch": 2.84,
      "grad_norm": 22.08131980895996,
      "learning_rate": 1.6213333333333333e-05,
      "loss": 0.466,
      "step": 9940
    },
    {
      "epoch": 2.842857142857143,
      "grad_norm": 0.4806840121746063,
      "learning_rate": 1.6209523809523812e-05,
      "loss": 0.5763,
      "step": 9950
    },
    {
      "epoch": 2.8457142857142856,
      "grad_norm": 10.843385696411133,
      "learning_rate": 1.6205714285714287e-05,
      "loss": 0.5593,
      "step": 9960
    },
    {
      "epoch": 2.8485714285714288,
      "grad_norm": 22.018232345581055,
      "learning_rate": 1.6201904761904763e-05,
      "loss": 0.7432,
      "step": 9970
    },
    {
      "epoch": 2.8514285714285714,
      "grad_norm": 12.07875919342041,
      "learning_rate": 1.619809523809524e-05,
      "loss": 0.741,
      "step": 9980
    },
    {
      "epoch": 2.854285714285714,
      "grad_norm": 10.732928276062012,
      "learning_rate": 1.6194285714285714e-05,
      "loss": 0.3207,
      "step": 9990
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 10.888436317443848,
      "learning_rate": 1.6190476190476193e-05,
      "loss": 0.6326,
      "step": 10000
    },
    {
      "epoch": 2.86,
      "grad_norm": 0.6970647573471069,
      "learning_rate": 1.618666666666667e-05,
      "loss": 0.3259,
      "step": 10010
    },
    {
      "epoch": 2.862857142857143,
      "grad_norm": 10.884135246276855,
      "learning_rate": 1.6182857142857144e-05,
      "loss": 1.1888,
      "step": 10020
    },
    {
      "epoch": 2.8657142857142857,
      "grad_norm": 0.7262569069862366,
      "learning_rate": 1.617904761904762e-05,
      "loss": 0.5386,
      "step": 10030
    },
    {
      "epoch": 2.8685714285714283,
      "grad_norm": 0.739236056804657,
      "learning_rate": 1.61752380952381e-05,
      "loss": 0.4277,
      "step": 10040
    },
    {
      "epoch": 2.8714285714285714,
      "grad_norm": 0.6566290855407715,
      "learning_rate": 1.6171428571428574e-05,
      "loss": 0.2221,
      "step": 10050
    },
    {
      "epoch": 2.8742857142857146,
      "grad_norm": 0.5553624629974365,
      "learning_rate": 1.616761904761905e-05,
      "loss": 0.3425,
      "step": 10060
    },
    {
      "epoch": 2.8771428571428572,
      "grad_norm": 0.5216726660728455,
      "learning_rate": 1.6163809523809526e-05,
      "loss": 0.3461,
      "step": 10070
    },
    {
      "epoch": 2.88,
      "grad_norm": 10.886784553527832,
      "learning_rate": 1.616e-05,
      "loss": 0.6807,
      "step": 10080
    },
    {
      "epoch": 2.882857142857143,
      "grad_norm": 10.951362609863281,
      "learning_rate": 1.6156190476190477e-05,
      "loss": 0.786,
      "step": 10090
    },
    {
      "epoch": 2.8857142857142857,
      "grad_norm": 0.5722193121910095,
      "learning_rate": 1.6152380952380952e-05,
      "loss": 0.2278,
      "step": 10100
    },
    {
      "epoch": 2.888571428571429,
      "grad_norm": 0.5796351432800293,
      "learning_rate": 1.6148571428571428e-05,
      "loss": 0.4426,
      "step": 10110
    },
    {
      "epoch": 2.8914285714285715,
      "grad_norm": 0.48578035831451416,
      "learning_rate": 1.6144761904761907e-05,
      "loss": 0.5718,
      "step": 10120
    },
    {
      "epoch": 2.894285714285714,
      "grad_norm": 10.84104061126709,
      "learning_rate": 1.6140952380952382e-05,
      "loss": 0.7959,
      "step": 10130
    },
    {
      "epoch": 2.8971428571428572,
      "grad_norm": 0.5400841236114502,
      "learning_rate": 1.6137142857142858e-05,
      "loss": 0.3396,
      "step": 10140
    },
    {
      "epoch": 2.9,
      "grad_norm": 10.98891830444336,
      "learning_rate": 1.6133333333333334e-05,
      "loss": 0.24,
      "step": 10150
    },
    {
      "epoch": 2.902857142857143,
      "grad_norm": 0.4740317463874817,
      "learning_rate": 1.612952380952381e-05,
      "loss": 0.8146,
      "step": 10160
    },
    {
      "epoch": 2.9057142857142857,
      "grad_norm": 0.48488402366638184,
      "learning_rate": 1.6125714285714288e-05,
      "loss": 0.5833,
      "step": 10170
    },
    {
      "epoch": 2.9085714285714284,
      "grad_norm": 0.4924218952655792,
      "learning_rate": 1.6121904761904764e-05,
      "loss": 0.6887,
      "step": 10180
    },
    {
      "epoch": 2.9114285714285715,
      "grad_norm": 11.027469635009766,
      "learning_rate": 1.611809523809524e-05,
      "loss": 0.697,
      "step": 10190
    },
    {
      "epoch": 2.914285714285714,
      "grad_norm": 0.5427646636962891,
      "learning_rate": 1.6114285714285715e-05,
      "loss": 0.4593,
      "step": 10200
    },
    {
      "epoch": 2.9171428571428573,
      "grad_norm": 11.359371185302734,
      "learning_rate": 1.611047619047619e-05,
      "loss": 0.6735,
      "step": 10210
    },
    {
      "epoch": 2.92,
      "grad_norm": 10.690467834472656,
      "learning_rate": 1.610666666666667e-05,
      "loss": 0.985,
      "step": 10220
    },
    {
      "epoch": 2.9228571428571426,
      "grad_norm": 0.7336042523384094,
      "learning_rate": 1.6102857142857145e-05,
      "loss": 0.4303,
      "step": 10230
    },
    {
      "epoch": 2.9257142857142857,
      "grad_norm": 0.7810455560684204,
      "learning_rate": 1.609904761904762e-05,
      "loss": 0.6332,
      "step": 10240
    },
    {
      "epoch": 2.928571428571429,
      "grad_norm": 0.7105050683021545,
      "learning_rate": 1.6095238095238096e-05,
      "loss": 0.2204,
      "step": 10250
    },
    {
      "epoch": 2.9314285714285715,
      "grad_norm": 22.020383834838867,
      "learning_rate": 1.6091428571428572e-05,
      "loss": 0.4468,
      "step": 10260
    },
    {
      "epoch": 2.934285714285714,
      "grad_norm": 0.5037018656730652,
      "learning_rate": 1.608761904761905e-05,
      "loss": 0.2303,
      "step": 10270
    },
    {
      "epoch": 2.9371428571428573,
      "grad_norm": 0.5216553807258606,
      "learning_rate": 1.6083809523809526e-05,
      "loss": 0.4578,
      "step": 10280
    },
    {
      "epoch": 2.94,
      "grad_norm": 0.494780570268631,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.5778,
      "step": 10290
    },
    {
      "epoch": 2.942857142857143,
      "grad_norm": 23.01618766784668,
      "learning_rate": 1.6076190476190477e-05,
      "loss": 0.3603,
      "step": 10300
    },
    {
      "epoch": 2.9457142857142857,
      "grad_norm": 11.242435455322266,
      "learning_rate": 1.6072380952380953e-05,
      "loss": 0.9506,
      "step": 10310
    },
    {
      "epoch": 2.9485714285714284,
      "grad_norm": 11.31688404083252,
      "learning_rate": 1.606857142857143e-05,
      "loss": 0.6844,
      "step": 10320
    },
    {
      "epoch": 2.9514285714285715,
      "grad_norm": 0.673620343208313,
      "learning_rate": 1.6064761904761904e-05,
      "loss": 0.5556,
      "step": 10330
    },
    {
      "epoch": 2.954285714285714,
      "grad_norm": 0.7389187216758728,
      "learning_rate": 1.6060952380952383e-05,
      "loss": 0.5303,
      "step": 10340
    },
    {
      "epoch": 2.9571428571428573,
      "grad_norm": 11.516414642333984,
      "learning_rate": 1.605714285714286e-05,
      "loss": 0.4315,
      "step": 10350
    },
    {
      "epoch": 2.96,
      "grad_norm": 11.828791618347168,
      "learning_rate": 1.6053333333333334e-05,
      "loss": 0.5319,
      "step": 10360
    },
    {
      "epoch": 2.9628571428571426,
      "grad_norm": 0.7546266317367554,
      "learning_rate": 1.604952380952381e-05,
      "loss": 0.4317,
      "step": 10370
    },
    {
      "epoch": 2.9657142857142857,
      "grad_norm": 0.7185408473014832,
      "learning_rate": 1.6045714285714286e-05,
      "loss": 0.4232,
      "step": 10380
    },
    {
      "epoch": 2.9685714285714284,
      "grad_norm": 0.5143505930900574,
      "learning_rate": 1.6041904761904764e-05,
      "loss": 0.2281,
      "step": 10390
    },
    {
      "epoch": 2.9714285714285715,
      "grad_norm": 0.4229757785797119,
      "learning_rate": 1.603809523809524e-05,
      "loss": 0.3492,
      "step": 10400
    },
    {
      "epoch": 2.974285714285714,
      "grad_norm": 11.061878204345703,
      "learning_rate": 1.6034285714285716e-05,
      "loss": 0.481,
      "step": 10410
    },
    {
      "epoch": 2.977142857142857,
      "grad_norm": 0.368333101272583,
      "learning_rate": 1.603047619047619e-05,
      "loss": 0.4939,
      "step": 10420
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.3869347870349884,
      "learning_rate": 1.6026666666666667e-05,
      "loss": 0.4874,
      "step": 10430
    },
    {
      "epoch": 2.982857142857143,
      "grad_norm": 11.302374839782715,
      "learning_rate": 1.6022857142857146e-05,
      "loss": 0.488,
      "step": 10440
    },
    {
      "epoch": 2.9857142857142858,
      "grad_norm": 0.43492385745048523,
      "learning_rate": 1.601904761904762e-05,
      "loss": 0.3639,
      "step": 10450
    },
    {
      "epoch": 2.9885714285714284,
      "grad_norm": 0.4574810266494751,
      "learning_rate": 1.6015238095238097e-05,
      "loss": 0.4708,
      "step": 10460
    },
    {
      "epoch": 2.9914285714285715,
      "grad_norm": 0.48308050632476807,
      "learning_rate": 1.6011428571428573e-05,
      "loss": 0.47,
      "step": 10470
    },
    {
      "epoch": 2.994285714285714,
      "grad_norm": 0.5031949877738953,
      "learning_rate": 1.6007619047619048e-05,
      "loss": 0.467,
      "step": 10480
    },
    {
      "epoch": 2.9971428571428573,
      "grad_norm": 10.817131042480469,
      "learning_rate": 1.6003809523809527e-05,
      "loss": 0.7922,
      "step": 10490
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.633548378944397,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.5568,
      "step": 10500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8893333333333333,
      "eval_f1": 0.0,
      "eval_loss": 0.4855218529701233,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 262.1246,
      "eval_samples_per_second": 11.445,
      "eval_steps_per_second": 2.861,
      "step": 10500
    },
    {
      "epoch": 3.0028571428571427,
      "grad_norm": 0.5582800507545471,
      "learning_rate": 1.5996190476190478e-05,
      "loss": 0.2352,
      "step": 10510
    },
    {
      "epoch": 3.005714285714286,
      "grad_norm": 10.940420150756836,
      "learning_rate": 1.5992380952380954e-05,
      "loss": 0.6729,
      "step": 10520
    },
    {
      "epoch": 3.0085714285714285,
      "grad_norm": 0.5667803883552551,
      "learning_rate": 1.598857142857143e-05,
      "loss": 0.4505,
      "step": 10530
    },
    {
      "epoch": 3.0114285714285716,
      "grad_norm": 0.5608817934989929,
      "learning_rate": 1.5984761904761905e-05,
      "loss": 0.7801,
      "step": 10540
    },
    {
      "epoch": 3.0142857142857142,
      "grad_norm": 10.845870018005371,
      "learning_rate": 1.598095238095238e-05,
      "loss": 0.6632,
      "step": 10550
    },
    {
      "epoch": 3.0171428571428573,
      "grad_norm": 0.6922534704208374,
      "learning_rate": 1.5977142857142856e-05,
      "loss": 0.6537,
      "step": 10560
    },
    {
      "epoch": 3.02,
      "grad_norm": 0.7343248128890991,
      "learning_rate": 1.5973333333333335e-05,
      "loss": 0.5321,
      "step": 10570
    },
    {
      "epoch": 3.0228571428571427,
      "grad_norm": 0.7018381953239441,
      "learning_rate": 1.596952380952381e-05,
      "loss": 0.5357,
      "step": 10580
    },
    {
      "epoch": 3.025714285714286,
      "grad_norm": 0.7992420792579651,
      "learning_rate": 1.5965714285714286e-05,
      "loss": 0.6323,
      "step": 10590
    },
    {
      "epoch": 3.0285714285714285,
      "grad_norm": 0.880533754825592,
      "learning_rate": 1.5961904761904762e-05,
      "loss": 0.5179,
      "step": 10600
    },
    {
      "epoch": 3.0314285714285716,
      "grad_norm": 10.571617126464844,
      "learning_rate": 1.595809523809524e-05,
      "loss": 0.7225,
      "step": 10610
    },
    {
      "epoch": 3.0342857142857143,
      "grad_norm": 0.740609884262085,
      "learning_rate": 1.5954285714285716e-05,
      "loss": 0.1191,
      "step": 10620
    },
    {
      "epoch": 3.0371428571428574,
      "grad_norm": 0.5938512682914734,
      "learning_rate": 1.5950476190476192e-05,
      "loss": 0.6485,
      "step": 10630
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.6678251624107361,
      "learning_rate": 1.5946666666666668e-05,
      "loss": 0.4396,
      "step": 10640
    },
    {
      "epoch": 3.0428571428571427,
      "grad_norm": 0.5964332818984985,
      "learning_rate": 1.5942857142857143e-05,
      "loss": 0.3374,
      "step": 10650
    },
    {
      "epoch": 3.045714285714286,
      "grad_norm": 0.6398226022720337,
      "learning_rate": 1.5939047619047622e-05,
      "loss": 0.6635,
      "step": 10660
    },
    {
      "epoch": 3.0485714285714285,
      "grad_norm": 0.7918678522109985,
      "learning_rate": 1.5935238095238098e-05,
      "loss": 0.8438,
      "step": 10670
    },
    {
      "epoch": 3.0514285714285716,
      "grad_norm": 0.8634223937988281,
      "learning_rate": 1.5931428571428573e-05,
      "loss": 0.3082,
      "step": 10680
    },
    {
      "epoch": 3.0542857142857143,
      "grad_norm": 0.747957706451416,
      "learning_rate": 1.592761904761905e-05,
      "loss": 0.4084,
      "step": 10690
    },
    {
      "epoch": 3.057142857142857,
      "grad_norm": 11.233318328857422,
      "learning_rate": 1.5923809523809524e-05,
      "loss": 0.4488,
      "step": 10700
    },
    {
      "epoch": 3.06,
      "grad_norm": 11.993935585021973,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.6706,
      "step": 10710
    },
    {
      "epoch": 3.0628571428571427,
      "grad_norm": 0.8009968400001526,
      "learning_rate": 1.591619047619048e-05,
      "loss": 0.7598,
      "step": 10720
    },
    {
      "epoch": 3.065714285714286,
      "grad_norm": 0.7767379283905029,
      "learning_rate": 1.5912380952380955e-05,
      "loss": 0.3218,
      "step": 10730
    },
    {
      "epoch": 3.0685714285714285,
      "grad_norm": 21.76228904724121,
      "learning_rate": 1.590857142857143e-05,
      "loss": 0.7188,
      "step": 10740
    },
    {
      "epoch": 3.0714285714285716,
      "grad_norm": 0.8261709213256836,
      "learning_rate": 1.5904761904761906e-05,
      "loss": 0.8461,
      "step": 10750
    },
    {
      "epoch": 3.0742857142857143,
      "grad_norm": 10.79177474975586,
      "learning_rate": 1.590095238095238e-05,
      "loss": 0.3165,
      "step": 10760
    },
    {
      "epoch": 3.077142857142857,
      "grad_norm": 0.6796380281448364,
      "learning_rate": 1.5897142857142857e-05,
      "loss": 0.3316,
      "step": 10770
    },
    {
      "epoch": 3.08,
      "grad_norm": 22.049882888793945,
      "learning_rate": 1.5893333333333333e-05,
      "loss": 0.454,
      "step": 10780
    },
    {
      "epoch": 3.0828571428571427,
      "grad_norm": 0.5278992056846619,
      "learning_rate": 1.588952380952381e-05,
      "loss": 0.7967,
      "step": 10790
    },
    {
      "epoch": 3.085714285714286,
      "grad_norm": 11.18458080291748,
      "learning_rate": 1.5885714285714287e-05,
      "loss": 0.6713,
      "step": 10800
    },
    {
      "epoch": 3.0885714285714285,
      "grad_norm": 0.5990892052650452,
      "learning_rate": 1.5881904761904763e-05,
      "loss": 0.4436,
      "step": 10810
    },
    {
      "epoch": 3.0914285714285716,
      "grad_norm": 0.6864508986473083,
      "learning_rate": 1.5878095238095238e-05,
      "loss": 0.4439,
      "step": 10820
    },
    {
      "epoch": 3.0942857142857143,
      "grad_norm": 0.6070848107337952,
      "learning_rate": 1.5874285714285714e-05,
      "loss": 0.5509,
      "step": 10830
    },
    {
      "epoch": 3.097142857142857,
      "grad_norm": 0.614150881767273,
      "learning_rate": 1.5870476190476193e-05,
      "loss": 0.776,
      "step": 10840
    },
    {
      "epoch": 3.1,
      "grad_norm": 10.737194061279297,
      "learning_rate": 1.586666666666667e-05,
      "loss": 0.4426,
      "step": 10850
    },
    {
      "epoch": 3.1028571428571428,
      "grad_norm": 0.5924205183982849,
      "learning_rate": 1.5862857142857144e-05,
      "loss": 0.3328,
      "step": 10860
    },
    {
      "epoch": 3.105714285714286,
      "grad_norm": 0.5329733490943909,
      "learning_rate": 1.585904761904762e-05,
      "loss": 0.5655,
      "step": 10870
    },
    {
      "epoch": 3.1085714285714285,
      "grad_norm": 0.47452154755592346,
      "learning_rate": 1.58552380952381e-05,
      "loss": 0.3474,
      "step": 10880
    },
    {
      "epoch": 3.111428571428571,
      "grad_norm": 10.933032989501953,
      "learning_rate": 1.5851428571428574e-05,
      "loss": 0.5861,
      "step": 10890
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 11.500855445861816,
      "learning_rate": 1.584761904761905e-05,
      "loss": 0.3527,
      "step": 10900
    },
    {
      "epoch": 3.117142857142857,
      "grad_norm": 0.46443161368370056,
      "learning_rate": 1.5843809523809525e-05,
      "loss": 0.4729,
      "step": 10910
    },
    {
      "epoch": 3.12,
      "grad_norm": 10.843755722045898,
      "learning_rate": 1.584e-05,
      "loss": 0.5854,
      "step": 10920
    },
    {
      "epoch": 3.1228571428571428,
      "grad_norm": 0.5456605553627014,
      "learning_rate": 1.583619047619048e-05,
      "loss": 0.9091,
      "step": 10930
    },
    {
      "epoch": 3.125714285714286,
      "grad_norm": 10.652064323425293,
      "learning_rate": 1.5832380952380955e-05,
      "loss": 0.5426,
      "step": 10940
    },
    {
      "epoch": 3.1285714285714286,
      "grad_norm": 10.549236297607422,
      "learning_rate": 1.582857142857143e-05,
      "loss": 0.7391,
      "step": 10950
    },
    {
      "epoch": 3.1314285714285712,
      "grad_norm": 0.8430861830711365,
      "learning_rate": 1.5824761904761907e-05,
      "loss": 0.5185,
      "step": 10960
    },
    {
      "epoch": 3.1342857142857143,
      "grad_norm": 0.8391236066818237,
      "learning_rate": 1.5820952380952382e-05,
      "loss": 0.2169,
      "step": 10970
    },
    {
      "epoch": 3.137142857142857,
      "grad_norm": 11.317160606384277,
      "learning_rate": 1.5817142857142858e-05,
      "loss": 0.5313,
      "step": 10980
    },
    {
      "epoch": 3.14,
      "grad_norm": 22.211862564086914,
      "learning_rate": 1.5813333333333333e-05,
      "loss": 0.5376,
      "step": 10990
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 0.732722818851471,
      "learning_rate": 1.580952380952381e-05,
      "loss": 0.2194,
      "step": 11000
    },
    {
      "epoch": 3.145714285714286,
      "grad_norm": 0.7745590806007385,
      "learning_rate": 1.5805714285714288e-05,
      "loss": 0.7498,
      "step": 11010
    },
    {
      "epoch": 3.1485714285714286,
      "grad_norm": 0.5777174234390259,
      "learning_rate": 1.5801904761904763e-05,
      "loss": 0.2253,
      "step": 11020
    },
    {
      "epoch": 3.1514285714285712,
      "grad_norm": 0.5675874352455139,
      "learning_rate": 1.579809523809524e-05,
      "loss": 0.7774,
      "step": 11030
    },
    {
      "epoch": 3.1542857142857144,
      "grad_norm": 10.861128807067871,
      "learning_rate": 1.5794285714285715e-05,
      "loss": 0.3479,
      "step": 11040
    },
    {
      "epoch": 3.157142857142857,
      "grad_norm": 11.182403564453125,
      "learning_rate": 1.579047619047619e-05,
      "loss": 0.4622,
      "step": 11050
    },
    {
      "epoch": 3.16,
      "grad_norm": 22.0096435546875,
      "learning_rate": 1.578666666666667e-05,
      "loss": 0.799,
      "step": 11060
    },
    {
      "epoch": 3.162857142857143,
      "grad_norm": 10.867341995239258,
      "learning_rate": 1.5782857142857145e-05,
      "loss": 0.6815,
      "step": 11070
    },
    {
      "epoch": 3.1657142857142855,
      "grad_norm": 0.5543060302734375,
      "learning_rate": 1.577904761904762e-05,
      "loss": 0.6752,
      "step": 11080
    },
    {
      "epoch": 3.1685714285714286,
      "grad_norm": 0.8203544020652771,
      "learning_rate": 1.5775238095238096e-05,
      "loss": 0.5522,
      "step": 11090
    },
    {
      "epoch": 3.1714285714285713,
      "grad_norm": 10.630932807922363,
      "learning_rate": 1.577142857142857e-05,
      "loss": 0.6447,
      "step": 11100
    },
    {
      "epoch": 3.1742857142857144,
      "grad_norm": 0.5153596997261047,
      "learning_rate": 1.576761904761905e-05,
      "loss": 0.1236,
      "step": 11110
    },
    {
      "epoch": 3.177142857142857,
      "grad_norm": 11.15416431427002,
      "learning_rate": 1.5763809523809526e-05,
      "loss": 0.4717,
      "step": 11120
    },
    {
      "epoch": 3.18,
      "grad_norm": 11.156177520751953,
      "learning_rate": 1.576e-05,
      "loss": 1.0397,
      "step": 11130
    },
    {
      "epoch": 3.182857142857143,
      "grad_norm": 0.6367604732513428,
      "learning_rate": 1.5756190476190477e-05,
      "loss": 0.5672,
      "step": 11140
    },
    {
      "epoch": 3.185714285714286,
      "grad_norm": 0.637517511844635,
      "learning_rate": 1.5752380952380956e-05,
      "loss": 0.548,
      "step": 11150
    },
    {
      "epoch": 3.1885714285714286,
      "grad_norm": 0.6249513626098633,
      "learning_rate": 1.5748571428571432e-05,
      "loss": 0.5464,
      "step": 11160
    },
    {
      "epoch": 3.1914285714285713,
      "grad_norm": 10.755011558532715,
      "learning_rate": 1.5744761904761907e-05,
      "loss": 0.6528,
      "step": 11170
    },
    {
      "epoch": 3.1942857142857144,
      "grad_norm": 10.804083824157715,
      "learning_rate": 1.5740952380952383e-05,
      "loss": 0.3375,
      "step": 11180
    },
    {
      "epoch": 3.197142857142857,
      "grad_norm": 0.6276882290840149,
      "learning_rate": 1.573714285714286e-05,
      "loss": 0.4425,
      "step": 11190
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.6257199645042419,
      "learning_rate": 1.5733333333333334e-05,
      "loss": 0.5481,
      "step": 11200
    },
    {
      "epoch": 3.202857142857143,
      "grad_norm": 0.6351560354232788,
      "learning_rate": 1.572952380952381e-05,
      "loss": 0.6571,
      "step": 11210
    },
    {
      "epoch": 3.2057142857142855,
      "grad_norm": 0.577754020690918,
      "learning_rate": 1.5725714285714285e-05,
      "loss": 0.1201,
      "step": 11220
    },
    {
      "epoch": 3.2085714285714286,
      "grad_norm": 10.758931159973145,
      "learning_rate": 1.5721904761904764e-05,
      "loss": 0.8779,
      "step": 11230
    },
    {
      "epoch": 3.2114285714285713,
      "grad_norm": 0.6054621934890747,
      "learning_rate": 1.571809523809524e-05,
      "loss": 0.4476,
      "step": 11240
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 21.97407341003418,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.4411,
      "step": 11250
    },
    {
      "epoch": 3.217142857142857,
      "grad_norm": 0.5060343146324158,
      "learning_rate": 1.571047619047619e-05,
      "loss": 0.1222,
      "step": 11260
    },
    {
      "epoch": 3.22,
      "grad_norm": 10.990025520324707,
      "learning_rate": 1.5706666666666666e-05,
      "loss": 0.8085,
      "step": 11270
    },
    {
      "epoch": 3.222857142857143,
      "grad_norm": 0.5844467282295227,
      "learning_rate": 1.5702857142857145e-05,
      "loss": 0.6761,
      "step": 11280
    },
    {
      "epoch": 3.2257142857142855,
      "grad_norm": 0.6258987784385681,
      "learning_rate": 1.569904761904762e-05,
      "loss": 0.6633,
      "step": 11290
    },
    {
      "epoch": 3.2285714285714286,
      "grad_norm": 0.6039997935295105,
      "learning_rate": 1.5695238095238097e-05,
      "loss": 0.2269,
      "step": 11300
    },
    {
      "epoch": 3.2314285714285713,
      "grad_norm": 10.977510452270508,
      "learning_rate": 1.5691428571428572e-05,
      "loss": 0.4513,
      "step": 11310
    },
    {
      "epoch": 3.2342857142857144,
      "grad_norm": 0.5730207562446594,
      "learning_rate": 1.5687619047619048e-05,
      "loss": 0.7804,
      "step": 11320
    },
    {
      "epoch": 3.237142857142857,
      "grad_norm": 22.0932559967041,
      "learning_rate": 1.5683809523809527e-05,
      "loss": 0.3507,
      "step": 11330
    },
    {
      "epoch": 3.24,
      "grad_norm": 11.023526191711426,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.9268,
      "step": 11340
    },
    {
      "epoch": 3.242857142857143,
      "grad_norm": 0.5718384385108948,
      "learning_rate": 1.5676190476190478e-05,
      "loss": 0.4547,
      "step": 11350
    },
    {
      "epoch": 3.2457142857142856,
      "grad_norm": 10.755940437316895,
      "learning_rate": 1.5672380952380954e-05,
      "loss": 0.3392,
      "step": 11360
    },
    {
      "epoch": 3.2485714285714287,
      "grad_norm": 10.704479217529297,
      "learning_rate": 1.566857142857143e-05,
      "loss": 0.8781,
      "step": 11370
    },
    {
      "epoch": 3.2514285714285713,
      "grad_norm": 11.081669807434082,
      "learning_rate": 1.5664761904761908e-05,
      "loss": 0.538,
      "step": 11380
    },
    {
      "epoch": 3.2542857142857144,
      "grad_norm": 11.207764625549316,
      "learning_rate": 1.566095238095238e-05,
      "loss": 0.5201,
      "step": 11390
    },
    {
      "epoch": 3.257142857142857,
      "grad_norm": 0.9596120119094849,
      "learning_rate": 1.5657142857142856e-05,
      "loss": 0.6114,
      "step": 11400
    },
    {
      "epoch": 3.26,
      "grad_norm": 0.8847946524620056,
      "learning_rate": 1.5653333333333335e-05,
      "loss": 0.314,
      "step": 11410
    },
    {
      "epoch": 3.262857142857143,
      "grad_norm": 0.8917292356491089,
      "learning_rate": 1.564952380952381e-05,
      "loss": 0.6091,
      "step": 11420
    },
    {
      "epoch": 3.2657142857142856,
      "grad_norm": 10.468731880187988,
      "learning_rate": 1.5645714285714286e-05,
      "loss": 0.6102,
      "step": 11430
    },
    {
      "epoch": 3.2685714285714287,
      "grad_norm": 0.8847543597221375,
      "learning_rate": 1.564190476190476e-05,
      "loss": 0.7107,
      "step": 11440
    },
    {
      "epoch": 3.2714285714285714,
      "grad_norm": 22.065507888793945,
      "learning_rate": 1.563809523809524e-05,
      "loss": 0.5199,
      "step": 11450
    },
    {
      "epoch": 3.2742857142857145,
      "grad_norm": 22.187559127807617,
      "learning_rate": 1.5634285714285716e-05,
      "loss": 0.4613,
      "step": 11460
    },
    {
      "epoch": 3.277142857142857,
      "grad_norm": 0.5230847001075745,
      "learning_rate": 1.563047619047619e-05,
      "loss": 0.3488,
      "step": 11470
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 10.9362154006958,
      "learning_rate": 1.5626666666666667e-05,
      "loss": 0.354,
      "step": 11480
    },
    {
      "epoch": 3.282857142857143,
      "grad_norm": 0.5169891119003296,
      "learning_rate": 1.5622857142857143e-05,
      "loss": 0.8087,
      "step": 11490
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 0.8543192148208618,
      "learning_rate": 1.5619047619047622e-05,
      "loss": 0.8581,
      "step": 11500
    },
    {
      "epoch": 3.2885714285714287,
      "grad_norm": 0.9394381046295166,
      "learning_rate": 1.5615238095238097e-05,
      "loss": 0.4087,
      "step": 11510
    },
    {
      "epoch": 3.2914285714285714,
      "grad_norm": 10.532590866088867,
      "learning_rate": 1.5611428571428573e-05,
      "loss": 0.5979,
      "step": 11520
    },
    {
      "epoch": 3.2942857142857145,
      "grad_norm": 0.950963020324707,
      "learning_rate": 1.560761904761905e-05,
      "loss": 0.8104,
      "step": 11530
    },
    {
      "epoch": 3.297142857142857,
      "grad_norm": 21.96503448486328,
      "learning_rate": 1.5603809523809524e-05,
      "loss": 0.4171,
      "step": 11540
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.6340915560722351,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.3229,
      "step": 11550
    },
    {
      "epoch": 3.302857142857143,
      "grad_norm": 0.6514721512794495,
      "learning_rate": 1.559619047619048e-05,
      "loss": 0.5488,
      "step": 11560
    },
    {
      "epoch": 3.3057142857142856,
      "grad_norm": 22.44747543334961,
      "learning_rate": 1.5592380952380954e-05,
      "loss": 0.9595,
      "step": 11570
    },
    {
      "epoch": 3.3085714285714287,
      "grad_norm": 10.592757225036621,
      "learning_rate": 1.558857142857143e-05,
      "loss": 0.5321,
      "step": 11580
    },
    {
      "epoch": 3.3114285714285714,
      "grad_norm": 0.7317718863487244,
      "learning_rate": 1.5584761904761905e-05,
      "loss": 0.4214,
      "step": 11590
    },
    {
      "epoch": 3.314285714285714,
      "grad_norm": 0.69197678565979,
      "learning_rate": 1.5580952380952384e-05,
      "loss": 0.4306,
      "step": 11600
    },
    {
      "epoch": 3.317142857142857,
      "grad_norm": 0.7139406800270081,
      "learning_rate": 1.5577142857142857e-05,
      "loss": 0.6429,
      "step": 11610
    },
    {
      "epoch": 3.32,
      "grad_norm": 10.814220428466797,
      "learning_rate": 1.5573333333333332e-05,
      "loss": 0.4359,
      "step": 11620
    },
    {
      "epoch": 3.322857142857143,
      "grad_norm": 0.6105363965034485,
      "learning_rate": 1.556952380952381e-05,
      "loss": 0.4449,
      "step": 11630
    },
    {
      "epoch": 3.3257142857142856,
      "grad_norm": 0.6163514256477356,
      "learning_rate": 1.5565714285714287e-05,
      "loss": 0.448,
      "step": 11640
    },
    {
      "epoch": 3.3285714285714287,
      "grad_norm": 0.5282184481620789,
      "learning_rate": 1.5561904761904762e-05,
      "loss": 0.1206,
      "step": 11650
    },
    {
      "epoch": 3.3314285714285714,
      "grad_norm": 0.40022537112236023,
      "learning_rate": 1.5558095238095238e-05,
      "loss": 0.5872,
      "step": 11660
    },
    {
      "epoch": 3.3342857142857145,
      "grad_norm": 10.883587837219238,
      "learning_rate": 1.5554285714285713e-05,
      "loss": 0.6004,
      "step": 11670
    },
    {
      "epoch": 3.337142857142857,
      "grad_norm": 10.955107688903809,
      "learning_rate": 1.5550476190476192e-05,
      "loss": 0.4783,
      "step": 11680
    },
    {
      "epoch": 3.34,
      "grad_norm": 0.4302537441253662,
      "learning_rate": 1.5546666666666668e-05,
      "loss": 0.01,
      "step": 11690
    },
    {
      "epoch": 3.342857142857143,
      "grad_norm": 0.42376118898391724,
      "learning_rate": 1.5542857142857144e-05,
      "loss": 0.4829,
      "step": 11700
    },
    {
      "epoch": 3.3457142857142856,
      "grad_norm": 0.44799140095710754,
      "learning_rate": 1.553904761904762e-05,
      "loss": 0.5953,
      "step": 11710
    },
    {
      "epoch": 3.3485714285714288,
      "grad_norm": 11.170183181762695,
      "learning_rate": 1.5535238095238098e-05,
      "loss": 0.4748,
      "step": 11720
    },
    {
      "epoch": 3.3514285714285714,
      "grad_norm": 0.46183013916015625,
      "learning_rate": 1.5531428571428574e-05,
      "loss": 0.4714,
      "step": 11730
    },
    {
      "epoch": 3.354285714285714,
      "grad_norm": 0.5221469402313232,
      "learning_rate": 1.552761904761905e-05,
      "loss": 0.5776,
      "step": 11740
    },
    {
      "epoch": 3.357142857142857,
      "grad_norm": 0.6064226031303406,
      "learning_rate": 1.5523809523809525e-05,
      "loss": 0.6735,
      "step": 11750
    },
    {
      "epoch": 3.36,
      "grad_norm": 10.88185977935791,
      "learning_rate": 1.552e-05,
      "loss": 0.9848,
      "step": 11760
    },
    {
      "epoch": 3.362857142857143,
      "grad_norm": 0.6373806595802307,
      "learning_rate": 1.551619047619048e-05,
      "loss": 0.1198,
      "step": 11770
    },
    {
      "epoch": 3.3657142857142857,
      "grad_norm": 0.5754984617233276,
      "learning_rate": 1.5512380952380955e-05,
      "loss": 0.2252,
      "step": 11780
    },
    {
      "epoch": 3.3685714285714283,
      "grad_norm": 0.5138645768165588,
      "learning_rate": 1.550857142857143e-05,
      "loss": 0.5664,
      "step": 11790
    },
    {
      "epoch": 3.3714285714285714,
      "grad_norm": 0.4996889531612396,
      "learning_rate": 1.5504761904761906e-05,
      "loss": 0.4604,
      "step": 11800
    },
    {
      "epoch": 3.374285714285714,
      "grad_norm": 0.484466552734375,
      "learning_rate": 1.5500952380952382e-05,
      "loss": 0.3488,
      "step": 11810
    },
    {
      "epoch": 3.3771428571428572,
      "grad_norm": 0.46937301754951477,
      "learning_rate": 1.549714285714286e-05,
      "loss": 0.3488,
      "step": 11820
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.462963342666626,
      "learning_rate": 1.5493333333333333e-05,
      "loss": 0.4633,
      "step": 11830
    },
    {
      "epoch": 3.382857142857143,
      "grad_norm": 0.44752800464630127,
      "learning_rate": 1.548952380952381e-05,
      "loss": 0.3526,
      "step": 11840
    },
    {
      "epoch": 3.3857142857142857,
      "grad_norm": 0.4658953547477722,
      "learning_rate": 1.5485714285714287e-05,
      "loss": 0.5827,
      "step": 11850
    },
    {
      "epoch": 3.388571428571429,
      "grad_norm": 0.4586349129676819,
      "learning_rate": 1.5481904761904763e-05,
      "loss": 0.2414,
      "step": 11860
    },
    {
      "epoch": 3.3914285714285715,
      "grad_norm": 10.857647895812988,
      "learning_rate": 1.547809523809524e-05,
      "loss": 0.8051,
      "step": 11870
    },
    {
      "epoch": 3.394285714285714,
      "grad_norm": 0.5093981027603149,
      "learning_rate": 1.5474285714285714e-05,
      "loss": 0.4576,
      "step": 11880
    },
    {
      "epoch": 3.3971428571428572,
      "grad_norm": 0.5166388750076294,
      "learning_rate": 1.547047619047619e-05,
      "loss": 0.6908,
      "step": 11890
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.5488672256469727,
      "learning_rate": 1.546666666666667e-05,
      "loss": 0.68,
      "step": 11900
    },
    {
      "epoch": 3.402857142857143,
      "grad_norm": 0.6077993512153625,
      "learning_rate": 1.5462857142857144e-05,
      "loss": 0.4477,
      "step": 11910
    },
    {
      "epoch": 3.4057142857142857,
      "grad_norm": 0.6343330144882202,
      "learning_rate": 1.545904761904762e-05,
      "loss": 0.442,
      "step": 11920
    },
    {
      "epoch": 3.4085714285714284,
      "grad_norm": 0.6232720613479614,
      "learning_rate": 1.5455238095238096e-05,
      "loss": 0.4447,
      "step": 11930
    },
    {
      "epoch": 3.4114285714285715,
      "grad_norm": 0.4719192385673523,
      "learning_rate": 1.545142857142857e-05,
      "loss": 0.2322,
      "step": 11940
    },
    {
      "epoch": 3.414285714285714,
      "grad_norm": 0.4222305715084076,
      "learning_rate": 1.544761904761905e-05,
      "loss": 0.4672,
      "step": 11950
    },
    {
      "epoch": 3.4171428571428573,
      "grad_norm": 0.39096006751060486,
      "learning_rate": 1.5443809523809526e-05,
      "loss": 0.3614,
      "step": 11960
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.3953077793121338,
      "learning_rate": 1.544e-05,
      "loss": 0.8373,
      "step": 11970
    },
    {
      "epoch": 3.422857142857143,
      "grad_norm": 11.07369613647461,
      "learning_rate": 1.5436190476190477e-05,
      "loss": 0.3624,
      "step": 11980
    },
    {
      "epoch": 3.4257142857142857,
      "grad_norm": 0.42729100584983826,
      "learning_rate": 1.5432380952380956e-05,
      "loss": 0.3585,
      "step": 11990
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.43672239780426025,
      "learning_rate": 1.542857142857143e-05,
      "loss": 0.1275,
      "step": 12000
    },
    {
      "epoch": 3.4314285714285715,
      "grad_norm": 0.3528415858745575,
      "learning_rate": 1.5424761904761907e-05,
      "loss": 0.2486,
      "step": 12010
    },
    {
      "epoch": 3.434285714285714,
      "grad_norm": 11.481264114379883,
      "learning_rate": 1.5420952380952383e-05,
      "loss": 0.3781,
      "step": 12020
    },
    {
      "epoch": 3.4371428571428573,
      "grad_norm": 0.3474922776222229,
      "learning_rate": 1.5417142857142858e-05,
      "loss": 0.6246,
      "step": 12030
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.41976410150527954,
      "learning_rate": 1.5413333333333337e-05,
      "loss": 0.8475,
      "step": 12040
    },
    {
      "epoch": 3.442857142857143,
      "grad_norm": 0.4531727135181427,
      "learning_rate": 1.540952380952381e-05,
      "loss": 0.587,
      "step": 12050
    },
    {
      "epoch": 3.4457142857142857,
      "grad_norm": 0.5342898368835449,
      "learning_rate": 1.5405714285714285e-05,
      "loss": 0.796,
      "step": 12060
    },
    {
      "epoch": 3.4485714285714284,
      "grad_norm": 10.744961738586426,
      "learning_rate": 1.5401904761904764e-05,
      "loss": 0.8784,
      "step": 12070
    },
    {
      "epoch": 3.4514285714285715,
      "grad_norm": 10.592839241027832,
      "learning_rate": 1.539809523809524e-05,
      "loss": 0.6323,
      "step": 12080
    },
    {
      "epoch": 3.454285714285714,
      "grad_norm": 10.621428489685059,
      "learning_rate": 1.5394285714285715e-05,
      "loss": 0.5137,
      "step": 12090
    },
    {
      "epoch": 3.4571428571428573,
      "grad_norm": 0.7864752411842346,
      "learning_rate": 1.539047619047619e-05,
      "loss": 0.513,
      "step": 12100
    },
    {
      "epoch": 3.46,
      "grad_norm": 0.73671954870224,
      "learning_rate": 1.5386666666666666e-05,
      "loss": 0.7458,
      "step": 12110
    },
    {
      "epoch": 3.4628571428571426,
      "grad_norm": 0.7127164602279663,
      "learning_rate": 1.5382857142857145e-05,
      "loss": 0.4351,
      "step": 12120
    },
    {
      "epoch": 3.4657142857142857,
      "grad_norm": 0.717476487159729,
      "learning_rate": 1.537904761904762e-05,
      "loss": 0.4299,
      "step": 12130
    },
    {
      "epoch": 3.4685714285714284,
      "grad_norm": 12.317098617553711,
      "learning_rate": 1.5375238095238096e-05,
      "loss": 0.336,
      "step": 12140
    },
    {
      "epoch": 3.4714285714285715,
      "grad_norm": 10.8462495803833,
      "learning_rate": 1.5371428571428572e-05,
      "loss": 0.7689,
      "step": 12150
    },
    {
      "epoch": 3.474285714285714,
      "grad_norm": 0.6601098775863647,
      "learning_rate": 1.5367619047619047e-05,
      "loss": 0.3303,
      "step": 12160
    },
    {
      "epoch": 3.4771428571428573,
      "grad_norm": 11.498382568359375,
      "learning_rate": 1.5363809523809526e-05,
      "loss": 0.8572,
      "step": 12170
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.7840822339057922,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.325,
      "step": 12180
    },
    {
      "epoch": 3.482857142857143,
      "grad_norm": 0.6416429877281189,
      "learning_rate": 1.5356190476190478e-05,
      "loss": 0.4303,
      "step": 12190
    },
    {
      "epoch": 3.4857142857142858,
      "grad_norm": 0.579110324382782,
      "learning_rate": 1.5352380952380953e-05,
      "loss": 0.4399,
      "step": 12200
    },
    {
      "epoch": 3.4885714285714284,
      "grad_norm": 0.6050654053688049,
      "learning_rate": 1.534857142857143e-05,
      "loss": 0.8723,
      "step": 12210
    },
    {
      "epoch": 3.4914285714285715,
      "grad_norm": 10.824711799621582,
      "learning_rate": 1.5344761904761908e-05,
      "loss": 0.7729,
      "step": 12220
    },
    {
      "epoch": 3.494285714285714,
      "grad_norm": 10.825533866882324,
      "learning_rate": 1.5340952380952383e-05,
      "loss": 0.3379,
      "step": 12230
    },
    {
      "epoch": 3.4971428571428573,
      "grad_norm": 10.871996879577637,
      "learning_rate": 1.533714285714286e-05,
      "loss": 0.4648,
      "step": 12240
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.41752442717552185,
      "learning_rate": 1.5333333333333334e-05,
      "loss": 0.241,
      "step": 12250
    },
    {
      "epoch": 3.5028571428571427,
      "grad_norm": 0.38201525807380676,
      "learning_rate": 1.532952380952381e-05,
      "loss": 0.4767,
      "step": 12260
    },
    {
      "epoch": 3.505714285714286,
      "grad_norm": 10.96942138671875,
      "learning_rate": 1.5325714285714286e-05,
      "loss": 0.733,
      "step": 12270
    },
    {
      "epoch": 3.5085714285714285,
      "grad_norm": 0.4162317216396332,
      "learning_rate": 1.532190476190476e-05,
      "loss": 0.4894,
      "step": 12280
    },
    {
      "epoch": 3.5114285714285716,
      "grad_norm": 0.3974250257015228,
      "learning_rate": 1.531809523809524e-05,
      "loss": 0.4832,
      "step": 12290
    },
    {
      "epoch": 3.5142857142857142,
      "grad_norm": 0.38114023208618164,
      "learning_rate": 1.5314285714285716e-05,
      "loss": 0.361,
      "step": 12300
    },
    {
      "epoch": 3.517142857142857,
      "grad_norm": 0.3404356837272644,
      "learning_rate": 1.531047619047619e-05,
      "loss": 0.2493,
      "step": 12310
    },
    {
      "epoch": 3.52,
      "grad_norm": 10.991873741149902,
      "learning_rate": 1.5306666666666667e-05,
      "loss": 0.4968,
      "step": 12320
    },
    {
      "epoch": 3.522857142857143,
      "grad_norm": 0.43439018726348877,
      "learning_rate": 1.5302857142857143e-05,
      "loss": 0.4914,
      "step": 12330
    },
    {
      "epoch": 3.525714285714286,
      "grad_norm": 0.47873008251190186,
      "learning_rate": 1.529904761904762e-05,
      "loss": 0.2444,
      "step": 12340
    },
    {
      "epoch": 3.5285714285714285,
      "grad_norm": 0.5117117762565613,
      "learning_rate": 1.5295238095238097e-05,
      "loss": 0.9162,
      "step": 12350
    },
    {
      "epoch": 3.5314285714285716,
      "grad_norm": 21.94444465637207,
      "learning_rate": 1.5291428571428573e-05,
      "loss": 0.9933,
      "step": 12360
    },
    {
      "epoch": 3.5342857142857143,
      "grad_norm": 0.8367435336112976,
      "learning_rate": 1.5287619047619048e-05,
      "loss": 0.9446,
      "step": 12370
    },
    {
      "epoch": 3.5371428571428574,
      "grad_norm": 0.845790684223175,
      "learning_rate": 1.5283809523809524e-05,
      "loss": 0.2165,
      "step": 12380
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.7087689638137817,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.3205,
      "step": 12390
    },
    {
      "epoch": 3.5428571428571427,
      "grad_norm": 0.6769908666610718,
      "learning_rate": 1.527619047619048e-05,
      "loss": 0.9771,
      "step": 12400
    },
    {
      "epoch": 3.545714285714286,
      "grad_norm": 0.6992518305778503,
      "learning_rate": 1.5272380952380954e-05,
      "loss": 0.3291,
      "step": 12410
    },
    {
      "epoch": 3.5485714285714285,
      "grad_norm": 10.712133407592773,
      "learning_rate": 1.526857142857143e-05,
      "loss": 0.539,
      "step": 12420
    },
    {
      "epoch": 3.5514285714285716,
      "grad_norm": 0.5380389094352722,
      "learning_rate": 1.5264761904761905e-05,
      "loss": 0.2282,
      "step": 12430
    },
    {
      "epoch": 3.5542857142857143,
      "grad_norm": 0.47339460253715515,
      "learning_rate": 1.5260952380952384e-05,
      "loss": 0.3482,
      "step": 12440
    },
    {
      "epoch": 3.557142857142857,
      "grad_norm": 10.853687286376953,
      "learning_rate": 1.525714285714286e-05,
      "loss": 0.805,
      "step": 12450
    },
    {
      "epoch": 3.56,
      "grad_norm": 11.569330215454102,
      "learning_rate": 1.5253333333333335e-05,
      "loss": 0.3472,
      "step": 12460
    },
    {
      "epoch": 3.5628571428571427,
      "grad_norm": 11.063322067260742,
      "learning_rate": 1.5249523809523813e-05,
      "loss": 0.458,
      "step": 12470
    },
    {
      "epoch": 3.565714285714286,
      "grad_norm": 0.5840489268302917,
      "learning_rate": 1.5245714285714286e-05,
      "loss": 0.4507,
      "step": 12480
    },
    {
      "epoch": 3.5685714285714285,
      "grad_norm": 0.5487505197525024,
      "learning_rate": 1.5241904761904762e-05,
      "loss": 0.3399,
      "step": 12490
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 10.860868453979492,
      "learning_rate": 1.523809523809524e-05,
      "loss": 0.3452,
      "step": 12500
    },
    {
      "epoch": 3.5742857142857143,
      "grad_norm": 0.418800413608551,
      "learning_rate": 1.5234285714285715e-05,
      "loss": 0.3589,
      "step": 12510
    },
    {
      "epoch": 3.5771428571428574,
      "grad_norm": 0.4008471965789795,
      "learning_rate": 1.523047619047619e-05,
      "loss": 0.2432,
      "step": 12520
    },
    {
      "epoch": 3.58,
      "grad_norm": 0.4302482306957245,
      "learning_rate": 1.5226666666666668e-05,
      "loss": 0.6088,
      "step": 12530
    },
    {
      "epoch": 3.5828571428571427,
      "grad_norm": 0.4530242681503296,
      "learning_rate": 1.5222857142857143e-05,
      "loss": 0.4702,
      "step": 12540
    },
    {
      "epoch": 3.585714285714286,
      "grad_norm": 0.48067402839660645,
      "learning_rate": 1.521904761904762e-05,
      "loss": 0.4669,
      "step": 12550
    },
    {
      "epoch": 3.5885714285714285,
      "grad_norm": 10.785778045654297,
      "learning_rate": 1.5215238095238096e-05,
      "loss": 0.4598,
      "step": 12560
    },
    {
      "epoch": 3.5914285714285716,
      "grad_norm": 10.974444389343262,
      "learning_rate": 1.5211428571428572e-05,
      "loss": 0.7598,
      "step": 12570
    },
    {
      "epoch": 3.5942857142857143,
      "grad_norm": 10.457626342773438,
      "learning_rate": 1.5207619047619049e-05,
      "loss": 0.9181,
      "step": 12580
    },
    {
      "epoch": 3.597142857142857,
      "grad_norm": 1.1116243600845337,
      "learning_rate": 1.5203809523809525e-05,
      "loss": 0.3981,
      "step": 12590
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.9488235116004944,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.401,
      "step": 12600
    },
    {
      "epoch": 3.6028571428571428,
      "grad_norm": 0.6624966263771057,
      "learning_rate": 1.5196190476190477e-05,
      "loss": 0.2161,
      "step": 12610
    },
    {
      "epoch": 3.605714285714286,
      "grad_norm": 14.445456504821777,
      "learning_rate": 1.5192380952380955e-05,
      "loss": 0.5609,
      "step": 12620
    },
    {
      "epoch": 3.6085714285714285,
      "grad_norm": 0.5415785312652588,
      "learning_rate": 1.518857142857143e-05,
      "loss": 0.5743,
      "step": 12630
    },
    {
      "epoch": 3.611428571428571,
      "grad_norm": 0.5735949873924255,
      "learning_rate": 1.5184761904761906e-05,
      "loss": 0.7766,
      "step": 12640
    },
    {
      "epoch": 3.6142857142857143,
      "grad_norm": 0.8225366473197937,
      "learning_rate": 1.5180952380952383e-05,
      "loss": 0.6643,
      "step": 12650
    },
    {
      "epoch": 3.617142857142857,
      "grad_norm": 10.598506927490234,
      "learning_rate": 1.5177142857142859e-05,
      "loss": 0.3229,
      "step": 12660
    },
    {
      "epoch": 3.62,
      "grad_norm": 0.6886915564537048,
      "learning_rate": 1.5173333333333336e-05,
      "loss": 0.334,
      "step": 12670
    },
    {
      "epoch": 3.6228571428571428,
      "grad_norm": 22.177207946777344,
      "learning_rate": 1.5169523809523812e-05,
      "loss": 0.6334,
      "step": 12680
    },
    {
      "epoch": 3.6257142857142854,
      "grad_norm": 21.857126235961914,
      "learning_rate": 1.5165714285714289e-05,
      "loss": 1.1643,
      "step": 12690
    },
    {
      "epoch": 3.6285714285714286,
      "grad_norm": 0.8005509972572327,
      "learning_rate": 1.5161904761904763e-05,
      "loss": 0.217,
      "step": 12700
    },
    {
      "epoch": 3.6314285714285717,
      "grad_norm": 11.482050895690918,
      "learning_rate": 1.5158095238095238e-05,
      "loss": 0.2218,
      "step": 12710
    },
    {
      "epoch": 3.6342857142857143,
      "grad_norm": 0.5460208654403687,
      "learning_rate": 1.5154285714285714e-05,
      "loss": 0.6691,
      "step": 12720
    },
    {
      "epoch": 3.637142857142857,
      "grad_norm": 11.102481842041016,
      "learning_rate": 1.5150476190476191e-05,
      "loss": 0.5605,
      "step": 12730
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.7022988796234131,
      "learning_rate": 1.5146666666666667e-05,
      "loss": 0.7605,
      "step": 12740
    },
    {
      "epoch": 3.642857142857143,
      "grad_norm": 0.7002333998680115,
      "learning_rate": 1.5142857142857144e-05,
      "loss": 0.4318,
      "step": 12750
    },
    {
      "epoch": 3.645714285714286,
      "grad_norm": 0.5822407007217407,
      "learning_rate": 1.513904761904762e-05,
      "loss": 0.1222,
      "step": 12760
    },
    {
      "epoch": 3.6485714285714286,
      "grad_norm": 0.5887259244918823,
      "learning_rate": 1.5135238095238097e-05,
      "loss": 0.6685,
      "step": 12770
    },
    {
      "epoch": 3.6514285714285712,
      "grad_norm": 0.5584943890571594,
      "learning_rate": 1.5131428571428572e-05,
      "loss": 0.445,
      "step": 12780
    },
    {
      "epoch": 3.6542857142857144,
      "grad_norm": 0.485242635011673,
      "learning_rate": 1.5127619047619048e-05,
      "loss": 0.2311,
      "step": 12790
    },
    {
      "epoch": 3.657142857142857,
      "grad_norm": 10.934020042419434,
      "learning_rate": 1.5123809523809525e-05,
      "loss": 0.4678,
      "step": 12800
    },
    {
      "epoch": 3.66,
      "grad_norm": 10.97593879699707,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.4763,
      "step": 12810
    },
    {
      "epoch": 3.662857142857143,
      "grad_norm": 0.4015958309173584,
      "learning_rate": 1.5116190476190478e-05,
      "loss": 0.3644,
      "step": 12820
    },
    {
      "epoch": 3.6657142857142855,
      "grad_norm": 0.36072880029678345,
      "learning_rate": 1.5112380952380954e-05,
      "loss": 0.1273,
      "step": 12830
    },
    {
      "epoch": 3.6685714285714286,
      "grad_norm": 0.28294801712036133,
      "learning_rate": 1.5108571428571431e-05,
      "loss": 0.1313,
      "step": 12840
    },
    {
      "epoch": 3.6714285714285713,
      "grad_norm": 0.24798263609409332,
      "learning_rate": 1.5104761904761907e-05,
      "loss": 0.5211,
      "step": 12850
    },
    {
      "epoch": 3.6742857142857144,
      "grad_norm": 0.2546730637550354,
      "learning_rate": 1.5100952380952382e-05,
      "loss": 0.3919,
      "step": 12860
    },
    {
      "epoch": 3.677142857142857,
      "grad_norm": 0.28507012128829956,
      "learning_rate": 1.509714285714286e-05,
      "loss": 0.5263,
      "step": 12870
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.3347848951816559,
      "learning_rate": 1.5093333333333335e-05,
      "loss": 0.7612,
      "step": 12880
    },
    {
      "epoch": 3.682857142857143,
      "grad_norm": 0.3421671986579895,
      "learning_rate": 1.5089523809523812e-05,
      "loss": 0.2496,
      "step": 12890
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.34293824434280396,
      "learning_rate": 1.5085714285714288e-05,
      "loss": 0.7368,
      "step": 12900
    },
    {
      "epoch": 3.6885714285714286,
      "grad_norm": 0.3457983434200287,
      "learning_rate": 1.5081904761904762e-05,
      "loss": 0.1279,
      "step": 12910
    },
    {
      "epoch": 3.6914285714285713,
      "grad_norm": 0.38253769278526306,
      "learning_rate": 1.5078095238095239e-05,
      "loss": 0.9722,
      "step": 12920
    },
    {
      "epoch": 3.6942857142857144,
      "grad_norm": 0.4170040190219879,
      "learning_rate": 1.5074285714285715e-05,
      "loss": 0.2445,
      "step": 12930
    },
    {
      "epoch": 3.697142857142857,
      "grad_norm": 0.39001306891441345,
      "learning_rate": 1.507047619047619e-05,
      "loss": 0.1253,
      "step": 12940
    },
    {
      "epoch": 3.7,
      "grad_norm": 22.21255874633789,
      "learning_rate": 1.5066666666666668e-05,
      "loss": 0.4921,
      "step": 12950
    },
    {
      "epoch": 3.702857142857143,
      "grad_norm": 0.341596394777298,
      "learning_rate": 1.5062857142857143e-05,
      "loss": 0.4953,
      "step": 12960
    },
    {
      "epoch": 3.7057142857142855,
      "grad_norm": 0.35001641511917114,
      "learning_rate": 1.505904761904762e-05,
      "loss": 0.3729,
      "step": 12970
    },
    {
      "epoch": 3.7085714285714286,
      "grad_norm": 11.231081008911133,
      "learning_rate": 1.5055238095238096e-05,
      "loss": 0.9774,
      "step": 12980
    },
    {
      "epoch": 3.7114285714285713,
      "grad_norm": 0.44498056173324585,
      "learning_rate": 1.5051428571428572e-05,
      "loss": 0.5984,
      "step": 12990
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.5138819217681885,
      "learning_rate": 1.5047619047619049e-05,
      "loss": 0.6928,
      "step": 13000
    },
    {
      "epoch": 3.717142857142857,
      "grad_norm": 0.512878954410553,
      "learning_rate": 1.5043809523809524e-05,
      "loss": 0.2325,
      "step": 13010
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 10.92444133758545,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.5688,
      "step": 13020
    },
    {
      "epoch": 3.722857142857143,
      "grad_norm": 0.5605898499488831,
      "learning_rate": 1.5036190476190477e-05,
      "loss": 0.6875,
      "step": 13030
    },
    {
      "epoch": 3.725714285714286,
      "grad_norm": 0.5371986627578735,
      "learning_rate": 1.5032380952380955e-05,
      "loss": 0.3397,
      "step": 13040
    },
    {
      "epoch": 3.7285714285714286,
      "grad_norm": 22.237751007080078,
      "learning_rate": 1.502857142857143e-05,
      "loss": 0.569,
      "step": 13050
    },
    {
      "epoch": 3.7314285714285713,
      "grad_norm": 0.5135387778282166,
      "learning_rate": 1.5024761904761906e-05,
      "loss": 0.5711,
      "step": 13060
    },
    {
      "epoch": 3.7342857142857144,
      "grad_norm": 0.5282479524612427,
      "learning_rate": 1.5020952380952383e-05,
      "loss": 0.5679,
      "step": 13070
    },
    {
      "epoch": 3.737142857142857,
      "grad_norm": 0.5021196603775024,
      "learning_rate": 1.5017142857142859e-05,
      "loss": 0.3452,
      "step": 13080
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.4677959978580475,
      "learning_rate": 1.5013333333333336e-05,
      "loss": 0.0108,
      "step": 13090
    },
    {
      "epoch": 3.742857142857143,
      "grad_norm": 0.43548497557640076,
      "learning_rate": 1.5009523809523811e-05,
      "loss": 0.5882,
      "step": 13100
    },
    {
      "epoch": 3.7457142857142856,
      "grad_norm": 10.915191650390625,
      "learning_rate": 1.5005714285714289e-05,
      "loss": 0.5845,
      "step": 13110
    },
    {
      "epoch": 3.7485714285714287,
      "grad_norm": 0.4881308376789093,
      "learning_rate": 1.5001904761904764e-05,
      "loss": 0.4632,
      "step": 13120
    },
    {
      "epoch": 3.7514285714285713,
      "grad_norm": 0.5064138174057007,
      "learning_rate": 1.4998095238095238e-05,
      "loss": 0.4588,
      "step": 13130
    },
    {
      "epoch": 3.7542857142857144,
      "grad_norm": 0.5419773459434509,
      "learning_rate": 1.4994285714285714e-05,
      "loss": 0.4517,
      "step": 13140
    },
    {
      "epoch": 3.757142857142857,
      "grad_norm": 22.075439453125,
      "learning_rate": 1.4990476190476191e-05,
      "loss": 0.8909,
      "step": 13150
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.597413182258606,
      "learning_rate": 1.4986666666666667e-05,
      "loss": 0.4494,
      "step": 13160
    },
    {
      "epoch": 3.762857142857143,
      "grad_norm": 10.814780235290527,
      "learning_rate": 1.4982857142857144e-05,
      "loss": 0.7716,
      "step": 13170
    },
    {
      "epoch": 3.7657142857142856,
      "grad_norm": 0.5917381048202515,
      "learning_rate": 1.497904761904762e-05,
      "loss": 0.2294,
      "step": 13180
    },
    {
      "epoch": 3.7685714285714287,
      "grad_norm": 10.723816871643066,
      "learning_rate": 1.4975238095238097e-05,
      "loss": 0.9886,
      "step": 13190
    },
    {
      "epoch": 3.7714285714285714,
      "grad_norm": 0.7113279700279236,
      "learning_rate": 1.4971428571428572e-05,
      "loss": 0.6455,
      "step": 13200
    },
    {
      "epoch": 3.774285714285714,
      "grad_norm": 0.7289494276046753,
      "learning_rate": 1.4967619047619048e-05,
      "loss": 0.3259,
      "step": 13210
    },
    {
      "epoch": 3.777142857142857,
      "grad_norm": 10.781479835510254,
      "learning_rate": 1.4963809523809525e-05,
      "loss": 0.5391,
      "step": 13220
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 10.601210594177246,
      "learning_rate": 1.496e-05,
      "loss": 0.8483,
      "step": 13230
    },
    {
      "epoch": 3.782857142857143,
      "grad_norm": 0.9505719542503357,
      "learning_rate": 1.4956190476190478e-05,
      "loss": 0.8208,
      "step": 13240
    },
    {
      "epoch": 3.7857142857142856,
      "grad_norm": 0.8499411940574646,
      "learning_rate": 1.4952380952380954e-05,
      "loss": 0.1166,
      "step": 13250
    },
    {
      "epoch": 3.7885714285714287,
      "grad_norm": 0.7713283896446228,
      "learning_rate": 1.4948571428571431e-05,
      "loss": 0.5218,
      "step": 13260
    },
    {
      "epoch": 3.7914285714285714,
      "grad_norm": 10.50966739654541,
      "learning_rate": 1.4944761904761906e-05,
      "loss": 0.7197,
      "step": 13270
    },
    {
      "epoch": 3.7942857142857145,
      "grad_norm": 10.550890922546387,
      "learning_rate": 1.4940952380952382e-05,
      "loss": 0.2215,
      "step": 13280
    },
    {
      "epoch": 3.797142857142857,
      "grad_norm": 10.684849739074707,
      "learning_rate": 1.493714285714286e-05,
      "loss": 0.73,
      "step": 13290
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.7509878277778625,
      "learning_rate": 1.4933333333333335e-05,
      "loss": 0.2205,
      "step": 13300
    },
    {
      "epoch": 3.802857142857143,
      "grad_norm": 0.7582480907440186,
      "learning_rate": 1.4929523809523812e-05,
      "loss": 0.6316,
      "step": 13310
    },
    {
      "epoch": 3.8057142857142856,
      "grad_norm": 10.665529251098633,
      "learning_rate": 1.4925714285714288e-05,
      "loss": 0.5254,
      "step": 13320
    },
    {
      "epoch": 3.8085714285714287,
      "grad_norm": 0.6329771876335144,
      "learning_rate": 1.4921904761904763e-05,
      "loss": 0.3306,
      "step": 13330
    },
    {
      "epoch": 3.8114285714285714,
      "grad_norm": 22.18075942993164,
      "learning_rate": 1.491809523809524e-05,
      "loss": 0.5565,
      "step": 13340
    },
    {
      "epoch": 3.814285714285714,
      "grad_norm": 0.4363953173160553,
      "learning_rate": 1.4914285714285715e-05,
      "loss": 0.1259,
      "step": 13350
    },
    {
      "epoch": 3.817142857142857,
      "grad_norm": 0.38610661029815674,
      "learning_rate": 1.491047619047619e-05,
      "loss": 0.487,
      "step": 13360
    },
    {
      "epoch": 3.82,
      "grad_norm": 0.3568935692310333,
      "learning_rate": 1.4906666666666667e-05,
      "loss": 0.3665,
      "step": 13370
    },
    {
      "epoch": 3.822857142857143,
      "grad_norm": 10.906740188598633,
      "learning_rate": 1.4902857142857143e-05,
      "loss": 0.7281,
      "step": 13380
    },
    {
      "epoch": 3.8257142857142856,
      "grad_norm": 0.4771079123020172,
      "learning_rate": 1.489904761904762e-05,
      "loss": 0.7046,
      "step": 13390
    },
    {
      "epoch": 3.8285714285714287,
      "grad_norm": 0.5168272852897644,
      "learning_rate": 1.4895238095238096e-05,
      "loss": 0.1227,
      "step": 13400
    },
    {
      "epoch": 3.8314285714285714,
      "grad_norm": 0.49790552258491516,
      "learning_rate": 1.4891428571428571e-05,
      "loss": 0.5797,
      "step": 13410
    },
    {
      "epoch": 3.8342857142857145,
      "grad_norm": 10.840696334838867,
      "learning_rate": 1.4887619047619049e-05,
      "loss": 0.4641,
      "step": 13420
    },
    {
      "epoch": 3.837142857142857,
      "grad_norm": 0.5283007621765137,
      "learning_rate": 1.4883809523809524e-05,
      "loss": 0.2356,
      "step": 13430
    },
    {
      "epoch": 3.84,
      "grad_norm": 10.931479454040527,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.5787,
      "step": 13440
    },
    {
      "epoch": 3.842857142857143,
      "grad_norm": 10.87806224822998,
      "learning_rate": 1.4876190476190477e-05,
      "loss": 1.0143,
      "step": 13450
    },
    {
      "epoch": 3.8457142857142856,
      "grad_norm": 10.697222709655762,
      "learning_rate": 1.4872380952380954e-05,
      "loss": 0.549,
      "step": 13460
    },
    {
      "epoch": 3.8485714285714288,
      "grad_norm": 0.7168336510658264,
      "learning_rate": 1.486857142857143e-05,
      "loss": 0.3222,
      "step": 13470
    },
    {
      "epoch": 3.8514285714285714,
      "grad_norm": 22.222517013549805,
      "learning_rate": 1.4864761904761906e-05,
      "loss": 0.7503,
      "step": 13480
    },
    {
      "epoch": 3.854285714285714,
      "grad_norm": 0.7369078397750854,
      "learning_rate": 1.4860952380952383e-05,
      "loss": 0.4334,
      "step": 13490
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 10.622162818908691,
      "learning_rate": 1.4857142857142858e-05,
      "loss": 0.7429,
      "step": 13500
    },
    {
      "epoch": 3.86,
      "grad_norm": 10.47241497039795,
      "learning_rate": 1.4853333333333336e-05,
      "loss": 0.6215,
      "step": 13510
    },
    {
      "epoch": 3.862857142857143,
      "grad_norm": 11.422052383422852,
      "learning_rate": 1.4849523809523811e-05,
      "loss": 0.5119,
      "step": 13520
    },
    {
      "epoch": 3.8657142857142857,
      "grad_norm": 0.9379856586456299,
      "learning_rate": 1.4845714285714289e-05,
      "loss": 0.4106,
      "step": 13530
    },
    {
      "epoch": 3.8685714285714283,
      "grad_norm": 0.8778988718986511,
      "learning_rate": 1.4841904761904764e-05,
      "loss": 0.3101,
      "step": 13540
    },
    {
      "epoch": 3.8714285714285714,
      "grad_norm": 0.7725510001182556,
      "learning_rate": 1.483809523809524e-05,
      "loss": 0.5217,
      "step": 13550
    },
    {
      "epoch": 3.8742857142857146,
      "grad_norm": 10.923795700073242,
      "learning_rate": 1.4834285714285714e-05,
      "loss": 0.5284,
      "step": 13560
    },
    {
      "epoch": 3.8771428571428572,
      "grad_norm": 0.6896253824234009,
      "learning_rate": 1.4830476190476191e-05,
      "loss": 0.2229,
      "step": 13570
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.7099769115447998,
      "learning_rate": 1.4826666666666666e-05,
      "loss": 0.8549,
      "step": 13580
    },
    {
      "epoch": 3.882857142857143,
      "grad_norm": 0.6550300121307373,
      "learning_rate": 1.4822857142857144e-05,
      "loss": 0.2225,
      "step": 13590
    },
    {
      "epoch": 3.8857142857142857,
      "grad_norm": 11.406063079833984,
      "learning_rate": 1.481904761904762e-05,
      "loss": 0.7625,
      "step": 13600
    },
    {
      "epoch": 3.888571428571429,
      "grad_norm": 10.611648559570312,
      "learning_rate": 1.4815238095238097e-05,
      "loss": 0.739,
      "step": 13610
    },
    {
      "epoch": 3.8914285714285715,
      "grad_norm": 0.9952058792114258,
      "learning_rate": 1.4811428571428572e-05,
      "loss": 0.7131,
      "step": 13620
    },
    {
      "epoch": 3.894285714285714,
      "grad_norm": 0.9961634874343872,
      "learning_rate": 1.4807619047619048e-05,
      "loss": 0.5967,
      "step": 13630
    },
    {
      "epoch": 3.8971428571428572,
      "grad_norm": 0.8715954422950745,
      "learning_rate": 1.4803809523809525e-05,
      "loss": 0.4088,
      "step": 13640
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.9866162538528442,
      "learning_rate": 1.48e-05,
      "loss": 0.5083,
      "step": 13650
    },
    {
      "epoch": 3.902857142857143,
      "grad_norm": 10.10093879699707,
      "learning_rate": 1.4796190476190478e-05,
      "loss": 0.776,
      "step": 13660
    },
    {
      "epoch": 3.9057142857142857,
      "grad_norm": 1.350630283355713,
      "learning_rate": 1.4792380952380953e-05,
      "loss": 0.4723,
      "step": 13670
    },
    {
      "epoch": 3.9085714285714284,
      "grad_norm": 21.556669235229492,
      "learning_rate": 1.478857142857143e-05,
      "loss": 0.8396,
      "step": 13680
    },
    {
      "epoch": 3.9114285714285715,
      "grad_norm": 10.336677551269531,
      "learning_rate": 1.4784761904761906e-05,
      "loss": 0.3981,
      "step": 13690
    },
    {
      "epoch": 3.914285714285714,
      "grad_norm": 10.282947540283203,
      "learning_rate": 1.4780952380952382e-05,
      "loss": 0.7638,
      "step": 13700
    },
    {
      "epoch": 3.9171428571428573,
      "grad_norm": 1.2172385454177856,
      "learning_rate": 1.477714285714286e-05,
      "loss": 0.4775,
      "step": 13710
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.9951799511909485,
      "learning_rate": 1.4773333333333335e-05,
      "loss": 0.2108,
      "step": 13720
    },
    {
      "epoch": 3.9228571428571426,
      "grad_norm": 0.7802183032035828,
      "learning_rate": 1.4769523809523812e-05,
      "loss": 0.3199,
      "step": 13730
    },
    {
      "epoch": 3.9257142857142857,
      "grad_norm": 0.6238077282905579,
      "learning_rate": 1.4765714285714288e-05,
      "loss": 0.2178,
      "step": 13740
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 0.5893489122390747,
      "learning_rate": 1.4761904761904763e-05,
      "loss": 0.6704,
      "step": 13750
    },
    {
      "epoch": 3.9314285714285715,
      "grad_norm": 0.5707422494888306,
      "learning_rate": 1.475809523809524e-05,
      "loss": 0.4463,
      "step": 13760
    },
    {
      "epoch": 3.934285714285714,
      "grad_norm": 0.6248857975006104,
      "learning_rate": 1.4754285714285716e-05,
      "loss": 0.7754,
      "step": 13770
    },
    {
      "epoch": 3.9371428571428573,
      "grad_norm": 0.7543703317642212,
      "learning_rate": 1.475047619047619e-05,
      "loss": 0.3176,
      "step": 13780
    },
    {
      "epoch": 3.94,
      "grad_norm": 0.6202457547187805,
      "learning_rate": 1.4746666666666667e-05,
      "loss": 0.444,
      "step": 13790
    },
    {
      "epoch": 3.942857142857143,
      "grad_norm": 0.5108984708786011,
      "learning_rate": 1.4742857142857143e-05,
      "loss": 0.2333,
      "step": 13800
    },
    {
      "epoch": 3.9457142857142857,
      "grad_norm": 0.4504583775997162,
      "learning_rate": 1.473904761904762e-05,
      "loss": 0.3511,
      "step": 13810
    },
    {
      "epoch": 3.9485714285714284,
      "grad_norm": 0.30406615138053894,
      "learning_rate": 1.4735238095238096e-05,
      "loss": 0.5067,
      "step": 13820
    },
    {
      "epoch": 3.9514285714285715,
      "grad_norm": 0.3239894509315491,
      "learning_rate": 1.4731428571428571e-05,
      "loss": 0.627,
      "step": 13830
    },
    {
      "epoch": 3.954285714285714,
      "grad_norm": 22.471233367919922,
      "learning_rate": 1.4727619047619049e-05,
      "loss": 0.4971,
      "step": 13840
    },
    {
      "epoch": 3.9571428571428573,
      "grad_norm": 11.304658889770508,
      "learning_rate": 1.4723809523809524e-05,
      "loss": 0.4865,
      "step": 13850
    },
    {
      "epoch": 3.96,
      "grad_norm": 22.18218994140625,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.6,
      "step": 13860
    },
    {
      "epoch": 3.9628571428571426,
      "grad_norm": 0.44835564494132996,
      "learning_rate": 1.4716190476190477e-05,
      "loss": 0.5939,
      "step": 13870
    },
    {
      "epoch": 3.9657142857142857,
      "grad_norm": 10.743661880493164,
      "learning_rate": 1.4712380952380954e-05,
      "loss": 0.571,
      "step": 13880
    },
    {
      "epoch": 3.9685714285714284,
      "grad_norm": 0.5768277049064636,
      "learning_rate": 1.470857142857143e-05,
      "loss": 0.3412,
      "step": 13890
    },
    {
      "epoch": 3.9714285714285715,
      "grad_norm": 10.79834270477295,
      "learning_rate": 1.4704761904761905e-05,
      "loss": 0.2347,
      "step": 13900
    },
    {
      "epoch": 3.974285714285714,
      "grad_norm": 10.7900390625,
      "learning_rate": 1.4700952380952383e-05,
      "loss": 0.57,
      "step": 13910
    },
    {
      "epoch": 3.977142857142857,
      "grad_norm": 0.4716187119483948,
      "learning_rate": 1.4697142857142858e-05,
      "loss": 0.2431,
      "step": 13920
    },
    {
      "epoch": 3.98,
      "grad_norm": 22.023054122924805,
      "learning_rate": 1.4693333333333336e-05,
      "loss": 0.9189,
      "step": 13930
    },
    {
      "epoch": 3.982857142857143,
      "grad_norm": 0.6010158658027649,
      "learning_rate": 1.4689523809523811e-05,
      "loss": 0.7836,
      "step": 13940
    },
    {
      "epoch": 3.9857142857142858,
      "grad_norm": 10.585946083068848,
      "learning_rate": 1.4685714285714288e-05,
      "loss": 0.7447,
      "step": 13950
    },
    {
      "epoch": 3.9885714285714284,
      "grad_norm": 0.8082396388053894,
      "learning_rate": 1.4681904761904764e-05,
      "loss": 0.414,
      "step": 13960
    },
    {
      "epoch": 3.9914285714285715,
      "grad_norm": 10.875014305114746,
      "learning_rate": 1.467809523809524e-05,
      "loss": 1.0266,
      "step": 13970
    },
    {
      "epoch": 3.994285714285714,
      "grad_norm": 0.9737720489501953,
      "learning_rate": 1.4674285714285717e-05,
      "loss": 0.3063,
      "step": 13980
    },
    {
      "epoch": 3.9971428571428573,
      "grad_norm": 10.696009635925293,
      "learning_rate": 1.4670476190476192e-05,
      "loss": 0.4285,
      "step": 13990
    },
    {
      "epoch": 4.0,
      "grad_norm": 10.80551815032959,
      "learning_rate": 1.4666666666666666e-05,
      "loss": 0.9589,
      "step": 14000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8893333333333333,
      "eval_f1": 0.0,
      "eval_loss": 0.47558513283729553,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 263.1704,
      "eval_samples_per_second": 11.399,
      "eval_steps_per_second": 2.85,
      "step": 14000
    },
    {
      "epoch": 4.002857142857143,
      "grad_norm": 0.716199517250061,
      "learning_rate": 1.4662857142857144e-05,
      "loss": 0.639,
      "step": 14010
    },
    {
      "epoch": 4.005714285714285,
      "grad_norm": 10.668749809265137,
      "learning_rate": 1.4659047619047619e-05,
      "loss": 0.7321,
      "step": 14020
    },
    {
      "epoch": 4.008571428571429,
      "grad_norm": 0.9052846431732178,
      "learning_rate": 1.4655238095238096e-05,
      "loss": 0.512,
      "step": 14030
    },
    {
      "epoch": 4.011428571428572,
      "grad_norm": 10.516236305236816,
      "learning_rate": 1.4651428571428572e-05,
      "loss": 0.4206,
      "step": 14040
    },
    {
      "epoch": 4.014285714285714,
      "grad_norm": 21.840600967407227,
      "learning_rate": 1.4647619047619048e-05,
      "loss": 0.424,
      "step": 14050
    },
    {
      "epoch": 4.017142857142857,
      "grad_norm": 0.710886538028717,
      "learning_rate": 1.4643809523809525e-05,
      "loss": 0.528,
      "step": 14060
    },
    {
      "epoch": 4.02,
      "grad_norm": 11.051472663879395,
      "learning_rate": 1.464e-05,
      "loss": 0.4377,
      "step": 14070
    },
    {
      "epoch": 4.022857142857143,
      "grad_norm": 0.6045483350753784,
      "learning_rate": 1.4636190476190478e-05,
      "loss": 0.1203,
      "step": 14080
    },
    {
      "epoch": 4.025714285714286,
      "grad_norm": 0.5549367666244507,
      "learning_rate": 1.4632380952380953e-05,
      "loss": 0.5599,
      "step": 14090
    },
    {
      "epoch": 4.0285714285714285,
      "grad_norm": 0.5548436641693115,
      "learning_rate": 1.462857142857143e-05,
      "loss": 0.5588,
      "step": 14100
    },
    {
      "epoch": 4.031428571428571,
      "grad_norm": 10.76212215423584,
      "learning_rate": 1.4624761904761906e-05,
      "loss": 0.7809,
      "step": 14110
    },
    {
      "epoch": 4.034285714285715,
      "grad_norm": 0.707958459854126,
      "learning_rate": 1.4620952380952382e-05,
      "loss": 0.762,
      "step": 14120
    },
    {
      "epoch": 4.037142857142857,
      "grad_norm": 0.6995324492454529,
      "learning_rate": 1.4617142857142859e-05,
      "loss": 0.4324,
      "step": 14130
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.5837854743003845,
      "learning_rate": 1.4613333333333335e-05,
      "loss": 0.4351,
      "step": 14140
    },
    {
      "epoch": 4.042857142857143,
      "grad_norm": 10.77462387084961,
      "learning_rate": 1.4609523809523812e-05,
      "loss": 0.4527,
      "step": 14150
    },
    {
      "epoch": 4.045714285714285,
      "grad_norm": 22.150053024291992,
      "learning_rate": 1.4605714285714287e-05,
      "loss": 0.4577,
      "step": 14160
    },
    {
      "epoch": 4.048571428571429,
      "grad_norm": 0.5913546681404114,
      "learning_rate": 1.4601904761904763e-05,
      "loss": 0.5689,
      "step": 14170
    },
    {
      "epoch": 4.051428571428572,
      "grad_norm": 0.5916043519973755,
      "learning_rate": 1.459809523809524e-05,
      "loss": 0.4471,
      "step": 14180
    },
    {
      "epoch": 4.054285714285714,
      "grad_norm": 10.832375526428223,
      "learning_rate": 1.4594285714285716e-05,
      "loss": 0.2354,
      "step": 14190
    },
    {
      "epoch": 4.057142857142857,
      "grad_norm": 0.514352023601532,
      "learning_rate": 1.4590476190476193e-05,
      "loss": 0.5708,
      "step": 14200
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.528403639793396,
      "learning_rate": 1.4586666666666667e-05,
      "loss": 0.2327,
      "step": 14210
    },
    {
      "epoch": 4.062857142857143,
      "grad_norm": 10.950610160827637,
      "learning_rate": 1.4582857142857143e-05,
      "loss": 0.8778,
      "step": 14220
    },
    {
      "epoch": 4.065714285714286,
      "grad_norm": 0.7913592457771301,
      "learning_rate": 1.457904761904762e-05,
      "loss": 0.2247,
      "step": 14230
    },
    {
      "epoch": 4.0685714285714285,
      "grad_norm": 11.288993835449219,
      "learning_rate": 1.4575238095238095e-05,
      "loss": 0.1245,
      "step": 14240
    },
    {
      "epoch": 4.071428571428571,
      "grad_norm": 0.48437047004699707,
      "learning_rate": 1.4571428571428573e-05,
      "loss": 0.4559,
      "step": 14250
    },
    {
      "epoch": 4.074285714285715,
      "grad_norm": 0.545764684677124,
      "learning_rate": 1.4567619047619048e-05,
      "loss": 0.2348,
      "step": 14260
    },
    {
      "epoch": 4.077142857142857,
      "grad_norm": 10.816534996032715,
      "learning_rate": 1.4563809523809524e-05,
      "loss": 1.1183,
      "step": 14270
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.7371754050254822,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.5482,
      "step": 14280
    },
    {
      "epoch": 4.082857142857143,
      "grad_norm": 0.7797554731369019,
      "learning_rate": 1.4556190476190477e-05,
      "loss": 0.525,
      "step": 14290
    },
    {
      "epoch": 4.085714285714285,
      "grad_norm": 10.645021438598633,
      "learning_rate": 1.4552380952380954e-05,
      "loss": 0.5269,
      "step": 14300
    },
    {
      "epoch": 4.088571428571429,
      "grad_norm": 0.6060476899147034,
      "learning_rate": 1.454857142857143e-05,
      "loss": 0.1202,
      "step": 14310
    },
    {
      "epoch": 4.091428571428572,
      "grad_norm": 22.289167404174805,
      "learning_rate": 1.4544761904761905e-05,
      "loss": 0.7949,
      "step": 14320
    },
    {
      "epoch": 4.094285714285714,
      "grad_norm": 0.5448958873748779,
      "learning_rate": 1.4540952380952383e-05,
      "loss": 0.5709,
      "step": 14330
    },
    {
      "epoch": 4.097142857142857,
      "grad_norm": 10.774365425109863,
      "learning_rate": 1.4537142857142858e-05,
      "loss": 0.5569,
      "step": 14340
    },
    {
      "epoch": 4.1,
      "grad_norm": 10.8878755569458,
      "learning_rate": 1.4533333333333335e-05,
      "loss": 0.3361,
      "step": 14350
    },
    {
      "epoch": 4.102857142857143,
      "grad_norm": 0.4911959171295166,
      "learning_rate": 1.4529523809523811e-05,
      "loss": 0.2372,
      "step": 14360
    },
    {
      "epoch": 4.105714285714286,
      "grad_norm": 11.010342597961426,
      "learning_rate": 1.4525714285714288e-05,
      "loss": 0.3542,
      "step": 14370
    },
    {
      "epoch": 4.1085714285714285,
      "grad_norm": 10.881795883178711,
      "learning_rate": 1.4521904761904764e-05,
      "loss": 0.9278,
      "step": 14380
    },
    {
      "epoch": 4.111428571428571,
      "grad_norm": 0.6352941393852234,
      "learning_rate": 1.451809523809524e-05,
      "loss": 0.5611,
      "step": 14390
    },
    {
      "epoch": 4.114285714285714,
      "grad_norm": 0.6032260060310364,
      "learning_rate": 1.4514285714285717e-05,
      "loss": 0.4452,
      "step": 14400
    },
    {
      "epoch": 4.117142857142857,
      "grad_norm": 0.6195569634437561,
      "learning_rate": 1.4510476190476192e-05,
      "loss": 0.5619,
      "step": 14410
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.6504101157188416,
      "learning_rate": 1.450666666666667e-05,
      "loss": 0.6619,
      "step": 14420
    },
    {
      "epoch": 4.122857142857143,
      "grad_norm": 10.768940925598145,
      "learning_rate": 1.4502857142857143e-05,
      "loss": 0.5421,
      "step": 14430
    },
    {
      "epoch": 4.1257142857142854,
      "grad_norm": 0.7083576321601868,
      "learning_rate": 1.4499047619047619e-05,
      "loss": 0.4283,
      "step": 14440
    },
    {
      "epoch": 4.128571428571428,
      "grad_norm": 0.6485610604286194,
      "learning_rate": 1.4495238095238096e-05,
      "loss": 0.1167,
      "step": 14450
    },
    {
      "epoch": 4.131428571428572,
      "grad_norm": 0.5216156840324402,
      "learning_rate": 1.4491428571428572e-05,
      "loss": 0.2303,
      "step": 14460
    },
    {
      "epoch": 4.134285714285714,
      "grad_norm": 0.47311633825302124,
      "learning_rate": 1.4487619047619047e-05,
      "loss": 0.4637,
      "step": 14470
    },
    {
      "epoch": 4.137142857142857,
      "grad_norm": 0.4816964566707611,
      "learning_rate": 1.4483809523809525e-05,
      "loss": 0.6964,
      "step": 14480
    },
    {
      "epoch": 4.14,
      "grad_norm": 0.5102701783180237,
      "learning_rate": 1.448e-05,
      "loss": 0.3482,
      "step": 14490
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 10.875831604003906,
      "learning_rate": 1.4476190476190478e-05,
      "loss": 0.2376,
      "step": 14500
    },
    {
      "epoch": 4.145714285714286,
      "grad_norm": 22.070598602294922,
      "learning_rate": 1.4472380952380953e-05,
      "loss": 0.8089,
      "step": 14510
    },
    {
      "epoch": 4.148571428571429,
      "grad_norm": 0.45603054761886597,
      "learning_rate": 1.446857142857143e-05,
      "loss": 0.2402,
      "step": 14520
    },
    {
      "epoch": 4.151428571428571,
      "grad_norm": 0.4935736656188965,
      "learning_rate": 1.4464761904761906e-05,
      "loss": 0.6938,
      "step": 14530
    },
    {
      "epoch": 4.154285714285714,
      "grad_norm": 10.968034744262695,
      "learning_rate": 1.4460952380952382e-05,
      "loss": 0.6873,
      "step": 14540
    },
    {
      "epoch": 4.1571428571428575,
      "grad_norm": 10.758533477783203,
      "learning_rate": 1.4457142857142859e-05,
      "loss": 0.5663,
      "step": 14550
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.5556194186210632,
      "learning_rate": 1.4453333333333334e-05,
      "loss": 0.3412,
      "step": 14560
    },
    {
      "epoch": 4.162857142857143,
      "grad_norm": 0.5367383360862732,
      "learning_rate": 1.4449523809523812e-05,
      "loss": 0.5625,
      "step": 14570
    },
    {
      "epoch": 4.1657142857142855,
      "grad_norm": 10.790584564208984,
      "learning_rate": 1.4445714285714287e-05,
      "loss": 0.4543,
      "step": 14580
    },
    {
      "epoch": 4.168571428571428,
      "grad_norm": 0.5376725792884827,
      "learning_rate": 1.4441904761904763e-05,
      "loss": 0.3445,
      "step": 14590
    },
    {
      "epoch": 4.171428571428572,
      "grad_norm": 0.5391020774841309,
      "learning_rate": 1.443809523809524e-05,
      "loss": 0.4561,
      "step": 14600
    },
    {
      "epoch": 4.174285714285714,
      "grad_norm": 0.5545398592948914,
      "learning_rate": 1.4434285714285716e-05,
      "loss": 0.673,
      "step": 14610
    },
    {
      "epoch": 4.177142857142857,
      "grad_norm": 0.5920392870903015,
      "learning_rate": 1.4430476190476193e-05,
      "loss": 0.6632,
      "step": 14620
    },
    {
      "epoch": 4.18,
      "grad_norm": 10.648860931396484,
      "learning_rate": 1.4426666666666669e-05,
      "loss": 0.3353,
      "step": 14630
    },
    {
      "epoch": 4.182857142857143,
      "grad_norm": 10.714766502380371,
      "learning_rate": 1.4422857142857146e-05,
      "loss": 0.4404,
      "step": 14640
    },
    {
      "epoch": 4.185714285714286,
      "grad_norm": 0.6564809679985046,
      "learning_rate": 1.441904761904762e-05,
      "loss": 0.6517,
      "step": 14650
    },
    {
      "epoch": 4.188571428571429,
      "grad_norm": 0.7968083620071411,
      "learning_rate": 1.4415238095238095e-05,
      "loss": 0.6357,
      "step": 14660
    },
    {
      "epoch": 4.191428571428571,
      "grad_norm": 10.626153945922852,
      "learning_rate": 1.4411428571428573e-05,
      "loss": 0.2228,
      "step": 14670
    },
    {
      "epoch": 4.194285714285714,
      "grad_norm": 0.6674389243125916,
      "learning_rate": 1.4407619047619048e-05,
      "loss": 0.7506,
      "step": 14680
    },
    {
      "epoch": 4.1971428571428575,
      "grad_norm": 0.672426700592041,
      "learning_rate": 1.4403809523809524e-05,
      "loss": 0.3301,
      "step": 14690
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.6710439920425415,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.7568,
      "step": 14700
    },
    {
      "epoch": 4.202857142857143,
      "grad_norm": 0.7476286888122559,
      "learning_rate": 1.4396190476190477e-05,
      "loss": 0.6407,
      "step": 14710
    },
    {
      "epoch": 4.2057142857142855,
      "grad_norm": 0.799553632736206,
      "learning_rate": 1.4392380952380954e-05,
      "loss": 0.633,
      "step": 14720
    },
    {
      "epoch": 4.208571428571428,
      "grad_norm": 10.762252807617188,
      "learning_rate": 1.438857142857143e-05,
      "loss": 0.5254,
      "step": 14730
    },
    {
      "epoch": 4.211428571428572,
      "grad_norm": 21.792892456054688,
      "learning_rate": 1.4384761904761905e-05,
      "loss": 0.6248,
      "step": 14740
    },
    {
      "epoch": 4.214285714285714,
      "grad_norm": 0.7422332167625427,
      "learning_rate": 1.4380952380952382e-05,
      "loss": 0.2207,
      "step": 14750
    },
    {
      "epoch": 4.217142857142857,
      "grad_norm": 10.624013900756836,
      "learning_rate": 1.4377142857142858e-05,
      "loss": 0.3301,
      "step": 14760
    },
    {
      "epoch": 4.22,
      "grad_norm": 10.75683307647705,
      "learning_rate": 1.4373333333333335e-05,
      "loss": 0.647,
      "step": 14770
    },
    {
      "epoch": 4.222857142857142,
      "grad_norm": 0.6677300333976746,
      "learning_rate": 1.436952380952381e-05,
      "loss": 0.646,
      "step": 14780
    },
    {
      "epoch": 4.225714285714286,
      "grad_norm": 0.6401053667068481,
      "learning_rate": 1.4365714285714288e-05,
      "loss": 0.3313,
      "step": 14790
    },
    {
      "epoch": 4.228571428571429,
      "grad_norm": 0.6010218858718872,
      "learning_rate": 1.4361904761904764e-05,
      "loss": 0.2278,
      "step": 14800
    },
    {
      "epoch": 4.231428571428571,
      "grad_norm": 0.6106328964233398,
      "learning_rate": 1.435809523809524e-05,
      "loss": 0.6609,
      "step": 14810
    },
    {
      "epoch": 4.234285714285714,
      "grad_norm": 10.656597137451172,
      "learning_rate": 1.4354285714285716e-05,
      "loss": 0.8637,
      "step": 14820
    },
    {
      "epoch": 4.2371428571428575,
      "grad_norm": 22.046146392822266,
      "learning_rate": 1.4350476190476192e-05,
      "loss": 0.4334,
      "step": 14830
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.7393231391906738,
      "learning_rate": 1.434666666666667e-05,
      "loss": 0.7457,
      "step": 14840
    },
    {
      "epoch": 4.242857142857143,
      "grad_norm": 0.7220777273178101,
      "learning_rate": 1.4342857142857145e-05,
      "loss": 0.4322,
      "step": 14850
    },
    {
      "epoch": 4.2457142857142856,
      "grad_norm": 0.7335102558135986,
      "learning_rate": 1.433904761904762e-05,
      "loss": 0.5311,
      "step": 14860
    },
    {
      "epoch": 4.248571428571428,
      "grad_norm": 0.6755687594413757,
      "learning_rate": 1.4335238095238096e-05,
      "loss": 0.3266,
      "step": 14870
    },
    {
      "epoch": 4.251428571428572,
      "grad_norm": 0.6856958270072937,
      "learning_rate": 1.4331428571428572e-05,
      "loss": 1.0646,
      "step": 14880
    },
    {
      "epoch": 4.2542857142857144,
      "grad_norm": 0.733401894569397,
      "learning_rate": 1.4327619047619047e-05,
      "loss": 0.3266,
      "step": 14890
    },
    {
      "epoch": 4.257142857142857,
      "grad_norm": 0.7457966208457947,
      "learning_rate": 1.4323809523809525e-05,
      "loss": 0.8352,
      "step": 14900
    },
    {
      "epoch": 4.26,
      "grad_norm": 0.7841904759407043,
      "learning_rate": 1.432e-05,
      "loss": 0.3223,
      "step": 14910
    },
    {
      "epoch": 4.2628571428571425,
      "grad_norm": 0.7385561466217041,
      "learning_rate": 1.4316190476190477e-05,
      "loss": 0.5311,
      "step": 14920
    },
    {
      "epoch": 4.265714285714286,
      "grad_norm": 11.472935676574707,
      "learning_rate": 1.4312380952380953e-05,
      "loss": 0.5365,
      "step": 14930
    },
    {
      "epoch": 4.268571428571429,
      "grad_norm": 0.6740353107452393,
      "learning_rate": 1.430857142857143e-05,
      "loss": 0.3311,
      "step": 14940
    },
    {
      "epoch": 4.271428571428571,
      "grad_norm": 0.6233417391777039,
      "learning_rate": 1.4304761904761906e-05,
      "loss": 0.3298,
      "step": 14950
    },
    {
      "epoch": 4.274285714285714,
      "grad_norm": 0.5361244678497314,
      "learning_rate": 1.4300952380952381e-05,
      "loss": 0.3422,
      "step": 14960
    },
    {
      "epoch": 4.277142857142858,
      "grad_norm": 10.825729370117188,
      "learning_rate": 1.4297142857142859e-05,
      "loss": 0.3466,
      "step": 14970
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.5761561393737793,
      "learning_rate": 1.4293333333333334e-05,
      "loss": 0.6801,
      "step": 14980
    },
    {
      "epoch": 4.282857142857143,
      "grad_norm": 10.726919174194336,
      "learning_rate": 1.4289523809523812e-05,
      "loss": 0.5527,
      "step": 14990
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.705149233341217,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 0.8611,
      "step": 15000
    },
    {
      "epoch": 4.288571428571428,
      "grad_norm": 10.487224578857422,
      "learning_rate": 1.4281904761904763e-05,
      "loss": 0.9308,
      "step": 15010
    },
    {
      "epoch": 4.291428571428572,
      "grad_norm": 0.9815040230751038,
      "learning_rate": 1.427809523809524e-05,
      "loss": 0.6923,
      "step": 15020
    },
    {
      "epoch": 4.2942857142857145,
      "grad_norm": 1.1588503122329712,
      "learning_rate": 1.4274285714285716e-05,
      "loss": 0.5837,
      "step": 15030
    },
    {
      "epoch": 4.297142857142857,
      "grad_norm": 1.0942708253860474,
      "learning_rate": 1.4270476190476193e-05,
      "loss": 0.5809,
      "step": 15040
    },
    {
      "epoch": 4.3,
      "grad_norm": 0.821993887424469,
      "learning_rate": 1.4266666666666668e-05,
      "loss": 0.0214,
      "step": 15050
    },
    {
      "epoch": 4.3028571428571425,
      "grad_norm": 0.7234801650047302,
      "learning_rate": 1.4262857142857146e-05,
      "loss": 0.7289,
      "step": 15060
    },
    {
      "epoch": 4.305714285714286,
      "grad_norm": 0.6553003191947937,
      "learning_rate": 1.4259047619047621e-05,
      "loss": 0.2231,
      "step": 15070
    },
    {
      "epoch": 4.308571428571429,
      "grad_norm": 10.72426986694336,
      "learning_rate": 1.4255238095238095e-05,
      "loss": 0.4403,
      "step": 15080
    },
    {
      "epoch": 4.311428571428571,
      "grad_norm": 0.5656178593635559,
      "learning_rate": 1.4251428571428572e-05,
      "loss": 0.4469,
      "step": 15090
    },
    {
      "epoch": 4.314285714285714,
      "grad_norm": 10.965518951416016,
      "learning_rate": 1.4247619047619048e-05,
      "loss": 0.3388,
      "step": 15100
    },
    {
      "epoch": 4.317142857142857,
      "grad_norm": 0.4977133870124817,
      "learning_rate": 1.4243809523809524e-05,
      "loss": 0.3512,
      "step": 15110
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.4933168888092041,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.5773,
      "step": 15120
    },
    {
      "epoch": 4.322857142857143,
      "grad_norm": 0.41476693749427795,
      "learning_rate": 1.4236190476190476e-05,
      "loss": 0.4831,
      "step": 15130
    },
    {
      "epoch": 4.325714285714286,
      "grad_norm": 0.42710238695144653,
      "learning_rate": 1.4232380952380954e-05,
      "loss": 0.4829,
      "step": 15140
    },
    {
      "epoch": 4.328571428571428,
      "grad_norm": 0.4190826416015625,
      "learning_rate": 1.422857142857143e-05,
      "loss": 0.5975,
      "step": 15150
    },
    {
      "epoch": 4.331428571428571,
      "grad_norm": 0.4816734492778778,
      "learning_rate": 1.4224761904761905e-05,
      "loss": 0.9292,
      "step": 15160
    },
    {
      "epoch": 4.3342857142857145,
      "grad_norm": 0.6406843066215515,
      "learning_rate": 1.4220952380952382e-05,
      "loss": 0.5567,
      "step": 15170
    },
    {
      "epoch": 4.337142857142857,
      "grad_norm": 22.007858276367188,
      "learning_rate": 1.4217142857142858e-05,
      "loss": 0.753,
      "step": 15180
    },
    {
      "epoch": 4.34,
      "grad_norm": 0.8360965847969055,
      "learning_rate": 1.4213333333333335e-05,
      "loss": 0.6312,
      "step": 15190
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.8344851732254028,
      "learning_rate": 1.420952380952381e-05,
      "loss": 0.3149,
      "step": 15200
    },
    {
      "epoch": 4.345714285714286,
      "grad_norm": 0.761841893196106,
      "learning_rate": 1.4205714285714288e-05,
      "loss": 0.3195,
      "step": 15210
    },
    {
      "epoch": 4.348571428571429,
      "grad_norm": 0.6879053711891174,
      "learning_rate": 1.4201904761904763e-05,
      "loss": 0.4246,
      "step": 15220
    },
    {
      "epoch": 4.351428571428571,
      "grad_norm": 0.6653305292129517,
      "learning_rate": 1.4198095238095239e-05,
      "loss": 0.9529,
      "step": 15230
    },
    {
      "epoch": 4.354285714285714,
      "grad_norm": 10.707183837890625,
      "learning_rate": 1.4194285714285716e-05,
      "loss": 0.4332,
      "step": 15240
    },
    {
      "epoch": 4.357142857142857,
      "grad_norm": 0.6487802863121033,
      "learning_rate": 1.4190476190476192e-05,
      "loss": 0.2224,
      "step": 15250
    },
    {
      "epoch": 4.36,
      "grad_norm": 10.791793823242188,
      "learning_rate": 1.418666666666667e-05,
      "loss": 0.975,
      "step": 15260
    },
    {
      "epoch": 4.362857142857143,
      "grad_norm": 0.7306968569755554,
      "learning_rate": 1.4182857142857145e-05,
      "loss": 0.332,
      "step": 15270
    },
    {
      "epoch": 4.365714285714286,
      "grad_norm": 0.6347887516021729,
      "learning_rate": 1.417904761904762e-05,
      "loss": 0.4398,
      "step": 15280
    },
    {
      "epoch": 4.368571428571428,
      "grad_norm": 10.743108749389648,
      "learning_rate": 1.4175238095238098e-05,
      "loss": 0.1233,
      "step": 15290
    },
    {
      "epoch": 4.371428571428572,
      "grad_norm": 10.759794235229492,
      "learning_rate": 1.4171428571428572e-05,
      "loss": 0.7797,
      "step": 15300
    },
    {
      "epoch": 4.3742857142857146,
      "grad_norm": 0.5672657489776611,
      "learning_rate": 1.4167619047619047e-05,
      "loss": 0.4516,
      "step": 15310
    },
    {
      "epoch": 4.377142857142857,
      "grad_norm": 0.5389976501464844,
      "learning_rate": 1.4163809523809524e-05,
      "loss": 0.1216,
      "step": 15320
    },
    {
      "epoch": 4.38,
      "grad_norm": 0.5284858345985413,
      "learning_rate": 1.416e-05,
      "loss": 0.6773,
      "step": 15330
    },
    {
      "epoch": 4.382857142857143,
      "grad_norm": 0.532387375831604,
      "learning_rate": 1.4156190476190477e-05,
      "loss": 0.3485,
      "step": 15340
    },
    {
      "epoch": 4.385714285714286,
      "grad_norm": 0.5205528140068054,
      "learning_rate": 1.4152380952380953e-05,
      "loss": 0.4541,
      "step": 15350
    },
    {
      "epoch": 4.388571428571429,
      "grad_norm": 0.5362139344215393,
      "learning_rate": 1.414857142857143e-05,
      "loss": 0.5677,
      "step": 15360
    },
    {
      "epoch": 4.3914285714285715,
      "grad_norm": 10.755668640136719,
      "learning_rate": 1.4144761904761906e-05,
      "loss": 0.7884,
      "step": 15370
    },
    {
      "epoch": 4.394285714285714,
      "grad_norm": 10.716039657592773,
      "learning_rate": 1.4140952380952381e-05,
      "loss": 0.447,
      "step": 15380
    },
    {
      "epoch": 4.397142857142857,
      "grad_norm": 10.752685546875,
      "learning_rate": 1.4137142857142859e-05,
      "loss": 0.5485,
      "step": 15390
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.7187442779541016,
      "learning_rate": 1.4133333333333334e-05,
      "loss": 0.5435,
      "step": 15400
    },
    {
      "epoch": 4.402857142857143,
      "grad_norm": 0.7056079506874084,
      "learning_rate": 1.4129523809523811e-05,
      "loss": 0.5344,
      "step": 15410
    },
    {
      "epoch": 4.405714285714286,
      "grad_norm": 10.60781478881836,
      "learning_rate": 1.4125714285714287e-05,
      "loss": 0.7424,
      "step": 15420
    },
    {
      "epoch": 4.408571428571428,
      "grad_norm": 0.7431207895278931,
      "learning_rate": 1.4121904761904763e-05,
      "loss": 0.3258,
      "step": 15430
    },
    {
      "epoch": 4.411428571428571,
      "grad_norm": 10.691307067871094,
      "learning_rate": 1.411809523809524e-05,
      "loss": 0.4288,
      "step": 15440
    },
    {
      "epoch": 4.414285714285715,
      "grad_norm": 0.6464414000511169,
      "learning_rate": 1.4114285714285715e-05,
      "loss": 0.5428,
      "step": 15450
    },
    {
      "epoch": 4.417142857142857,
      "grad_norm": 10.678970336914062,
      "learning_rate": 1.4110476190476193e-05,
      "loss": 0.5455,
      "step": 15460
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.59996098279953,
      "learning_rate": 1.4106666666666668e-05,
      "loss": 0.337,
      "step": 15470
    },
    {
      "epoch": 4.422857142857143,
      "grad_norm": 0.5224235653877258,
      "learning_rate": 1.4102857142857146e-05,
      "loss": 0.4567,
      "step": 15480
    },
    {
      "epoch": 4.425714285714285,
      "grad_norm": 0.4857173264026642,
      "learning_rate": 1.4099047619047621e-05,
      "loss": 0.2351,
      "step": 15490
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 22.082988739013672,
      "learning_rate": 1.4095238095238097e-05,
      "loss": 0.4642,
      "step": 15500
    },
    {
      "epoch": 4.4314285714285715,
      "grad_norm": 0.4720987379550934,
      "learning_rate": 1.4091428571428574e-05,
      "loss": 0.3519,
      "step": 15510
    },
    {
      "epoch": 4.434285714285714,
      "grad_norm": 10.83612060546875,
      "learning_rate": 1.4087619047619048e-05,
      "loss": 0.5796,
      "step": 15520
    },
    {
      "epoch": 4.437142857142857,
      "grad_norm": 0.5113015174865723,
      "learning_rate": 1.4083809523809523e-05,
      "loss": 0.5764,
      "step": 15530
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.5669815540313721,
      "learning_rate": 1.408e-05,
      "loss": 0.906,
      "step": 15540
    },
    {
      "epoch": 4.442857142857143,
      "grad_norm": 0.5496664047241211,
      "learning_rate": 1.4076190476190476e-05,
      "loss": 0.2335,
      "step": 15550
    },
    {
      "epoch": 4.445714285714286,
      "grad_norm": 10.809168815612793,
      "learning_rate": 1.4072380952380954e-05,
      "loss": 0.6806,
      "step": 15560
    },
    {
      "epoch": 4.448571428571428,
      "grad_norm": 10.915854454040527,
      "learning_rate": 1.406857142857143e-05,
      "loss": 0.351,
      "step": 15570
    },
    {
      "epoch": 4.451428571428571,
      "grad_norm": 10.828174591064453,
      "learning_rate": 1.4064761904761905e-05,
      "loss": 0.5734,
      "step": 15580
    },
    {
      "epoch": 4.454285714285715,
      "grad_norm": 10.831316947937012,
      "learning_rate": 1.4060952380952382e-05,
      "loss": 0.9033,
      "step": 15590
    },
    {
      "epoch": 4.457142857142857,
      "grad_norm": 10.72270679473877,
      "learning_rate": 1.4057142857142858e-05,
      "loss": 0.4484,
      "step": 15600
    },
    {
      "epoch": 4.46,
      "grad_norm": 10.974727630615234,
      "learning_rate": 1.4053333333333335e-05,
      "loss": 0.971,
      "step": 15610
    },
    {
      "epoch": 4.462857142857143,
      "grad_norm": 11.629234313964844,
      "learning_rate": 1.404952380952381e-05,
      "loss": 0.6279,
      "step": 15620
    },
    {
      "epoch": 4.465714285714285,
      "grad_norm": 0.856173038482666,
      "learning_rate": 1.4045714285714288e-05,
      "loss": 0.2193,
      "step": 15630
    },
    {
      "epoch": 4.468571428571429,
      "grad_norm": 0.7833789587020874,
      "learning_rate": 1.4041904761904763e-05,
      "loss": 0.9244,
      "step": 15640
    },
    {
      "epoch": 4.4714285714285715,
      "grad_norm": 0.795468807220459,
      "learning_rate": 1.4038095238095239e-05,
      "loss": 0.2198,
      "step": 15650
    },
    {
      "epoch": 4.474285714285714,
      "grad_norm": 10.745798110961914,
      "learning_rate": 1.4034285714285716e-05,
      "loss": 0.3322,
      "step": 15660
    },
    {
      "epoch": 4.477142857142857,
      "grad_norm": 0.6045036911964417,
      "learning_rate": 1.4030476190476192e-05,
      "loss": 0.6538,
      "step": 15670
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.6034168601036072,
      "learning_rate": 1.4026666666666669e-05,
      "loss": 0.6591,
      "step": 15680
    },
    {
      "epoch": 4.482857142857143,
      "grad_norm": 0.6335553526878357,
      "learning_rate": 1.4022857142857145e-05,
      "loss": 0.6545,
      "step": 15690
    },
    {
      "epoch": 4.485714285714286,
      "grad_norm": 0.6071472764015198,
      "learning_rate": 1.401904761904762e-05,
      "loss": 0.2251,
      "step": 15700
    },
    {
      "epoch": 4.488571428571428,
      "grad_norm": 0.5258616209030151,
      "learning_rate": 1.4015238095238097e-05,
      "loss": 0.4459,
      "step": 15710
    },
    {
      "epoch": 4.491428571428571,
      "grad_norm": 10.820621490478516,
      "learning_rate": 1.4011428571428573e-05,
      "loss": 0.6789,
      "step": 15720
    },
    {
      "epoch": 4.494285714285715,
      "grad_norm": 0.6220946311950684,
      "learning_rate": 1.4007619047619047e-05,
      "loss": 0.3379,
      "step": 15730
    },
    {
      "epoch": 4.497142857142857,
      "grad_norm": 0.6398035287857056,
      "learning_rate": 1.4003809523809524e-05,
      "loss": 0.6573,
      "step": 15740
    },
    {
      "epoch": 4.5,
      "grad_norm": 10.650918960571289,
      "learning_rate": 1.4e-05,
      "loss": 0.8611,
      "step": 15750
    },
    {
      "epoch": 4.502857142857143,
      "grad_norm": 10.664960861206055,
      "learning_rate": 1.3996190476190477e-05,
      "loss": 0.7355,
      "step": 15760
    },
    {
      "epoch": 4.505714285714285,
      "grad_norm": 10.507345199584961,
      "learning_rate": 1.3992380952380953e-05,
      "loss": 0.6195,
      "step": 15770
    },
    {
      "epoch": 4.508571428571429,
      "grad_norm": 10.509861946105957,
      "learning_rate": 1.398857142857143e-05,
      "loss": 0.3177,
      "step": 15780
    },
    {
      "epoch": 4.511428571428572,
      "grad_norm": 0.709298312664032,
      "learning_rate": 1.3984761904761906e-05,
      "loss": 0.2179,
      "step": 15790
    },
    {
      "epoch": 4.514285714285714,
      "grad_norm": 10.746049880981445,
      "learning_rate": 1.3980952380952381e-05,
      "loss": 0.541,
      "step": 15800
    },
    {
      "epoch": 4.517142857142857,
      "grad_norm": 0.6467541456222534,
      "learning_rate": 1.3977142857142858e-05,
      "loss": 0.5494,
      "step": 15810
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.5671369433403015,
      "learning_rate": 1.3973333333333334e-05,
      "loss": 0.4485,
      "step": 15820
    },
    {
      "epoch": 4.522857142857143,
      "grad_norm": 11.37929916381836,
      "learning_rate": 1.3969523809523811e-05,
      "loss": 0.3422,
      "step": 15830
    },
    {
      "epoch": 4.525714285714286,
      "grad_norm": 22.805824279785156,
      "learning_rate": 1.3965714285714287e-05,
      "loss": 0.7084,
      "step": 15840
    },
    {
      "epoch": 4.5285714285714285,
      "grad_norm": 11.202264785766602,
      "learning_rate": 1.3961904761904762e-05,
      "loss": 0.4766,
      "step": 15850
    },
    {
      "epoch": 4.531428571428571,
      "grad_norm": 11.916013717651367,
      "learning_rate": 1.395809523809524e-05,
      "loss": 0.485,
      "step": 15860
    },
    {
      "epoch": 4.534285714285714,
      "grad_norm": 22.342823028564453,
      "learning_rate": 1.3954285714285715e-05,
      "loss": 0.8111,
      "step": 15870
    },
    {
      "epoch": 4.537142857142857,
      "grad_norm": 10.775612831115723,
      "learning_rate": 1.3950476190476193e-05,
      "loss": 0.5579,
      "step": 15880
    },
    {
      "epoch": 4.54,
      "grad_norm": 10.706360816955566,
      "learning_rate": 1.3946666666666668e-05,
      "loss": 0.7628,
      "step": 15890
    },
    {
      "epoch": 4.542857142857143,
      "grad_norm": 0.6272817254066467,
      "learning_rate": 1.3942857142857145e-05,
      "loss": 0.2257,
      "step": 15900
    },
    {
      "epoch": 4.545714285714285,
      "grad_norm": 10.78506088256836,
      "learning_rate": 1.3939047619047621e-05,
      "loss": 0.6711,
      "step": 15910
    },
    {
      "epoch": 4.548571428571429,
      "grad_norm": 21.992538452148438,
      "learning_rate": 1.3935238095238097e-05,
      "loss": 0.8761,
      "step": 15920
    },
    {
      "epoch": 4.551428571428572,
      "grad_norm": 0.6634778380393982,
      "learning_rate": 1.3931428571428574e-05,
      "loss": 0.2257,
      "step": 15930
    },
    {
      "epoch": 4.554285714285714,
      "grad_norm": 0.6429846286773682,
      "learning_rate": 1.392761904761905e-05,
      "loss": 0.3305,
      "step": 15940
    },
    {
      "epoch": 4.557142857142857,
      "grad_norm": 0.6342543959617615,
      "learning_rate": 1.3923809523809523e-05,
      "loss": 0.4372,
      "step": 15950
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.5711084008216858,
      "learning_rate": 1.392e-05,
      "loss": 0.229,
      "step": 15960
    },
    {
      "epoch": 4.562857142857143,
      "grad_norm": 10.855661392211914,
      "learning_rate": 1.3916190476190476e-05,
      "loss": 0.4512,
      "step": 15970
    },
    {
      "epoch": 4.565714285714286,
      "grad_norm": 0.5442677140235901,
      "learning_rate": 1.3912380952380953e-05,
      "loss": 0.5626,
      "step": 15980
    },
    {
      "epoch": 4.5685714285714285,
      "grad_norm": 0.5802105069160461,
      "learning_rate": 1.3908571428571429e-05,
      "loss": 0.8953,
      "step": 15990
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.6078325510025024,
      "learning_rate": 1.3904761904761905e-05,
      "loss": 0.448,
      "step": 16000
    },
    {
      "epoch": 4.574285714285715,
      "grad_norm": 10.685948371887207,
      "learning_rate": 1.3900952380952382e-05,
      "loss": 0.5509,
      "step": 16010
    },
    {
      "epoch": 4.577142857142857,
      "grad_norm": 0.5973239541053772,
      "learning_rate": 1.3897142857142857e-05,
      "loss": 0.337,
      "step": 16020
    },
    {
      "epoch": 4.58,
      "grad_norm": 0.5862671732902527,
      "learning_rate": 1.3893333333333335e-05,
      "loss": 0.4463,
      "step": 16030
    },
    {
      "epoch": 4.582857142857143,
      "grad_norm": 0.6460959315299988,
      "learning_rate": 1.388952380952381e-05,
      "loss": 0.5506,
      "step": 16040
    },
    {
      "epoch": 4.585714285714285,
      "grad_norm": 10.762749671936035,
      "learning_rate": 1.3885714285714288e-05,
      "loss": 0.6496,
      "step": 16050
    },
    {
      "epoch": 4.588571428571429,
      "grad_norm": 10.83629322052002,
      "learning_rate": 1.3881904761904763e-05,
      "loss": 0.3323,
      "step": 16060
    },
    {
      "epoch": 4.591428571428572,
      "grad_norm": 10.665727615356445,
      "learning_rate": 1.3878095238095239e-05,
      "loss": 0.5483,
      "step": 16070
    },
    {
      "epoch": 4.594285714285714,
      "grad_norm": 0.6921512484550476,
      "learning_rate": 1.3874285714285716e-05,
      "loss": 0.5435,
      "step": 16080
    },
    {
      "epoch": 4.597142857142857,
      "grad_norm": 0.7690143585205078,
      "learning_rate": 1.3870476190476192e-05,
      "loss": 0.8402,
      "step": 16090
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.73760586977005,
      "learning_rate": 1.3866666666666669e-05,
      "loss": 0.2217,
      "step": 16100
    },
    {
      "epoch": 4.602857142857143,
      "grad_norm": 10.920207977294922,
      "learning_rate": 1.3862857142857144e-05,
      "loss": 0.5357,
      "step": 16110
    },
    {
      "epoch": 4.605714285714286,
      "grad_norm": 0.7106788754463196,
      "learning_rate": 1.385904761904762e-05,
      "loss": 0.4344,
      "step": 16120
    },
    {
      "epoch": 4.6085714285714285,
      "grad_norm": 10.710136413574219,
      "learning_rate": 1.3855238095238097e-05,
      "loss": 0.5425,
      "step": 16130
    },
    {
      "epoch": 4.611428571428571,
      "grad_norm": 0.6486246585845947,
      "learning_rate": 1.3851428571428573e-05,
      "loss": 0.5423,
      "step": 16140
    },
    {
      "epoch": 4.614285714285714,
      "grad_norm": 0.6699120998382568,
      "learning_rate": 1.384761904761905e-05,
      "loss": 0.5403,
      "step": 16150
    },
    {
      "epoch": 4.617142857142857,
      "grad_norm": 0.7281118035316467,
      "learning_rate": 1.3843809523809526e-05,
      "loss": 0.7522,
      "step": 16160
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.7752262949943542,
      "learning_rate": 1.384e-05,
      "loss": 0.2228,
      "step": 16170
    },
    {
      "epoch": 4.622857142857143,
      "grad_norm": 0.6359584927558899,
      "learning_rate": 1.3836190476190477e-05,
      "loss": 0.5478,
      "step": 16180
    },
    {
      "epoch": 4.6257142857142854,
      "grad_norm": 10.61796760559082,
      "learning_rate": 1.3832380952380952e-05,
      "loss": 0.9578,
      "step": 16190
    },
    {
      "epoch": 4.628571428571428,
      "grad_norm": 10.708131790161133,
      "learning_rate": 1.382857142857143e-05,
      "loss": 0.5445,
      "step": 16200
    },
    {
      "epoch": 4.631428571428572,
      "grad_norm": 0.7215451002120972,
      "learning_rate": 1.3824761904761905e-05,
      "loss": 0.6453,
      "step": 16210
    },
    {
      "epoch": 4.634285714285714,
      "grad_norm": 21.952476501464844,
      "learning_rate": 1.3820952380952381e-05,
      "loss": 0.8422,
      "step": 16220
    },
    {
      "epoch": 4.637142857142857,
      "grad_norm": 10.635880470275879,
      "learning_rate": 1.3817142857142858e-05,
      "loss": 0.3266,
      "step": 16230
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.6336553692817688,
      "learning_rate": 1.3813333333333334e-05,
      "loss": 0.1205,
      "step": 16240
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 0.5687471628189087,
      "learning_rate": 1.3809523809523811e-05,
      "loss": 0.5572,
      "step": 16250
    },
    {
      "epoch": 4.645714285714286,
      "grad_norm": 0.5538231730461121,
      "learning_rate": 1.3805714285714287e-05,
      "loss": 0.341,
      "step": 16260
    },
    {
      "epoch": 4.648571428571429,
      "grad_norm": 10.763096809387207,
      "learning_rate": 1.3801904761904762e-05,
      "loss": 0.6691,
      "step": 16270
    },
    {
      "epoch": 4.651428571428571,
      "grad_norm": 0.6445385217666626,
      "learning_rate": 1.379809523809524e-05,
      "loss": 0.5482,
      "step": 16280
    },
    {
      "epoch": 4.654285714285714,
      "grad_norm": 0.6771273612976074,
      "learning_rate": 1.3794285714285715e-05,
      "loss": 0.3229,
      "step": 16290
    },
    {
      "epoch": 4.6571428571428575,
      "grad_norm": 0.6490932106971741,
      "learning_rate": 1.3790476190476192e-05,
      "loss": 0.5507,
      "step": 16300
    },
    {
      "epoch": 4.66,
      "grad_norm": 10.941375732421875,
      "learning_rate": 1.3786666666666668e-05,
      "loss": 0.437,
      "step": 16310
    },
    {
      "epoch": 4.662857142857143,
      "grad_norm": 0.6845049858093262,
      "learning_rate": 1.3782857142857145e-05,
      "loss": 0.4376,
      "step": 16320
    },
    {
      "epoch": 4.6657142857142855,
      "grad_norm": 0.673442542552948,
      "learning_rate": 1.377904761904762e-05,
      "loss": 0.4378,
      "step": 16330
    },
    {
      "epoch": 4.668571428571429,
      "grad_norm": 0.6406835317611694,
      "learning_rate": 1.3775238095238096e-05,
      "loss": 0.1215,
      "step": 16340
    },
    {
      "epoch": 4.671428571428572,
      "grad_norm": 0.5715047121047974,
      "learning_rate": 1.3771428571428574e-05,
      "loss": 0.6612,
      "step": 16350
    },
    {
      "epoch": 4.674285714285714,
      "grad_norm": 0.5643688440322876,
      "learning_rate": 1.376761904761905e-05,
      "loss": 0.6646,
      "step": 16360
    },
    {
      "epoch": 4.677142857142857,
      "grad_norm": 0.5364670157432556,
      "learning_rate": 1.3763809523809527e-05,
      "loss": 0.2312,
      "step": 16370
    },
    {
      "epoch": 4.68,
      "grad_norm": 33.25426483154297,
      "learning_rate": 1.376e-05,
      "loss": 0.7921,
      "step": 16380
    },
    {
      "epoch": 4.682857142857143,
      "grad_norm": 10.7842435836792,
      "learning_rate": 1.3756190476190476e-05,
      "loss": 0.4581,
      "step": 16390
    },
    {
      "epoch": 4.685714285714286,
      "grad_norm": 10.759000778198242,
      "learning_rate": 1.3752380952380953e-05,
      "loss": 0.4579,
      "step": 16400
    },
    {
      "epoch": 4.688571428571429,
      "grad_norm": 22.128786087036133,
      "learning_rate": 1.3748571428571429e-05,
      "loss": 0.249,
      "step": 16410
    },
    {
      "epoch": 4.691428571428571,
      "grad_norm": 0.3628292381763458,
      "learning_rate": 1.3744761904761904e-05,
      "loss": 0.2482,
      "step": 16420
    },
    {
      "epoch": 4.694285714285714,
      "grad_norm": 10.981832504272461,
      "learning_rate": 1.3740952380952382e-05,
      "loss": 0.4934,
      "step": 16430
    },
    {
      "epoch": 4.6971428571428575,
      "grad_norm": 0.3800058662891388,
      "learning_rate": 1.3737142857142857e-05,
      "loss": 0.4897,
      "step": 16440
    },
    {
      "epoch": 4.7,
      "grad_norm": 0.4179539382457733,
      "learning_rate": 1.3733333333333335e-05,
      "loss": 0.7227,
      "step": 16450
    },
    {
      "epoch": 4.702857142857143,
      "grad_norm": 0.41213110089302063,
      "learning_rate": 1.372952380952381e-05,
      "loss": 0.3584,
      "step": 16460
    },
    {
      "epoch": 4.7057142857142855,
      "grad_norm": 10.867586135864258,
      "learning_rate": 1.3725714285714287e-05,
      "loss": 0.3592,
      "step": 16470
    },
    {
      "epoch": 4.708571428571428,
      "grad_norm": 0.43155553936958313,
      "learning_rate": 1.3721904761904763e-05,
      "loss": 0.2429,
      "step": 16480
    },
    {
      "epoch": 4.711428571428572,
      "grad_norm": 0.4348267614841461,
      "learning_rate": 1.3718095238095239e-05,
      "loss": 0.9374,
      "step": 16490
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 10.861419677734375,
      "learning_rate": 1.3714285714285716e-05,
      "loss": 0.8193,
      "step": 16500
    },
    {
      "epoch": 4.717142857142857,
      "grad_norm": 10.77374267578125,
      "learning_rate": 1.3710476190476191e-05,
      "loss": 1.0204,
      "step": 16510
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.6345911026000977,
      "learning_rate": 1.3706666666666669e-05,
      "loss": 0.7677,
      "step": 16520
    },
    {
      "epoch": 4.722857142857142,
      "grad_norm": 0.6545860171318054,
      "learning_rate": 1.3702857142857144e-05,
      "loss": 0.3317,
      "step": 16530
    },
    {
      "epoch": 4.725714285714286,
      "grad_norm": 0.5930510759353638,
      "learning_rate": 1.369904761904762e-05,
      "loss": 0.1193,
      "step": 16540
    },
    {
      "epoch": 4.728571428571429,
      "grad_norm": 0.5720338821411133,
      "learning_rate": 1.3695238095238097e-05,
      "loss": 0.6667,
      "step": 16550
    },
    {
      "epoch": 4.731428571428571,
      "grad_norm": 0.573107898235321,
      "learning_rate": 1.3691428571428573e-05,
      "loss": 0.6653,
      "step": 16560
    },
    {
      "epoch": 4.734285714285714,
      "grad_norm": 22.22201919555664,
      "learning_rate": 1.368761904761905e-05,
      "loss": 0.6733,
      "step": 16570
    },
    {
      "epoch": 4.737142857142857,
      "grad_norm": 0.5342880487442017,
      "learning_rate": 1.3683809523809526e-05,
      "loss": 0.2336,
      "step": 16580
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.5115705132484436,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.4544,
      "step": 16590
    },
    {
      "epoch": 4.742857142857143,
      "grad_norm": 10.816357612609863,
      "learning_rate": 1.3676190476190477e-05,
      "loss": 0.8056,
      "step": 16600
    },
    {
      "epoch": 4.7457142857142856,
      "grad_norm": 10.698525428771973,
      "learning_rate": 1.3672380952380952e-05,
      "loss": 0.5667,
      "step": 16610
    },
    {
      "epoch": 4.748571428571428,
      "grad_norm": 0.6460375785827637,
      "learning_rate": 1.366857142857143e-05,
      "loss": 0.4458,
      "step": 16620
    },
    {
      "epoch": 4.751428571428572,
      "grad_norm": 10.830740928649902,
      "learning_rate": 1.3664761904761905e-05,
      "loss": 0.6496,
      "step": 16630
    },
    {
      "epoch": 4.7542857142857144,
      "grad_norm": 10.857804298400879,
      "learning_rate": 1.366095238095238e-05,
      "loss": 0.4381,
      "step": 16640
    },
    {
      "epoch": 4.757142857142857,
      "grad_norm": 22.000560760498047,
      "learning_rate": 1.3657142857142858e-05,
      "loss": 0.8717,
      "step": 16650
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.6880471706390381,
      "learning_rate": 1.3653333333333334e-05,
      "loss": 0.2242,
      "step": 16660
    },
    {
      "epoch": 4.762857142857143,
      "grad_norm": 10.662858009338379,
      "learning_rate": 1.3649523809523811e-05,
      "loss": 1.0482,
      "step": 16670
    },
    {
      "epoch": 4.765714285714286,
      "grad_norm": 0.9173648357391357,
      "learning_rate": 1.3645714285714286e-05,
      "loss": 0.315,
      "step": 16680
    },
    {
      "epoch": 4.768571428571429,
      "grad_norm": 0.8209707140922546,
      "learning_rate": 1.3641904761904762e-05,
      "loss": 0.4133,
      "step": 16690
    },
    {
      "epoch": 4.771428571428571,
      "grad_norm": 0.7610481977462769,
      "learning_rate": 1.363809523809524e-05,
      "loss": 0.5184,
      "step": 16700
    },
    {
      "epoch": 4.774285714285714,
      "grad_norm": 0.669798731803894,
      "learning_rate": 1.3634285714285715e-05,
      "loss": 0.2229,
      "step": 16710
    },
    {
      "epoch": 4.777142857142858,
      "grad_norm": 10.8308744430542,
      "learning_rate": 1.3630476190476192e-05,
      "loss": 0.3422,
      "step": 16720
    },
    {
      "epoch": 4.78,
      "grad_norm": 0.5134419202804565,
      "learning_rate": 1.3626666666666668e-05,
      "loss": 0.6818,
      "step": 16730
    },
    {
      "epoch": 4.782857142857143,
      "grad_norm": 0.5577192902565002,
      "learning_rate": 1.3622857142857145e-05,
      "loss": 0.5618,
      "step": 16740
    },
    {
      "epoch": 4.785714285714286,
      "grad_norm": 21.970027923583984,
      "learning_rate": 1.361904761904762e-05,
      "loss": 0.6666,
      "step": 16750
    },
    {
      "epoch": 4.788571428571428,
      "grad_norm": 22.025863647460938,
      "learning_rate": 1.3615238095238096e-05,
      "loss": 0.5564,
      "step": 16760
    },
    {
      "epoch": 4.791428571428572,
      "grad_norm": 10.736048698425293,
      "learning_rate": 1.3611428571428573e-05,
      "loss": 0.6619,
      "step": 16770
    },
    {
      "epoch": 4.7942857142857145,
      "grad_norm": 10.732687950134277,
      "learning_rate": 1.3607619047619049e-05,
      "loss": 0.6528,
      "step": 16780
    },
    {
      "epoch": 4.797142857142857,
      "grad_norm": 10.589971542358398,
      "learning_rate": 1.3603809523809526e-05,
      "loss": 0.848,
      "step": 16790
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.7227914929389954,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.1179,
      "step": 16800
    },
    {
      "epoch": 4.8028571428571425,
      "grad_norm": 10.77719497680664,
      "learning_rate": 1.359619047619048e-05,
      "loss": 0.4335,
      "step": 16810
    },
    {
      "epoch": 4.805714285714286,
      "grad_norm": 10.604284286499023,
      "learning_rate": 1.3592380952380953e-05,
      "loss": 0.9546,
      "step": 16820
    },
    {
      "epoch": 4.808571428571429,
      "grad_norm": 0.8017482161521912,
      "learning_rate": 1.3588571428571429e-05,
      "loss": 0.6301,
      "step": 16830
    },
    {
      "epoch": 4.811428571428571,
      "grad_norm": 0.8285977840423584,
      "learning_rate": 1.3584761904761904e-05,
      "loss": 0.3194,
      "step": 16840
    },
    {
      "epoch": 4.814285714285714,
      "grad_norm": 0.6962685585021973,
      "learning_rate": 1.3580952380952382e-05,
      "loss": 0.2167,
      "step": 16850
    },
    {
      "epoch": 4.817142857142857,
      "grad_norm": 0.5397700071334839,
      "learning_rate": 1.3577142857142857e-05,
      "loss": 0.3372,
      "step": 16860
    },
    {
      "epoch": 4.82,
      "grad_norm": 22.14017677307129,
      "learning_rate": 1.3573333333333334e-05,
      "loss": 0.3583,
      "step": 16870
    },
    {
      "epoch": 4.822857142857143,
      "grad_norm": 0.44100531935691833,
      "learning_rate": 1.356952380952381e-05,
      "loss": 0.9411,
      "step": 16880
    },
    {
      "epoch": 4.825714285714286,
      "grad_norm": 0.4786665141582489,
      "learning_rate": 1.3565714285714287e-05,
      "loss": 0.3529,
      "step": 16890
    },
    {
      "epoch": 4.828571428571428,
      "grad_norm": 10.91529655456543,
      "learning_rate": 1.3561904761904763e-05,
      "loss": 0.3507,
      "step": 16900
    },
    {
      "epoch": 4.831428571428571,
      "grad_norm": 0.48651939630508423,
      "learning_rate": 1.3558095238095238e-05,
      "loss": 0.5772,
      "step": 16910
    },
    {
      "epoch": 4.8342857142857145,
      "grad_norm": 0.46163925528526306,
      "learning_rate": 1.3554285714285716e-05,
      "loss": 0.239,
      "step": 16920
    },
    {
      "epoch": 4.837142857142857,
      "grad_norm": 0.4665415585041046,
      "learning_rate": 1.3550476190476191e-05,
      "loss": 0.6993,
      "step": 16930
    },
    {
      "epoch": 4.84,
      "grad_norm": 10.797257423400879,
      "learning_rate": 1.3546666666666669e-05,
      "loss": 0.5763,
      "step": 16940
    },
    {
      "epoch": 4.8428571428571425,
      "grad_norm": 0.5649659633636475,
      "learning_rate": 1.3542857142857144e-05,
      "loss": 1.0096,
      "step": 16950
    },
    {
      "epoch": 4.845714285714286,
      "grad_norm": 10.776885986328125,
      "learning_rate": 1.3539047619047621e-05,
      "loss": 0.5534,
      "step": 16960
    },
    {
      "epoch": 4.848571428571429,
      "grad_norm": 0.6305558681488037,
      "learning_rate": 1.3535238095238097e-05,
      "loss": 0.3349,
      "step": 16970
    },
    {
      "epoch": 4.851428571428571,
      "grad_norm": 22.460819244384766,
      "learning_rate": 1.3531428571428573e-05,
      "loss": 0.3413,
      "step": 16980
    },
    {
      "epoch": 4.854285714285714,
      "grad_norm": 0.5244250297546387,
      "learning_rate": 1.352761904761905e-05,
      "loss": 0.1241,
      "step": 16990
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.49731582403182983,
      "learning_rate": 1.3523809523809525e-05,
      "loss": 0.3457,
      "step": 17000
    },
    {
      "epoch": 4.86,
      "grad_norm": 22.096132278442383,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.6942,
      "step": 17010
    },
    {
      "epoch": 4.862857142857143,
      "grad_norm": 0.5540534257888794,
      "learning_rate": 1.3516190476190478e-05,
      "loss": 0.9035,
      "step": 17020
    },
    {
      "epoch": 4.865714285714286,
      "grad_norm": 10.71078872680664,
      "learning_rate": 1.3512380952380952e-05,
      "loss": 0.7721,
      "step": 17030
    },
    {
      "epoch": 4.868571428571428,
      "grad_norm": 10.831489562988281,
      "learning_rate": 1.350857142857143e-05,
      "loss": 0.6529,
      "step": 17040
    },
    {
      "epoch": 4.871428571428572,
      "grad_norm": 0.7036618590354919,
      "learning_rate": 1.3504761904761905e-05,
      "loss": 0.541,
      "step": 17050
    },
    {
      "epoch": 4.8742857142857146,
      "grad_norm": 0.7124089598655701,
      "learning_rate": 1.350095238095238e-05,
      "loss": 0.5337,
      "step": 17060
    },
    {
      "epoch": 4.877142857142857,
      "grad_norm": 10.682563781738281,
      "learning_rate": 1.3497142857142858e-05,
      "loss": 0.2254,
      "step": 17070
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.6660566329956055,
      "learning_rate": 1.3493333333333333e-05,
      "loss": 0.3291,
      "step": 17080
    },
    {
      "epoch": 4.882857142857143,
      "grad_norm": 10.64665412902832,
      "learning_rate": 1.348952380952381e-05,
      "loss": 0.6453,
      "step": 17090
    },
    {
      "epoch": 4.885714285714286,
      "grad_norm": 0.6938386559486389,
      "learning_rate": 1.3485714285714286e-05,
      "loss": 0.4326,
      "step": 17100
    },
    {
      "epoch": 4.888571428571429,
      "grad_norm": 11.122517585754395,
      "learning_rate": 1.3481904761904762e-05,
      "loss": 0.4333,
      "step": 17110
    },
    {
      "epoch": 4.8914285714285715,
      "grad_norm": 0.6314775943756104,
      "learning_rate": 1.347809523809524e-05,
      "loss": 0.2249,
      "step": 17120
    },
    {
      "epoch": 4.894285714285714,
      "grad_norm": 0.5289601683616638,
      "learning_rate": 1.3474285714285715e-05,
      "loss": 0.3452,
      "step": 17130
    },
    {
      "epoch": 4.897142857142857,
      "grad_norm": 0.5040956735610962,
      "learning_rate": 1.3470476190476192e-05,
      "loss": 0.3479,
      "step": 17140
    },
    {
      "epoch": 4.9,
      "grad_norm": 0.4812260568141937,
      "learning_rate": 1.3466666666666668e-05,
      "loss": 0.4584,
      "step": 17150
    },
    {
      "epoch": 4.902857142857143,
      "grad_norm": 0.47090208530426025,
      "learning_rate": 1.3462857142857145e-05,
      "loss": 0.4653,
      "step": 17160
    },
    {
      "epoch": 4.905714285714286,
      "grad_norm": 11.168547630310059,
      "learning_rate": 1.345904761904762e-05,
      "loss": 0.2422,
      "step": 17170
    },
    {
      "epoch": 4.908571428571428,
      "grad_norm": 11.110722541809082,
      "learning_rate": 1.3455238095238096e-05,
      "loss": 0.373,
      "step": 17180
    },
    {
      "epoch": 4.911428571428571,
      "grad_norm": 22.31148338317871,
      "learning_rate": 1.3451428571428573e-05,
      "loss": 0.9745,
      "step": 17190
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.48964017629623413,
      "learning_rate": 1.3447619047619049e-05,
      "loss": 0.8264,
      "step": 17200
    },
    {
      "epoch": 4.917142857142857,
      "grad_norm": 22.049015045166016,
      "learning_rate": 1.3443809523809526e-05,
      "loss": 0.5722,
      "step": 17210
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.456241637468338,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.2381,
      "step": 17220
    },
    {
      "epoch": 4.922857142857143,
      "grad_norm": 0.4533974826335907,
      "learning_rate": 1.3436190476190479e-05,
      "loss": 0.8155,
      "step": 17230
    },
    {
      "epoch": 4.925714285714285,
      "grad_norm": 0.4628983736038208,
      "learning_rate": 1.3432380952380955e-05,
      "loss": 0.2386,
      "step": 17240
    },
    {
      "epoch": 4.928571428571429,
      "grad_norm": 0.4423845708370209,
      "learning_rate": 1.3428571428571429e-05,
      "loss": 0.2394,
      "step": 17250
    },
    {
      "epoch": 4.9314285714285715,
      "grad_norm": 10.871017456054688,
      "learning_rate": 1.3424761904761904e-05,
      "loss": 0.8229,
      "step": 17260
    },
    {
      "epoch": 4.934285714285714,
      "grad_norm": 10.854451179504395,
      "learning_rate": 1.3420952380952381e-05,
      "loss": 0.5881,
      "step": 17270
    },
    {
      "epoch": 4.937142857142857,
      "grad_norm": 10.863372802734375,
      "learning_rate": 1.3417142857142857e-05,
      "loss": 0.5857,
      "step": 17280
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 10.81617259979248,
      "learning_rate": 1.3413333333333334e-05,
      "loss": 0.9233,
      "step": 17290
    },
    {
      "epoch": 4.942857142857143,
      "grad_norm": 0.5458100438117981,
      "learning_rate": 1.340952380952381e-05,
      "loss": 0.6807,
      "step": 17300
    },
    {
      "epoch": 4.945714285714286,
      "grad_norm": 0.6267215609550476,
      "learning_rate": 1.3405714285714287e-05,
      "loss": 0.4459,
      "step": 17310
    },
    {
      "epoch": 4.948571428571428,
      "grad_norm": 10.61483097076416,
      "learning_rate": 1.3401904761904763e-05,
      "loss": 0.8555,
      "step": 17320
    },
    {
      "epoch": 4.951428571428571,
      "grad_norm": 0.8010308742523193,
      "learning_rate": 1.3398095238095238e-05,
      "loss": 0.4223,
      "step": 17330
    },
    {
      "epoch": 4.954285714285715,
      "grad_norm": 21.85690689086914,
      "learning_rate": 1.3394285714285716e-05,
      "loss": 0.6227,
      "step": 17340
    },
    {
      "epoch": 4.957142857142857,
      "grad_norm": 10.607369422912598,
      "learning_rate": 1.3390476190476191e-05,
      "loss": 0.7192,
      "step": 17350
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.824773907661438,
      "learning_rate": 1.3386666666666668e-05,
      "loss": 0.3145,
      "step": 17360
    },
    {
      "epoch": 4.962857142857143,
      "grad_norm": 0.7942920923233032,
      "learning_rate": 1.3382857142857144e-05,
      "loss": 0.6218,
      "step": 17370
    },
    {
      "epoch": 4.965714285714286,
      "grad_norm": 0.7992578148841858,
      "learning_rate": 1.3379047619047621e-05,
      "loss": 0.5205,
      "step": 17380
    },
    {
      "epoch": 4.968571428571429,
      "grad_norm": 0.7951765656471252,
      "learning_rate": 1.3375238095238097e-05,
      "loss": 0.524,
      "step": 17390
    },
    {
      "epoch": 4.9714285714285715,
      "grad_norm": 0.8452416658401489,
      "learning_rate": 1.3371428571428572e-05,
      "loss": 0.6198,
      "step": 17400
    },
    {
      "epoch": 4.974285714285714,
      "grad_norm": 0.8021947741508484,
      "learning_rate": 1.336761904761905e-05,
      "loss": 0.2173,
      "step": 17410
    },
    {
      "epoch": 4.977142857142857,
      "grad_norm": 0.630813479423523,
      "learning_rate": 1.3363809523809525e-05,
      "loss": 0.216,
      "step": 17420
    },
    {
      "epoch": 4.98,
      "grad_norm": 10.742286682128906,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.5558,
      "step": 17430
    },
    {
      "epoch": 4.982857142857143,
      "grad_norm": 0.556110143661499,
      "learning_rate": 1.3356190476190478e-05,
      "loss": 0.4487,
      "step": 17440
    },
    {
      "epoch": 4.985714285714286,
      "grad_norm": 0.5601140856742859,
      "learning_rate": 1.3352380952380954e-05,
      "loss": 0.5638,
      "step": 17450
    },
    {
      "epoch": 4.988571428571428,
      "grad_norm": 0.4369083046913147,
      "learning_rate": 1.3348571428571431e-05,
      "loss": 0.1269,
      "step": 17460
    },
    {
      "epoch": 4.991428571428571,
      "grad_norm": 0.36508381366729736,
      "learning_rate": 1.3344761904761905e-05,
      "loss": 0.6036,
      "step": 17470
    },
    {
      "epoch": 4.994285714285715,
      "grad_norm": 0.3800186812877655,
      "learning_rate": 1.334095238095238e-05,
      "loss": 0.2475,
      "step": 17480
    },
    {
      "epoch": 4.997142857142857,
      "grad_norm": 11.267121315002441,
      "learning_rate": 1.3337142857142858e-05,
      "loss": 0.8672,
      "step": 17490
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.4287721514701843,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.6027,
      "step": 17500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8893333333333333,
      "eval_f1": 0.0,
      "eval_loss": 0.5222077965736389,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 262.7641,
      "eval_samples_per_second": 11.417,
      "eval_steps_per_second": 2.854,
      "step": 17500
    },
    {
      "epoch": 5.002857142857143,
      "grad_norm": 10.809052467346191,
      "learning_rate": 1.332952380952381e-05,
      "loss": 0.693,
      "step": 17510
    },
    {
      "epoch": 5.005714285714285,
      "grad_norm": 10.71994400024414,
      "learning_rate": 1.3325714285714286e-05,
      "loss": 0.4511,
      "step": 17520
    },
    {
      "epoch": 5.008571428571429,
      "grad_norm": 0.5977635383605957,
      "learning_rate": 1.3321904761904762e-05,
      "loss": 0.6661,
      "step": 17530
    },
    {
      "epoch": 5.011428571428572,
      "grad_norm": 10.72407341003418,
      "learning_rate": 1.3318095238095239e-05,
      "loss": 0.5529,
      "step": 17540
    },
    {
      "epoch": 5.014285714285714,
      "grad_norm": 0.6369818449020386,
      "learning_rate": 1.3314285714285715e-05,
      "loss": 0.4402,
      "step": 17550
    },
    {
      "epoch": 5.017142857142857,
      "grad_norm": 0.5864320993423462,
      "learning_rate": 1.3310476190476192e-05,
      "loss": 0.4449,
      "step": 17560
    },
    {
      "epoch": 5.02,
      "grad_norm": 10.903393745422363,
      "learning_rate": 1.3306666666666667e-05,
      "loss": 1.0812,
      "step": 17570
    },
    {
      "epoch": 5.022857142857143,
      "grad_norm": 0.5159035921096802,
      "learning_rate": 1.3302857142857145e-05,
      "loss": 0.236,
      "step": 17580
    },
    {
      "epoch": 5.025714285714286,
      "grad_norm": 0.5532321333885193,
      "learning_rate": 1.329904761904762e-05,
      "loss": 0.9239,
      "step": 17590
    },
    {
      "epoch": 5.0285714285714285,
      "grad_norm": 10.853204727172852,
      "learning_rate": 1.3295238095238096e-05,
      "loss": 0.6638,
      "step": 17600
    },
    {
      "epoch": 5.031428571428571,
      "grad_norm": 10.550471305847168,
      "learning_rate": 1.3291428571428573e-05,
      "loss": 1.2724,
      "step": 17610
    },
    {
      "epoch": 5.034285714285715,
      "grad_norm": 0.8529636859893799,
      "learning_rate": 1.3287619047619049e-05,
      "loss": 0.4149,
      "step": 17620
    },
    {
      "epoch": 5.037142857142857,
      "grad_norm": 10.709397315979004,
      "learning_rate": 1.3283809523809526e-05,
      "loss": 0.6164,
      "step": 17630
    },
    {
      "epoch": 5.04,
      "grad_norm": 10.495281219482422,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.6199,
      "step": 17640
    },
    {
      "epoch": 5.042857142857143,
      "grad_norm": 0.8446303009986877,
      "learning_rate": 1.3276190476190479e-05,
      "loss": 0.5166,
      "step": 17650
    },
    {
      "epoch": 5.045714285714285,
      "grad_norm": 0.7088055610656738,
      "learning_rate": 1.3272380952380954e-05,
      "loss": 0.2182,
      "step": 17660
    },
    {
      "epoch": 5.048571428571429,
      "grad_norm": 0.6487303376197815,
      "learning_rate": 1.326857142857143e-05,
      "loss": 0.6466,
      "step": 17670
    },
    {
      "epoch": 5.051428571428572,
      "grad_norm": 10.908561706542969,
      "learning_rate": 1.3264761904761907e-05,
      "loss": 0.6493,
      "step": 17680
    },
    {
      "epoch": 5.054285714285714,
      "grad_norm": 0.5087244510650635,
      "learning_rate": 1.3260952380952381e-05,
      "loss": 0.3379,
      "step": 17690
    },
    {
      "epoch": 5.057142857142857,
      "grad_norm": 0.4857091009616852,
      "learning_rate": 1.3257142857142857e-05,
      "loss": 0.3527,
      "step": 17700
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.46865543723106384,
      "learning_rate": 1.3253333333333334e-05,
      "loss": 0.4663,
      "step": 17710
    },
    {
      "epoch": 5.062857142857143,
      "grad_norm": 10.925630569458008,
      "learning_rate": 1.324952380952381e-05,
      "loss": 0.7013,
      "step": 17720
    },
    {
      "epoch": 5.065714285714286,
      "grad_norm": 0.4519038200378418,
      "learning_rate": 1.3245714285714287e-05,
      "loss": 0.2413,
      "step": 17730
    },
    {
      "epoch": 5.0685714285714285,
      "grad_norm": 0.4451679587364197,
      "learning_rate": 1.3241904761904762e-05,
      "loss": 0.3594,
      "step": 17740
    },
    {
      "epoch": 5.071428571428571,
      "grad_norm": 0.4067695140838623,
      "learning_rate": 1.3238095238095238e-05,
      "loss": 0.2413,
      "step": 17750
    },
    {
      "epoch": 5.074285714285715,
      "grad_norm": 10.954565048217773,
      "learning_rate": 1.3234285714285715e-05,
      "loss": 0.3653,
      "step": 17760
    },
    {
      "epoch": 5.077142857142857,
      "grad_norm": 0.3977949619293213,
      "learning_rate": 1.3230476190476191e-05,
      "loss": 0.4868,
      "step": 17770
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.4040697515010834,
      "learning_rate": 1.3226666666666668e-05,
      "loss": 0.5989,
      "step": 17780
    },
    {
      "epoch": 5.082857142857143,
      "grad_norm": 0.4065004587173462,
      "learning_rate": 1.3222857142857144e-05,
      "loss": 0.4799,
      "step": 17790
    },
    {
      "epoch": 5.085714285714285,
      "grad_norm": 0.3964526355266571,
      "learning_rate": 1.3219047619047621e-05,
      "loss": 0.2418,
      "step": 17800
    },
    {
      "epoch": 5.088571428571429,
      "grad_norm": 13.395376205444336,
      "learning_rate": 1.3215238095238097e-05,
      "loss": 0.4885,
      "step": 17810
    },
    {
      "epoch": 5.091428571428572,
      "grad_norm": 11.216310501098633,
      "learning_rate": 1.3211428571428572e-05,
      "loss": 0.6112,
      "step": 17820
    },
    {
      "epoch": 5.094285714285714,
      "grad_norm": 0.4347108006477356,
      "learning_rate": 1.320761904761905e-05,
      "loss": 0.4762,
      "step": 17830
    },
    {
      "epoch": 5.097142857142857,
      "grad_norm": 10.955925941467285,
      "learning_rate": 1.3203809523809525e-05,
      "loss": 0.247,
      "step": 17840
    },
    {
      "epoch": 5.1,
      "grad_norm": 0.38824519515037537,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.6037,
      "step": 17850
    },
    {
      "epoch": 5.102857142857143,
      "grad_norm": 10.9284086227417,
      "learning_rate": 1.3196190476190478e-05,
      "loss": 0.3595,
      "step": 17860
    },
    {
      "epoch": 5.105714285714286,
      "grad_norm": 10.832666397094727,
      "learning_rate": 1.3192380952380954e-05,
      "loss": 1.1697,
      "step": 17870
    },
    {
      "epoch": 5.1085714285714285,
      "grad_norm": 0.5430311560630798,
      "learning_rate": 1.318857142857143e-05,
      "loss": 0.4574,
      "step": 17880
    },
    {
      "epoch": 5.111428571428571,
      "grad_norm": 0.58561772108078,
      "learning_rate": 1.3184761904761906e-05,
      "loss": 0.6678,
      "step": 17890
    },
    {
      "epoch": 5.114285714285714,
      "grad_norm": 0.6095916032791138,
      "learning_rate": 1.318095238095238e-05,
      "loss": 0.6617,
      "step": 17900
    },
    {
      "epoch": 5.117142857142857,
      "grad_norm": 10.665003776550293,
      "learning_rate": 1.3177142857142858e-05,
      "loss": 0.6518,
      "step": 17910
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.7168136239051819,
      "learning_rate": 1.3173333333333333e-05,
      "loss": 0.4349,
      "step": 17920
    },
    {
      "epoch": 5.122857142857143,
      "grad_norm": 0.5242568254470825,
      "learning_rate": 1.316952380952381e-05,
      "loss": 0.2287,
      "step": 17930
    },
    {
      "epoch": 5.1257142857142854,
      "grad_norm": 22.34502410888672,
      "learning_rate": 1.3165714285714286e-05,
      "loss": 1.2546,
      "step": 17940
    },
    {
      "epoch": 5.128571428571428,
      "grad_norm": 0.6160039305686951,
      "learning_rate": 1.3161904761904762e-05,
      "loss": 0.554,
      "step": 17950
    },
    {
      "epoch": 5.131428571428572,
      "grad_norm": 22.024185180664062,
      "learning_rate": 1.3158095238095239e-05,
      "loss": 0.2292,
      "step": 17960
    },
    {
      "epoch": 5.134285714285714,
      "grad_norm": 10.761632919311523,
      "learning_rate": 1.3154285714285714e-05,
      "loss": 0.446,
      "step": 17970
    },
    {
      "epoch": 5.137142857142857,
      "grad_norm": 10.63243293762207,
      "learning_rate": 1.3150476190476192e-05,
      "loss": 1.0767,
      "step": 17980
    },
    {
      "epoch": 5.14,
      "grad_norm": 0.7236723303794861,
      "learning_rate": 1.3146666666666667e-05,
      "loss": 0.1196,
      "step": 17990
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.6563553810119629,
      "learning_rate": 1.3142857142857145e-05,
      "loss": 0.3279,
      "step": 18000
    },
    {
      "epoch": 5.145714285714286,
      "grad_norm": 0.6166402697563171,
      "learning_rate": 1.313904761904762e-05,
      "loss": 0.4407,
      "step": 18010
    },
    {
      "epoch": 5.148571428571429,
      "grad_norm": 10.733965873718262,
      "learning_rate": 1.3135238095238096e-05,
      "loss": 1.0871,
      "step": 18020
    },
    {
      "epoch": 5.151428571428571,
      "grad_norm": 0.747730553150177,
      "learning_rate": 1.3131428571428573e-05,
      "loss": 0.3274,
      "step": 18030
    },
    {
      "epoch": 5.154285714285714,
      "grad_norm": 0.7956374287605286,
      "learning_rate": 1.3127619047619049e-05,
      "loss": 0.7298,
      "step": 18040
    },
    {
      "epoch": 5.1571428571428575,
      "grad_norm": 0.840898871421814,
      "learning_rate": 1.3123809523809526e-05,
      "loss": 0.7233,
      "step": 18050
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.8158143162727356,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.1171,
      "step": 18060
    },
    {
      "epoch": 5.162857142857143,
      "grad_norm": 0.6479344367980957,
      "learning_rate": 1.3116190476190479e-05,
      "loss": 0.5343,
      "step": 18070
    },
    {
      "epoch": 5.1657142857142855,
      "grad_norm": 10.63428783416748,
      "learning_rate": 1.3112380952380954e-05,
      "loss": 0.7515,
      "step": 18080
    },
    {
      "epoch": 5.168571428571428,
      "grad_norm": 0.6545864939689636,
      "learning_rate": 1.310857142857143e-05,
      "loss": 0.0154,
      "step": 18090
    },
    {
      "epoch": 5.171428571428572,
      "grad_norm": 0.4666127860546112,
      "learning_rate": 1.3104761904761907e-05,
      "loss": 0.1239,
      "step": 18100
    },
    {
      "epoch": 5.174285714285714,
      "grad_norm": 26.693700790405273,
      "learning_rate": 1.3100952380952383e-05,
      "loss": 0.8208,
      "step": 18110
    },
    {
      "epoch": 5.177142857142857,
      "grad_norm": 0.4011131823062897,
      "learning_rate": 1.3097142857142857e-05,
      "loss": 0.2395,
      "step": 18120
    },
    {
      "epoch": 5.18,
      "grad_norm": 10.912267684936523,
      "learning_rate": 1.3093333333333334e-05,
      "loss": 0.835,
      "step": 18130
    },
    {
      "epoch": 5.182857142857143,
      "grad_norm": 0.5289822220802307,
      "learning_rate": 1.308952380952381e-05,
      "loss": 0.4669,
      "step": 18140
    },
    {
      "epoch": 5.185714285714286,
      "grad_norm": 10.842730522155762,
      "learning_rate": 1.3085714285714287e-05,
      "loss": 0.2358,
      "step": 18150
    },
    {
      "epoch": 5.188571428571429,
      "grad_norm": 0.536243200302124,
      "learning_rate": 1.3081904761904762e-05,
      "loss": 0.6904,
      "step": 18160
    },
    {
      "epoch": 5.191428571428571,
      "grad_norm": 10.84410285949707,
      "learning_rate": 1.3078095238095238e-05,
      "loss": 0.6742,
      "step": 18170
    },
    {
      "epoch": 5.194285714285714,
      "grad_norm": 0.5905327200889587,
      "learning_rate": 1.3074285714285715e-05,
      "loss": 0.3405,
      "step": 18180
    },
    {
      "epoch": 5.1971428571428575,
      "grad_norm": 0.5503835678100586,
      "learning_rate": 1.307047619047619e-05,
      "loss": 1.1206,
      "step": 18190
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.6165316700935364,
      "learning_rate": 1.3066666666666668e-05,
      "loss": 0.4462,
      "step": 18200
    },
    {
      "epoch": 5.202857142857143,
      "grad_norm": 0.6326996088027954,
      "learning_rate": 1.3062857142857144e-05,
      "loss": 0.6547,
      "step": 18210
    },
    {
      "epoch": 5.2057142857142855,
      "grad_norm": 0.613381028175354,
      "learning_rate": 1.3059047619047621e-05,
      "loss": 0.2274,
      "step": 18220
    },
    {
      "epoch": 5.208571428571428,
      "grad_norm": 0.5170761346817017,
      "learning_rate": 1.3055238095238096e-05,
      "loss": 0.5681,
      "step": 18230
    },
    {
      "epoch": 5.211428571428572,
      "grad_norm": 0.5614370107650757,
      "learning_rate": 1.3051428571428572e-05,
      "loss": 0.6697,
      "step": 18240
    },
    {
      "epoch": 5.214285714285714,
      "grad_norm": 10.785292625427246,
      "learning_rate": 1.304761904761905e-05,
      "loss": 0.6643,
      "step": 18250
    },
    {
      "epoch": 5.217142857142857,
      "grad_norm": 0.6712836623191833,
      "learning_rate": 1.3043809523809525e-05,
      "loss": 0.8733,
      "step": 18260
    },
    {
      "epoch": 5.22,
      "grad_norm": 0.6787562966346741,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.1196,
      "step": 18270
    },
    {
      "epoch": 5.222857142857142,
      "grad_norm": 21.94481658935547,
      "learning_rate": 1.3036190476190478e-05,
      "loss": 0.6514,
      "step": 18280
    },
    {
      "epoch": 5.225714285714286,
      "grad_norm": 10.790467262268066,
      "learning_rate": 1.3032380952380953e-05,
      "loss": 0.5473,
      "step": 18290
    },
    {
      "epoch": 5.228571428571429,
      "grad_norm": 0.6045604944229126,
      "learning_rate": 1.302857142857143e-05,
      "loss": 0.2273,
      "step": 18300
    },
    {
      "epoch": 5.231428571428571,
      "grad_norm": 0.5445202589035034,
      "learning_rate": 1.3024761904761906e-05,
      "loss": 0.3415,
      "step": 18310
    },
    {
      "epoch": 5.234285714285714,
      "grad_norm": 10.78941822052002,
      "learning_rate": 1.3020952380952384e-05,
      "loss": 0.5691,
      "step": 18320
    },
    {
      "epoch": 5.2371428571428575,
      "grad_norm": 0.5786424875259399,
      "learning_rate": 1.3017142857142859e-05,
      "loss": 0.6715,
      "step": 18330
    },
    {
      "epoch": 5.24,
      "grad_norm": 22.00099754333496,
      "learning_rate": 1.3013333333333333e-05,
      "loss": 0.8798,
      "step": 18340
    },
    {
      "epoch": 5.242857142857143,
      "grad_norm": 0.6577789187431335,
      "learning_rate": 1.300952380952381e-05,
      "loss": 0.3324,
      "step": 18350
    },
    {
      "epoch": 5.2457142857142856,
      "grad_norm": 0.6384948492050171,
      "learning_rate": 1.3005714285714286e-05,
      "loss": 0.5444,
      "step": 18360
    },
    {
      "epoch": 5.248571428571428,
      "grad_norm": 0.5985390543937683,
      "learning_rate": 1.3001904761904761e-05,
      "loss": 0.3364,
      "step": 18370
    },
    {
      "epoch": 5.251428571428572,
      "grad_norm": 0.5656628608703613,
      "learning_rate": 1.2998095238095239e-05,
      "loss": 0.4472,
      "step": 18380
    },
    {
      "epoch": 5.2542857142857144,
      "grad_norm": 0.5798276662826538,
      "learning_rate": 1.2994285714285714e-05,
      "loss": 0.3391,
      "step": 18390
    },
    {
      "epoch": 5.257142857142857,
      "grad_norm": 0.6245221495628357,
      "learning_rate": 1.2990476190476192e-05,
      "loss": 0.7738,
      "step": 18400
    },
    {
      "epoch": 5.26,
      "grad_norm": 10.769968032836914,
      "learning_rate": 1.2986666666666667e-05,
      "loss": 0.6569,
      "step": 18410
    },
    {
      "epoch": 5.2628571428571425,
      "grad_norm": 10.748052597045898,
      "learning_rate": 1.2982857142857144e-05,
      "loss": 0.5577,
      "step": 18420
    },
    {
      "epoch": 5.265714285714286,
      "grad_norm": 0.574067234992981,
      "learning_rate": 1.297904761904762e-05,
      "loss": 0.2334,
      "step": 18430
    },
    {
      "epoch": 5.268571428571429,
      "grad_norm": 0.5281011462211609,
      "learning_rate": 1.2975238095238096e-05,
      "loss": 0.2317,
      "step": 18440
    },
    {
      "epoch": 5.271428571428571,
      "grad_norm": 0.4916802644729614,
      "learning_rate": 1.2971428571428573e-05,
      "loss": 0.348,
      "step": 18450
    },
    {
      "epoch": 5.274285714285714,
      "grad_norm": 22.24156951904297,
      "learning_rate": 1.2967619047619048e-05,
      "loss": 0.6842,
      "step": 18460
    },
    {
      "epoch": 5.277142857142858,
      "grad_norm": 0.49929672479629517,
      "learning_rate": 1.2963809523809526e-05,
      "loss": 0.4656,
      "step": 18470
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.6092163920402527,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.4533,
      "step": 18480
    },
    {
      "epoch": 5.282857142857143,
      "grad_norm": 0.6122168898582458,
      "learning_rate": 1.2956190476190479e-05,
      "loss": 0.3355,
      "step": 18490
    },
    {
      "epoch": 5.285714285714286,
      "grad_norm": 0.5531191825866699,
      "learning_rate": 1.2952380952380954e-05,
      "loss": 0.3387,
      "step": 18500
    },
    {
      "epoch": 5.288571428571428,
      "grad_norm": 0.4480937719345093,
      "learning_rate": 1.294857142857143e-05,
      "loss": 0.6945,
      "step": 18510
    },
    {
      "epoch": 5.291428571428572,
      "grad_norm": 0.441702276468277,
      "learning_rate": 1.2944761904761907e-05,
      "loss": 0.2407,
      "step": 18520
    },
    {
      "epoch": 5.2942857142857145,
      "grad_norm": 0.47766825556755066,
      "learning_rate": 1.2940952380952383e-05,
      "loss": 0.9314,
      "step": 18530
    },
    {
      "epoch": 5.297142857142857,
      "grad_norm": 33.324554443359375,
      "learning_rate": 1.293714285714286e-05,
      "loss": 0.4602,
      "step": 18540
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.506284773349762,
      "learning_rate": 1.2933333333333334e-05,
      "loss": 0.4585,
      "step": 18550
    },
    {
      "epoch": 5.3028571428571425,
      "grad_norm": 0.5336049199104309,
      "learning_rate": 1.292952380952381e-05,
      "loss": 0.2342,
      "step": 18560
    },
    {
      "epoch": 5.305714285714286,
      "grad_norm": 0.5406204462051392,
      "learning_rate": 1.2925714285714287e-05,
      "loss": 0.4543,
      "step": 18570
    },
    {
      "epoch": 5.308571428571429,
      "grad_norm": 11.117084503173828,
      "learning_rate": 1.2921904761904762e-05,
      "loss": 0.4565,
      "step": 18580
    },
    {
      "epoch": 5.311428571428571,
      "grad_norm": 0.5807763338088989,
      "learning_rate": 1.2918095238095238e-05,
      "loss": 0.8848,
      "step": 18590
    },
    {
      "epoch": 5.314285714285714,
      "grad_norm": 0.579783022403717,
      "learning_rate": 1.2914285714285715e-05,
      "loss": 0.3413,
      "step": 18600
    },
    {
      "epoch": 5.317142857142857,
      "grad_norm": 11.20205020904541,
      "learning_rate": 1.291047619047619e-05,
      "loss": 0.4544,
      "step": 18610
    },
    {
      "epoch": 5.32,
      "grad_norm": 10.811060905456543,
      "learning_rate": 1.2906666666666668e-05,
      "loss": 0.8749,
      "step": 18620
    },
    {
      "epoch": 5.322857142857143,
      "grad_norm": 10.625657081604004,
      "learning_rate": 1.2902857142857143e-05,
      "loss": 0.7479,
      "step": 18630
    },
    {
      "epoch": 5.325714285714286,
      "grad_norm": 33.05820846557617,
      "learning_rate": 1.289904761904762e-05,
      "loss": 0.726,
      "step": 18640
    },
    {
      "epoch": 5.328571428571428,
      "grad_norm": 10.52401065826416,
      "learning_rate": 1.2895238095238096e-05,
      "loss": 0.3201,
      "step": 18650
    },
    {
      "epoch": 5.331428571428571,
      "grad_norm": 0.6897873282432556,
      "learning_rate": 1.2891428571428572e-05,
      "loss": 0.3239,
      "step": 18660
    },
    {
      "epoch": 5.3342857142857145,
      "grad_norm": 0.6191564798355103,
      "learning_rate": 1.288761904761905e-05,
      "loss": 0.3339,
      "step": 18670
    },
    {
      "epoch": 5.337142857142857,
      "grad_norm": 10.739693641662598,
      "learning_rate": 1.2883809523809525e-05,
      "loss": 0.768,
      "step": 18680
    },
    {
      "epoch": 5.34,
      "grad_norm": 0.5478478670120239,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.2331,
      "step": 18690
    },
    {
      "epoch": 5.3428571428571425,
      "grad_norm": 10.791028022766113,
      "learning_rate": 1.2876190476190478e-05,
      "loss": 0.7841,
      "step": 18700
    },
    {
      "epoch": 5.345714285714286,
      "grad_norm": 0.5777812600135803,
      "learning_rate": 1.2872380952380953e-05,
      "loss": 0.3391,
      "step": 18710
    },
    {
      "epoch": 5.348571428571429,
      "grad_norm": 21.907451629638672,
      "learning_rate": 1.286857142857143e-05,
      "loss": 0.7692,
      "step": 18720
    },
    {
      "epoch": 5.351428571428571,
      "grad_norm": 0.7094421982765198,
      "learning_rate": 1.2864761904761906e-05,
      "loss": 0.5472,
      "step": 18730
    },
    {
      "epoch": 5.354285714285714,
      "grad_norm": 11.250246047973633,
      "learning_rate": 1.2860952380952383e-05,
      "loss": 1.0493,
      "step": 18740
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 10.492429733276367,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 0.3164,
      "step": 18750
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.8762314319610596,
      "learning_rate": 1.2853333333333336e-05,
      "loss": 0.4167,
      "step": 18760
    },
    {
      "epoch": 5.362857142857143,
      "grad_norm": 0.7134061455726624,
      "learning_rate": 1.284952380952381e-05,
      "loss": 0.12,
      "step": 18770
    },
    {
      "epoch": 5.365714285714286,
      "grad_norm": 10.664466857910156,
      "learning_rate": 1.2845714285714286e-05,
      "loss": 0.7533,
      "step": 18780
    },
    {
      "epoch": 5.368571428571428,
      "grad_norm": 0.6262145638465881,
      "learning_rate": 1.2841904761904763e-05,
      "loss": 0.439,
      "step": 18790
    },
    {
      "epoch": 5.371428571428572,
      "grad_norm": 0.584013044834137,
      "learning_rate": 1.2838095238095239e-05,
      "loss": 0.3372,
      "step": 18800
    },
    {
      "epoch": 5.3742857142857146,
      "grad_norm": 0.6278789043426514,
      "learning_rate": 1.2834285714285714e-05,
      "loss": 0.555,
      "step": 18810
    },
    {
      "epoch": 5.377142857142857,
      "grad_norm": 0.5546339154243469,
      "learning_rate": 1.2830476190476191e-05,
      "loss": 0.0134,
      "step": 18820
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.537555992603302,
      "learning_rate": 1.2826666666666667e-05,
      "loss": 0.784,
      "step": 18830
    },
    {
      "epoch": 5.382857142857143,
      "grad_norm": 0.5699265003204346,
      "learning_rate": 1.2822857142857144e-05,
      "loss": 0.5619,
      "step": 18840
    },
    {
      "epoch": 5.385714285714286,
      "grad_norm": 0.5736541152000427,
      "learning_rate": 1.281904761904762e-05,
      "loss": 0.2298,
      "step": 18850
    },
    {
      "epoch": 5.388571428571429,
      "grad_norm": 10.803106307983398,
      "learning_rate": 1.2815238095238095e-05,
      "loss": 0.5587,
      "step": 18860
    },
    {
      "epoch": 5.3914285714285715,
      "grad_norm": 10.683988571166992,
      "learning_rate": 1.2811428571428573e-05,
      "loss": 0.5505,
      "step": 18870
    },
    {
      "epoch": 5.394285714285714,
      "grad_norm": 10.729456901550293,
      "learning_rate": 1.2807619047619048e-05,
      "loss": 0.4421,
      "step": 18880
    },
    {
      "epoch": 5.397142857142857,
      "grad_norm": 0.633208692073822,
      "learning_rate": 1.2803809523809526e-05,
      "loss": 0.6606,
      "step": 18890
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.6082152128219604,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.3364,
      "step": 18900
    },
    {
      "epoch": 5.402857142857143,
      "grad_norm": 0.6272673010826111,
      "learning_rate": 1.2796190476190478e-05,
      "loss": 0.6568,
      "step": 18910
    },
    {
      "epoch": 5.405714285714286,
      "grad_norm": 0.6868144869804382,
      "learning_rate": 1.2792380952380954e-05,
      "loss": 0.6482,
      "step": 18920
    },
    {
      "epoch": 5.408571428571428,
      "grad_norm": 0.7103874087333679,
      "learning_rate": 1.278857142857143e-05,
      "loss": 0.3276,
      "step": 18930
    },
    {
      "epoch": 5.411428571428571,
      "grad_norm": 0.6661115288734436,
      "learning_rate": 1.2784761904761907e-05,
      "loss": 0.5436,
      "step": 18940
    },
    {
      "epoch": 5.414285714285715,
      "grad_norm": 0.6573768854141235,
      "learning_rate": 1.2780952380952382e-05,
      "loss": 0.5426,
      "step": 18950
    },
    {
      "epoch": 5.417142857142857,
      "grad_norm": 0.6880907416343689,
      "learning_rate": 1.277714285714286e-05,
      "loss": 0.7518,
      "step": 18960
    },
    {
      "epoch": 5.42,
      "grad_norm": 0.679208517074585,
      "learning_rate": 1.2773333333333335e-05,
      "loss": 0.5397,
      "step": 18970
    },
    {
      "epoch": 5.422857142857143,
      "grad_norm": 0.6445313096046448,
      "learning_rate": 1.2769523809523811e-05,
      "loss": 0.5399,
      "step": 18980
    },
    {
      "epoch": 5.425714285714285,
      "grad_norm": 22.70130157470703,
      "learning_rate": 1.2765714285714286e-05,
      "loss": 0.7574,
      "step": 18990
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 0.5103901028633118,
      "learning_rate": 1.2761904761904762e-05,
      "loss": 0.1249,
      "step": 19000
    },
    {
      "epoch": 5.4314285714285715,
      "grad_norm": 0.4815712571144104,
      "learning_rate": 1.2758095238095238e-05,
      "loss": 0.2361,
      "step": 19010
    },
    {
      "epoch": 5.434285714285714,
      "grad_norm": 10.870739936828613,
      "learning_rate": 1.2754285714285715e-05,
      "loss": 0.8123,
      "step": 19020
    },
    {
      "epoch": 5.437142857142857,
      "grad_norm": 0.46395939588546753,
      "learning_rate": 1.275047619047619e-05,
      "loss": 0.5842,
      "step": 19030
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.4777650535106659,
      "learning_rate": 1.2746666666666668e-05,
      "loss": 0.351,
      "step": 19040
    },
    {
      "epoch": 5.442857142857143,
      "grad_norm": 10.931169509887695,
      "learning_rate": 1.2742857142857143e-05,
      "loss": 0.4653,
      "step": 19050
    },
    {
      "epoch": 5.445714285714286,
      "grad_norm": 10.845431327819824,
      "learning_rate": 1.273904761904762e-05,
      "loss": 0.572,
      "step": 19060
    },
    {
      "epoch": 5.448571428571428,
      "grad_norm": 0.5664618611335754,
      "learning_rate": 1.2735238095238096e-05,
      "loss": 0.4558,
      "step": 19070
    },
    {
      "epoch": 5.451428571428571,
      "grad_norm": 0.5075088143348694,
      "learning_rate": 1.2731428571428572e-05,
      "loss": 0.2329,
      "step": 19080
    },
    {
      "epoch": 5.454285714285715,
      "grad_norm": 0.5127034187316895,
      "learning_rate": 1.2727619047619049e-05,
      "loss": 0.6814,
      "step": 19090
    },
    {
      "epoch": 5.457142857142857,
      "grad_norm": 0.5375844240188599,
      "learning_rate": 1.2723809523809525e-05,
      "loss": 0.6807,
      "step": 19100
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.5813993811607361,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.6688,
      "step": 19110
    },
    {
      "epoch": 5.462857142857143,
      "grad_norm": 0.6456906199455261,
      "learning_rate": 1.2716190476190477e-05,
      "loss": 0.7685,
      "step": 19120
    },
    {
      "epoch": 5.465714285714285,
      "grad_norm": 21.96048927307129,
      "learning_rate": 1.2712380952380953e-05,
      "loss": 0.4387,
      "step": 19130
    },
    {
      "epoch": 5.468571428571429,
      "grad_norm": 0.6331288814544678,
      "learning_rate": 1.270857142857143e-05,
      "loss": 0.4403,
      "step": 19140
    },
    {
      "epoch": 5.4714285714285715,
      "grad_norm": 0.6820921897888184,
      "learning_rate": 1.2704761904761906e-05,
      "loss": 0.5419,
      "step": 19150
    },
    {
      "epoch": 5.474285714285714,
      "grad_norm": 0.6809882521629333,
      "learning_rate": 1.2700952380952383e-05,
      "loss": 0.5406,
      "step": 19160
    },
    {
      "epoch": 5.477142857142857,
      "grad_norm": 10.577744483947754,
      "learning_rate": 1.2697142857142859e-05,
      "loss": 1.2664,
      "step": 19170
    },
    {
      "epoch": 5.48,
      "grad_norm": 10.466999053955078,
      "learning_rate": 1.2693333333333336e-05,
      "loss": 0.7163,
      "step": 19180
    },
    {
      "epoch": 5.482857142857143,
      "grad_norm": 0.8762003779411316,
      "learning_rate": 1.2689523809523812e-05,
      "loss": 0.3169,
      "step": 19190
    },
    {
      "epoch": 5.485714285714286,
      "grad_norm": 0.5431104898452759,
      "learning_rate": 1.2685714285714286e-05,
      "loss": 0.1216,
      "step": 19200
    },
    {
      "epoch": 5.488571428571428,
      "grad_norm": 0.47939208149909973,
      "learning_rate": 1.2681904761904763e-05,
      "loss": 0.3491,
      "step": 19210
    },
    {
      "epoch": 5.491428571428571,
      "grad_norm": 10.859764099121094,
      "learning_rate": 1.2678095238095238e-05,
      "loss": 0.9214,
      "step": 19220
    },
    {
      "epoch": 5.494285714285715,
      "grad_norm": 0.5158047080039978,
      "learning_rate": 1.2674285714285714e-05,
      "loss": 0.6865,
      "step": 19230
    },
    {
      "epoch": 5.497142857142857,
      "grad_norm": 0.47670212388038635,
      "learning_rate": 1.2670476190476191e-05,
      "loss": 0.4536,
      "step": 19240
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.5788286924362183,
      "learning_rate": 1.2666666666666667e-05,
      "loss": 0.9072,
      "step": 19250
    },
    {
      "epoch": 5.502857142857143,
      "grad_norm": 0.6070429682731628,
      "learning_rate": 1.2662857142857144e-05,
      "loss": 0.5561,
      "step": 19260
    },
    {
      "epoch": 5.505714285714285,
      "grad_norm": 0.5582422018051147,
      "learning_rate": 1.265904761904762e-05,
      "loss": 0.5527,
      "step": 19270
    },
    {
      "epoch": 5.508571428571429,
      "grad_norm": 0.6161074042320251,
      "learning_rate": 1.2655238095238095e-05,
      "loss": 0.6578,
      "step": 19280
    },
    {
      "epoch": 5.511428571428572,
      "grad_norm": 0.6115065217018127,
      "learning_rate": 1.2651428571428573e-05,
      "loss": 0.6549,
      "step": 19290
    },
    {
      "epoch": 5.514285714285714,
      "grad_norm": 22.350425720214844,
      "learning_rate": 1.2647619047619048e-05,
      "loss": 0.3418,
      "step": 19300
    },
    {
      "epoch": 5.517142857142857,
      "grad_norm": 0.40954330563545227,
      "learning_rate": 1.2643809523809525e-05,
      "loss": 0.682,
      "step": 19310
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.43806254863739014,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.581,
      "step": 19320
    },
    {
      "epoch": 5.522857142857143,
      "grad_norm": 11.734443664550781,
      "learning_rate": 1.2636190476190478e-05,
      "loss": 0.3814,
      "step": 19330
    },
    {
      "epoch": 5.525714285714286,
      "grad_norm": 10.881052017211914,
      "learning_rate": 1.2632380952380954e-05,
      "loss": 0.787,
      "step": 19340
    },
    {
      "epoch": 5.5285714285714285,
      "grad_norm": 10.48865795135498,
      "learning_rate": 1.262857142857143e-05,
      "loss": 0.9456,
      "step": 19350
    },
    {
      "epoch": 5.531428571428571,
      "grad_norm": 10.62766170501709,
      "learning_rate": 1.2624761904761907e-05,
      "loss": 0.6926,
      "step": 19360
    },
    {
      "epoch": 5.534285714285714,
      "grad_norm": 1.0849392414093018,
      "learning_rate": 1.2620952380952382e-05,
      "loss": 0.4912,
      "step": 19370
    },
    {
      "epoch": 5.537142857142857,
      "grad_norm": 10.53393840789795,
      "learning_rate": 1.261714285714286e-05,
      "loss": 0.2089,
      "step": 19380
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.7690430283546448,
      "learning_rate": 1.2613333333333335e-05,
      "loss": 0.3096,
      "step": 19390
    },
    {
      "epoch": 5.542857142857143,
      "grad_norm": 10.674144744873047,
      "learning_rate": 1.260952380952381e-05,
      "loss": 0.5269,
      "step": 19400
    },
    {
      "epoch": 5.545714285714285,
      "grad_norm": 0.6361575126647949,
      "learning_rate": 1.2605714285714288e-05,
      "loss": 0.334,
      "step": 19410
    },
    {
      "epoch": 5.548571428571429,
      "grad_norm": 0.5090013742446899,
      "learning_rate": 1.2601904761904762e-05,
      "loss": 0.1153,
      "step": 19420
    },
    {
      "epoch": 5.551428571428572,
      "grad_norm": 0.4758143126964569,
      "learning_rate": 1.2598095238095237e-05,
      "loss": 0.5789,
      "step": 19430
    },
    {
      "epoch": 5.554285714285714,
      "grad_norm": 0.5307894945144653,
      "learning_rate": 1.2594285714285715e-05,
      "loss": 0.4553,
      "step": 19440
    },
    {
      "epoch": 5.557142857142857,
      "grad_norm": 11.35011100769043,
      "learning_rate": 1.259047619047619e-05,
      "loss": 0.5632,
      "step": 19450
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 10.697589874267578,
      "learning_rate": 1.2586666666666668e-05,
      "loss": 0.6642,
      "step": 19460
    },
    {
      "epoch": 5.562857142857143,
      "grad_norm": 0.7055881023406982,
      "learning_rate": 1.2582857142857143e-05,
      "loss": 0.2191,
      "step": 19470
    },
    {
      "epoch": 5.565714285714286,
      "grad_norm": 0.5033231973648071,
      "learning_rate": 1.257904761904762e-05,
      "loss": 0.4443,
      "step": 19480
    },
    {
      "epoch": 5.5685714285714285,
      "grad_norm": 21.97198486328125,
      "learning_rate": 1.2575238095238096e-05,
      "loss": 0.8546,
      "step": 19490
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 11.02325439453125,
      "learning_rate": 1.2571428571428572e-05,
      "loss": 0.9354,
      "step": 19500
    },
    {
      "epoch": 5.574285714285715,
      "grad_norm": 10.291460990905762,
      "learning_rate": 1.2567619047619049e-05,
      "loss": 0.3811,
      "step": 19510
    },
    {
      "epoch": 5.577142857142857,
      "grad_norm": 0.7588678598403931,
      "learning_rate": 1.2563809523809524e-05,
      "loss": 0.7048,
      "step": 19520
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.609931230545044,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.32,
      "step": 19530
    },
    {
      "epoch": 5.582857142857143,
      "grad_norm": 0.44865894317626953,
      "learning_rate": 1.2556190476190477e-05,
      "loss": 0.1227,
      "step": 19540
    },
    {
      "epoch": 5.585714285714285,
      "grad_norm": 22.172800064086914,
      "learning_rate": 1.2552380952380953e-05,
      "loss": 0.5984,
      "step": 19550
    },
    {
      "epoch": 5.588571428571429,
      "grad_norm": 0.4082717001438141,
      "learning_rate": 1.254857142857143e-05,
      "loss": 0.4785,
      "step": 19560
    },
    {
      "epoch": 5.591428571428572,
      "grad_norm": 31.524946212768555,
      "learning_rate": 1.2544761904761906e-05,
      "loss": 0.7637,
      "step": 19570
    },
    {
      "epoch": 5.594285714285714,
      "grad_norm": 21.63099479675293,
      "learning_rate": 1.2540952380952383e-05,
      "loss": 0.6633,
      "step": 19580
    },
    {
      "epoch": 5.597142857142857,
      "grad_norm": 10.506855010986328,
      "learning_rate": 1.2537142857142859e-05,
      "loss": 0.6526,
      "step": 19590
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.0547422170639038,
      "learning_rate": 1.2533333333333336e-05,
      "loss": 0.2974,
      "step": 19600
    },
    {
      "epoch": 5.602857142857143,
      "grad_norm": 0.7230191230773926,
      "learning_rate": 1.2529523809523811e-05,
      "loss": 0.5235,
      "step": 19610
    },
    {
      "epoch": 5.605714285714286,
      "grad_norm": 0.5664198994636536,
      "learning_rate": 1.2525714285714287e-05,
      "loss": 0.4468,
      "step": 19620
    },
    {
      "epoch": 5.6085714285714285,
      "grad_norm": 0.5519221425056458,
      "learning_rate": 1.2521904761904764e-05,
      "loss": 0.4541,
      "step": 19630
    },
    {
      "epoch": 5.611428571428571,
      "grad_norm": 0.5106935501098633,
      "learning_rate": 1.2518095238095238e-05,
      "loss": 0.3441,
      "step": 19640
    },
    {
      "epoch": 5.614285714285714,
      "grad_norm": 0.5396050810813904,
      "learning_rate": 1.2514285714285714e-05,
      "loss": 1.0204,
      "step": 19650
    },
    {
      "epoch": 5.617142857142857,
      "grad_norm": 0.521960437297821,
      "learning_rate": 1.2510476190476191e-05,
      "loss": 0.5516,
      "step": 19660
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.5607778429985046,
      "learning_rate": 1.2506666666666667e-05,
      "loss": 0.3296,
      "step": 19670
    },
    {
      "epoch": 5.622857142857143,
      "grad_norm": 11.0181884765625,
      "learning_rate": 1.2502857142857144e-05,
      "loss": 0.3441,
      "step": 19680
    },
    {
      "epoch": 5.6257142857142854,
      "grad_norm": 10.831006050109863,
      "learning_rate": 1.249904761904762e-05,
      "loss": 0.8831,
      "step": 19690
    },
    {
      "epoch": 5.628571428571428,
      "grad_norm": 10.67855453491211,
      "learning_rate": 1.2495238095238095e-05,
      "loss": 0.5408,
      "step": 19700
    },
    {
      "epoch": 5.631428571428572,
      "grad_norm": 0.843870997428894,
      "learning_rate": 1.2491428571428572e-05,
      "loss": 0.6276,
      "step": 19710
    },
    {
      "epoch": 5.634285714285714,
      "grad_norm": 10.490405082702637,
      "learning_rate": 1.2487619047619048e-05,
      "loss": 0.4162,
      "step": 19720
    },
    {
      "epoch": 5.637142857142857,
      "grad_norm": 10.63477897644043,
      "learning_rate": 1.2483809523809525e-05,
      "loss": 0.4295,
      "step": 19730
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.7244966626167297,
      "learning_rate": 1.248e-05,
      "loss": 0.5293,
      "step": 19740
    },
    {
      "epoch": 5.642857142857143,
      "grad_norm": 0.6483203768730164,
      "learning_rate": 1.2476190476190478e-05,
      "loss": 0.6226,
      "step": 19750
    },
    {
      "epoch": 5.645714285714286,
      "grad_norm": 11.394563674926758,
      "learning_rate": 1.2472380952380954e-05,
      "loss": 0.5304,
      "step": 19760
    },
    {
      "epoch": 5.648571428571429,
      "grad_norm": 0.5784084796905518,
      "learning_rate": 1.246857142857143e-05,
      "loss": 0.321,
      "step": 19770
    },
    {
      "epoch": 5.651428571428571,
      "grad_norm": 0.5740137100219727,
      "learning_rate": 1.2464761904761907e-05,
      "loss": 0.2214,
      "step": 19780
    },
    {
      "epoch": 5.654285714285714,
      "grad_norm": 12.080753326416016,
      "learning_rate": 1.2460952380952382e-05,
      "loss": 0.5462,
      "step": 19790
    },
    {
      "epoch": 5.6571428571428575,
      "grad_norm": 0.46650856733322144,
      "learning_rate": 1.245714285714286e-05,
      "loss": 0.4623,
      "step": 19800
    },
    {
      "epoch": 5.66,
      "grad_norm": 11.010481834411621,
      "learning_rate": 1.2453333333333335e-05,
      "loss": 0.6704,
      "step": 19810
    },
    {
      "epoch": 5.662857142857143,
      "grad_norm": 11.057132720947266,
      "learning_rate": 1.244952380952381e-05,
      "loss": 0.3111,
      "step": 19820
    },
    {
      "epoch": 5.6657142857142855,
      "grad_norm": 0.3535600006580353,
      "learning_rate": 1.2445714285714288e-05,
      "loss": 0.3066,
      "step": 19830
    },
    {
      "epoch": 5.668571428571429,
      "grad_norm": 11.128670692443848,
      "learning_rate": 1.2441904761904763e-05,
      "loss": 0.6532,
      "step": 19840
    },
    {
      "epoch": 5.671428571428572,
      "grad_norm": 11.311685562133789,
      "learning_rate": 1.243809523809524e-05,
      "loss": 1.0723,
      "step": 19850
    },
    {
      "epoch": 5.674285714285714,
      "grad_norm": 0.3414350748062134,
      "learning_rate": 1.2434285714285715e-05,
      "loss": 0.3886,
      "step": 19860
    },
    {
      "epoch": 5.677142857142857,
      "grad_norm": 24.002185821533203,
      "learning_rate": 1.243047619047619e-05,
      "loss": 0.5667,
      "step": 19870
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.4946710467338562,
      "learning_rate": 1.2426666666666667e-05,
      "loss": 0.4964,
      "step": 19880
    },
    {
      "epoch": 5.682857142857143,
      "grad_norm": 0.997466504573822,
      "learning_rate": 1.2422857142857143e-05,
      "loss": 0.3853,
      "step": 19890
    },
    {
      "epoch": 5.685714285714286,
      "grad_norm": 0.6020767688751221,
      "learning_rate": 1.241904761904762e-05,
      "loss": 0.4312,
      "step": 19900
    },
    {
      "epoch": 5.688571428571429,
      "grad_norm": 10.846545219421387,
      "learning_rate": 1.2415238095238096e-05,
      "loss": 0.135,
      "step": 19910
    },
    {
      "epoch": 5.691428571428571,
      "grad_norm": 0.2669644355773926,
      "learning_rate": 1.2411428571428571e-05,
      "loss": 0.6735,
      "step": 19920
    },
    {
      "epoch": 5.694285714285714,
      "grad_norm": 0.46388357877731323,
      "learning_rate": 1.2407619047619049e-05,
      "loss": 0.3867,
      "step": 19930
    },
    {
      "epoch": 5.6971428571428575,
      "grad_norm": 0.3134867250919342,
      "learning_rate": 1.2403809523809524e-05,
      "loss": 0.5823,
      "step": 19940
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.36735761165618896,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.329,
      "step": 19950
    },
    {
      "epoch": 5.702857142857143,
      "grad_norm": 10.819045066833496,
      "learning_rate": 1.2396190476190477e-05,
      "loss": 0.2471,
      "step": 19960
    },
    {
      "epoch": 5.7057142857142855,
      "grad_norm": 0.34490150213241577,
      "learning_rate": 1.2392380952380953e-05,
      "loss": 0.4992,
      "step": 19970
    },
    {
      "epoch": 5.708571428571428,
      "grad_norm": 0.3491390347480774,
      "learning_rate": 1.238857142857143e-05,
      "loss": 0.7188,
      "step": 19980
    },
    {
      "epoch": 5.711428571428572,
      "grad_norm": 0.37271639704704285,
      "learning_rate": 1.2384761904761906e-05,
      "loss": 0.3177,
      "step": 19990
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.40276971459388733,
      "learning_rate": 1.2380952380952383e-05,
      "loss": 0.549,
      "step": 20000
    },
    {
      "epoch": 5.717142857142857,
      "grad_norm": 291.4379577636719,
      "learning_rate": 1.2377142857142858e-05,
      "loss": 0.3291,
      "step": 20010
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.6066873669624329,
      "learning_rate": 1.2373333333333336e-05,
      "loss": 0.6301,
      "step": 20020
    },
    {
      "epoch": 5.722857142857142,
      "grad_norm": 0.42701664566993713,
      "learning_rate": 1.2369523809523811e-05,
      "loss": 0.2139,
      "step": 20030
    },
    {
      "epoch": 5.725714285714286,
      "grad_norm": 10.537714958190918,
      "learning_rate": 1.2365714285714287e-05,
      "loss": 0.6356,
      "step": 20040
    },
    {
      "epoch": 5.728571428571429,
      "grad_norm": 0.6411209106445312,
      "learning_rate": 1.2361904761904764e-05,
      "loss": 0.5999,
      "step": 20050
    },
    {
      "epoch": 5.731428571428571,
      "grad_norm": 0.6827560663223267,
      "learning_rate": 1.235809523809524e-05,
      "loss": 0.3292,
      "step": 20060
    },
    {
      "epoch": 5.734285714285714,
      "grad_norm": 11.567827224731445,
      "learning_rate": 1.2354285714285714e-05,
      "loss": 0.7355,
      "step": 20070
    },
    {
      "epoch": 5.737142857142857,
      "grad_norm": 10.177495002746582,
      "learning_rate": 1.2350476190476191e-05,
      "loss": 0.7076,
      "step": 20080
    },
    {
      "epoch": 5.74,
      "grad_norm": 0.5767565369606018,
      "learning_rate": 1.2346666666666666e-05,
      "loss": 0.3351,
      "step": 20090
    },
    {
      "epoch": 5.742857142857143,
      "grad_norm": 10.89551830291748,
      "learning_rate": 1.2342857142857144e-05,
      "loss": 0.5676,
      "step": 20100
    },
    {
      "epoch": 5.7457142857142856,
      "grad_norm": 10.746456146240234,
      "learning_rate": 1.233904761904762e-05,
      "loss": 0.4564,
      "step": 20110
    },
    {
      "epoch": 5.748571428571428,
      "grad_norm": 10.690388679504395,
      "learning_rate": 1.2335238095238095e-05,
      "loss": 0.3719,
      "step": 20120
    },
    {
      "epoch": 5.751428571428572,
      "grad_norm": 0.50328129529953,
      "learning_rate": 1.2331428571428572e-05,
      "loss": 0.5474,
      "step": 20130
    },
    {
      "epoch": 5.7542857142857144,
      "grad_norm": 11.837759971618652,
      "learning_rate": 1.2327619047619048e-05,
      "loss": 0.4365,
      "step": 20140
    },
    {
      "epoch": 5.757142857142857,
      "grad_norm": 0.44360512495040894,
      "learning_rate": 1.2323809523809525e-05,
      "loss": 0.1237,
      "step": 20150
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.38919126987457275,
      "learning_rate": 1.232e-05,
      "loss": 0.5428,
      "step": 20160
    },
    {
      "epoch": 5.762857142857143,
      "grad_norm": 0.4003327786922455,
      "learning_rate": 1.2316190476190478e-05,
      "loss": 0.6153,
      "step": 20170
    },
    {
      "epoch": 5.765714285714286,
      "grad_norm": 11.556158065795898,
      "learning_rate": 1.2312380952380953e-05,
      "loss": 0.8002,
      "step": 20180
    },
    {
      "epoch": 5.768571428571429,
      "grad_norm": 21.655006408691406,
      "learning_rate": 1.2308571428571429e-05,
      "loss": 0.5135,
      "step": 20190
    },
    {
      "epoch": 5.771428571428571,
      "grad_norm": 10.799328804016113,
      "learning_rate": 1.2304761904761906e-05,
      "loss": 0.5428,
      "step": 20200
    },
    {
      "epoch": 5.774285714285714,
      "grad_norm": 1.041464924812317,
      "learning_rate": 1.2300952380952382e-05,
      "loss": 0.4159,
      "step": 20210
    },
    {
      "epoch": 5.777142857142858,
      "grad_norm": 21.998977661132812,
      "learning_rate": 1.229714285714286e-05,
      "loss": 0.4301,
      "step": 20220
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.1409634351730347,
      "learning_rate": 1.2293333333333335e-05,
      "loss": 0.6812,
      "step": 20230
    },
    {
      "epoch": 5.782857142857143,
      "grad_norm": 10.713740348815918,
      "learning_rate": 1.228952380952381e-05,
      "loss": 0.1982,
      "step": 20240
    },
    {
      "epoch": 5.785714285714286,
      "grad_norm": 1.0383634567260742,
      "learning_rate": 1.2285714285714288e-05,
      "loss": 0.4398,
      "step": 20250
    },
    {
      "epoch": 5.788571428571428,
      "grad_norm": 10.832488059997559,
      "learning_rate": 1.2281904761904763e-05,
      "loss": 0.2322,
      "step": 20260
    },
    {
      "epoch": 5.791428571428572,
      "grad_norm": 10.846633911132812,
      "learning_rate": 1.227809523809524e-05,
      "loss": 0.5336,
      "step": 20270
    },
    {
      "epoch": 5.7942857142857145,
      "grad_norm": 0.5673384666442871,
      "learning_rate": 1.2274285714285716e-05,
      "loss": 0.6505,
      "step": 20280
    },
    {
      "epoch": 5.797142857142857,
      "grad_norm": 0.5211406350135803,
      "learning_rate": 1.227047619047619e-05,
      "loss": 0.2359,
      "step": 20290
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.47935277223587036,
      "learning_rate": 1.2266666666666667e-05,
      "loss": 0.2347,
      "step": 20300
    },
    {
      "epoch": 5.8028571428571425,
      "grad_norm": 10.764891624450684,
      "learning_rate": 1.2262857142857143e-05,
      "loss": 0.5593,
      "step": 20310
    },
    {
      "epoch": 5.805714285714286,
      "grad_norm": 0.433145135641098,
      "learning_rate": 1.225904761904762e-05,
      "loss": 0.4438,
      "step": 20320
    },
    {
      "epoch": 5.808571428571429,
      "grad_norm": 10.88172435760498,
      "learning_rate": 1.2255238095238096e-05,
      "loss": 0.4463,
      "step": 20330
    },
    {
      "epoch": 5.811428571428571,
      "grad_norm": 11.639008522033691,
      "learning_rate": 1.2251428571428571e-05,
      "loss": 0.4388,
      "step": 20340
    },
    {
      "epoch": 5.814285714285714,
      "grad_norm": 0.9049084782600403,
      "learning_rate": 1.2247619047619049e-05,
      "loss": 0.5118,
      "step": 20350
    },
    {
      "epoch": 5.817142857142857,
      "grad_norm": 0.8268316984176636,
      "learning_rate": 1.2243809523809524e-05,
      "loss": 0.6287,
      "step": 20360
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.02101731300354,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.3562,
      "step": 20370
    },
    {
      "epoch": 5.822857142857143,
      "grad_norm": 11.156859397888184,
      "learning_rate": 1.2236190476190477e-05,
      "loss": 0.3512,
      "step": 20380
    },
    {
      "epoch": 5.825714285714286,
      "grad_norm": 11.042353630065918,
      "learning_rate": 1.2232380952380953e-05,
      "loss": 0.5583,
      "step": 20390
    },
    {
      "epoch": 5.828571428571428,
      "grad_norm": 0.48640599846839905,
      "learning_rate": 1.222857142857143e-05,
      "loss": 0.5125,
      "step": 20400
    },
    {
      "epoch": 5.831428571428571,
      "grad_norm": 10.963902473449707,
      "learning_rate": 1.2224761904761905e-05,
      "loss": 0.3326,
      "step": 20410
    },
    {
      "epoch": 5.8342857142857145,
      "grad_norm": 22.112186431884766,
      "learning_rate": 1.2220952380952383e-05,
      "loss": 0.684,
      "step": 20420
    },
    {
      "epoch": 5.837142857142857,
      "grad_norm": 10.81457805633545,
      "learning_rate": 1.2217142857142858e-05,
      "loss": 1.2167,
      "step": 20430
    },
    {
      "epoch": 5.84,
      "grad_norm": 10.922300338745117,
      "learning_rate": 1.2213333333333336e-05,
      "loss": 0.309,
      "step": 20440
    },
    {
      "epoch": 5.8428571428571425,
      "grad_norm": 0.6496255397796631,
      "learning_rate": 1.2209523809523811e-05,
      "loss": 0.5215,
      "step": 20450
    },
    {
      "epoch": 5.845714285714286,
      "grad_norm": 0.5868129730224609,
      "learning_rate": 1.2205714285714287e-05,
      "loss": 0.2055,
      "step": 20460
    },
    {
      "epoch": 5.848571428571429,
      "grad_norm": 0.7675325274467468,
      "learning_rate": 1.2201904761904764e-05,
      "loss": 0.6791,
      "step": 20470
    },
    {
      "epoch": 5.851428571428571,
      "grad_norm": 10.791935920715332,
      "learning_rate": 1.219809523809524e-05,
      "loss": 0.4541,
      "step": 20480
    },
    {
      "epoch": 5.854285714285714,
      "grad_norm": 0.529971718788147,
      "learning_rate": 1.2194285714285717e-05,
      "loss": 0.5407,
      "step": 20490
    },
    {
      "epoch": 5.857142857142857,
      "grad_norm": 10.545575141906738,
      "learning_rate": 1.2190476190476192e-05,
      "loss": 0.3462,
      "step": 20500
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.5442847013473511,
      "learning_rate": 1.2186666666666666e-05,
      "loss": 0.5405,
      "step": 20510
    },
    {
      "epoch": 5.862857142857143,
      "grad_norm": 0.530850887298584,
      "learning_rate": 1.2182857142857144e-05,
      "loss": 0.318,
      "step": 20520
    },
    {
      "epoch": 5.865714285714286,
      "grad_norm": 0.7678749561309814,
      "learning_rate": 1.217904761904762e-05,
      "loss": 0.2353,
      "step": 20530
    },
    {
      "epoch": 5.868571428571428,
      "grad_norm": 0.5122909545898438,
      "learning_rate": 1.2175238095238095e-05,
      "loss": 0.6515,
      "step": 20540
    },
    {
      "epoch": 5.871428571428572,
      "grad_norm": 10.82956600189209,
      "learning_rate": 1.2171428571428572e-05,
      "loss": 0.5439,
      "step": 20550
    },
    {
      "epoch": 5.8742857142857146,
      "grad_norm": 0.5448829531669617,
      "learning_rate": 1.2167619047619048e-05,
      "loss": 0.5655,
      "step": 20560
    },
    {
      "epoch": 5.877142857142857,
      "grad_norm": 0.7362527847290039,
      "learning_rate": 1.2163809523809525e-05,
      "loss": 0.3476,
      "step": 20570
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.7110977172851562,
      "learning_rate": 1.216e-05,
      "loss": 0.4601,
      "step": 20580
    },
    {
      "epoch": 5.882857142857143,
      "grad_norm": 0.4747776985168457,
      "learning_rate": 1.2156190476190478e-05,
      "loss": 0.123,
      "step": 20590
    },
    {
      "epoch": 5.885714285714286,
      "grad_norm": 0.4651889204978943,
      "learning_rate": 1.2152380952380953e-05,
      "loss": 0.8037,
      "step": 20600
    },
    {
      "epoch": 5.888571428571429,
      "grad_norm": 0.48697036504745483,
      "learning_rate": 1.2148571428571429e-05,
      "loss": 0.4473,
      "step": 20610
    },
    {
      "epoch": 5.8914285714285715,
      "grad_norm": 11.580849647521973,
      "learning_rate": 1.2144761904761906e-05,
      "loss": 0.9701,
      "step": 20620
    },
    {
      "epoch": 5.894285714285714,
      "grad_norm": 0.6503427624702454,
      "learning_rate": 1.2140952380952382e-05,
      "loss": 0.441,
      "step": 20630
    },
    {
      "epoch": 5.897142857142857,
      "grad_norm": 0.7180386185646057,
      "learning_rate": 1.2137142857142859e-05,
      "loss": 0.5901,
      "step": 20640
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.7041820883750916,
      "learning_rate": 1.2133333333333335e-05,
      "loss": 0.4014,
      "step": 20650
    },
    {
      "epoch": 5.902857142857143,
      "grad_norm": 0.6256382465362549,
      "learning_rate": 1.212952380952381e-05,
      "loss": 0.2256,
      "step": 20660
    },
    {
      "epoch": 5.905714285714286,
      "grad_norm": 10.809596061706543,
      "learning_rate": 1.2125714285714287e-05,
      "loss": 0.7653,
      "step": 20670
    },
    {
      "epoch": 5.908571428571428,
      "grad_norm": 10.759800910949707,
      "learning_rate": 1.2121904761904763e-05,
      "loss": 0.5452,
      "step": 20680
    },
    {
      "epoch": 5.911428571428571,
      "grad_norm": 0.6545234322547913,
      "learning_rate": 1.211809523809524e-05,
      "loss": 0.4083,
      "step": 20690
    },
    {
      "epoch": 5.914285714285715,
      "grad_norm": 0.6588799357414246,
      "learning_rate": 1.2114285714285716e-05,
      "loss": 0.5423,
      "step": 20700
    },
    {
      "epoch": 5.917142857142857,
      "grad_norm": 10.709096908569336,
      "learning_rate": 1.2110476190476193e-05,
      "loss": 0.4147,
      "step": 20710
    },
    {
      "epoch": 5.92,
      "grad_norm": 21.937725067138672,
      "learning_rate": 1.2106666666666667e-05,
      "loss": 0.8193,
      "step": 20720
    },
    {
      "epoch": 5.922857142857143,
      "grad_norm": 10.833168029785156,
      "learning_rate": 1.2102857142857143e-05,
      "loss": 0.5497,
      "step": 20730
    },
    {
      "epoch": 5.925714285714285,
      "grad_norm": 10.431523323059082,
      "learning_rate": 1.209904761904762e-05,
      "loss": 0.677,
      "step": 20740
    },
    {
      "epoch": 5.928571428571429,
      "grad_norm": 0.6232920289039612,
      "learning_rate": 1.2095238095238096e-05,
      "loss": 0.4354,
      "step": 20750
    },
    {
      "epoch": 5.9314285714285715,
      "grad_norm": 0.6006134748458862,
      "learning_rate": 1.2091428571428571e-05,
      "loss": 0.1944,
      "step": 20760
    },
    {
      "epoch": 5.934285714285714,
      "grad_norm": 0.44581520557403564,
      "learning_rate": 1.2087619047619048e-05,
      "loss": 0.3121,
      "step": 20770
    },
    {
      "epoch": 5.937142857142857,
      "grad_norm": 0.26671189069747925,
      "learning_rate": 1.2083809523809524e-05,
      "loss": 0.1341,
      "step": 20780
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 0.21650905907154083,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.1766,
      "step": 20790
    },
    {
      "epoch": 5.942857142857143,
      "grad_norm": 0.1870446801185608,
      "learning_rate": 1.2076190476190477e-05,
      "loss": 0.4282,
      "step": 20800
    },
    {
      "epoch": 5.945714285714286,
      "grad_norm": 11.646271705627441,
      "learning_rate": 1.2072380952380952e-05,
      "loss": 0.7785,
      "step": 20810
    },
    {
      "epoch": 5.948571428571428,
      "grad_norm": 0.3227912187576294,
      "learning_rate": 1.206857142857143e-05,
      "loss": 0.5163,
      "step": 20820
    },
    {
      "epoch": 5.951428571428571,
      "grad_norm": 22.814136505126953,
      "learning_rate": 1.2064761904761905e-05,
      "loss": 0.4011,
      "step": 20830
    },
    {
      "epoch": 5.954285714285715,
      "grad_norm": 0.620396614074707,
      "learning_rate": 1.2060952380952383e-05,
      "loss": 0.3447,
      "step": 20840
    },
    {
      "epoch": 5.957142857142857,
      "grad_norm": 10.825872421264648,
      "learning_rate": 1.2057142857142858e-05,
      "loss": 0.4079,
      "step": 20850
    },
    {
      "epoch": 5.96,
      "grad_norm": 1.1248974800109863,
      "learning_rate": 1.2053333333333335e-05,
      "loss": 0.3756,
      "step": 20860
    },
    {
      "epoch": 5.962857142857143,
      "grad_norm": 0.23973889648914337,
      "learning_rate": 1.2049523809523811e-05,
      "loss": 0.3529,
      "step": 20870
    },
    {
      "epoch": 5.965714285714286,
      "grad_norm": 14.379644393920898,
      "learning_rate": 1.2045714285714287e-05,
      "loss": 0.4857,
      "step": 20880
    },
    {
      "epoch": 5.968571428571429,
      "grad_norm": 0.4100438058376312,
      "learning_rate": 1.2041904761904764e-05,
      "loss": 0.4741,
      "step": 20890
    },
    {
      "epoch": 5.9714285714285715,
      "grad_norm": 11.092370986938477,
      "learning_rate": 1.203809523809524e-05,
      "loss": 1.0255,
      "step": 20900
    },
    {
      "epoch": 5.974285714285714,
      "grad_norm": 12.379007339477539,
      "learning_rate": 1.2034285714285717e-05,
      "loss": 0.8779,
      "step": 20910
    },
    {
      "epoch": 5.977142857142857,
      "grad_norm": 0.7290804982185364,
      "learning_rate": 1.2030476190476192e-05,
      "loss": 0.5444,
      "step": 20920
    },
    {
      "epoch": 5.98,
      "grad_norm": 11.533978462219238,
      "learning_rate": 1.202666666666667e-05,
      "loss": 0.3724,
      "step": 20930
    },
    {
      "epoch": 5.982857142857143,
      "grad_norm": 0.6987681984901428,
      "learning_rate": 1.2022857142857143e-05,
      "loss": 0.3678,
      "step": 20940
    },
    {
      "epoch": 5.985714285714286,
      "grad_norm": 10.618075370788574,
      "learning_rate": 1.2019047619047619e-05,
      "loss": 0.418,
      "step": 20950
    },
    {
      "epoch": 5.988571428571428,
      "grad_norm": 0.6541764736175537,
      "learning_rate": 1.2015238095238095e-05,
      "loss": 0.1023,
      "step": 20960
    },
    {
      "epoch": 5.991428571428571,
      "grad_norm": 11.234574317932129,
      "learning_rate": 1.2011428571428572e-05,
      "loss": 0.7644,
      "step": 20970
    },
    {
      "epoch": 5.994285714285715,
      "grad_norm": 0.4173215627670288,
      "learning_rate": 1.2007619047619047e-05,
      "loss": 0.4417,
      "step": 20980
    },
    {
      "epoch": 5.997142857142857,
      "grad_norm": 21.57084846496582,
      "learning_rate": 1.2003809523809525e-05,
      "loss": 1.1539,
      "step": 20990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.5831276774406433,
      "learning_rate": 1.2e-05,
      "loss": 0.5253,
      "step": 21000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8893333333333333,
      "eval_f1": 0.0,
      "eval_loss": 0.45639151334762573,
      "eval_precision": 0.0,
      "eval_recall": 0.0,
      "eval_runtime": 263.2202,
      "eval_samples_per_second": 11.397,
      "eval_steps_per_second": 2.849,
      "step": 21000
    },
    {
      "epoch": 6.002857142857143,
      "grad_norm": 10.8726167678833,
      "learning_rate": 1.1996190476190478e-05,
      "loss": 0.6629,
      "step": 21010
    },
    {
      "epoch": 6.005714285714285,
      "grad_norm": 0.6114464998245239,
      "learning_rate": 1.1992380952380953e-05,
      "loss": 0.3001,
      "step": 21020
    },
    {
      "epoch": 6.008571428571429,
      "grad_norm": 22.119380950927734,
      "learning_rate": 1.1988571428571429e-05,
      "loss": 0.2359,
      "step": 21030
    },
    {
      "epoch": 6.011428571428572,
      "grad_norm": 0.5081325769424438,
      "learning_rate": 1.1984761904761906e-05,
      "loss": 0.4622,
      "step": 21040
    },
    {
      "epoch": 6.014285714285714,
      "grad_norm": 0.452107697725296,
      "learning_rate": 1.1980952380952382e-05,
      "loss": 0.3852,
      "step": 21050
    },
    {
      "epoch": 6.017142857142857,
      "grad_norm": 0.4135546088218689,
      "learning_rate": 1.1977142857142859e-05,
      "loss": 0.246,
      "step": 21060
    },
    {
      "epoch": 6.02,
      "grad_norm": 11.441701889038086,
      "learning_rate": 1.1973333333333334e-05,
      "loss": 0.247,
      "step": 21070
    },
    {
      "epoch": 6.022857142857143,
      "grad_norm": 0.3629150390625,
      "learning_rate": 1.196952380952381e-05,
      "loss": 0.4757,
      "step": 21080
    },
    {
      "epoch": 6.025714285714286,
      "grad_norm": 0.31694021821022034,
      "learning_rate": 1.1965714285714287e-05,
      "loss": 0.2029,
      "step": 21090
    },
    {
      "epoch": 6.0285714285714285,
      "grad_norm": 11.020039558410645,
      "learning_rate": 1.1961904761904763e-05,
      "loss": 0.8222,
      "step": 21100
    },
    {
      "epoch": 6.031428571428571,
      "grad_norm": 11.066936492919922,
      "learning_rate": 1.195809523809524e-05,
      "loss": 0.482,
      "step": 21110
    },
    {
      "epoch": 6.034285714285715,
      "grad_norm": 0.44870617985725403,
      "learning_rate": 1.1954285714285716e-05,
      "loss": 0.708,
      "step": 21120
    },
    {
      "epoch": 6.037142857142857,
      "grad_norm": 10.996060371398926,
      "learning_rate": 1.1950476190476193e-05,
      "loss": 0.1274,
      "step": 21130
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.31612518429756165,
      "learning_rate": 1.1946666666666669e-05,
      "loss": 0.6156,
      "step": 21140
    },
    {
      "epoch": 6.042857142857143,
      "grad_norm": 21.47857666015625,
      "learning_rate": 1.1942857142857144e-05,
      "loss": 0.5088,
      "step": 21150
    },
    {
      "epoch": 6.045714285714285,
      "grad_norm": 23.466672897338867,
      "learning_rate": 1.193904761904762e-05,
      "loss": 0.9002,
      "step": 21160
    },
    {
      "epoch": 6.048571428571429,
      "grad_norm": 0.5489094257354736,
      "learning_rate": 1.1935238095238095e-05,
      "loss": 0.3462,
      "step": 21170
    },
    {
      "epoch": 6.051428571428572,
      "grad_norm": 0.44413748383522034,
      "learning_rate": 1.1931428571428571e-05,
      "loss": 0.2857,
      "step": 21180
    },
    {
      "epoch": 6.054285714285714,
      "grad_norm": 22.60163688659668,
      "learning_rate": 1.1927619047619048e-05,
      "loss": 0.4303,
      "step": 21190
    },
    {
      "epoch": 6.057142857142857,
      "grad_norm": 0.3570573627948761,
      "learning_rate": 1.1923809523809524e-05,
      "loss": 0.6724,
      "step": 21200
    },
    {
      "epoch": 6.06,
      "grad_norm": 10.8174409866333,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.539,
      "step": 21210
    },
    {
      "epoch": 6.062857142857143,
      "grad_norm": 0.40352725982666016,
      "learning_rate": 1.1916190476190477e-05,
      "loss": 0.431,
      "step": 21220
    },
    {
      "epoch": 6.065714285714286,
      "grad_norm": 0.45104917883872986,
      "learning_rate": 1.1912380952380952e-05,
      "loss": 0.172,
      "step": 21230
    },
    {
      "epoch": 6.0685714285714285,
      "grad_norm": 0.36481773853302,
      "learning_rate": 1.190857142857143e-05,
      "loss": 0.2475,
      "step": 21240
    },
    {
      "epoch": 6.071428571428571,
      "grad_norm": 11.859559059143066,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 0.87,
      "step": 21250
    },
    {
      "epoch": 6.074285714285715,
      "grad_norm": 0.49205130338668823,
      "learning_rate": 1.1900952380952382e-05,
      "loss": 0.5194,
      "step": 21260
    },
    {
      "epoch": 6.077142857142857,
      "grad_norm": 13.138991355895996,
      "learning_rate": 1.1897142857142858e-05,
      "loss": 0.2697,
      "step": 21270
    },
    {
      "epoch": 6.08,
      "grad_norm": 9.3958740234375,
      "learning_rate": 1.1893333333333335e-05,
      "loss": 0.6477,
      "step": 21280
    },
    {
      "epoch": 6.082857142857143,
      "grad_norm": 18.7775821685791,
      "learning_rate": 1.188952380952381e-05,
      "loss": 0.5328,
      "step": 21290
    },
    {
      "epoch": 6.085714285714285,
      "grad_norm": 14.412009239196777,
      "learning_rate": 1.1885714285714286e-05,
      "loss": 0.4782,
      "step": 21300
    },
    {
      "epoch": 6.088571428571429,
      "grad_norm": 7.299705505371094,
      "learning_rate": 1.1881904761904764e-05,
      "loss": 0.4314,
      "step": 21310
    },
    {
      "epoch": 6.091428571428572,
      "grad_norm": 1.6669946908950806,
      "learning_rate": 1.187809523809524e-05,
      "loss": 0.422,
      "step": 21320
    },
    {
      "epoch": 6.094285714285714,
      "grad_norm": 0.7997918128967285,
      "learning_rate": 1.1874285714285717e-05,
      "loss": 0.351,
      "step": 21330
    },
    {
      "epoch": 6.097142857142857,
      "grad_norm": 0.3751727342605591,
      "learning_rate": 1.1870476190476192e-05,
      "loss": 0.4614,
      "step": 21340
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.941769599914551,
      "learning_rate": 1.186666666666667e-05,
      "loss": 0.4273,
      "step": 21350
    },
    {
      "epoch": 6.102857142857143,
      "grad_norm": 0.35243383049964905,
      "learning_rate": 1.1862857142857145e-05,
      "loss": 0.4514,
      "step": 21360
    },
    {
      "epoch": 6.105714285714286,
      "grad_norm": 0.39033007621765137,
      "learning_rate": 1.1859047619047619e-05,
      "loss": 0.3487,
      "step": 21370
    },
    {
      "epoch": 6.1085714285714285,
      "grad_norm": 0.38103362917900085,
      "learning_rate": 1.1855238095238094e-05,
      "loss": 0.2582,
      "step": 21380
    },
    {
      "epoch": 6.111428571428571,
      "grad_norm": 0.3117503821849823,
      "learning_rate": 1.1851428571428572e-05,
      "loss": 0.2125,
      "step": 21390
    },
    {
      "epoch": 6.114285714285714,
      "grad_norm": 0.5453499555587769,
      "learning_rate": 1.1847619047619047e-05,
      "loss": 0.6562,
      "step": 21400
    },
    {
      "epoch": 6.117142857142857,
      "grad_norm": 0.3013792037963867,
      "learning_rate": 1.1843809523809525e-05,
      "loss": 0.2764,
      "step": 21410
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.3913992643356323,
      "learning_rate": 1.184e-05,
      "loss": 0.146,
      "step": 21420
    },
    {
      "epoch": 6.122857142857143,
      "grad_norm": 0.5106382966041565,
      "learning_rate": 1.1836190476190477e-05,
      "loss": 0.2599,
      "step": 21430
    },
    {
      "epoch": 6.1257142857142854,
      "grad_norm": 0.15347398817539215,
      "learning_rate": 1.1832380952380953e-05,
      "loss": 0.2654,
      "step": 21440
    },
    {
      "epoch": 6.128571428571428,
      "grad_norm": 0.24197286367416382,
      "learning_rate": 1.1828571428571429e-05,
      "loss": 0.6568,
      "step": 21450
    },
    {
      "epoch": 6.131428571428572,
      "grad_norm": 11.132438659667969,
      "learning_rate": 1.1824761904761906e-05,
      "loss": 0.366,
      "step": 21460
    },
    {
      "epoch": 6.134285714285714,
      "grad_norm": 12.073088645935059,
      "learning_rate": 1.1820952380952381e-05,
      "loss": 0.123,
      "step": 21470
    },
    {
      "epoch": 6.137142857142857,
      "grad_norm": 0.43737080693244934,
      "learning_rate": 1.1817142857142859e-05,
      "loss": 0.1334,
      "step": 21480
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.13423682749271393,
      "learning_rate": 1.1813333333333334e-05,
      "loss": 0.0047,
      "step": 21490
    },
    {
      "epoch": 6.142857142857143,
      "grad_norm": 0.1170601174235344,
      "learning_rate": 1.180952380952381e-05,
      "loss": 0.149,
      "step": 21500
    },
    {
      "epoch": 6.145714285714286,
      "grad_norm": 0.15243035554885864,
      "learning_rate": 1.1805714285714287e-05,
      "loss": 0.3056,
      "step": 21510
    },
    {
      "epoch": 6.148571428571429,
      "grad_norm": 0.17670537531375885,
      "learning_rate": 1.1801904761904763e-05,
      "loss": 0.6619,
      "step": 21520
    },
    {
      "epoch": 6.151428571428571,
      "grad_norm": 0.22423608601093292,
      "learning_rate": 1.179809523809524e-05,
      "loss": 0.2512,
      "step": 21530
    },
    {
      "epoch": 6.154285714285714,
      "grad_norm": 0.22965116798877716,
      "learning_rate": 1.1794285714285716e-05,
      "loss": 0.5544,
      "step": 21540
    },
    {
      "epoch": 6.1571428571428575,
      "grad_norm": 15.670646667480469,
      "learning_rate": 1.1790476190476193e-05,
      "loss": 0.7941,
      "step": 21550
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.6427818536758423,
      "learning_rate": 1.1786666666666668e-05,
      "loss": 0.8597,
      "step": 21560
    },
    {
      "epoch": 6.162857142857143,
      "grad_norm": 2.351141929626465,
      "learning_rate": 1.1782857142857144e-05,
      "loss": 0.3952,
      "step": 21570
    },
    {
      "epoch": 6.1657142857142855,
      "grad_norm": 1.0586665868759155,
      "learning_rate": 1.1779047619047621e-05,
      "loss": 0.1807,
      "step": 21580
    },
    {
      "epoch": 6.168571428571428,
      "grad_norm": 0.5139938592910767,
      "learning_rate": 1.1775238095238095e-05,
      "loss": 0.4178,
      "step": 21590
    },
    {
      "epoch": 6.171428571428572,
      "grad_norm": 0.48753783106803894,
      "learning_rate": 1.177142857142857e-05,
      "loss": 0.3444,
      "step": 21600
    },
    {
      "epoch": 6.174285714285714,
      "grad_norm": 0.5066827535629272,
      "learning_rate": 1.1767619047619048e-05,
      "loss": 0.3694,
      "step": 21610
    },
    {
      "epoch": 6.177142857142857,
      "grad_norm": 0.32206737995147705,
      "learning_rate": 1.1763809523809524e-05,
      "loss": 0.2411,
      "step": 21620
    },
    {
      "epoch": 6.18,
      "grad_norm": 0.31821373105049133,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.7411,
      "step": 21630
    },
    {
      "epoch": 6.182857142857143,
      "grad_norm": 0.5049319863319397,
      "learning_rate": 1.1756190476190476e-05,
      "loss": 0.2253,
      "step": 21640
    },
    {
      "epoch": 6.185714285714286,
      "grad_norm": 0.3869326114654541,
      "learning_rate": 1.1752380952380952e-05,
      "loss": 0.0225,
      "step": 21650
    },
    {
      "epoch": 6.188571428571429,
      "grad_norm": 0.13594874739646912,
      "learning_rate": 1.174857142857143e-05,
      "loss": 0.3261,
      "step": 21660
    },
    {
      "epoch": 6.191428571428571,
      "grad_norm": 11.270658493041992,
      "learning_rate": 1.1744761904761905e-05,
      "loss": 0.4576,
      "step": 21670
    },
    {
      "epoch": 6.194285714285714,
      "grad_norm": 13.025294303894043,
      "learning_rate": 1.1740952380952382e-05,
      "loss": 0.5615,
      "step": 21680
    },
    {
      "epoch": 6.1971428571428575,
      "grad_norm": 0.5489353537559509,
      "learning_rate": 1.1737142857142858e-05,
      "loss": 0.4743,
      "step": 21690
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.3554256558418274,
      "learning_rate": 1.1733333333333335e-05,
      "loss": 0.1535,
      "step": 21700
    },
    {
      "epoch": 6.202857142857143,
      "grad_norm": 11.528258323669434,
      "learning_rate": 1.172952380952381e-05,
      "loss": 0.4833,
      "step": 21710
    },
    {
      "epoch": 6.2057142857142855,
      "grad_norm": 0.2177131175994873,
      "learning_rate": 1.1725714285714286e-05,
      "loss": 0.2916,
      "step": 21720
    },
    {
      "epoch": 6.208571428571428,
      "grad_norm": 12.664260864257812,
      "learning_rate": 1.1721904761904763e-05,
      "loss": 0.7509,
      "step": 21730
    },
    {
      "epoch": 6.211428571428572,
      "grad_norm": 23.543479919433594,
      "learning_rate": 1.1718095238095239e-05,
      "loss": 0.9322,
      "step": 21740
    },
    {
      "epoch": 6.214285714285714,
      "grad_norm": 13.183250427246094,
      "learning_rate": 1.1714285714285716e-05,
      "loss": 0.328,
      "step": 21750
    },
    {
      "epoch": 6.217142857142857,
      "grad_norm": 1.4206057786941528,
      "learning_rate": 1.1710476190476192e-05,
      "loss": 0.234,
      "step": 21760
    },
    {
      "epoch": 6.22,
      "grad_norm": 23.34317398071289,
      "learning_rate": 1.170666666666667e-05,
      "loss": 0.8258,
      "step": 21770
    },
    {
      "epoch": 6.222857142857142,
      "grad_norm": 4.117998123168945,
      "learning_rate": 1.1702857142857145e-05,
      "loss": 0.461,
      "step": 21780
    },
    {
      "epoch": 6.225714285714286,
      "grad_norm": 23.16612434387207,
      "learning_rate": 1.169904761904762e-05,
      "loss": 0.3037,
      "step": 21790
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 11.602665901184082,
      "learning_rate": 1.1695238095238098e-05,
      "loss": 0.2477,
      "step": 21800
    },
    {
      "epoch": 6.231428571428571,
      "grad_norm": 11.779741287231445,
      "learning_rate": 1.1691428571428572e-05,
      "loss": 0.5317,
      "step": 21810
    },
    {
      "epoch": 6.234285714285714,
      "grad_norm": 1.6352651119232178,
      "learning_rate": 1.1687619047619047e-05,
      "loss": 0.0273,
      "step": 21820
    },
    {
      "epoch": 6.2371428571428575,
      "grad_norm": 0.08058937638998032,
      "learning_rate": 1.1683809523809524e-05,
      "loss": 0.1042,
      "step": 21830
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.21378572285175323,
      "learning_rate": 1.168e-05,
      "loss": 0.4545,
      "step": 21840
    },
    {
      "epoch": 6.242857142857143,
      "grad_norm": 0.3089504837989807,
      "learning_rate": 1.1676190476190477e-05,
      "loss": 0.4734,
      "step": 21850
    },
    {
      "epoch": 6.2457142857142856,
      "grad_norm": 0.6925819516181946,
      "learning_rate": 1.1672380952380953e-05,
      "loss": 0.387,
      "step": 21860
    },
    {
      "epoch": 6.248571428571428,
      "grad_norm": 1.074736475944519,
      "learning_rate": 1.1668571428571428e-05,
      "loss": 0.4596,
      "step": 21870
    },
    {
      "epoch": 6.251428571428572,
      "grad_norm": 0.5827807784080505,
      "learning_rate": 1.1664761904761906e-05,
      "loss": 0.1833,
      "step": 21880
    },
    {
      "epoch": 6.2542857142857144,
      "grad_norm": 0.16926494240760803,
      "learning_rate": 1.1660952380952381e-05,
      "loss": 0.2528,
      "step": 21890
    },
    {
      "epoch": 6.257142857142857,
      "grad_norm": 15.32951831817627,
      "learning_rate": 1.1657142857142859e-05,
      "loss": 0.3487,
      "step": 21900
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.18502236902713776,
      "learning_rate": 1.1653333333333334e-05,
      "loss": 0.5678,
      "step": 21910
    },
    {
      "epoch": 6.2628571428571425,
      "grad_norm": 0.1499498337507248,
      "learning_rate": 1.1649523809523811e-05,
      "loss": 0.4851,
      "step": 21920
    },
    {
      "epoch": 6.265714285714286,
      "grad_norm": 19.09383773803711,
      "learning_rate": 1.1645714285714287e-05,
      "loss": 0.39,
      "step": 21930
    },
    {
      "epoch": 6.268571428571429,
      "grad_norm": 0.65619957447052,
      "learning_rate": 1.1641904761904763e-05,
      "loss": 0.276,
      "step": 21940
    },
    {
      "epoch": 6.271428571428571,
      "grad_norm": 0.3199429512023926,
      "learning_rate": 1.163809523809524e-05,
      "loss": 0.6098,
      "step": 21950
    },
    {
      "epoch": 6.274285714285714,
      "grad_norm": 2.4507389068603516,
      "learning_rate": 1.1634285714285715e-05,
      "loss": 0.4763,
      "step": 21960
    },
    {
      "epoch": 6.277142857142858,
      "grad_norm": 0.5043600797653198,
      "learning_rate": 1.1630476190476193e-05,
      "loss": 0.2806,
      "step": 21970
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.3096504807472229,
      "learning_rate": 1.1626666666666668e-05,
      "loss": 0.1905,
      "step": 21980
    },
    {
      "epoch": 6.282857142857143,
      "grad_norm": 12.602463722229004,
      "learning_rate": 1.1622857142857144e-05,
      "loss": 0.4895,
      "step": 21990
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 14.783757209777832,
      "learning_rate": 1.1619047619047621e-05,
      "loss": 0.555,
      "step": 22000
    },
    {
      "epoch": 6.288571428571428,
      "grad_norm": 9.543107032775879,
      "learning_rate": 1.1615238095238097e-05,
      "loss": 0.4329,
      "step": 22010
    },
    {
      "epoch": 6.291428571428572,
      "grad_norm": 11.740541458129883,
      "learning_rate": 1.161142857142857e-05,
      "loss": 0.2714,
      "step": 22020
    },
    {
      "epoch": 6.2942857142857145,
      "grad_norm": 0.4360186457633972,
      "learning_rate": 1.1607619047619048e-05,
      "loss": 0.2396,
      "step": 22030
    },
    {
      "epoch": 6.297142857142857,
      "grad_norm": 0.17997673153877258,
      "learning_rate": 1.1603809523809523e-05,
      "loss": 0.4583,
      "step": 22040
    },
    {
      "epoch": 6.3,
      "grad_norm": 0.3701021373271942,
      "learning_rate": 1.16e-05,
      "loss": 0.714,
      "step": 22050
    },
    {
      "epoch": 6.3028571428571425,
      "grad_norm": 12.513160705566406,
      "learning_rate": 1.1596190476190476e-05,
      "loss": 0.3192,
      "step": 22060
    },
    {
      "epoch": 6.305714285714286,
      "grad_norm": 23.82164192199707,
      "learning_rate": 1.1592380952380952e-05,
      "loss": 0.4242,
      "step": 22070
    },
    {
      "epoch": 6.308571428571429,
      "grad_norm": 31.26149559020996,
      "learning_rate": 1.158857142857143e-05,
      "loss": 0.5006,
      "step": 22080
    },
    {
      "epoch": 6.311428571428571,
      "grad_norm": 0.6884464621543884,
      "learning_rate": 1.1584761904761905e-05,
      "loss": 0.1674,
      "step": 22090
    },
    {
      "epoch": 6.314285714285714,
      "grad_norm": 14.971136093139648,
      "learning_rate": 1.1580952380952382e-05,
      "loss": 0.25,
      "step": 22100
    },
    {
      "epoch": 6.317142857142857,
      "grad_norm": 0.4909660220146179,
      "learning_rate": 1.1577142857142858e-05,
      "loss": 0.4865,
      "step": 22110
    },
    {
      "epoch": 6.32,
      "grad_norm": 4.236096382141113,
      "learning_rate": 1.1573333333333335e-05,
      "loss": 0.5383,
      "step": 22120
    },
    {
      "epoch": 6.322857142857143,
      "grad_norm": 0.3579694926738739,
      "learning_rate": 1.156952380952381e-05,
      "loss": 0.1125,
      "step": 22130
    },
    {
      "epoch": 6.325714285714286,
      "grad_norm": 13.248269081115723,
      "learning_rate": 1.1565714285714286e-05,
      "loss": 0.333,
      "step": 22140
    },
    {
      "epoch": 6.328571428571428,
      "grad_norm": 12.749176979064941,
      "learning_rate": 1.1561904761904763e-05,
      "loss": 0.7425,
      "step": 22150
    },
    {
      "epoch": 6.331428571428571,
      "grad_norm": 11.159126281738281,
      "learning_rate": 1.1558095238095239e-05,
      "loss": 0.2501,
      "step": 22160
    },
    {
      "epoch": 6.3342857142857145,
      "grad_norm": 0.3534849286079407,
      "learning_rate": 1.1554285714285716e-05,
      "loss": 0.2896,
      "step": 22170
    },
    {
      "epoch": 6.337142857142857,
      "grad_norm": 12.39200496673584,
      "learning_rate": 1.1550476190476192e-05,
      "loss": 0.602,
      "step": 22180
    },
    {
      "epoch": 6.34,
      "grad_norm": 0.17544369399547577,
      "learning_rate": 1.1546666666666669e-05,
      "loss": 0.0064,
      "step": 22190
    },
    {
      "epoch": 6.3428571428571425,
      "grad_norm": 0.1976330727338791,
      "learning_rate": 1.1542857142857145e-05,
      "loss": 0.3804,
      "step": 22200
    },
    {
      "epoch": 6.345714285714286,
      "grad_norm": 0.3292885422706604,
      "learning_rate": 1.153904761904762e-05,
      "loss": 0.4469,
      "step": 22210
    },
    {
      "epoch": 6.348571428571429,
      "grad_norm": 0.20652708411216736,
      "learning_rate": 1.1535238095238097e-05,
      "loss": 0.419,
      "step": 22220
    },
    {
      "epoch": 6.351428571428571,
      "grad_norm": 0.6147478222846985,
      "learning_rate": 1.1531428571428573e-05,
      "loss": 0.3785,
      "step": 22230
    },
    {
      "epoch": 6.354285714285714,
      "grad_norm": 1.1194711923599243,
      "learning_rate": 1.1527619047619047e-05,
      "loss": 0.0891,
      "step": 22240
    },
    {
      "epoch": 6.357142857142857,
      "grad_norm": 11.585229873657227,
      "learning_rate": 1.1523809523809524e-05,
      "loss": 0.182,
      "step": 22250
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.09786419570446014,
      "learning_rate": 1.152e-05,
      "loss": 0.1142,
      "step": 22260
    },
    {
      "epoch": 6.362857142857143,
      "grad_norm": 0.08105017989873886,
      "learning_rate": 1.1516190476190477e-05,
      "loss": 0.5775,
      "step": 22270
    },
    {
      "epoch": 6.365714285714286,
      "grad_norm": 0.4251117408275604,
      "learning_rate": 1.1512380952380953e-05,
      "loss": 0.3964,
      "step": 22280
    },
    {
      "epoch": 6.368571428571428,
      "grad_norm": 0.22913576662540436,
      "learning_rate": 1.1508571428571428e-05,
      "loss": 0.0801,
      "step": 22290
    },
    {
      "epoch": 6.371428571428572,
      "grad_norm": 0.14951682090759277,
      "learning_rate": 1.1504761904761906e-05,
      "loss": 0.5193,
      "step": 22300
    },
    {
      "epoch": 6.3742857142857146,
      "grad_norm": 0.721583902835846,
      "learning_rate": 1.1500952380952381e-05,
      "loss": 0.4834,
      "step": 22310
    },
    {
      "epoch": 6.377142857142857,
      "grad_norm": 0.26360198855400085,
      "learning_rate": 1.1497142857142858e-05,
      "loss": 0.4506,
      "step": 22320
    },
    {
      "epoch": 6.38,
      "grad_norm": 5.698936939239502,
      "learning_rate": 1.1493333333333334e-05,
      "loss": 0.1521,
      "step": 22330
    },
    {
      "epoch": 6.382857142857143,
      "grad_norm": 14.745491027832031,
      "learning_rate": 1.1489523809523811e-05,
      "loss": 0.3695,
      "step": 22340
    },
    {
      "epoch": 6.385714285714286,
      "grad_norm": 0.32700127363204956,
      "learning_rate": 1.1485714285714287e-05,
      "loss": 0.2509,
      "step": 22350
    },
    {
      "epoch": 6.388571428571429,
      "grad_norm": 12.066336631774902,
      "learning_rate": 1.1481904761904762e-05,
      "loss": 0.466,
      "step": 22360
    },
    {
      "epoch": 6.3914285714285715,
      "grad_norm": 17.985876083374023,
      "learning_rate": 1.147809523809524e-05,
      "loss": 0.3006,
      "step": 22370
    },
    {
      "epoch": 6.394285714285714,
      "grad_norm": 0.039640434086322784,
      "learning_rate": 1.1474285714285715e-05,
      "loss": 0.2079,
      "step": 22380
    },
    {
      "epoch": 6.397142857142857,
      "grad_norm": 0.06240751966834068,
      "learning_rate": 1.1470476190476193e-05,
      "loss": 0.2103,
      "step": 22390
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.011168209835886955,
      "learning_rate": 1.1466666666666668e-05,
      "loss": 0.0032,
      "step": 22400
    },
    {
      "epoch": 6.402857142857143,
      "grad_norm": 0.21380804479122162,
      "learning_rate": 1.1462857142857144e-05,
      "loss": 0.662,
      "step": 22410
    },
    {
      "epoch": 6.405714285714286,
      "grad_norm": 0.13343432545661926,
      "learning_rate": 1.1459047619047621e-05,
      "loss": 0.5621,
      "step": 22420
    },
    {
      "epoch": 6.408571428571428,
      "grad_norm": 0.25328329205513,
      "learning_rate": 1.1455238095238097e-05,
      "loss": 0.3724,
      "step": 22430
    },
    {
      "epoch": 6.411428571428571,
      "grad_norm": 1.3163807392120361,
      "learning_rate": 1.1451428571428574e-05,
      "loss": 0.0974,
      "step": 22440
    },
    {
      "epoch": 6.414285714285715,
      "grad_norm": 0.09100454300642014,
      "learning_rate": 1.144761904761905e-05,
      "loss": 0.4084,
      "step": 22450
    },
    {
      "epoch": 6.417142857142857,
      "grad_norm": 0.1656472384929657,
      "learning_rate": 1.1443809523809523e-05,
      "loss": 0.3097,
      "step": 22460
    },
    {
      "epoch": 6.42,
      "grad_norm": 0.3093172013759613,
      "learning_rate": 1.144e-05,
      "loss": 0.4876,
      "step": 22470
    },
    {
      "epoch": 6.422857142857143,
      "grad_norm": 11.811996459960938,
      "learning_rate": 1.1436190476190476e-05,
      "loss": 0.4961,
      "step": 22480
    },
    {
      "epoch": 6.425714285714285,
      "grad_norm": 9.62834644317627,
      "learning_rate": 1.1432380952380952e-05,
      "loss": 0.4465,
      "step": 22490
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 11.434020042419434,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 0.314,
      "step": 22500
    },
    {
      "epoch": 6.4314285714285715,
      "grad_norm": 0.5327645540237427,
      "learning_rate": 1.1424761904761905e-05,
      "loss": 0.3699,
      "step": 22510
    },
    {
      "epoch": 6.434285714285714,
      "grad_norm": 23.024913787841797,
      "learning_rate": 1.1420952380952382e-05,
      "loss": 0.5848,
      "step": 22520
    },
    {
      "epoch": 6.437142857142857,
      "grad_norm": 0.23464347422122955,
      "learning_rate": 1.1417142857142857e-05,
      "loss": 0.2746,
      "step": 22530
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.17390605807304382,
      "learning_rate": 1.1413333333333335e-05,
      "loss": 0.3153,
      "step": 22540
    },
    {
      "epoch": 6.442857142857143,
      "grad_norm": 0.3968309164047241,
      "learning_rate": 1.140952380952381e-05,
      "loss": 0.3145,
      "step": 22550
    },
    {
      "epoch": 6.445714285714286,
      "grad_norm": 0.13331791758537292,
      "learning_rate": 1.1405714285714286e-05,
      "loss": 0.474,
      "step": 22560
    },
    {
      "epoch": 6.448571428571428,
      "grad_norm": 0.08061783015727997,
      "learning_rate": 1.1401904761904763e-05,
      "loss": 0.1911,
      "step": 22570
    },
    {
      "epoch": 6.451428571428571,
      "grad_norm": 0.7879881858825684,
      "learning_rate": 1.1398095238095239e-05,
      "loss": 0.3835,
      "step": 22580
    },
    {
      "epoch": 6.454285714285715,
      "grad_norm": 47.0221061706543,
      "learning_rate": 1.1394285714285716e-05,
      "loss": 0.4525,
      "step": 22590
    },
    {
      "epoch": 6.457142857142857,
      "grad_norm": 11.900391578674316,
      "learning_rate": 1.1390476190476192e-05,
      "loss": 0.4425,
      "step": 22600
    },
    {
      "epoch": 6.46,
      "grad_norm": 18.258169174194336,
      "learning_rate": 1.1386666666666669e-05,
      "loss": 0.3815,
      "step": 22610
    },
    {
      "epoch": 6.462857142857143,
      "grad_norm": 0.10063407570123672,
      "learning_rate": 1.1382857142857144e-05,
      "loss": 0.4157,
      "step": 22620
    },
    {
      "epoch": 6.465714285714285,
      "grad_norm": 0.3094547986984253,
      "learning_rate": 1.137904761904762e-05,
      "loss": 0.2955,
      "step": 22630
    },
    {
      "epoch": 6.468571428571429,
      "grad_norm": 0.3311317563056946,
      "learning_rate": 1.1375238095238097e-05,
      "loss": 0.125,
      "step": 22640
    },
    {
      "epoch": 6.4714285714285715,
      "grad_norm": 45.43695831298828,
      "learning_rate": 1.1371428571428573e-05,
      "loss": 0.1186,
      "step": 22650
    },
    {
      "epoch": 6.474285714285714,
      "grad_norm": 0.04651859402656555,
      "learning_rate": 1.136761904761905e-05,
      "loss": 0.4846,
      "step": 22660
    },
    {
      "epoch": 6.477142857142857,
      "grad_norm": 15.355517387390137,
      "learning_rate": 1.1363809523809526e-05,
      "loss": 0.3236,
      "step": 22670
    },
    {
      "epoch": 6.48,
      "grad_norm": 31.898151397705078,
      "learning_rate": 1.136e-05,
      "loss": 0.652,
      "step": 22680
    },
    {
      "epoch": 6.482857142857143,
      "grad_norm": 0.0865456834435463,
      "learning_rate": 1.1356190476190477e-05,
      "loss": 0.2959,
      "step": 22690
    },
    {
      "epoch": 6.485714285714286,
      "grad_norm": 0.2467266023159027,
      "learning_rate": 1.1352380952380953e-05,
      "loss": 0.0974,
      "step": 22700
    },
    {
      "epoch": 6.488571428571428,
      "grad_norm": 0.15271791815757751,
      "learning_rate": 1.1348571428571428e-05,
      "loss": 0.4156,
      "step": 22710
    },
    {
      "epoch": 6.491428571428571,
      "grad_norm": 0.0519055500626564,
      "learning_rate": 1.1344761904761905e-05,
      "loss": 0.3841,
      "step": 22720
    },
    {
      "epoch": 6.494285714285715,
      "grad_norm": 0.25872910022735596,
      "learning_rate": 1.1340952380952381e-05,
      "loss": 0.4904,
      "step": 22730
    },
    {
      "epoch": 6.497142857142857,
      "grad_norm": 14.522774696350098,
      "learning_rate": 1.1337142857142858e-05,
      "loss": 0.2069,
      "step": 22740
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.16513803601264954,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.2797,
      "step": 22750
    },
    {
      "epoch": 6.502857142857143,
      "grad_norm": 0.092912957072258,
      "learning_rate": 1.1329523809523811e-05,
      "loss": 0.0143,
      "step": 22760
    },
    {
      "epoch": 6.505714285714285,
      "grad_norm": 0.135239839553833,
      "learning_rate": 1.1325714285714287e-05,
      "loss": 0.4083,
      "step": 22770
    },
    {
      "epoch": 6.508571428571429,
      "grad_norm": 13.334266662597656,
      "learning_rate": 1.1321904761904762e-05,
      "loss": 0.5395,
      "step": 22780
    },
    {
      "epoch": 6.511428571428572,
      "grad_norm": 0.6166518926620483,
      "learning_rate": 1.131809523809524e-05,
      "loss": 0.4541,
      "step": 22790
    },
    {
      "epoch": 6.514285714285714,
      "grad_norm": 0.9539886713027954,
      "learning_rate": 1.1314285714285715e-05,
      "loss": 0.4873,
      "step": 22800
    },
    {
      "epoch": 6.517142857142857,
      "grad_norm": 0.3186459541320801,
      "learning_rate": 1.1310476190476192e-05,
      "loss": 0.4374,
      "step": 22810
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.1622979640960693,
      "learning_rate": 1.1306666666666668e-05,
      "loss": 0.2426,
      "step": 22820
    },
    {
      "epoch": 6.522857142857143,
      "grad_norm": 22.744298934936523,
      "learning_rate": 1.1302857142857144e-05,
      "loss": 0.2398,
      "step": 22830
    },
    {
      "epoch": 6.525714285714286,
      "grad_norm": 0.16155245900154114,
      "learning_rate": 1.129904761904762e-05,
      "loss": 0.1835,
      "step": 22840
    },
    {
      "epoch": 6.5285714285714285,
      "grad_norm": 0.3856101930141449,
      "learning_rate": 1.1295238095238096e-05,
      "loss": 0.4201,
      "step": 22850
    },
    {
      "epoch": 6.531428571428571,
      "grad_norm": 0.04683459922671318,
      "learning_rate": 1.1291428571428574e-05,
      "loss": 0.0912,
      "step": 22860
    },
    {
      "epoch": 6.534285714285714,
      "grad_norm": 0.05583151429891586,
      "learning_rate": 1.128761904761905e-05,
      "loss": 0.3733,
      "step": 22870
    },
    {
      "epoch": 6.537142857142857,
      "grad_norm": 0.04091930016875267,
      "learning_rate": 1.1283809523809527e-05,
      "loss": 0.1292,
      "step": 22880
    },
    {
      "epoch": 6.54,
      "grad_norm": 13.686100959777832,
      "learning_rate": 1.128e-05,
      "loss": 0.0883,
      "step": 22890
    },
    {
      "epoch": 6.542857142857143,
      "grad_norm": 13.732060432434082,
      "learning_rate": 1.1276190476190476e-05,
      "loss": 0.2953,
      "step": 22900
    },
    {
      "epoch": 6.545714285714285,
      "grad_norm": 12.949657440185547,
      "learning_rate": 1.1272380952380952e-05,
      "loss": 0.4746,
      "step": 22910
    },
    {
      "epoch": 6.548571428571429,
      "grad_norm": 0.060442887246608734,
      "learning_rate": 1.1268571428571429e-05,
      "loss": 0.1746,
      "step": 22920
    },
    {
      "epoch": 6.551428571428572,
      "grad_norm": 0.0728679820895195,
      "learning_rate": 1.1264761904761904e-05,
      "loss": 0.0767,
      "step": 22930
    },
    {
      "epoch": 6.554285714285714,
      "grad_norm": 0.0529366135597229,
      "learning_rate": 1.1260952380952382e-05,
      "loss": 0.5011,
      "step": 22940
    },
    {
      "epoch": 6.557142857142857,
      "grad_norm": 0.1175830066204071,
      "learning_rate": 1.1257142857142857e-05,
      "loss": 0.2589,
      "step": 22950
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.09733441472053528,
      "learning_rate": 1.1253333333333335e-05,
      "loss": 0.4169,
      "step": 22960
    },
    {
      "epoch": 6.562857142857143,
      "grad_norm": 0.2777843177318573,
      "learning_rate": 1.124952380952381e-05,
      "loss": 0.47,
      "step": 22970
    },
    {
      "epoch": 6.565714285714286,
      "grad_norm": 1.1080483198165894,
      "learning_rate": 1.1245714285714286e-05,
      "loss": 0.5722,
      "step": 22980
    },
    {
      "epoch": 6.5685714285714285,
      "grad_norm": 0.23865778744220734,
      "learning_rate": 1.1241904761904763e-05,
      "loss": 0.1976,
      "step": 22990
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.7848320603370667,
      "learning_rate": 1.1238095238095239e-05,
      "loss": 0.4937,
      "step": 23000
    },
    {
      "epoch": 6.574285714285715,
      "grad_norm": 0.44233840703964233,
      "learning_rate": 1.1234285714285716e-05,
      "loss": 0.1048,
      "step": 23010
    },
    {
      "epoch": 6.577142857142857,
      "grad_norm": 0.0922725647687912,
      "learning_rate": 1.1230476190476191e-05,
      "loss": 0.7241,
      "step": 23020
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.18571186065673828,
      "learning_rate": 1.1226666666666669e-05,
      "loss": 0.3708,
      "step": 23030
    },
    {
      "epoch": 6.582857142857143,
      "grad_norm": 0.6311429142951965,
      "learning_rate": 1.1222857142857144e-05,
      "loss": 0.2227,
      "step": 23040
    },
    {
      "epoch": 6.585714285714285,
      "grad_norm": 0.1074240654706955,
      "learning_rate": 1.121904761904762e-05,
      "loss": 0.3858,
      "step": 23050
    },
    {
      "epoch": 6.588571428571429,
      "grad_norm": 0.19634702801704407,
      "learning_rate": 1.1215238095238097e-05,
      "loss": 0.4121,
      "step": 23060
    },
    {
      "epoch": 6.591428571428572,
      "grad_norm": 0.48694390058517456,
      "learning_rate": 1.1211428571428573e-05,
      "loss": 0.1021,
      "step": 23070
    },
    {
      "epoch": 6.594285714285714,
      "grad_norm": 12.052610397338867,
      "learning_rate": 1.120761904761905e-05,
      "loss": 0.3815,
      "step": 23080
    },
    {
      "epoch": 6.597142857142857,
      "grad_norm": 0.07186776399612427,
      "learning_rate": 1.1203809523809526e-05,
      "loss": 0.4293,
      "step": 23090
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.4620119631290436,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0844,
      "step": 23100
    },
    {
      "epoch": 6.602857142857143,
      "grad_norm": 0.11414273828268051,
      "learning_rate": 1.1196190476190477e-05,
      "loss": 0.1695,
      "step": 23110
    },
    {
      "epoch": 6.605714285714286,
      "grad_norm": 20.916019439697266,
      "learning_rate": 1.1192380952380952e-05,
      "loss": 0.5393,
      "step": 23120
    },
    {
      "epoch": 6.6085714285714285,
      "grad_norm": 1.501585841178894,
      "learning_rate": 1.1188571428571428e-05,
      "loss": 0.1757,
      "step": 23130
    },
    {
      "epoch": 6.611428571428571,
      "grad_norm": 0.6894123554229736,
      "learning_rate": 1.1184761904761905e-05,
      "loss": 0.3621,
      "step": 23140
    },
    {
      "epoch": 6.614285714285714,
      "grad_norm": 0.17405197024345398,
      "learning_rate": 1.118095238095238e-05,
      "loss": 0.4256,
      "step": 23150
    },
    {
      "epoch": 6.617142857142857,
      "grad_norm": 30.486568450927734,
      "learning_rate": 1.1177142857142858e-05,
      "loss": 0.2305,
      "step": 23160
    },
    {
      "epoch": 6.62,
      "grad_norm": 0.2863580584526062,
      "learning_rate": 1.1173333333333334e-05,
      "loss": 0.2093,
      "step": 23170
    },
    {
      "epoch": 6.622857142857143,
      "grad_norm": 14.584566116333008,
      "learning_rate": 1.1169523809523811e-05,
      "loss": 0.5601,
      "step": 23180
    },
    {
      "epoch": 6.6257142857142854,
      "grad_norm": 43.65853500366211,
      "learning_rate": 1.1165714285714287e-05,
      "loss": 0.7545,
      "step": 23190
    },
    {
      "epoch": 6.628571428571428,
      "grad_norm": 6.780946731567383,
      "learning_rate": 1.1161904761904762e-05,
      "loss": 0.4637,
      "step": 23200
    },
    {
      "epoch": 6.631428571428572,
      "grad_norm": 0.3957332372665405,
      "learning_rate": 1.115809523809524e-05,
      "loss": 0.2958,
      "step": 23210
    },
    {
      "epoch": 6.634285714285714,
      "grad_norm": 13.279609680175781,
      "learning_rate": 1.1154285714285715e-05,
      "loss": 0.1951,
      "step": 23220
    },
    {
      "epoch": 6.637142857142857,
      "grad_norm": 0.37993156909942627,
      "learning_rate": 1.1150476190476192e-05,
      "loss": 0.2795,
      "step": 23230
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.21403329074382782,
      "learning_rate": 1.1146666666666668e-05,
      "loss": 0.12,
      "step": 23240
    },
    {
      "epoch": 6.642857142857143,
      "grad_norm": 0.6663390398025513,
      "learning_rate": 1.1142857142857143e-05,
      "loss": 0.3752,
      "step": 23250
    },
    {
      "epoch": 6.645714285714286,
      "grad_norm": 0.018059590831398964,
      "learning_rate": 1.113904761904762e-05,
      "loss": 0.3363,
      "step": 23260
    },
    {
      "epoch": 6.648571428571429,
      "grad_norm": 0.38899344205856323,
      "learning_rate": 1.1135238095238096e-05,
      "loss": 0.1895,
      "step": 23270
    },
    {
      "epoch": 6.651428571428571,
      "grad_norm": 12.723955154418945,
      "learning_rate": 1.1131428571428574e-05,
      "loss": 0.26,
      "step": 23280
    },
    {
      "epoch": 6.654285714285714,
      "grad_norm": 0.06475226581096649,
      "learning_rate": 1.1127619047619049e-05,
      "loss": 0.0711,
      "step": 23290
    },
    {
      "epoch": 6.6571428571428575,
      "grad_norm": 0.11219140887260437,
      "learning_rate": 1.1123809523809526e-05,
      "loss": 0.723,
      "step": 23300
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.22734147310256958,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.2954,
      "step": 23310
    },
    {
      "epoch": 6.662857142857143,
      "grad_norm": 0.505079984664917,
      "learning_rate": 1.1116190476190478e-05,
      "loss": 0.4372,
      "step": 23320
    },
    {
      "epoch": 6.6657142857142855,
      "grad_norm": 0.33460891246795654,
      "learning_rate": 1.1112380952380951e-05,
      "loss": 0.4858,
      "step": 23330
    },
    {
      "epoch": 6.668571428571429,
      "grad_norm": 0.2089279294013977,
      "learning_rate": 1.1108571428571429e-05,
      "loss": 0.0109,
      "step": 23340
    },
    {
      "epoch": 6.671428571428572,
      "grad_norm": 0.042010702192783356,
      "learning_rate": 1.1104761904761904e-05,
      "loss": 0.4059,
      "step": 23350
    },
    {
      "epoch": 6.674285714285714,
      "grad_norm": 0.4814991354942322,
      "learning_rate": 1.1100952380952382e-05,
      "loss": 0.2545,
      "step": 23360
    },
    {
      "epoch": 6.677142857142857,
      "grad_norm": 0.053392473608255386,
      "learning_rate": 1.1097142857142857e-05,
      "loss": 0.2709,
      "step": 23370
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.4091188907623291,
      "learning_rate": 1.1093333333333334e-05,
      "loss": 0.1564,
      "step": 23380
    },
    {
      "epoch": 6.682857142857143,
      "grad_norm": 0.24002613127231598,
      "learning_rate": 1.108952380952381e-05,
      "loss": 0.3203,
      "step": 23390
    },
    {
      "epoch": 6.685714285714286,
      "grad_norm": 17.934955596923828,
      "learning_rate": 1.1085714285714286e-05,
      "loss": 0.8298,
      "step": 23400
    },
    {
      "epoch": 6.688571428571429,
      "grad_norm": 0.5806472301483154,
      "learning_rate": 1.1081904761904763e-05,
      "loss": 0.0228,
      "step": 23410
    },
    {
      "epoch": 6.691428571428571,
      "grad_norm": 0.22884178161621094,
      "learning_rate": 1.1078095238095238e-05,
      "loss": 0.4421,
      "step": 23420
    },
    {
      "epoch": 6.694285714285714,
      "grad_norm": 31.09368324279785,
      "learning_rate": 1.1074285714285716e-05,
      "loss": 0.354,
      "step": 23430
    },
    {
      "epoch": 6.6971428571428575,
      "grad_norm": 0.15592199563980103,
      "learning_rate": 1.1070476190476191e-05,
      "loss": 0.1651,
      "step": 23440
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.267711341381073,
      "learning_rate": 1.1066666666666669e-05,
      "loss": 0.8449,
      "step": 23450
    },
    {
      "epoch": 6.702857142857143,
      "grad_norm": 0.13525985181331635,
      "learning_rate": 1.1062857142857144e-05,
      "loss": 0.1375,
      "step": 23460
    },
    {
      "epoch": 6.7057142857142855,
      "grad_norm": 0.11604814231395721,
      "learning_rate": 1.105904761904762e-05,
      "loss": 0.4738,
      "step": 23470
    },
    {
      "epoch": 6.708571428571428,
      "grad_norm": 0.11832674592733383,
      "learning_rate": 1.1055238095238097e-05,
      "loss": 0.6847,
      "step": 23480
    },
    {
      "epoch": 6.711428571428572,
      "grad_norm": 0.5595888495445251,
      "learning_rate": 1.1051428571428573e-05,
      "loss": 0.1166,
      "step": 23490
    },
    {
      "epoch": 6.714285714285714,
      "grad_norm": 0.18587154150009155,
      "learning_rate": 1.104761904761905e-05,
      "loss": 0.2281,
      "step": 23500
    },
    {
      "epoch": 6.717142857142857,
      "grad_norm": 12.626203536987305,
      "learning_rate": 1.1043809523809525e-05,
      "loss": 0.3229,
      "step": 23510
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.17035681009292603,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.1646,
      "step": 23520
    },
    {
      "epoch": 6.722857142857142,
      "grad_norm": 28.265972137451172,
      "learning_rate": 1.1036190476190478e-05,
      "loss": 0.1447,
      "step": 23530
    },
    {
      "epoch": 6.725714285714286,
      "grad_norm": 0.10216380655765533,
      "learning_rate": 1.1032380952380952e-05,
      "loss": 0.5784,
      "step": 23540
    },
    {
      "epoch": 6.728571428571429,
      "grad_norm": 0.09810323268175125,
      "learning_rate": 1.1028571428571428e-05,
      "loss": 0.4802,
      "step": 23550
    },
    {
      "epoch": 6.731428571428571,
      "grad_norm": 0.4697493016719818,
      "learning_rate": 1.1024761904761905e-05,
      "loss": 0.134,
      "step": 23560
    },
    {
      "epoch": 6.734285714285714,
      "grad_norm": 0.21818271279335022,
      "learning_rate": 1.102095238095238e-05,
      "loss": 0.4767,
      "step": 23570
    },
    {
      "epoch": 6.737142857142857,
      "grad_norm": 15.25101089477539,
      "learning_rate": 1.1017142857142858e-05,
      "loss": 0.6772,
      "step": 23580
    },
    {
      "epoch": 6.74,
      "grad_norm": 12.05314826965332,
      "learning_rate": 1.1013333333333333e-05,
      "loss": 0.4077,
      "step": 23590
    },
    {
      "epoch": 6.742857142857143,
      "grad_norm": 12.48856258392334,
      "learning_rate": 1.100952380952381e-05,
      "loss": 0.6944,
      "step": 23600
    },
    {
      "epoch": 6.7457142857142856,
      "grad_norm": 0.31494662165641785,
      "learning_rate": 1.1005714285714286e-05,
      "loss": 0.5268,
      "step": 23610
    },
    {
      "epoch": 6.748571428571428,
      "grad_norm": 14.703629493713379,
      "learning_rate": 1.1001904761904762e-05,
      "loss": 0.2415,
      "step": 23620
    },
    {
      "epoch": 6.751428571428572,
      "grad_norm": 0.2840043604373932,
      "learning_rate": 1.099809523809524e-05,
      "loss": 0.3664,
      "step": 23630
    },
    {
      "epoch": 6.7542857142857144,
      "grad_norm": 1.6945055723190308,
      "learning_rate": 1.0994285714285715e-05,
      "loss": 0.3512,
      "step": 23640
    },
    {
      "epoch": 6.757142857142857,
      "grad_norm": 12.938010215759277,
      "learning_rate": 1.0990476190476192e-05,
      "loss": 0.1636,
      "step": 23650
    },
    {
      "epoch": 6.76,
      "grad_norm": 12.073257446289062,
      "learning_rate": 1.0986666666666668e-05,
      "loss": 0.2817,
      "step": 23660
    },
    {
      "epoch": 6.762857142857143,
      "grad_norm": 0.12267542630434036,
      "learning_rate": 1.0982857142857143e-05,
      "loss": 0.4533,
      "step": 23670
    },
    {
      "epoch": 6.765714285714286,
      "grad_norm": 12.790520668029785,
      "learning_rate": 1.097904761904762e-05,
      "loss": 0.4451,
      "step": 23680
    },
    {
      "epoch": 6.768571428571429,
      "grad_norm": 12.054306030273438,
      "learning_rate": 1.0975238095238096e-05,
      "loss": 0.5311,
      "step": 23690
    },
    {
      "epoch": 6.771428571428571,
      "grad_norm": 0.5141323804855347,
      "learning_rate": 1.0971428571428573e-05,
      "loss": 0.4087,
      "step": 23700
    },
    {
      "epoch": 6.774285714285714,
      "grad_norm": 12.220921516418457,
      "learning_rate": 1.0967619047619049e-05,
      "loss": 0.4546,
      "step": 23710
    },
    {
      "epoch": 6.777142857142858,
      "grad_norm": 0.1914728730916977,
      "learning_rate": 1.0963809523809526e-05,
      "loss": 0.1963,
      "step": 23720
    },
    {
      "epoch": 6.78,
      "grad_norm": 12.752889633178711,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.3351,
      "step": 23730
    },
    {
      "epoch": 6.782857142857143,
      "grad_norm": 0.32491743564605713,
      "learning_rate": 1.0956190476190477e-05,
      "loss": 0.3362,
      "step": 23740
    },
    {
      "epoch": 6.785714285714286,
      "grad_norm": 0.1225687712430954,
      "learning_rate": 1.0952380952380955e-05,
      "loss": 0.4866,
      "step": 23750
    },
    {
      "epoch": 6.788571428571428,
      "grad_norm": 0.30725640058517456,
      "learning_rate": 1.0948571428571429e-05,
      "loss": 0.3403,
      "step": 23760
    },
    {
      "epoch": 6.791428571428572,
      "grad_norm": 213.44119262695312,
      "learning_rate": 1.0944761904761904e-05,
      "loss": 0.3864,
      "step": 23770
    },
    {
      "epoch": 6.7942857142857145,
      "grad_norm": 13.404476165771484,
      "learning_rate": 1.0940952380952381e-05,
      "loss": 0.4962,
      "step": 23780
    },
    {
      "epoch": 6.797142857142857,
      "grad_norm": 0.34032219648361206,
      "learning_rate": 1.0937142857142857e-05,
      "loss": 0.3045,
      "step": 23790
    },
    {
      "epoch": 6.8,
      "grad_norm": 13.652777671813965,
      "learning_rate": 1.0933333333333334e-05,
      "loss": 0.2381,
      "step": 23800
    },
    {
      "epoch": 6.8028571428571425,
      "grad_norm": 0.2199021577835083,
      "learning_rate": 1.092952380952381e-05,
      "loss": 0.1131,
      "step": 23810
    },
    {
      "epoch": 6.805714285714286,
      "grad_norm": 0.09001921862363815,
      "learning_rate": 1.0925714285714285e-05,
      "loss": 0.2055,
      "step": 23820
    },
    {
      "epoch": 6.808571428571429,
      "grad_norm": 0.2392047792673111,
      "learning_rate": 1.0921904761904763e-05,
      "loss": 0.6341,
      "step": 23830
    },
    {
      "epoch": 6.811428571428571,
      "grad_norm": 0.2795553207397461,
      "learning_rate": 1.0918095238095238e-05,
      "loss": 0.4266,
      "step": 23840
    },
    {
      "epoch": 6.814285714285714,
      "grad_norm": 12.429564476013184,
      "learning_rate": 1.0914285714285716e-05,
      "loss": 0.3392,
      "step": 23850
    },
    {
      "epoch": 6.817142857142857,
      "grad_norm": 0.5109117031097412,
      "learning_rate": 1.0910476190476191e-05,
      "loss": 0.1099,
      "step": 23860
    },
    {
      "epoch": 6.82,
      "grad_norm": 0.4272869825363159,
      "learning_rate": 1.0906666666666668e-05,
      "loss": 0.2204,
      "step": 23870
    },
    {
      "epoch": 6.822857142857143,
      "grad_norm": 0.23260803520679474,
      "learning_rate": 1.0902857142857144e-05,
      "loss": 0.2864,
      "step": 23880
    },
    {
      "epoch": 6.825714285714286,
      "grad_norm": 16.549602508544922,
      "learning_rate": 1.089904761904762e-05,
      "loss": 0.2513,
      "step": 23890
    },
    {
      "epoch": 6.828571428571428,
      "grad_norm": 0.12920647859573364,
      "learning_rate": 1.0895238095238097e-05,
      "loss": 0.5947,
      "step": 23900
    },
    {
      "epoch": 6.831428571428571,
      "grad_norm": 0.46239030361175537,
      "learning_rate": 1.0891428571428572e-05,
      "loss": 0.2984,
      "step": 23910
    },
    {
      "epoch": 6.8342857142857145,
      "grad_norm": 0.03957211971282959,
      "learning_rate": 1.088761904761905e-05,
      "loss": 0.0072,
      "step": 23920
    },
    {
      "epoch": 6.837142857142857,
      "grad_norm": 0.027125168591737747,
      "learning_rate": 1.0883809523809525e-05,
      "loss": 0.106,
      "step": 23930
    },
    {
      "epoch": 6.84,
      "grad_norm": 12.136693000793457,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.2187,
      "step": 23940
    },
    {
      "epoch": 6.8428571428571425,
      "grad_norm": 21.750225067138672,
      "learning_rate": 1.0876190476190478e-05,
      "loss": 0.6396,
      "step": 23950
    },
    {
      "epoch": 6.845714285714286,
      "grad_norm": 0.5340166687965393,
      "learning_rate": 1.0872380952380954e-05,
      "loss": 0.2877,
      "step": 23960
    },
    {
      "epoch": 6.848571428571429,
      "grad_norm": 0.3595353960990906,
      "learning_rate": 1.0868571428571431e-05,
      "loss": 0.1773,
      "step": 23970
    },
    {
      "epoch": 6.851428571428571,
      "grad_norm": 0.16531860828399658,
      "learning_rate": 1.0864761904761905e-05,
      "loss": 0.5622,
      "step": 23980
    },
    {
      "epoch": 6.854285714285714,
      "grad_norm": 13.390326499938965,
      "learning_rate": 1.086095238095238e-05,
      "loss": 0.4145,
      "step": 23990
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 0.04586021974682808,
      "learning_rate": 1.0857142857142858e-05,
      "loss": 0.3961,
      "step": 24000
    },
    {
      "epoch": 6.86,
      "grad_norm": 0.4417741000652313,
      "learning_rate": 1.0853333333333333e-05,
      "loss": 0.3786,
      "step": 24010
    },
    {
      "epoch": 6.862857142857143,
      "grad_norm": 0.32814767956733704,
      "learning_rate": 1.084952380952381e-05,
      "loss": 0.0072,
      "step": 24020
    },
    {
      "epoch": 6.865714285714286,
      "grad_norm": 0.09819266200065613,
      "learning_rate": 1.0845714285714286e-05,
      "loss": 0.6676,
      "step": 24030
    },
    {
      "epoch": 6.868571428571428,
      "grad_norm": 0.33836403489112854,
      "learning_rate": 1.0841904761904762e-05,
      "loss": 0.0945,
      "step": 24040
    },
    {
      "epoch": 6.871428571428572,
      "grad_norm": 18.499038696289062,
      "learning_rate": 1.0838095238095239e-05,
      "loss": 0.138,
      "step": 24050
    },
    {
      "epoch": 6.8742857142857146,
      "grad_norm": 12.860578536987305,
      "learning_rate": 1.0834285714285715e-05,
      "loss": 0.3869,
      "step": 24060
    },
    {
      "epoch": 6.877142857142857,
      "grad_norm": 0.0698043629527092,
      "learning_rate": 1.0830476190476192e-05,
      "loss": 0.1943,
      "step": 24070
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.0500333346426487,
      "learning_rate": 1.0826666666666667e-05,
      "loss": 0.4067,
      "step": 24080
    },
    {
      "epoch": 6.882857142857143,
      "grad_norm": 0.06768323481082916,
      "learning_rate": 1.0822857142857143e-05,
      "loss": 0.1051,
      "step": 24090
    },
    {
      "epoch": 6.885714285714286,
      "grad_norm": 0.08632710576057434,
      "learning_rate": 1.081904761904762e-05,
      "loss": 0.137,
      "step": 24100
    },
    {
      "epoch": 6.888571428571429,
      "grad_norm": 14.126686096191406,
      "learning_rate": 1.0815238095238096e-05,
      "loss": 0.2583,
      "step": 24110
    },
    {
      "epoch": 6.8914285714285715,
      "grad_norm": 0.22268866002559662,
      "learning_rate": 1.0811428571428573e-05,
      "loss": 0.5343,
      "step": 24120
    },
    {
      "epoch": 6.894285714285714,
      "grad_norm": 94.62344360351562,
      "learning_rate": 1.0807619047619049e-05,
      "loss": 0.2159,
      "step": 24130
    },
    {
      "epoch": 6.897142857142857,
      "grad_norm": 0.45859673619270325,
      "learning_rate": 1.0803809523809526e-05,
      "loss": 0.4186,
      "step": 24140
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.03902147337794304,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.3036,
      "step": 24150
    },
    {
      "epoch": 6.902857142857143,
      "grad_norm": 11.313387870788574,
      "learning_rate": 1.0796190476190477e-05,
      "loss": 0.3885,
      "step": 24160
    },
    {
      "epoch": 6.905714285714286,
      "grad_norm": 11.981305122375488,
      "learning_rate": 1.0792380952380954e-05,
      "loss": 0.4462,
      "step": 24170
    },
    {
      "epoch": 6.908571428571428,
      "grad_norm": 0.7112969756126404,
      "learning_rate": 1.078857142857143e-05,
      "loss": 0.1982,
      "step": 24180
    },
    {
      "epoch": 6.911428571428571,
      "grad_norm": 1.5953130722045898,
      "learning_rate": 1.0784761904761904e-05,
      "loss": 0.5165,
      "step": 24190
    },
    {
      "epoch": 6.914285714285715,
      "grad_norm": 17.312829971313477,
      "learning_rate": 1.0780952380952381e-05,
      "loss": 0.4783,
      "step": 24200
    },
    {
      "epoch": 6.917142857142857,
      "grad_norm": 52.29877853393555,
      "learning_rate": 1.0777142857142857e-05,
      "loss": 0.5033,
      "step": 24210
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.2498743534088135,
      "learning_rate": 1.0773333333333334e-05,
      "loss": 0.3693,
      "step": 24220
    },
    {
      "epoch": 6.922857142857143,
      "grad_norm": 0.8542986512184143,
      "learning_rate": 1.076952380952381e-05,
      "loss": 0.1991,
      "step": 24230
    },
    {
      "epoch": 6.925714285714285,
      "grad_norm": 0.19623884558677673,
      "learning_rate": 1.0765714285714285e-05,
      "loss": 0.1255,
      "step": 24240
    },
    {
      "epoch": 6.928571428571429,
      "grad_norm": 0.264370322227478,
      "learning_rate": 1.0761904761904763e-05,
      "loss": 0.2736,
      "step": 24250
    },
    {
      "epoch": 6.9314285714285715,
      "grad_norm": 0.02542462758719921,
      "learning_rate": 1.0758095238095238e-05,
      "loss": 0.0932,
      "step": 24260
    },
    {
      "epoch": 6.934285714285714,
      "grad_norm": 0.04492644965648651,
      "learning_rate": 1.0754285714285715e-05,
      "loss": 0.4085,
      "step": 24270
    },
    {
      "epoch": 6.937142857142857,
      "grad_norm": 0.05009288713335991,
      "learning_rate": 1.0750476190476191e-05,
      "loss": 0.2949,
      "step": 24280
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.5786727666854858,
      "learning_rate": 1.0746666666666668e-05,
      "loss": 0.5496,
      "step": 24290
    },
    {
      "epoch": 6.942857142857143,
      "grad_norm": 0.02900541014969349,
      "learning_rate": 1.0742857142857144e-05,
      "loss": 0.1976,
      "step": 24300
    },
    {
      "epoch": 6.945714285714286,
      "grad_norm": 0.2562381327152252,
      "learning_rate": 1.073904761904762e-05,
      "loss": 0.2751,
      "step": 24310
    },
    {
      "epoch": 6.948571428571428,
      "grad_norm": 0.4523181915283203,
      "learning_rate": 1.0735238095238097e-05,
      "loss": 0.1912,
      "step": 24320
    },
    {
      "epoch": 6.951428571428571,
      "grad_norm": 0.013793363235890865,
      "learning_rate": 1.0731428571428572e-05,
      "loss": 0.2621,
      "step": 24330
    },
    {
      "epoch": 6.954285714285715,
      "grad_norm": 0.2803800404071808,
      "learning_rate": 1.072761904761905e-05,
      "loss": 0.3017,
      "step": 24340
    },
    {
      "epoch": 6.957142857142857,
      "grad_norm": 0.032243844121694565,
      "learning_rate": 1.0723809523809525e-05,
      "loss": 0.2006,
      "step": 24350
    },
    {
      "epoch": 6.96,
      "grad_norm": 13.945013999938965,
      "learning_rate": 1.072e-05,
      "loss": 0.1881,
      "step": 24360
    },
    {
      "epoch": 6.962857142857143,
      "grad_norm": 0.2682916224002838,
      "learning_rate": 1.0716190476190478e-05,
      "loss": 0.0866,
      "step": 24370
    },
    {
      "epoch": 6.965714285714286,
      "grad_norm": 0.06822176277637482,
      "learning_rate": 1.0712380952380954e-05,
      "loss": 0.1058,
      "step": 24380
    },
    {
      "epoch": 6.968571428571429,
      "grad_norm": 12.42361831665039,
      "learning_rate": 1.070857142857143e-05,
      "loss": 0.7611,
      "step": 24390
    },
    {
      "epoch": 6.9714285714285715,
      "grad_norm": 0.1256055235862732,
      "learning_rate": 1.0704761904761906e-05,
      "loss": 0.5792,
      "step": 24400
    },
    {
      "epoch": 6.974285714285714,
      "grad_norm": 0.12589968740940094,
      "learning_rate": 1.070095238095238e-05,
      "loss": 0.1216,
      "step": 24410
    },
    {
      "epoch": 6.977142857142857,
      "grad_norm": 0.31387072801589966,
      "learning_rate": 1.0697142857142858e-05,
      "loss": 0.4148,
      "step": 24420
    },
    {
      "epoch": 6.98,
      "grad_norm": 0.12390903383493423,
      "learning_rate": 1.0693333333333333e-05,
      "loss": 0.2612,
      "step": 24430
    },
    {
      "epoch": 6.982857142857143,
      "grad_norm": 0.07400170713663101,
      "learning_rate": 1.068952380952381e-05,
      "loss": 0.2728,
      "step": 24440
    },
    {
      "epoch": 6.985714285714286,
      "grad_norm": 0.5947644710540771,
      "learning_rate": 1.0685714285714286e-05,
      "loss": 0.2029,
      "step": 24450
    },
    {
      "epoch": 6.988571428571428,
      "grad_norm": 37.69062805175781,
      "learning_rate": 1.0681904761904762e-05,
      "loss": 0.1373,
      "step": 24460
    },
    {
      "epoch": 6.991428571428571,
      "grad_norm": 0.11946350336074829,
      "learning_rate": 1.0678095238095239e-05,
      "loss": 0.1551,
      "step": 24470
    },
    {
      "epoch": 6.994285714285715,
      "grad_norm": 0.4591089189052582,
      "learning_rate": 1.0674285714285714e-05,
      "loss": 0.3485,
      "step": 24480
    },
    {
      "epoch": 6.997142857142857,
      "grad_norm": 12.790307998657227,
      "learning_rate": 1.0670476190476192e-05,
      "loss": 0.5203,
      "step": 24490
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.1416989415884018,
      "learning_rate": 1.0666666666666667e-05,
      "loss": 0.3636,
      "step": 24500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9236666666666666,
      "eval_f1": 0.5336048879837068,
      "eval_loss": 0.3292403817176819,
      "eval_precision": 0.8238993710691824,
      "eval_recall": 0.39457831325301207,
      "eval_runtime": 265.3107,
      "eval_samples_per_second": 11.307,
      "eval_steps_per_second": 2.827,
      "step": 24500
    },
    {
      "epoch": 7.002857142857143,
      "grad_norm": 0.103535957634449,
      "learning_rate": 1.0662857142857143e-05,
      "loss": 0.0608,
      "step": 24510
    },
    {
      "epoch": 7.005714285714285,
      "grad_norm": 0.1195291057229042,
      "learning_rate": 1.065904761904762e-05,
      "loss": 0.3963,
      "step": 24520
    },
    {
      "epoch": 7.008571428571429,
      "grad_norm": 0.11067968606948853,
      "learning_rate": 1.0655238095238096e-05,
      "loss": 0.2109,
      "step": 24530
    },
    {
      "epoch": 7.011428571428572,
      "grad_norm": 0.6391905546188354,
      "learning_rate": 1.0651428571428573e-05,
      "loss": 0.3877,
      "step": 24540
    },
    {
      "epoch": 7.014285714285714,
      "grad_norm": 0.050175055861473083,
      "learning_rate": 1.0647619047619049e-05,
      "loss": 0.2025,
      "step": 24550
    },
    {
      "epoch": 7.017142857142857,
      "grad_norm": 0.9481076598167419,
      "learning_rate": 1.0643809523809526e-05,
      "loss": 0.0045,
      "step": 24560
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.03568059206008911,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.1474,
      "step": 24570
    },
    {
      "epoch": 7.022857142857143,
      "grad_norm": 0.15548516809940338,
      "learning_rate": 1.0636190476190477e-05,
      "loss": 0.1893,
      "step": 24580
    },
    {
      "epoch": 7.025714285714286,
      "grad_norm": 0.09645077586174011,
      "learning_rate": 1.0632380952380954e-05,
      "loss": 0.2822,
      "step": 24590
    },
    {
      "epoch": 7.0285714285714285,
      "grad_norm": 0.10805219411849976,
      "learning_rate": 1.062857142857143e-05,
      "loss": 0.073,
      "step": 24600
    },
    {
      "epoch": 7.031428571428571,
      "grad_norm": 0.12658482789993286,
      "learning_rate": 1.0624761904761907e-05,
      "loss": 0.1418,
      "step": 24610
    },
    {
      "epoch": 7.034285714285715,
      "grad_norm": 0.06246758624911308,
      "learning_rate": 1.0620952380952383e-05,
      "loss": 0.307,
      "step": 24620
    },
    {
      "epoch": 7.037142857142857,
      "grad_norm": 0.09666657447814941,
      "learning_rate": 1.0617142857142857e-05,
      "loss": 0.4101,
      "step": 24630
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.03337973356246948,
      "learning_rate": 1.0613333333333334e-05,
      "loss": 0.3113,
      "step": 24640
    },
    {
      "epoch": 7.042857142857143,
      "grad_norm": 0.032182179391384125,
      "learning_rate": 1.060952380952381e-05,
      "loss": 0.0046,
      "step": 24650
    },
    {
      "epoch": 7.045714285714285,
      "grad_norm": 26.804901123046875,
      "learning_rate": 1.0605714285714285e-05,
      "loss": 0.659,
      "step": 24660
    },
    {
      "epoch": 7.048571428571429,
      "grad_norm": 0.15151627361774445,
      "learning_rate": 1.0601904761904762e-05,
      "loss": 0.3078,
      "step": 24670
    },
    {
      "epoch": 7.051428571428572,
      "grad_norm": 0.04968595877289772,
      "learning_rate": 1.0598095238095238e-05,
      "loss": 0.0566,
      "step": 24680
    },
    {
      "epoch": 7.054285714285714,
      "grad_norm": 0.05919763445854187,
      "learning_rate": 1.0594285714285715e-05,
      "loss": 0.0041,
      "step": 24690
    },
    {
      "epoch": 7.057142857142857,
      "grad_norm": 0.027362430468201637,
      "learning_rate": 1.059047619047619e-05,
      "loss": 0.1934,
      "step": 24700
    },
    {
      "epoch": 7.06,
      "grad_norm": 0.0291458610445261,
      "learning_rate": 1.0586666666666668e-05,
      "loss": 0.4299,
      "step": 24710
    },
    {
      "epoch": 7.062857142857143,
      "grad_norm": 0.642551064491272,
      "learning_rate": 1.0582857142857144e-05,
      "loss": 0.1246,
      "step": 24720
    },
    {
      "epoch": 7.065714285714286,
      "grad_norm": 24.24142074584961,
      "learning_rate": 1.057904761904762e-05,
      "loss": 0.0732,
      "step": 24730
    },
    {
      "epoch": 7.0685714285714285,
      "grad_norm": 0.12700922787189484,
      "learning_rate": 1.0575238095238097e-05,
      "loss": 0.1125,
      "step": 24740
    },
    {
      "epoch": 7.071428571428571,
      "grad_norm": 0.02696261554956436,
      "learning_rate": 1.0571428571428572e-05,
      "loss": 0.0061,
      "step": 24750
    },
    {
      "epoch": 7.074285714285715,
      "grad_norm": 13.138251304626465,
      "learning_rate": 1.056761904761905e-05,
      "loss": 0.8558,
      "step": 24760
    },
    {
      "epoch": 7.077142857142857,
      "grad_norm": 0.19355127215385437,
      "learning_rate": 1.0563809523809525e-05,
      "loss": 0.2769,
      "step": 24770
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.054668400436639786,
      "learning_rate": 1.056e-05,
      "loss": 0.0022,
      "step": 24780
    },
    {
      "epoch": 7.082857142857143,
      "grad_norm": 14.556761741638184,
      "learning_rate": 1.0556190476190478e-05,
      "loss": 0.4031,
      "step": 24790
    },
    {
      "epoch": 7.085714285714285,
      "grad_norm": 0.2068631649017334,
      "learning_rate": 1.0552380952380953e-05,
      "loss": 0.1624,
      "step": 24800
    },
    {
      "epoch": 7.088571428571429,
      "grad_norm": 65.05300903320312,
      "learning_rate": 1.054857142857143e-05,
      "loss": 0.5638,
      "step": 24810
    },
    {
      "epoch": 7.091428571428572,
      "grad_norm": 0.1238178089261055,
      "learning_rate": 1.0544761904761906e-05,
      "loss": 0.0284,
      "step": 24820
    },
    {
      "epoch": 7.094285714285714,
      "grad_norm": 0.3040156066417694,
      "learning_rate": 1.0540952380952384e-05,
      "loss": 0.1177,
      "step": 24830
    },
    {
      "epoch": 7.097142857142857,
      "grad_norm": 0.05005928501486778,
      "learning_rate": 1.0537142857142857e-05,
      "loss": 0.2661,
      "step": 24840
    },
    {
      "epoch": 7.1,
      "grad_norm": 29.461503982543945,
      "learning_rate": 1.0533333333333333e-05,
      "loss": 0.2629,
      "step": 24850
    },
    {
      "epoch": 7.102857142857143,
      "grad_norm": 0.17109152674674988,
      "learning_rate": 1.052952380952381e-05,
      "loss": 0.0047,
      "step": 24860
    },
    {
      "epoch": 7.105714285714286,
      "grad_norm": 0.06757481396198273,
      "learning_rate": 1.0525714285714286e-05,
      "loss": 0.6981,
      "step": 24870
    },
    {
      "epoch": 7.1085714285714285,
      "grad_norm": 0.3580658435821533,
      "learning_rate": 1.0521904761904761e-05,
      "loss": 0.2122,
      "step": 24880
    },
    {
      "epoch": 7.111428571428571,
      "grad_norm": 0.4230019152164459,
      "learning_rate": 1.0518095238095239e-05,
      "loss": 0.4565,
      "step": 24890
    },
    {
      "epoch": 7.114285714285714,
      "grad_norm": 0.28470513224601746,
      "learning_rate": 1.0514285714285714e-05,
      "loss": 0.2517,
      "step": 24900
    },
    {
      "epoch": 7.117142857142857,
      "grad_norm": 0.052528440952301025,
      "learning_rate": 1.0510476190476192e-05,
      "loss": 0.0742,
      "step": 24910
    },
    {
      "epoch": 7.12,
      "grad_norm": 100.34663391113281,
      "learning_rate": 1.0506666666666667e-05,
      "loss": 0.4024,
      "step": 24920
    },
    {
      "epoch": 7.122857142857143,
      "grad_norm": 0.07876301556825638,
      "learning_rate": 1.0502857142857143e-05,
      "loss": 0.3092,
      "step": 24930
    },
    {
      "epoch": 7.1257142857142854,
      "grad_norm": 0.3683306872844696,
      "learning_rate": 1.049904761904762e-05,
      "loss": 0.2983,
      "step": 24940
    },
    {
      "epoch": 7.128571428571428,
      "grad_norm": 0.45252206921577454,
      "learning_rate": 1.0495238095238096e-05,
      "loss": 0.0748,
      "step": 24950
    },
    {
      "epoch": 7.131428571428572,
      "grad_norm": 0.04695870727300644,
      "learning_rate": 1.0491428571428573e-05,
      "loss": 0.0945,
      "step": 24960
    },
    {
      "epoch": 7.134285714285714,
      "grad_norm": 0.159319207072258,
      "learning_rate": 1.0487619047619048e-05,
      "loss": 0.0043,
      "step": 24970
    },
    {
      "epoch": 7.137142857142857,
      "grad_norm": 0.03882823884487152,
      "learning_rate": 1.0483809523809526e-05,
      "loss": 0.1882,
      "step": 24980
    },
    {
      "epoch": 7.14,
      "grad_norm": 0.5035610198974609,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.5143,
      "step": 24990
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 13.125091552734375,
      "learning_rate": 1.0476190476190477e-05,
      "loss": 0.2625,
      "step": 25000
    },
    {
      "epoch": 7.145714285714286,
      "grad_norm": 0.2656536400318146,
      "learning_rate": 1.0472380952380954e-05,
      "loss": 0.1206,
      "step": 25010
    },
    {
      "epoch": 7.148571428571429,
      "grad_norm": 0.2234097570180893,
      "learning_rate": 1.046857142857143e-05,
      "loss": 0.3216,
      "step": 25020
    },
    {
      "epoch": 7.151428571428571,
      "grad_norm": 0.034290630370378494,
      "learning_rate": 1.0464761904761907e-05,
      "loss": 0.1112,
      "step": 25030
    },
    {
      "epoch": 7.154285714285714,
      "grad_norm": 0.017975900322198868,
      "learning_rate": 1.0460952380952383e-05,
      "loss": 0.1758,
      "step": 25040
    },
    {
      "epoch": 7.1571428571428575,
      "grad_norm": 0.01771966740489006,
      "learning_rate": 1.045714285714286e-05,
      "loss": 0.0029,
      "step": 25050
    },
    {
      "epoch": 7.16,
      "grad_norm": 16.38602638244629,
      "learning_rate": 1.0453333333333334e-05,
      "loss": 0.7011,
      "step": 25060
    },
    {
      "epoch": 7.162857142857143,
      "grad_norm": 8.345630645751953,
      "learning_rate": 1.044952380952381e-05,
      "loss": 0.1126,
      "step": 25070
    },
    {
      "epoch": 7.1657142857142855,
      "grad_norm": 12.149009704589844,
      "learning_rate": 1.0445714285714285e-05,
      "loss": 0.3474,
      "step": 25080
    },
    {
      "epoch": 7.168571428571428,
      "grad_norm": 0.19425053894519806,
      "learning_rate": 1.0441904761904762e-05,
      "loss": 0.525,
      "step": 25090
    },
    {
      "epoch": 7.171428571428572,
      "grad_norm": 0.7710754871368408,
      "learning_rate": 1.0438095238095238e-05,
      "loss": 0.0478,
      "step": 25100
    },
    {
      "epoch": 7.174285714285714,
      "grad_norm": 14.859831809997559,
      "learning_rate": 1.0434285714285715e-05,
      "loss": 0.3841,
      "step": 25110
    },
    {
      "epoch": 7.177142857142857,
      "grad_norm": 0.14424850046634674,
      "learning_rate": 1.043047619047619e-05,
      "loss": 0.068,
      "step": 25120
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.021509423851966858,
      "learning_rate": 1.0426666666666668e-05,
      "loss": 0.3375,
      "step": 25130
    },
    {
      "epoch": 7.182857142857143,
      "grad_norm": 0.7759714126586914,
      "learning_rate": 1.0422857142857143e-05,
      "loss": 0.4452,
      "step": 25140
    },
    {
      "epoch": 7.185714285714286,
      "grad_norm": 16.363557815551758,
      "learning_rate": 1.0419047619047619e-05,
      "loss": 0.4707,
      "step": 25150
    },
    {
      "epoch": 7.188571428571429,
      "grad_norm": 0.20878687500953674,
      "learning_rate": 1.0415238095238096e-05,
      "loss": 0.2177,
      "step": 25160
    },
    {
      "epoch": 7.191428571428571,
      "grad_norm": 0.03891418129205704,
      "learning_rate": 1.0411428571428572e-05,
      "loss": 0.2076,
      "step": 25170
    },
    {
      "epoch": 7.194285714285714,
      "grad_norm": 0.2665480673313141,
      "learning_rate": 1.040761904761905e-05,
      "loss": 0.179,
      "step": 25180
    },
    {
      "epoch": 7.1971428571428575,
      "grad_norm": 0.2891501486301422,
      "learning_rate": 1.0403809523809525e-05,
      "loss": 0.0929,
      "step": 25190
    },
    {
      "epoch": 7.2,
      "grad_norm": 102.00736999511719,
      "learning_rate": 1.04e-05,
      "loss": 0.0475,
      "step": 25200
    },
    {
      "epoch": 7.202857142857143,
      "grad_norm": 0.020339425653219223,
      "learning_rate": 1.0396190476190478e-05,
      "loss": 0.2975,
      "step": 25210
    },
    {
      "epoch": 7.2057142857142855,
      "grad_norm": 0.02189701423048973,
      "learning_rate": 1.0392380952380953e-05,
      "loss": 0.0652,
      "step": 25220
    },
    {
      "epoch": 7.208571428571428,
      "grad_norm": 12.354970932006836,
      "learning_rate": 1.038857142857143e-05,
      "loss": 0.3109,
      "step": 25230
    },
    {
      "epoch": 7.211428571428572,
      "grad_norm": 0.025262726470828056,
      "learning_rate": 1.0384761904761906e-05,
      "loss": 0.5035,
      "step": 25240
    },
    {
      "epoch": 7.214285714285714,
      "grad_norm": 0.8655391335487366,
      "learning_rate": 1.0380952380952383e-05,
      "loss": 0.0051,
      "step": 25250
    },
    {
      "epoch": 7.217142857142857,
      "grad_norm": 12.10798168182373,
      "learning_rate": 1.0377142857142859e-05,
      "loss": 0.2638,
      "step": 25260
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.025127004832029343,
      "learning_rate": 1.0373333333333335e-05,
      "loss": 0.096,
      "step": 25270
    },
    {
      "epoch": 7.222857142857142,
      "grad_norm": 0.1941913515329361,
      "learning_rate": 1.036952380952381e-05,
      "loss": 0.0972,
      "step": 25280
    },
    {
      "epoch": 7.225714285714286,
      "grad_norm": 16.947917938232422,
      "learning_rate": 1.0365714285714286e-05,
      "loss": 0.5065,
      "step": 25290
    },
    {
      "epoch": 7.228571428571429,
      "grad_norm": 0.1387322098016739,
      "learning_rate": 1.0361904761904761e-05,
      "loss": 0.0044,
      "step": 25300
    },
    {
      "epoch": 7.231428571428571,
      "grad_norm": 65.65868377685547,
      "learning_rate": 1.0358095238095239e-05,
      "loss": 0.2025,
      "step": 25310
    },
    {
      "epoch": 7.234285714285714,
      "grad_norm": 86.27859497070312,
      "learning_rate": 1.0354285714285714e-05,
      "loss": 0.4968,
      "step": 25320
    },
    {
      "epoch": 7.2371428571428575,
      "grad_norm": 0.13433779776096344,
      "learning_rate": 1.0350476190476191e-05,
      "loss": 0.3112,
      "step": 25330
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.05736406147480011,
      "learning_rate": 1.0346666666666667e-05,
      "loss": 0.1343,
      "step": 25340
    },
    {
      "epoch": 7.242857142857143,
      "grad_norm": 13.598978996276855,
      "learning_rate": 1.0342857142857143e-05,
      "loss": 0.1784,
      "step": 25350
    },
    {
      "epoch": 7.2457142857142856,
      "grad_norm": 0.04283341392874718,
      "learning_rate": 1.033904761904762e-05,
      "loss": 0.2772,
      "step": 25360
    },
    {
      "epoch": 7.248571428571428,
      "grad_norm": 0.43431439995765686,
      "learning_rate": 1.0335238095238095e-05,
      "loss": 0.1693,
      "step": 25370
    },
    {
      "epoch": 7.251428571428572,
      "grad_norm": 0.07510832697153091,
      "learning_rate": 1.0331428571428573e-05,
      "loss": 0.1927,
      "step": 25380
    },
    {
      "epoch": 7.2542857142857144,
      "grad_norm": 32.62683868408203,
      "learning_rate": 1.0327619047619048e-05,
      "loss": 0.318,
      "step": 25390
    },
    {
      "epoch": 7.257142857142857,
      "grad_norm": 11.771592140197754,
      "learning_rate": 1.0323809523809526e-05,
      "loss": 0.2463,
      "step": 25400
    },
    {
      "epoch": 7.26,
      "grad_norm": 0.21703080832958221,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.3622,
      "step": 25410
    },
    {
      "epoch": 7.2628571428571425,
      "grad_norm": 0.029411932453513145,
      "learning_rate": 1.0316190476190477e-05,
      "loss": 0.081,
      "step": 25420
    },
    {
      "epoch": 7.265714285714286,
      "grad_norm": 28.821353912353516,
      "learning_rate": 1.0312380952380954e-05,
      "loss": 0.2144,
      "step": 25430
    },
    {
      "epoch": 7.268571428571429,
      "grad_norm": 0.014748793095350266,
      "learning_rate": 1.030857142857143e-05,
      "loss": 0.3246,
      "step": 25440
    },
    {
      "epoch": 7.271428571428571,
      "grad_norm": 0.8010903596878052,
      "learning_rate": 1.0304761904761907e-05,
      "loss": 0.8045,
      "step": 25450
    },
    {
      "epoch": 7.274285714285714,
      "grad_norm": 12.28602123260498,
      "learning_rate": 1.0300952380952382e-05,
      "loss": 0.3639,
      "step": 25460
    },
    {
      "epoch": 7.277142857142858,
      "grad_norm": 0.03973861038684845,
      "learning_rate": 1.029714285714286e-05,
      "loss": 0.1316,
      "step": 25470
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.1229965686798096,
      "learning_rate": 1.0293333333333335e-05,
      "loss": 0.3625,
      "step": 25480
    },
    {
      "epoch": 7.282857142857143,
      "grad_norm": 0.043227121233940125,
      "learning_rate": 1.0289523809523811e-05,
      "loss": 0.199,
      "step": 25490
    },
    {
      "epoch": 7.285714285714286,
      "grad_norm": 19.87289810180664,
      "learning_rate": 1.0285714285714285e-05,
      "loss": 0.2145,
      "step": 25500
    },
    {
      "epoch": 7.288571428571428,
      "grad_norm": 0.07408834993839264,
      "learning_rate": 1.0281904761904762e-05,
      "loss": 0.1584,
      "step": 25510
    },
    {
      "epoch": 7.291428571428572,
      "grad_norm": 0.04629550874233246,
      "learning_rate": 1.0278095238095238e-05,
      "loss": 0.3342,
      "step": 25520
    },
    {
      "epoch": 7.2942857142857145,
      "grad_norm": 16.919891357421875,
      "learning_rate": 1.0274285714285715e-05,
      "loss": 0.1257,
      "step": 25530
    },
    {
      "epoch": 7.297142857142857,
      "grad_norm": 0.03045964241027832,
      "learning_rate": 1.027047619047619e-05,
      "loss": 0.0038,
      "step": 25540
    },
    {
      "epoch": 7.3,
      "grad_norm": 0.05834995582699776,
      "learning_rate": 1.0266666666666668e-05,
      "loss": 0.0832,
      "step": 25550
    },
    {
      "epoch": 7.3028571428571425,
      "grad_norm": 28.339658737182617,
      "learning_rate": 1.0262857142857143e-05,
      "loss": 0.3245,
      "step": 25560
    },
    {
      "epoch": 7.305714285714286,
      "grad_norm": 0.1882839947938919,
      "learning_rate": 1.0259047619047619e-05,
      "loss": 0.0085,
      "step": 25570
    },
    {
      "epoch": 7.308571428571429,
      "grad_norm": 5.985471725463867,
      "learning_rate": 1.0255238095238096e-05,
      "loss": 0.0587,
      "step": 25580
    },
    {
      "epoch": 7.311428571428571,
      "grad_norm": 0.07593350857496262,
      "learning_rate": 1.0251428571428572e-05,
      "loss": 0.3005,
      "step": 25590
    },
    {
      "epoch": 7.314285714285714,
      "grad_norm": 0.029834408313035965,
      "learning_rate": 1.0247619047619049e-05,
      "loss": 0.0007,
      "step": 25600
    },
    {
      "epoch": 7.317142857142857,
      "grad_norm": 0.02850710228085518,
      "learning_rate": 1.0243809523809525e-05,
      "loss": 0.1704,
      "step": 25610
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.10829780995845795,
      "learning_rate": 1.024e-05,
      "loss": 0.097,
      "step": 25620
    },
    {
      "epoch": 7.322857142857143,
      "grad_norm": 0.09244678914546967,
      "learning_rate": 1.0236190476190477e-05,
      "loss": 0.2543,
      "step": 25630
    },
    {
      "epoch": 7.325714285714286,
      "grad_norm": 45.510459899902344,
      "learning_rate": 1.0232380952380953e-05,
      "loss": 0.0075,
      "step": 25640
    },
    {
      "epoch": 7.328571428571428,
      "grad_norm": 0.027081308886408806,
      "learning_rate": 1.022857142857143e-05,
      "loss": 0.1865,
      "step": 25650
    },
    {
      "epoch": 7.331428571428571,
      "grad_norm": 0.036686189472675323,
      "learning_rate": 1.0224761904761906e-05,
      "loss": 0.3389,
      "step": 25660
    },
    {
      "epoch": 7.3342857142857145,
      "grad_norm": 0.10154541581869125,
      "learning_rate": 1.0220952380952383e-05,
      "loss": 0.308,
      "step": 25670
    },
    {
      "epoch": 7.337142857142857,
      "grad_norm": 0.0643242821097374,
      "learning_rate": 1.0217142857142859e-05,
      "loss": 0.2826,
      "step": 25680
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.14647702872753143,
      "learning_rate": 1.0213333333333334e-05,
      "loss": 0.0578,
      "step": 25690
    },
    {
      "epoch": 7.3428571428571425,
      "grad_norm": 0.054587338119745255,
      "learning_rate": 1.0209523809523812e-05,
      "loss": 0.2769,
      "step": 25700
    },
    {
      "epoch": 7.345714285714286,
      "grad_norm": 14.93261432647705,
      "learning_rate": 1.0205714285714286e-05,
      "loss": 0.3642,
      "step": 25710
    },
    {
      "epoch": 7.348571428571429,
      "grad_norm": 3.5208323001861572,
      "learning_rate": 1.0201904761904761e-05,
      "loss": 0.2359,
      "step": 25720
    },
    {
      "epoch": 7.351428571428571,
      "grad_norm": 0.6946496963500977,
      "learning_rate": 1.0198095238095238e-05,
      "loss": 0.1569,
      "step": 25730
    },
    {
      "epoch": 7.354285714285714,
      "grad_norm": 15.118996620178223,
      "learning_rate": 1.0194285714285714e-05,
      "loss": 0.3868,
      "step": 25740
    },
    {
      "epoch": 7.357142857142857,
      "grad_norm": 0.3364375829696655,
      "learning_rate": 1.0190476190476191e-05,
      "loss": 0.1546,
      "step": 25750
    },
    {
      "epoch": 7.36,
      "grad_norm": 14.048591613769531,
      "learning_rate": 1.0186666666666667e-05,
      "loss": 0.2879,
      "step": 25760
    },
    {
      "epoch": 7.362857142857143,
      "grad_norm": 0.13087525963783264,
      "learning_rate": 1.0182857142857142e-05,
      "loss": 0.1363,
      "step": 25770
    },
    {
      "epoch": 7.365714285714286,
      "grad_norm": 0.05159115791320801,
      "learning_rate": 1.017904761904762e-05,
      "loss": 0.0069,
      "step": 25780
    },
    {
      "epoch": 7.368571428571428,
      "grad_norm": 0.049575962126255035,
      "learning_rate": 1.0175238095238095e-05,
      "loss": 0.1932,
      "step": 25790
    },
    {
      "epoch": 7.371428571428572,
      "grad_norm": 0.36893370747566223,
      "learning_rate": 1.0171428571428573e-05,
      "loss": 0.0806,
      "step": 25800
    },
    {
      "epoch": 7.3742857142857146,
      "grad_norm": 0.013512913137674332,
      "learning_rate": 1.0167619047619048e-05,
      "loss": 0.4557,
      "step": 25810
    },
    {
      "epoch": 7.377142857142857,
      "grad_norm": 0.15005138516426086,
      "learning_rate": 1.0163809523809525e-05,
      "loss": 0.0785,
      "step": 25820
    },
    {
      "epoch": 7.38,
      "grad_norm": 5.212344169616699,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.1283,
      "step": 25830
    },
    {
      "epoch": 7.382857142857143,
      "grad_norm": 0.04480399936437607,
      "learning_rate": 1.0156190476190477e-05,
      "loss": 0.2192,
      "step": 25840
    },
    {
      "epoch": 7.385714285714286,
      "grad_norm": 0.010313751175999641,
      "learning_rate": 1.0152380952380954e-05,
      "loss": 0.4285,
      "step": 25850
    },
    {
      "epoch": 7.388571428571429,
      "grad_norm": 22.75300407409668,
      "learning_rate": 1.014857142857143e-05,
      "loss": 0.4066,
      "step": 25860
    },
    {
      "epoch": 7.3914285714285715,
      "grad_norm": 0.05416707694530487,
      "learning_rate": 1.0144761904761907e-05,
      "loss": 0.4713,
      "step": 25870
    },
    {
      "epoch": 7.394285714285714,
      "grad_norm": 0.11998629570007324,
      "learning_rate": 1.0140952380952382e-05,
      "loss": 0.2727,
      "step": 25880
    },
    {
      "epoch": 7.397142857142857,
      "grad_norm": 0.02194344811141491,
      "learning_rate": 1.013714285714286e-05,
      "loss": 0.4321,
      "step": 25890
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.132623091340065,
      "learning_rate": 1.0133333333333335e-05,
      "loss": 0.1276,
      "step": 25900
    },
    {
      "epoch": 7.402857142857143,
      "grad_norm": 0.031911127269268036,
      "learning_rate": 1.012952380952381e-05,
      "loss": 0.0228,
      "step": 25910
    },
    {
      "epoch": 7.405714285714286,
      "grad_norm": 0.22910785675048828,
      "learning_rate": 1.0125714285714288e-05,
      "loss": 0.1133,
      "step": 25920
    },
    {
      "epoch": 7.408571428571428,
      "grad_norm": 24.647218704223633,
      "learning_rate": 1.0121904761904762e-05,
      "loss": 0.2868,
      "step": 25930
    },
    {
      "epoch": 7.411428571428571,
      "grad_norm": 0.21323886513710022,
      "learning_rate": 1.0118095238095237e-05,
      "loss": 0.2046,
      "step": 25940
    },
    {
      "epoch": 7.414285714285715,
      "grad_norm": 0.06574606895446777,
      "learning_rate": 1.0114285714285715e-05,
      "loss": 0.2024,
      "step": 25950
    },
    {
      "epoch": 7.417142857142857,
      "grad_norm": 0.03426682576537132,
      "learning_rate": 1.011047619047619e-05,
      "loss": 0.0674,
      "step": 25960
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.08213414251804352,
      "learning_rate": 1.0106666666666668e-05,
      "loss": 0.058,
      "step": 25970
    },
    {
      "epoch": 7.422857142857143,
      "grad_norm": 42.62046432495117,
      "learning_rate": 1.0102857142857143e-05,
      "loss": 0.3888,
      "step": 25980
    },
    {
      "epoch": 7.425714285714285,
      "grad_norm": 1.033857822418213,
      "learning_rate": 1.0099047619047619e-05,
      "loss": 0.2364,
      "step": 25990
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 39.315189361572266,
      "learning_rate": 1.0095238095238096e-05,
      "loss": 0.1672,
      "step": 26000
    },
    {
      "epoch": 7.4314285714285715,
      "grad_norm": 0.30305904150009155,
      "learning_rate": 1.0091428571428572e-05,
      "loss": 0.1836,
      "step": 26010
    },
    {
      "epoch": 7.434285714285714,
      "grad_norm": 0.3161557614803314,
      "learning_rate": 1.0087619047619049e-05,
      "loss": 0.0022,
      "step": 26020
    },
    {
      "epoch": 7.437142857142857,
      "grad_norm": 0.14429225027561188,
      "learning_rate": 1.0083809523809524e-05,
      "loss": 0.0998,
      "step": 26030
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.834641933441162,
      "learning_rate": 1.008e-05,
      "loss": 0.2318,
      "step": 26040
    },
    {
      "epoch": 7.442857142857143,
      "grad_norm": 14.266526222229004,
      "learning_rate": 1.0076190476190477e-05,
      "loss": 0.4989,
      "step": 26050
    },
    {
      "epoch": 7.445714285714286,
      "grad_norm": 0.5396320223808289,
      "learning_rate": 1.0072380952380953e-05,
      "loss": 0.1273,
      "step": 26060
    },
    {
      "epoch": 7.448571428571428,
      "grad_norm": 0.16284598410129547,
      "learning_rate": 1.006857142857143e-05,
      "loss": 0.1595,
      "step": 26070
    },
    {
      "epoch": 7.451428571428571,
      "grad_norm": 56.66263961791992,
      "learning_rate": 1.0064761904761906e-05,
      "loss": 0.2122,
      "step": 26080
    },
    {
      "epoch": 7.454285714285715,
      "grad_norm": 0.0628286823630333,
      "learning_rate": 1.0060952380952383e-05,
      "loss": 0.1664,
      "step": 26090
    },
    {
      "epoch": 7.457142857142857,
      "grad_norm": 0.19113539159297943,
      "learning_rate": 1.0057142857142859e-05,
      "loss": 0.1694,
      "step": 26100
    },
    {
      "epoch": 7.46,
      "grad_norm": 0.21782204508781433,
      "learning_rate": 1.0053333333333334e-05,
      "loss": 0.0669,
      "step": 26110
    },
    {
      "epoch": 7.462857142857143,
      "grad_norm": 0.16158635914325714,
      "learning_rate": 1.0049523809523811e-05,
      "loss": 0.0016,
      "step": 26120
    },
    {
      "epoch": 7.465714285714285,
      "grad_norm": 0.609505295753479,
      "learning_rate": 1.0045714285714287e-05,
      "loss": 0.0163,
      "step": 26130
    },
    {
      "epoch": 7.468571428571429,
      "grad_norm": 0.006414886564016342,
      "learning_rate": 1.0041904761904764e-05,
      "loss": 0.4239,
      "step": 26140
    },
    {
      "epoch": 7.4714285714285715,
      "grad_norm": 0.08080368489027023,
      "learning_rate": 1.0038095238095238e-05,
      "loss": 0.2351,
      "step": 26150
    },
    {
      "epoch": 7.474285714285714,
      "grad_norm": 0.027083544060587883,
      "learning_rate": 1.0034285714285714e-05,
      "loss": 0.1299,
      "step": 26160
    },
    {
      "epoch": 7.477142857142857,
      "grad_norm": 13.078717231750488,
      "learning_rate": 1.0030476190476191e-05,
      "loss": 0.2447,
      "step": 26170
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.11632446199655533,
      "learning_rate": 1.0026666666666667e-05,
      "loss": 0.6039,
      "step": 26180
    },
    {
      "epoch": 7.482857142857143,
      "grad_norm": 0.037664491683244705,
      "learning_rate": 1.0022857142857142e-05,
      "loss": 0.2686,
      "step": 26190
    },
    {
      "epoch": 7.485714285714286,
      "grad_norm": 0.2984120547771454,
      "learning_rate": 1.001904761904762e-05,
      "loss": 0.2128,
      "step": 26200
    },
    {
      "epoch": 7.488571428571428,
      "grad_norm": 0.10345488041639328,
      "learning_rate": 1.0015238095238095e-05,
      "loss": 0.3802,
      "step": 26210
    },
    {
      "epoch": 7.491428571428571,
      "grad_norm": 0.044493358582258224,
      "learning_rate": 1.0011428571428572e-05,
      "loss": 0.2359,
      "step": 26220
    },
    {
      "epoch": 7.494285714285715,
      "grad_norm": 0.21256577968597412,
      "learning_rate": 1.0007619047619048e-05,
      "loss": 0.0039,
      "step": 26230
    },
    {
      "epoch": 7.497142857142857,
      "grad_norm": 0.05001133307814598,
      "learning_rate": 1.0003809523809525e-05,
      "loss": 0.1079,
      "step": 26240
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.025363273918628693,
      "learning_rate": 1e-05,
      "loss": 0.0006,
      "step": 26250
    },
    {
      "epoch": 7.502857142857143,
      "grad_norm": 0.21942706406116486,
      "learning_rate": 9.996190476190476e-06,
      "loss": 0.1077,
      "step": 26260
    },
    {
      "epoch": 7.505714285714285,
      "grad_norm": 0.03732449933886528,
      "learning_rate": 9.992380952380954e-06,
      "loss": 0.0025,
      "step": 26270
    },
    {
      "epoch": 7.508571428571429,
      "grad_norm": 0.007719484157860279,
      "learning_rate": 9.98857142857143e-06,
      "loss": 0.2013,
      "step": 26280
    },
    {
      "epoch": 7.511428571428572,
      "grad_norm": 0.1912987232208252,
      "learning_rate": 9.984761904761907e-06,
      "loss": 0.0029,
      "step": 26290
    },
    {
      "epoch": 7.514285714285714,
      "grad_norm": 0.1627509593963623,
      "learning_rate": 9.980952380952382e-06,
      "loss": 0.1917,
      "step": 26300
    },
    {
      "epoch": 7.517142857142857,
      "grad_norm": 0.1536523550748825,
      "learning_rate": 9.977142857142858e-06,
      "loss": 0.1801,
      "step": 26310
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.021158086135983467,
      "learning_rate": 9.973333333333333e-06,
      "loss": 0.1127,
      "step": 26320
    },
    {
      "epoch": 7.522857142857143,
      "grad_norm": 0.02544240839779377,
      "learning_rate": 9.96952380952381e-06,
      "loss": 0.2106,
      "step": 26330
    },
    {
      "epoch": 7.525714285714286,
      "grad_norm": 0.022976871579885483,
      "learning_rate": 9.965714285714286e-06,
      "loss": 0.1943,
      "step": 26340
    },
    {
      "epoch": 7.5285714285714285,
      "grad_norm": 0.00479086535051465,
      "learning_rate": 9.961904761904763e-06,
      "loss": 0.5221,
      "step": 26350
    },
    {
      "epoch": 7.531428571428571,
      "grad_norm": 0.22927986085414886,
      "learning_rate": 9.958095238095239e-06,
      "loss": 0.2259,
      "step": 26360
    },
    {
      "epoch": 7.534285714285714,
      "grad_norm": 0.08903781324625015,
      "learning_rate": 9.954285714285715e-06,
      "loss": 0.2906,
      "step": 26370
    },
    {
      "epoch": 7.537142857142857,
      "grad_norm": 0.20679834485054016,
      "learning_rate": 9.950476190476192e-06,
      "loss": 0.313,
      "step": 26380
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.09667836874723434,
      "learning_rate": 9.946666666666667e-06,
      "loss": 0.2199,
      "step": 26390
    },
    {
      "epoch": 7.542857142857143,
      "grad_norm": 0.01460734847933054,
      "learning_rate": 9.942857142857145e-06,
      "loss": 0.1047,
      "step": 26400
    },
    {
      "epoch": 7.545714285714285,
      "grad_norm": 0.02339690551161766,
      "learning_rate": 9.93904761904762e-06,
      "loss": 0.2636,
      "step": 26410
    },
    {
      "epoch": 7.548571428571429,
      "grad_norm": 1.6844404935836792,
      "learning_rate": 9.935238095238096e-06,
      "loss": 0.1408,
      "step": 26420
    },
    {
      "epoch": 7.551428571428572,
      "grad_norm": 0.0534832738339901,
      "learning_rate": 9.931428571428571e-06,
      "loss": 0.1193,
      "step": 26430
    },
    {
      "epoch": 7.554285714285714,
      "grad_norm": 0.033584412187337875,
      "learning_rate": 9.927619047619049e-06,
      "loss": 0.1704,
      "step": 26440
    },
    {
      "epoch": 7.557142857142857,
      "grad_norm": 0.2303556501865387,
      "learning_rate": 9.923809523809524e-06,
      "loss": 0.2518,
      "step": 26450
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.22544710338115692,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.4653,
      "step": 26460
    },
    {
      "epoch": 7.562857142857143,
      "grad_norm": 0.36984825134277344,
      "learning_rate": 9.916190476190477e-06,
      "loss": 0.2165,
      "step": 26470
    },
    {
      "epoch": 7.565714285714286,
      "grad_norm": 15.499216079711914,
      "learning_rate": 9.912380952380953e-06,
      "loss": 0.1749,
      "step": 26480
    },
    {
      "epoch": 7.5685714285714285,
      "grad_norm": 0.7652391791343689,
      "learning_rate": 9.90857142857143e-06,
      "loss": 0.1052,
      "step": 26490
    },
    {
      "epoch": 7.571428571428571,
      "grad_norm": 1.3763030767440796,
      "learning_rate": 9.904761904761906e-06,
      "loss": 0.0037,
      "step": 26500
    },
    {
      "epoch": 7.574285714285715,
      "grad_norm": 0.029538821429014206,
      "learning_rate": 9.900952380952383e-06,
      "loss": 0.213,
      "step": 26510
    },
    {
      "epoch": 7.577142857142857,
      "grad_norm": 0.0020850948058068752,
      "learning_rate": 9.897142857142858e-06,
      "loss": 0.0694,
      "step": 26520
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.8285963535308838,
      "learning_rate": 9.893333333333334e-06,
      "loss": 0.1976,
      "step": 26530
    },
    {
      "epoch": 7.582857142857143,
      "grad_norm": 0.11849319934844971,
      "learning_rate": 9.88952380952381e-06,
      "loss": 0.2439,
      "step": 26540
    },
    {
      "epoch": 7.585714285714285,
      "grad_norm": 91.40345001220703,
      "learning_rate": 9.885714285714287e-06,
      "loss": 0.2627,
      "step": 26550
    },
    {
      "epoch": 7.588571428571429,
      "grad_norm": 0.1296413689851761,
      "learning_rate": 9.881904761904762e-06,
      "loss": 0.1136,
      "step": 26560
    },
    {
      "epoch": 7.591428571428572,
      "grad_norm": 15.095017433166504,
      "learning_rate": 9.878095238095238e-06,
      "loss": 0.3383,
      "step": 26570
    },
    {
      "epoch": 7.594285714285714,
      "grad_norm": 0.13475550711154938,
      "learning_rate": 9.874285714285715e-06,
      "loss": 0.2561,
      "step": 26580
    },
    {
      "epoch": 7.597142857142857,
      "grad_norm": 2.112891674041748,
      "learning_rate": 9.870476190476191e-06,
      "loss": 0.2288,
      "step": 26590
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.1337042599916458,
      "learning_rate": 9.866666666666668e-06,
      "loss": 0.3583,
      "step": 26600
    },
    {
      "epoch": 7.602857142857143,
      "grad_norm": 0.08693636208772659,
      "learning_rate": 9.862857142857144e-06,
      "loss": 0.2425,
      "step": 26610
    },
    {
      "epoch": 7.605714285714286,
      "grad_norm": 12.84662914276123,
      "learning_rate": 9.859047619047621e-06,
      "loss": 0.5784,
      "step": 26620
    },
    {
      "epoch": 7.6085714285714285,
      "grad_norm": 0.04765889793634415,
      "learning_rate": 9.855238095238095e-06,
      "loss": 0.2137,
      "step": 26630
    },
    {
      "epoch": 7.611428571428571,
      "grad_norm": 6.404939651489258,
      "learning_rate": 9.851428571428572e-06,
      "loss": 0.1054,
      "step": 26640
    },
    {
      "epoch": 7.614285714285714,
      "grad_norm": 0.2694564461708069,
      "learning_rate": 9.847619047619048e-06,
      "loss": 0.0017,
      "step": 26650
    },
    {
      "epoch": 7.617142857142857,
      "grad_norm": 0.041346997022628784,
      "learning_rate": 9.843809523809525e-06,
      "loss": 0.4233,
      "step": 26660
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.41175028681755066,
      "learning_rate": 9.84e-06,
      "loss": 0.0029,
      "step": 26670
    },
    {
      "epoch": 7.622857142857143,
      "grad_norm": 0.06650751084089279,
      "learning_rate": 9.836190476190476e-06,
      "loss": 0.3017,
      "step": 26680
    },
    {
      "epoch": 7.6257142857142854,
      "grad_norm": 0.17476579546928406,
      "learning_rate": 9.832380952380954e-06,
      "loss": 0.1885,
      "step": 26690
    },
    {
      "epoch": 7.628571428571428,
      "grad_norm": 0.17680516839027405,
      "learning_rate": 9.828571428571429e-06,
      "loss": 0.3841,
      "step": 26700
    },
    {
      "epoch": 7.631428571428572,
      "grad_norm": 0.0735456794500351,
      "learning_rate": 9.824761904761906e-06,
      "loss": 0.2011,
      "step": 26710
    },
    {
      "epoch": 7.634285714285714,
      "grad_norm": 0.05146710202097893,
      "learning_rate": 9.820952380952382e-06,
      "loss": 0.4153,
      "step": 26720
    },
    {
      "epoch": 7.637142857142857,
      "grad_norm": 18.902502059936523,
      "learning_rate": 9.81714285714286e-06,
      "loss": 0.3741,
      "step": 26730
    },
    {
      "epoch": 7.64,
      "grad_norm": 16.31036376953125,
      "learning_rate": 9.813333333333333e-06,
      "loss": 0.561,
      "step": 26740
    },
    {
      "epoch": 7.642857142857143,
      "grad_norm": 21.45319175720215,
      "learning_rate": 9.80952380952381e-06,
      "loss": 0.0218,
      "step": 26750
    },
    {
      "epoch": 7.645714285714286,
      "grad_norm": 27.887451171875,
      "learning_rate": 9.805714285714286e-06,
      "loss": 0.198,
      "step": 26760
    },
    {
      "epoch": 7.648571428571429,
      "grad_norm": 0.042357366532087326,
      "learning_rate": 9.801904761904763e-06,
      "loss": 0.0306,
      "step": 26770
    },
    {
      "epoch": 7.651428571428571,
      "grad_norm": 0.3016521632671356,
      "learning_rate": 9.798095238095239e-06,
      "loss": 0.0072,
      "step": 26780
    },
    {
      "epoch": 7.654285714285714,
      "grad_norm": 0.029754361137747765,
      "learning_rate": 9.794285714285714e-06,
      "loss": 0.276,
      "step": 26790
    },
    {
      "epoch": 7.6571428571428575,
      "grad_norm": 0.028271233662962914,
      "learning_rate": 9.790476190476192e-06,
      "loss": 0.1913,
      "step": 26800
    },
    {
      "epoch": 7.66,
      "grad_norm": 13.306170463562012,
      "learning_rate": 9.786666666666667e-06,
      "loss": 0.2852,
      "step": 26810
    },
    {
      "epoch": 7.662857142857143,
      "grad_norm": 144.01846313476562,
      "learning_rate": 9.782857142857145e-06,
      "loss": 0.2869,
      "step": 26820
    },
    {
      "epoch": 7.6657142857142855,
      "grad_norm": 26.565494537353516,
      "learning_rate": 9.77904761904762e-06,
      "loss": 0.3495,
      "step": 26830
    },
    {
      "epoch": 7.668571428571429,
      "grad_norm": 0.038745712488889694,
      "learning_rate": 9.775238095238096e-06,
      "loss": 0.3621,
      "step": 26840
    },
    {
      "epoch": 7.671428571428572,
      "grad_norm": 0.06646964699029922,
      "learning_rate": 9.771428571428571e-06,
      "loss": 0.1553,
      "step": 26850
    },
    {
      "epoch": 7.674285714285714,
      "grad_norm": 0.12798991799354553,
      "learning_rate": 9.767619047619049e-06,
      "loss": 0.2117,
      "step": 26860
    },
    {
      "epoch": 7.677142857142857,
      "grad_norm": 13.859967231750488,
      "learning_rate": 9.763809523809524e-06,
      "loss": 0.8258,
      "step": 26870
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.5693835020065308,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.1173,
      "step": 26880
    },
    {
      "epoch": 7.682857142857143,
      "grad_norm": 0.03304802253842354,
      "learning_rate": 9.756190476190477e-06,
      "loss": 0.2084,
      "step": 26890
    },
    {
      "epoch": 7.685714285714286,
      "grad_norm": 0.04068686068058014,
      "learning_rate": 9.752380952380953e-06,
      "loss": 0.3787,
      "step": 26900
    },
    {
      "epoch": 7.688571428571429,
      "grad_norm": 14.682758331298828,
      "learning_rate": 9.74857142857143e-06,
      "loss": 0.3544,
      "step": 26910
    },
    {
      "epoch": 7.691428571428571,
      "grad_norm": 0.344952791929245,
      "learning_rate": 9.744761904761905e-06,
      "loss": 0.246,
      "step": 26920
    },
    {
      "epoch": 7.694285714285714,
      "grad_norm": 0.0397418737411499,
      "learning_rate": 9.740952380952383e-06,
      "loss": 0.1314,
      "step": 26930
    },
    {
      "epoch": 7.6971428571428575,
      "grad_norm": 0.0347527414560318,
      "learning_rate": 9.737142857142858e-06,
      "loss": 0.0032,
      "step": 26940
    },
    {
      "epoch": 7.7,
      "grad_norm": 0.15427479147911072,
      "learning_rate": 9.733333333333334e-06,
      "loss": 0.0053,
      "step": 26950
    },
    {
      "epoch": 7.702857142857143,
      "grad_norm": 0.5997119545936584,
      "learning_rate": 9.72952380952381e-06,
      "loss": 0.1266,
      "step": 26960
    },
    {
      "epoch": 7.7057142857142855,
      "grad_norm": 1.7815189361572266,
      "learning_rate": 9.725714285714287e-06,
      "loss": 0.0903,
      "step": 26970
    },
    {
      "epoch": 7.708571428571428,
      "grad_norm": 57.84895706176758,
      "learning_rate": 9.721904761904762e-06,
      "loss": 0.3519,
      "step": 26980
    },
    {
      "epoch": 7.711428571428572,
      "grad_norm": 0.13821382820606232,
      "learning_rate": 9.718095238095238e-06,
      "loss": 0.0684,
      "step": 26990
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 0.10187725722789764,
      "learning_rate": 9.714285714285715e-06,
      "loss": 0.2859,
      "step": 27000
    },
    {
      "epoch": 7.717142857142857,
      "grad_norm": 0.05924078822135925,
      "learning_rate": 9.71047619047619e-06,
      "loss": 0.2442,
      "step": 27010
    },
    {
      "epoch": 7.72,
      "grad_norm": 4.132547855377197,
      "learning_rate": 9.706666666666668e-06,
      "loss": 0.31,
      "step": 27020
    },
    {
      "epoch": 7.722857142857142,
      "grad_norm": 0.010448448359966278,
      "learning_rate": 9.702857142857144e-06,
      "loss": 0.2589,
      "step": 27030
    },
    {
      "epoch": 7.725714285714286,
      "grad_norm": 0.12776337563991547,
      "learning_rate": 9.699047619047621e-06,
      "loss": 0.1296,
      "step": 27040
    },
    {
      "epoch": 7.728571428571429,
      "grad_norm": 16.288930892944336,
      "learning_rate": 9.695238095238096e-06,
      "loss": 0.3309,
      "step": 27050
    },
    {
      "epoch": 7.731428571428571,
      "grad_norm": 0.1434914916753769,
      "learning_rate": 9.691428571428572e-06,
      "loss": 0.4005,
      "step": 27060
    },
    {
      "epoch": 7.734285714285714,
      "grad_norm": 0.07125362753868103,
      "learning_rate": 9.687619047619048e-06,
      "loss": 0.5222,
      "step": 27070
    },
    {
      "epoch": 7.737142857142857,
      "grad_norm": 12.580310821533203,
      "learning_rate": 9.683809523809525e-06,
      "loss": 0.2225,
      "step": 27080
    },
    {
      "epoch": 7.74,
      "grad_norm": 0.11150818318128586,
      "learning_rate": 9.68e-06,
      "loss": 0.204,
      "step": 27090
    },
    {
      "epoch": 7.742857142857143,
      "grad_norm": 0.3337278366088867,
      "learning_rate": 9.676190476190476e-06,
      "loss": 0.0073,
      "step": 27100
    },
    {
      "epoch": 7.7457142857142856,
      "grad_norm": 0.027335695922374725,
      "learning_rate": 9.672380952380953e-06,
      "loss": 0.1724,
      "step": 27110
    },
    {
      "epoch": 7.748571428571428,
      "grad_norm": 0.04113595187664032,
      "learning_rate": 9.668571428571429e-06,
      "loss": 0.4807,
      "step": 27120
    },
    {
      "epoch": 7.751428571428572,
      "grad_norm": 0.0595988966524601,
      "learning_rate": 9.664761904761906e-06,
      "loss": 0.0995,
      "step": 27130
    },
    {
      "epoch": 7.7542857142857144,
      "grad_norm": 2.512171506881714,
      "learning_rate": 9.660952380952382e-06,
      "loss": 0.1068,
      "step": 27140
    },
    {
      "epoch": 7.757142857142857,
      "grad_norm": 22.200435638427734,
      "learning_rate": 9.657142857142859e-06,
      "loss": 0.4115,
      "step": 27150
    },
    {
      "epoch": 7.76,
      "grad_norm": 13.015665054321289,
      "learning_rate": 9.653333333333335e-06,
      "loss": 0.3407,
      "step": 27160
    },
    {
      "epoch": 7.762857142857143,
      "grad_norm": 0.7721174955368042,
      "learning_rate": 9.64952380952381e-06,
      "loss": 0.3895,
      "step": 27170
    },
    {
      "epoch": 7.765714285714286,
      "grad_norm": 0.6617906093597412,
      "learning_rate": 9.645714285714286e-06,
      "loss": 0.4133,
      "step": 27180
    },
    {
      "epoch": 7.768571428571429,
      "grad_norm": 0.06726580858230591,
      "learning_rate": 9.641904761904763e-06,
      "loss": 0.2987,
      "step": 27190
    },
    {
      "epoch": 7.771428571428571,
      "grad_norm": 0.13413310050964355,
      "learning_rate": 9.638095238095239e-06,
      "loss": 0.3454,
      "step": 27200
    },
    {
      "epoch": 7.774285714285714,
      "grad_norm": 0.02555929310619831,
      "learning_rate": 9.634285714285714e-06,
      "loss": 0.0058,
      "step": 27210
    },
    {
      "epoch": 7.777142857142858,
      "grad_norm": 32.74741744995117,
      "learning_rate": 9.630476190476192e-06,
      "loss": 0.269,
      "step": 27220
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.05622921511530876,
      "learning_rate": 9.626666666666667e-06,
      "loss": 0.7909,
      "step": 27230
    },
    {
      "epoch": 7.782857142857143,
      "grad_norm": 0.17214064300060272,
      "learning_rate": 9.622857142857144e-06,
      "loss": 0.0058,
      "step": 27240
    },
    {
      "epoch": 7.785714285714286,
      "grad_norm": 14.124773979187012,
      "learning_rate": 9.61904761904762e-06,
      "loss": 0.2325,
      "step": 27250
    },
    {
      "epoch": 7.788571428571428,
      "grad_norm": 0.03523547574877739,
      "learning_rate": 9.615238095238096e-06,
      "loss": 0.128,
      "step": 27260
    },
    {
      "epoch": 7.791428571428572,
      "grad_norm": 0.06534162908792496,
      "learning_rate": 9.611428571428573e-06,
      "loss": 0.2252,
      "step": 27270
    },
    {
      "epoch": 7.7942857142857145,
      "grad_norm": 0.6639764904975891,
      "learning_rate": 9.607619047619048e-06,
      "loss": 0.7317,
      "step": 27280
    },
    {
      "epoch": 7.797142857142857,
      "grad_norm": 0.7813047170639038,
      "learning_rate": 9.603809523809524e-06,
      "loss": 0.0083,
      "step": 27290
    },
    {
      "epoch": 7.8,
      "grad_norm": 12.76591968536377,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.2377,
      "step": 27300
    },
    {
      "epoch": 7.8028571428571425,
      "grad_norm": 0.13274630904197693,
      "learning_rate": 9.596190476190477e-06,
      "loss": 0.0465,
      "step": 27310
    },
    {
      "epoch": 7.805714285714286,
      "grad_norm": 0.07042659819126129,
      "learning_rate": 9.592380952380952e-06,
      "loss": 0.0027,
      "step": 27320
    },
    {
      "epoch": 7.808571428571429,
      "grad_norm": 0.05627002194523811,
      "learning_rate": 9.58857142857143e-06,
      "loss": 0.4406,
      "step": 27330
    },
    {
      "epoch": 7.811428571428571,
      "grad_norm": 0.01750887557864189,
      "learning_rate": 9.584761904761905e-06,
      "loss": 0.194,
      "step": 27340
    },
    {
      "epoch": 7.814285714285714,
      "grad_norm": 16.717878341674805,
      "learning_rate": 9.580952380952383e-06,
      "loss": 0.3568,
      "step": 27350
    },
    {
      "epoch": 7.817142857142857,
      "grad_norm": 0.03526325151324272,
      "learning_rate": 9.577142857142858e-06,
      "loss": 0.1147,
      "step": 27360
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.014218474738299847,
      "learning_rate": 9.573333333333334e-06,
      "loss": 0.0954,
      "step": 27370
    },
    {
      "epoch": 7.822857142857143,
      "grad_norm": 0.02670416049659252,
      "learning_rate": 9.569523809523811e-06,
      "loss": 0.226,
      "step": 27380
    },
    {
      "epoch": 7.825714285714286,
      "grad_norm": 13.624800682067871,
      "learning_rate": 9.565714285714287e-06,
      "loss": 0.3246,
      "step": 27390
    },
    {
      "epoch": 7.828571428571428,
      "grad_norm": 0.2195153832435608,
      "learning_rate": 9.561904761904762e-06,
      "loss": 0.0034,
      "step": 27400
    },
    {
      "epoch": 7.831428571428571,
      "grad_norm": 0.1212087944149971,
      "learning_rate": 9.558095238095238e-06,
      "loss": 0.151,
      "step": 27410
    },
    {
      "epoch": 7.8342857142857145,
      "grad_norm": 2.358135461807251,
      "learning_rate": 9.554285714285715e-06,
      "loss": 0.0621,
      "step": 27420
    },
    {
      "epoch": 7.837142857142857,
      "grad_norm": 13.779717445373535,
      "learning_rate": 9.55047619047619e-06,
      "loss": 0.3286,
      "step": 27430
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.04805871844291687,
      "learning_rate": 9.546666666666668e-06,
      "loss": 0.231,
      "step": 27440
    },
    {
      "epoch": 7.8428571428571425,
      "grad_norm": 0.08542566746473312,
      "learning_rate": 9.542857142857143e-06,
      "loss": 0.0027,
      "step": 27450
    },
    {
      "epoch": 7.845714285714286,
      "grad_norm": 0.10714365541934967,
      "learning_rate": 9.53904761904762e-06,
      "loss": 0.0635,
      "step": 27460
    },
    {
      "epoch": 7.848571428571429,
      "grad_norm": 0.024987416341900826,
      "learning_rate": 9.535238095238096e-06,
      "loss": 0.31,
      "step": 27470
    },
    {
      "epoch": 7.851428571428571,
      "grad_norm": 0.19779261946678162,
      "learning_rate": 9.531428571428572e-06,
      "loss": 0.0827,
      "step": 27480
    },
    {
      "epoch": 7.854285714285714,
      "grad_norm": 0.039248742163181305,
      "learning_rate": 9.52761904761905e-06,
      "loss": 0.1383,
      "step": 27490
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.1889236569404602,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.378,
      "step": 27500
    },
    {
      "epoch": 7.86,
      "grad_norm": 0.016404282301664352,
      "learning_rate": 9.52e-06,
      "loss": 0.425,
      "step": 27510
    },
    {
      "epoch": 7.862857142857143,
      "grad_norm": 3.109483480453491,
      "learning_rate": 9.516190476190476e-06,
      "loss": 0.0054,
      "step": 27520
    },
    {
      "epoch": 7.865714285714286,
      "grad_norm": 0.1383475661277771,
      "learning_rate": 9.512380952380953e-06,
      "loss": 0.0026,
      "step": 27530
    },
    {
      "epoch": 7.868571428571428,
      "grad_norm": 0.09574176371097565,
      "learning_rate": 9.508571428571429e-06,
      "loss": 0.1058,
      "step": 27540
    },
    {
      "epoch": 7.871428571428572,
      "grad_norm": 0.00872414093464613,
      "learning_rate": 9.504761904761906e-06,
      "loss": 0.0009,
      "step": 27550
    },
    {
      "epoch": 7.8742857142857146,
      "grad_norm": 0.11611468344926834,
      "learning_rate": 9.500952380952382e-06,
      "loss": 0.2799,
      "step": 27560
    },
    {
      "epoch": 7.877142857142857,
      "grad_norm": 0.004501379560679197,
      "learning_rate": 9.497142857142859e-06,
      "loss": 0.2273,
      "step": 27570
    },
    {
      "epoch": 7.88,
      "grad_norm": 12.560418128967285,
      "learning_rate": 9.493333333333334e-06,
      "loss": 0.2165,
      "step": 27580
    },
    {
      "epoch": 7.882857142857143,
      "grad_norm": 0.0026892407331615686,
      "learning_rate": 9.48952380952381e-06,
      "loss": 0.0985,
      "step": 27590
    },
    {
      "epoch": 7.885714285714286,
      "grad_norm": 0.005203964654356241,
      "learning_rate": 9.485714285714287e-06,
      "loss": 0.0014,
      "step": 27600
    },
    {
      "epoch": 7.888571428571429,
      "grad_norm": 0.001976504223421216,
      "learning_rate": 9.481904761904763e-06,
      "loss": 0.4035,
      "step": 27610
    },
    {
      "epoch": 7.8914285714285715,
      "grad_norm": 0.08930343389511108,
      "learning_rate": 9.478095238095239e-06,
      "loss": 0.0607,
      "step": 27620
    },
    {
      "epoch": 7.894285714285714,
      "grad_norm": 0.6536901593208313,
      "learning_rate": 9.474285714285714e-06,
      "loss": 0.3698,
      "step": 27630
    },
    {
      "epoch": 7.897142857142857,
      "grad_norm": 0.5182299017906189,
      "learning_rate": 9.470476190476191e-06,
      "loss": 0.4765,
      "step": 27640
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.15952704846858978,
      "learning_rate": 9.466666666666667e-06,
      "loss": 0.0888,
      "step": 27650
    },
    {
      "epoch": 7.902857142857143,
      "grad_norm": 0.3652421534061432,
      "learning_rate": 9.462857142857144e-06,
      "loss": 0.1102,
      "step": 27660
    },
    {
      "epoch": 7.905714285714286,
      "grad_norm": 18.196895599365234,
      "learning_rate": 9.45904761904762e-06,
      "loss": 0.3643,
      "step": 27670
    },
    {
      "epoch": 7.908571428571428,
      "grad_norm": 24.692134857177734,
      "learning_rate": 9.455238095238095e-06,
      "loss": 0.2034,
      "step": 27680
    },
    {
      "epoch": 7.911428571428571,
      "grad_norm": 0.1481497436761856,
      "learning_rate": 9.451428571428573e-06,
      "loss": 0.2186,
      "step": 27690
    },
    {
      "epoch": 7.914285714285715,
      "grad_norm": 0.17520861327648163,
      "learning_rate": 9.447619047619048e-06,
      "loss": 0.0979,
      "step": 27700
    },
    {
      "epoch": 7.917142857142857,
      "grad_norm": 17.6734619140625,
      "learning_rate": 9.443809523809526e-06,
      "loss": 0.1278,
      "step": 27710
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.022063320502638817,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0011,
      "step": 27720
    },
    {
      "epoch": 7.922857142857143,
      "grad_norm": 13.604904174804688,
      "learning_rate": 9.436190476190477e-06,
      "loss": 0.2544,
      "step": 27730
    },
    {
      "epoch": 7.925714285714285,
      "grad_norm": 0.015456636436283588,
      "learning_rate": 9.432380952380952e-06,
      "loss": 0.2927,
      "step": 27740
    },
    {
      "epoch": 7.928571428571429,
      "grad_norm": 0.022794675081968307,
      "learning_rate": 9.42857142857143e-06,
      "loss": 0.168,
      "step": 27750
    },
    {
      "epoch": 7.9314285714285715,
      "grad_norm": 0.25841811299324036,
      "learning_rate": 9.424761904761905e-06,
      "loss": 0.0031,
      "step": 27760
    },
    {
      "epoch": 7.934285714285714,
      "grad_norm": 0.005371568724513054,
      "learning_rate": 9.420952380952382e-06,
      "loss": 0.0025,
      "step": 27770
    },
    {
      "epoch": 7.937142857142857,
      "grad_norm": 0.17200396955013275,
      "learning_rate": 9.417142857142858e-06,
      "loss": 0.0035,
      "step": 27780
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 0.02698463760316372,
      "learning_rate": 9.413333333333334e-06,
      "loss": 0.278,
      "step": 27790
    },
    {
      "epoch": 7.942857142857143,
      "grad_norm": 0.006541557610034943,
      "learning_rate": 9.40952380952381e-06,
      "loss": 0.0011,
      "step": 27800
    },
    {
      "epoch": 7.945714285714286,
      "grad_norm": 17.32125473022461,
      "learning_rate": 9.405714285714286e-06,
      "loss": 0.7933,
      "step": 27810
    },
    {
      "epoch": 7.948571428571428,
      "grad_norm": 0.09850092977285385,
      "learning_rate": 9.401904761904764e-06,
      "loss": 0.2496,
      "step": 27820
    },
    {
      "epoch": 7.951428571428571,
      "grad_norm": 14.514122009277344,
      "learning_rate": 9.398095238095238e-06,
      "loss": 0.173,
      "step": 27830
    },
    {
      "epoch": 7.954285714285715,
      "grad_norm": 0.09876339137554169,
      "learning_rate": 9.394285714285715e-06,
      "loss": 0.1237,
      "step": 27840
    },
    {
      "epoch": 7.957142857142857,
      "grad_norm": 0.15591572225093842,
      "learning_rate": 9.39047619047619e-06,
      "loss": 0.2027,
      "step": 27850
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.11952140927314758,
      "learning_rate": 9.386666666666668e-06,
      "loss": 0.2853,
      "step": 27860
    },
    {
      "epoch": 7.962857142857143,
      "grad_norm": 12.165616989135742,
      "learning_rate": 9.382857142857143e-06,
      "loss": 0.457,
      "step": 27870
    },
    {
      "epoch": 7.965714285714286,
      "grad_norm": 0.3195370137691498,
      "learning_rate": 9.37904761904762e-06,
      "loss": 0.3637,
      "step": 27880
    },
    {
      "epoch": 7.968571428571429,
      "grad_norm": 0.7206438183784485,
      "learning_rate": 9.375238095238096e-06,
      "loss": 0.2004,
      "step": 27890
    },
    {
      "epoch": 7.9714285714285715,
      "grad_norm": 12.513401985168457,
      "learning_rate": 9.371428571428572e-06,
      "loss": 0.2036,
      "step": 27900
    },
    {
      "epoch": 7.974285714285714,
      "grad_norm": 0.10661095380783081,
      "learning_rate": 9.367619047619049e-06,
      "loss": 0.5907,
      "step": 27910
    },
    {
      "epoch": 7.977142857142857,
      "grad_norm": 0.193911612033844,
      "learning_rate": 9.363809523809525e-06,
      "loss": 0.2401,
      "step": 27920
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.2159244567155838,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0032,
      "step": 27930
    },
    {
      "epoch": 7.982857142857143,
      "grad_norm": 0.03093109093606472,
      "learning_rate": 9.356190476190476e-06,
      "loss": 0.0026,
      "step": 27940
    },
    {
      "epoch": 7.985714285714286,
      "grad_norm": 0.01505738403648138,
      "learning_rate": 9.352380952380953e-06,
      "loss": 0.002,
      "step": 27950
    },
    {
      "epoch": 7.988571428571428,
      "grad_norm": 0.013678300194442272,
      "learning_rate": 9.348571428571429e-06,
      "loss": 0.5429,
      "step": 27960
    },
    {
      "epoch": 7.991428571428571,
      "grad_norm": 0.017983268946409225,
      "learning_rate": 9.344761904761906e-06,
      "loss": 0.1268,
      "step": 27970
    },
    {
      "epoch": 7.994285714285715,
      "grad_norm": 0.07517050951719284,
      "learning_rate": 9.340952380952381e-06,
      "loss": 0.331,
      "step": 27980
    },
    {
      "epoch": 7.997142857142857,
      "grad_norm": 0.33365610241889954,
      "learning_rate": 9.337142857142859e-06,
      "loss": 0.415,
      "step": 27990
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.14667803049087524,
      "learning_rate": 9.333333333333334e-06,
      "loss": 0.1085,
      "step": 28000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.949,
      "eval_f1": 0.777292576419214,
      "eval_loss": 0.2392750233411789,
      "eval_precision": 0.752112676056338,
      "eval_recall": 0.8042168674698795,
      "eval_runtime": 265.2548,
      "eval_samples_per_second": 11.31,
      "eval_steps_per_second": 2.827,
      "step": 28000
    },
    {
      "epoch": 8.002857142857144,
      "grad_norm": 0.08625124394893646,
      "learning_rate": 9.32952380952381e-06,
      "loss": 0.1244,
      "step": 28010
    },
    {
      "epoch": 8.005714285714285,
      "grad_norm": 0.0866667851805687,
      "learning_rate": 9.325714285714287e-06,
      "loss": 0.004,
      "step": 28020
    },
    {
      "epoch": 8.008571428571429,
      "grad_norm": 13.435812950134277,
      "learning_rate": 9.321904761904763e-06,
      "loss": 0.1354,
      "step": 28030
    },
    {
      "epoch": 8.01142857142857,
      "grad_norm": 82.84671020507812,
      "learning_rate": 9.318095238095238e-06,
      "loss": 0.2098,
      "step": 28040
    },
    {
      "epoch": 8.014285714285714,
      "grad_norm": 0.02659703977406025,
      "learning_rate": 9.314285714285714e-06,
      "loss": 0.5037,
      "step": 28050
    },
    {
      "epoch": 8.017142857142858,
      "grad_norm": 0.12401657551527023,
      "learning_rate": 9.310476190476191e-06,
      "loss": 0.4215,
      "step": 28060
    },
    {
      "epoch": 8.02,
      "grad_norm": 5.158255100250244,
      "learning_rate": 9.306666666666667e-06,
      "loss": 0.0032,
      "step": 28070
    },
    {
      "epoch": 8.022857142857143,
      "grad_norm": 0.04398435726761818,
      "learning_rate": 9.302857142857144e-06,
      "loss": 0.5664,
      "step": 28080
    },
    {
      "epoch": 8.025714285714285,
      "grad_norm": 0.04458533227443695,
      "learning_rate": 9.29904761904762e-06,
      "loss": 0.2003,
      "step": 28090
    },
    {
      "epoch": 8.028571428571428,
      "grad_norm": 0.02459755539894104,
      "learning_rate": 9.295238095238095e-06,
      "loss": 0.1598,
      "step": 28100
    },
    {
      "epoch": 8.031428571428572,
      "grad_norm": 0.18984170258045197,
      "learning_rate": 9.291428571428572e-06,
      "loss": 0.1643,
      "step": 28110
    },
    {
      "epoch": 8.034285714285714,
      "grad_norm": 0.1119929850101471,
      "learning_rate": 9.287619047619048e-06,
      "loss": 0.1267,
      "step": 28120
    },
    {
      "epoch": 8.037142857142857,
      "grad_norm": 0.1481178253889084,
      "learning_rate": 9.283809523809525e-06,
      "loss": 0.2428,
      "step": 28130
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.33100101351737976,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.233,
      "step": 28140
    },
    {
      "epoch": 8.042857142857143,
      "grad_norm": 0.22267422080039978,
      "learning_rate": 9.276190476190477e-06,
      "loss": 0.1079,
      "step": 28150
    },
    {
      "epoch": 8.045714285714286,
      "grad_norm": 13.254664421081543,
      "learning_rate": 9.272380952380952e-06,
      "loss": 0.2415,
      "step": 28160
    },
    {
      "epoch": 8.048571428571428,
      "grad_norm": 0.034509651362895966,
      "learning_rate": 9.26857142857143e-06,
      "loss": 0.2392,
      "step": 28170
    },
    {
      "epoch": 8.051428571428572,
      "grad_norm": 0.22767041623592377,
      "learning_rate": 9.264761904761905e-06,
      "loss": 0.0037,
      "step": 28180
    },
    {
      "epoch": 8.054285714285715,
      "grad_norm": 0.1362036019563675,
      "learning_rate": 9.260952380952382e-06,
      "loss": 0.0015,
      "step": 28190
    },
    {
      "epoch": 8.057142857142857,
      "grad_norm": 0.014481541700661182,
      "learning_rate": 9.257142857142858e-06,
      "loss": 0.002,
      "step": 28200
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.0910288617014885,
      "learning_rate": 9.253333333333333e-06,
      "loss": 0.0502,
      "step": 28210
    },
    {
      "epoch": 8.062857142857142,
      "grad_norm": 0.12711797654628754,
      "learning_rate": 9.24952380952381e-06,
      "loss": 0.198,
      "step": 28220
    },
    {
      "epoch": 8.065714285714286,
      "grad_norm": 12.335719108581543,
      "learning_rate": 9.245714285714286e-06,
      "loss": 0.3059,
      "step": 28230
    },
    {
      "epoch": 8.06857142857143,
      "grad_norm": 0.03686525300145149,
      "learning_rate": 9.241904761904764e-06,
      "loss": 0.0509,
      "step": 28240
    },
    {
      "epoch": 8.071428571428571,
      "grad_norm": 0.05315786600112915,
      "learning_rate": 9.238095238095239e-06,
      "loss": 0.1283,
      "step": 28250
    },
    {
      "epoch": 8.074285714285715,
      "grad_norm": 18.590862274169922,
      "learning_rate": 9.234285714285715e-06,
      "loss": 0.3566,
      "step": 28260
    },
    {
      "epoch": 8.077142857142857,
      "grad_norm": 0.04602684825658798,
      "learning_rate": 9.23047619047619e-06,
      "loss": 0.0025,
      "step": 28270
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.3036063015460968,
      "learning_rate": 9.226666666666668e-06,
      "loss": 0.1048,
      "step": 28280
    },
    {
      "epoch": 8.082857142857144,
      "grad_norm": 0.004342907108366489,
      "learning_rate": 9.222857142857143e-06,
      "loss": 0.1932,
      "step": 28290
    },
    {
      "epoch": 8.085714285714285,
      "grad_norm": 0.006515151355415583,
      "learning_rate": 9.21904761904762e-06,
      "loss": 0.0013,
      "step": 28300
    },
    {
      "epoch": 8.088571428571429,
      "grad_norm": 0.2017337530851364,
      "learning_rate": 9.215238095238096e-06,
      "loss": 0.1209,
      "step": 28310
    },
    {
      "epoch": 8.09142857142857,
      "grad_norm": 0.10327200591564178,
      "learning_rate": 9.211428571428572e-06,
      "loss": 0.1463,
      "step": 28320
    },
    {
      "epoch": 8.094285714285714,
      "grad_norm": 0.12088965624570847,
      "learning_rate": 9.207619047619049e-06,
      "loss": 0.0017,
      "step": 28330
    },
    {
      "epoch": 8.097142857142858,
      "grad_norm": 0.11053762584924698,
      "learning_rate": 9.203809523809524e-06,
      "loss": 0.128,
      "step": 28340
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.09168093651533127,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0987,
      "step": 28350
    },
    {
      "epoch": 8.102857142857143,
      "grad_norm": 0.003607329912483692,
      "learning_rate": 9.196190476190477e-06,
      "loss": 0.2782,
      "step": 28360
    },
    {
      "epoch": 8.105714285714285,
      "grad_norm": 0.030600719153881073,
      "learning_rate": 9.192380952380953e-06,
      "loss": 0.5624,
      "step": 28370
    },
    {
      "epoch": 8.108571428571429,
      "grad_norm": 15.685917854309082,
      "learning_rate": 9.188571428571428e-06,
      "loss": 0.3001,
      "step": 28380
    },
    {
      "epoch": 8.111428571428572,
      "grad_norm": 0.08516214042901993,
      "learning_rate": 9.184761904761906e-06,
      "loss": 0.1143,
      "step": 28390
    },
    {
      "epoch": 8.114285714285714,
      "grad_norm": 12.597285270690918,
      "learning_rate": 9.180952380952381e-06,
      "loss": 0.2916,
      "step": 28400
    },
    {
      "epoch": 8.117142857142857,
      "grad_norm": 0.055412657558918,
      "learning_rate": 9.177142857142859e-06,
      "loss": 0.2985,
      "step": 28410
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.12378327548503876,
      "learning_rate": 9.173333333333334e-06,
      "loss": 0.1218,
      "step": 28420
    },
    {
      "epoch": 8.122857142857143,
      "grad_norm": 0.04233124852180481,
      "learning_rate": 9.16952380952381e-06,
      "loss": 0.1128,
      "step": 28430
    },
    {
      "epoch": 8.125714285714286,
      "grad_norm": 0.004944519139826298,
      "learning_rate": 9.165714285714287e-06,
      "loss": 0.2014,
      "step": 28440
    },
    {
      "epoch": 8.128571428571428,
      "grad_norm": 0.009815552271902561,
      "learning_rate": 9.161904761904763e-06,
      "loss": 0.1918,
      "step": 28450
    },
    {
      "epoch": 8.131428571428572,
      "grad_norm": 0.0013953183079138398,
      "learning_rate": 9.15809523809524e-06,
      "loss": 0.089,
      "step": 28460
    },
    {
      "epoch": 8.134285714285713,
      "grad_norm": 0.002036263234913349,
      "learning_rate": 9.154285714285715e-06,
      "loss": 0.2028,
      "step": 28470
    },
    {
      "epoch": 8.137142857142857,
      "grad_norm": 0.0026249410584568977,
      "learning_rate": 9.150476190476191e-06,
      "loss": 0.1927,
      "step": 28480
    },
    {
      "epoch": 8.14,
      "grad_norm": 0.2294289469718933,
      "learning_rate": 9.146666666666667e-06,
      "loss": 0.0043,
      "step": 28490
    },
    {
      "epoch": 8.142857142857142,
      "grad_norm": 0.003403024049475789,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.0871,
      "step": 28500
    },
    {
      "epoch": 8.145714285714286,
      "grad_norm": 0.259954035282135,
      "learning_rate": 9.13904761904762e-06,
      "loss": 0.1754,
      "step": 28510
    },
    {
      "epoch": 8.14857142857143,
      "grad_norm": 0.0020462162792682648,
      "learning_rate": 9.135238095238095e-06,
      "loss": 0.0009,
      "step": 28520
    },
    {
      "epoch": 8.151428571428571,
      "grad_norm": 11.976519584655762,
      "learning_rate": 9.131428571428572e-06,
      "loss": 0.3859,
      "step": 28530
    },
    {
      "epoch": 8.154285714285715,
      "grad_norm": 0.005330550950020552,
      "learning_rate": 9.127619047619048e-06,
      "loss": 0.1127,
      "step": 28540
    },
    {
      "epoch": 8.157142857142857,
      "grad_norm": 0.13575561344623566,
      "learning_rate": 9.123809523809525e-06,
      "loss": 0.0019,
      "step": 28550
    },
    {
      "epoch": 8.16,
      "grad_norm": 17.22003746032715,
      "learning_rate": 9.12e-06,
      "loss": 0.458,
      "step": 28560
    },
    {
      "epoch": 8.162857142857144,
      "grad_norm": 0.03191302716732025,
      "learning_rate": 9.116190476190478e-06,
      "loss": 0.0786,
      "step": 28570
    },
    {
      "epoch": 8.165714285714285,
      "grad_norm": 0.6832585334777832,
      "learning_rate": 9.112380952380954e-06,
      "loss": 0.1813,
      "step": 28580
    },
    {
      "epoch": 8.168571428571429,
      "grad_norm": 0.0673048198223114,
      "learning_rate": 9.10857142857143e-06,
      "loss": 0.1784,
      "step": 28590
    },
    {
      "epoch": 8.17142857142857,
      "grad_norm": 0.012758709490299225,
      "learning_rate": 9.104761904761905e-06,
      "loss": 0.003,
      "step": 28600
    },
    {
      "epoch": 8.174285714285714,
      "grad_norm": 0.23360180854797363,
      "learning_rate": 9.100952380952382e-06,
      "loss": 0.2204,
      "step": 28610
    },
    {
      "epoch": 8.177142857142858,
      "grad_norm": 0.08928551524877548,
      "learning_rate": 9.097142857142858e-06,
      "loss": 0.1924,
      "step": 28620
    },
    {
      "epoch": 8.18,
      "grad_norm": 0.06660706549882889,
      "learning_rate": 9.093333333333333e-06,
      "loss": 0.1233,
      "step": 28630
    },
    {
      "epoch": 8.182857142857143,
      "grad_norm": 0.5230559706687927,
      "learning_rate": 9.08952380952381e-06,
      "loss": 0.1229,
      "step": 28640
    },
    {
      "epoch": 8.185714285714285,
      "grad_norm": 0.007961486466228962,
      "learning_rate": 9.085714285714286e-06,
      "loss": 0.0042,
      "step": 28650
    },
    {
      "epoch": 8.188571428571429,
      "grad_norm": 0.09038558602333069,
      "learning_rate": 9.081904761904763e-06,
      "loss": 0.2049,
      "step": 28660
    },
    {
      "epoch": 8.191428571428572,
      "grad_norm": 0.1511397659778595,
      "learning_rate": 9.078095238095239e-06,
      "loss": 0.185,
      "step": 28670
    },
    {
      "epoch": 8.194285714285714,
      "grad_norm": 0.08299191296100616,
      "learning_rate": 9.074285714285716e-06,
      "loss": 0.0759,
      "step": 28680
    },
    {
      "epoch": 8.197142857142858,
      "grad_norm": 0.10396569967269897,
      "learning_rate": 9.070476190476192e-06,
      "loss": 0.2522,
      "step": 28690
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.02231893129646778,
      "learning_rate": 9.066666666666667e-06,
      "loss": 0.0587,
      "step": 28700
    },
    {
      "epoch": 8.202857142857143,
      "grad_norm": 0.035084959119558334,
      "learning_rate": 9.062857142857143e-06,
      "loss": 0.2716,
      "step": 28710
    },
    {
      "epoch": 8.205714285714286,
      "grad_norm": 0.00590854324400425,
      "learning_rate": 9.05904761904762e-06,
      "loss": 0.401,
      "step": 28720
    },
    {
      "epoch": 8.208571428571428,
      "grad_norm": 0.09078971296548843,
      "learning_rate": 9.055238095238096e-06,
      "loss": 0.4088,
      "step": 28730
    },
    {
      "epoch": 8.211428571428572,
      "grad_norm": 0.33423006534576416,
      "learning_rate": 9.051428571428571e-06,
      "loss": 0.0025,
      "step": 28740
    },
    {
      "epoch": 8.214285714285714,
      "grad_norm": 0.12179502844810486,
      "learning_rate": 9.047619047619049e-06,
      "loss": 0.1112,
      "step": 28750
    },
    {
      "epoch": 8.217142857142857,
      "grad_norm": 0.011176574043929577,
      "learning_rate": 9.043809523809524e-06,
      "loss": 0.1338,
      "step": 28760
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.15123365819454193,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.1245,
      "step": 28770
    },
    {
      "epoch": 8.222857142857142,
      "grad_norm": 20.340837478637695,
      "learning_rate": 9.036190476190477e-06,
      "loss": 0.452,
      "step": 28780
    },
    {
      "epoch": 8.225714285714286,
      "grad_norm": 15.50705623626709,
      "learning_rate": 9.032380952380954e-06,
      "loss": 0.1887,
      "step": 28790
    },
    {
      "epoch": 8.228571428571428,
      "grad_norm": 2.562744617462158,
      "learning_rate": 9.028571428571428e-06,
      "loss": 0.0026,
      "step": 28800
    },
    {
      "epoch": 8.231428571428571,
      "grad_norm": 0.15461365878582,
      "learning_rate": 9.024761904761906e-06,
      "loss": 0.1238,
      "step": 28810
    },
    {
      "epoch": 8.234285714285715,
      "grad_norm": 20.750314712524414,
      "learning_rate": 9.020952380952381e-06,
      "loss": 0.1952,
      "step": 28820
    },
    {
      "epoch": 8.237142857142857,
      "grad_norm": 0.0664706900715828,
      "learning_rate": 9.017142857142858e-06,
      "loss": 0.2868,
      "step": 28830
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.04599248617887497,
      "learning_rate": 9.013333333333334e-06,
      "loss": 0.1002,
      "step": 28840
    },
    {
      "epoch": 8.242857142857142,
      "grad_norm": 46.351966857910156,
      "learning_rate": 9.00952380952381e-06,
      "loss": 0.0242,
      "step": 28850
    },
    {
      "epoch": 8.245714285714286,
      "grad_norm": 14.860319137573242,
      "learning_rate": 9.005714285714287e-06,
      "loss": 0.6359,
      "step": 28860
    },
    {
      "epoch": 8.248571428571429,
      "grad_norm": 0.05219494551420212,
      "learning_rate": 9.001904761904762e-06,
      "loss": 0.0024,
      "step": 28870
    },
    {
      "epoch": 8.251428571428571,
      "grad_norm": 0.10223639011383057,
      "learning_rate": 8.99809523809524e-06,
      "loss": 0.0034,
      "step": 28880
    },
    {
      "epoch": 8.254285714285714,
      "grad_norm": 0.11222724616527557,
      "learning_rate": 8.994285714285715e-06,
      "loss": 0.2458,
      "step": 28890
    },
    {
      "epoch": 8.257142857142856,
      "grad_norm": 0.10900554805994034,
      "learning_rate": 8.990476190476191e-06,
      "loss": 0.04,
      "step": 28900
    },
    {
      "epoch": 8.26,
      "grad_norm": 84.8949966430664,
      "learning_rate": 8.986666666666666e-06,
      "loss": 0.1507,
      "step": 28910
    },
    {
      "epoch": 8.262857142857143,
      "grad_norm": 0.08158019185066223,
      "learning_rate": 8.982857142857144e-06,
      "loss": 0.0033,
      "step": 28920
    },
    {
      "epoch": 8.265714285714285,
      "grad_norm": 18.424072265625,
      "learning_rate": 8.97904761904762e-06,
      "loss": 0.1697,
      "step": 28930
    },
    {
      "epoch": 8.268571428571429,
      "grad_norm": 0.009306325577199459,
      "learning_rate": 8.975238095238097e-06,
      "loss": 0.421,
      "step": 28940
    },
    {
      "epoch": 8.271428571428572,
      "grad_norm": 0.006549075711518526,
      "learning_rate": 8.971428571428572e-06,
      "loss": 0.1326,
      "step": 28950
    },
    {
      "epoch": 8.274285714285714,
      "grad_norm": 0.07663759589195251,
      "learning_rate": 8.967619047619048e-06,
      "loss": 0.075,
      "step": 28960
    },
    {
      "epoch": 8.277142857142858,
      "grad_norm": 0.0046456619165837765,
      "learning_rate": 8.963809523809525e-06,
      "loss": 0.213,
      "step": 28970
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.23887650668621063,
      "learning_rate": 8.96e-06,
      "loss": 0.2236,
      "step": 28980
    },
    {
      "epoch": 8.282857142857143,
      "grad_norm": 0.015175181441009045,
      "learning_rate": 8.956190476190478e-06,
      "loss": 0.0007,
      "step": 28990
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 0.2174217849969864,
      "learning_rate": 8.952380952380953e-06,
      "loss": 0.5611,
      "step": 29000
    },
    {
      "epoch": 8.288571428571428,
      "grad_norm": 2.5624608993530273,
      "learning_rate": 8.948571428571429e-06,
      "loss": 0.1906,
      "step": 29010
    },
    {
      "epoch": 8.291428571428572,
      "grad_norm": 0.1548454463481903,
      "learning_rate": 8.944761904761905e-06,
      "loss": 0.1229,
      "step": 29020
    },
    {
      "epoch": 8.294285714285714,
      "grad_norm": 0.1375008374452591,
      "learning_rate": 8.940952380952382e-06,
      "loss": 0.3845,
      "step": 29030
    },
    {
      "epoch": 8.297142857142857,
      "grad_norm": 0.026245061308145523,
      "learning_rate": 8.937142857142857e-06,
      "loss": 0.002,
      "step": 29040
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.04154660925269127,
      "learning_rate": 8.933333333333333e-06,
      "loss": 0.1872,
      "step": 29050
    },
    {
      "epoch": 8.302857142857142,
      "grad_norm": 0.03307681158185005,
      "learning_rate": 8.92952380952381e-06,
      "loss": 0.3579,
      "step": 29060
    },
    {
      "epoch": 8.305714285714286,
      "grad_norm": 0.13108782470226288,
      "learning_rate": 8.925714285714286e-06,
      "loss": 0.1014,
      "step": 29070
    },
    {
      "epoch": 8.308571428571428,
      "grad_norm": 0.0351429358124733,
      "learning_rate": 8.921904761904763e-06,
      "loss": 0.2322,
      "step": 29080
    },
    {
      "epoch": 8.311428571428571,
      "grad_norm": 0.33683088421821594,
      "learning_rate": 8.918095238095239e-06,
      "loss": 0.0838,
      "step": 29090
    },
    {
      "epoch": 8.314285714285715,
      "grad_norm": 0.014845368452370167,
      "learning_rate": 8.914285714285716e-06,
      "loss": 0.0681,
      "step": 29100
    },
    {
      "epoch": 8.317142857142857,
      "grad_norm": 0.015317030251026154,
      "learning_rate": 8.910476190476192e-06,
      "loss": 0.3354,
      "step": 29110
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.012447563000023365,
      "learning_rate": 8.906666666666667e-06,
      "loss": 0.0018,
      "step": 29120
    },
    {
      "epoch": 8.322857142857142,
      "grad_norm": 0.014621258713304996,
      "learning_rate": 8.902857142857143e-06,
      "loss": 0.3537,
      "step": 29130
    },
    {
      "epoch": 8.325714285714286,
      "grad_norm": 0.03358802944421768,
      "learning_rate": 8.89904761904762e-06,
      "loss": 0.1599,
      "step": 29140
    },
    {
      "epoch": 8.32857142857143,
      "grad_norm": 0.013257605023682117,
      "learning_rate": 8.895238095238096e-06,
      "loss": 0.1756,
      "step": 29150
    },
    {
      "epoch": 8.331428571428571,
      "grad_norm": 0.010023320093750954,
      "learning_rate": 8.891428571428571e-06,
      "loss": 0.0012,
      "step": 29160
    },
    {
      "epoch": 8.334285714285715,
      "grad_norm": 0.02132461778819561,
      "learning_rate": 8.887619047619049e-06,
      "loss": 0.0038,
      "step": 29170
    },
    {
      "epoch": 8.337142857142856,
      "grad_norm": 35.3440055847168,
      "learning_rate": 8.883809523809524e-06,
      "loss": 0.3627,
      "step": 29180
    },
    {
      "epoch": 8.34,
      "grad_norm": 0.666233479976654,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.004,
      "step": 29190
    },
    {
      "epoch": 8.342857142857143,
      "grad_norm": 54.839237213134766,
      "learning_rate": 8.876190476190477e-06,
      "loss": 0.1986,
      "step": 29200
    },
    {
      "epoch": 8.345714285714285,
      "grad_norm": 0.09221307933330536,
      "learning_rate": 8.872380952380954e-06,
      "loss": 0.0009,
      "step": 29210
    },
    {
      "epoch": 8.348571428571429,
      "grad_norm": 0.0873212069272995,
      "learning_rate": 8.86857142857143e-06,
      "loss": 0.0031,
      "step": 29220
    },
    {
      "epoch": 8.35142857142857,
      "grad_norm": 0.0900745838880539,
      "learning_rate": 8.864761904761905e-06,
      "loss": 0.3496,
      "step": 29230
    },
    {
      "epoch": 8.354285714285714,
      "grad_norm": 0.01567389816045761,
      "learning_rate": 8.860952380952381e-06,
      "loss": 0.0019,
      "step": 29240
    },
    {
      "epoch": 8.357142857142858,
      "grad_norm": 0.10941547900438309,
      "learning_rate": 8.857142857142858e-06,
      "loss": 0.0012,
      "step": 29250
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.08130999654531479,
      "learning_rate": 8.853333333333334e-06,
      "loss": 0.1118,
      "step": 29260
    },
    {
      "epoch": 8.362857142857143,
      "grad_norm": 0.07831607013940811,
      "learning_rate": 8.84952380952381e-06,
      "loss": 0.3082,
      "step": 29270
    },
    {
      "epoch": 8.365714285714287,
      "grad_norm": 0.02050638385117054,
      "learning_rate": 8.845714285714287e-06,
      "loss": 0.1156,
      "step": 29280
    },
    {
      "epoch": 8.368571428571428,
      "grad_norm": 0.03382381796836853,
      "learning_rate": 8.841904761904762e-06,
      "loss": 0.1159,
      "step": 29290
    },
    {
      "epoch": 8.371428571428572,
      "grad_norm": 0.10915057361125946,
      "learning_rate": 8.83809523809524e-06,
      "loss": 0.0037,
      "step": 29300
    },
    {
      "epoch": 8.374285714285714,
      "grad_norm": 0.1465369611978531,
      "learning_rate": 8.834285714285715e-06,
      "loss": 0.003,
      "step": 29310
    },
    {
      "epoch": 8.377142857142857,
      "grad_norm": 17.676973342895508,
      "learning_rate": 8.83047619047619e-06,
      "loss": 0.3458,
      "step": 29320
    },
    {
      "epoch": 8.38,
      "grad_norm": 0.04560502991080284,
      "learning_rate": 8.826666666666668e-06,
      "loss": 0.099,
      "step": 29330
    },
    {
      "epoch": 8.382857142857143,
      "grad_norm": 0.056862931698560715,
      "learning_rate": 8.822857142857144e-06,
      "loss": 0.0736,
      "step": 29340
    },
    {
      "epoch": 8.385714285714286,
      "grad_norm": 0.07714657485485077,
      "learning_rate": 8.819047619047619e-06,
      "loss": 0.1249,
      "step": 29350
    },
    {
      "epoch": 8.388571428571428,
      "grad_norm": 0.015202161855995655,
      "learning_rate": 8.815238095238096e-06,
      "loss": 0.2239,
      "step": 29360
    },
    {
      "epoch": 8.391428571428571,
      "grad_norm": 0.5697031021118164,
      "learning_rate": 8.811428571428572e-06,
      "loss": 0.4747,
      "step": 29370
    },
    {
      "epoch": 8.394285714285715,
      "grad_norm": 0.2670654058456421,
      "learning_rate": 8.807619047619048e-06,
      "loss": 0.3644,
      "step": 29380
    },
    {
      "epoch": 8.397142857142857,
      "grad_norm": 0.019849026575684547,
      "learning_rate": 8.803809523809525e-06,
      "loss": 0.0018,
      "step": 29390
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.009724359028041363,
      "learning_rate": 8.8e-06,
      "loss": 0.1136,
      "step": 29400
    },
    {
      "epoch": 8.402857142857142,
      "grad_norm": 0.37757134437561035,
      "learning_rate": 8.796190476190478e-06,
      "loss": 0.1904,
      "step": 29410
    },
    {
      "epoch": 8.405714285714286,
      "grad_norm": 0.00498303072527051,
      "learning_rate": 8.792380952380953e-06,
      "loss": 0.0027,
      "step": 29420
    },
    {
      "epoch": 8.40857142857143,
      "grad_norm": 0.1434018313884735,
      "learning_rate": 8.788571428571429e-06,
      "loss": 0.0859,
      "step": 29430
    },
    {
      "epoch": 8.411428571428571,
      "grad_norm": 0.006098400801420212,
      "learning_rate": 8.784761904761906e-06,
      "loss": 0.0008,
      "step": 29440
    },
    {
      "epoch": 8.414285714285715,
      "grad_norm": 0.006529787089675665,
      "learning_rate": 8.780952380952382e-06,
      "loss": 0.243,
      "step": 29450
    },
    {
      "epoch": 8.417142857142856,
      "grad_norm": 0.09922875463962555,
      "learning_rate": 8.777142857142857e-06,
      "loss": 0.0016,
      "step": 29460
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.09858930855989456,
      "learning_rate": 8.773333333333333e-06,
      "loss": 0.0017,
      "step": 29470
    },
    {
      "epoch": 8.422857142857143,
      "grad_norm": 0.004742272198200226,
      "learning_rate": 8.76952380952381e-06,
      "loss": 0.1339,
      "step": 29480
    },
    {
      "epoch": 8.425714285714285,
      "grad_norm": 0.11738890409469604,
      "learning_rate": 8.765714285714286e-06,
      "loss": 0.2256,
      "step": 29490
    },
    {
      "epoch": 8.428571428571429,
      "grad_norm": 0.0037721716798841953,
      "learning_rate": 8.761904761904763e-06,
      "loss": 0.0009,
      "step": 29500
    },
    {
      "epoch": 8.43142857142857,
      "grad_norm": 0.1594163179397583,
      "learning_rate": 8.758095238095239e-06,
      "loss": 0.5239,
      "step": 29510
    },
    {
      "epoch": 8.434285714285714,
      "grad_norm": 0.08926375210285187,
      "learning_rate": 8.754285714285716e-06,
      "loss": 0.1235,
      "step": 29520
    },
    {
      "epoch": 8.437142857142858,
      "grad_norm": 0.042187247425317764,
      "learning_rate": 8.750476190476191e-06,
      "loss": 0.0536,
      "step": 29530
    },
    {
      "epoch": 8.44,
      "grad_norm": 12.049874305725098,
      "learning_rate": 8.746666666666667e-06,
      "loss": 0.3347,
      "step": 29540
    },
    {
      "epoch": 8.442857142857143,
      "grad_norm": 0.013822115957736969,
      "learning_rate": 8.742857142857144e-06,
      "loss": 0.0012,
      "step": 29550
    },
    {
      "epoch": 8.445714285714285,
      "grad_norm": 0.021055961027741432,
      "learning_rate": 8.73904761904762e-06,
      "loss": 0.218,
      "step": 29560
    },
    {
      "epoch": 8.448571428571428,
      "grad_norm": 0.024399371817708015,
      "learning_rate": 8.735238095238096e-06,
      "loss": 0.0015,
      "step": 29570
    },
    {
      "epoch": 8.451428571428572,
      "grad_norm": 0.06324823945760727,
      "learning_rate": 8.731428571428571e-06,
      "loss": 0.0893,
      "step": 29580
    },
    {
      "epoch": 8.454285714285714,
      "grad_norm": 0.06860097497701645,
      "learning_rate": 8.727619047619048e-06,
      "loss": 0.1933,
      "step": 29590
    },
    {
      "epoch": 8.457142857142857,
      "grad_norm": 0.013729973696172237,
      "learning_rate": 8.723809523809524e-06,
      "loss": 0.237,
      "step": 29600
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.2251577079296112,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.1795,
      "step": 29610
    },
    {
      "epoch": 8.462857142857143,
      "grad_norm": 0.026448845863342285,
      "learning_rate": 8.716190476190477e-06,
      "loss": 0.2739,
      "step": 29620
    },
    {
      "epoch": 8.465714285714286,
      "grad_norm": 12.348956108093262,
      "learning_rate": 8.712380952380954e-06,
      "loss": 0.244,
      "step": 29630
    },
    {
      "epoch": 8.468571428571428,
      "grad_norm": 0.011433469131588936,
      "learning_rate": 8.70857142857143e-06,
      "loss": 0.0009,
      "step": 29640
    },
    {
      "epoch": 8.471428571428572,
      "grad_norm": 0.004791494458913803,
      "learning_rate": 8.704761904761905e-06,
      "loss": 0.0017,
      "step": 29650
    },
    {
      "epoch": 8.474285714285715,
      "grad_norm": 0.10847723484039307,
      "learning_rate": 8.700952380952383e-06,
      "loss": 0.0848,
      "step": 29660
    },
    {
      "epoch": 8.477142857142857,
      "grad_norm": 17.40183448791504,
      "learning_rate": 8.697142857142858e-06,
      "loss": 0.4644,
      "step": 29670
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.07176118344068527,
      "learning_rate": 8.693333333333334e-06,
      "loss": 0.1978,
      "step": 29680
    },
    {
      "epoch": 8.482857142857142,
      "grad_norm": 0.03418876230716705,
      "learning_rate": 8.68952380952381e-06,
      "loss": 0.1303,
      "step": 29690
    },
    {
      "epoch": 8.485714285714286,
      "grad_norm": 0.04124665632843971,
      "learning_rate": 8.685714285714287e-06,
      "loss": 0.2656,
      "step": 29700
    },
    {
      "epoch": 8.48857142857143,
      "grad_norm": 0.11368384212255478,
      "learning_rate": 8.681904761904762e-06,
      "loss": 0.0015,
      "step": 29710
    },
    {
      "epoch": 8.491428571428571,
      "grad_norm": 0.20821475982666016,
      "learning_rate": 8.67809523809524e-06,
      "loss": 0.0021,
      "step": 29720
    },
    {
      "epoch": 8.494285714285715,
      "grad_norm": 0.08411555737257004,
      "learning_rate": 8.674285714285715e-06,
      "loss": 0.0012,
      "step": 29730
    },
    {
      "epoch": 8.497142857142856,
      "grad_norm": 20.010700225830078,
      "learning_rate": 8.67047619047619e-06,
      "loss": 0.2764,
      "step": 29740
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.07378890365362167,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.3635,
      "step": 29750
    },
    {
      "epoch": 8.502857142857144,
      "grad_norm": 0.04203006625175476,
      "learning_rate": 8.662857142857143e-06,
      "loss": 0.1317,
      "step": 29760
    },
    {
      "epoch": 8.505714285714285,
      "grad_norm": 0.1041131466627121,
      "learning_rate": 8.65904761904762e-06,
      "loss": 0.0561,
      "step": 29770
    },
    {
      "epoch": 8.508571428571429,
      "grad_norm": 0.10356766730546951,
      "learning_rate": 8.655238095238096e-06,
      "loss": 0.3049,
      "step": 29780
    },
    {
      "epoch": 8.51142857142857,
      "grad_norm": 0.11538830399513245,
      "learning_rate": 8.651428571428572e-06,
      "loss": 0.228,
      "step": 29790
    },
    {
      "epoch": 8.514285714285714,
      "grad_norm": 0.09680100530385971,
      "learning_rate": 8.647619047619047e-06,
      "loss": 0.1351,
      "step": 29800
    },
    {
      "epoch": 8.517142857142858,
      "grad_norm": 0.05368710681796074,
      "learning_rate": 8.643809523809525e-06,
      "loss": 0.002,
      "step": 29810
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.05226965248584747,
      "learning_rate": 8.64e-06,
      "loss": 0.1256,
      "step": 29820
    },
    {
      "epoch": 8.522857142857143,
      "grad_norm": 0.027083754539489746,
      "learning_rate": 8.636190476190478e-06,
      "loss": 0.002,
      "step": 29830
    },
    {
      "epoch": 8.525714285714285,
      "grad_norm": 14.298828125,
      "learning_rate": 8.632380952380953e-06,
      "loss": 0.4097,
      "step": 29840
    },
    {
      "epoch": 8.528571428571428,
      "grad_norm": 0.013049748726189137,
      "learning_rate": 8.628571428571429e-06,
      "loss": 0.0474,
      "step": 29850
    },
    {
      "epoch": 8.531428571428572,
      "grad_norm": 0.02140411175787449,
      "learning_rate": 8.624761904761906e-06,
      "loss": 0.1326,
      "step": 29860
    },
    {
      "epoch": 8.534285714285714,
      "grad_norm": 0.009769517928361893,
      "learning_rate": 8.620952380952382e-06,
      "loss": 0.0012,
      "step": 29870
    },
    {
      "epoch": 8.537142857142857,
      "grad_norm": 0.011625716462731361,
      "learning_rate": 8.617142857142859e-06,
      "loss": 0.2957,
      "step": 29880
    },
    {
      "epoch": 8.54,
      "grad_norm": 0.13040779531002045,
      "learning_rate": 8.613333333333333e-06,
      "loss": 0.1454,
      "step": 29890
    },
    {
      "epoch": 8.542857142857143,
      "grad_norm": 0.1803007423877716,
      "learning_rate": 8.60952380952381e-06,
      "loss": 0.2222,
      "step": 29900
    },
    {
      "epoch": 8.545714285714286,
      "grad_norm": 0.03569747507572174,
      "learning_rate": 8.605714285714286e-06,
      "loss": 0.1699,
      "step": 29910
    },
    {
      "epoch": 8.548571428571428,
      "grad_norm": 0.028614861890673637,
      "learning_rate": 8.601904761904763e-06,
      "loss": 0.0033,
      "step": 29920
    },
    {
      "epoch": 8.551428571428572,
      "grad_norm": 0.03766323998570442,
      "learning_rate": 8.598095238095238e-06,
      "loss": 0.1574,
      "step": 29930
    },
    {
      "epoch": 8.554285714285715,
      "grad_norm": 0.04151574894785881,
      "learning_rate": 8.594285714285716e-06,
      "loss": 0.0009,
      "step": 29940
    },
    {
      "epoch": 8.557142857142857,
      "grad_norm": 0.00810975767672062,
      "learning_rate": 8.590476190476191e-06,
      "loss": 0.4302,
      "step": 29950
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.01536947675049305,
      "learning_rate": 8.586666666666667e-06,
      "loss": 0.0028,
      "step": 29960
    },
    {
      "epoch": 8.562857142857142,
      "grad_norm": 0.05364156886935234,
      "learning_rate": 8.582857142857144e-06,
      "loss": 0.2907,
      "step": 29970
    },
    {
      "epoch": 8.565714285714286,
      "grad_norm": 0.12256159633398056,
      "learning_rate": 8.57904761904762e-06,
      "loss": 0.1054,
      "step": 29980
    },
    {
      "epoch": 8.56857142857143,
      "grad_norm": 0.11397599428892136,
      "learning_rate": 8.575238095238097e-06,
      "loss": 0.1246,
      "step": 29990
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.0057211341336369514,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.4061,
      "step": 30000
    },
    {
      "epoch": 8.574285714285715,
      "grad_norm": 0.04091833904385567,
      "learning_rate": 8.567619047619048e-06,
      "loss": 0.3112,
      "step": 30010
    },
    {
      "epoch": 8.577142857142857,
      "grad_norm": 0.21380533277988434,
      "learning_rate": 8.563809523809524e-06,
      "loss": 0.0024,
      "step": 30020
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.11696548759937286,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.1246,
      "step": 30030
    },
    {
      "epoch": 8.582857142857144,
      "grad_norm": 0.019334636628627777,
      "learning_rate": 8.556190476190477e-06,
      "loss": 0.23,
      "step": 30040
    },
    {
      "epoch": 8.585714285714285,
      "grad_norm": 0.07326016575098038,
      "learning_rate": 8.552380952380954e-06,
      "loss": 0.0014,
      "step": 30050
    },
    {
      "epoch": 8.588571428571429,
      "grad_norm": 13.296998023986816,
      "learning_rate": 8.54857142857143e-06,
      "loss": 0.2453,
      "step": 30060
    },
    {
      "epoch": 8.59142857142857,
      "grad_norm": 0.2489088922739029,
      "learning_rate": 8.544761904761905e-06,
      "loss": 0.0021,
      "step": 30070
    },
    {
      "epoch": 8.594285714285714,
      "grad_norm": 0.120298832654953,
      "learning_rate": 8.540952380952382e-06,
      "loss": 0.0011,
      "step": 30080
    },
    {
      "epoch": 8.597142857142858,
      "grad_norm": 0.011738771572709084,
      "learning_rate": 8.537142857142858e-06,
      "loss": 0.2809,
      "step": 30090
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.13769689202308655,
      "learning_rate": 8.533333333333335e-06,
      "loss": 0.1079,
      "step": 30100
    },
    {
      "epoch": 8.602857142857143,
      "grad_norm": 0.010737407021224499,
      "learning_rate": 8.529523809523809e-06,
      "loss": 0.0028,
      "step": 30110
    },
    {
      "epoch": 8.605714285714285,
      "grad_norm": 0.007054959423840046,
      "learning_rate": 8.525714285714286e-06,
      "loss": 0.3756,
      "step": 30120
    },
    {
      "epoch": 8.608571428571429,
      "grad_norm": 0.12112798541784286,
      "learning_rate": 8.521904761904762e-06,
      "loss": 0.1555,
      "step": 30130
    },
    {
      "epoch": 8.611428571428572,
      "grad_norm": 0.0949978232383728,
      "learning_rate": 8.51809523809524e-06,
      "loss": 0.0078,
      "step": 30140
    },
    {
      "epoch": 8.614285714285714,
      "grad_norm": 0.05465357378125191,
      "learning_rate": 8.514285714285715e-06,
      "loss": 0.4334,
      "step": 30150
    },
    {
      "epoch": 8.617142857142857,
      "grad_norm": 0.12208280712366104,
      "learning_rate": 8.51047619047619e-06,
      "loss": 0.002,
      "step": 30160
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.019519556313753128,
      "learning_rate": 8.506666666666668e-06,
      "loss": 0.2,
      "step": 30170
    },
    {
      "epoch": 8.622857142857143,
      "grad_norm": 0.019643321633338928,
      "learning_rate": 8.502857142857143e-06,
      "loss": 0.0674,
      "step": 30180
    },
    {
      "epoch": 8.625714285714286,
      "grad_norm": 0.03473832830786705,
      "learning_rate": 8.49904761904762e-06,
      "loss": 0.1198,
      "step": 30190
    },
    {
      "epoch": 8.628571428571428,
      "grad_norm": 0.08451945334672928,
      "learning_rate": 8.495238095238096e-06,
      "loss": 0.0021,
      "step": 30200
    },
    {
      "epoch": 8.631428571428572,
      "grad_norm": 0.12057512998580933,
      "learning_rate": 8.491428571428572e-06,
      "loss": 0.1975,
      "step": 30210
    },
    {
      "epoch": 8.634285714285713,
      "grad_norm": 0.03491140902042389,
      "learning_rate": 8.487619047619047e-06,
      "loss": 0.3021,
      "step": 30220
    },
    {
      "epoch": 8.637142857142857,
      "grad_norm": 17.60742950439453,
      "learning_rate": 8.483809523809525e-06,
      "loss": 0.3342,
      "step": 30230
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.09273219853639603,
      "learning_rate": 8.48e-06,
      "loss": 0.1623,
      "step": 30240
    },
    {
      "epoch": 8.642857142857142,
      "grad_norm": 0.19278764724731445,
      "learning_rate": 8.476190476190477e-06,
      "loss": 0.5308,
      "step": 30250
    },
    {
      "epoch": 8.645714285714286,
      "grad_norm": 0.26026326417922974,
      "learning_rate": 8.472380952380953e-06,
      "loss": 0.002,
      "step": 30260
    },
    {
      "epoch": 8.64857142857143,
      "grad_norm": 0.09863390028476715,
      "learning_rate": 8.468571428571429e-06,
      "loss": 0.1057,
      "step": 30270
    },
    {
      "epoch": 8.651428571428571,
      "grad_norm": 0.04304182529449463,
      "learning_rate": 8.464761904761906e-06,
      "loss": 0.1234,
      "step": 30280
    },
    {
      "epoch": 8.654285714285715,
      "grad_norm": 0.0026209026109427214,
      "learning_rate": 8.460952380952381e-06,
      "loss": 0.3154,
      "step": 30290
    },
    {
      "epoch": 8.657142857142857,
      "grad_norm": 0.09672710299491882,
      "learning_rate": 8.457142857142859e-06,
      "loss": 0.0673,
      "step": 30300
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.17863287031650543,
      "learning_rate": 8.453333333333334e-06,
      "loss": 0.0016,
      "step": 30310
    },
    {
      "epoch": 8.662857142857142,
      "grad_norm": 0.023487921804189682,
      "learning_rate": 8.44952380952381e-06,
      "loss": 0.1775,
      "step": 30320
    },
    {
      "epoch": 8.665714285714285,
      "grad_norm": 0.06304894387722015,
      "learning_rate": 8.445714285714285e-06,
      "loss": 0.1167,
      "step": 30330
    },
    {
      "epoch": 8.668571428571429,
      "grad_norm": 0.003755414392799139,
      "learning_rate": 8.441904761904763e-06,
      "loss": 0.2348,
      "step": 30340
    },
    {
      "epoch": 8.67142857142857,
      "grad_norm": 21.3110294342041,
      "learning_rate": 8.438095238095238e-06,
      "loss": 0.0955,
      "step": 30350
    },
    {
      "epoch": 8.674285714285714,
      "grad_norm": 0.04739386588335037,
      "learning_rate": 8.434285714285716e-06,
      "loss": 0.0028,
      "step": 30360
    },
    {
      "epoch": 8.677142857142858,
      "grad_norm": 0.02358626015484333,
      "learning_rate": 8.430476190476191e-06,
      "loss": 0.0008,
      "step": 30370
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.014202168211340904,
      "learning_rate": 8.426666666666667e-06,
      "loss": 0.0804,
      "step": 30380
    },
    {
      "epoch": 8.682857142857143,
      "grad_norm": 0.004617336671799421,
      "learning_rate": 8.422857142857144e-06,
      "loss": 0.2633,
      "step": 30390
    },
    {
      "epoch": 8.685714285714285,
      "grad_norm": 0.0013714457163587213,
      "learning_rate": 8.41904761904762e-06,
      "loss": 0.0014,
      "step": 30400
    },
    {
      "epoch": 8.688571428571429,
      "grad_norm": 0.13745026290416718,
      "learning_rate": 8.415238095238097e-06,
      "loss": 0.1305,
      "step": 30410
    },
    {
      "epoch": 8.691428571428572,
      "grad_norm": 0.21290495991706848,
      "learning_rate": 8.411428571428572e-06,
      "loss": 0.0014,
      "step": 30420
    },
    {
      "epoch": 8.694285714285714,
      "grad_norm": 0.01664300635457039,
      "learning_rate": 8.407619047619048e-06,
      "loss": 0.1193,
      "step": 30430
    },
    {
      "epoch": 8.697142857142858,
      "grad_norm": 0.015990784391760826,
      "learning_rate": 8.403809523809524e-06,
      "loss": 0.0009,
      "step": 30440
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.029389528557658195,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.1808,
      "step": 30450
    },
    {
      "epoch": 8.702857142857143,
      "grad_norm": 0.0821651890873909,
      "learning_rate": 8.396190476190476e-06,
      "loss": 0.1154,
      "step": 30460
    },
    {
      "epoch": 8.705714285714286,
      "grad_norm": 0.011239568702876568,
      "learning_rate": 8.392380952380954e-06,
      "loss": 0.0009,
      "step": 30470
    },
    {
      "epoch": 8.708571428571428,
      "grad_norm": 0.016051989048719406,
      "learning_rate": 8.38857142857143e-06,
      "loss": 0.314,
      "step": 30480
    },
    {
      "epoch": 8.711428571428572,
      "grad_norm": 0.14055891335010529,
      "learning_rate": 8.384761904761905e-06,
      "loss": 0.3175,
      "step": 30490
    },
    {
      "epoch": 8.714285714285714,
      "grad_norm": 0.06186038255691528,
      "learning_rate": 8.380952380952382e-06,
      "loss": 0.0018,
      "step": 30500
    },
    {
      "epoch": 8.717142857142857,
      "grad_norm": 0.15005849301815033,
      "learning_rate": 8.377142857142858e-06,
      "loss": 0.1646,
      "step": 30510
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.04732652008533478,
      "learning_rate": 8.373333333333335e-06,
      "loss": 0.1522,
      "step": 30520
    },
    {
      "epoch": 8.722857142857142,
      "grad_norm": 0.04781857505440712,
      "learning_rate": 8.36952380952381e-06,
      "loss": 0.3614,
      "step": 30530
    },
    {
      "epoch": 8.725714285714286,
      "grad_norm": 0.09316486865282059,
      "learning_rate": 8.365714285714286e-06,
      "loss": 0.3903,
      "step": 30540
    },
    {
      "epoch": 8.728571428571428,
      "grad_norm": 20.489221572875977,
      "learning_rate": 8.361904761904762e-06,
      "loss": 0.0667,
      "step": 30550
    },
    {
      "epoch": 8.731428571428571,
      "grad_norm": 0.14422278106212616,
      "learning_rate": 8.358095238095239e-06,
      "loss": 0.3346,
      "step": 30560
    },
    {
      "epoch": 8.734285714285715,
      "grad_norm": 0.08406899869441986,
      "learning_rate": 8.354285714285715e-06,
      "loss": 0.0039,
      "step": 30570
    },
    {
      "epoch": 8.737142857142857,
      "grad_norm": 0.002257479587569833,
      "learning_rate": 8.35047619047619e-06,
      "loss": 0.003,
      "step": 30580
    },
    {
      "epoch": 8.74,
      "grad_norm": 0.181207537651062,
      "learning_rate": 8.346666666666668e-06,
      "loss": 0.2281,
      "step": 30590
    },
    {
      "epoch": 8.742857142857144,
      "grad_norm": 0.14808158576488495,
      "learning_rate": 8.342857142857143e-06,
      "loss": 0.1813,
      "step": 30600
    },
    {
      "epoch": 8.745714285714286,
      "grad_norm": 0.006912716198712587,
      "learning_rate": 8.33904761904762e-06,
      "loss": 0.37,
      "step": 30610
    },
    {
      "epoch": 8.748571428571429,
      "grad_norm": 0.06453870981931686,
      "learning_rate": 8.335238095238096e-06,
      "loss": 0.2427,
      "step": 30620
    },
    {
      "epoch": 8.751428571428571,
      "grad_norm": 0.011315134353935719,
      "learning_rate": 8.331428571428573e-06,
      "loss": 0.0712,
      "step": 30630
    },
    {
      "epoch": 8.754285714285714,
      "grad_norm": 12.188074111938477,
      "learning_rate": 8.327619047619049e-06,
      "loss": 0.2575,
      "step": 30640
    },
    {
      "epoch": 8.757142857142856,
      "grad_norm": 0.21560244262218475,
      "learning_rate": 8.323809523809524e-06,
      "loss": 0.0015,
      "step": 30650
    },
    {
      "epoch": 8.76,
      "grad_norm": 36.26676940917969,
      "learning_rate": 8.32e-06,
      "loss": 0.0312,
      "step": 30660
    },
    {
      "epoch": 8.762857142857143,
      "grad_norm": 0.05145890265703201,
      "learning_rate": 8.316190476190477e-06,
      "loss": 0.1302,
      "step": 30670
    },
    {
      "epoch": 8.765714285714285,
      "grad_norm": 0.06812422722578049,
      "learning_rate": 8.312380952380953e-06,
      "loss": 0.2285,
      "step": 30680
    },
    {
      "epoch": 8.768571428571429,
      "grad_norm": 0.0639835000038147,
      "learning_rate": 8.308571428571428e-06,
      "loss": 0.1748,
      "step": 30690
    },
    {
      "epoch": 8.771428571428572,
      "grad_norm": 0.3028867840766907,
      "learning_rate": 8.304761904761906e-06,
      "loss": 0.0025,
      "step": 30700
    },
    {
      "epoch": 8.774285714285714,
      "grad_norm": 16.02014923095703,
      "learning_rate": 8.300952380952381e-06,
      "loss": 0.3138,
      "step": 30710
    },
    {
      "epoch": 8.777142857142858,
      "grad_norm": 0.09554225951433182,
      "learning_rate": 8.297142857142859e-06,
      "loss": 0.2574,
      "step": 30720
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.09361525624990463,
      "learning_rate": 8.293333333333334e-06,
      "loss": 0.0984,
      "step": 30730
    },
    {
      "epoch": 8.782857142857143,
      "grad_norm": 0.012232635170221329,
      "learning_rate": 8.289523809523811e-06,
      "loss": 0.0193,
      "step": 30740
    },
    {
      "epoch": 8.785714285714286,
      "grad_norm": 16.770767211914062,
      "learning_rate": 8.285714285714287e-06,
      "loss": 0.3078,
      "step": 30750
    },
    {
      "epoch": 8.788571428571428,
      "grad_norm": 0.0725514143705368,
      "learning_rate": 8.281904761904763e-06,
      "loss": 0.2955,
      "step": 30760
    },
    {
      "epoch": 8.791428571428572,
      "grad_norm": 0.0558072105050087,
      "learning_rate": 8.278095238095238e-06,
      "loss": 0.1549,
      "step": 30770
    },
    {
      "epoch": 8.794285714285714,
      "grad_norm": 0.29978737235069275,
      "learning_rate": 8.274285714285715e-06,
      "loss": 0.1177,
      "step": 30780
    },
    {
      "epoch": 8.797142857142857,
      "grad_norm": 0.06787700206041336,
      "learning_rate": 8.270476190476191e-06,
      "loss": 0.1579,
      "step": 30790
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.046991489827632904,
      "learning_rate": 8.266666666666667e-06,
      "loss": 0.0018,
      "step": 30800
    },
    {
      "epoch": 8.802857142857142,
      "grad_norm": 0.07177260518074036,
      "learning_rate": 8.262857142857144e-06,
      "loss": 0.2838,
      "step": 30810
    },
    {
      "epoch": 8.805714285714286,
      "grad_norm": 0.04387153685092926,
      "learning_rate": 8.25904761904762e-06,
      "loss": 0.1592,
      "step": 30820
    },
    {
      "epoch": 8.808571428571428,
      "grad_norm": 0.061470672488212585,
      "learning_rate": 8.255238095238097e-06,
      "loss": 0.202,
      "step": 30830
    },
    {
      "epoch": 8.811428571428571,
      "grad_norm": 0.06550656259059906,
      "learning_rate": 8.251428571428572e-06,
      "loss": 0.0017,
      "step": 30840
    },
    {
      "epoch": 8.814285714285715,
      "grad_norm": 0.03532007336616516,
      "learning_rate": 8.24761904761905e-06,
      "loss": 0.0015,
      "step": 30850
    },
    {
      "epoch": 8.817142857142857,
      "grad_norm": 0.016506733372807503,
      "learning_rate": 8.243809523809525e-06,
      "loss": 0.1092,
      "step": 30860
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.08355441689491272,
      "learning_rate": 8.24e-06,
      "loss": 0.2461,
      "step": 30870
    },
    {
      "epoch": 8.822857142857142,
      "grad_norm": 0.01812056265771389,
      "learning_rate": 8.236190476190476e-06,
      "loss": 0.018,
      "step": 30880
    },
    {
      "epoch": 8.825714285714286,
      "grad_norm": 0.04651353880763054,
      "learning_rate": 8.232380952380954e-06,
      "loss": 0.0013,
      "step": 30890
    },
    {
      "epoch": 8.82857142857143,
      "grad_norm": 0.07959898561239243,
      "learning_rate": 8.22857142857143e-06,
      "loss": 0.3308,
      "step": 30900
    },
    {
      "epoch": 8.831428571428571,
      "grad_norm": 0.029659979045391083,
      "learning_rate": 8.224761904761905e-06,
      "loss": 0.0012,
      "step": 30910
    },
    {
      "epoch": 8.834285714285715,
      "grad_norm": 0.16330085694789886,
      "learning_rate": 8.220952380952382e-06,
      "loss": 0.1937,
      "step": 30920
    },
    {
      "epoch": 8.837142857142858,
      "grad_norm": 13.122089385986328,
      "learning_rate": 8.217142857142858e-06,
      "loss": 0.1616,
      "step": 30930
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.05461539328098297,
      "learning_rate": 8.213333333333335e-06,
      "loss": 0.1269,
      "step": 30940
    },
    {
      "epoch": 8.842857142857143,
      "grad_norm": 0.013513494282960892,
      "learning_rate": 8.20952380952381e-06,
      "loss": 0.0009,
      "step": 30950
    },
    {
      "epoch": 8.845714285714285,
      "grad_norm": 0.029092269018292427,
      "learning_rate": 8.205714285714286e-06,
      "loss": 0.1335,
      "step": 30960
    },
    {
      "epoch": 8.848571428571429,
      "grad_norm": 0.023542791604995728,
      "learning_rate": 8.201904761904762e-06,
      "loss": 0.001,
      "step": 30970
    },
    {
      "epoch": 8.85142857142857,
      "grad_norm": 0.026360221207141876,
      "learning_rate": 8.198095238095239e-06,
      "loss": 0.1874,
      "step": 30980
    },
    {
      "epoch": 8.854285714285714,
      "grad_norm": 0.005613808054476976,
      "learning_rate": 8.194285714285714e-06,
      "loss": 0.2561,
      "step": 30990
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.054834671318531036,
      "learning_rate": 8.190476190476192e-06,
      "loss": 0.2529,
      "step": 31000
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.01640145666897297,
      "learning_rate": 8.186666666666667e-06,
      "loss": 0.1629,
      "step": 31010
    },
    {
      "epoch": 8.862857142857143,
      "grad_norm": 30.391918182373047,
      "learning_rate": 8.182857142857143e-06,
      "loss": 0.4363,
      "step": 31020
    },
    {
      "epoch": 8.865714285714287,
      "grad_norm": 0.02346831187605858,
      "learning_rate": 8.17904761904762e-06,
      "loss": 0.1892,
      "step": 31030
    },
    {
      "epoch": 8.868571428571428,
      "grad_norm": 0.05657518655061722,
      "learning_rate": 8.175238095238096e-06,
      "loss": 0.0306,
      "step": 31040
    },
    {
      "epoch": 8.871428571428572,
      "grad_norm": 0.03414100781083107,
      "learning_rate": 8.171428571428573e-06,
      "loss": 0.3162,
      "step": 31050
    },
    {
      "epoch": 8.874285714285714,
      "grad_norm": 0.02452344261109829,
      "learning_rate": 8.167619047619049e-06,
      "loss": 0.0009,
      "step": 31060
    },
    {
      "epoch": 8.877142857142857,
      "grad_norm": 0.021365610882639885,
      "learning_rate": 8.163809523809524e-06,
      "loss": 0.1754,
      "step": 31070
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.5390508770942688,
      "learning_rate": 8.16e-06,
      "loss": 0.1903,
      "step": 31080
    },
    {
      "epoch": 8.882857142857143,
      "grad_norm": 0.02167205698788166,
      "learning_rate": 8.156190476190477e-06,
      "loss": 0.2205,
      "step": 31090
    },
    {
      "epoch": 8.885714285714286,
      "grad_norm": 0.10814210772514343,
      "learning_rate": 8.152380952380953e-06,
      "loss": 0.0016,
      "step": 31100
    },
    {
      "epoch": 8.888571428571428,
      "grad_norm": 0.022098934277892113,
      "learning_rate": 8.148571428571428e-06,
      "loss": 0.002,
      "step": 31110
    },
    {
      "epoch": 8.891428571428571,
      "grad_norm": 0.02500169165432453,
      "learning_rate": 8.144761904761906e-06,
      "loss": 0.1273,
      "step": 31120
    },
    {
      "epoch": 8.894285714285715,
      "grad_norm": 0.13935959339141846,
      "learning_rate": 8.140952380952381e-06,
      "loss": 0.0021,
      "step": 31130
    },
    {
      "epoch": 8.897142857142857,
      "grad_norm": 12.949370384216309,
      "learning_rate": 8.137142857142858e-06,
      "loss": 0.3333,
      "step": 31140
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.0061490521766245365,
      "learning_rate": 8.133333333333334e-06,
      "loss": 0.1445,
      "step": 31150
    },
    {
      "epoch": 8.902857142857142,
      "grad_norm": 0.015041284263134003,
      "learning_rate": 8.129523809523811e-06,
      "loss": 0.1059,
      "step": 31160
    },
    {
      "epoch": 8.905714285714286,
      "grad_norm": 0.11378777027130127,
      "learning_rate": 8.125714285714287e-06,
      "loss": 0.0018,
      "step": 31170
    },
    {
      "epoch": 8.90857142857143,
      "grad_norm": 0.13960009813308716,
      "learning_rate": 8.121904761904762e-06,
      "loss": 0.3136,
      "step": 31180
    },
    {
      "epoch": 8.911428571428571,
      "grad_norm": 14.561738014221191,
      "learning_rate": 8.118095238095238e-06,
      "loss": 0.2688,
      "step": 31190
    },
    {
      "epoch": 8.914285714285715,
      "grad_norm": 0.02297884039580822,
      "learning_rate": 8.114285714285715e-06,
      "loss": 0.2272,
      "step": 31200
    },
    {
      "epoch": 8.917142857142856,
      "grad_norm": 18.42917823791504,
      "learning_rate": 8.11047619047619e-06,
      "loss": 0.3019,
      "step": 31210
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.02336089126765728,
      "learning_rate": 8.106666666666666e-06,
      "loss": 0.2342,
      "step": 31220
    },
    {
      "epoch": 8.922857142857143,
      "grad_norm": 0.47616514563560486,
      "learning_rate": 8.102857142857144e-06,
      "loss": 0.1476,
      "step": 31230
    },
    {
      "epoch": 8.925714285714285,
      "grad_norm": 0.02363981120288372,
      "learning_rate": 8.09904761904762e-06,
      "loss": 0.0011,
      "step": 31240
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.031873177736997604,
      "learning_rate": 8.095238095238097e-06,
      "loss": 0.1278,
      "step": 31250
    },
    {
      "epoch": 8.93142857142857,
      "grad_norm": 15.31872272491455,
      "learning_rate": 8.091428571428572e-06,
      "loss": 0.2263,
      "step": 31260
    },
    {
      "epoch": 8.934285714285714,
      "grad_norm": 0.2505490779876709,
      "learning_rate": 8.08761904761905e-06,
      "loss": 0.2732,
      "step": 31270
    },
    {
      "epoch": 8.937142857142858,
      "grad_norm": 0.14946801960468292,
      "learning_rate": 8.083809523809525e-06,
      "loss": 0.1899,
      "step": 31280
    },
    {
      "epoch": 8.94,
      "grad_norm": 0.011331797577440739,
      "learning_rate": 8.08e-06,
      "loss": 0.0024,
      "step": 31290
    },
    {
      "epoch": 8.942857142857143,
      "grad_norm": 0.018102504312992096,
      "learning_rate": 8.076190476190476e-06,
      "loss": 0.0688,
      "step": 31300
    },
    {
      "epoch": 8.945714285714285,
      "grad_norm": 12.665127754211426,
      "learning_rate": 8.072380952380953e-06,
      "loss": 0.1373,
      "step": 31310
    },
    {
      "epoch": 8.948571428571428,
      "grad_norm": 0.004443824756890535,
      "learning_rate": 8.068571428571429e-06,
      "loss": 0.1124,
      "step": 31320
    },
    {
      "epoch": 8.951428571428572,
      "grad_norm": 0.10133176296949387,
      "learning_rate": 8.064761904761905e-06,
      "loss": 0.527,
      "step": 31330
    },
    {
      "epoch": 8.954285714285714,
      "grad_norm": 0.2478889524936676,
      "learning_rate": 8.060952380952382e-06,
      "loss": 0.0062,
      "step": 31340
    },
    {
      "epoch": 8.957142857142857,
      "grad_norm": 0.04258789122104645,
      "learning_rate": 8.057142857142857e-06,
      "loss": 0.2273,
      "step": 31350
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.09396044909954071,
      "learning_rate": 8.053333333333335e-06,
      "loss": 0.0014,
      "step": 31360
    },
    {
      "epoch": 8.962857142857143,
      "grad_norm": 0.009271493181586266,
      "learning_rate": 8.04952380952381e-06,
      "loss": 0.0149,
      "step": 31370
    },
    {
      "epoch": 8.965714285714286,
      "grad_norm": 0.04135557636618614,
      "learning_rate": 8.045714285714286e-06,
      "loss": 0.0017,
      "step": 31380
    },
    {
      "epoch": 8.968571428571428,
      "grad_norm": 0.0482468456029892,
      "learning_rate": 8.041904761904763e-06,
      "loss": 0.1363,
      "step": 31390
    },
    {
      "epoch": 8.971428571428572,
      "grad_norm": 0.20973503589630127,
      "learning_rate": 8.038095238095239e-06,
      "loss": 0.4941,
      "step": 31400
    },
    {
      "epoch": 8.974285714285715,
      "grad_norm": 0.08914836496114731,
      "learning_rate": 8.034285714285714e-06,
      "loss": 0.0018,
      "step": 31410
    },
    {
      "epoch": 8.977142857142857,
      "grad_norm": 0.06826271861791611,
      "learning_rate": 8.030476190476192e-06,
      "loss": 0.3966,
      "step": 31420
    },
    {
      "epoch": 8.98,
      "grad_norm": 0.042178183794021606,
      "learning_rate": 8.026666666666667e-06,
      "loss": 0.1483,
      "step": 31430
    },
    {
      "epoch": 8.982857142857142,
      "grad_norm": 0.057437531650066376,
      "learning_rate": 8.022857142857143e-06,
      "loss": 0.1588,
      "step": 31440
    },
    {
      "epoch": 8.985714285714286,
      "grad_norm": 0.5661641359329224,
      "learning_rate": 8.01904761904762e-06,
      "loss": 0.381,
      "step": 31450
    },
    {
      "epoch": 8.98857142857143,
      "grad_norm": 18.370500564575195,
      "learning_rate": 8.015238095238096e-06,
      "loss": 0.2421,
      "step": 31460
    },
    {
      "epoch": 8.991428571428571,
      "grad_norm": 0.2131507396697998,
      "learning_rate": 8.011428571428573e-06,
      "loss": 0.2423,
      "step": 31470
    },
    {
      "epoch": 8.994285714285715,
      "grad_norm": 0.031078947708010674,
      "learning_rate": 8.007619047619048e-06,
      "loss": 0.1045,
      "step": 31480
    },
    {
      "epoch": 8.997142857142856,
      "grad_norm": 0.02088175341486931,
      "learning_rate": 8.003809523809524e-06,
      "loss": 0.0989,
      "step": 31490
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.1295277327299118,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.2172,
      "step": 31500
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9603333333333334,
      "eval_f1": 0.810207336523126,
      "eval_loss": 0.20284293591976166,
      "eval_precision": 0.8610169491525423,
      "eval_recall": 0.7650602409638554,
      "eval_runtime": 264.417,
      "eval_samples_per_second": 11.346,
      "eval_steps_per_second": 2.836,
      "step": 31500
    },
    {
      "epoch": 9.002857142857144,
      "grad_norm": 0.09073314070701599,
      "learning_rate": 7.996190476190477e-06,
      "loss": 0.0015,
      "step": 31510
    },
    {
      "epoch": 9.005714285714285,
      "grad_norm": 0.009391004219651222,
      "learning_rate": 7.992380952380952e-06,
      "loss": 0.0009,
      "step": 31520
    },
    {
      "epoch": 9.008571428571429,
      "grad_norm": 0.006328694522380829,
      "learning_rate": 7.988571428571428e-06,
      "loss": 0.0012,
      "step": 31530
    },
    {
      "epoch": 9.01142857142857,
      "grad_norm": 0.04999661073088646,
      "learning_rate": 7.984761904761905e-06,
      "loss": 0.1484,
      "step": 31540
    },
    {
      "epoch": 9.014285714285714,
      "grad_norm": 0.08020244538784027,
      "learning_rate": 7.980952380952381e-06,
      "loss": 0.2284,
      "step": 31550
    },
    {
      "epoch": 9.017142857142858,
      "grad_norm": 0.046102866530418396,
      "learning_rate": 7.977142857142858e-06,
      "loss": 0.0009,
      "step": 31560
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.04706427454948425,
      "learning_rate": 7.973333333333334e-06,
      "loss": 0.2755,
      "step": 31570
    },
    {
      "epoch": 9.022857142857143,
      "grad_norm": 0.06129194423556328,
      "learning_rate": 7.969523809523811e-06,
      "loss": 0.0022,
      "step": 31580
    },
    {
      "epoch": 9.025714285714285,
      "grad_norm": 0.12722206115722656,
      "learning_rate": 7.965714285714287e-06,
      "loss": 0.1418,
      "step": 31590
    },
    {
      "epoch": 9.028571428571428,
      "grad_norm": 0.002382009057328105,
      "learning_rate": 7.961904761904762e-06,
      "loss": 0.0006,
      "step": 31600
    },
    {
      "epoch": 9.031428571428572,
      "grad_norm": 0.1147124171257019,
      "learning_rate": 7.95809523809524e-06,
      "loss": 0.2277,
      "step": 31610
    },
    {
      "epoch": 9.034285714285714,
      "grad_norm": 0.0025391108356416225,
      "learning_rate": 7.954285714285715e-06,
      "loss": 0.0007,
      "step": 31620
    },
    {
      "epoch": 9.037142857142857,
      "grad_norm": 0.006677313707768917,
      "learning_rate": 7.95047619047619e-06,
      "loss": 0.0014,
      "step": 31630
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.00112981500569731,
      "learning_rate": 7.946666666666666e-06,
      "loss": 0.0007,
      "step": 31640
    },
    {
      "epoch": 9.042857142857143,
      "grad_norm": 0.05885971337556839,
      "learning_rate": 7.942857142857144e-06,
      "loss": 0.0008,
      "step": 31650
    },
    {
      "epoch": 9.045714285714286,
      "grad_norm": 0.05582728236913681,
      "learning_rate": 7.939047619047619e-06,
      "loss": 0.0005,
      "step": 31660
    },
    {
      "epoch": 9.048571428571428,
      "grad_norm": 0.12275014072656631,
      "learning_rate": 7.935238095238096e-06,
      "loss": 0.0097,
      "step": 31670
    },
    {
      "epoch": 9.051428571428572,
      "grad_norm": 0.05500997602939606,
      "learning_rate": 7.931428571428572e-06,
      "loss": 0.2006,
      "step": 31680
    },
    {
      "epoch": 9.054285714285715,
      "grad_norm": 0.00449545681476593,
      "learning_rate": 7.92761904761905e-06,
      "loss": 0.138,
      "step": 31690
    },
    {
      "epoch": 9.057142857142857,
      "grad_norm": 0.07560523599386215,
      "learning_rate": 7.923809523809525e-06,
      "loss": 0.1343,
      "step": 31700
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.0415252223610878,
      "learning_rate": 7.92e-06,
      "loss": 0.0235,
      "step": 31710
    },
    {
      "epoch": 9.062857142857142,
      "grad_norm": 0.028849469497799873,
      "learning_rate": 7.916190476190478e-06,
      "loss": 0.097,
      "step": 31720
    },
    {
      "epoch": 9.065714285714286,
      "grad_norm": 0.05314968153834343,
      "learning_rate": 7.912380952380953e-06,
      "loss": 0.41,
      "step": 31730
    },
    {
      "epoch": 9.06857142857143,
      "grad_norm": 0.1793755441904068,
      "learning_rate": 7.908571428571429e-06,
      "loss": 0.2502,
      "step": 31740
    },
    {
      "epoch": 9.071428571428571,
      "grad_norm": 0.13788266479969025,
      "learning_rate": 7.904761904761904e-06,
      "loss": 0.0031,
      "step": 31750
    },
    {
      "epoch": 9.074285714285715,
      "grad_norm": 0.08394848555326462,
      "learning_rate": 7.900952380952382e-06,
      "loss": 0.2928,
      "step": 31760
    },
    {
      "epoch": 9.077142857142857,
      "grad_norm": 0.0031775410752743483,
      "learning_rate": 7.897142857142857e-06,
      "loss": 0.107,
      "step": 31770
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.0018319926457479596,
      "learning_rate": 7.893333333333335e-06,
      "loss": 0.0008,
      "step": 31780
    },
    {
      "epoch": 9.082857142857144,
      "grad_norm": 0.041215769946575165,
      "learning_rate": 7.88952380952381e-06,
      "loss": 0.0012,
      "step": 31790
    },
    {
      "epoch": 9.085714285714285,
      "grad_norm": 0.002079387428238988,
      "learning_rate": 7.885714285714286e-06,
      "loss": 0.0008,
      "step": 31800
    },
    {
      "epoch": 9.088571428571429,
      "grad_norm": 0.06633380800485611,
      "learning_rate": 7.881904761904763e-06,
      "loss": 0.1395,
      "step": 31810
    },
    {
      "epoch": 9.09142857142857,
      "grad_norm": 0.001225674874149263,
      "learning_rate": 7.878095238095239e-06,
      "loss": 0.0977,
      "step": 31820
    },
    {
      "epoch": 9.094285714285714,
      "grad_norm": 0.01586008258163929,
      "learning_rate": 7.874285714285716e-06,
      "loss": 0.0015,
      "step": 31830
    },
    {
      "epoch": 9.097142857142858,
      "grad_norm": 0.0017778733745217323,
      "learning_rate": 7.870476190476191e-06,
      "loss": 0.1614,
      "step": 31840
    },
    {
      "epoch": 9.1,
      "grad_norm": 13.220874786376953,
      "learning_rate": 7.866666666666667e-06,
      "loss": 0.1757,
      "step": 31850
    },
    {
      "epoch": 9.102857142857143,
      "grad_norm": 0.005892680026590824,
      "learning_rate": 7.862857142857143e-06,
      "loss": 0.2858,
      "step": 31860
    },
    {
      "epoch": 9.105714285714285,
      "grad_norm": 0.002774560358375311,
      "learning_rate": 7.85904761904762e-06,
      "loss": 0.0005,
      "step": 31870
    },
    {
      "epoch": 9.108571428571429,
      "grad_norm": 0.10476155579090118,
      "learning_rate": 7.855238095238095e-06,
      "loss": 0.0015,
      "step": 31880
    },
    {
      "epoch": 9.111428571428572,
      "grad_norm": 0.003169582225382328,
      "learning_rate": 7.851428571428573e-06,
      "loss": 0.0003,
      "step": 31890
    },
    {
      "epoch": 9.114285714285714,
      "grad_norm": 0.002557207830250263,
      "learning_rate": 7.847619047619048e-06,
      "loss": 0.3451,
      "step": 31900
    },
    {
      "epoch": 9.117142857142857,
      "grad_norm": 0.004875172860920429,
      "learning_rate": 7.843809523809524e-06,
      "loss": 0.0006,
      "step": 31910
    },
    {
      "epoch": 9.12,
      "grad_norm": 29.727493286132812,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.2222,
      "step": 31920
    },
    {
      "epoch": 9.122857142857143,
      "grad_norm": 0.3161294162273407,
      "learning_rate": 7.836190476190477e-06,
      "loss": 0.0013,
      "step": 31930
    },
    {
      "epoch": 9.125714285714286,
      "grad_norm": 0.05805673450231552,
      "learning_rate": 7.832380952380954e-06,
      "loss": 0.2606,
      "step": 31940
    },
    {
      "epoch": 9.128571428571428,
      "grad_norm": 0.098497673869133,
      "learning_rate": 7.828571428571428e-06,
      "loss": 0.4161,
      "step": 31950
    },
    {
      "epoch": 9.131428571428572,
      "grad_norm": 0.20292338728904724,
      "learning_rate": 7.824761904761905e-06,
      "loss": 0.2637,
      "step": 31960
    },
    {
      "epoch": 9.134285714285713,
      "grad_norm": 0.018810946494340897,
      "learning_rate": 7.82095238095238e-06,
      "loss": 0.0013,
      "step": 31970
    },
    {
      "epoch": 9.137142857142857,
      "grad_norm": 0.39942803978919983,
      "learning_rate": 7.817142857142858e-06,
      "loss": 0.1583,
      "step": 31980
    },
    {
      "epoch": 9.14,
      "grad_norm": 0.09770315885543823,
      "learning_rate": 7.813333333333334e-06,
      "loss": 0.0007,
      "step": 31990
    },
    {
      "epoch": 9.142857142857142,
      "grad_norm": 0.009317772462964058,
      "learning_rate": 7.809523809523811e-06,
      "loss": 0.0018,
      "step": 32000
    },
    {
      "epoch": 9.145714285714286,
      "grad_norm": 14.974272727966309,
      "learning_rate": 7.805714285714286e-06,
      "loss": 0.3102,
      "step": 32010
    },
    {
      "epoch": 9.14857142857143,
      "grad_norm": 0.056095514446496964,
      "learning_rate": 7.801904761904762e-06,
      "loss": 0.1257,
      "step": 32020
    },
    {
      "epoch": 9.151428571428571,
      "grad_norm": 17.520780563354492,
      "learning_rate": 7.79809523809524e-06,
      "loss": 0.0107,
      "step": 32030
    },
    {
      "epoch": 9.154285714285715,
      "grad_norm": 0.005861196201294661,
      "learning_rate": 7.794285714285715e-06,
      "loss": 0.0008,
      "step": 32040
    },
    {
      "epoch": 9.157142857142857,
      "grad_norm": 0.6353300213813782,
      "learning_rate": 7.790476190476192e-06,
      "loss": 0.1295,
      "step": 32050
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.0019178494112566113,
      "learning_rate": 7.786666666666666e-06,
      "loss": 0.1495,
      "step": 32060
    },
    {
      "epoch": 9.162857142857144,
      "grad_norm": 0.09256131201982498,
      "learning_rate": 7.782857142857143e-06,
      "loss": 0.2737,
      "step": 32070
    },
    {
      "epoch": 9.165714285714285,
      "grad_norm": 0.004471695516258478,
      "learning_rate": 7.779047619047619e-06,
      "loss": 0.0011,
      "step": 32080
    },
    {
      "epoch": 9.168571428571429,
      "grad_norm": 0.10653548687696457,
      "learning_rate": 7.775238095238096e-06,
      "loss": 0.092,
      "step": 32090
    },
    {
      "epoch": 9.17142857142857,
      "grad_norm": 0.33985307812690735,
      "learning_rate": 7.771428571428572e-06,
      "loss": 0.0033,
      "step": 32100
    },
    {
      "epoch": 9.174285714285714,
      "grad_norm": 0.0017933071358129382,
      "learning_rate": 7.767619047619049e-06,
      "loss": 0.1991,
      "step": 32110
    },
    {
      "epoch": 9.177142857142858,
      "grad_norm": 0.003434619400650263,
      "learning_rate": 7.763809523809525e-06,
      "loss": 0.0894,
      "step": 32120
    },
    {
      "epoch": 9.18,
      "grad_norm": 0.18939056992530823,
      "learning_rate": 7.76e-06,
      "loss": 0.2481,
      "step": 32130
    },
    {
      "epoch": 9.182857142857143,
      "grad_norm": 0.023548338562250137,
      "learning_rate": 7.756190476190478e-06,
      "loss": 0.0388,
      "step": 32140
    },
    {
      "epoch": 9.185714285714285,
      "grad_norm": 0.07190234214067459,
      "learning_rate": 7.752380952380953e-06,
      "loss": 0.0179,
      "step": 32150
    },
    {
      "epoch": 9.188571428571429,
      "grad_norm": 0.00693011237308383,
      "learning_rate": 7.74857142857143e-06,
      "loss": 0.0016,
      "step": 32160
    },
    {
      "epoch": 9.191428571428572,
      "grad_norm": 0.007932945154607296,
      "learning_rate": 7.744761904761904e-06,
      "loss": 0.0006,
      "step": 32170
    },
    {
      "epoch": 9.194285714285714,
      "grad_norm": 0.03466181457042694,
      "learning_rate": 7.740952380952382e-06,
      "loss": 0.1178,
      "step": 32180
    },
    {
      "epoch": 9.197142857142858,
      "grad_norm": 0.10922644287347794,
      "learning_rate": 7.737142857142857e-06,
      "loss": 0.0007,
      "step": 32190
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.06514628976583481,
      "learning_rate": 7.733333333333334e-06,
      "loss": 0.3227,
      "step": 32200
    },
    {
      "epoch": 9.202857142857143,
      "grad_norm": 0.08706022799015045,
      "learning_rate": 7.72952380952381e-06,
      "loss": 0.2494,
      "step": 32210
    },
    {
      "epoch": 9.205714285714286,
      "grad_norm": 0.009070009924471378,
      "learning_rate": 7.725714285714286e-06,
      "loss": 0.002,
      "step": 32220
    },
    {
      "epoch": 9.208571428571428,
      "grad_norm": 0.00898060854524374,
      "learning_rate": 7.721904761904763e-06,
      "loss": 0.1344,
      "step": 32230
    },
    {
      "epoch": 9.211428571428572,
      "grad_norm": 0.014862929470837116,
      "learning_rate": 7.718095238095238e-06,
      "loss": 0.1329,
      "step": 32240
    },
    {
      "epoch": 9.214285714285714,
      "grad_norm": 0.02748660184442997,
      "learning_rate": 7.714285714285716e-06,
      "loss": 0.1352,
      "step": 32250
    },
    {
      "epoch": 9.217142857142857,
      "grad_norm": 0.19915026426315308,
      "learning_rate": 7.710476190476191e-06,
      "loss": 0.1332,
      "step": 32260
    },
    {
      "epoch": 9.22,
      "grad_norm": 0.13618560135364532,
      "learning_rate": 7.706666666666669e-06,
      "loss": 0.2005,
      "step": 32270
    },
    {
      "epoch": 9.222857142857142,
      "grad_norm": 0.18604306876659393,
      "learning_rate": 7.702857142857142e-06,
      "loss": 0.0019,
      "step": 32280
    },
    {
      "epoch": 9.225714285714286,
      "grad_norm": 0.5616722106933594,
      "learning_rate": 7.69904761904762e-06,
      "loss": 0.2104,
      "step": 32290
    },
    {
      "epoch": 9.228571428571428,
      "grad_norm": 0.11724361777305603,
      "learning_rate": 7.695238095238095e-06,
      "loss": 0.0031,
      "step": 32300
    },
    {
      "epoch": 9.231428571428571,
      "grad_norm": 0.022612478584051132,
      "learning_rate": 7.691428571428573e-06,
      "loss": 0.0901,
      "step": 32310
    },
    {
      "epoch": 9.234285714285715,
      "grad_norm": 0.1321748048067093,
      "learning_rate": 7.687619047619048e-06,
      "loss": 0.0017,
      "step": 32320
    },
    {
      "epoch": 9.237142857142857,
      "grad_norm": 0.0025572609156370163,
      "learning_rate": 7.683809523809524e-06,
      "loss": 0.1377,
      "step": 32330
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.053945861756801605,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.3572,
      "step": 32340
    },
    {
      "epoch": 9.242857142857142,
      "grad_norm": 0.014982737600803375,
      "learning_rate": 7.676190476190477e-06,
      "loss": 0.1145,
      "step": 32350
    },
    {
      "epoch": 9.245714285714286,
      "grad_norm": 0.05546177551150322,
      "learning_rate": 7.672380952380954e-06,
      "loss": 0.001,
      "step": 32360
    },
    {
      "epoch": 9.248571428571429,
      "grad_norm": 0.0018325911369174719,
      "learning_rate": 7.66857142857143e-06,
      "loss": 0.2798,
      "step": 32370
    },
    {
      "epoch": 9.251428571428571,
      "grad_norm": 0.014904029667377472,
      "learning_rate": 7.664761904761905e-06,
      "loss": 0.0004,
      "step": 32380
    },
    {
      "epoch": 9.254285714285714,
      "grad_norm": 0.07867593318223953,
      "learning_rate": 7.66095238095238e-06,
      "loss": 0.0008,
      "step": 32390
    },
    {
      "epoch": 9.257142857142856,
      "grad_norm": 0.004065883345901966,
      "learning_rate": 7.657142857142858e-06,
      "loss": 0.0072,
      "step": 32400
    },
    {
      "epoch": 9.26,
      "grad_norm": 0.26516175270080566,
      "learning_rate": 7.653333333333333e-06,
      "loss": 0.3467,
      "step": 32410
    },
    {
      "epoch": 9.262857142857143,
      "grad_norm": 0.09049053490161896,
      "learning_rate": 7.64952380952381e-06,
      "loss": 0.0558,
      "step": 32420
    },
    {
      "epoch": 9.265714285714285,
      "grad_norm": 0.05919446423649788,
      "learning_rate": 7.645714285714286e-06,
      "loss": 0.1719,
      "step": 32430
    },
    {
      "epoch": 9.268571428571429,
      "grad_norm": 0.12023987621068954,
      "learning_rate": 7.641904761904762e-06,
      "loss": 0.0888,
      "step": 32440
    },
    {
      "epoch": 9.271428571428572,
      "grad_norm": 0.06713461130857468,
      "learning_rate": 7.63809523809524e-06,
      "loss": 0.0014,
      "step": 32450
    },
    {
      "epoch": 9.274285714285714,
      "grad_norm": 0.03403095528483391,
      "learning_rate": 7.634285714285715e-06,
      "loss": 0.001,
      "step": 32460
    },
    {
      "epoch": 9.277142857142858,
      "grad_norm": 0.0016850747633725405,
      "learning_rate": 7.630476190476192e-06,
      "loss": 0.0009,
      "step": 32470
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.004746380727738142,
      "learning_rate": 7.626666666666668e-06,
      "loss": 0.0011,
      "step": 32480
    },
    {
      "epoch": 9.282857142857143,
      "grad_norm": 0.0037905198987573385,
      "learning_rate": 7.622857142857143e-06,
      "loss": 0.0003,
      "step": 32490
    },
    {
      "epoch": 9.285714285714286,
      "grad_norm": 0.01371917873620987,
      "learning_rate": 7.61904761904762e-06,
      "loss": 0.1907,
      "step": 32500
    },
    {
      "epoch": 9.288571428571428,
      "grad_norm": 0.004009275697171688,
      "learning_rate": 7.615238095238095e-06,
      "loss": 0.1536,
      "step": 32510
    },
    {
      "epoch": 9.291428571428572,
      "grad_norm": 0.02958228811621666,
      "learning_rate": 7.611428571428572e-06,
      "loss": 0.0014,
      "step": 32520
    },
    {
      "epoch": 9.294285714285714,
      "grad_norm": 0.03892575949430466,
      "learning_rate": 7.607619047619048e-06,
      "loss": 0.0015,
      "step": 32530
    },
    {
      "epoch": 9.297142857142857,
      "grad_norm": 0.022025393322110176,
      "learning_rate": 7.6038095238095245e-06,
      "loss": 0.5857,
      "step": 32540
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.06800302118062973,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.154,
      "step": 32550
    },
    {
      "epoch": 9.302857142857142,
      "grad_norm": 0.002788536949083209,
      "learning_rate": 7.596190476190477e-06,
      "loss": 0.148,
      "step": 32560
    },
    {
      "epoch": 9.305714285714286,
      "grad_norm": 0.03576880693435669,
      "learning_rate": 7.592380952380953e-06,
      "loss": 0.0734,
      "step": 32570
    },
    {
      "epoch": 9.308571428571428,
      "grad_norm": 0.07432370632886887,
      "learning_rate": 7.588571428571429e-06,
      "loss": 0.0009,
      "step": 32580
    },
    {
      "epoch": 9.311428571428571,
      "grad_norm": 0.00711833918467164,
      "learning_rate": 7.584761904761906e-06,
      "loss": 0.1277,
      "step": 32590
    },
    {
      "epoch": 9.314285714285715,
      "grad_norm": 0.009153280407190323,
      "learning_rate": 7.580952380952381e-06,
      "loss": 0.1213,
      "step": 32600
    },
    {
      "epoch": 9.317142857142857,
      "grad_norm": 0.01274921279400587,
      "learning_rate": 7.577142857142857e-06,
      "loss": 0.0024,
      "step": 32610
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.00661212345585227,
      "learning_rate": 7.573333333333333e-06,
      "loss": 0.1193,
      "step": 32620
    },
    {
      "epoch": 9.322857142857142,
      "grad_norm": 0.0013895280426368117,
      "learning_rate": 7.56952380952381e-06,
      "loss": 0.1546,
      "step": 32630
    },
    {
      "epoch": 9.325714285714286,
      "grad_norm": 0.19802841544151306,
      "learning_rate": 7.565714285714286e-06,
      "loss": 0.0019,
      "step": 32640
    },
    {
      "epoch": 9.32857142857143,
      "grad_norm": 0.043618734925985336,
      "learning_rate": 7.561904761904763e-06,
      "loss": 0.1772,
      "step": 32650
    },
    {
      "epoch": 9.331428571428571,
      "grad_norm": 0.040217325091362,
      "learning_rate": 7.558095238095239e-06,
      "loss": 0.0009,
      "step": 32660
    },
    {
      "epoch": 9.334285714285715,
      "grad_norm": 0.1807882934808731,
      "learning_rate": 7.5542857142857155e-06,
      "loss": 0.0008,
      "step": 32670
    },
    {
      "epoch": 9.337142857142856,
      "grad_norm": 0.019944917410612106,
      "learning_rate": 7.550476190476191e-06,
      "loss": 0.0008,
      "step": 32680
    },
    {
      "epoch": 9.34,
      "grad_norm": 0.0081618782132864,
      "learning_rate": 7.5466666666666675e-06,
      "loss": 0.3351,
      "step": 32690
    },
    {
      "epoch": 9.342857142857143,
      "grad_norm": 0.1853203922510147,
      "learning_rate": 7.542857142857144e-06,
      "loss": 0.1387,
      "step": 32700
    },
    {
      "epoch": 9.345714285714285,
      "grad_norm": 0.030905695632100105,
      "learning_rate": 7.5390476190476195e-06,
      "loss": 0.0197,
      "step": 32710
    },
    {
      "epoch": 9.348571428571429,
      "grad_norm": 0.0029565945733338594,
      "learning_rate": 7.535238095238095e-06,
      "loss": 0.0559,
      "step": 32720
    },
    {
      "epoch": 9.35142857142857,
      "grad_norm": 0.01877535507082939,
      "learning_rate": 7.5314285714285716e-06,
      "loss": 0.2409,
      "step": 32730
    },
    {
      "epoch": 9.354285714285714,
      "grad_norm": 0.08101855218410492,
      "learning_rate": 7.527619047619048e-06,
      "loss": 0.2132,
      "step": 32740
    },
    {
      "epoch": 9.357142857142858,
      "grad_norm": 0.03771256282925606,
      "learning_rate": 7.523809523809524e-06,
      "loss": 0.0014,
      "step": 32750
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.0013539759675040841,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.145,
      "step": 32760
    },
    {
      "epoch": 9.362857142857143,
      "grad_norm": 0.6852033734321594,
      "learning_rate": 7.516190476190477e-06,
      "loss": 0.0027,
      "step": 32770
    },
    {
      "epoch": 9.365714285714287,
      "grad_norm": 0.03880998119711876,
      "learning_rate": 7.512380952380953e-06,
      "loss": 0.4919,
      "step": 32780
    },
    {
      "epoch": 9.368571428571428,
      "grad_norm": 0.001060061389580369,
      "learning_rate": 7.508571428571429e-06,
      "loss": 0.0007,
      "step": 32790
    },
    {
      "epoch": 9.371428571428572,
      "grad_norm": 0.08767495304346085,
      "learning_rate": 7.504761904761906e-06,
      "loss": 0.039,
      "step": 32800
    },
    {
      "epoch": 9.374285714285714,
      "grad_norm": 0.051156166940927505,
      "learning_rate": 7.500952380952382e-06,
      "loss": 0.002,
      "step": 32810
    },
    {
      "epoch": 9.377142857142857,
      "grad_norm": 14.310708999633789,
      "learning_rate": 7.497142857142857e-06,
      "loss": 0.0896,
      "step": 32820
    },
    {
      "epoch": 9.38,
      "grad_norm": 0.0024909144267439842,
      "learning_rate": 7.493333333333333e-06,
      "loss": 0.2195,
      "step": 32830
    },
    {
      "epoch": 9.382857142857143,
      "grad_norm": 0.00030239467741921544,
      "learning_rate": 7.48952380952381e-06,
      "loss": 0.2433,
      "step": 32840
    },
    {
      "epoch": 9.385714285714286,
      "grad_norm": 16.588411331176758,
      "learning_rate": 7.485714285714286e-06,
      "loss": 0.138,
      "step": 32850
    },
    {
      "epoch": 9.388571428571428,
      "grad_norm": 0.007622395642101765,
      "learning_rate": 7.481904761904763e-06,
      "loss": 0.0009,
      "step": 32860
    },
    {
      "epoch": 9.391428571428571,
      "grad_norm": 0.0008475487120449543,
      "learning_rate": 7.478095238095239e-06,
      "loss": 0.002,
      "step": 32870
    },
    {
      "epoch": 9.394285714285715,
      "grad_norm": 0.0003350743209011853,
      "learning_rate": 7.4742857142857154e-06,
      "loss": 0.0008,
      "step": 32880
    },
    {
      "epoch": 9.397142857142857,
      "grad_norm": 0.08359356969594955,
      "learning_rate": 7.470476190476191e-06,
      "loss": 0.001,
      "step": 32890
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.00012971409887541085,
      "learning_rate": 7.4666666666666675e-06,
      "loss": 0.13,
      "step": 32900
    },
    {
      "epoch": 9.402857142857142,
      "grad_norm": 0.08195076137781143,
      "learning_rate": 7.462857142857144e-06,
      "loss": 0.2402,
      "step": 32910
    },
    {
      "epoch": 9.405714285714286,
      "grad_norm": 0.0910392478108406,
      "learning_rate": 7.45904761904762e-06,
      "loss": 0.2205,
      "step": 32920
    },
    {
      "epoch": 9.40857142857143,
      "grad_norm": 0.9291393160820007,
      "learning_rate": 7.455238095238095e-06,
      "loss": 0.2017,
      "step": 32930
    },
    {
      "epoch": 9.411428571428571,
      "grad_norm": 0.035104092210531235,
      "learning_rate": 7.4514285714285715e-06,
      "loss": 0.0023,
      "step": 32940
    },
    {
      "epoch": 9.414285714285715,
      "grad_norm": 0.17336203157901764,
      "learning_rate": 7.447619047619048e-06,
      "loss": 0.0911,
      "step": 32950
    },
    {
      "epoch": 9.417142857142856,
      "grad_norm": 0.013096052221953869,
      "learning_rate": 7.443809523809524e-06,
      "loss": 0.2315,
      "step": 32960
    },
    {
      "epoch": 9.42,
      "grad_norm": 368.1145935058594,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.2988,
      "step": 32970
    },
    {
      "epoch": 9.422857142857143,
      "grad_norm": 0.06751374900341034,
      "learning_rate": 7.436190476190477e-06,
      "loss": 0.2524,
      "step": 32980
    },
    {
      "epoch": 9.425714285714285,
      "grad_norm": 0.009969777427613735,
      "learning_rate": 7.432380952380953e-06,
      "loss": 0.0018,
      "step": 32990
    },
    {
      "epoch": 9.428571428571429,
      "grad_norm": 0.12808293104171753,
      "learning_rate": 7.428571428571429e-06,
      "loss": 0.3292,
      "step": 33000
    },
    {
      "epoch": 9.43142857142857,
      "grad_norm": 0.006474523339420557,
      "learning_rate": 7.424761904761906e-06,
      "loss": 0.0016,
      "step": 33010
    },
    {
      "epoch": 9.434285714285714,
      "grad_norm": 0.0121493861079216,
      "learning_rate": 7.420952380952382e-06,
      "loss": 0.0014,
      "step": 33020
    },
    {
      "epoch": 9.437142857142858,
      "grad_norm": 0.16209551692008972,
      "learning_rate": 7.417142857142857e-06,
      "loss": 0.1152,
      "step": 33030
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.0005270731053315103,
      "learning_rate": 7.413333333333333e-06,
      "loss": 0.1983,
      "step": 33040
    },
    {
      "epoch": 9.442857142857143,
      "grad_norm": 13.653160095214844,
      "learning_rate": 7.40952380952381e-06,
      "loss": 0.4019,
      "step": 33050
    },
    {
      "epoch": 9.445714285714285,
      "grad_norm": 0.034151677042245865,
      "learning_rate": 7.405714285714286e-06,
      "loss": 0.1527,
      "step": 33060
    },
    {
      "epoch": 9.448571428571428,
      "grad_norm": 0.1262216717004776,
      "learning_rate": 7.4019047619047625e-06,
      "loss": 0.2202,
      "step": 33070
    },
    {
      "epoch": 9.451428571428572,
      "grad_norm": 0.18549880385398865,
      "learning_rate": 7.398095238095239e-06,
      "loss": 0.002,
      "step": 33080
    },
    {
      "epoch": 9.454285714285714,
      "grad_norm": 0.15093401074409485,
      "learning_rate": 7.394285714285715e-06,
      "loss": 0.3129,
      "step": 33090
    },
    {
      "epoch": 9.457142857142857,
      "grad_norm": 0.31999677419662476,
      "learning_rate": 7.390476190476191e-06,
      "loss": 0.1154,
      "step": 33100
    },
    {
      "epoch": 9.46,
      "grad_norm": 0.321767121553421,
      "learning_rate": 7.386666666666667e-06,
      "loss": 0.1061,
      "step": 33110
    },
    {
      "epoch": 9.462857142857143,
      "grad_norm": 11.907940864562988,
      "learning_rate": 7.382857142857144e-06,
      "loss": 0.1859,
      "step": 33120
    },
    {
      "epoch": 9.465714285714286,
      "grad_norm": 0.0003587788960430771,
      "learning_rate": 7.37904761904762e-06,
      "loss": 0.0875,
      "step": 33130
    },
    {
      "epoch": 9.468571428571428,
      "grad_norm": 4.405215263366699,
      "learning_rate": 7.375238095238095e-06,
      "loss": 0.5511,
      "step": 33140
    },
    {
      "epoch": 9.471428571428572,
      "grad_norm": 0.9168587327003479,
      "learning_rate": 7.371428571428571e-06,
      "loss": 0.0039,
      "step": 33150
    },
    {
      "epoch": 9.474285714285715,
      "grad_norm": 0.04829477518796921,
      "learning_rate": 7.367619047619048e-06,
      "loss": 0.0791,
      "step": 33160
    },
    {
      "epoch": 9.477142857142857,
      "grad_norm": 11.459031105041504,
      "learning_rate": 7.363809523809524e-06,
      "loss": 0.3417,
      "step": 33170
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.003571550827473402,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.1036,
      "step": 33180
    },
    {
      "epoch": 9.482857142857142,
      "grad_norm": 0.02494540624320507,
      "learning_rate": 7.356190476190477e-06,
      "loss": 0.0033,
      "step": 33190
    },
    {
      "epoch": 9.485714285714286,
      "grad_norm": 0.16912537813186646,
      "learning_rate": 7.352380952380953e-06,
      "loss": 0.2233,
      "step": 33200
    },
    {
      "epoch": 9.48857142857143,
      "grad_norm": 9.690131992101669e-05,
      "learning_rate": 7.348571428571429e-06,
      "loss": 0.0904,
      "step": 33210
    },
    {
      "epoch": 9.491428571428571,
      "grad_norm": 0.07838871330022812,
      "learning_rate": 7.3447619047619056e-06,
      "loss": 0.0066,
      "step": 33220
    },
    {
      "epoch": 9.494285714285715,
      "grad_norm": 25.827415466308594,
      "learning_rate": 7.340952380952382e-06,
      "loss": 0.2633,
      "step": 33230
    },
    {
      "epoch": 9.497142857142856,
      "grad_norm": 0.0006979763857088983,
      "learning_rate": 7.337142857142858e-06,
      "loss": 0.0004,
      "step": 33240
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.014329709112644196,
      "learning_rate": 7.333333333333333e-06,
      "loss": 0.2143,
      "step": 33250
    },
    {
      "epoch": 9.502857142857144,
      "grad_norm": 0.10664524137973785,
      "learning_rate": 7.3295238095238096e-06,
      "loss": 0.354,
      "step": 33260
    },
    {
      "epoch": 9.505714285714285,
      "grad_norm": 16.11957359313965,
      "learning_rate": 7.325714285714286e-06,
      "loss": 0.099,
      "step": 33270
    },
    {
      "epoch": 9.508571428571429,
      "grad_norm": 0.011648907326161861,
      "learning_rate": 7.3219047619047624e-06,
      "loss": 0.1345,
      "step": 33280
    },
    {
      "epoch": 9.51142857142857,
      "grad_norm": 0.009810141287744045,
      "learning_rate": 7.318095238095239e-06,
      "loss": 0.0016,
      "step": 33290
    },
    {
      "epoch": 9.514285714285714,
      "grad_norm": 0.19641588628292084,
      "learning_rate": 7.314285714285715e-06,
      "loss": 0.293,
      "step": 33300
    },
    {
      "epoch": 9.517142857142858,
      "grad_norm": 0.0017254757694900036,
      "learning_rate": 7.310476190476191e-06,
      "loss": 0.0017,
      "step": 33310
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.0007189192110672593,
      "learning_rate": 7.306666666666667e-06,
      "loss": 0.118,
      "step": 33320
    },
    {
      "epoch": 9.522857142857143,
      "grad_norm": 0.124491386115551,
      "learning_rate": 7.302857142857144e-06,
      "loss": 0.0536,
      "step": 33330
    },
    {
      "epoch": 9.525714285714285,
      "grad_norm": 0.7323892116546631,
      "learning_rate": 7.29904761904762e-06,
      "loss": 0.0017,
      "step": 33340
    },
    {
      "epoch": 9.528571428571428,
      "grad_norm": 0.07011597603559494,
      "learning_rate": 7.295238095238097e-06,
      "loss": 0.2505,
      "step": 33350
    },
    {
      "epoch": 9.531428571428572,
      "grad_norm": 0.1943860799074173,
      "learning_rate": 7.291428571428571e-06,
      "loss": 0.0125,
      "step": 33360
    },
    {
      "epoch": 9.534285714285714,
      "grad_norm": 0.21444973349571228,
      "learning_rate": 7.287619047619048e-06,
      "loss": 0.1256,
      "step": 33370
    },
    {
      "epoch": 9.537142857142857,
      "grad_norm": 0.07019416987895966,
      "learning_rate": 7.283809523809524e-06,
      "loss": 0.3274,
      "step": 33380
    },
    {
      "epoch": 9.54,
      "grad_norm": 0.004857090301811695,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.106,
      "step": 33390
    },
    {
      "epoch": 9.542857142857143,
      "grad_norm": 0.07214774936437607,
      "learning_rate": 7.276190476190477e-06,
      "loss": 0.295,
      "step": 33400
    },
    {
      "epoch": 9.545714285714286,
      "grad_norm": 0.37007442116737366,
      "learning_rate": 7.272380952380953e-06,
      "loss": 0.1184,
      "step": 33410
    },
    {
      "epoch": 9.548571428571428,
      "grad_norm": 0.01734868623316288,
      "learning_rate": 7.268571428571429e-06,
      "loss": 0.1057,
      "step": 33420
    },
    {
      "epoch": 9.551428571428572,
      "grad_norm": 0.0002180744195356965,
      "learning_rate": 7.2647619047619055e-06,
      "loss": 0.001,
      "step": 33430
    },
    {
      "epoch": 9.554285714285715,
      "grad_norm": 0.0009443853050470352,
      "learning_rate": 7.260952380952382e-06,
      "loss": 0.0009,
      "step": 33440
    },
    {
      "epoch": 9.557142857142857,
      "grad_norm": 0.6163085699081421,
      "learning_rate": 7.257142857142858e-06,
      "loss": 0.0015,
      "step": 33450
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.0015057636192068458,
      "learning_rate": 7.253333333333335e-06,
      "loss": 0.2526,
      "step": 33460
    },
    {
      "epoch": 9.562857142857142,
      "grad_norm": 0.010286853648722172,
      "learning_rate": 7.2495238095238095e-06,
      "loss": 0.3199,
      "step": 33470
    },
    {
      "epoch": 9.565714285714286,
      "grad_norm": 0.06003084033727646,
      "learning_rate": 7.245714285714286e-06,
      "loss": 0.3565,
      "step": 33480
    },
    {
      "epoch": 9.56857142857143,
      "grad_norm": 16.077905654907227,
      "learning_rate": 7.241904761904762e-06,
      "loss": 0.0917,
      "step": 33490
    },
    {
      "epoch": 9.571428571428571,
      "grad_norm": 0.004133703652769327,
      "learning_rate": 7.238095238095239e-06,
      "loss": 0.5586,
      "step": 33500
    },
    {
      "epoch": 9.574285714285715,
      "grad_norm": 0.03707551956176758,
      "learning_rate": 7.234285714285715e-06,
      "loss": 0.001,
      "step": 33510
    },
    {
      "epoch": 9.577142857142857,
      "grad_norm": 0.09391463547945023,
      "learning_rate": 7.230476190476191e-06,
      "loss": 0.0013,
      "step": 33520
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.00022149663709569722,
      "learning_rate": 7.226666666666667e-06,
      "loss": 0.2734,
      "step": 33530
    },
    {
      "epoch": 9.582857142857144,
      "grad_norm": 0.01626071147620678,
      "learning_rate": 7.222857142857144e-06,
      "loss": 0.0009,
      "step": 33540
    },
    {
      "epoch": 9.585714285714285,
      "grad_norm": 0.45868027210235596,
      "learning_rate": 7.21904761904762e-06,
      "loss": 0.0017,
      "step": 33550
    },
    {
      "epoch": 9.588571428571429,
      "grad_norm": 4.964649677276611,
      "learning_rate": 7.2152380952380965e-06,
      "loss": 0.0029,
      "step": 33560
    },
    {
      "epoch": 9.59142857142857,
      "grad_norm": 0.04726167768239975,
      "learning_rate": 7.211428571428573e-06,
      "loss": 0.0011,
      "step": 33570
    },
    {
      "epoch": 9.594285714285714,
      "grad_norm": 0.2974463999271393,
      "learning_rate": 7.207619047619048e-06,
      "loss": 0.0205,
      "step": 33580
    },
    {
      "epoch": 9.597142857142858,
      "grad_norm": 0.02377430722117424,
      "learning_rate": 7.203809523809524e-06,
      "loss": 0.0006,
      "step": 33590
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.04791339114308357,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.8733,
      "step": 33600
    },
    {
      "epoch": 9.602857142857143,
      "grad_norm": 20.871225357055664,
      "learning_rate": 7.196190476190477e-06,
      "loss": 0.1008,
      "step": 33610
    },
    {
      "epoch": 9.605714285714285,
      "grad_norm": 15.591758728027344,
      "learning_rate": 7.1923809523809525e-06,
      "loss": 0.1178,
      "step": 33620
    },
    {
      "epoch": 9.608571428571429,
      "grad_norm": 0.07654358446598053,
      "learning_rate": 7.188571428571429e-06,
      "loss": 0.0012,
      "step": 33630
    },
    {
      "epoch": 9.611428571428572,
      "grad_norm": 0.005701810587197542,
      "learning_rate": 7.184761904761905e-06,
      "loss": 0.0014,
      "step": 33640
    },
    {
      "epoch": 9.614285714285714,
      "grad_norm": 163.40283203125,
      "learning_rate": 7.180952380952382e-06,
      "loss": 0.0228,
      "step": 33650
    },
    {
      "epoch": 9.617142857142857,
      "grad_norm": 0.12580883502960205,
      "learning_rate": 7.177142857142858e-06,
      "loss": 0.1273,
      "step": 33660
    },
    {
      "epoch": 9.62,
      "grad_norm": 0.03041861765086651,
      "learning_rate": 7.173333333333335e-06,
      "loss": 0.118,
      "step": 33670
    },
    {
      "epoch": 9.622857142857143,
      "grad_norm": 0.0225108303129673,
      "learning_rate": 7.16952380952381e-06,
      "loss": 0.0011,
      "step": 33680
    },
    {
      "epoch": 9.625714285714286,
      "grad_norm": 0.02032736875116825,
      "learning_rate": 7.165714285714286e-06,
      "loss": 0.0275,
      "step": 33690
    },
    {
      "epoch": 9.628571428571428,
      "grad_norm": 0.003982078284025192,
      "learning_rate": 7.161904761904762e-06,
      "loss": 0.2218,
      "step": 33700
    },
    {
      "epoch": 9.631428571428572,
      "grad_norm": 0.021464044228196144,
      "learning_rate": 7.158095238095239e-06,
      "loss": 0.0006,
      "step": 33710
    },
    {
      "epoch": 9.634285714285713,
      "grad_norm": 0.031576842069625854,
      "learning_rate": 7.154285714285715e-06,
      "loss": 0.0008,
      "step": 33720
    },
    {
      "epoch": 9.637142857142857,
      "grad_norm": 0.5628494620323181,
      "learning_rate": 7.150476190476191e-06,
      "loss": 0.3985,
      "step": 33730
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.007367825135588646,
      "learning_rate": 7.146666666666667e-06,
      "loss": 0.1356,
      "step": 33740
    },
    {
      "epoch": 9.642857142857142,
      "grad_norm": 0.015636099502444267,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.0015,
      "step": 33750
    },
    {
      "epoch": 9.645714285714286,
      "grad_norm": 0.044990237802267075,
      "learning_rate": 7.13904761904762e-06,
      "loss": 0.1611,
      "step": 33760
    },
    {
      "epoch": 9.64857142857143,
      "grad_norm": 0.006083476357161999,
      "learning_rate": 7.135238095238096e-06,
      "loss": 0.2104,
      "step": 33770
    },
    {
      "epoch": 9.651428571428571,
      "grad_norm": 0.028578544035553932,
      "learning_rate": 7.131428571428573e-06,
      "loss": 0.1453,
      "step": 33780
    },
    {
      "epoch": 9.654285714285715,
      "grad_norm": 16.22845458984375,
      "learning_rate": 7.127619047619048e-06,
      "loss": 0.1374,
      "step": 33790
    },
    {
      "epoch": 9.657142857142857,
      "grad_norm": 0.056955620646476746,
      "learning_rate": 7.123809523809524e-06,
      "loss": 0.2459,
      "step": 33800
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.072275310754776,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.1526,
      "step": 33810
    },
    {
      "epoch": 9.662857142857142,
      "grad_norm": 0.26338958740234375,
      "learning_rate": 7.116190476190477e-06,
      "loss": 0.0021,
      "step": 33820
    },
    {
      "epoch": 9.665714285714285,
      "grad_norm": 0.08077264577150345,
      "learning_rate": 7.1123809523809525e-06,
      "loss": 0.1107,
      "step": 33830
    },
    {
      "epoch": 9.668571428571429,
      "grad_norm": 0.01927521638572216,
      "learning_rate": 7.108571428571429e-06,
      "loss": 0.0017,
      "step": 33840
    },
    {
      "epoch": 9.67142857142857,
      "grad_norm": 0.024896617978811264,
      "learning_rate": 7.104761904761905e-06,
      "loss": 0.1647,
      "step": 33850
    },
    {
      "epoch": 9.674285714285714,
      "grad_norm": 0.01754046604037285,
      "learning_rate": 7.100952380952382e-06,
      "loss": 0.0014,
      "step": 33860
    },
    {
      "epoch": 9.677142857142858,
      "grad_norm": 0.04889563471078873,
      "learning_rate": 7.097142857142858e-06,
      "loss": 0.0007,
      "step": 33870
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.0069297607988119125,
      "learning_rate": 7.093333333333335e-06,
      "loss": 0.1377,
      "step": 33880
    },
    {
      "epoch": 9.682857142857143,
      "grad_norm": 0.005658288486301899,
      "learning_rate": 7.08952380952381e-06,
      "loss": 0.0007,
      "step": 33890
    },
    {
      "epoch": 9.685714285714285,
      "grad_norm": 0.0016688451869413257,
      "learning_rate": 7.085714285714286e-06,
      "loss": 0.0014,
      "step": 33900
    },
    {
      "epoch": 9.688571428571429,
      "grad_norm": 0.043054450303316116,
      "learning_rate": 7.081904761904762e-06,
      "loss": 0.1414,
      "step": 33910
    },
    {
      "epoch": 9.691428571428572,
      "grad_norm": 0.004815129097551107,
      "learning_rate": 7.078095238095239e-06,
      "loss": 0.1982,
      "step": 33920
    },
    {
      "epoch": 9.694285714285714,
      "grad_norm": 0.0037754327058792114,
      "learning_rate": 7.074285714285715e-06,
      "loss": 0.0015,
      "step": 33930
    },
    {
      "epoch": 9.697142857142858,
      "grad_norm": 0.0013598210643976927,
      "learning_rate": 7.070476190476191e-06,
      "loss": 0.0093,
      "step": 33940
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.05588378384709358,
      "learning_rate": 7.066666666666667e-06,
      "loss": 0.2152,
      "step": 33950
    },
    {
      "epoch": 9.702857142857143,
      "grad_norm": 16.016687393188477,
      "learning_rate": 7.0628571428571435e-06,
      "loss": 0.2434,
      "step": 33960
    },
    {
      "epoch": 9.705714285714286,
      "grad_norm": 0.04779230058193207,
      "learning_rate": 7.05904761904762e-06,
      "loss": 0.1187,
      "step": 33970
    },
    {
      "epoch": 9.708571428571428,
      "grad_norm": 0.03913072496652603,
      "learning_rate": 7.055238095238096e-06,
      "loss": 0.2094,
      "step": 33980
    },
    {
      "epoch": 9.711428571428572,
      "grad_norm": 0.04544072225689888,
      "learning_rate": 7.051428571428573e-06,
      "loss": 0.0008,
      "step": 33990
    },
    {
      "epoch": 9.714285714285714,
      "grad_norm": 0.0052992915734648705,
      "learning_rate": 7.047619047619048e-06,
      "loss": 0.206,
      "step": 34000
    },
    {
      "epoch": 9.717142857142857,
      "grad_norm": 0.053435318171978,
      "learning_rate": 7.043809523809524e-06,
      "loss": 0.3374,
      "step": 34010
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.0013095680624246597,
      "learning_rate": 7.04e-06,
      "loss": 0.0004,
      "step": 34020
    },
    {
      "epoch": 9.722857142857142,
      "grad_norm": 0.010879225097596645,
      "learning_rate": 7.036190476190477e-06,
      "loss": 0.0012,
      "step": 34030
    },
    {
      "epoch": 9.725714285714286,
      "grad_norm": 0.2899882197380066,
      "learning_rate": 7.032380952380952e-06,
      "loss": 0.0024,
      "step": 34040
    },
    {
      "epoch": 9.728571428571428,
      "grad_norm": 0.004504442680627108,
      "learning_rate": 7.028571428571429e-06,
      "loss": 0.098,
      "step": 34050
    },
    {
      "epoch": 9.731428571428571,
      "grad_norm": 25.365924835205078,
      "learning_rate": 7.024761904761905e-06,
      "loss": 0.1135,
      "step": 34060
    },
    {
      "epoch": 9.734285714285715,
      "grad_norm": 0.0016825629863888025,
      "learning_rate": 7.020952380952382e-06,
      "loss": 0.0012,
      "step": 34070
    },
    {
      "epoch": 9.737142857142857,
      "grad_norm": 0.20878207683563232,
      "learning_rate": 7.017142857142858e-06,
      "loss": 0.0008,
      "step": 34080
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.0018218187615275383,
      "learning_rate": 7.0133333333333345e-06,
      "loss": 0.0056,
      "step": 34090
    },
    {
      "epoch": 9.742857142857144,
      "grad_norm": 0.0010130576556548476,
      "learning_rate": 7.00952380952381e-06,
      "loss": 0.2272,
      "step": 34100
    },
    {
      "epoch": 9.745714285714286,
      "grad_norm": 0.009880300611257553,
      "learning_rate": 7.0057142857142865e-06,
      "loss": 0.0002,
      "step": 34110
    },
    {
      "epoch": 9.748571428571429,
      "grad_norm": 0.0016227418091148138,
      "learning_rate": 7.001904761904762e-06,
      "loss": 0.2939,
      "step": 34120
    },
    {
      "epoch": 9.751428571428571,
      "grad_norm": 0.07408041507005692,
      "learning_rate": 6.9980952380952385e-06,
      "loss": 0.0007,
      "step": 34130
    },
    {
      "epoch": 9.754285714285714,
      "grad_norm": 0.03771466761827469,
      "learning_rate": 6.994285714285715e-06,
      "loss": 0.1561,
      "step": 34140
    },
    {
      "epoch": 9.757142857142856,
      "grad_norm": 0.26473313570022583,
      "learning_rate": 6.9904761904761905e-06,
      "loss": 0.187,
      "step": 34150
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.08565334230661392,
      "learning_rate": 6.986666666666667e-06,
      "loss": 0.098,
      "step": 34160
    },
    {
      "epoch": 9.762857142857143,
      "grad_norm": 0.05020173266530037,
      "learning_rate": 6.982857142857143e-06,
      "loss": 0.0848,
      "step": 34170
    },
    {
      "epoch": 9.765714285714285,
      "grad_norm": 0.018319621682167053,
      "learning_rate": 6.97904761904762e-06,
      "loss": 0.0012,
      "step": 34180
    },
    {
      "epoch": 9.768571428571429,
      "grad_norm": 0.001718243001960218,
      "learning_rate": 6.975238095238096e-06,
      "loss": 0.0009,
      "step": 34190
    },
    {
      "epoch": 9.771428571428572,
      "grad_norm": 0.04162365943193436,
      "learning_rate": 6.971428571428573e-06,
      "loss": 0.0007,
      "step": 34200
    },
    {
      "epoch": 9.774285714285714,
      "grad_norm": 0.0018156197620555758,
      "learning_rate": 6.967619047619048e-06,
      "loss": 0.0003,
      "step": 34210
    },
    {
      "epoch": 9.777142857142858,
      "grad_norm": 0.027899179607629776,
      "learning_rate": 6.963809523809525e-06,
      "loss": 0.146,
      "step": 34220
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.00027672055875882506,
      "learning_rate": 6.96e-06,
      "loss": 0.0005,
      "step": 34230
    },
    {
      "epoch": 9.782857142857143,
      "grad_norm": 0.0005158506100997329,
      "learning_rate": 6.956190476190477e-06,
      "loss": 0.2494,
      "step": 34240
    },
    {
      "epoch": 9.785714285714286,
      "grad_norm": 0.019772890955209732,
      "learning_rate": 6.952380952380952e-06,
      "loss": 0.1279,
      "step": 34250
    },
    {
      "epoch": 9.788571428571428,
      "grad_norm": 0.004034942947328091,
      "learning_rate": 6.948571428571429e-06,
      "loss": 0.0005,
      "step": 34260
    },
    {
      "epoch": 9.791428571428572,
      "grad_norm": 0.0449991337954998,
      "learning_rate": 6.944761904761905e-06,
      "loss": 0.1001,
      "step": 34270
    },
    {
      "epoch": 9.794285714285714,
      "grad_norm": 0.01680675894021988,
      "learning_rate": 6.9409523809523816e-06,
      "loss": 0.1196,
      "step": 34280
    },
    {
      "epoch": 9.797142857142857,
      "grad_norm": 0.0023420637007802725,
      "learning_rate": 6.937142857142858e-06,
      "loss": 0.1375,
      "step": 34290
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.001897293608635664,
      "learning_rate": 6.9333333333333344e-06,
      "loss": 0.0009,
      "step": 34300
    },
    {
      "epoch": 9.802857142857142,
      "grad_norm": 0.12324058264493942,
      "learning_rate": 6.92952380952381e-06,
      "loss": 0.5221,
      "step": 34310
    },
    {
      "epoch": 9.805714285714286,
      "grad_norm": 0.04108243063092232,
      "learning_rate": 6.9257142857142864e-06,
      "loss": 0.0006,
      "step": 34320
    },
    {
      "epoch": 9.808571428571428,
      "grad_norm": 0.259852796792984,
      "learning_rate": 6.921904761904763e-06,
      "loss": 0.0021,
      "step": 34330
    },
    {
      "epoch": 9.811428571428571,
      "grad_norm": 0.005875898990780115,
      "learning_rate": 6.9180952380952385e-06,
      "loss": 0.0011,
      "step": 34340
    },
    {
      "epoch": 9.814285714285715,
      "grad_norm": 0.027980199083685875,
      "learning_rate": 6.914285714285715e-06,
      "loss": 0.009,
      "step": 34350
    },
    {
      "epoch": 9.817142857142857,
      "grad_norm": 0.00648774579167366,
      "learning_rate": 6.9104761904761905e-06,
      "loss": 0.4728,
      "step": 34360
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.02768305502831936,
      "learning_rate": 6.906666666666667e-06,
      "loss": 0.0214,
      "step": 34370
    },
    {
      "epoch": 9.822857142857142,
      "grad_norm": 17.189558029174805,
      "learning_rate": 6.902857142857143e-06,
      "loss": 0.2527,
      "step": 34380
    },
    {
      "epoch": 9.825714285714286,
      "grad_norm": 0.19201068580150604,
      "learning_rate": 6.89904761904762e-06,
      "loss": 0.114,
      "step": 34390
    },
    {
      "epoch": 9.82857142857143,
      "grad_norm": 0.027292916551232338,
      "learning_rate": 6.895238095238096e-06,
      "loss": 0.0023,
      "step": 34400
    },
    {
      "epoch": 9.831428571428571,
      "grad_norm": 0.025126302614808083,
      "learning_rate": 6.891428571428573e-06,
      "loss": 0.1193,
      "step": 34410
    },
    {
      "epoch": 9.834285714285715,
      "grad_norm": 0.05223873630166054,
      "learning_rate": 6.887619047619048e-06,
      "loss": 0.1418,
      "step": 34420
    },
    {
      "epoch": 9.837142857142858,
      "grad_norm": 0.07642366737127304,
      "learning_rate": 6.883809523809525e-06,
      "loss": 0.0021,
      "step": 34430
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.1225448027253151,
      "learning_rate": 6.88e-06,
      "loss": 0.0017,
      "step": 34440
    },
    {
      "epoch": 9.842857142857143,
      "grad_norm": 0.07868127524852753,
      "learning_rate": 6.876190476190477e-06,
      "loss": 0.0007,
      "step": 34450
    },
    {
      "epoch": 9.845714285714285,
      "grad_norm": 0.00759706599637866,
      "learning_rate": 6.872380952380952e-06,
      "loss": 0.185,
      "step": 34460
    },
    {
      "epoch": 9.848571428571429,
      "grad_norm": 0.003438421292230487,
      "learning_rate": 6.868571428571429e-06,
      "loss": 0.1067,
      "step": 34470
    },
    {
      "epoch": 9.85142857142857,
      "grad_norm": 0.005364882759749889,
      "learning_rate": 6.864761904761905e-06,
      "loss": 0.0002,
      "step": 34480
    },
    {
      "epoch": 9.854285714285714,
      "grad_norm": 0.026896992698311806,
      "learning_rate": 6.8609523809523815e-06,
      "loss": 0.0104,
      "step": 34490
    },
    {
      "epoch": 9.857142857142858,
      "grad_norm": 0.023301564157009125,
      "learning_rate": 6.857142857142858e-06,
      "loss": 0.285,
      "step": 34500
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.029967686161398888,
      "learning_rate": 6.853333333333334e-06,
      "loss": 0.2814,
      "step": 34510
    },
    {
      "epoch": 9.862857142857143,
      "grad_norm": 0.18085502088069916,
      "learning_rate": 6.84952380952381e-06,
      "loss": 0.0018,
      "step": 34520
    },
    {
      "epoch": 9.865714285714287,
      "grad_norm": 0.0060643223114311695,
      "learning_rate": 6.845714285714286e-06,
      "loss": 0.0007,
      "step": 34530
    },
    {
      "epoch": 9.868571428571428,
      "grad_norm": 0.003187423339113593,
      "learning_rate": 6.841904761904763e-06,
      "loss": 0.0071,
      "step": 34540
    },
    {
      "epoch": 9.871428571428572,
      "grad_norm": 0.0012006264878436923,
      "learning_rate": 6.838095238095238e-06,
      "loss": 0.0003,
      "step": 34550
    },
    {
      "epoch": 9.874285714285714,
      "grad_norm": 0.002034494187682867,
      "learning_rate": 6.834285714285715e-06,
      "loss": 0.0011,
      "step": 34560
    },
    {
      "epoch": 9.877142857142857,
      "grad_norm": 0.023097319528460503,
      "learning_rate": 6.83047619047619e-06,
      "loss": 0.2635,
      "step": 34570
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.022999776527285576,
      "learning_rate": 6.826666666666667e-06,
      "loss": 0.0004,
      "step": 34580
    },
    {
      "epoch": 9.882857142857143,
      "grad_norm": 0.016625909134745598,
      "learning_rate": 6.822857142857143e-06,
      "loss": 0.0004,
      "step": 34590
    },
    {
      "epoch": 9.885714285714286,
      "grad_norm": 12.344887733459473,
      "learning_rate": 6.81904761904762e-06,
      "loss": 0.2836,
      "step": 34600
    },
    {
      "epoch": 9.888571428571428,
      "grad_norm": 0.0019851059187203646,
      "learning_rate": 6.815238095238096e-06,
      "loss": 0.0006,
      "step": 34610
    },
    {
      "epoch": 9.891428571428571,
      "grad_norm": 0.0018069252837449312,
      "learning_rate": 6.8114285714285725e-06,
      "loss": 0.0005,
      "step": 34620
    },
    {
      "epoch": 9.894285714285715,
      "grad_norm": 0.05949994549155235,
      "learning_rate": 6.807619047619048e-06,
      "loss": 0.2125,
      "step": 34630
    },
    {
      "epoch": 9.897142857142857,
      "grad_norm": 3.554090976715088,
      "learning_rate": 6.8038095238095245e-06,
      "loss": 0.002,
      "step": 34640
    },
    {
      "epoch": 9.9,
      "grad_norm": 223.3240509033203,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.3011,
      "step": 34650
    },
    {
      "epoch": 9.902857142857142,
      "grad_norm": 0.0059068575501441956,
      "learning_rate": 6.7961904761904765e-06,
      "loss": 0.0008,
      "step": 34660
    },
    {
      "epoch": 9.905714285714286,
      "grad_norm": 0.00191215961240232,
      "learning_rate": 6.792380952380952e-06,
      "loss": 0.066,
      "step": 34670
    },
    {
      "epoch": 9.90857142857143,
      "grad_norm": 0.038359135389328,
      "learning_rate": 6.7885714285714286e-06,
      "loss": 0.1524,
      "step": 34680
    },
    {
      "epoch": 9.911428571428571,
      "grad_norm": 12.51848316192627,
      "learning_rate": 6.784761904761905e-06,
      "loss": 0.2646,
      "step": 34690
    },
    {
      "epoch": 9.914285714285715,
      "grad_norm": 0.11873050034046173,
      "learning_rate": 6.780952380952381e-06,
      "loss": 0.1447,
      "step": 34700
    },
    {
      "epoch": 9.917142857142856,
      "grad_norm": 0.22232100367546082,
      "learning_rate": 6.777142857142858e-06,
      "loss": 0.0011,
      "step": 34710
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.07548878341913223,
      "learning_rate": 6.773333333333334e-06,
      "loss": 0.4089,
      "step": 34720
    },
    {
      "epoch": 9.922857142857143,
      "grad_norm": 0.07183510810136795,
      "learning_rate": 6.769523809523811e-06,
      "loss": 0.1062,
      "step": 34730
    },
    {
      "epoch": 9.925714285714285,
      "grad_norm": 0.05447342246770859,
      "learning_rate": 6.765714285714286e-06,
      "loss": 0.1269,
      "step": 34740
    },
    {
      "epoch": 9.928571428571429,
      "grad_norm": 0.1358276903629303,
      "learning_rate": 6.761904761904763e-06,
      "loss": 0.0018,
      "step": 34750
    },
    {
      "epoch": 9.93142857142857,
      "grad_norm": 0.09725916385650635,
      "learning_rate": 6.758095238095239e-06,
      "loss": 0.3047,
      "step": 34760
    },
    {
      "epoch": 9.934285714285714,
      "grad_norm": 0.17895551025867462,
      "learning_rate": 6.754285714285715e-06,
      "loss": 0.2904,
      "step": 34770
    },
    {
      "epoch": 9.937142857142858,
      "grad_norm": 0.07271237671375275,
      "learning_rate": 6.75047619047619e-06,
      "loss": 0.2504,
      "step": 34780
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.12313424795866013,
      "learning_rate": 6.746666666666667e-06,
      "loss": 0.2041,
      "step": 34790
    },
    {
      "epoch": 9.942857142857143,
      "grad_norm": 0.07163519412279129,
      "learning_rate": 6.742857142857143e-06,
      "loss": 0.2937,
      "step": 34800
    },
    {
      "epoch": 9.945714285714285,
      "grad_norm": 0.11628822982311249,
      "learning_rate": 6.73904761904762e-06,
      "loss": 0.001,
      "step": 34810
    },
    {
      "epoch": 9.948571428571428,
      "grad_norm": 35.98003387451172,
      "learning_rate": 6.735238095238096e-06,
      "loss": 0.0062,
      "step": 34820
    },
    {
      "epoch": 9.951428571428572,
      "grad_norm": 0.004701853264123201,
      "learning_rate": 6.7314285714285724e-06,
      "loss": 0.001,
      "step": 34830
    },
    {
      "epoch": 9.954285714285714,
      "grad_norm": 0.21331612765789032,
      "learning_rate": 6.727619047619048e-06,
      "loss": 0.0805,
      "step": 34840
    },
    {
      "epoch": 9.957142857142857,
      "grad_norm": 0.14990951120853424,
      "learning_rate": 6.7238095238095245e-06,
      "loss": 0.0019,
      "step": 34850
    },
    {
      "epoch": 9.96,
      "grad_norm": 0.06215615198016167,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.001,
      "step": 34860
    },
    {
      "epoch": 9.962857142857143,
      "grad_norm": 0.013847106136381626,
      "learning_rate": 6.716190476190477e-06,
      "loss": 0.0006,
      "step": 34870
    },
    {
      "epoch": 9.965714285714286,
      "grad_norm": 0.0050432076677680016,
      "learning_rate": 6.712380952380952e-06,
      "loss": 0.2165,
      "step": 34880
    },
    {
      "epoch": 9.968571428571428,
      "grad_norm": 24.364580154418945,
      "learning_rate": 6.7085714285714285e-06,
      "loss": 0.3751,
      "step": 34890
    },
    {
      "epoch": 9.971428571428572,
      "grad_norm": 0.32307738065719604,
      "learning_rate": 6.704761904761905e-06,
      "loss": 0.1367,
      "step": 34900
    },
    {
      "epoch": 9.974285714285715,
      "grad_norm": 0.3439386785030365,
      "learning_rate": 6.700952380952381e-06,
      "loss": 0.0863,
      "step": 34910
    },
    {
      "epoch": 9.977142857142857,
      "grad_norm": 0.32706379890441895,
      "learning_rate": 6.697142857142858e-06,
      "loss": 0.0019,
      "step": 34920
    },
    {
      "epoch": 9.98,
      "grad_norm": 0.0415395051240921,
      "learning_rate": 6.693333333333334e-06,
      "loss": 0.017,
      "step": 34930
    },
    {
      "epoch": 9.982857142857142,
      "grad_norm": 0.04194708168506622,
      "learning_rate": 6.689523809523811e-06,
      "loss": 0.133,
      "step": 34940
    },
    {
      "epoch": 9.985714285714286,
      "grad_norm": 0.06049978360533714,
      "learning_rate": 6.685714285714286e-06,
      "loss": 0.0009,
      "step": 34950
    },
    {
      "epoch": 9.98857142857143,
      "grad_norm": 0.03425487503409386,
      "learning_rate": 6.681904761904763e-06,
      "loss": 0.1404,
      "step": 34960
    },
    {
      "epoch": 9.991428571428571,
      "grad_norm": 0.05337958037853241,
      "learning_rate": 6.678095238095239e-06,
      "loss": 0.0005,
      "step": 34970
    },
    {
      "epoch": 9.994285714285715,
      "grad_norm": 0.0018982061883434653,
      "learning_rate": 6.6742857142857155e-06,
      "loss": 0.3789,
      "step": 34980
    },
    {
      "epoch": 9.997142857142856,
      "grad_norm": 0.10940010845661163,
      "learning_rate": 6.67047619047619e-06,
      "loss": 0.0837,
      "step": 34990
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0011548997135832906,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.1235,
      "step": 35000
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9606666666666667,
      "eval_f1": 0.8279883381924199,
      "eval_loss": 0.2066946178674698,
      "eval_precision": 0.8022598870056498,
      "eval_recall": 0.8554216867469879,
      "eval_runtime": 263.3434,
      "eval_samples_per_second": 11.392,
      "eval_steps_per_second": 2.848,
      "step": 35000
    },
    {
      "epoch": 10.002857142857144,
      "grad_norm": 0.0572655163705349,
      "learning_rate": 6.662857142857143e-06,
      "loss": 0.105,
      "step": 35010
    },
    {
      "epoch": 10.005714285714285,
      "grad_norm": 0.07282863557338715,
      "learning_rate": 6.6590476190476195e-06,
      "loss": 0.0015,
      "step": 35020
    },
    {
      "epoch": 10.008571428571429,
      "grad_norm": 0.0032419711351394653,
      "learning_rate": 6.655238095238096e-06,
      "loss": 0.0006,
      "step": 35030
    },
    {
      "epoch": 10.01142857142857,
      "grad_norm": 0.058957748115062714,
      "learning_rate": 6.651428571428572e-06,
      "loss": 0.0174,
      "step": 35040
    },
    {
      "epoch": 10.014285714285714,
      "grad_norm": 0.0017014043405652046,
      "learning_rate": 6.647619047619048e-06,
      "loss": 0.1398,
      "step": 35050
    },
    {
      "epoch": 10.017142857142858,
      "grad_norm": 0.02846459299325943,
      "learning_rate": 6.643809523809524e-06,
      "loss": 0.0317,
      "step": 35060
    },
    {
      "epoch": 10.02,
      "grad_norm": 0.0001787127403076738,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0004,
      "step": 35070
    },
    {
      "epoch": 10.022857142857143,
      "grad_norm": 15.266382217407227,
      "learning_rate": 6.636190476190477e-06,
      "loss": 0.1827,
      "step": 35080
    },
    {
      "epoch": 10.025714285714285,
      "grad_norm": 0.0029394347220659256,
      "learning_rate": 6.632380952380954e-06,
      "loss": 0.0007,
      "step": 35090
    },
    {
      "epoch": 10.028571428571428,
      "grad_norm": 0.05567339435219765,
      "learning_rate": 6.628571428571428e-06,
      "loss": 0.1474,
      "step": 35100
    },
    {
      "epoch": 10.031428571428572,
      "grad_norm": 0.14707526564598083,
      "learning_rate": 6.624761904761905e-06,
      "loss": 0.0004,
      "step": 35110
    },
    {
      "epoch": 10.034285714285714,
      "grad_norm": 0.2791277766227722,
      "learning_rate": 6.620952380952381e-06,
      "loss": 0.0006,
      "step": 35120
    },
    {
      "epoch": 10.037142857142857,
      "grad_norm": 0.09118801355361938,
      "learning_rate": 6.617142857142858e-06,
      "loss": 0.001,
      "step": 35130
    },
    {
      "epoch": 10.04,
      "grad_norm": 0.0002849471056833863,
      "learning_rate": 6.613333333333334e-06,
      "loss": 0.1565,
      "step": 35140
    },
    {
      "epoch": 10.042857142857143,
      "grad_norm": 0.029186969622969627,
      "learning_rate": 6.6095238095238105e-06,
      "loss": 0.123,
      "step": 35150
    },
    {
      "epoch": 10.045714285714286,
      "grad_norm": 0.002639933954924345,
      "learning_rate": 6.605714285714286e-06,
      "loss": 0.2355,
      "step": 35160
    },
    {
      "epoch": 10.048571428571428,
      "grad_norm": 18.423603057861328,
      "learning_rate": 6.6019047619047625e-06,
      "loss": 0.3288,
      "step": 35170
    },
    {
      "epoch": 10.051428571428572,
      "grad_norm": 0.002335392637178302,
      "learning_rate": 6.598095238095239e-06,
      "loss": 0.0005,
      "step": 35180
    },
    {
      "epoch": 10.054285714285715,
      "grad_norm": 0.00047086659469641745,
      "learning_rate": 6.594285714285715e-06,
      "loss": 0.0004,
      "step": 35190
    },
    {
      "epoch": 10.057142857142857,
      "grad_norm": 0.00010763765021692961,
      "learning_rate": 6.59047619047619e-06,
      "loss": 0.0013,
      "step": 35200
    },
    {
      "epoch": 10.06,
      "grad_norm": 0.0007816614815965295,
      "learning_rate": 6.5866666666666666e-06,
      "loss": 0.3273,
      "step": 35210
    },
    {
      "epoch": 10.062857142857142,
      "grad_norm": 0.024442657828330994,
      "learning_rate": 6.582857142857143e-06,
      "loss": 0.0174,
      "step": 35220
    },
    {
      "epoch": 10.065714285714286,
      "grad_norm": 0.03984619304537773,
      "learning_rate": 6.579047619047619e-06,
      "loss": 0.0006,
      "step": 35230
    },
    {
      "epoch": 10.06857142857143,
      "grad_norm": 0.0017425246769562364,
      "learning_rate": 6.575238095238096e-06,
      "loss": 0.1455,
      "step": 35240
    },
    {
      "epoch": 10.071428571428571,
      "grad_norm": 0.00036858185194432735,
      "learning_rate": 6.571428571428572e-06,
      "loss": 0.149,
      "step": 35250
    },
    {
      "epoch": 10.074285714285715,
      "grad_norm": 0.0004734976391773671,
      "learning_rate": 6.567619047619048e-06,
      "loss": 0.0006,
      "step": 35260
    },
    {
      "epoch": 10.077142857142857,
      "grad_norm": 0.0007887622341513634,
      "learning_rate": 6.563809523809524e-06,
      "loss": 0.001,
      "step": 35270
    },
    {
      "epoch": 10.08,
      "grad_norm": 0.15536224842071533,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.0029,
      "step": 35280
    },
    {
      "epoch": 10.082857142857144,
      "grad_norm": 1.1088263988494873,
      "learning_rate": 6.556190476190477e-06,
      "loss": 0.0931,
      "step": 35290
    },
    {
      "epoch": 10.085714285714285,
      "grad_norm": 0.009684915654361248,
      "learning_rate": 6.552380952380954e-06,
      "loss": 0.0007,
      "step": 35300
    },
    {
      "epoch": 10.088571428571429,
      "grad_norm": 0.00012098974548280239,
      "learning_rate": 6.548571428571428e-06,
      "loss": 0.0002,
      "step": 35310
    },
    {
      "epoch": 10.09142857142857,
      "grad_norm": 0.00033327375422231853,
      "learning_rate": 6.544761904761905e-06,
      "loss": 0.2079,
      "step": 35320
    },
    {
      "epoch": 10.094285714285714,
      "grad_norm": 0.0005196670535951853,
      "learning_rate": 6.540952380952381e-06,
      "loss": 0.0002,
      "step": 35330
    },
    {
      "epoch": 10.097142857142858,
      "grad_norm": 0.09535255283117294,
      "learning_rate": 6.537142857142858e-06,
      "loss": 0.0005,
      "step": 35340
    },
    {
      "epoch": 10.1,
      "grad_norm": 0.004399308934807777,
      "learning_rate": 6.533333333333334e-06,
      "loss": 0.0005,
      "step": 35350
    },
    {
      "epoch": 10.102857142857143,
      "grad_norm": 0.03996429964900017,
      "learning_rate": 6.5295238095238105e-06,
      "loss": 0.0005,
      "step": 35360
    },
    {
      "epoch": 10.105714285714285,
      "grad_norm": 0.016010865569114685,
      "learning_rate": 6.525714285714286e-06,
      "loss": 0.0005,
      "step": 35370
    },
    {
      "epoch": 10.108571428571429,
      "grad_norm": 0.01640598103404045,
      "learning_rate": 6.5219047619047625e-06,
      "loss": 0.2204,
      "step": 35380
    },
    {
      "epoch": 10.111428571428572,
      "grad_norm": 0.013842755928635597,
      "learning_rate": 6.518095238095239e-06,
      "loss": 0.2917,
      "step": 35390
    },
    {
      "epoch": 10.114285714285714,
      "grad_norm": 0.011084714904427528,
      "learning_rate": 6.514285714285715e-06,
      "loss": 0.1683,
      "step": 35400
    },
    {
      "epoch": 10.117142857142857,
      "grad_norm": 0.002974691102281213,
      "learning_rate": 6.510476190476192e-06,
      "loss": 0.0003,
      "step": 35410
    },
    {
      "epoch": 10.12,
      "grad_norm": 39.71581268310547,
      "learning_rate": 6.5066666666666665e-06,
      "loss": 0.2508,
      "step": 35420
    },
    {
      "epoch": 10.122857142857143,
      "grad_norm": 0.01268242858350277,
      "learning_rate": 6.502857142857143e-06,
      "loss": 0.0002,
      "step": 35430
    },
    {
      "epoch": 10.125714285714286,
      "grad_norm": 0.0022915774025022984,
      "learning_rate": 6.499047619047619e-06,
      "loss": 0.0003,
      "step": 35440
    },
    {
      "epoch": 10.128571428571428,
      "grad_norm": 0.01735912822186947,
      "learning_rate": 6.495238095238096e-06,
      "loss": 0.0003,
      "step": 35450
    },
    {
      "epoch": 10.131428571428572,
      "grad_norm": 0.004468526691198349,
      "learning_rate": 6.491428571428572e-06,
      "loss": 0.1047,
      "step": 35460
    },
    {
      "epoch": 10.134285714285713,
      "grad_norm": 0.01533753052353859,
      "learning_rate": 6.487619047619048e-06,
      "loss": 0.0006,
      "step": 35470
    },
    {
      "epoch": 10.137142857142857,
      "grad_norm": 0.0018959291046485305,
      "learning_rate": 6.483809523809524e-06,
      "loss": 0.0005,
      "step": 35480
    },
    {
      "epoch": 10.14,
      "grad_norm": 0.00838660728186369,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.3588,
      "step": 35490
    },
    {
      "epoch": 10.142857142857142,
      "grad_norm": 0.1279008984565735,
      "learning_rate": 6.476190476190477e-06,
      "loss": 0.0019,
      "step": 35500
    },
    {
      "epoch": 10.145714285714286,
      "grad_norm": 0.007748131174594164,
      "learning_rate": 6.4723809523809535e-06,
      "loss": 0.2696,
      "step": 35510
    },
    {
      "epoch": 10.14857142857143,
      "grad_norm": 0.004084834363311529,
      "learning_rate": 6.46857142857143e-06,
      "loss": 0.0005,
      "step": 35520
    },
    {
      "epoch": 10.151428571428571,
      "grad_norm": 0.0017785325180739164,
      "learning_rate": 6.464761904761905e-06,
      "loss": 0.0019,
      "step": 35530
    },
    {
      "epoch": 10.154285714285715,
      "grad_norm": 0.05087292939424515,
      "learning_rate": 6.460952380952381e-06,
      "loss": 0.2099,
      "step": 35540
    },
    {
      "epoch": 10.157142857142857,
      "grad_norm": 0.0028071575798094273,
      "learning_rate": 6.4571428571428575e-06,
      "loss": 0.0003,
      "step": 35550
    },
    {
      "epoch": 10.16,
      "grad_norm": 0.0020999733824282885,
      "learning_rate": 6.453333333333334e-06,
      "loss": 0.1111,
      "step": 35560
    },
    {
      "epoch": 10.162857142857144,
      "grad_norm": 0.010053304024040699,
      "learning_rate": 6.44952380952381e-06,
      "loss": 0.0002,
      "step": 35570
    },
    {
      "epoch": 10.165714285714285,
      "grad_norm": 0.00924427155405283,
      "learning_rate": 6.445714285714286e-06,
      "loss": 0.1609,
      "step": 35580
    },
    {
      "epoch": 10.168571428571429,
      "grad_norm": 0.027720503509044647,
      "learning_rate": 6.441904761904762e-06,
      "loss": 0.0063,
      "step": 35590
    },
    {
      "epoch": 10.17142857142857,
      "grad_norm": 0.01045138482004404,
      "learning_rate": 6.438095238095239e-06,
      "loss": 0.0005,
      "step": 35600
    },
    {
      "epoch": 10.174285714285714,
      "grad_norm": 0.03382948413491249,
      "learning_rate": 6.434285714285715e-06,
      "loss": 0.219,
      "step": 35610
    },
    {
      "epoch": 10.177142857142858,
      "grad_norm": 0.11807921528816223,
      "learning_rate": 6.430476190476192e-06,
      "loss": 0.1842,
      "step": 35620
    },
    {
      "epoch": 10.18,
      "grad_norm": 0.009451165795326233,
      "learning_rate": 6.426666666666668e-06,
      "loss": 0.0004,
      "step": 35630
    },
    {
      "epoch": 10.182857142857143,
      "grad_norm": 0.010899071581661701,
      "learning_rate": 6.422857142857143e-06,
      "loss": 0.0008,
      "step": 35640
    },
    {
      "epoch": 10.185714285714285,
      "grad_norm": 0.012306134216487408,
      "learning_rate": 6.419047619047619e-06,
      "loss": 0.1236,
      "step": 35650
    },
    {
      "epoch": 10.188571428571429,
      "grad_norm": 0.003833887167274952,
      "learning_rate": 6.415238095238096e-06,
      "loss": 0.1399,
      "step": 35660
    },
    {
      "epoch": 10.191428571428572,
      "grad_norm": 0.016480928286910057,
      "learning_rate": 6.411428571428572e-06,
      "loss": 0.0009,
      "step": 35670
    },
    {
      "epoch": 10.194285714285714,
      "grad_norm": 0.011169529519975185,
      "learning_rate": 6.407619047619048e-06,
      "loss": 0.4714,
      "step": 35680
    },
    {
      "epoch": 10.197142857142858,
      "grad_norm": 0.013065352104604244,
      "learning_rate": 6.403809523809524e-06,
      "loss": 0.0013,
      "step": 35690
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.11738177388906479,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0006,
      "step": 35700
    },
    {
      "epoch": 10.202857142857143,
      "grad_norm": 0.07014746963977814,
      "learning_rate": 6.396190476190477e-06,
      "loss": 0.2144,
      "step": 35710
    },
    {
      "epoch": 10.205714285714286,
      "grad_norm": 0.48055464029312134,
      "learning_rate": 6.392380952380953e-06,
      "loss": 0.1775,
      "step": 35720
    },
    {
      "epoch": 10.208571428571428,
      "grad_norm": 0.02491261437535286,
      "learning_rate": 6.38857142857143e-06,
      "loss": 0.0939,
      "step": 35730
    },
    {
      "epoch": 10.211428571428572,
      "grad_norm": 0.008912107907235622,
      "learning_rate": 6.3847619047619054e-06,
      "loss": 0.0004,
      "step": 35740
    },
    {
      "epoch": 10.214285714285714,
      "grad_norm": 0.033422499895095825,
      "learning_rate": 6.380952380952381e-06,
      "loss": 0.0013,
      "step": 35750
    },
    {
      "epoch": 10.217142857142857,
      "grad_norm": 18.898700714111328,
      "learning_rate": 6.3771428571428574e-06,
      "loss": 0.2875,
      "step": 35760
    },
    {
      "epoch": 10.22,
      "grad_norm": 0.0757150948047638,
      "learning_rate": 6.373333333333334e-06,
      "loss": 0.0354,
      "step": 35770
    },
    {
      "epoch": 10.222857142857142,
      "grad_norm": 0.0315060056746006,
      "learning_rate": 6.36952380952381e-06,
      "loss": 0.1013,
      "step": 35780
    },
    {
      "epoch": 10.225714285714286,
      "grad_norm": 0.0055282237008214,
      "learning_rate": 6.365714285714286e-06,
      "loss": 0.0008,
      "step": 35790
    },
    {
      "epoch": 10.228571428571428,
      "grad_norm": 0.012629197910428047,
      "learning_rate": 6.361904761904762e-06,
      "loss": 0.0263,
      "step": 35800
    },
    {
      "epoch": 10.231428571428571,
      "grad_norm": 0.0032247749622911215,
      "learning_rate": 6.358095238095239e-06,
      "loss": 0.0004,
      "step": 35810
    },
    {
      "epoch": 10.234285714285715,
      "grad_norm": 1.9267449378967285,
      "learning_rate": 6.354285714285715e-06,
      "loss": 0.1547,
      "step": 35820
    },
    {
      "epoch": 10.237142857142857,
      "grad_norm": 16.508983612060547,
      "learning_rate": 6.350476190476192e-06,
      "loss": 0.1312,
      "step": 35830
    },
    {
      "epoch": 10.24,
      "grad_norm": 17.708986282348633,
      "learning_rate": 6.346666666666668e-06,
      "loss": 0.2702,
      "step": 35840
    },
    {
      "epoch": 10.242857142857142,
      "grad_norm": 0.0010819934541359544,
      "learning_rate": 6.342857142857143e-06,
      "loss": 0.2335,
      "step": 35850
    },
    {
      "epoch": 10.245714285714286,
      "grad_norm": 0.07897952944040298,
      "learning_rate": 6.339047619047619e-06,
      "loss": 0.0009,
      "step": 35860
    },
    {
      "epoch": 10.248571428571429,
      "grad_norm": 0.13307546079158783,
      "learning_rate": 6.335238095238096e-06,
      "loss": 0.0018,
      "step": 35870
    },
    {
      "epoch": 10.251428571428571,
      "grad_norm": 0.001680830609984696,
      "learning_rate": 6.331428571428572e-06,
      "loss": 0.1062,
      "step": 35880
    },
    {
      "epoch": 10.254285714285714,
      "grad_norm": 0.404313862323761,
      "learning_rate": 6.327619047619048e-06,
      "loss": 0.001,
      "step": 35890
    },
    {
      "epoch": 10.257142857142856,
      "grad_norm": 0.003432959085330367,
      "learning_rate": 6.323809523809524e-06,
      "loss": 0.1166,
      "step": 35900
    },
    {
      "epoch": 10.26,
      "grad_norm": 0.04968438297510147,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0004,
      "step": 35910
    },
    {
      "epoch": 10.262857142857143,
      "grad_norm": 0.01917574182152748,
      "learning_rate": 6.316190476190477e-06,
      "loss": 0.1074,
      "step": 35920
    },
    {
      "epoch": 10.265714285714285,
      "grad_norm": 0.35631412267684937,
      "learning_rate": 6.312380952380953e-06,
      "loss": 0.0008,
      "step": 35930
    },
    {
      "epoch": 10.268571428571429,
      "grad_norm": 0.10021889954805374,
      "learning_rate": 6.30857142857143e-06,
      "loss": 0.0007,
      "step": 35940
    },
    {
      "epoch": 10.271428571428572,
      "grad_norm": 0.01099391933530569,
      "learning_rate": 6.304761904761905e-06,
      "loss": 0.0007,
      "step": 35950
    },
    {
      "epoch": 10.274285714285714,
      "grad_norm": 0.0005064538563601673,
      "learning_rate": 6.300952380952381e-06,
      "loss": 0.0004,
      "step": 35960
    },
    {
      "epoch": 10.277142857142858,
      "grad_norm": 0.009283001534640789,
      "learning_rate": 6.297142857142857e-06,
      "loss": 0.0003,
      "step": 35970
    },
    {
      "epoch": 10.28,
      "grad_norm": 0.020714813843369484,
      "learning_rate": 6.293333333333334e-06,
      "loss": 0.0002,
      "step": 35980
    },
    {
      "epoch": 10.282857142857143,
      "grad_norm": 0.0003073696861974895,
      "learning_rate": 6.28952380952381e-06,
      "loss": 0.001,
      "step": 35990
    },
    {
      "epoch": 10.285714285714286,
      "grad_norm": 0.0009783472632989287,
      "learning_rate": 6.285714285714286e-06,
      "loss": 0.1364,
      "step": 36000
    },
    {
      "epoch": 10.288571428571428,
      "grad_norm": 0.002640131628140807,
      "learning_rate": 6.281904761904762e-06,
      "loss": 0.2352,
      "step": 36010
    },
    {
      "epoch": 10.291428571428572,
      "grad_norm": 0.0004481571668293327,
      "learning_rate": 6.278095238095239e-06,
      "loss": 0.0006,
      "step": 36020
    },
    {
      "epoch": 10.294285714285714,
      "grad_norm": 0.011484202928841114,
      "learning_rate": 6.274285714285715e-06,
      "loss": 0.2295,
      "step": 36030
    },
    {
      "epoch": 10.297142857142857,
      "grad_norm": 0.2223968356847763,
      "learning_rate": 6.2704761904761915e-06,
      "loss": 0.2964,
      "step": 36040
    },
    {
      "epoch": 10.3,
      "grad_norm": 0.0012932101963087916,
      "learning_rate": 6.266666666666668e-06,
      "loss": 0.3293,
      "step": 36050
    },
    {
      "epoch": 10.302857142857142,
      "grad_norm": 0.0031762411817908287,
      "learning_rate": 6.2628571428571435e-06,
      "loss": 0.2084,
      "step": 36060
    },
    {
      "epoch": 10.305714285714286,
      "grad_norm": 41.64879608154297,
      "learning_rate": 6.259047619047619e-06,
      "loss": 0.1868,
      "step": 36070
    },
    {
      "epoch": 10.308571428571428,
      "grad_norm": 0.007304003462195396,
      "learning_rate": 6.2552380952380955e-06,
      "loss": 0.0758,
      "step": 36080
    },
    {
      "epoch": 10.311428571428571,
      "grad_norm": 10.818126678466797,
      "learning_rate": 6.251428571428572e-06,
      "loss": 0.3449,
      "step": 36090
    },
    {
      "epoch": 10.314285714285715,
      "grad_norm": 0.0032196911051869392,
      "learning_rate": 6.2476190476190475e-06,
      "loss": 0.1596,
      "step": 36100
    },
    {
      "epoch": 10.317142857142857,
      "grad_norm": 0.4406656324863434,
      "learning_rate": 6.243809523809524e-06,
      "loss": 0.1025,
      "step": 36110
    },
    {
      "epoch": 10.32,
      "grad_norm": 0.6260091066360474,
      "learning_rate": 6.24e-06,
      "loss": 0.0019,
      "step": 36120
    },
    {
      "epoch": 10.322857142857142,
      "grad_norm": 0.011854053474962711,
      "learning_rate": 6.236190476190477e-06,
      "loss": 0.0862,
      "step": 36130
    },
    {
      "epoch": 10.325714285714286,
      "grad_norm": 0.12256351858377457,
      "learning_rate": 6.232380952380953e-06,
      "loss": 0.0008,
      "step": 36140
    },
    {
      "epoch": 10.32857142857143,
      "grad_norm": 0.0006587541429325938,
      "learning_rate": 6.22857142857143e-06,
      "loss": 0.0015,
      "step": 36150
    },
    {
      "epoch": 10.331428571428571,
      "grad_norm": 0.0012389562325552106,
      "learning_rate": 6.224761904761905e-06,
      "loss": 0.0001,
      "step": 36160
    },
    {
      "epoch": 10.334285714285715,
      "grad_norm": 0.14033900201320648,
      "learning_rate": 6.220952380952382e-06,
      "loss": 0.2425,
      "step": 36170
    },
    {
      "epoch": 10.337142857142856,
      "grad_norm": 19.05916404724121,
      "learning_rate": 6.217142857142857e-06,
      "loss": 0.1464,
      "step": 36180
    },
    {
      "epoch": 10.34,
      "grad_norm": 0.0033637816086411476,
      "learning_rate": 6.213333333333334e-06,
      "loss": 0.0003,
      "step": 36190
    },
    {
      "epoch": 10.342857142857143,
      "grad_norm": 0.015993332490324974,
      "learning_rate": 6.20952380952381e-06,
      "loss": 0.086,
      "step": 36200
    },
    {
      "epoch": 10.345714285714285,
      "grad_norm": 0.02426140382885933,
      "learning_rate": 6.205714285714286e-06,
      "loss": 0.0299,
      "step": 36210
    },
    {
      "epoch": 10.348571428571429,
      "grad_norm": 0.012423249892890453,
      "learning_rate": 6.201904761904762e-06,
      "loss": 0.1199,
      "step": 36220
    },
    {
      "epoch": 10.35142857142857,
      "grad_norm": 0.01504901610314846,
      "learning_rate": 6.1980952380952386e-06,
      "loss": 0.0001,
      "step": 36230
    },
    {
      "epoch": 10.354285714285714,
      "grad_norm": 0.4005589485168457,
      "learning_rate": 6.194285714285715e-06,
      "loss": 0.0009,
      "step": 36240
    },
    {
      "epoch": 10.357142857142858,
      "grad_norm": 0.014139799401164055,
      "learning_rate": 6.1904761904761914e-06,
      "loss": 0.0002,
      "step": 36250
    },
    {
      "epoch": 10.36,
      "grad_norm": 0.005949382204562426,
      "learning_rate": 6.186666666666668e-06,
      "loss": 0.0001,
      "step": 36260
    },
    {
      "epoch": 10.362857142857143,
      "grad_norm": 0.21505804359912872,
      "learning_rate": 6.1828571428571434e-06,
      "loss": 0.1732,
      "step": 36270
    },
    {
      "epoch": 10.365714285714287,
      "grad_norm": 0.07998597621917725,
      "learning_rate": 6.17904761904762e-06,
      "loss": 0.0005,
      "step": 36280
    },
    {
      "epoch": 10.368571428571428,
      "grad_norm": 0.0012835926609113812,
      "learning_rate": 6.1752380952380954e-06,
      "loss": 0.0003,
      "step": 36290
    },
    {
      "epoch": 10.371428571428572,
      "grad_norm": 0.005870528984814882,
      "learning_rate": 6.171428571428572e-06,
      "loss": 0.0004,
      "step": 36300
    },
    {
      "epoch": 10.374285714285714,
      "grad_norm": 0.12080512940883636,
      "learning_rate": 6.1676190476190475e-06,
      "loss": 0.0004,
      "step": 36310
    },
    {
      "epoch": 10.377142857142857,
      "grad_norm": 0.019793260842561722,
      "learning_rate": 6.163809523809524e-06,
      "loss": 0.0001,
      "step": 36320
    },
    {
      "epoch": 10.38,
      "grad_norm": 0.0012256309855729342,
      "learning_rate": 6.16e-06,
      "loss": 0.0051,
      "step": 36330
    },
    {
      "epoch": 10.382857142857143,
      "grad_norm": 0.00022216059733182192,
      "learning_rate": 6.156190476190477e-06,
      "loss": 0.0005,
      "step": 36340
    },
    {
      "epoch": 10.385714285714286,
      "grad_norm": 0.004638961050659418,
      "learning_rate": 6.152380952380953e-06,
      "loss": 0.0002,
      "step": 36350
    },
    {
      "epoch": 10.388571428571428,
      "grad_norm": 0.09826706349849701,
      "learning_rate": 6.14857142857143e-06,
      "loss": 0.0001,
      "step": 36360
    },
    {
      "epoch": 10.391428571428571,
      "grad_norm": 0.0026879720389842987,
      "learning_rate": 6.144761904761905e-06,
      "loss": 0.0002,
      "step": 36370
    },
    {
      "epoch": 10.394285714285715,
      "grad_norm": 0.0008386804256588221,
      "learning_rate": 6.140952380952382e-06,
      "loss": 0.3246,
      "step": 36380
    },
    {
      "epoch": 10.397142857142857,
      "grad_norm": 1.3469829559326172,
      "learning_rate": 6.137142857142858e-06,
      "loss": 0.0017,
      "step": 36390
    },
    {
      "epoch": 10.4,
      "grad_norm": 21.453702926635742,
      "learning_rate": 6.133333333333334e-06,
      "loss": 0.4261,
      "step": 36400
    },
    {
      "epoch": 10.402857142857142,
      "grad_norm": 0.005758012179285288,
      "learning_rate": 6.12952380952381e-06,
      "loss": 0.0352,
      "step": 36410
    },
    {
      "epoch": 10.405714285714286,
      "grad_norm": 0.002637887140735984,
      "learning_rate": 6.125714285714286e-06,
      "loss": 0.0002,
      "step": 36420
    },
    {
      "epoch": 10.40857142857143,
      "grad_norm": 0.029665863141417503,
      "learning_rate": 6.121904761904762e-06,
      "loss": 0.3467,
      "step": 36430
    },
    {
      "epoch": 10.411428571428571,
      "grad_norm": 0.02171577885746956,
      "learning_rate": 6.1180952380952385e-06,
      "loss": 0.2565,
      "step": 36440
    },
    {
      "epoch": 10.414285714285715,
      "grad_norm": 18.827768325805664,
      "learning_rate": 6.114285714285715e-06,
      "loss": 0.0043,
      "step": 36450
    },
    {
      "epoch": 10.417142857142856,
      "grad_norm": 12.172526359558105,
      "learning_rate": 6.110476190476191e-06,
      "loss": 0.1111,
      "step": 36460
    },
    {
      "epoch": 10.42,
      "grad_norm": 0.004713800270110369,
      "learning_rate": 6.106666666666668e-06,
      "loss": 0.0008,
      "step": 36470
    },
    {
      "epoch": 10.422857142857143,
      "grad_norm": 0.005002954509109259,
      "learning_rate": 6.102857142857143e-06,
      "loss": 0.119,
      "step": 36480
    },
    {
      "epoch": 10.425714285714285,
      "grad_norm": 0.0015333266928792,
      "learning_rate": 6.09904761904762e-06,
      "loss": 0.1151,
      "step": 36490
    },
    {
      "epoch": 10.428571428571429,
      "grad_norm": 0.044314827769994736,
      "learning_rate": 6.095238095238096e-06,
      "loss": 0.0011,
      "step": 36500
    },
    {
      "epoch": 10.43142857142857,
      "grad_norm": 0.05372640863060951,
      "learning_rate": 6.091428571428572e-06,
      "loss": 0.1045,
      "step": 36510
    },
    {
      "epoch": 10.434285714285714,
      "grad_norm": 0.04951940104365349,
      "learning_rate": 6.087619047619047e-06,
      "loss": 0.136,
      "step": 36520
    },
    {
      "epoch": 10.437142857142858,
      "grad_norm": 0.000924882129766047,
      "learning_rate": 6.083809523809524e-06,
      "loss": 0.0468,
      "step": 36530
    },
    {
      "epoch": 10.44,
      "grad_norm": 0.002030218718573451,
      "learning_rate": 6.08e-06,
      "loss": 0.0008,
      "step": 36540
    },
    {
      "epoch": 10.442857142857143,
      "grad_norm": 0.022998040542006493,
      "learning_rate": 6.076190476190477e-06,
      "loss": 0.0007,
      "step": 36550
    },
    {
      "epoch": 10.445714285714285,
      "grad_norm": 0.04938901960849762,
      "learning_rate": 6.072380952380953e-06,
      "loss": 0.0973,
      "step": 36560
    },
    {
      "epoch": 10.448571428571428,
      "grad_norm": 0.008012575097382069,
      "learning_rate": 6.0685714285714295e-06,
      "loss": 0.001,
      "step": 36570
    },
    {
      "epoch": 10.451428571428572,
      "grad_norm": 13.754359245300293,
      "learning_rate": 6.064761904761905e-06,
      "loss": 0.2778,
      "step": 36580
    },
    {
      "epoch": 10.454285714285714,
      "grad_norm": 0.001042104559019208,
      "learning_rate": 6.0609523809523815e-06,
      "loss": 0.1874,
      "step": 36590
    },
    {
      "epoch": 10.457142857142857,
      "grad_norm": 0.038990799337625504,
      "learning_rate": 6.057142857142858e-06,
      "loss": 0.0074,
      "step": 36600
    },
    {
      "epoch": 10.46,
      "grad_norm": 0.046777982264757156,
      "learning_rate": 6.0533333333333335e-06,
      "loss": 0.0009,
      "step": 36610
    },
    {
      "epoch": 10.462857142857143,
      "grad_norm": 0.05289669334888458,
      "learning_rate": 6.04952380952381e-06,
      "loss": 0.1935,
      "step": 36620
    },
    {
      "epoch": 10.465714285714286,
      "grad_norm": 15.029454231262207,
      "learning_rate": 6.0457142857142855e-06,
      "loss": 0.0918,
      "step": 36630
    },
    {
      "epoch": 10.468571428571428,
      "grad_norm": 0.9316242337226868,
      "learning_rate": 6.041904761904762e-06,
      "loss": 0.0584,
      "step": 36640
    },
    {
      "epoch": 10.471428571428572,
      "grad_norm": 0.001131687080487609,
      "learning_rate": 6.038095238095238e-06,
      "loss": 0.0036,
      "step": 36650
    },
    {
      "epoch": 10.474285714285715,
      "grad_norm": 0.022177692502737045,
      "learning_rate": 6.034285714285715e-06,
      "loss": 0.002,
      "step": 36660
    },
    {
      "epoch": 10.477142857142857,
      "grad_norm": 0.14407233893871307,
      "learning_rate": 6.030476190476191e-06,
      "loss": 0.0004,
      "step": 36670
    },
    {
      "epoch": 10.48,
      "grad_norm": 0.0009734848863445222,
      "learning_rate": 6.026666666666668e-06,
      "loss": 0.1664,
      "step": 36680
    },
    {
      "epoch": 10.482857142857142,
      "grad_norm": 6.650953769683838,
      "learning_rate": 6.022857142857143e-06,
      "loss": 0.0032,
      "step": 36690
    },
    {
      "epoch": 10.485714285714286,
      "grad_norm": 0.002563088433817029,
      "learning_rate": 6.01904761904762e-06,
      "loss": 0.0012,
      "step": 36700
    },
    {
      "epoch": 10.48857142857143,
      "grad_norm": 0.0001621367409825325,
      "learning_rate": 6.015238095238096e-06,
      "loss": 0.1328,
      "step": 36710
    },
    {
      "epoch": 10.491428571428571,
      "grad_norm": 0.002026007743552327,
      "learning_rate": 6.011428571428572e-06,
      "loss": 0.1976,
      "step": 36720
    },
    {
      "epoch": 10.494285714285715,
      "grad_norm": 0.01760794408619404,
      "learning_rate": 6.007619047619047e-06,
      "loss": 0.3722,
      "step": 36730
    },
    {
      "epoch": 10.497142857142856,
      "grad_norm": 36.04584884643555,
      "learning_rate": 6.003809523809524e-06,
      "loss": 0.0603,
      "step": 36740
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.0007147739524953067,
      "learning_rate": 6e-06,
      "loss": 0.002,
      "step": 36750
    },
    {
      "epoch": 10.502857142857144,
      "grad_norm": 4.964921951293945,
      "learning_rate": 5.996190476190477e-06,
      "loss": 0.1585,
      "step": 36760
    },
    {
      "epoch": 10.505714285714285,
      "grad_norm": 0.0025526853278279305,
      "learning_rate": 5.992380952380953e-06,
      "loss": 0.0003,
      "step": 36770
    },
    {
      "epoch": 10.508571428571429,
      "grad_norm": 15.260412216186523,
      "learning_rate": 5.9885714285714294e-06,
      "loss": 0.1577,
      "step": 36780
    },
    {
      "epoch": 10.51142857142857,
      "grad_norm": 0.0007681236602365971,
      "learning_rate": 5.984761904761905e-06,
      "loss": 0.1633,
      "step": 36790
    },
    {
      "epoch": 10.514285714285714,
      "grad_norm": 0.005926643032580614,
      "learning_rate": 5.9809523809523814e-06,
      "loss": 0.2004,
      "step": 36800
    },
    {
      "epoch": 10.517142857142858,
      "grad_norm": 0.009335329756140709,
      "learning_rate": 5.977142857142858e-06,
      "loss": 0.0885,
      "step": 36810
    },
    {
      "epoch": 10.52,
      "grad_norm": 0.039875328540802,
      "learning_rate": 5.973333333333334e-06,
      "loss": 0.0112,
      "step": 36820
    },
    {
      "epoch": 10.522857142857143,
      "grad_norm": 0.05998462438583374,
      "learning_rate": 5.96952380952381e-06,
      "loss": 0.0003,
      "step": 36830
    },
    {
      "epoch": 10.525714285714285,
      "grad_norm": 0.05400078371167183,
      "learning_rate": 5.9657142857142855e-06,
      "loss": 0.1475,
      "step": 36840
    },
    {
      "epoch": 10.528571428571428,
      "grad_norm": 0.028844201937317848,
      "learning_rate": 5.961904761904762e-06,
      "loss": 0.1034,
      "step": 36850
    },
    {
      "epoch": 10.531428571428572,
      "grad_norm": 0.005037332884967327,
      "learning_rate": 5.958095238095238e-06,
      "loss": 0.1113,
      "step": 36860
    },
    {
      "epoch": 10.534285714285714,
      "grad_norm": 0.031122174113988876,
      "learning_rate": 5.954285714285715e-06,
      "loss": 0.0011,
      "step": 36870
    },
    {
      "epoch": 10.537142857142857,
      "grad_norm": 0.005947253201156855,
      "learning_rate": 5.950476190476191e-06,
      "loss": 0.1972,
      "step": 36880
    },
    {
      "epoch": 10.54,
      "grad_norm": 0.020656771957874298,
      "learning_rate": 5.946666666666668e-06,
      "loss": 0.0006,
      "step": 36890
    },
    {
      "epoch": 10.542857142857143,
      "grad_norm": 0.001123633817769587,
      "learning_rate": 5.942857142857143e-06,
      "loss": 0.2214,
      "step": 36900
    },
    {
      "epoch": 10.545714285714286,
      "grad_norm": 0.10696061700582504,
      "learning_rate": 5.93904761904762e-06,
      "loss": 0.0015,
      "step": 36910
    },
    {
      "epoch": 10.548571428571428,
      "grad_norm": 0.056651219725608826,
      "learning_rate": 5.935238095238096e-06,
      "loss": 0.1237,
      "step": 36920
    },
    {
      "epoch": 10.551428571428572,
      "grad_norm": 0.024057982489466667,
      "learning_rate": 5.9314285714285725e-06,
      "loss": 0.2913,
      "step": 36930
    },
    {
      "epoch": 10.554285714285715,
      "grad_norm": 0.005727668758481741,
      "learning_rate": 5.927619047619047e-06,
      "loss": 0.0901,
      "step": 36940
    },
    {
      "epoch": 10.557142857142857,
      "grad_norm": 13.000914573669434,
      "learning_rate": 5.923809523809524e-06,
      "loss": 0.084,
      "step": 36950
    },
    {
      "epoch": 10.56,
      "grad_norm": 0.11046942323446274,
      "learning_rate": 5.92e-06,
      "loss": 0.0997,
      "step": 36960
    },
    {
      "epoch": 10.562857142857142,
      "grad_norm": 0.01347813755273819,
      "learning_rate": 5.9161904761904765e-06,
      "loss": 0.1967,
      "step": 36970
    },
    {
      "epoch": 10.565714285714286,
      "grad_norm": 0.008994016796350479,
      "learning_rate": 5.912380952380953e-06,
      "loss": 0.3001,
      "step": 36980
    },
    {
      "epoch": 10.56857142857143,
      "grad_norm": 0.008706602267920971,
      "learning_rate": 5.908571428571429e-06,
      "loss": 0.1615,
      "step": 36990
    },
    {
      "epoch": 10.571428571428571,
      "grad_norm": 0.15012508630752563,
      "learning_rate": 5.904761904761905e-06,
      "loss": 0.0025,
      "step": 37000
    },
    {
      "epoch": 10.574285714285715,
      "grad_norm": 0.041221801191568375,
      "learning_rate": 5.900952380952381e-06,
      "loss": 0.1323,
      "step": 37010
    },
    {
      "epoch": 10.577142857142857,
      "grad_norm": 0.0027330771554261446,
      "learning_rate": 5.897142857142858e-06,
      "loss": 0.0039,
      "step": 37020
    },
    {
      "epoch": 10.58,
      "grad_norm": 0.0037480106111615896,
      "learning_rate": 5.893333333333334e-06,
      "loss": 0.0015,
      "step": 37030
    },
    {
      "epoch": 10.582857142857144,
      "grad_norm": 0.0008396741468459368,
      "learning_rate": 5.889523809523811e-06,
      "loss": 0.1214,
      "step": 37040
    },
    {
      "epoch": 10.585714285714285,
      "grad_norm": 0.03969864174723625,
      "learning_rate": 5.885714285714285e-06,
      "loss": 0.2041,
      "step": 37050
    },
    {
      "epoch": 10.588571428571429,
      "grad_norm": 0.5087277293205261,
      "learning_rate": 5.881904761904762e-06,
      "loss": 0.0015,
      "step": 37060
    },
    {
      "epoch": 10.59142857142857,
      "grad_norm": 0.025690697133541107,
      "learning_rate": 5.878095238095238e-06,
      "loss": 0.3109,
      "step": 37070
    },
    {
      "epoch": 10.594285714285714,
      "grad_norm": 0.034953247755765915,
      "learning_rate": 5.874285714285715e-06,
      "loss": 0.0004,
      "step": 37080
    },
    {
      "epoch": 10.597142857142858,
      "grad_norm": 15.672508239746094,
      "learning_rate": 5.870476190476191e-06,
      "loss": 0.184,
      "step": 37090
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.0466410256922245,
      "learning_rate": 5.8666666666666675e-06,
      "loss": 0.001,
      "step": 37100
    },
    {
      "epoch": 10.602857142857143,
      "grad_norm": 0.02953433245420456,
      "learning_rate": 5.862857142857143e-06,
      "loss": 0.133,
      "step": 37110
    },
    {
      "epoch": 10.605714285714285,
      "grad_norm": 0.010307108983397484,
      "learning_rate": 5.8590476190476195e-06,
      "loss": 0.1202,
      "step": 37120
    },
    {
      "epoch": 10.608571428571429,
      "grad_norm": 0.24710629880428314,
      "learning_rate": 5.855238095238096e-06,
      "loss": 0.2101,
      "step": 37130
    },
    {
      "epoch": 10.611428571428572,
      "grad_norm": 0.04115322604775429,
      "learning_rate": 5.851428571428572e-06,
      "loss": 0.2298,
      "step": 37140
    },
    {
      "epoch": 10.614285714285714,
      "grad_norm": 0.03329325094819069,
      "learning_rate": 5.847619047619049e-06,
      "loss": 0.1264,
      "step": 37150
    },
    {
      "epoch": 10.617142857142857,
      "grad_norm": 0.1338702142238617,
      "learning_rate": 5.8438095238095236e-06,
      "loss": 0.0018,
      "step": 37160
    },
    {
      "epoch": 10.62,
      "grad_norm": 0.6715512871742249,
      "learning_rate": 5.84e-06,
      "loss": 0.0793,
      "step": 37170
    },
    {
      "epoch": 10.622857142857143,
      "grad_norm": 0.018544096499681473,
      "learning_rate": 5.836190476190476e-06,
      "loss": 0.0018,
      "step": 37180
    },
    {
      "epoch": 10.625714285714286,
      "grad_norm": 0.00513578811660409,
      "learning_rate": 5.832380952380953e-06,
      "loss": 0.0973,
      "step": 37190
    },
    {
      "epoch": 10.628571428571428,
      "grad_norm": 0.03855745866894722,
      "learning_rate": 5.828571428571429e-06,
      "loss": 0.0236,
      "step": 37200
    },
    {
      "epoch": 10.631428571428572,
      "grad_norm": 0.018162012100219727,
      "learning_rate": 5.824761904761906e-06,
      "loss": 0.098,
      "step": 37210
    },
    {
      "epoch": 10.634285714285713,
      "grad_norm": 0.01703152060508728,
      "learning_rate": 5.820952380952381e-06,
      "loss": 0.0982,
      "step": 37220
    },
    {
      "epoch": 10.637142857142857,
      "grad_norm": 0.009348330087959766,
      "learning_rate": 5.817142857142858e-06,
      "loss": 0.2527,
      "step": 37230
    },
    {
      "epoch": 10.64,
      "grad_norm": 0.014405720867216587,
      "learning_rate": 5.813333333333334e-06,
      "loss": 0.0005,
      "step": 37240
    },
    {
      "epoch": 10.642857142857142,
      "grad_norm": 0.004106427077203989,
      "learning_rate": 5.8095238095238106e-06,
      "loss": 0.0003,
      "step": 37250
    },
    {
      "epoch": 10.645714285714286,
      "grad_norm": 0.005904064513742924,
      "learning_rate": 5.805714285714285e-06,
      "loss": 0.0005,
      "step": 37260
    },
    {
      "epoch": 10.64857142857143,
      "grad_norm": 0.018523341044783592,
      "learning_rate": 5.801904761904762e-06,
      "loss": 0.0038,
      "step": 37270
    },
    {
      "epoch": 10.651428571428571,
      "grad_norm": 0.0011620414443314075,
      "learning_rate": 5.798095238095238e-06,
      "loss": 0.1617,
      "step": 37280
    },
    {
      "epoch": 10.654285714285715,
      "grad_norm": 0.026650462299585342,
      "learning_rate": 5.794285714285715e-06,
      "loss": 0.0023,
      "step": 37290
    },
    {
      "epoch": 10.657142857142857,
      "grad_norm": 0.0012249271385371685,
      "learning_rate": 5.790476190476191e-06,
      "loss": 0.0008,
      "step": 37300
    },
    {
      "epoch": 10.66,
      "grad_norm": 0.04798109829425812,
      "learning_rate": 5.7866666666666674e-06,
      "loss": 0.0011,
      "step": 37310
    },
    {
      "epoch": 10.662857142857142,
      "grad_norm": 0.0011897346703335643,
      "learning_rate": 5.782857142857143e-06,
      "loss": 0.0007,
      "step": 37320
    },
    {
      "epoch": 10.665714285714285,
      "grad_norm": 0.03495841100811958,
      "learning_rate": 5.7790476190476195e-06,
      "loss": 0.0001,
      "step": 37330
    },
    {
      "epoch": 10.668571428571429,
      "grad_norm": 0.042774125933647156,
      "learning_rate": 5.775238095238096e-06,
      "loss": 0.0004,
      "step": 37340
    },
    {
      "epoch": 10.67142857142857,
      "grad_norm": 0.021483344957232475,
      "learning_rate": 5.771428571428572e-06,
      "loss": 0.0006,
      "step": 37350
    },
    {
      "epoch": 10.674285714285714,
      "grad_norm": 0.008550044149160385,
      "learning_rate": 5.767619047619049e-06,
      "loss": 0.0001,
      "step": 37360
    },
    {
      "epoch": 10.677142857142858,
      "grad_norm": 0.000502034614328295,
      "learning_rate": 5.7638095238095235e-06,
      "loss": 0.1794,
      "step": 37370
    },
    {
      "epoch": 10.68,
      "grad_norm": 78.03140258789062,
      "learning_rate": 5.76e-06,
      "loss": 0.1239,
      "step": 37380
    },
    {
      "epoch": 10.682857142857143,
      "grad_norm": 0.1328212171792984,
      "learning_rate": 5.756190476190476e-06,
      "loss": 0.0005,
      "step": 37390
    },
    {
      "epoch": 10.685714285714285,
      "grad_norm": 0.010356303304433823,
      "learning_rate": 5.752380952380953e-06,
      "loss": 0.0002,
      "step": 37400
    },
    {
      "epoch": 10.688571428571429,
      "grad_norm": 0.0378001406788826,
      "learning_rate": 5.748571428571429e-06,
      "loss": 0.1693,
      "step": 37410
    },
    {
      "epoch": 10.691428571428572,
      "grad_norm": 0.005849090870469809,
      "learning_rate": 5.744761904761906e-06,
      "loss": 0.1524,
      "step": 37420
    },
    {
      "epoch": 10.694285714285714,
      "grad_norm": 0.009260399267077446,
      "learning_rate": 5.740952380952381e-06,
      "loss": 0.1722,
      "step": 37430
    },
    {
      "epoch": 10.697142857142858,
      "grad_norm": 0.010499934665858746,
      "learning_rate": 5.737142857142858e-06,
      "loss": 0.0007,
      "step": 37440
    },
    {
      "epoch": 10.7,
      "grad_norm": 0.0038605218287557364,
      "learning_rate": 5.733333333333334e-06,
      "loss": 0.0005,
      "step": 37450
    },
    {
      "epoch": 10.702857142857143,
      "grad_norm": 0.013884860090911388,
      "learning_rate": 5.7295238095238105e-06,
      "loss": 0.0007,
      "step": 37460
    },
    {
      "epoch": 10.705714285714286,
      "grad_norm": 0.003943481016904116,
      "learning_rate": 5.725714285714287e-06,
      "loss": 0.0004,
      "step": 37470
    },
    {
      "epoch": 10.708571428571428,
      "grad_norm": 0.0018262354424223304,
      "learning_rate": 5.721904761904762e-06,
      "loss": 0.123,
      "step": 37480
    },
    {
      "epoch": 10.711428571428572,
      "grad_norm": 0.49207666516304016,
      "learning_rate": 5.718095238095238e-06,
      "loss": 0.5158,
      "step": 37490
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.0019030339317396283,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.0002,
      "step": 37500
    },
    {
      "epoch": 10.717142857142857,
      "grad_norm": 0.02904410846531391,
      "learning_rate": 5.710476190476191e-06,
      "loss": 0.408,
      "step": 37510
    },
    {
      "epoch": 10.72,
      "grad_norm": 0.06392975151538849,
      "learning_rate": 5.706666666666667e-06,
      "loss": 0.1415,
      "step": 37520
    },
    {
      "epoch": 10.722857142857142,
      "grad_norm": 0.015093768015503883,
      "learning_rate": 5.702857142857143e-06,
      "loss": 0.0006,
      "step": 37530
    },
    {
      "epoch": 10.725714285714286,
      "grad_norm": 0.019552143290638924,
      "learning_rate": 5.699047619047619e-06,
      "loss": 0.0005,
      "step": 37540
    },
    {
      "epoch": 10.728571428571428,
      "grad_norm": 0.0018540722085162997,
      "learning_rate": 5.695238095238096e-06,
      "loss": 0.0008,
      "step": 37550
    },
    {
      "epoch": 10.731428571428571,
      "grad_norm": 0.0006594988517463207,
      "learning_rate": 5.691428571428572e-06,
      "loss": 0.3607,
      "step": 37560
    },
    {
      "epoch": 10.734285714285715,
      "grad_norm": 24.793216705322266,
      "learning_rate": 5.687619047619049e-06,
      "loss": 0.1459,
      "step": 37570
    },
    {
      "epoch": 10.737142857142857,
      "grad_norm": 0.025007326155900955,
      "learning_rate": 5.683809523809525e-06,
      "loss": 0.1926,
      "step": 37580
    },
    {
      "epoch": 10.74,
      "grad_norm": 0.18758782744407654,
      "learning_rate": 5.68e-06,
      "loss": 0.1223,
      "step": 37590
    },
    {
      "epoch": 10.742857142857144,
      "grad_norm": 0.0002171261585317552,
      "learning_rate": 5.676190476190476e-06,
      "loss": 0.0958,
      "step": 37600
    },
    {
      "epoch": 10.745714285714286,
      "grad_norm": 0.13090629875659943,
      "learning_rate": 5.672380952380953e-06,
      "loss": 0.0014,
      "step": 37610
    },
    {
      "epoch": 10.748571428571429,
      "grad_norm": 0.01815825141966343,
      "learning_rate": 5.668571428571429e-06,
      "loss": 0.0204,
      "step": 37620
    },
    {
      "epoch": 10.751428571428571,
      "grad_norm": 0.00023252476239576936,
      "learning_rate": 5.6647619047619055e-06,
      "loss": 0.1302,
      "step": 37630
    },
    {
      "epoch": 10.754285714285714,
      "grad_norm": 0.053002070635557175,
      "learning_rate": 5.660952380952381e-06,
      "loss": 0.0007,
      "step": 37640
    },
    {
      "epoch": 10.757142857142856,
      "grad_norm": 0.01967480219900608,
      "learning_rate": 5.6571428571428576e-06,
      "loss": 0.1438,
      "step": 37650
    },
    {
      "epoch": 10.76,
      "grad_norm": 0.017543300986289978,
      "learning_rate": 5.653333333333334e-06,
      "loss": 0.0006,
      "step": 37660
    },
    {
      "epoch": 10.762857142857143,
      "grad_norm": 0.000520937202963978,
      "learning_rate": 5.64952380952381e-06,
      "loss": 0.1053,
      "step": 37670
    },
    {
      "epoch": 10.765714285714285,
      "grad_norm": 0.025367705151438713,
      "learning_rate": 5.645714285714287e-06,
      "loss": 0.0025,
      "step": 37680
    },
    {
      "epoch": 10.768571428571429,
      "grad_norm": 0.06963694095611572,
      "learning_rate": 5.641904761904763e-06,
      "loss": 0.1621,
      "step": 37690
    },
    {
      "epoch": 10.771428571428572,
      "grad_norm": 0.029295142740011215,
      "learning_rate": 5.638095238095238e-06,
      "loss": 0.0005,
      "step": 37700
    },
    {
      "epoch": 10.774285714285714,
      "grad_norm": 0.0013874695869162679,
      "learning_rate": 5.6342857142857144e-06,
      "loss": 0.2866,
      "step": 37710
    },
    {
      "epoch": 10.777142857142858,
      "grad_norm": 0.0017069745808839798,
      "learning_rate": 5.630476190476191e-06,
      "loss": 0.1539,
      "step": 37720
    },
    {
      "epoch": 10.78,
      "grad_norm": 0.006647720001637936,
      "learning_rate": 5.626666666666667e-06,
      "loss": 0.124,
      "step": 37730
    },
    {
      "epoch": 10.782857142857143,
      "grad_norm": 0.25928226113319397,
      "learning_rate": 5.622857142857143e-06,
      "loss": 0.0008,
      "step": 37740
    },
    {
      "epoch": 10.785714285714286,
      "grad_norm": 0.3122858703136444,
      "learning_rate": 5.619047619047619e-06,
      "loss": 0.0022,
      "step": 37750
    },
    {
      "epoch": 10.788571428571428,
      "grad_norm": 0.04054461047053337,
      "learning_rate": 5.615238095238096e-06,
      "loss": 0.0002,
      "step": 37760
    },
    {
      "epoch": 10.791428571428572,
      "grad_norm": 0.0015435180393978953,
      "learning_rate": 5.611428571428572e-06,
      "loss": 0.3672,
      "step": 37770
    },
    {
      "epoch": 10.794285714285714,
      "grad_norm": 0.014448967762291431,
      "learning_rate": 5.607619047619049e-06,
      "loss": 0.5663,
      "step": 37780
    },
    {
      "epoch": 10.797142857142857,
      "grad_norm": 0.6058328151702881,
      "learning_rate": 5.603809523809525e-06,
      "loss": 0.002,
      "step": 37790
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.06657116115093231,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.2281,
      "step": 37800
    },
    {
      "epoch": 10.802857142857142,
      "grad_norm": 0.12270020693540573,
      "learning_rate": 5.596190476190476e-06,
      "loss": 0.0014,
      "step": 37810
    },
    {
      "epoch": 10.805714285714286,
      "grad_norm": 2.418386459350586,
      "learning_rate": 5.592380952380953e-06,
      "loss": 0.2331,
      "step": 37820
    },
    {
      "epoch": 10.808571428571428,
      "grad_norm": 28.176044464111328,
      "learning_rate": 5.588571428571429e-06,
      "loss": 0.1243,
      "step": 37830
    },
    {
      "epoch": 10.811428571428571,
      "grad_norm": 0.044597309082746506,
      "learning_rate": 5.5847619047619055e-06,
      "loss": 0.1155,
      "step": 37840
    },
    {
      "epoch": 10.814285714285715,
      "grad_norm": 0.5722128748893738,
      "learning_rate": 5.580952380952381e-06,
      "loss": 0.1856,
      "step": 37850
    },
    {
      "epoch": 10.817142857142857,
      "grad_norm": 0.09768539667129517,
      "learning_rate": 5.5771428571428575e-06,
      "loss": 0.1173,
      "step": 37860
    },
    {
      "epoch": 10.82,
      "grad_norm": 0.029408149421215057,
      "learning_rate": 5.573333333333334e-06,
      "loss": 0.186,
      "step": 37870
    },
    {
      "epoch": 10.822857142857142,
      "grad_norm": 0.3778863847255707,
      "learning_rate": 5.56952380952381e-06,
      "loss": 0.0019,
      "step": 37880
    },
    {
      "epoch": 10.825714285714286,
      "grad_norm": 0.04757687449455261,
      "learning_rate": 5.565714285714287e-06,
      "loss": 0.1022,
      "step": 37890
    },
    {
      "epoch": 10.82857142857143,
      "grad_norm": 0.04548751562833786,
      "learning_rate": 5.561904761904763e-06,
      "loss": 0.0359,
      "step": 37900
    },
    {
      "epoch": 10.831428571428571,
      "grad_norm": 0.0024579770397394896,
      "learning_rate": 5.558095238095239e-06,
      "loss": 0.2679,
      "step": 37910
    },
    {
      "epoch": 10.834285714285715,
      "grad_norm": 0.13399623334407806,
      "learning_rate": 5.554285714285714e-06,
      "loss": 0.0021,
      "step": 37920
    },
    {
      "epoch": 10.837142857142858,
      "grad_norm": 0.0018729788716882467,
      "learning_rate": 5.550476190476191e-06,
      "loss": 0.0037,
      "step": 37930
    },
    {
      "epoch": 10.84,
      "grad_norm": 0.35594508051872253,
      "learning_rate": 5.546666666666667e-06,
      "loss": 0.0018,
      "step": 37940
    },
    {
      "epoch": 10.842857142857143,
      "grad_norm": 0.0038724245969206095,
      "learning_rate": 5.542857142857143e-06,
      "loss": 0.0881,
      "step": 37950
    },
    {
      "epoch": 10.845714285714285,
      "grad_norm": 0.0026276675052940845,
      "learning_rate": 5.539047619047619e-06,
      "loss": 0.1567,
      "step": 37960
    },
    {
      "epoch": 10.848571428571429,
      "grad_norm": 0.003465366782620549,
      "learning_rate": 5.535238095238096e-06,
      "loss": 0.0848,
      "step": 37970
    },
    {
      "epoch": 10.85142857142857,
      "grad_norm": 0.16499648988246918,
      "learning_rate": 5.531428571428572e-06,
      "loss": 0.0012,
      "step": 37980
    },
    {
      "epoch": 10.854285714285714,
      "grad_norm": 0.001086500589735806,
      "learning_rate": 5.5276190476190485e-06,
      "loss": 0.1238,
      "step": 37990
    },
    {
      "epoch": 10.857142857142858,
      "grad_norm": 0.04840138554573059,
      "learning_rate": 5.523809523809525e-06,
      "loss": 0.0142,
      "step": 38000
    },
    {
      "epoch": 10.86,
      "grad_norm": 0.07379595935344696,
      "learning_rate": 5.5200000000000005e-06,
      "loss": 0.0007,
      "step": 38010
    },
    {
      "epoch": 10.862857142857143,
      "grad_norm": 0.008257627487182617,
      "learning_rate": 5.516190476190476e-06,
      "loss": 0.0004,
      "step": 38020
    },
    {
      "epoch": 10.865714285714287,
      "grad_norm": 0.028980329632759094,
      "learning_rate": 5.5123809523809525e-06,
      "loss": 0.0006,
      "step": 38030
    },
    {
      "epoch": 10.868571428571428,
      "grad_norm": 0.00047771685058251023,
      "learning_rate": 5.508571428571429e-06,
      "loss": 0.0766,
      "step": 38040
    },
    {
      "epoch": 10.871428571428572,
      "grad_norm": 0.0003982149937655777,
      "learning_rate": 5.504761904761905e-06,
      "loss": 0.2217,
      "step": 38050
    },
    {
      "epoch": 10.874285714285714,
      "grad_norm": 0.00661720335483551,
      "learning_rate": 5.500952380952381e-06,
      "loss": 0.1094,
      "step": 38060
    },
    {
      "epoch": 10.877142857142857,
      "grad_norm": 0.0046608662232756615,
      "learning_rate": 5.497142857142857e-06,
      "loss": 0.0007,
      "step": 38070
    },
    {
      "epoch": 10.88,
      "grad_norm": 0.10977480560541153,
      "learning_rate": 5.493333333333334e-06,
      "loss": 0.3724,
      "step": 38080
    },
    {
      "epoch": 10.882857142857143,
      "grad_norm": 0.004140414297580719,
      "learning_rate": 5.48952380952381e-06,
      "loss": 0.0011,
      "step": 38090
    },
    {
      "epoch": 10.885714285714286,
      "grad_norm": 0.001420997316017747,
      "learning_rate": 5.485714285714287e-06,
      "loss": 0.0007,
      "step": 38100
    },
    {
      "epoch": 10.888571428571428,
      "grad_norm": 0.0003493635158520192,
      "learning_rate": 5.481904761904763e-06,
      "loss": 0.0005,
      "step": 38110
    },
    {
      "epoch": 10.891428571428571,
      "grad_norm": 13.034967422485352,
      "learning_rate": 5.478095238095239e-06,
      "loss": 0.2345,
      "step": 38120
    },
    {
      "epoch": 10.894285714285715,
      "grad_norm": 0.011347245424985886,
      "learning_rate": 5.474285714285714e-06,
      "loss": 0.001,
      "step": 38130
    },
    {
      "epoch": 10.897142857142857,
      "grad_norm": 0.0004860322515014559,
      "learning_rate": 5.470476190476191e-06,
      "loss": 0.0148,
      "step": 38140
    },
    {
      "epoch": 10.9,
      "grad_norm": 0.004920259118080139,
      "learning_rate": 5.466666666666667e-06,
      "loss": 0.0008,
      "step": 38150
    },
    {
      "epoch": 10.902857142857142,
      "grad_norm": 0.0007416941807605326,
      "learning_rate": 5.462857142857143e-06,
      "loss": 0.0006,
      "step": 38160
    },
    {
      "epoch": 10.905714285714286,
      "grad_norm": 0.014609583653509617,
      "learning_rate": 5.459047619047619e-06,
      "loss": 0.0003,
      "step": 38170
    },
    {
      "epoch": 10.90857142857143,
      "grad_norm": 0.043297965079545975,
      "learning_rate": 5.4552380952380956e-06,
      "loss": 0.0015,
      "step": 38180
    },
    {
      "epoch": 10.911428571428571,
      "grad_norm": 0.11072812974452972,
      "learning_rate": 5.451428571428572e-06,
      "loss": 0.1506,
      "step": 38190
    },
    {
      "epoch": 10.914285714285715,
      "grad_norm": 0.029146375134587288,
      "learning_rate": 5.447619047619048e-06,
      "loss": 0.0006,
      "step": 38200
    },
    {
      "epoch": 10.917142857142856,
      "grad_norm": 0.004702144302427769,
      "learning_rate": 5.443809523809525e-06,
      "loss": 0.0003,
      "step": 38210
    },
    {
      "epoch": 10.92,
      "grad_norm": 0.00030916568357497454,
      "learning_rate": 5.4400000000000004e-06,
      "loss": 0.0203,
      "step": 38220
    },
    {
      "epoch": 10.922857142857143,
      "grad_norm": 0.0003584848018363118,
      "learning_rate": 5.436190476190477e-06,
      "loss": 0.0014,
      "step": 38230
    },
    {
      "epoch": 10.925714285714285,
      "grad_norm": 0.033859048038721085,
      "learning_rate": 5.4323809523809524e-06,
      "loss": 0.1211,
      "step": 38240
    },
    {
      "epoch": 10.928571428571429,
      "grad_norm": 0.07534822821617126,
      "learning_rate": 5.428571428571429e-06,
      "loss": 0.0003,
      "step": 38250
    },
    {
      "epoch": 10.93142857142857,
      "grad_norm": 0.04878289997577667,
      "learning_rate": 5.424761904761905e-06,
      "loss": 0.0003,
      "step": 38260
    },
    {
      "epoch": 10.934285714285714,
      "grad_norm": 0.0002136707043973729,
      "learning_rate": 5.420952380952381e-06,
      "loss": 0.1319,
      "step": 38270
    },
    {
      "epoch": 10.937142857142858,
      "grad_norm": 0.19509465992450714,
      "learning_rate": 5.417142857142857e-06,
      "loss": 0.1258,
      "step": 38280
    },
    {
      "epoch": 10.94,
      "grad_norm": 0.17401589453220367,
      "learning_rate": 5.413333333333334e-06,
      "loss": 0.1494,
      "step": 38290
    },
    {
      "epoch": 10.942857142857143,
      "grad_norm": 7.109410216799006e-05,
      "learning_rate": 5.40952380952381e-06,
      "loss": 0.0015,
      "step": 38300
    },
    {
      "epoch": 10.945714285714285,
      "grad_norm": 0.0845576748251915,
      "learning_rate": 5.405714285714287e-06,
      "loss": 0.0003,
      "step": 38310
    },
    {
      "epoch": 10.948571428571428,
      "grad_norm": 0.07422281056642532,
      "learning_rate": 5.401904761904763e-06,
      "loss": 0.2877,
      "step": 38320
    },
    {
      "epoch": 10.951428571428572,
      "grad_norm": 0.009579851292073727,
      "learning_rate": 5.398095238095239e-06,
      "loss": 0.0005,
      "step": 38330
    },
    {
      "epoch": 10.954285714285714,
      "grad_norm": 0.19146087765693665,
      "learning_rate": 5.394285714285715e-06,
      "loss": 0.0015,
      "step": 38340
    },
    {
      "epoch": 10.957142857142857,
      "grad_norm": 17.724300384521484,
      "learning_rate": 5.390476190476191e-06,
      "loss": 0.1009,
      "step": 38350
    },
    {
      "epoch": 10.96,
      "grad_norm": 0.00010238248069072142,
      "learning_rate": 5.386666666666667e-06,
      "loss": 0.1746,
      "step": 38360
    },
    {
      "epoch": 10.962857142857143,
      "grad_norm": 552.8148803710938,
      "learning_rate": 5.382857142857143e-06,
      "loss": 0.0342,
      "step": 38370
    },
    {
      "epoch": 10.965714285714286,
      "grad_norm": 8.184566831914708e-05,
      "learning_rate": 5.379047619047619e-06,
      "loss": 0.1582,
      "step": 38380
    },
    {
      "epoch": 10.968571428571428,
      "grad_norm": 0.01473543606698513,
      "learning_rate": 5.3752380952380955e-06,
      "loss": 0.0001,
      "step": 38390
    },
    {
      "epoch": 10.971428571428572,
      "grad_norm": 0.037598852068185806,
      "learning_rate": 5.371428571428572e-06,
      "loss": 0.0003,
      "step": 38400
    },
    {
      "epoch": 10.974285714285715,
      "grad_norm": 0.08864635974168777,
      "learning_rate": 5.367619047619048e-06,
      "loss": 0.2391,
      "step": 38410
    },
    {
      "epoch": 10.977142857142857,
      "grad_norm": 0.06973814964294434,
      "learning_rate": 5.363809523809525e-06,
      "loss": 0.0004,
      "step": 38420
    },
    {
      "epoch": 10.98,
      "grad_norm": 0.004819443915039301,
      "learning_rate": 5.36e-06,
      "loss": 0.142,
      "step": 38430
    },
    {
      "epoch": 10.982857142857142,
      "grad_norm": 0.11598557233810425,
      "learning_rate": 5.356190476190477e-06,
      "loss": 0.1122,
      "step": 38440
    },
    {
      "epoch": 10.985714285714286,
      "grad_norm": 0.02521275356411934,
      "learning_rate": 5.352380952380953e-06,
      "loss": 0.0013,
      "step": 38450
    },
    {
      "epoch": 10.98857142857143,
      "grad_norm": 0.0002697373565752059,
      "learning_rate": 5.348571428571429e-06,
      "loss": 0.002,
      "step": 38460
    },
    {
      "epoch": 10.991428571428571,
      "grad_norm": 0.039817482233047485,
      "learning_rate": 5.344761904761905e-06,
      "loss": 0.0002,
      "step": 38470
    },
    {
      "epoch": 10.994285714285715,
      "grad_norm": 0.00012869933561887592,
      "learning_rate": 5.340952380952381e-06,
      "loss": 0.1257,
      "step": 38480
    },
    {
      "epoch": 10.997142857142856,
      "grad_norm": 0.004098229575902224,
      "learning_rate": 5.337142857142857e-06,
      "loss": 0.0022,
      "step": 38490
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.04145676642656326,
      "learning_rate": 5.333333333333334e-06,
      "loss": 0.0584,
      "step": 38500
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.967,
      "eval_f1": 0.8426073131955485,
      "eval_loss": 0.22243261337280273,
      "eval_precision": 0.8922558922558923,
      "eval_recall": 0.7981927710843374,
      "eval_runtime": 266.3196,
      "eval_samples_per_second": 11.265,
      "eval_steps_per_second": 2.816,
      "step": 38500
    },
    {
      "epoch": 11.002857142857144,
      "grad_norm": 0.11954547464847565,
      "learning_rate": 5.32952380952381e-06,
      "loss": 0.1484,
      "step": 38510
    },
    {
      "epoch": 11.005714285714285,
      "grad_norm": 8.364445966435596e-05,
      "learning_rate": 5.3257142857142865e-06,
      "loss": 0.0009,
      "step": 38520
    },
    {
      "epoch": 11.008571428571429,
      "grad_norm": 0.053631462156772614,
      "learning_rate": 5.321904761904763e-06,
      "loss": 0.1463,
      "step": 38530
    },
    {
      "epoch": 11.01142857142857,
      "grad_norm": 0.12095649540424347,
      "learning_rate": 5.3180952380952385e-06,
      "loss": 0.1243,
      "step": 38540
    },
    {
      "epoch": 11.014285714285714,
      "grad_norm": 0.9448580741882324,
      "learning_rate": 5.314285714285715e-06,
      "loss": 0.0012,
      "step": 38550
    },
    {
      "epoch": 11.017142857142858,
      "grad_norm": 0.014081721194088459,
      "learning_rate": 5.310476190476191e-06,
      "loss": 0.0005,
      "step": 38560
    },
    {
      "epoch": 11.02,
      "grad_norm": 0.0006108082015998662,
      "learning_rate": 5.306666666666667e-06,
      "loss": 0.1085,
      "step": 38570
    },
    {
      "epoch": 11.022857142857143,
      "grad_norm": 0.008307153359055519,
      "learning_rate": 5.3028571428571425e-06,
      "loss": 0.0003,
      "step": 38580
    },
    {
      "epoch": 11.025714285714285,
      "grad_norm": 0.404353529214859,
      "learning_rate": 5.299047619047619e-06,
      "loss": 0.0007,
      "step": 38590
    },
    {
      "epoch": 11.028571428571428,
      "grad_norm": 0.0013587804278358817,
      "learning_rate": 5.295238095238095e-06,
      "loss": 0.1187,
      "step": 38600
    },
    {
      "epoch": 11.031428571428572,
      "grad_norm": 0.03584892675280571,
      "learning_rate": 5.291428571428572e-06,
      "loss": 0.0003,
      "step": 38610
    },
    {
      "epoch": 11.034285714285714,
      "grad_norm": 0.06225091591477394,
      "learning_rate": 5.287619047619048e-06,
      "loss": 0.0006,
      "step": 38620
    },
    {
      "epoch": 11.037142857142857,
      "grad_norm": 0.00044640342821367085,
      "learning_rate": 5.283809523809525e-06,
      "loss": 0.0002,
      "step": 38630
    },
    {
      "epoch": 11.04,
      "grad_norm": 0.02699393406510353,
      "learning_rate": 5.28e-06,
      "loss": 0.0006,
      "step": 38640
    },
    {
      "epoch": 11.042857142857143,
      "grad_norm": 0.0005098198307678103,
      "learning_rate": 5.276190476190477e-06,
      "loss": 0.0002,
      "step": 38650
    },
    {
      "epoch": 11.045714285714286,
      "grad_norm": 0.030847296118736267,
      "learning_rate": 5.272380952380953e-06,
      "loss": 0.1689,
      "step": 38660
    },
    {
      "epoch": 11.048571428571428,
      "grad_norm": 0.09525773674249649,
      "learning_rate": 5.268571428571429e-06,
      "loss": 0.0002,
      "step": 38670
    },
    {
      "epoch": 11.051428571428572,
      "grad_norm": 0.013425265438854694,
      "learning_rate": 5.264761904761905e-06,
      "loss": 0.0003,
      "step": 38680
    },
    {
      "epoch": 11.054285714285715,
      "grad_norm": 0.03903048112988472,
      "learning_rate": 5.260952380952381e-06,
      "loss": 0.1183,
      "step": 38690
    },
    {
      "epoch": 11.057142857142857,
      "grad_norm": 0.0017492909682914615,
      "learning_rate": 5.257142857142857e-06,
      "loss": 0.0002,
      "step": 38700
    },
    {
      "epoch": 11.06,
      "grad_norm": 0.018891986459493637,
      "learning_rate": 5.2533333333333336e-06,
      "loss": 0.0182,
      "step": 38710
    },
    {
      "epoch": 11.062857142857142,
      "grad_norm": 0.0001385617651976645,
      "learning_rate": 5.24952380952381e-06,
      "loss": 0.0003,
      "step": 38720
    },
    {
      "epoch": 11.065714285714286,
      "grad_norm": 0.000174903470906429,
      "learning_rate": 5.2457142857142864e-06,
      "loss": 0.0007,
      "step": 38730
    },
    {
      "epoch": 11.06857142857143,
      "grad_norm": 0.006191157270222902,
      "learning_rate": 5.241904761904763e-06,
      "loss": 0.1266,
      "step": 38740
    },
    {
      "epoch": 11.071428571428571,
      "grad_norm": 5.9645022702170536e-05,
      "learning_rate": 5.2380952380952384e-06,
      "loss": 0.0001,
      "step": 38750
    },
    {
      "epoch": 11.074285714285715,
      "grad_norm": 0.00011010708112735301,
      "learning_rate": 5.234285714285715e-06,
      "loss": 0.1536,
      "step": 38760
    },
    {
      "epoch": 11.077142857142857,
      "grad_norm": 0.026316998526453972,
      "learning_rate": 5.230476190476191e-06,
      "loss": 0.2729,
      "step": 38770
    },
    {
      "epoch": 11.08,
      "grad_norm": 0.009460082277655602,
      "learning_rate": 5.226666666666667e-06,
      "loss": 0.1838,
      "step": 38780
    },
    {
      "epoch": 11.082857142857144,
      "grad_norm": 1.719028115272522,
      "learning_rate": 5.2228571428571425e-06,
      "loss": 0.0014,
      "step": 38790
    },
    {
      "epoch": 11.085714285714285,
      "grad_norm": 3.5225388273829594e-05,
      "learning_rate": 5.219047619047619e-06,
      "loss": 0.0006,
      "step": 38800
    },
    {
      "epoch": 11.088571428571429,
      "grad_norm": 0.040669865906238556,
      "learning_rate": 5.215238095238095e-06,
      "loss": 0.1059,
      "step": 38810
    },
    {
      "epoch": 11.09142857142857,
      "grad_norm": 0.11708725243806839,
      "learning_rate": 5.211428571428572e-06,
      "loss": 0.0004,
      "step": 38820
    },
    {
      "epoch": 11.094285714285714,
      "grad_norm": 0.001167563023045659,
      "learning_rate": 5.207619047619048e-06,
      "loss": 0.0002,
      "step": 38830
    },
    {
      "epoch": 11.097142857142858,
      "grad_norm": 0.0005498240934684873,
      "learning_rate": 5.203809523809525e-06,
      "loss": 0.0001,
      "step": 38840
    },
    {
      "epoch": 11.1,
      "grad_norm": 0.0014775155577808619,
      "learning_rate": 5.2e-06,
      "loss": 0.2087,
      "step": 38850
    },
    {
      "epoch": 11.102857142857143,
      "grad_norm": 0.00040661817183718085,
      "learning_rate": 5.196190476190477e-06,
      "loss": 0.0783,
      "step": 38860
    },
    {
      "epoch": 11.105714285714285,
      "grad_norm": 0.062182873487472534,
      "learning_rate": 5.192380952380953e-06,
      "loss": 0.1365,
      "step": 38870
    },
    {
      "epoch": 11.108571428571429,
      "grad_norm": 1.074945330619812,
      "learning_rate": 5.1885714285714295e-06,
      "loss": 0.0011,
      "step": 38880
    },
    {
      "epoch": 11.111428571428572,
      "grad_norm": 0.018138553947210312,
      "learning_rate": 5.184761904761905e-06,
      "loss": 0.0005,
      "step": 38890
    },
    {
      "epoch": 11.114285714285714,
      "grad_norm": 3.06483889289666e-05,
      "learning_rate": 5.180952380952381e-06,
      "loss": 0.001,
      "step": 38900
    },
    {
      "epoch": 11.117142857142857,
      "grad_norm": 0.00014566870231647044,
      "learning_rate": 5.177142857142857e-06,
      "loss": 0.0003,
      "step": 38910
    },
    {
      "epoch": 11.12,
      "grad_norm": 0.001086123287677765,
      "learning_rate": 5.1733333333333335e-06,
      "loss": 0.1141,
      "step": 38920
    },
    {
      "epoch": 11.122857142857143,
      "grad_norm": 9.579773904988542e-05,
      "learning_rate": 5.16952380952381e-06,
      "loss": 0.0011,
      "step": 38930
    },
    {
      "epoch": 11.125714285714286,
      "grad_norm": 4.3097908928757533e-05,
      "learning_rate": 5.165714285714286e-06,
      "loss": 0.1247,
      "step": 38940
    },
    {
      "epoch": 11.128571428571428,
      "grad_norm": 0.0003476854180917144,
      "learning_rate": 5.161904761904763e-06,
      "loss": 0.0001,
      "step": 38950
    },
    {
      "epoch": 11.131428571428572,
      "grad_norm": 0.0054915230721235275,
      "learning_rate": 5.158095238095238e-06,
      "loss": 0.0081,
      "step": 38960
    },
    {
      "epoch": 11.134285714285713,
      "grad_norm": 0.010355961509048939,
      "learning_rate": 5.154285714285715e-06,
      "loss": 0.0004,
      "step": 38970
    },
    {
      "epoch": 11.137142857142857,
      "grad_norm": 0.04419635236263275,
      "learning_rate": 5.150476190476191e-06,
      "loss": 0.239,
      "step": 38980
    },
    {
      "epoch": 11.14,
      "grad_norm": 0.06426592916250229,
      "learning_rate": 5.146666666666668e-06,
      "loss": 0.0004,
      "step": 38990
    },
    {
      "epoch": 11.142857142857142,
      "grad_norm": 0.5444375276565552,
      "learning_rate": 5.142857142857142e-06,
      "loss": 0.0014,
      "step": 39000
    },
    {
      "epoch": 11.145714285714286,
      "grad_norm": 0.020393110811710358,
      "learning_rate": 5.139047619047619e-06,
      "loss": 0.0005,
      "step": 39010
    },
    {
      "epoch": 11.14857142857143,
      "grad_norm": 4.9610771384323016e-05,
      "learning_rate": 5.135238095238095e-06,
      "loss": 0.2409,
      "step": 39020
    },
    {
      "epoch": 11.151428571428571,
      "grad_norm": 9.388599210069515e-06,
      "learning_rate": 5.131428571428572e-06,
      "loss": 0.0007,
      "step": 39030
    },
    {
      "epoch": 11.154285714285715,
      "grad_norm": 15.56965160369873,
      "learning_rate": 5.127619047619048e-06,
      "loss": 0.1387,
      "step": 39040
    },
    {
      "epoch": 11.157142857142857,
      "grad_norm": 0.013179890811443329,
      "learning_rate": 5.1238095238095245e-06,
      "loss": 0.2356,
      "step": 39050
    },
    {
      "epoch": 11.16,
      "grad_norm": 0.02849811688065529,
      "learning_rate": 5.12e-06,
      "loss": 0.1116,
      "step": 39060
    },
    {
      "epoch": 11.162857142857144,
      "grad_norm": 0.003277973970398307,
      "learning_rate": 5.1161904761904765e-06,
      "loss": 0.1207,
      "step": 39070
    },
    {
      "epoch": 11.165714285714285,
      "grad_norm": 0.24359704554080963,
      "learning_rate": 5.112380952380953e-06,
      "loss": 0.0006,
      "step": 39080
    },
    {
      "epoch": 11.168571428571429,
      "grad_norm": 0.02066154032945633,
      "learning_rate": 5.108571428571429e-06,
      "loss": 0.001,
      "step": 39090
    },
    {
      "epoch": 11.17142857142857,
      "grad_norm": 0.008104395121335983,
      "learning_rate": 5.104761904761906e-06,
      "loss": 0.0005,
      "step": 39100
    },
    {
      "epoch": 11.174285714285714,
      "grad_norm": 0.02352900058031082,
      "learning_rate": 5.1009523809523806e-06,
      "loss": 0.2165,
      "step": 39110
    },
    {
      "epoch": 11.177142857142858,
      "grad_norm": 0.00204102648422122,
      "learning_rate": 5.097142857142857e-06,
      "loss": 0.1611,
      "step": 39120
    },
    {
      "epoch": 11.18,
      "grad_norm": 0.10265816003084183,
      "learning_rate": 5.093333333333333e-06,
      "loss": 0.0204,
      "step": 39130
    },
    {
      "epoch": 11.182857142857143,
      "grad_norm": 0.022437918931245804,
      "learning_rate": 5.08952380952381e-06,
      "loss": 0.0003,
      "step": 39140
    },
    {
      "epoch": 11.185714285714285,
      "grad_norm": 0.01664247363805771,
      "learning_rate": 5.085714285714286e-06,
      "loss": 0.0002,
      "step": 39150
    },
    {
      "epoch": 11.188571428571429,
      "grad_norm": 0.10787298530340195,
      "learning_rate": 5.081904761904763e-06,
      "loss": 0.0006,
      "step": 39160
    },
    {
      "epoch": 11.191428571428572,
      "grad_norm": 25.993257522583008,
      "learning_rate": 5.078095238095238e-06,
      "loss": 0.2006,
      "step": 39170
    },
    {
      "epoch": 11.194285714285714,
      "grad_norm": 0.06920789182186127,
      "learning_rate": 5.074285714285715e-06,
      "loss": 0.0505,
      "step": 39180
    },
    {
      "epoch": 11.197142857142858,
      "grad_norm": 0.0008016569190658629,
      "learning_rate": 5.070476190476191e-06,
      "loss": 0.006,
      "step": 39190
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.00759168341755867,
      "learning_rate": 5.0666666666666676e-06,
      "loss": 0.0005,
      "step": 39200
    },
    {
      "epoch": 11.202857142857143,
      "grad_norm": 0.000934092327952385,
      "learning_rate": 5.062857142857144e-06,
      "loss": 0.2563,
      "step": 39210
    },
    {
      "epoch": 11.205714285714286,
      "grad_norm": 0.00010766720515675843,
      "learning_rate": 5.059047619047619e-06,
      "loss": 0.0004,
      "step": 39220
    },
    {
      "epoch": 11.208571428571428,
      "grad_norm": 289.9250183105469,
      "learning_rate": 5.055238095238095e-06,
      "loss": 0.1558,
      "step": 39230
    },
    {
      "epoch": 11.211428571428572,
      "grad_norm": 0.024667173624038696,
      "learning_rate": 5.051428571428572e-06,
      "loss": 0.0006,
      "step": 39240
    },
    {
      "epoch": 11.214285714285714,
      "grad_norm": 0.02079346589744091,
      "learning_rate": 5.047619047619048e-06,
      "loss": 0.4036,
      "step": 39250
    },
    {
      "epoch": 11.217142857142857,
      "grad_norm": 0.5481758713722229,
      "learning_rate": 5.0438095238095244e-06,
      "loss": 0.0041,
      "step": 39260
    },
    {
      "epoch": 11.22,
      "grad_norm": 7.495853787986562e-05,
      "learning_rate": 5.04e-06,
      "loss": 0.0003,
      "step": 39270
    },
    {
      "epoch": 11.222857142857142,
      "grad_norm": 0.00021046931215096265,
      "learning_rate": 5.0361904761904765e-06,
      "loss": 0.0001,
      "step": 39280
    },
    {
      "epoch": 11.225714285714286,
      "grad_norm": 0.0008048134623095393,
      "learning_rate": 5.032380952380953e-06,
      "loss": 0.1296,
      "step": 39290
    },
    {
      "epoch": 11.228571428571428,
      "grad_norm": 0.0004013355646748096,
      "learning_rate": 5.028571428571429e-06,
      "loss": 0.0788,
      "step": 39300
    },
    {
      "epoch": 11.231428571428571,
      "grad_norm": 17.573808670043945,
      "learning_rate": 5.024761904761906e-06,
      "loss": 0.1367,
      "step": 39310
    },
    {
      "epoch": 11.234285714285715,
      "grad_norm": 0.01775137148797512,
      "learning_rate": 5.020952380952382e-06,
      "loss": 0.0008,
      "step": 39320
    },
    {
      "epoch": 11.237142857142857,
      "grad_norm": 0.9152196049690247,
      "learning_rate": 5.017142857142857e-06,
      "loss": 0.2958,
      "step": 39330
    },
    {
      "epoch": 11.24,
      "grad_norm": 0.1652282476425171,
      "learning_rate": 5.013333333333333e-06,
      "loss": 0.0014,
      "step": 39340
    },
    {
      "epoch": 11.242857142857142,
      "grad_norm": 1.0502492189407349,
      "learning_rate": 5.00952380952381e-06,
      "loss": 0.3851,
      "step": 39350
    },
    {
      "epoch": 11.245714285714286,
      "grad_norm": 0.11834868788719177,
      "learning_rate": 5.005714285714286e-06,
      "loss": 0.0595,
      "step": 39360
    },
    {
      "epoch": 11.248571428571429,
      "grad_norm": 0.06352691352367401,
      "learning_rate": 5.001904761904763e-06,
      "loss": 0.0006,
      "step": 39370
    },
    {
      "epoch": 11.251428571428571,
      "grad_norm": 0.047760456800460815,
      "learning_rate": 4.998095238095238e-06,
      "loss": 0.0014,
      "step": 39380
    },
    {
      "epoch": 11.254285714285714,
      "grad_norm": 0.0025079664774239063,
      "learning_rate": 4.994285714285715e-06,
      "loss": 0.0001,
      "step": 39390
    },
    {
      "epoch": 11.257142857142856,
      "grad_norm": 0.00649163918569684,
      "learning_rate": 4.990476190476191e-06,
      "loss": 0.0001,
      "step": 39400
    },
    {
      "epoch": 11.26,
      "grad_norm": 0.0007909549749456346,
      "learning_rate": 4.986666666666667e-06,
      "loss": 0.0004,
      "step": 39410
    },
    {
      "epoch": 11.262857142857143,
      "grad_norm": 0.016569958999753,
      "learning_rate": 4.982857142857143e-06,
      "loss": 0.0002,
      "step": 39420
    },
    {
      "epoch": 11.265714285714285,
      "grad_norm": 0.0004254738159943372,
      "learning_rate": 4.9790476190476195e-06,
      "loss": 0.0005,
      "step": 39430
    },
    {
      "epoch": 11.268571428571429,
      "grad_norm": 0.0004411845002323389,
      "learning_rate": 4.975238095238096e-06,
      "loss": 0.0007,
      "step": 39440
    },
    {
      "epoch": 11.271428571428572,
      "grad_norm": 0.0039032145868986845,
      "learning_rate": 4.971428571428572e-06,
      "loss": 0.0002,
      "step": 39450
    },
    {
      "epoch": 11.274285714285714,
      "grad_norm": 0.001588977174833417,
      "learning_rate": 4.967619047619048e-06,
      "loss": 0.0003,
      "step": 39460
    },
    {
      "epoch": 11.277142857142858,
      "grad_norm": 0.02176331914961338,
      "learning_rate": 4.963809523809524e-06,
      "loss": 0.0002,
      "step": 39470
    },
    {
      "epoch": 11.28,
      "grad_norm": 0.0006285026320256293,
      "learning_rate": 4.960000000000001e-06,
      "loss": 0.0003,
      "step": 39480
    },
    {
      "epoch": 11.282857142857143,
      "grad_norm": 0.00023913673066999763,
      "learning_rate": 4.956190476190476e-06,
      "loss": 0.0005,
      "step": 39490
    },
    {
      "epoch": 11.285714285714286,
      "grad_norm": 0.022956907749176025,
      "learning_rate": 4.952380952380953e-06,
      "loss": 0.0001,
      "step": 39500
    },
    {
      "epoch": 11.288571428571428,
      "grad_norm": 0.024407804012298584,
      "learning_rate": 4.948571428571429e-06,
      "loss": 0.0001,
      "step": 39510
    },
    {
      "epoch": 11.291428571428572,
      "grad_norm": 1.471756100654602,
      "learning_rate": 4.944761904761905e-06,
      "loss": 0.0004,
      "step": 39520
    },
    {
      "epoch": 11.294285714285714,
      "grad_norm": 0.003924549091607332,
      "learning_rate": 4.940952380952381e-06,
      "loss": 0.185,
      "step": 39530
    },
    {
      "epoch": 11.297142857142857,
      "grad_norm": 0.007460023742169142,
      "learning_rate": 4.937142857142858e-06,
      "loss": 0.1191,
      "step": 39540
    },
    {
      "epoch": 11.3,
      "grad_norm": 0.003416632069274783,
      "learning_rate": 4.933333333333334e-06,
      "loss": 0.1058,
      "step": 39550
    },
    {
      "epoch": 11.302857142857142,
      "grad_norm": 0.002428332343697548,
      "learning_rate": 4.9295238095238105e-06,
      "loss": 0.1933,
      "step": 39560
    },
    {
      "epoch": 11.305714285714286,
      "grad_norm": 0.003035672241821885,
      "learning_rate": 4.925714285714286e-06,
      "loss": 0.0039,
      "step": 39570
    },
    {
      "epoch": 11.308571428571428,
      "grad_norm": 0.014642663300037384,
      "learning_rate": 4.9219047619047625e-06,
      "loss": 0.1653,
      "step": 39580
    },
    {
      "epoch": 11.311428571428571,
      "grad_norm": 0.051144201308488846,
      "learning_rate": 4.918095238095238e-06,
      "loss": 0.1171,
      "step": 39590
    },
    {
      "epoch": 11.314285714285715,
      "grad_norm": 0.010377545841038227,
      "learning_rate": 4.9142857142857145e-06,
      "loss": 0.1031,
      "step": 39600
    },
    {
      "epoch": 11.317142857142857,
      "grad_norm": 0.0004783988988492638,
      "learning_rate": 4.910476190476191e-06,
      "loss": 0.1117,
      "step": 39610
    },
    {
      "epoch": 11.32,
      "grad_norm": 0.06252777576446533,
      "learning_rate": 4.9066666666666666e-06,
      "loss": 0.0921,
      "step": 39620
    },
    {
      "epoch": 11.322857142857142,
      "grad_norm": 20.465993881225586,
      "learning_rate": 4.902857142857143e-06,
      "loss": 0.3636,
      "step": 39630
    },
    {
      "epoch": 11.325714285714286,
      "grad_norm": 0.00300441961735487,
      "learning_rate": 4.899047619047619e-06,
      "loss": 0.0006,
      "step": 39640
    },
    {
      "epoch": 11.32857142857143,
      "grad_norm": 0.04682745039463043,
      "learning_rate": 4.895238095238096e-06,
      "loss": 0.0019,
      "step": 39650
    },
    {
      "epoch": 11.331428571428571,
      "grad_norm": 0.011441873386502266,
      "learning_rate": 4.891428571428572e-06,
      "loss": 0.0004,
      "step": 39660
    },
    {
      "epoch": 11.334285714285715,
      "grad_norm": 0.09596996009349823,
      "learning_rate": 4.887619047619048e-06,
      "loss": 0.0701,
      "step": 39670
    },
    {
      "epoch": 11.337142857142856,
      "grad_norm": 0.0005212854011915624,
      "learning_rate": 4.883809523809524e-06,
      "loss": 0.0058,
      "step": 39680
    },
    {
      "epoch": 11.34,
      "grad_norm": 0.04989621788263321,
      "learning_rate": 4.880000000000001e-06,
      "loss": 0.0001,
      "step": 39690
    },
    {
      "epoch": 11.342857142857143,
      "grad_norm": 0.0014815973117947578,
      "learning_rate": 4.876190476190476e-06,
      "loss": 0.0006,
      "step": 39700
    },
    {
      "epoch": 11.345714285714285,
      "grad_norm": 0.0004478033515624702,
      "learning_rate": 4.872380952380953e-06,
      "loss": 0.0005,
      "step": 39710
    },
    {
      "epoch": 11.348571428571429,
      "grad_norm": 0.0006853491067886353,
      "learning_rate": 4.868571428571429e-06,
      "loss": 0.0001,
      "step": 39720
    },
    {
      "epoch": 11.35142857142857,
      "grad_norm": 0.000577862374484539,
      "learning_rate": 4.864761904761905e-06,
      "loss": 0.0002,
      "step": 39730
    },
    {
      "epoch": 11.354285714285714,
      "grad_norm": 0.0002870610333047807,
      "learning_rate": 4.860952380952381e-06,
      "loss": 0.1907,
      "step": 39740
    },
    {
      "epoch": 11.357142857142858,
      "grad_norm": 0.002573237754404545,
      "learning_rate": 4.857142857142858e-06,
      "loss": 0.0004,
      "step": 39750
    },
    {
      "epoch": 11.36,
      "grad_norm": 0.0005819895304739475,
      "learning_rate": 4.853333333333334e-06,
      "loss": 0.3675,
      "step": 39760
    },
    {
      "epoch": 11.362857142857143,
      "grad_norm": 8.800801151664928e-05,
      "learning_rate": 4.8495238095238104e-06,
      "loss": 0.0001,
      "step": 39770
    },
    {
      "epoch": 11.365714285714287,
      "grad_norm": 0.004254724830389023,
      "learning_rate": 4.845714285714286e-06,
      "loss": 0.0005,
      "step": 39780
    },
    {
      "epoch": 11.368571428571428,
      "grad_norm": 0.0005082470597699285,
      "learning_rate": 4.8419047619047625e-06,
      "loss": 0.1632,
      "step": 39790
    },
    {
      "epoch": 11.371428571428572,
      "grad_norm": 0.0049007791094481945,
      "learning_rate": 4.838095238095238e-06,
      "loss": 0.0503,
      "step": 39800
    },
    {
      "epoch": 11.374285714285714,
      "grad_norm": 0.02359425649046898,
      "learning_rate": 4.8342857142857145e-06,
      "loss": 0.0006,
      "step": 39810
    },
    {
      "epoch": 11.377142857142857,
      "grad_norm": 0.15444058179855347,
      "learning_rate": 4.830476190476191e-06,
      "loss": 0.0803,
      "step": 39820
    },
    {
      "epoch": 11.38,
      "grad_norm": 0.0033940798602998257,
      "learning_rate": 4.826666666666667e-06,
      "loss": 0.1107,
      "step": 39830
    },
    {
      "epoch": 11.382857142857143,
      "grad_norm": 0.0925317257642746,
      "learning_rate": 4.822857142857143e-06,
      "loss": 0.0003,
      "step": 39840
    },
    {
      "epoch": 11.385714285714286,
      "grad_norm": 0.001694712438620627,
      "learning_rate": 4.819047619047619e-06,
      "loss": 0.0006,
      "step": 39850
    },
    {
      "epoch": 11.388571428571428,
      "grad_norm": 0.0009287323337048292,
      "learning_rate": 4.815238095238096e-06,
      "loss": 0.459,
      "step": 39860
    },
    {
      "epoch": 11.391428571428571,
      "grad_norm": 0.028222771361470222,
      "learning_rate": 4.811428571428572e-06,
      "loss": 0.2824,
      "step": 39870
    },
    {
      "epoch": 11.394285714285715,
      "grad_norm": 0.017040379345417023,
      "learning_rate": 4.807619047619048e-06,
      "loss": 0.1038,
      "step": 39880
    },
    {
      "epoch": 11.397142857142857,
      "grad_norm": 0.0005862280377186835,
      "learning_rate": 4.803809523809524e-06,
      "loss": 0.1367,
      "step": 39890
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.10866307467222214,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.1065,
      "step": 39900
    },
    {
      "epoch": 11.402857142857142,
      "grad_norm": 0.1363171637058258,
      "learning_rate": 4.796190476190476e-06,
      "loss": 0.0009,
      "step": 39910
    },
    {
      "epoch": 11.405714285714286,
      "grad_norm": 0.20440414547920227,
      "learning_rate": 4.792380952380953e-06,
      "loss": 0.1938,
      "step": 39920
    },
    {
      "epoch": 11.40857142857143,
      "grad_norm": 0.001796423108316958,
      "learning_rate": 4.788571428571429e-06,
      "loss": 0.0001,
      "step": 39930
    },
    {
      "epoch": 11.411428571428571,
      "grad_norm": 0.00022236263612285256,
      "learning_rate": 4.7847619047619055e-06,
      "loss": 0.0003,
      "step": 39940
    },
    {
      "epoch": 11.414285714285715,
      "grad_norm": 0.000991215929389,
      "learning_rate": 4.780952380952381e-06,
      "loss": 0.0007,
      "step": 39950
    },
    {
      "epoch": 11.417142857142856,
      "grad_norm": 0.14015506207942963,
      "learning_rate": 4.7771428571428575e-06,
      "loss": 0.0002,
      "step": 39960
    },
    {
      "epoch": 11.42,
      "grad_norm": 0.069859080016613,
      "learning_rate": 4.773333333333334e-06,
      "loss": 0.0003,
      "step": 39970
    },
    {
      "epoch": 11.422857142857143,
      "grad_norm": 0.006954676005989313,
      "learning_rate": 4.76952380952381e-06,
      "loss": 0.0001,
      "step": 39980
    },
    {
      "epoch": 11.425714285714285,
      "grad_norm": 4.694895324064419e-05,
      "learning_rate": 4.765714285714286e-06,
      "loss": 0.0005,
      "step": 39990
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 18.665096282958984,
      "learning_rate": 4.761904761904762e-06,
      "loss": 0.2074,
      "step": 40000
    },
    {
      "epoch": 11.43142857142857,
      "grad_norm": 2.6495179554331116e-05,
      "learning_rate": 4.758095238095238e-06,
      "loss": 0.0003,
      "step": 40010
    },
    {
      "epoch": 11.434285714285714,
      "grad_norm": 0.05833661928772926,
      "learning_rate": 4.754285714285714e-06,
      "loss": 0.0004,
      "step": 40020
    },
    {
      "epoch": 11.437142857142858,
      "grad_norm": 0.004462632350623608,
      "learning_rate": 4.750476190476191e-06,
      "loss": 0.1539,
      "step": 40030
    },
    {
      "epoch": 11.44,
      "grad_norm": 0.00041708737262524664,
      "learning_rate": 4.746666666666667e-06,
      "loss": 0.0001,
      "step": 40040
    },
    {
      "epoch": 11.442857142857143,
      "grad_norm": 5.01393988088239e-05,
      "learning_rate": 4.742857142857144e-06,
      "loss": 0.0011,
      "step": 40050
    },
    {
      "epoch": 11.445714285714285,
      "grad_norm": 0.00025322323199361563,
      "learning_rate": 4.739047619047619e-06,
      "loss": 0.0,
      "step": 40060
    },
    {
      "epoch": 11.448571428571428,
      "grad_norm": 0.007587751839309931,
      "learning_rate": 4.735238095238096e-06,
      "loss": 0.0001,
      "step": 40070
    },
    {
      "epoch": 11.451428571428572,
      "grad_norm": 6.18375779595226e-05,
      "learning_rate": 4.731428571428572e-06,
      "loss": 0.1489,
      "step": 40080
    },
    {
      "epoch": 11.454285714285714,
      "grad_norm": 2.0011097149108537e-05,
      "learning_rate": 4.727619047619048e-06,
      "loss": 0.0002,
      "step": 40090
    },
    {
      "epoch": 11.457142857142857,
      "grad_norm": 0.06076979264616966,
      "learning_rate": 4.723809523809524e-06,
      "loss": 0.0895,
      "step": 40100
    },
    {
      "epoch": 11.46,
      "grad_norm": 0.011054742150008678,
      "learning_rate": 4.7200000000000005e-06,
      "loss": 0.0001,
      "step": 40110
    },
    {
      "epoch": 11.462857142857143,
      "grad_norm": 6.462629971792921e-05,
      "learning_rate": 4.716190476190476e-06,
      "loss": 0.0034,
      "step": 40120
    },
    {
      "epoch": 11.465714285714286,
      "grad_norm": 0.04796857014298439,
      "learning_rate": 4.7123809523809526e-06,
      "loss": 0.0004,
      "step": 40130
    },
    {
      "epoch": 11.468571428571428,
      "grad_norm": 0.007292516063898802,
      "learning_rate": 4.708571428571429e-06,
      "loss": 0.0002,
      "step": 40140
    },
    {
      "epoch": 11.471428571428572,
      "grad_norm": 0.007318045478314161,
      "learning_rate": 4.704761904761905e-06,
      "loss": 0.0001,
      "step": 40150
    },
    {
      "epoch": 11.474285714285715,
      "grad_norm": 0.01030501164495945,
      "learning_rate": 4.700952380952382e-06,
      "loss": 0.1224,
      "step": 40160
    },
    {
      "epoch": 11.477142857142857,
      "grad_norm": 0.00011746429663617164,
      "learning_rate": 4.6971428571428574e-06,
      "loss": 0.0001,
      "step": 40170
    },
    {
      "epoch": 11.48,
      "grad_norm": 0.002492826897650957,
      "learning_rate": 4.693333333333334e-06,
      "loss": 0.0001,
      "step": 40180
    },
    {
      "epoch": 11.482857142857142,
      "grad_norm": 0.08424597233533859,
      "learning_rate": 4.68952380952381e-06,
      "loss": 0.0004,
      "step": 40190
    },
    {
      "epoch": 11.485714285714286,
      "grad_norm": 0.0004444880469236523,
      "learning_rate": 4.685714285714286e-06,
      "loss": 0.1601,
      "step": 40200
    },
    {
      "epoch": 11.48857142857143,
      "grad_norm": 0.04492541775107384,
      "learning_rate": 4.681904761904762e-06,
      "loss": 0.096,
      "step": 40210
    },
    {
      "epoch": 11.491428571428571,
      "grad_norm": 1.9999395590275526e-05,
      "learning_rate": 4.678095238095238e-06,
      "loss": 0.0003,
      "step": 40220
    },
    {
      "epoch": 11.494285714285715,
      "grad_norm": 0.00814929697662592,
      "learning_rate": 4.674285714285714e-06,
      "loss": 0.2132,
      "step": 40230
    },
    {
      "epoch": 11.497142857142856,
      "grad_norm": 0.0017185317119583488,
      "learning_rate": 4.670476190476191e-06,
      "loss": 0.0005,
      "step": 40240
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.002479960909113288,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.0876,
      "step": 40250
    },
    {
      "epoch": 11.502857142857144,
      "grad_norm": 0.011045978404581547,
      "learning_rate": 4.662857142857144e-06,
      "loss": 0.0009,
      "step": 40260
    },
    {
      "epoch": 11.505714285714285,
      "grad_norm": 0.002544843126088381,
      "learning_rate": 4.659047619047619e-06,
      "loss": 0.2968,
      "step": 40270
    },
    {
      "epoch": 11.508571428571429,
      "grad_norm": 0.0022843650076538324,
      "learning_rate": 4.655238095238096e-06,
      "loss": 0.0002,
      "step": 40280
    },
    {
      "epoch": 11.51142857142857,
      "grad_norm": 0.0044198669493198395,
      "learning_rate": 4.651428571428572e-06,
      "loss": 0.0006,
      "step": 40290
    },
    {
      "epoch": 11.514285714285714,
      "grad_norm": 0.008332927711308002,
      "learning_rate": 4.647619047619048e-06,
      "loss": 0.0001,
      "step": 40300
    },
    {
      "epoch": 11.517142857142858,
      "grad_norm": 0.0020461478270590305,
      "learning_rate": 4.643809523809524e-06,
      "loss": 0.0001,
      "step": 40310
    },
    {
      "epoch": 11.52,
      "grad_norm": 45.03445053100586,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.1381,
      "step": 40320
    },
    {
      "epoch": 11.522857142857143,
      "grad_norm": 0.0007748811040073633,
      "learning_rate": 4.636190476190476e-06,
      "loss": 0.1778,
      "step": 40330
    },
    {
      "epoch": 11.525714285714285,
      "grad_norm": 0.024177351966500282,
      "learning_rate": 4.6323809523809525e-06,
      "loss": 0.1596,
      "step": 40340
    },
    {
      "epoch": 11.528571428571428,
      "grad_norm": 0.009283503517508507,
      "learning_rate": 4.628571428571429e-06,
      "loss": 0.0002,
      "step": 40350
    },
    {
      "epoch": 11.531428571428572,
      "grad_norm": 0.058960821479558945,
      "learning_rate": 4.624761904761905e-06,
      "loss": 0.0002,
      "step": 40360
    },
    {
      "epoch": 11.534285714285714,
      "grad_norm": 0.007034344132989645,
      "learning_rate": 4.620952380952382e-06,
      "loss": 0.0004,
      "step": 40370
    },
    {
      "epoch": 11.537142857142857,
      "grad_norm": 0.0017736873123794794,
      "learning_rate": 4.617142857142857e-06,
      "loss": 0.0003,
      "step": 40380
    },
    {
      "epoch": 11.54,
      "grad_norm": 0.0165950208902359,
      "learning_rate": 4.613333333333334e-06,
      "loss": 0.0001,
      "step": 40390
    },
    {
      "epoch": 11.542857142857143,
      "grad_norm": 0.0022559580393135548,
      "learning_rate": 4.60952380952381e-06,
      "loss": 0.2497,
      "step": 40400
    },
    {
      "epoch": 11.545714285714286,
      "grad_norm": 0.001719798892736435,
      "learning_rate": 4.605714285714286e-06,
      "loss": 0.0002,
      "step": 40410
    },
    {
      "epoch": 11.548571428571428,
      "grad_norm": 0.01230330765247345,
      "learning_rate": 4.601904761904762e-06,
      "loss": 0.1279,
      "step": 40420
    },
    {
      "epoch": 11.551428571428572,
      "grad_norm": 0.028615863993763924,
      "learning_rate": 4.598095238095239e-06,
      "loss": 0.0005,
      "step": 40430
    },
    {
      "epoch": 11.554285714285715,
      "grad_norm": 0.014857357367873192,
      "learning_rate": 4.594285714285714e-06,
      "loss": 0.0001,
      "step": 40440
    },
    {
      "epoch": 11.557142857142857,
      "grad_norm": 0.009865297004580498,
      "learning_rate": 4.590476190476191e-06,
      "loss": 0.0005,
      "step": 40450
    },
    {
      "epoch": 11.56,
      "grad_norm": 0.0010577915236353874,
      "learning_rate": 4.586666666666667e-06,
      "loss": 0.1089,
      "step": 40460
    },
    {
      "epoch": 11.562857142857142,
      "grad_norm": 0.0077371480874717236,
      "learning_rate": 4.5828571428571435e-06,
      "loss": 0.0003,
      "step": 40470
    },
    {
      "epoch": 11.565714285714286,
      "grad_norm": 0.011846535839140415,
      "learning_rate": 4.57904761904762e-06,
      "loss": 0.1919,
      "step": 40480
    },
    {
      "epoch": 11.56857142857143,
      "grad_norm": 0.3306087553501129,
      "learning_rate": 4.5752380952380955e-06,
      "loss": 0.0006,
      "step": 40490
    },
    {
      "epoch": 11.571428571428571,
      "grad_norm": 0.01375763863325119,
      "learning_rate": 4.571428571428572e-06,
      "loss": 0.0002,
      "step": 40500
    },
    {
      "epoch": 11.574285714285715,
      "grad_norm": 0.00024506633053533733,
      "learning_rate": 4.5676190476190475e-06,
      "loss": 0.0002,
      "step": 40510
    },
    {
      "epoch": 11.577142857142857,
      "grad_norm": 729.9683837890625,
      "learning_rate": 4.563809523809524e-06,
      "loss": 0.3573,
      "step": 40520
    },
    {
      "epoch": 11.58,
      "grad_norm": 0.004131763707846403,
      "learning_rate": 4.56e-06,
      "loss": 0.0002,
      "step": 40530
    },
    {
      "epoch": 11.582857142857144,
      "grad_norm": 0.05397626757621765,
      "learning_rate": 4.556190476190477e-06,
      "loss": 0.0019,
      "step": 40540
    },
    {
      "epoch": 11.585714285714285,
      "grad_norm": 0.0014733154093846679,
      "learning_rate": 4.552380952380952e-06,
      "loss": 0.0003,
      "step": 40550
    },
    {
      "epoch": 11.588571428571429,
      "grad_norm": 0.020016569644212723,
      "learning_rate": 4.548571428571429e-06,
      "loss": 0.0002,
      "step": 40560
    },
    {
      "epoch": 11.59142857142857,
      "grad_norm": 17.839061737060547,
      "learning_rate": 4.544761904761905e-06,
      "loss": 0.126,
      "step": 40570
    },
    {
      "epoch": 11.594285714285714,
      "grad_norm": 0.00011348772386554629,
      "learning_rate": 4.540952380952382e-06,
      "loss": 0.2579,
      "step": 40580
    },
    {
      "epoch": 11.597142857142858,
      "grad_norm": 0.00011897530202986673,
      "learning_rate": 4.537142857142858e-06,
      "loss": 0.0,
      "step": 40590
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.0006724450504407287,
      "learning_rate": 4.533333333333334e-06,
      "loss": 0.0002,
      "step": 40600
    },
    {
      "epoch": 11.602857142857143,
      "grad_norm": 0.000520376255735755,
      "learning_rate": 4.52952380952381e-06,
      "loss": 0.0002,
      "step": 40610
    },
    {
      "epoch": 11.605714285714285,
      "grad_norm": 0.005572622641921043,
      "learning_rate": 4.525714285714286e-06,
      "loss": 0.0001,
      "step": 40620
    },
    {
      "epoch": 11.608571428571429,
      "grad_norm": 0.05133089795708656,
      "learning_rate": 4.521904761904762e-06,
      "loss": 0.0003,
      "step": 40630
    },
    {
      "epoch": 11.611428571428572,
      "grad_norm": 0.00013893985305912793,
      "learning_rate": 4.5180952380952386e-06,
      "loss": 0.0698,
      "step": 40640
    },
    {
      "epoch": 11.614285714285714,
      "grad_norm": 0.007501919753849506,
      "learning_rate": 4.514285714285714e-06,
      "loss": 0.0,
      "step": 40650
    },
    {
      "epoch": 11.617142857142857,
      "grad_norm": 7.44645731174387e-05,
      "learning_rate": 4.5104761904761906e-06,
      "loss": 0.1699,
      "step": 40660
    },
    {
      "epoch": 11.62,
      "grad_norm": 0.01348040346056223,
      "learning_rate": 4.506666666666667e-06,
      "loss": 0.1833,
      "step": 40670
    },
    {
      "epoch": 11.622857142857143,
      "grad_norm": 0.002533534076064825,
      "learning_rate": 4.5028571428571434e-06,
      "loss": 0.0752,
      "step": 40680
    },
    {
      "epoch": 11.625714285714286,
      "grad_norm": 20.428565979003906,
      "learning_rate": 4.49904761904762e-06,
      "loss": 0.3292,
      "step": 40690
    },
    {
      "epoch": 11.628571428571428,
      "grad_norm": 0.011872807517647743,
      "learning_rate": 4.4952380952380954e-06,
      "loss": 0.1426,
      "step": 40700
    },
    {
      "epoch": 11.631428571428572,
      "grad_norm": 0.46944761276245117,
      "learning_rate": 4.491428571428572e-06,
      "loss": 0.0014,
      "step": 40710
    },
    {
      "epoch": 11.634285714285713,
      "grad_norm": 0.025404004380106926,
      "learning_rate": 4.487619047619048e-06,
      "loss": 0.0019,
      "step": 40720
    },
    {
      "epoch": 11.637142857142857,
      "grad_norm": 0.1009189561009407,
      "learning_rate": 4.483809523809524e-06,
      "loss": 0.0009,
      "step": 40730
    },
    {
      "epoch": 11.64,
      "grad_norm": 33.385887145996094,
      "learning_rate": 4.48e-06,
      "loss": 0.1162,
      "step": 40740
    },
    {
      "epoch": 11.642857142857142,
      "grad_norm": 0.048334963619709015,
      "learning_rate": 4.476190476190477e-06,
      "loss": 0.0031,
      "step": 40750
    },
    {
      "epoch": 11.645714285714286,
      "grad_norm": 13.558263778686523,
      "learning_rate": 4.472380952380952e-06,
      "loss": 0.1505,
      "step": 40760
    },
    {
      "epoch": 11.64857142857143,
      "grad_norm": 0.0018240056233480573,
      "learning_rate": 4.468571428571429e-06,
      "loss": 0.001,
      "step": 40770
    },
    {
      "epoch": 11.651428571428571,
      "grad_norm": 0.017084632068872452,
      "learning_rate": 4.464761904761905e-06,
      "loss": 0.0014,
      "step": 40780
    },
    {
      "epoch": 11.654285714285715,
      "grad_norm": 0.05742420628666878,
      "learning_rate": 4.460952380952382e-06,
      "loss": 0.0006,
      "step": 40790
    },
    {
      "epoch": 11.657142857142857,
      "grad_norm": 0.0035547595471143723,
      "learning_rate": 4.457142857142858e-06,
      "loss": 0.0003,
      "step": 40800
    },
    {
      "epoch": 11.66,
      "grad_norm": 0.16099420189857483,
      "learning_rate": 4.453333333333334e-06,
      "loss": 0.0005,
      "step": 40810
    },
    {
      "epoch": 11.662857142857142,
      "grad_norm": 0.0523211844265461,
      "learning_rate": 4.44952380952381e-06,
      "loss": 0.0085,
      "step": 40820
    },
    {
      "epoch": 11.665714285714285,
      "grad_norm": 0.000639281643088907,
      "learning_rate": 4.445714285714286e-06,
      "loss": 0.0001,
      "step": 40830
    },
    {
      "epoch": 11.668571428571429,
      "grad_norm": 9.16039789444767e-05,
      "learning_rate": 4.441904761904762e-06,
      "loss": 0.1269,
      "step": 40840
    },
    {
      "epoch": 11.67142857142857,
      "grad_norm": 0.0015128683298826218,
      "learning_rate": 4.4380952380952385e-06,
      "loss": 0.0101,
      "step": 40850
    },
    {
      "epoch": 11.674285714285714,
      "grad_norm": 0.00020859428332187235,
      "learning_rate": 4.434285714285715e-06,
      "loss": 0.0001,
      "step": 40860
    },
    {
      "epoch": 11.677142857142858,
      "grad_norm": 0.024763943627476692,
      "learning_rate": 4.4304761904761905e-06,
      "loss": 0.1578,
      "step": 40870
    },
    {
      "epoch": 11.68,
      "grad_norm": 0.01708308607339859,
      "learning_rate": 4.426666666666667e-06,
      "loss": 0.0002,
      "step": 40880
    },
    {
      "epoch": 11.682857142857143,
      "grad_norm": 0.004409554414451122,
      "learning_rate": 4.422857142857143e-06,
      "loss": 0.0002,
      "step": 40890
    },
    {
      "epoch": 11.685714285714285,
      "grad_norm": 78.20677947998047,
      "learning_rate": 4.41904761904762e-06,
      "loss": 0.2464,
      "step": 40900
    },
    {
      "epoch": 11.688571428571429,
      "grad_norm": 0.0010146067943423986,
      "learning_rate": 4.415238095238095e-06,
      "loss": 0.0002,
      "step": 40910
    },
    {
      "epoch": 11.691428571428572,
      "grad_norm": 0.05089680477976799,
      "learning_rate": 4.411428571428572e-06,
      "loss": 0.0005,
      "step": 40920
    },
    {
      "epoch": 11.694285714285714,
      "grad_norm": 0.0038009872660040855,
      "learning_rate": 4.407619047619048e-06,
      "loss": 0.0002,
      "step": 40930
    },
    {
      "epoch": 11.697142857142858,
      "grad_norm": 0.0004643869469873607,
      "learning_rate": 4.403809523809524e-06,
      "loss": 0.0021,
      "step": 40940
    },
    {
      "epoch": 11.7,
      "grad_norm": 0.00030219409381970763,
      "learning_rate": 4.4e-06,
      "loss": 0.035,
      "step": 40950
    },
    {
      "epoch": 11.702857142857143,
      "grad_norm": 0.0010196802904829383,
      "learning_rate": 4.396190476190477e-06,
      "loss": 0.1188,
      "step": 40960
    },
    {
      "epoch": 11.705714285714286,
      "grad_norm": 0.9688653349876404,
      "learning_rate": 4.392380952380953e-06,
      "loss": 0.0011,
      "step": 40970
    },
    {
      "epoch": 11.708571428571428,
      "grad_norm": 0.033216554671525955,
      "learning_rate": 4.388571428571429e-06,
      "loss": 0.0001,
      "step": 40980
    },
    {
      "epoch": 11.711428571428572,
      "grad_norm": 0.00028018574812449515,
      "learning_rate": 4.384761904761905e-06,
      "loss": 0.1236,
      "step": 40990
    },
    {
      "epoch": 11.714285714285714,
      "grad_norm": 0.00021999527234584093,
      "learning_rate": 4.3809523809523815e-06,
      "loss": 0.0427,
      "step": 41000
    },
    {
      "epoch": 11.717142857142857,
      "grad_norm": 0.021977635100483894,
      "learning_rate": 4.377142857142858e-06,
      "loss": 0.001,
      "step": 41010
    },
    {
      "epoch": 11.72,
      "grad_norm": 0.023932654410600662,
      "learning_rate": 4.3733333333333335e-06,
      "loss": 0.1894,
      "step": 41020
    },
    {
      "epoch": 11.722857142857142,
      "grad_norm": 0.0012394925579428673,
      "learning_rate": 4.36952380952381e-06,
      "loss": 0.0005,
      "step": 41030
    },
    {
      "epoch": 11.725714285714286,
      "grad_norm": 0.025163907557725906,
      "learning_rate": 4.3657142857142855e-06,
      "loss": 0.2802,
      "step": 41040
    },
    {
      "epoch": 11.728571428571428,
      "grad_norm": 0.5572083592414856,
      "learning_rate": 4.361904761904762e-06,
      "loss": 0.0094,
      "step": 41050
    },
    {
      "epoch": 11.731428571428571,
      "grad_norm": 0.057172611355781555,
      "learning_rate": 4.358095238095238e-06,
      "loss": 0.002,
      "step": 41060
    },
    {
      "epoch": 11.734285714285715,
      "grad_norm": 0.00595281133428216,
      "learning_rate": 4.354285714285715e-06,
      "loss": 0.2818,
      "step": 41070
    },
    {
      "epoch": 11.737142857142857,
      "grad_norm": 0.031616657972335815,
      "learning_rate": 4.350476190476191e-06,
      "loss": 0.0029,
      "step": 41080
    },
    {
      "epoch": 11.74,
      "grad_norm": 0.00010785085760289803,
      "learning_rate": 4.346666666666667e-06,
      "loss": 0.1122,
      "step": 41090
    },
    {
      "epoch": 11.742857142857144,
      "grad_norm": 0.03627067804336548,
      "learning_rate": 4.342857142857143e-06,
      "loss": 0.3474,
      "step": 41100
    },
    {
      "epoch": 11.745714285714286,
      "grad_norm": 0.0003436428669374436,
      "learning_rate": 4.33904761904762e-06,
      "loss": 0.1122,
      "step": 41110
    },
    {
      "epoch": 11.748571428571429,
      "grad_norm": 0.044425737112760544,
      "learning_rate": 4.335238095238095e-06,
      "loss": 0.0935,
      "step": 41120
    },
    {
      "epoch": 11.751428571428571,
      "grad_norm": 0.00015395299124065787,
      "learning_rate": 4.331428571428572e-06,
      "loss": 0.0019,
      "step": 41130
    },
    {
      "epoch": 11.754285714285714,
      "grad_norm": 9.026675979839638e-05,
      "learning_rate": 4.327619047619048e-06,
      "loss": 0.0857,
      "step": 41140
    },
    {
      "epoch": 11.757142857142856,
      "grad_norm": 0.00019037624588236213,
      "learning_rate": 4.323809523809524e-06,
      "loss": 0.0646,
      "step": 41150
    },
    {
      "epoch": 11.76,
      "grad_norm": 0.07428862154483795,
      "learning_rate": 4.32e-06,
      "loss": 0.0003,
      "step": 41160
    },
    {
      "epoch": 11.762857142857143,
      "grad_norm": 0.000302815402392298,
      "learning_rate": 4.3161904761904766e-06,
      "loss": 0.1148,
      "step": 41170
    },
    {
      "epoch": 11.765714285714285,
      "grad_norm": 0.02758393995463848,
      "learning_rate": 4.312380952380953e-06,
      "loss": 0.0028,
      "step": 41180
    },
    {
      "epoch": 11.768571428571429,
      "grad_norm": 0.01729608327150345,
      "learning_rate": 4.3085714285714294e-06,
      "loss": 0.0006,
      "step": 41190
    },
    {
      "epoch": 11.771428571428572,
      "grad_norm": 0.0004681581922341138,
      "learning_rate": 4.304761904761905e-06,
      "loss": 0.1699,
      "step": 41200
    },
    {
      "epoch": 11.774285714285714,
      "grad_norm": 0.08212120831012726,
      "learning_rate": 4.3009523809523814e-06,
      "loss": 0.059,
      "step": 41210
    },
    {
      "epoch": 11.777142857142858,
      "grad_norm": 1.9369274014024995e-05,
      "learning_rate": 4.297142857142858e-06,
      "loss": 0.0011,
      "step": 41220
    },
    {
      "epoch": 11.78,
      "grad_norm": 0.007025805301964283,
      "learning_rate": 4.2933333333333334e-06,
      "loss": 0.0028,
      "step": 41230
    },
    {
      "epoch": 11.782857142857143,
      "grad_norm": 0.00017117589595727623,
      "learning_rate": 4.28952380952381e-06,
      "loss": 0.0003,
      "step": 41240
    },
    {
      "epoch": 11.785714285714286,
      "grad_norm": 0.0030026151798665524,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.1108,
      "step": 41250
    },
    {
      "epoch": 11.788571428571428,
      "grad_norm": 0.05649050325155258,
      "learning_rate": 4.281904761904762e-06,
      "loss": 0.2717,
      "step": 41260
    },
    {
      "epoch": 11.791428571428572,
      "grad_norm": 0.00035018110065720975,
      "learning_rate": 4.278095238095238e-06,
      "loss": 0.1173,
      "step": 41270
    },
    {
      "epoch": 11.794285714285714,
      "grad_norm": 0.023886723443865776,
      "learning_rate": 4.274285714285715e-06,
      "loss": 0.0003,
      "step": 41280
    },
    {
      "epoch": 11.797142857142857,
      "grad_norm": 0.00014480360550805926,
      "learning_rate": 4.270476190476191e-06,
      "loss": 0.0005,
      "step": 41290
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.275351345539093,
      "learning_rate": 4.266666666666668e-06,
      "loss": 0.0016,
      "step": 41300
    },
    {
      "epoch": 11.802857142857142,
      "grad_norm": 0.00041267770575359464,
      "learning_rate": 4.262857142857143e-06,
      "loss": 0.0007,
      "step": 41310
    },
    {
      "epoch": 11.805714285714286,
      "grad_norm": 0.06138329580426216,
      "learning_rate": 4.25904761904762e-06,
      "loss": 0.1488,
      "step": 41320
    },
    {
      "epoch": 11.808571428571428,
      "grad_norm": 0.004666706081479788,
      "learning_rate": 4.255238095238095e-06,
      "loss": 0.0002,
      "step": 41330
    },
    {
      "epoch": 11.811428571428571,
      "grad_norm": 0.01974583975970745,
      "learning_rate": 4.251428571428572e-06,
      "loss": 0.0004,
      "step": 41340
    },
    {
      "epoch": 11.814285714285715,
      "grad_norm": 15.239301681518555,
      "learning_rate": 4.247619047619048e-06,
      "loss": 0.0849,
      "step": 41350
    },
    {
      "epoch": 11.817142857142857,
      "grad_norm": 0.1310376226902008,
      "learning_rate": 4.243809523809524e-06,
      "loss": 0.1198,
      "step": 41360
    },
    {
      "epoch": 11.82,
      "grad_norm": 0.010229933075606823,
      "learning_rate": 4.24e-06,
      "loss": 0.0002,
      "step": 41370
    },
    {
      "epoch": 11.822857142857142,
      "grad_norm": 0.4219154715538025,
      "learning_rate": 4.2361904761904765e-06,
      "loss": 0.1378,
      "step": 41380
    },
    {
      "epoch": 11.825714285714286,
      "grad_norm": 0.0011299385223537683,
      "learning_rate": 4.232380952380953e-06,
      "loss": 0.1054,
      "step": 41390
    },
    {
      "epoch": 11.82857142857143,
      "grad_norm": 0.039223309606313705,
      "learning_rate": 4.228571428571429e-06,
      "loss": 0.0012,
      "step": 41400
    },
    {
      "epoch": 11.831428571428571,
      "grad_norm": 0.05582239478826523,
      "learning_rate": 4.224761904761905e-06,
      "loss": 0.0969,
      "step": 41410
    },
    {
      "epoch": 11.834285714285715,
      "grad_norm": 0.01860945299267769,
      "learning_rate": 4.220952380952381e-06,
      "loss": 0.0002,
      "step": 41420
    },
    {
      "epoch": 11.837142857142858,
      "grad_norm": 0.009139918722212315,
      "learning_rate": 4.217142857142858e-06,
      "loss": 0.0011,
      "step": 41430
    },
    {
      "epoch": 11.84,
      "grad_norm": 0.24312013387680054,
      "learning_rate": 4.213333333333333e-06,
      "loss": 0.0008,
      "step": 41440
    },
    {
      "epoch": 11.842857142857143,
      "grad_norm": 0.010549426078796387,
      "learning_rate": 4.20952380952381e-06,
      "loss": 0.0286,
      "step": 41450
    },
    {
      "epoch": 11.845714285714285,
      "grad_norm": 4.418812022777274e-05,
      "learning_rate": 4.205714285714286e-06,
      "loss": 0.0005,
      "step": 41460
    },
    {
      "epoch": 11.848571428571429,
      "grad_norm": 0.004286229144781828,
      "learning_rate": 4.201904761904762e-06,
      "loss": 0.1318,
      "step": 41470
    },
    {
      "epoch": 11.85142857142857,
      "grad_norm": 0.010050320066511631,
      "learning_rate": 4.198095238095238e-06,
      "loss": 0.1073,
      "step": 41480
    },
    {
      "epoch": 11.854285714285714,
      "grad_norm": 0.06925807148218155,
      "learning_rate": 4.194285714285715e-06,
      "loss": 0.1515,
      "step": 41490
    },
    {
      "epoch": 11.857142857142858,
      "grad_norm": 0.02169031836092472,
      "learning_rate": 4.190476190476191e-06,
      "loss": 0.0008,
      "step": 41500
    },
    {
      "epoch": 11.86,
      "grad_norm": 0.00975058600306511,
      "learning_rate": 4.1866666666666675e-06,
      "loss": 0.1111,
      "step": 41510
    },
    {
      "epoch": 11.862857142857143,
      "grad_norm": 0.021632280200719833,
      "learning_rate": 4.182857142857143e-06,
      "loss": 0.0003,
      "step": 41520
    },
    {
      "epoch": 11.865714285714287,
      "grad_norm": 0.00039433781057596207,
      "learning_rate": 4.1790476190476195e-06,
      "loss": 0.0,
      "step": 41530
    },
    {
      "epoch": 11.868571428571428,
      "grad_norm": 0.011038307100534439,
      "learning_rate": 4.175238095238095e-06,
      "loss": 0.0013,
      "step": 41540
    },
    {
      "epoch": 11.871428571428572,
      "grad_norm": 0.0003208912967238575,
      "learning_rate": 4.1714285714285715e-06,
      "loss": 0.0849,
      "step": 41550
    },
    {
      "epoch": 11.874285714285714,
      "grad_norm": 0.00686989538371563,
      "learning_rate": 4.167619047619048e-06,
      "loss": 0.0002,
      "step": 41560
    },
    {
      "epoch": 11.877142857142857,
      "grad_norm": 0.06043020635843277,
      "learning_rate": 4.163809523809524e-06,
      "loss": 0.1155,
      "step": 41570
    },
    {
      "epoch": 11.88,
      "grad_norm": 4.871923374594189e-05,
      "learning_rate": 4.16e-06,
      "loss": 0.001,
      "step": 41580
    },
    {
      "epoch": 11.882857142857143,
      "grad_norm": 6.94746122462675e-05,
      "learning_rate": 4.156190476190476e-06,
      "loss": 0.0029,
      "step": 41590
    },
    {
      "epoch": 11.885714285714286,
      "grad_norm": 0.0003869074862450361,
      "learning_rate": 4.152380952380953e-06,
      "loss": 0.0001,
      "step": 41600
    },
    {
      "epoch": 11.888571428571428,
      "grad_norm": 14.811285018920898,
      "learning_rate": 4.148571428571429e-06,
      "loss": 0.0616,
      "step": 41610
    },
    {
      "epoch": 11.891428571428571,
      "grad_norm": 0.018444841727614403,
      "learning_rate": 4.144761904761906e-06,
      "loss": 0.1923,
      "step": 41620
    },
    {
      "epoch": 11.894285714285715,
      "grad_norm": 0.0064620450139045715,
      "learning_rate": 4.140952380952381e-06,
      "loss": 0.0012,
      "step": 41630
    },
    {
      "epoch": 11.897142857142857,
      "grad_norm": 0.00245205732062459,
      "learning_rate": 4.137142857142858e-06,
      "loss": 0.0857,
      "step": 41640
    },
    {
      "epoch": 11.9,
      "grad_norm": 0.00017576896061655134,
      "learning_rate": 4.133333333333333e-06,
      "loss": 0.0003,
      "step": 41650
    },
    {
      "epoch": 11.902857142857142,
      "grad_norm": 0.012571225874125957,
      "learning_rate": 4.12952380952381e-06,
      "loss": 0.0002,
      "step": 41660
    },
    {
      "epoch": 11.905714285714286,
      "grad_norm": 0.0030458797700703144,
      "learning_rate": 4.125714285714286e-06,
      "loss": 0.0815,
      "step": 41670
    },
    {
      "epoch": 11.90857142857143,
      "grad_norm": 0.00010037299216492102,
      "learning_rate": 4.1219047619047626e-06,
      "loss": 0.0002,
      "step": 41680
    },
    {
      "epoch": 11.911428571428571,
      "grad_norm": 0.014814555644989014,
      "learning_rate": 4.118095238095238e-06,
      "loss": 0.0534,
      "step": 41690
    },
    {
      "epoch": 11.914285714285715,
      "grad_norm": 0.001310180057771504,
      "learning_rate": 4.114285714285715e-06,
      "loss": 0.0003,
      "step": 41700
    },
    {
      "epoch": 11.917142857142856,
      "grad_norm": 0.002822232898324728,
      "learning_rate": 4.110476190476191e-06,
      "loss": 0.1677,
      "step": 41710
    },
    {
      "epoch": 11.92,
      "grad_norm": 0.0006222716765478253,
      "learning_rate": 4.1066666666666674e-06,
      "loss": 0.0875,
      "step": 41720
    },
    {
      "epoch": 11.922857142857143,
      "grad_norm": 0.000329437229083851,
      "learning_rate": 4.102857142857143e-06,
      "loss": 0.1255,
      "step": 41730
    },
    {
      "epoch": 11.925714285714285,
      "grad_norm": 0.0019406700739637017,
      "learning_rate": 4.0990476190476195e-06,
      "loss": 0.0014,
      "step": 41740
    },
    {
      "epoch": 11.928571428571429,
      "grad_norm": 0.0001869767438620329,
      "learning_rate": 4.095238095238096e-06,
      "loss": 0.0006,
      "step": 41750
    },
    {
      "epoch": 11.93142857142857,
      "grad_norm": 0.0001951662270585075,
      "learning_rate": 4.0914285714285715e-06,
      "loss": 0.1736,
      "step": 41760
    },
    {
      "epoch": 11.934285714285714,
      "grad_norm": 7.29481180314906e-05,
      "learning_rate": 4.087619047619048e-06,
      "loss": 0.0013,
      "step": 41770
    },
    {
      "epoch": 11.937142857142858,
      "grad_norm": 0.0071945227682590485,
      "learning_rate": 4.083809523809524e-06,
      "loss": 0.1247,
      "step": 41780
    },
    {
      "epoch": 11.94,
      "grad_norm": 0.013022027909755707,
      "learning_rate": 4.08e-06,
      "loss": 0.0008,
      "step": 41790
    },
    {
      "epoch": 11.942857142857143,
      "grad_norm": 0.0006850755889900029,
      "learning_rate": 4.076190476190476e-06,
      "loss": 0.0005,
      "step": 41800
    },
    {
      "epoch": 11.945714285714285,
      "grad_norm": 0.010963767766952515,
      "learning_rate": 4.072380952380953e-06,
      "loss": 0.0001,
      "step": 41810
    },
    {
      "epoch": 11.948571428571428,
      "grad_norm": 0.000658777542412281,
      "learning_rate": 4.068571428571429e-06,
      "loss": 0.0001,
      "step": 41820
    },
    {
      "epoch": 11.951428571428572,
      "grad_norm": 0.000514560379087925,
      "learning_rate": 4.064761904761906e-06,
      "loss": 0.2272,
      "step": 41830
    },
    {
      "epoch": 11.954285714285714,
      "grad_norm": 0.32166165113449097,
      "learning_rate": 4.060952380952381e-06,
      "loss": 0.0005,
      "step": 41840
    },
    {
      "epoch": 11.957142857142857,
      "grad_norm": 0.0031379726715385914,
      "learning_rate": 4.057142857142858e-06,
      "loss": 0.0757,
      "step": 41850
    },
    {
      "epoch": 11.96,
      "grad_norm": 0.004978806711733341,
      "learning_rate": 4.053333333333333e-06,
      "loss": 0.0032,
      "step": 41860
    },
    {
      "epoch": 11.962857142857143,
      "grad_norm": 0.006407100707292557,
      "learning_rate": 4.04952380952381e-06,
      "loss": 0.0001,
      "step": 41870
    },
    {
      "epoch": 11.965714285714286,
      "grad_norm": 0.00025933212600648403,
      "learning_rate": 4.045714285714286e-06,
      "loss": 0.0849,
      "step": 41880
    },
    {
      "epoch": 11.968571428571428,
      "grad_norm": 0.001929465332068503,
      "learning_rate": 4.0419047619047625e-06,
      "loss": 0.0001,
      "step": 41890
    },
    {
      "epoch": 11.971428571428572,
      "grad_norm": 0.0016175133641809225,
      "learning_rate": 4.038095238095238e-06,
      "loss": 0.1322,
      "step": 41900
    },
    {
      "epoch": 11.974285714285715,
      "grad_norm": 0.00010393116826890036,
      "learning_rate": 4.0342857142857145e-06,
      "loss": 0.0004,
      "step": 41910
    },
    {
      "epoch": 11.977142857142857,
      "grad_norm": 3.675188054330647e-05,
      "learning_rate": 4.030476190476191e-06,
      "loss": 0.0003,
      "step": 41920
    },
    {
      "epoch": 11.98,
      "grad_norm": 0.02104947715997696,
      "learning_rate": 4.026666666666667e-06,
      "loss": 0.0002,
      "step": 41930
    },
    {
      "epoch": 11.982857142857142,
      "grad_norm": 0.0683765783905983,
      "learning_rate": 4.022857142857143e-06,
      "loss": 0.0003,
      "step": 41940
    },
    {
      "epoch": 11.985714285714286,
      "grad_norm": 0.03437132388353348,
      "learning_rate": 4.019047619047619e-06,
      "loss": 0.0408,
      "step": 41950
    },
    {
      "epoch": 11.98857142857143,
      "grad_norm": 0.0003425826726015657,
      "learning_rate": 4.015238095238096e-06,
      "loss": 0.0006,
      "step": 41960
    },
    {
      "epoch": 11.991428571428571,
      "grad_norm": 0.009251555427908897,
      "learning_rate": 4.011428571428571e-06,
      "loss": 0.0001,
      "step": 41970
    },
    {
      "epoch": 11.994285714285715,
      "grad_norm": 0.09543735533952713,
      "learning_rate": 4.007619047619048e-06,
      "loss": 0.1534,
      "step": 41980
    },
    {
      "epoch": 11.997142857142856,
      "grad_norm": 0.0017972382484003901,
      "learning_rate": 4.003809523809524e-06,
      "loss": 0.0006,
      "step": 41990
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.0003277505747973919,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2103,
      "step": 42000
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.9663333333333334,
      "eval_f1": 0.8414442700156985,
      "eval_loss": 0.2555752396583557,
      "eval_precision": 0.8786885245901639,
      "eval_recall": 0.8072289156626506,
      "eval_runtime": 266.4441,
      "eval_samples_per_second": 11.259,
      "eval_steps_per_second": 2.815,
      "step": 42000
    },
    {
      "epoch": 12.002857142857144,
      "grad_norm": 0.00048552738735452294,
      "learning_rate": 3.996190476190476e-06,
      "loss": 0.0004,
      "step": 42010
    },
    {
      "epoch": 12.005714285714285,
      "grad_norm": 0.012193922884762287,
      "learning_rate": 3.992380952380953e-06,
      "loss": 0.0,
      "step": 42020
    },
    {
      "epoch": 12.008571428571429,
      "grad_norm": 0.007765785790979862,
      "learning_rate": 3.988571428571429e-06,
      "loss": 0.0001,
      "step": 42030
    },
    {
      "epoch": 12.01142857142857,
      "grad_norm": 0.12031286209821701,
      "learning_rate": 3.9847619047619055e-06,
      "loss": 0.2852,
      "step": 42040
    },
    {
      "epoch": 12.014285714285714,
      "grad_norm": 0.007739122025668621,
      "learning_rate": 3.980952380952381e-06,
      "loss": 0.0001,
      "step": 42050
    },
    {
      "epoch": 12.017142857142858,
      "grad_norm": 0.04283557087182999,
      "learning_rate": 3.9771428571428575e-06,
      "loss": 0.0003,
      "step": 42060
    },
    {
      "epoch": 12.02,
      "grad_norm": 0.0270322784781456,
      "learning_rate": 3.973333333333333e-06,
      "loss": 0.0002,
      "step": 42070
    },
    {
      "epoch": 12.022857142857143,
      "grad_norm": 0.007897083647549152,
      "learning_rate": 3.9695238095238096e-06,
      "loss": 0.0007,
      "step": 42080
    },
    {
      "epoch": 12.025714285714285,
      "grad_norm": 0.041173335164785385,
      "learning_rate": 3.965714285714286e-06,
      "loss": 0.0001,
      "step": 42090
    },
    {
      "epoch": 12.028571428571428,
      "grad_norm": 0.0009238350903615355,
      "learning_rate": 3.961904761904762e-06,
      "loss": 0.0001,
      "step": 42100
    },
    {
      "epoch": 12.031428571428572,
      "grad_norm": 0.08579867333173752,
      "learning_rate": 3.958095238095239e-06,
      "loss": 0.128,
      "step": 42110
    },
    {
      "epoch": 12.034285714285714,
      "grad_norm": 0.0022062910720705986,
      "learning_rate": 3.954285714285714e-06,
      "loss": 0.0078,
      "step": 42120
    },
    {
      "epoch": 12.037142857142857,
      "grad_norm": 0.000581911881454289,
      "learning_rate": 3.950476190476191e-06,
      "loss": 0.0,
      "step": 42130
    },
    {
      "epoch": 12.04,
      "grad_norm": 0.00036259391345083714,
      "learning_rate": 3.946666666666667e-06,
      "loss": 0.0001,
      "step": 42140
    },
    {
      "epoch": 12.042857142857143,
      "grad_norm": 0.0001669203193159774,
      "learning_rate": 3.942857142857143e-06,
      "loss": 0.0001,
      "step": 42150
    },
    {
      "epoch": 12.045714285714286,
      "grad_norm": 0.0013120563235133886,
      "learning_rate": 3.939047619047619e-06,
      "loss": 0.0002,
      "step": 42160
    },
    {
      "epoch": 12.048571428571428,
      "grad_norm": 0.00430721091106534,
      "learning_rate": 3.935238095238096e-06,
      "loss": 0.205,
      "step": 42170
    },
    {
      "epoch": 12.051428571428572,
      "grad_norm": 9.192104334942997e-05,
      "learning_rate": 3.931428571428571e-06,
      "loss": 0.0001,
      "step": 42180
    },
    {
      "epoch": 12.054285714285715,
      "grad_norm": 6.522460898850113e-05,
      "learning_rate": 3.927619047619048e-06,
      "loss": 0.0001,
      "step": 42190
    },
    {
      "epoch": 12.057142857142857,
      "grad_norm": 0.0031798125710338354,
      "learning_rate": 3.923809523809524e-06,
      "loss": 0.0,
      "step": 42200
    },
    {
      "epoch": 12.06,
      "grad_norm": 0.003266309853643179,
      "learning_rate": 3.920000000000001e-06,
      "loss": 0.2299,
      "step": 42210
    },
    {
      "epoch": 12.062857142857142,
      "grad_norm": 0.0045527508482337,
      "learning_rate": 3.916190476190477e-06,
      "loss": 0.0001,
      "step": 42220
    },
    {
      "epoch": 12.065714285714286,
      "grad_norm": 0.00034335622331127524,
      "learning_rate": 3.912380952380953e-06,
      "loss": 0.0004,
      "step": 42230
    },
    {
      "epoch": 12.06857142857143,
      "grad_norm": 0.0069158342666924,
      "learning_rate": 3.908571428571429e-06,
      "loss": 0.2086,
      "step": 42240
    },
    {
      "epoch": 12.071428571428571,
      "grad_norm": 0.005136760417371988,
      "learning_rate": 3.9047619047619055e-06,
      "loss": 0.0001,
      "step": 42250
    },
    {
      "epoch": 12.074285714285715,
      "grad_norm": 0.011020560748875141,
      "learning_rate": 3.900952380952381e-06,
      "loss": 0.0001,
      "step": 42260
    },
    {
      "epoch": 12.077142857142857,
      "grad_norm": 0.0001392498379573226,
      "learning_rate": 3.8971428571428575e-06,
      "loss": 0.0004,
      "step": 42270
    },
    {
      "epoch": 12.08,
      "grad_norm": 0.020415902137756348,
      "learning_rate": 3.893333333333333e-06,
      "loss": 0.1932,
      "step": 42280
    },
    {
      "epoch": 12.082857142857144,
      "grad_norm": 0.0615522526204586,
      "learning_rate": 3.8895238095238095e-06,
      "loss": 0.0002,
      "step": 42290
    },
    {
      "epoch": 12.085714285714285,
      "grad_norm": 0.011195606552064419,
      "learning_rate": 3.885714285714286e-06,
      "loss": 0.0002,
      "step": 42300
    },
    {
      "epoch": 12.088571428571429,
      "grad_norm": 0.04196016862988472,
      "learning_rate": 3.881904761904762e-06,
      "loss": 0.0005,
      "step": 42310
    },
    {
      "epoch": 12.09142857142857,
      "grad_norm": 0.12918442487716675,
      "learning_rate": 3.878095238095239e-06,
      "loss": 0.0003,
      "step": 42320
    },
    {
      "epoch": 12.094285714285714,
      "grad_norm": 0.028189629316329956,
      "learning_rate": 3.874285714285715e-06,
      "loss": 0.0002,
      "step": 42330
    },
    {
      "epoch": 12.097142857142858,
      "grad_norm": 2.3449696527677588e-05,
      "learning_rate": 3.870476190476191e-06,
      "loss": 0.0001,
      "step": 42340
    },
    {
      "epoch": 12.1,
      "grad_norm": 3.543001366779208e-05,
      "learning_rate": 3.866666666666667e-06,
      "loss": 0.1394,
      "step": 42350
    },
    {
      "epoch": 12.102857142857143,
      "grad_norm": 0.016159357503056526,
      "learning_rate": 3.862857142857143e-06,
      "loss": 0.0002,
      "step": 42360
    },
    {
      "epoch": 12.105714285714285,
      "grad_norm": 0.00011921759141841903,
      "learning_rate": 3.859047619047619e-06,
      "loss": 0.0001,
      "step": 42370
    },
    {
      "epoch": 12.108571428571429,
      "grad_norm": 2.436988870613277e-05,
      "learning_rate": 3.855238095238096e-06,
      "loss": 0.001,
      "step": 42380
    },
    {
      "epoch": 12.111428571428572,
      "grad_norm": 4.845457442570478e-05,
      "learning_rate": 3.851428571428571e-06,
      "loss": 0.0005,
      "step": 42390
    },
    {
      "epoch": 12.114285714285714,
      "grad_norm": 0.01569681242108345,
      "learning_rate": 3.847619047619048e-06,
      "loss": 0.0,
      "step": 42400
    },
    {
      "epoch": 12.117142857142857,
      "grad_norm": 0.05598470941185951,
      "learning_rate": 3.843809523809524e-06,
      "loss": 0.0001,
      "step": 42410
    },
    {
      "epoch": 12.12,
      "grad_norm": 0.0852474644780159,
      "learning_rate": 3.8400000000000005e-06,
      "loss": 0.0006,
      "step": 42420
    },
    {
      "epoch": 12.122857142857143,
      "grad_norm": 0.0011130666825920343,
      "learning_rate": 3.836190476190477e-06,
      "loss": 0.0001,
      "step": 42430
    },
    {
      "epoch": 12.125714285714286,
      "grad_norm": 0.05454973503947258,
      "learning_rate": 3.8323809523809525e-06,
      "loss": 0.1682,
      "step": 42440
    },
    {
      "epoch": 12.128571428571428,
      "grad_norm": 0.053346890956163406,
      "learning_rate": 3.828571428571429e-06,
      "loss": 0.0002,
      "step": 42450
    },
    {
      "epoch": 12.131428571428572,
      "grad_norm": 0.06913577020168304,
      "learning_rate": 3.824761904761905e-06,
      "loss": 0.0001,
      "step": 42460
    },
    {
      "epoch": 12.134285714285713,
      "grad_norm": 0.011607117019593716,
      "learning_rate": 3.820952380952381e-06,
      "loss": 0.0001,
      "step": 42470
    },
    {
      "epoch": 12.137142857142857,
      "grad_norm": 0.00011203522444702685,
      "learning_rate": 3.817142857142857e-06,
      "loss": 0.1089,
      "step": 42480
    },
    {
      "epoch": 12.14,
      "grad_norm": 5.466950096888468e-05,
      "learning_rate": 3.813333333333334e-06,
      "loss": 0.0004,
      "step": 42490
    },
    {
      "epoch": 12.142857142857142,
      "grad_norm": 0.002624872839078307,
      "learning_rate": 3.80952380952381e-06,
      "loss": 0.1115,
      "step": 42500
    },
    {
      "epoch": 12.145714285714286,
      "grad_norm": 6.41338701825589e-05,
      "learning_rate": 3.805714285714286e-06,
      "loss": 0.1523,
      "step": 42510
    },
    {
      "epoch": 12.14857142857143,
      "grad_norm": 0.002856039209291339,
      "learning_rate": 3.8019047619047622e-06,
      "loss": 0.1446,
      "step": 42520
    },
    {
      "epoch": 12.151428571428571,
      "grad_norm": 0.00020818669872824103,
      "learning_rate": 3.7980952380952387e-06,
      "loss": 0.0006,
      "step": 42530
    },
    {
      "epoch": 12.154285714285715,
      "grad_norm": 2.407724787190091e-05,
      "learning_rate": 3.7942857142857147e-06,
      "loss": 0.0004,
      "step": 42540
    },
    {
      "epoch": 12.157142857142857,
      "grad_norm": 0.0006963263731449842,
      "learning_rate": 3.7904761904761907e-06,
      "loss": 0.0001,
      "step": 42550
    },
    {
      "epoch": 12.16,
      "grad_norm": 38.630130767822266,
      "learning_rate": 3.7866666666666667e-06,
      "loss": 0.1101,
      "step": 42560
    },
    {
      "epoch": 12.162857142857144,
      "grad_norm": 8.937253733165562e-05,
      "learning_rate": 3.782857142857143e-06,
      "loss": 0.0002,
      "step": 42570
    },
    {
      "epoch": 12.165714285714285,
      "grad_norm": 24.08501625061035,
      "learning_rate": 3.7790476190476196e-06,
      "loss": 0.3216,
      "step": 42580
    },
    {
      "epoch": 12.168571428571429,
      "grad_norm": 0.012371215969324112,
      "learning_rate": 3.7752380952380956e-06,
      "loss": 0.0001,
      "step": 42590
    },
    {
      "epoch": 12.17142857142857,
      "grad_norm": 0.06355437636375427,
      "learning_rate": 3.771428571428572e-06,
      "loss": 0.0017,
      "step": 42600
    },
    {
      "epoch": 12.174285714285714,
      "grad_norm": 0.0014258817536756396,
      "learning_rate": 3.7676190476190476e-06,
      "loss": 0.0026,
      "step": 42610
    },
    {
      "epoch": 12.177142857142858,
      "grad_norm": 0.0010904427617788315,
      "learning_rate": 3.763809523809524e-06,
      "loss": 0.0005,
      "step": 42620
    },
    {
      "epoch": 12.18,
      "grad_norm": 0.001151164760813117,
      "learning_rate": 3.7600000000000004e-06,
      "loss": 0.0001,
      "step": 42630
    },
    {
      "epoch": 12.182857142857143,
      "grad_norm": 0.007216110825538635,
      "learning_rate": 3.7561904761904764e-06,
      "loss": 0.1563,
      "step": 42640
    },
    {
      "epoch": 12.185714285714285,
      "grad_norm": 0.005814822856336832,
      "learning_rate": 3.752380952380953e-06,
      "loss": 0.0006,
      "step": 42650
    },
    {
      "epoch": 12.188571428571429,
      "grad_norm": 0.2122703641653061,
      "learning_rate": 3.7485714285714284e-06,
      "loss": 0.0005,
      "step": 42660
    },
    {
      "epoch": 12.191428571428572,
      "grad_norm": 0.009465052746236324,
      "learning_rate": 3.744761904761905e-06,
      "loss": 0.0003,
      "step": 42670
    },
    {
      "epoch": 12.194285714285714,
      "grad_norm": 0.00011732011626008898,
      "learning_rate": 3.7409523809523813e-06,
      "loss": 0.1388,
      "step": 42680
    },
    {
      "epoch": 12.197142857142858,
      "grad_norm": 0.012052038684487343,
      "learning_rate": 3.7371428571428577e-06,
      "loss": 0.0002,
      "step": 42690
    },
    {
      "epoch": 12.2,
      "grad_norm": 0.10882174223661423,
      "learning_rate": 3.7333333333333337e-06,
      "loss": 0.2009,
      "step": 42700
    },
    {
      "epoch": 12.202857142857143,
      "grad_norm": 0.00013365531049203128,
      "learning_rate": 3.72952380952381e-06,
      "loss": 0.0001,
      "step": 42710
    },
    {
      "epoch": 12.205714285714286,
      "grad_norm": 0.0002029776806011796,
      "learning_rate": 3.7257142857142857e-06,
      "loss": 0.0007,
      "step": 42720
    },
    {
      "epoch": 12.208571428571428,
      "grad_norm": 0.00034905836218968034,
      "learning_rate": 3.721904761904762e-06,
      "loss": 0.011,
      "step": 42730
    },
    {
      "epoch": 12.211428571428572,
      "grad_norm": 0.0072695473209023476,
      "learning_rate": 3.7180952380952386e-06,
      "loss": 0.0006,
      "step": 42740
    },
    {
      "epoch": 12.214285714285714,
      "grad_norm": 0.0062070139683783054,
      "learning_rate": 3.7142857142857146e-06,
      "loss": 0.1134,
      "step": 42750
    },
    {
      "epoch": 12.217142857142857,
      "grad_norm": 0.7670572400093079,
      "learning_rate": 3.710476190476191e-06,
      "loss": 0.1265,
      "step": 42760
    },
    {
      "epoch": 12.22,
      "grad_norm": 4.4057771447114646e-05,
      "learning_rate": 3.7066666666666666e-06,
      "loss": 0.1148,
      "step": 42770
    },
    {
      "epoch": 12.222857142857142,
      "grad_norm": 0.010759571567177773,
      "learning_rate": 3.702857142857143e-06,
      "loss": 0.0001,
      "step": 42780
    },
    {
      "epoch": 12.225714285714286,
      "grad_norm": 4.822274422622286e-05,
      "learning_rate": 3.6990476190476195e-06,
      "loss": 0.0,
      "step": 42790
    },
    {
      "epoch": 12.228571428571428,
      "grad_norm": 2.067487184831407e-05,
      "learning_rate": 3.6952380952380955e-06,
      "loss": 0.0007,
      "step": 42800
    },
    {
      "epoch": 12.231428571428571,
      "grad_norm": 0.0006382322171702981,
      "learning_rate": 3.691428571428572e-06,
      "loss": 0.054,
      "step": 42810
    },
    {
      "epoch": 12.234285714285715,
      "grad_norm": 0.0007864736253395677,
      "learning_rate": 3.6876190476190475e-06,
      "loss": 0.0001,
      "step": 42820
    },
    {
      "epoch": 12.237142857142857,
      "grad_norm": 0.05770515650510788,
      "learning_rate": 3.683809523809524e-06,
      "loss": 0.1352,
      "step": 42830
    },
    {
      "epoch": 12.24,
      "grad_norm": 2.531742757128086e-05,
      "learning_rate": 3.6800000000000003e-06,
      "loss": 0.0003,
      "step": 42840
    },
    {
      "epoch": 12.242857142857142,
      "grad_norm": 0.0002658704179339111,
      "learning_rate": 3.6761904761904763e-06,
      "loss": 0.001,
      "step": 42850
    },
    {
      "epoch": 12.245714285714286,
      "grad_norm": 0.0006085749482735991,
      "learning_rate": 3.6723809523809528e-06,
      "loss": 0.0001,
      "step": 42860
    },
    {
      "epoch": 12.248571428571429,
      "grad_norm": 0.00019992716261185706,
      "learning_rate": 3.668571428571429e-06,
      "loss": 0.1076,
      "step": 42870
    },
    {
      "epoch": 12.251428571428571,
      "grad_norm": 0.0018592029809951782,
      "learning_rate": 3.6647619047619048e-06,
      "loss": 0.0001,
      "step": 42880
    },
    {
      "epoch": 12.254285714285714,
      "grad_norm": 0.0032901957165449858,
      "learning_rate": 3.6609523809523812e-06,
      "loss": 0.0001,
      "step": 42890
    },
    {
      "epoch": 12.257142857142856,
      "grad_norm": 0.0005272685084491968,
      "learning_rate": 3.6571428571428576e-06,
      "loss": 0.0002,
      "step": 42900
    },
    {
      "epoch": 12.26,
      "grad_norm": 5.000172677682713e-05,
      "learning_rate": 3.6533333333333336e-06,
      "loss": 0.0003,
      "step": 42910
    },
    {
      "epoch": 12.262857142857143,
      "grad_norm": 0.0002578244311735034,
      "learning_rate": 3.64952380952381e-06,
      "loss": 0.0004,
      "step": 42920
    },
    {
      "epoch": 12.265714285714285,
      "grad_norm": 0.003726533381268382,
      "learning_rate": 3.6457142857142857e-06,
      "loss": 0.0001,
      "step": 42930
    },
    {
      "epoch": 12.268571428571429,
      "grad_norm": 0.00021085327898617834,
      "learning_rate": 3.641904761904762e-06,
      "loss": 0.1306,
      "step": 42940
    },
    {
      "epoch": 12.271428571428572,
      "grad_norm": 0.027141062542796135,
      "learning_rate": 3.6380952380952385e-06,
      "loss": 0.0001,
      "step": 42950
    },
    {
      "epoch": 12.274285714285714,
      "grad_norm": 0.0001848047540988773,
      "learning_rate": 3.6342857142857145e-06,
      "loss": 0.1212,
      "step": 42960
    },
    {
      "epoch": 12.277142857142858,
      "grad_norm": 0.0011436970671638846,
      "learning_rate": 3.630476190476191e-06,
      "loss": 0.0058,
      "step": 42970
    },
    {
      "epoch": 12.28,
      "grad_norm": 0.00016349622455891222,
      "learning_rate": 3.6266666666666674e-06,
      "loss": 0.0003,
      "step": 42980
    },
    {
      "epoch": 12.282857142857143,
      "grad_norm": 0.00022594058827962726,
      "learning_rate": 3.622857142857143e-06,
      "loss": 0.0066,
      "step": 42990
    },
    {
      "epoch": 12.285714285714286,
      "grad_norm": 0.0036640637554228306,
      "learning_rate": 3.6190476190476194e-06,
      "loss": 0.0507,
      "step": 43000
    },
    {
      "epoch": 12.288571428571428,
      "grad_norm": 0.0034455773420631886,
      "learning_rate": 3.6152380952380954e-06,
      "loss": 0.0001,
      "step": 43010
    },
    {
      "epoch": 12.291428571428572,
      "grad_norm": 2.009422860282939e-05,
      "learning_rate": 3.611428571428572e-06,
      "loss": 0.0001,
      "step": 43020
    },
    {
      "epoch": 12.294285714285714,
      "grad_norm": 0.00012474825780373067,
      "learning_rate": 3.6076190476190483e-06,
      "loss": 0.2146,
      "step": 43030
    },
    {
      "epoch": 12.297142857142857,
      "grad_norm": 2.4996047019958496,
      "learning_rate": 3.603809523809524e-06,
      "loss": 0.0968,
      "step": 43040
    },
    {
      "epoch": 12.3,
      "grad_norm": 0.00856898445636034,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.1027,
      "step": 43050
    },
    {
      "epoch": 12.302857142857142,
      "grad_norm": 0.003299040487036109,
      "learning_rate": 3.5961904761904763e-06,
      "loss": 0.0001,
      "step": 43060
    },
    {
      "epoch": 12.305714285714286,
      "grad_norm": 0.04237068444490433,
      "learning_rate": 3.5923809523809527e-06,
      "loss": 0.1267,
      "step": 43070
    },
    {
      "epoch": 12.308571428571428,
      "grad_norm": 0.002033600816503167,
      "learning_rate": 3.588571428571429e-06,
      "loss": 0.0004,
      "step": 43080
    },
    {
      "epoch": 12.311428571428571,
      "grad_norm": 0.00026735657593235373,
      "learning_rate": 3.584761904761905e-06,
      "loss": 0.2043,
      "step": 43090
    },
    {
      "epoch": 12.314285714285715,
      "grad_norm": 1.039493441581726,
      "learning_rate": 3.580952380952381e-06,
      "loss": 0.0007,
      "step": 43100
    },
    {
      "epoch": 12.317142857142857,
      "grad_norm": 0.004692147485911846,
      "learning_rate": 3.5771428571428576e-06,
      "loss": 0.0002,
      "step": 43110
    },
    {
      "epoch": 12.32,
      "grad_norm": 28.594776153564453,
      "learning_rate": 3.5733333333333336e-06,
      "loss": 0.264,
      "step": 43120
    },
    {
      "epoch": 12.322857142857142,
      "grad_norm": 0.0041211810894310474,
      "learning_rate": 3.56952380952381e-06,
      "loss": 0.0007,
      "step": 43130
    },
    {
      "epoch": 12.325714285714286,
      "grad_norm": 0.0002598456630948931,
      "learning_rate": 3.5657142857142864e-06,
      "loss": 0.0,
      "step": 43140
    },
    {
      "epoch": 12.32857142857143,
      "grad_norm": 0.1254412680864334,
      "learning_rate": 3.561904761904762e-06,
      "loss": 0.081,
      "step": 43150
    },
    {
      "epoch": 12.331428571428571,
      "grad_norm": 0.019065050408244133,
      "learning_rate": 3.5580952380952384e-06,
      "loss": 0.0001,
      "step": 43160
    },
    {
      "epoch": 12.334285714285715,
      "grad_norm": 0.0011502965353429317,
      "learning_rate": 3.5542857142857144e-06,
      "loss": 0.0008,
      "step": 43170
    },
    {
      "epoch": 12.337142857142856,
      "grad_norm": 0.00019580671505536884,
      "learning_rate": 3.550476190476191e-06,
      "loss": 0.0001,
      "step": 43180
    },
    {
      "epoch": 12.34,
      "grad_norm": 0.002959689125418663,
      "learning_rate": 3.5466666666666673e-06,
      "loss": 0.0015,
      "step": 43190
    },
    {
      "epoch": 12.342857142857143,
      "grad_norm": 0.07560833543539047,
      "learning_rate": 3.542857142857143e-06,
      "loss": 0.0005,
      "step": 43200
    },
    {
      "epoch": 12.345714285714285,
      "grad_norm": 0.004373143892735243,
      "learning_rate": 3.5390476190476193e-06,
      "loss": 0.0003,
      "step": 43210
    },
    {
      "epoch": 12.348571428571429,
      "grad_norm": 8.625600457889959e-05,
      "learning_rate": 3.5352380952380953e-06,
      "loss": 0.0001,
      "step": 43220
    },
    {
      "epoch": 12.35142857142857,
      "grad_norm": 0.001395838800817728,
      "learning_rate": 3.5314285714285717e-06,
      "loss": 0.0007,
      "step": 43230
    },
    {
      "epoch": 12.354285714285714,
      "grad_norm": 0.021874606609344482,
      "learning_rate": 3.527619047619048e-06,
      "loss": 0.1164,
      "step": 43240
    },
    {
      "epoch": 12.357142857142858,
      "grad_norm": 0.033902499824762344,
      "learning_rate": 3.523809523809524e-06,
      "loss": 0.1013,
      "step": 43250
    },
    {
      "epoch": 12.36,
      "grad_norm": 0.001047325786203146,
      "learning_rate": 3.52e-06,
      "loss": 0.0733,
      "step": 43260
    },
    {
      "epoch": 12.362857142857143,
      "grad_norm": 0.00024890233180485666,
      "learning_rate": 3.516190476190476e-06,
      "loss": 0.0003,
      "step": 43270
    },
    {
      "epoch": 12.365714285714287,
      "grad_norm": 3.31762021232862e-05,
      "learning_rate": 3.5123809523809526e-06,
      "loss": 0.0002,
      "step": 43280
    },
    {
      "epoch": 12.368571428571428,
      "grad_norm": 81.51933288574219,
      "learning_rate": 3.508571428571429e-06,
      "loss": 0.0504,
      "step": 43290
    },
    {
      "epoch": 12.371428571428572,
      "grad_norm": 8.134058952331543,
      "learning_rate": 3.504761904761905e-06,
      "loss": 0.191,
      "step": 43300
    },
    {
      "epoch": 12.374285714285714,
      "grad_norm": 0.0003756032092496753,
      "learning_rate": 3.500952380952381e-06,
      "loss": 0.0,
      "step": 43310
    },
    {
      "epoch": 12.377142857142857,
      "grad_norm": 0.6947579979896545,
      "learning_rate": 3.4971428571428575e-06,
      "loss": 0.1596,
      "step": 43320
    },
    {
      "epoch": 12.38,
      "grad_norm": 0.007652651984244585,
      "learning_rate": 3.4933333333333335e-06,
      "loss": 0.0976,
      "step": 43330
    },
    {
      "epoch": 12.382857142857143,
      "grad_norm": 0.007304157596081495,
      "learning_rate": 3.48952380952381e-06,
      "loss": 0.0606,
      "step": 43340
    },
    {
      "epoch": 12.385714285714286,
      "grad_norm": 0.0005484072025865316,
      "learning_rate": 3.4857142857142863e-06,
      "loss": 0.0002,
      "step": 43350
    },
    {
      "epoch": 12.388571428571428,
      "grad_norm": 0.003710936289280653,
      "learning_rate": 3.4819047619047623e-06,
      "loss": 0.0,
      "step": 43360
    },
    {
      "epoch": 12.391428571428571,
      "grad_norm": 0.043914951384067535,
      "learning_rate": 3.4780952380952384e-06,
      "loss": 0.0002,
      "step": 43370
    },
    {
      "epoch": 12.394285714285715,
      "grad_norm": 0.002192057901993394,
      "learning_rate": 3.4742857142857144e-06,
      "loss": 0.0001,
      "step": 43380
    },
    {
      "epoch": 12.397142857142857,
      "grad_norm": 0.000159616261953488,
      "learning_rate": 3.4704761904761908e-06,
      "loss": 0.0009,
      "step": 43390
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.0009848271729424596,
      "learning_rate": 3.4666666666666672e-06,
      "loss": 0.0001,
      "step": 43400
    },
    {
      "epoch": 12.402857142857142,
      "grad_norm": 0.001732149627059698,
      "learning_rate": 3.4628571428571432e-06,
      "loss": 0.2016,
      "step": 43410
    },
    {
      "epoch": 12.405714285714286,
      "grad_norm": 0.04270841181278229,
      "learning_rate": 3.4590476190476192e-06,
      "loss": 0.0005,
      "step": 43420
    },
    {
      "epoch": 12.40857142857143,
      "grad_norm": 0.024219615384936333,
      "learning_rate": 3.4552380952380952e-06,
      "loss": 0.0024,
      "step": 43430
    },
    {
      "epoch": 12.411428571428571,
      "grad_norm": 0.16080792248249054,
      "learning_rate": 3.4514285714285717e-06,
      "loss": 0.0002,
      "step": 43440
    },
    {
      "epoch": 12.414285714285715,
      "grad_norm": 0.03210050240159035,
      "learning_rate": 3.447619047619048e-06,
      "loss": 0.0162,
      "step": 43450
    },
    {
      "epoch": 12.417142857142856,
      "grad_norm": 5.277448508422822e-05,
      "learning_rate": 3.443809523809524e-06,
      "loss": 0.0008,
      "step": 43460
    },
    {
      "epoch": 12.42,
      "grad_norm": 1.849956788646523e-05,
      "learning_rate": 3.44e-06,
      "loss": 0.0,
      "step": 43470
    },
    {
      "epoch": 12.422857142857143,
      "grad_norm": 0.0037760892882943153,
      "learning_rate": 3.436190476190476e-06,
      "loss": 0.0511,
      "step": 43480
    },
    {
      "epoch": 12.425714285714285,
      "grad_norm": 0.00017178697453346103,
      "learning_rate": 3.4323809523809525e-06,
      "loss": 0.0825,
      "step": 43490
    },
    {
      "epoch": 12.428571428571429,
      "grad_norm": 0.2569083273410797,
      "learning_rate": 3.428571428571429e-06,
      "loss": 0.0002,
      "step": 43500
    },
    {
      "epoch": 12.43142857142857,
      "grad_norm": 0.082351453602314,
      "learning_rate": 3.424761904761905e-06,
      "loss": 0.0001,
      "step": 43510
    },
    {
      "epoch": 12.434285714285714,
      "grad_norm": 0.0033748976420611143,
      "learning_rate": 3.4209523809523814e-06,
      "loss": 0.2517,
      "step": 43520
    },
    {
      "epoch": 12.437142857142858,
      "grad_norm": 0.001669488032348454,
      "learning_rate": 3.4171428571428574e-06,
      "loss": 0.0,
      "step": 43530
    },
    {
      "epoch": 12.44,
      "grad_norm": 0.00037241028621792793,
      "learning_rate": 3.4133333333333334e-06,
      "loss": 0.0022,
      "step": 43540
    },
    {
      "epoch": 12.442857142857143,
      "grad_norm": 0.008573856204748154,
      "learning_rate": 3.40952380952381e-06,
      "loss": 0.1625,
      "step": 43550
    },
    {
      "epoch": 12.445714285714285,
      "grad_norm": 0.015610123053193092,
      "learning_rate": 3.4057142857142863e-06,
      "loss": 0.0671,
      "step": 43560
    },
    {
      "epoch": 12.448571428571428,
      "grad_norm": 0.021003127098083496,
      "learning_rate": 3.4019047619047623e-06,
      "loss": 0.0001,
      "step": 43570
    },
    {
      "epoch": 12.451428571428572,
      "grad_norm": 0.00374995986931026,
      "learning_rate": 3.3980952380952383e-06,
      "loss": 0.0006,
      "step": 43580
    },
    {
      "epoch": 12.454285714285714,
      "grad_norm": 0.004695332143455744,
      "learning_rate": 3.3942857142857143e-06,
      "loss": 0.0996,
      "step": 43590
    },
    {
      "epoch": 12.457142857142857,
      "grad_norm": 0.00045271660201251507,
      "learning_rate": 3.3904761904761907e-06,
      "loss": 0.0003,
      "step": 43600
    },
    {
      "epoch": 12.46,
      "grad_norm": 0.03258760645985603,
      "learning_rate": 3.386666666666667e-06,
      "loss": 0.0005,
      "step": 43610
    },
    {
      "epoch": 12.462857142857143,
      "grad_norm": 0.00021199391630943865,
      "learning_rate": 3.382857142857143e-06,
      "loss": 0.0,
      "step": 43620
    },
    {
      "epoch": 12.465714285714286,
      "grad_norm": 0.01897755078971386,
      "learning_rate": 3.3790476190476196e-06,
      "loss": 0.13,
      "step": 43630
    },
    {
      "epoch": 12.468571428571428,
      "grad_norm": 0.0005542697617784142,
      "learning_rate": 3.375238095238095e-06,
      "loss": 0.0003,
      "step": 43640
    },
    {
      "epoch": 12.471428571428572,
      "grad_norm": 0.00131324608810246,
      "learning_rate": 3.3714285714285716e-06,
      "loss": 0.142,
      "step": 43650
    },
    {
      "epoch": 12.474285714285715,
      "grad_norm": 7.359668961726129e-05,
      "learning_rate": 3.367619047619048e-06,
      "loss": 0.0,
      "step": 43660
    },
    {
      "epoch": 12.477142857142857,
      "grad_norm": 0.009134153835475445,
      "learning_rate": 3.363809523809524e-06,
      "loss": 0.0004,
      "step": 43670
    },
    {
      "epoch": 12.48,
      "grad_norm": 0.06333820521831512,
      "learning_rate": 3.3600000000000004e-06,
      "loss": 0.0003,
      "step": 43680
    },
    {
      "epoch": 12.482857142857142,
      "grad_norm": 0.019023708999156952,
      "learning_rate": 3.356190476190476e-06,
      "loss": 0.2118,
      "step": 43690
    },
    {
      "epoch": 12.485714285714286,
      "grad_norm": 0.1134190559387207,
      "learning_rate": 3.3523809523809525e-06,
      "loss": 0.0003,
      "step": 43700
    },
    {
      "epoch": 12.48857142857143,
      "grad_norm": 0.00018253417511004955,
      "learning_rate": 3.348571428571429e-06,
      "loss": 0.0002,
      "step": 43710
    },
    {
      "epoch": 12.491428571428571,
      "grad_norm": 0.0005946576711721718,
      "learning_rate": 3.3447619047619053e-06,
      "loss": 0.1395,
      "step": 43720
    },
    {
      "epoch": 12.494285714285715,
      "grad_norm": 0.009499884210526943,
      "learning_rate": 3.3409523809523813e-06,
      "loss": 0.0002,
      "step": 43730
    },
    {
      "epoch": 12.497142857142856,
      "grad_norm": 0.00022722937865182757,
      "learning_rate": 3.3371428571428577e-06,
      "loss": 0.0011,
      "step": 43740
    },
    {
      "epoch": 12.5,
      "grad_norm": 7.641951378900558e-05,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0,
      "step": 43750
    },
    {
      "epoch": 12.502857142857144,
      "grad_norm": 0.0003543433849699795,
      "learning_rate": 3.3295238095238098e-06,
      "loss": 0.0001,
      "step": 43760
    },
    {
      "epoch": 12.505714285714285,
      "grad_norm": 0.0023762839846313,
      "learning_rate": 3.325714285714286e-06,
      "loss": 0.0001,
      "step": 43770
    },
    {
      "epoch": 12.508571428571429,
      "grad_norm": 25.82448959350586,
      "learning_rate": 3.321904761904762e-06,
      "loss": 0.1992,
      "step": 43780
    },
    {
      "epoch": 12.51142857142857,
      "grad_norm": 0.015135753899812698,
      "learning_rate": 3.3180952380952386e-06,
      "loss": 0.0,
      "step": 43790
    },
    {
      "epoch": 12.514285714285714,
      "grad_norm": 0.0021951713133603334,
      "learning_rate": 3.314285714285714e-06,
      "loss": 0.0001,
      "step": 43800
    },
    {
      "epoch": 12.517142857142858,
      "grad_norm": 0.0001858374016592279,
      "learning_rate": 3.3104761904761906e-06,
      "loss": 0.0,
      "step": 43810
    },
    {
      "epoch": 12.52,
      "grad_norm": 0.00012044014147249982,
      "learning_rate": 3.306666666666667e-06,
      "loss": 0.0,
      "step": 43820
    },
    {
      "epoch": 12.522857142857143,
      "grad_norm": 0.002376014133915305,
      "learning_rate": 3.302857142857143e-06,
      "loss": 0.0007,
      "step": 43830
    },
    {
      "epoch": 12.525714285714285,
      "grad_norm": 0.0008975164382718503,
      "learning_rate": 3.2990476190476195e-06,
      "loss": 0.0001,
      "step": 43840
    },
    {
      "epoch": 12.528571428571428,
      "grad_norm": 0.0001419528853148222,
      "learning_rate": 3.295238095238095e-06,
      "loss": 0.1387,
      "step": 43850
    },
    {
      "epoch": 12.531428571428572,
      "grad_norm": 0.0007915537571534514,
      "learning_rate": 3.2914285714285715e-06,
      "loss": 0.108,
      "step": 43860
    },
    {
      "epoch": 12.534285714285714,
      "grad_norm": 7.733022357570007e-05,
      "learning_rate": 3.287619047619048e-06,
      "loss": 0.0033,
      "step": 43870
    },
    {
      "epoch": 12.537142857142857,
      "grad_norm": 0.0032665033359080553,
      "learning_rate": 3.283809523809524e-06,
      "loss": 0.0001,
      "step": 43880
    },
    {
      "epoch": 12.54,
      "grad_norm": 0.0020173094235360622,
      "learning_rate": 3.2800000000000004e-06,
      "loss": 0.1079,
      "step": 43890
    },
    {
      "epoch": 12.542857142857143,
      "grad_norm": 0.00362195773050189,
      "learning_rate": 3.276190476190477e-06,
      "loss": 0.0006,
      "step": 43900
    },
    {
      "epoch": 12.545714285714286,
      "grad_norm": 0.000748169666621834,
      "learning_rate": 3.2723809523809524e-06,
      "loss": 0.0,
      "step": 43910
    },
    {
      "epoch": 12.548571428571428,
      "grad_norm": 0.0003985493094660342,
      "learning_rate": 3.268571428571429e-06,
      "loss": 0.0472,
      "step": 43920
    },
    {
      "epoch": 12.551428571428572,
      "grad_norm": 0.02028343454003334,
      "learning_rate": 3.2647619047619052e-06,
      "loss": 0.0019,
      "step": 43930
    },
    {
      "epoch": 12.554285714285715,
      "grad_norm": 0.00022687406453769654,
      "learning_rate": 3.2609523809523812e-06,
      "loss": 0.0,
      "step": 43940
    },
    {
      "epoch": 12.557142857142857,
      "grad_norm": 0.007014337461441755,
      "learning_rate": 3.2571428571428577e-06,
      "loss": 0.002,
      "step": 43950
    },
    {
      "epoch": 12.56,
      "grad_norm": 0.0014757603639736772,
      "learning_rate": 3.2533333333333332e-06,
      "loss": 0.0,
      "step": 43960
    },
    {
      "epoch": 12.562857142857142,
      "grad_norm": 0.1475173979997635,
      "learning_rate": 3.2495238095238097e-06,
      "loss": 0.0602,
      "step": 43970
    },
    {
      "epoch": 12.565714285714286,
      "grad_norm": 29.192363739013672,
      "learning_rate": 3.245714285714286e-06,
      "loss": 0.3143,
      "step": 43980
    },
    {
      "epoch": 12.56857142857143,
      "grad_norm": 0.009660891257226467,
      "learning_rate": 3.241904761904762e-06,
      "loss": 0.0011,
      "step": 43990
    },
    {
      "epoch": 12.571428571428571,
      "grad_norm": 0.0032977040391415358,
      "learning_rate": 3.2380952380952385e-06,
      "loss": 0.0001,
      "step": 44000
    },
    {
      "epoch": 12.574285714285715,
      "grad_norm": 1.6835333108901978,
      "learning_rate": 3.234285714285715e-06,
      "loss": 0.0032,
      "step": 44010
    },
    {
      "epoch": 12.577142857142857,
      "grad_norm": 0.004686896223574877,
      "learning_rate": 3.2304761904761905e-06,
      "loss": 0.0002,
      "step": 44020
    },
    {
      "epoch": 12.58,
      "grad_norm": 8.559289562981576e-05,
      "learning_rate": 3.226666666666667e-06,
      "loss": 0.099,
      "step": 44030
    },
    {
      "epoch": 12.582857142857144,
      "grad_norm": 0.0008813161985017359,
      "learning_rate": 3.222857142857143e-06,
      "loss": 0.0621,
      "step": 44040
    },
    {
      "epoch": 12.585714285714285,
      "grad_norm": 0.07894054800271988,
      "learning_rate": 3.2190476190476194e-06,
      "loss": 0.0203,
      "step": 44050
    },
    {
      "epoch": 12.588571428571429,
      "grad_norm": 0.0016573783941566944,
      "learning_rate": 3.215238095238096e-06,
      "loss": 0.0001,
      "step": 44060
    },
    {
      "epoch": 12.59142857142857,
      "grad_norm": 0.0038587581366300583,
      "learning_rate": 3.2114285714285714e-06,
      "loss": 0.0001,
      "step": 44070
    },
    {
      "epoch": 12.594285714285714,
      "grad_norm": 0.00037157992483116686,
      "learning_rate": 3.207619047619048e-06,
      "loss": 0.2261,
      "step": 44080
    },
    {
      "epoch": 12.597142857142858,
      "grad_norm": 0.0003077713481616229,
      "learning_rate": 3.203809523809524e-06,
      "loss": 0.1141,
      "step": 44090
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.004069932270795107,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0001,
      "step": 44100
    },
    {
      "epoch": 12.602857142857143,
      "grad_norm": 0.003814880969002843,
      "learning_rate": 3.1961904761904767e-06,
      "loss": 0.0001,
      "step": 44110
    },
    {
      "epoch": 12.605714285714285,
      "grad_norm": 0.0205729641020298,
      "learning_rate": 3.1923809523809527e-06,
      "loss": 0.2054,
      "step": 44120
    },
    {
      "epoch": 12.608571428571429,
      "grad_norm": 0.000411072134738788,
      "learning_rate": 3.1885714285714287e-06,
      "loss": 0.2077,
      "step": 44130
    },
    {
      "epoch": 12.611428571428572,
      "grad_norm": 0.00015629432164132595,
      "learning_rate": 3.184761904761905e-06,
      "loss": 0.0001,
      "step": 44140
    },
    {
      "epoch": 12.614285714285714,
      "grad_norm": 0.008173446170985699,
      "learning_rate": 3.180952380952381e-06,
      "loss": 0.0883,
      "step": 44150
    },
    {
      "epoch": 12.617142857142857,
      "grad_norm": 0.48646673560142517,
      "learning_rate": 3.1771428571428576e-06,
      "loss": 0.1008,
      "step": 44160
    },
    {
      "epoch": 12.62,
      "grad_norm": 0.18691302835941315,
      "learning_rate": 3.173333333333334e-06,
      "loss": 0.0938,
      "step": 44170
    },
    {
      "epoch": 12.622857142857143,
      "grad_norm": 0.005554452072829008,
      "learning_rate": 3.1695238095238096e-06,
      "loss": 0.0001,
      "step": 44180
    },
    {
      "epoch": 12.625714285714286,
      "grad_norm": 0.0013566690031439066,
      "learning_rate": 3.165714285714286e-06,
      "loss": 0.1012,
      "step": 44190
    },
    {
      "epoch": 12.628571428571428,
      "grad_norm": 0.34455183148384094,
      "learning_rate": 3.161904761904762e-06,
      "loss": 0.3063,
      "step": 44200
    },
    {
      "epoch": 12.631428571428572,
      "grad_norm": 0.0017722378252074122,
      "learning_rate": 3.1580952380952385e-06,
      "loss": 0.0011,
      "step": 44210
    },
    {
      "epoch": 12.634285714285713,
      "grad_norm": 0.0020389833953231573,
      "learning_rate": 3.154285714285715e-06,
      "loss": 0.2893,
      "step": 44220
    },
    {
      "epoch": 12.637142857142857,
      "grad_norm": 0.44560813903808594,
      "learning_rate": 3.1504761904761905e-06,
      "loss": 0.0327,
      "step": 44230
    },
    {
      "epoch": 12.64,
      "grad_norm": 0.013738264329731464,
      "learning_rate": 3.146666666666667e-06,
      "loss": 0.0002,
      "step": 44240
    },
    {
      "epoch": 12.642857142857142,
      "grad_norm": 0.003953765146434307,
      "learning_rate": 3.142857142857143e-06,
      "loss": 0.0344,
      "step": 44250
    },
    {
      "epoch": 12.645714285714286,
      "grad_norm": 3.419204949750565e-05,
      "learning_rate": 3.1390476190476193e-06,
      "loss": 0.0003,
      "step": 44260
    },
    {
      "epoch": 12.64857142857143,
      "grad_norm": 0.0014054375933483243,
      "learning_rate": 3.1352380952380958e-06,
      "loss": 0.0729,
      "step": 44270
    },
    {
      "epoch": 12.651428571428571,
      "grad_norm": 3.5732429027557373,
      "learning_rate": 3.1314285714285718e-06,
      "loss": 0.0009,
      "step": 44280
    },
    {
      "epoch": 12.654285714285715,
      "grad_norm": 0.0006054223631508648,
      "learning_rate": 3.1276190476190478e-06,
      "loss": 0.0002,
      "step": 44290
    },
    {
      "epoch": 12.657142857142857,
      "grad_norm": 0.003106396645307541,
      "learning_rate": 3.1238095238095238e-06,
      "loss": 0.0973,
      "step": 44300
    },
    {
      "epoch": 12.66,
      "grad_norm": 0.0018582480261102319,
      "learning_rate": 3.12e-06,
      "loss": 0.0001,
      "step": 44310
    },
    {
      "epoch": 12.662857142857142,
      "grad_norm": 0.005048093385994434,
      "learning_rate": 3.1161904761904766e-06,
      "loss": 0.0001,
      "step": 44320
    },
    {
      "epoch": 12.665714285714285,
      "grad_norm": 0.08957742154598236,
      "learning_rate": 3.1123809523809526e-06,
      "loss": 0.0002,
      "step": 44330
    },
    {
      "epoch": 12.668571428571429,
      "grad_norm": 0.06375601142644882,
      "learning_rate": 3.1085714285714286e-06,
      "loss": 0.0758,
      "step": 44340
    },
    {
      "epoch": 12.67142857142857,
      "grad_norm": 1.1497115337988362e-05,
      "learning_rate": 3.104761904761905e-06,
      "loss": 0.0067,
      "step": 44350
    },
    {
      "epoch": 12.674285714285714,
      "grad_norm": 0.00022834133415017277,
      "learning_rate": 3.100952380952381e-06,
      "loss": 0.0007,
      "step": 44360
    },
    {
      "epoch": 12.677142857142858,
      "grad_norm": 0.00232820026576519,
      "learning_rate": 3.0971428571428575e-06,
      "loss": 0.0,
      "step": 44370
    },
    {
      "epoch": 12.68,
      "grad_norm": 0.00024770983145572245,
      "learning_rate": 3.093333333333334e-06,
      "loss": 0.0001,
      "step": 44380
    },
    {
      "epoch": 12.682857142857143,
      "grad_norm": 0.2055450975894928,
      "learning_rate": 3.08952380952381e-06,
      "loss": 0.0801,
      "step": 44390
    },
    {
      "epoch": 12.685714285714285,
      "grad_norm": 2.590520125522744e-05,
      "learning_rate": 3.085714285714286e-06,
      "loss": 0.0349,
      "step": 44400
    },
    {
      "epoch": 12.688571428571429,
      "grad_norm": 1.2637226973311044e-05,
      "learning_rate": 3.081904761904762e-06,
      "loss": 0.0007,
      "step": 44410
    },
    {
      "epoch": 12.691428571428572,
      "grad_norm": 5.0485075917094946e-05,
      "learning_rate": 3.0780952380952384e-06,
      "loss": 0.0002,
      "step": 44420
    },
    {
      "epoch": 12.694285714285714,
      "grad_norm": 7.127440039766952e-05,
      "learning_rate": 3.074285714285715e-06,
      "loss": 0.0132,
      "step": 44430
    },
    {
      "epoch": 12.697142857142858,
      "grad_norm": 0.004408019129186869,
      "learning_rate": 3.070476190476191e-06,
      "loss": 0.0001,
      "step": 44440
    },
    {
      "epoch": 12.7,
      "grad_norm": 28.1019229888916,
      "learning_rate": 3.066666666666667e-06,
      "loss": 0.1891,
      "step": 44450
    },
    {
      "epoch": 12.702857142857143,
      "grad_norm": 0.0013548871502280235,
      "learning_rate": 3.062857142857143e-06,
      "loss": 0.1845,
      "step": 44460
    },
    {
      "epoch": 12.705714285714286,
      "grad_norm": 0.0008880686364136636,
      "learning_rate": 3.0590476190476192e-06,
      "loss": 0.0791,
      "step": 44470
    },
    {
      "epoch": 12.708571428571428,
      "grad_norm": 0.0010196586372330785,
      "learning_rate": 3.0552380952380957e-06,
      "loss": 0.0,
      "step": 44480
    },
    {
      "epoch": 12.711428571428572,
      "grad_norm": 0.013310756534337997,
      "learning_rate": 3.0514285714285717e-06,
      "loss": 0.1064,
      "step": 44490
    },
    {
      "epoch": 12.714285714285714,
      "grad_norm": 9.900215809466317e-05,
      "learning_rate": 3.047619047619048e-06,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 12.717142857142857,
      "grad_norm": 4.881864151684567e-05,
      "learning_rate": 3.0438095238095237e-06,
      "loss": 0.0,
      "step": 44510
    },
    {
      "epoch": 12.72,
      "grad_norm": 0.004930638242512941,
      "learning_rate": 3.04e-06,
      "loss": 0.0633,
      "step": 44520
    },
    {
      "epoch": 12.722857142857142,
      "grad_norm": 0.0011020204983651638,
      "learning_rate": 3.0361904761904765e-06,
      "loss": 0.0001,
      "step": 44530
    },
    {
      "epoch": 12.725714285714286,
      "grad_norm": 0.004762137774378061,
      "learning_rate": 3.0323809523809526e-06,
      "loss": 0.1911,
      "step": 44540
    },
    {
      "epoch": 12.728571428571428,
      "grad_norm": 0.001960520865395665,
      "learning_rate": 3.028571428571429e-06,
      "loss": 0.0,
      "step": 44550
    },
    {
      "epoch": 12.731428571428571,
      "grad_norm": 0.0007661663694307208,
      "learning_rate": 3.024761904761905e-06,
      "loss": 0.0001,
      "step": 44560
    },
    {
      "epoch": 12.734285714285715,
      "grad_norm": 0.00013419706374406815,
      "learning_rate": 3.020952380952381e-06,
      "loss": 0.0,
      "step": 44570
    },
    {
      "epoch": 12.737142857142857,
      "grad_norm": 0.0036452049389481544,
      "learning_rate": 3.0171428571428574e-06,
      "loss": 0.0004,
      "step": 44580
    },
    {
      "epoch": 12.74,
      "grad_norm": 0.008097311481833458,
      "learning_rate": 3.013333333333334e-06,
      "loss": 0.0001,
      "step": 44590
    },
    {
      "epoch": 12.742857142857144,
      "grad_norm": 0.007365689147263765,
      "learning_rate": 3.00952380952381e-06,
      "loss": 0.0,
      "step": 44600
    },
    {
      "epoch": 12.745714285714286,
      "grad_norm": 3.979227039963007e-05,
      "learning_rate": 3.005714285714286e-06,
      "loss": 0.0006,
      "step": 44610
    },
    {
      "epoch": 12.748571428571429,
      "grad_norm": 0.00021918780112173408,
      "learning_rate": 3.001904761904762e-06,
      "loss": 0.1393,
      "step": 44620
    },
    {
      "epoch": 12.751428571428571,
      "grad_norm": 0.00016660240362398326,
      "learning_rate": 2.9980952380952383e-06,
      "loss": 0.0303,
      "step": 44630
    },
    {
      "epoch": 12.754285714285714,
      "grad_norm": 0.008226298727095127,
      "learning_rate": 2.9942857142857147e-06,
      "loss": 0.0,
      "step": 44640
    },
    {
      "epoch": 12.757142857142856,
      "grad_norm": 1.7057427167892456,
      "learning_rate": 2.9904761904761907e-06,
      "loss": 0.1946,
      "step": 44650
    },
    {
      "epoch": 12.76,
      "grad_norm": 5.494476226886036e-06,
      "learning_rate": 2.986666666666667e-06,
      "loss": 0.0001,
      "step": 44660
    },
    {
      "epoch": 12.762857142857143,
      "grad_norm": 0.0005954853841103613,
      "learning_rate": 2.9828571428571427e-06,
      "loss": 0.0,
      "step": 44670
    },
    {
      "epoch": 12.765714285714285,
      "grad_norm": 1.654141306062229e-05,
      "learning_rate": 2.979047619047619e-06,
      "loss": 0.0001,
      "step": 44680
    },
    {
      "epoch": 12.768571428571429,
      "grad_norm": 7.927964361442719e-06,
      "learning_rate": 2.9752380952380956e-06,
      "loss": 0.0086,
      "step": 44690
    },
    {
      "epoch": 12.771428571428572,
      "grad_norm": 1.0219598152616527e-05,
      "learning_rate": 2.9714285714285716e-06,
      "loss": 0.0,
      "step": 44700
    },
    {
      "epoch": 12.774285714285714,
      "grad_norm": 0.0001438223262084648,
      "learning_rate": 2.967619047619048e-06,
      "loss": 0.0014,
      "step": 44710
    },
    {
      "epoch": 12.777142857142858,
      "grad_norm": 4.781908501172438e-05,
      "learning_rate": 2.9638095238095236e-06,
      "loss": 0.0,
      "step": 44720
    },
    {
      "epoch": 12.78,
      "grad_norm": 0.006164256017655134,
      "learning_rate": 2.96e-06,
      "loss": 0.0646,
      "step": 44730
    },
    {
      "epoch": 12.782857142857143,
      "grad_norm": 9.197030158247799e-05,
      "learning_rate": 2.9561904761904765e-06,
      "loss": 0.0005,
      "step": 44740
    },
    {
      "epoch": 12.785714285714286,
      "grad_norm": 0.00012145283835707232,
      "learning_rate": 2.9523809523809525e-06,
      "loss": 0.1061,
      "step": 44750
    },
    {
      "epoch": 12.788571428571428,
      "grad_norm": 0.5985628962516785,
      "learning_rate": 2.948571428571429e-06,
      "loss": 0.0009,
      "step": 44760
    },
    {
      "epoch": 12.791428571428572,
      "grad_norm": 1.0052875040855724e-05,
      "learning_rate": 2.9447619047619053e-06,
      "loss": 0.1444,
      "step": 44770
    },
    {
      "epoch": 12.794285714285714,
      "grad_norm": 0.02648133970797062,
      "learning_rate": 2.940952380952381e-06,
      "loss": 0.1477,
      "step": 44780
    },
    {
      "epoch": 12.797142857142857,
      "grad_norm": 0.0002697078452911228,
      "learning_rate": 2.9371428571428573e-06,
      "loss": 0.0002,
      "step": 44790
    },
    {
      "epoch": 12.8,
      "grad_norm": 11.778502464294434,
      "learning_rate": 2.9333333333333338e-06,
      "loss": 0.0258,
      "step": 44800
    },
    {
      "epoch": 12.802857142857142,
      "grad_norm": 0.008923911489546299,
      "learning_rate": 2.9295238095238098e-06,
      "loss": 0.0001,
      "step": 44810
    },
    {
      "epoch": 12.805714285714286,
      "grad_norm": 0.273418664932251,
      "learning_rate": 2.925714285714286e-06,
      "loss": 0.0005,
      "step": 44820
    },
    {
      "epoch": 12.808571428571428,
      "grad_norm": 0.005158478859812021,
      "learning_rate": 2.9219047619047618e-06,
      "loss": 0.0002,
      "step": 44830
    },
    {
      "epoch": 12.811428571428571,
      "grad_norm": 0.0004465043020900339,
      "learning_rate": 2.918095238095238e-06,
      "loss": 0.0,
      "step": 44840
    },
    {
      "epoch": 12.814285714285715,
      "grad_norm": 8.832763342070393e-06,
      "learning_rate": 2.9142857142857146e-06,
      "loss": 0.0008,
      "step": 44850
    },
    {
      "epoch": 12.817142857142857,
      "grad_norm": 0.0033130596857517958,
      "learning_rate": 2.9104761904761906e-06,
      "loss": 0.112,
      "step": 44860
    },
    {
      "epoch": 12.82,
      "grad_norm": 0.0010407980298623443,
      "learning_rate": 2.906666666666667e-06,
      "loss": 0.1915,
      "step": 44870
    },
    {
      "epoch": 12.822857142857142,
      "grad_norm": 0.0006675151525996625,
      "learning_rate": 2.9028571428571427e-06,
      "loss": 0.0473,
      "step": 44880
    },
    {
      "epoch": 12.825714285714286,
      "grad_norm": 0.000254032522207126,
      "learning_rate": 2.899047619047619e-06,
      "loss": 0.0,
      "step": 44890
    },
    {
      "epoch": 12.82857142857143,
      "grad_norm": 0.017176706343889236,
      "learning_rate": 2.8952380952380955e-06,
      "loss": 0.032,
      "step": 44900
    },
    {
      "epoch": 12.831428571428571,
      "grad_norm": 0.004289929289370775,
      "learning_rate": 2.8914285714285715e-06,
      "loss": 0.0002,
      "step": 44910
    },
    {
      "epoch": 12.834285714285715,
      "grad_norm": 0.003139941254630685,
      "learning_rate": 2.887619047619048e-06,
      "loss": 0.0951,
      "step": 44920
    },
    {
      "epoch": 12.837142857142858,
      "grad_norm": 0.0013421063777059317,
      "learning_rate": 2.8838095238095244e-06,
      "loss": 0.128,
      "step": 44930
    },
    {
      "epoch": 12.84,
      "grad_norm": 0.0012085703201591969,
      "learning_rate": 2.88e-06,
      "loss": 0.0002,
      "step": 44940
    },
    {
      "epoch": 12.842857142857143,
      "grad_norm": 5.073803185950965e-05,
      "learning_rate": 2.8761904761904764e-06,
      "loss": 0.0001,
      "step": 44950
    },
    {
      "epoch": 12.845714285714285,
      "grad_norm": 1.740825427987147e-05,
      "learning_rate": 2.872380952380953e-06,
      "loss": 0.0,
      "step": 44960
    },
    {
      "epoch": 12.848571428571429,
      "grad_norm": 0.00013347850472200662,
      "learning_rate": 2.868571428571429e-06,
      "loss": 0.1227,
      "step": 44970
    },
    {
      "epoch": 12.85142857142857,
      "grad_norm": 5.627432619803585e-05,
      "learning_rate": 2.8647619047619052e-06,
      "loss": 0.0,
      "step": 44980
    },
    {
      "epoch": 12.854285714285714,
      "grad_norm": 0.005508747883141041,
      "learning_rate": 2.860952380952381e-06,
      "loss": 0.0,
      "step": 44990
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 0.00030772638274356723,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.0008,
      "step": 45000
    },
    {
      "epoch": 12.86,
      "grad_norm": 1.5870136849116534e-05,
      "learning_rate": 2.8533333333333337e-06,
      "loss": 0.1908,
      "step": 45010
    },
    {
      "epoch": 12.862857142857143,
      "grad_norm": 0.0002560137363616377,
      "learning_rate": 2.8495238095238097e-06,
      "loss": 0.0527,
      "step": 45020
    },
    {
      "epoch": 12.865714285714287,
      "grad_norm": 0.0005953690852038562,
      "learning_rate": 2.845714285714286e-06,
      "loss": 0.0005,
      "step": 45030
    },
    {
      "epoch": 12.868571428571428,
      "grad_norm": 9.328215674031526e-05,
      "learning_rate": 2.8419047619047625e-06,
      "loss": 0.0011,
      "step": 45040
    },
    {
      "epoch": 12.871428571428572,
      "grad_norm": 0.004367065150290728,
      "learning_rate": 2.838095238095238e-06,
      "loss": 0.0001,
      "step": 45050
    },
    {
      "epoch": 12.874285714285714,
      "grad_norm": 0.0002027501177508384,
      "learning_rate": 2.8342857142857146e-06,
      "loss": 0.1525,
      "step": 45060
    },
    {
      "epoch": 12.877142857142857,
      "grad_norm": 0.000501540838740766,
      "learning_rate": 2.8304761904761906e-06,
      "loss": 0.0325,
      "step": 45070
    },
    {
      "epoch": 12.88,
      "grad_norm": 0.08198732137680054,
      "learning_rate": 2.826666666666667e-06,
      "loss": 0.0553,
      "step": 45080
    },
    {
      "epoch": 12.882857142857143,
      "grad_norm": 0.009106325916945934,
      "learning_rate": 2.8228571428571434e-06,
      "loss": 0.2161,
      "step": 45090
    },
    {
      "epoch": 12.885714285714286,
      "grad_norm": 0.0031985733658075333,
      "learning_rate": 2.819047619047619e-06,
      "loss": 0.1223,
      "step": 45100
    },
    {
      "epoch": 12.888571428571428,
      "grad_norm": 0.005030920263379812,
      "learning_rate": 2.8152380952380954e-06,
      "loss": 0.0123,
      "step": 45110
    },
    {
      "epoch": 12.891428571428571,
      "grad_norm": 0.0011238261358812451,
      "learning_rate": 2.8114285714285714e-06,
      "loss": 0.0028,
      "step": 45120
    },
    {
      "epoch": 12.894285714285715,
      "grad_norm": 0.12051250785589218,
      "learning_rate": 2.807619047619048e-06,
      "loss": 0.0014,
      "step": 45130
    },
    {
      "epoch": 12.897142857142857,
      "grad_norm": 0.004364991094917059,
      "learning_rate": 2.8038095238095243e-06,
      "loss": 0.0002,
      "step": 45140
    },
    {
      "epoch": 12.9,
      "grad_norm": 0.0022032230626791716,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0002,
      "step": 45150
    },
    {
      "epoch": 12.902857142857142,
      "grad_norm": 0.00017364831001032144,
      "learning_rate": 2.7961904761904763e-06,
      "loss": 0.0001,
      "step": 45160
    },
    {
      "epoch": 12.905714285714286,
      "grad_norm": 0.0011071352055296302,
      "learning_rate": 2.7923809523809527e-06,
      "loss": 0.0002,
      "step": 45170
    },
    {
      "epoch": 12.90857142857143,
      "grad_norm": 0.016556115821003914,
      "learning_rate": 2.7885714285714287e-06,
      "loss": 0.0048,
      "step": 45180
    },
    {
      "epoch": 12.911428571428571,
      "grad_norm": 0.007798975333571434,
      "learning_rate": 2.784761904761905e-06,
      "loss": 0.1025,
      "step": 45190
    },
    {
      "epoch": 12.914285714285715,
      "grad_norm": 1.4912472579453606e-05,
      "learning_rate": 2.7809523809523816e-06,
      "loss": 0.0,
      "step": 45200
    },
    {
      "epoch": 12.917142857142856,
      "grad_norm": 6.866233161417767e-05,
      "learning_rate": 2.777142857142857e-06,
      "loss": 0.1333,
      "step": 45210
    },
    {
      "epoch": 12.92,
      "grad_norm": 0.011820961721241474,
      "learning_rate": 2.7733333333333336e-06,
      "loss": 0.0,
      "step": 45220
    },
    {
      "epoch": 12.922857142857143,
      "grad_norm": 0.004281253088265657,
      "learning_rate": 2.7695238095238096e-06,
      "loss": 0.0011,
      "step": 45230
    },
    {
      "epoch": 12.925714285714285,
      "grad_norm": 0.09389454126358032,
      "learning_rate": 2.765714285714286e-06,
      "loss": 0.0002,
      "step": 45240
    },
    {
      "epoch": 12.928571428571429,
      "grad_norm": 5.988970588077791e-05,
      "learning_rate": 2.7619047619047625e-06,
      "loss": 0.0002,
      "step": 45250
    },
    {
      "epoch": 12.93142857142857,
      "grad_norm": 2.2647234800388105e-05,
      "learning_rate": 2.758095238095238e-06,
      "loss": 0.0,
      "step": 45260
    },
    {
      "epoch": 12.934285714285714,
      "grad_norm": 0.0013165249256417155,
      "learning_rate": 2.7542857142857145e-06,
      "loss": 0.0,
      "step": 45270
    },
    {
      "epoch": 12.937142857142858,
      "grad_norm": 0.19390064477920532,
      "learning_rate": 2.7504761904761905e-06,
      "loss": 0.0002,
      "step": 45280
    },
    {
      "epoch": 12.94,
      "grad_norm": 1.3834080164087936e-05,
      "learning_rate": 2.746666666666667e-06,
      "loss": 0.0096,
      "step": 45290
    },
    {
      "epoch": 12.942857142857143,
      "grad_norm": 0.00017918359662871808,
      "learning_rate": 2.7428571428571433e-06,
      "loss": 0.0,
      "step": 45300
    },
    {
      "epoch": 12.945714285714285,
      "grad_norm": 0.0042289490811526775,
      "learning_rate": 2.7390476190476193e-06,
      "loss": 0.0989,
      "step": 45310
    },
    {
      "epoch": 12.948571428571428,
      "grad_norm": 0.0003320519463159144,
      "learning_rate": 2.7352380952380953e-06,
      "loss": 0.0,
      "step": 45320
    },
    {
      "epoch": 12.951428571428572,
      "grad_norm": 0.08394830673933029,
      "learning_rate": 2.7314285714285714e-06,
      "loss": 0.0001,
      "step": 45330
    },
    {
      "epoch": 12.954285714285714,
      "grad_norm": 39.37677764892578,
      "learning_rate": 2.7276190476190478e-06,
      "loss": 0.106,
      "step": 45340
    },
    {
      "epoch": 12.957142857142857,
      "grad_norm": 0.01614060439169407,
      "learning_rate": 2.723809523809524e-06,
      "loss": 0.1503,
      "step": 45350
    },
    {
      "epoch": 12.96,
      "grad_norm": 0.0020421110093593597,
      "learning_rate": 2.7200000000000002e-06,
      "loss": 0.0,
      "step": 45360
    },
    {
      "epoch": 12.962857142857143,
      "grad_norm": 0.9347457885742188,
      "learning_rate": 2.7161904761904762e-06,
      "loss": 0.0009,
      "step": 45370
    },
    {
      "epoch": 12.965714285714286,
      "grad_norm": 2.1889649360673502e-05,
      "learning_rate": 2.7123809523809526e-06,
      "loss": 0.263,
      "step": 45380
    },
    {
      "epoch": 12.968571428571428,
      "grad_norm": 1.4087433555687312e-05,
      "learning_rate": 2.7085714285714287e-06,
      "loss": 0.0004,
      "step": 45390
    },
    {
      "epoch": 12.971428571428572,
      "grad_norm": 0.10518946498632431,
      "learning_rate": 2.704761904761905e-06,
      "loss": 0.0002,
      "step": 45400
    },
    {
      "epoch": 12.974285714285715,
      "grad_norm": 0.12551641464233398,
      "learning_rate": 2.7009523809523815e-06,
      "loss": 0.0001,
      "step": 45410
    },
    {
      "epoch": 12.977142857142857,
      "grad_norm": 8.025702845770866e-05,
      "learning_rate": 2.6971428571428575e-06,
      "loss": 0.0004,
      "step": 45420
    },
    {
      "epoch": 12.98,
      "grad_norm": 0.0002145228791050613,
      "learning_rate": 2.6933333333333335e-06,
      "loss": 0.0001,
      "step": 45430
    },
    {
      "epoch": 12.982857142857142,
      "grad_norm": 0.016424985602498055,
      "learning_rate": 2.6895238095238095e-06,
      "loss": 0.0,
      "step": 45440
    },
    {
      "epoch": 12.985714285714286,
      "grad_norm": 2.343238338653464e-05,
      "learning_rate": 2.685714285714286e-06,
      "loss": 0.0241,
      "step": 45450
    },
    {
      "epoch": 12.98857142857143,
      "grad_norm": 0.0007215113728307188,
      "learning_rate": 2.6819047619047624e-06,
      "loss": 0.0002,
      "step": 45460
    },
    {
      "epoch": 12.991428571428571,
      "grad_norm": 7.452745194314048e-05,
      "learning_rate": 2.6780952380952384e-06,
      "loss": 0.0002,
      "step": 45470
    },
    {
      "epoch": 12.994285714285715,
      "grad_norm": 0.002599273109808564,
      "learning_rate": 2.6742857142857144e-06,
      "loss": 0.0158,
      "step": 45480
    },
    {
      "epoch": 12.997142857142856,
      "grad_norm": 0.1103169322013855,
      "learning_rate": 2.6704761904761904e-06,
      "loss": 0.0001,
      "step": 45490
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.1720464903628454e-05,
      "learning_rate": 2.666666666666667e-06,
      "loss": 0.0001,
      "step": 45500
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.97,
      "eval_f1": 0.8602484472049688,
      "eval_loss": 0.24231462180614471,
      "eval_precision": 0.8878205128205128,
      "eval_recall": 0.8343373493975904,
      "eval_runtime": 267.4552,
      "eval_samples_per_second": 11.217,
      "eval_steps_per_second": 2.804,
      "step": 45500
    }
  ],
  "logging_steps": 10,
  "max_steps": 52500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.155862229541264e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
