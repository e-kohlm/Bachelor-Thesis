{
  "best_metric": 0.8253968253968254,
  "best_model_checkpoint": "../saved_models/sql_20000_770/checkpoint-51326",
  "epoch": 11.0,
  "eval_steps": 500,
  "global_step": 51326,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002143163309044149,
      "grad_norm": 96.8985366821289,
      "learning_rate": 1.999971424489213e-05,
      "loss": 0.7321,
      "step": 1
    },
    {
      "epoch": 0.0021431633090441492,
      "grad_norm": 4.358039855957031,
      "learning_rate": 1.9997142448921276e-05,
      "loss": 0.2918,
      "step": 10
    },
    {
      "epoch": 0.0042863266180882984,
      "grad_norm": 0.4016043245792389,
      "learning_rate": 1.999428489784255e-05,
      "loss": 1.2188,
      "step": 20
    },
    {
      "epoch": 0.006429489927132447,
      "grad_norm": 0.7652460932731628,
      "learning_rate": 1.9991427346763827e-05,
      "loss": 1.9505,
      "step": 30
    },
    {
      "epoch": 0.008572653236176597,
      "grad_norm": 0.5369184613227844,
      "learning_rate": 1.99885697956851e-05,
      "loss": 1.1954,
      "step": 40
    },
    {
      "epoch": 0.010715816545220747,
      "grad_norm": 1.7567508220672607,
      "learning_rate": 1.9985712244606375e-05,
      "loss": 1.1114,
      "step": 50
    },
    {
      "epoch": 0.012858979854264894,
      "grad_norm": 84.01718139648438,
      "learning_rate": 1.998285469352765e-05,
      "loss": 0.7383,
      "step": 60
    },
    {
      "epoch": 0.015002143163309044,
      "grad_norm": 0.1601238250732422,
      "learning_rate": 1.9979997142448923e-05,
      "loss": 0.2248,
      "step": 70
    },
    {
      "epoch": 0.017145306472353194,
      "grad_norm": 95.2698745727539,
      "learning_rate": 1.99771395913702e-05,
      "loss": 1.4737,
      "step": 80
    },
    {
      "epoch": 0.01928846978139734,
      "grad_norm": 0.5671541690826416,
      "learning_rate": 1.9974282040291474e-05,
      "loss": 0.8331,
      "step": 90
    },
    {
      "epoch": 0.021431633090441493,
      "grad_norm": 1.0998992919921875,
      "learning_rate": 1.9971424489212748e-05,
      "loss": 0.9556,
      "step": 100
    },
    {
      "epoch": 0.02357479639948564,
      "grad_norm": 67.56217193603516,
      "learning_rate": 1.9968566938134018e-05,
      "loss": 1.2474,
      "step": 110
    },
    {
      "epoch": 0.02571795970852979,
      "grad_norm": 69.2518081665039,
      "learning_rate": 1.9965709387055296e-05,
      "loss": 1.2636,
      "step": 120
    },
    {
      "epoch": 0.02786112301757394,
      "grad_norm": 18.57940101623535,
      "learning_rate": 1.996285183597657e-05,
      "loss": 0.7738,
      "step": 130
    },
    {
      "epoch": 0.03000428632661809,
      "grad_norm": 52.150691986083984,
      "learning_rate": 1.9959994284897843e-05,
      "loss": 0.5396,
      "step": 140
    },
    {
      "epoch": 0.03214744963566224,
      "grad_norm": 2.2223143577575684,
      "learning_rate": 1.9957136733819117e-05,
      "loss": 1.5908,
      "step": 150
    },
    {
      "epoch": 0.03429061294470639,
      "grad_norm": 52.931617736816406,
      "learning_rate": 1.995427918274039e-05,
      "loss": 1.1044,
      "step": 160
    },
    {
      "epoch": 0.036433776253750536,
      "grad_norm": 0.10731316357851028,
      "learning_rate": 1.995142163166167e-05,
      "loss": 0.2356,
      "step": 170
    },
    {
      "epoch": 0.03857693956279468,
      "grad_norm": 0.35785534977912903,
      "learning_rate": 1.9948564080582943e-05,
      "loss": 1.7788,
      "step": 180
    },
    {
      "epoch": 0.04072010287183883,
      "grad_norm": 92.14838409423828,
      "learning_rate": 1.9945706529504216e-05,
      "loss": 0.9515,
      "step": 190
    },
    {
      "epoch": 0.042863266180882986,
      "grad_norm": 0.5088983178138733,
      "learning_rate": 1.994284897842549e-05,
      "loss": 0.4198,
      "step": 200
    },
    {
      "epoch": 0.045006429489927134,
      "grad_norm": 1.1080470085144043,
      "learning_rate": 1.9939991427346764e-05,
      "loss": 0.8334,
      "step": 210
    },
    {
      "epoch": 0.04714959279897128,
      "grad_norm": 0.32167842984199524,
      "learning_rate": 1.993713387626804e-05,
      "loss": 0.3183,
      "step": 220
    },
    {
      "epoch": 0.04929275610801543,
      "grad_norm": 42.222007751464844,
      "learning_rate": 1.9934276325189316e-05,
      "loss": 1.7515,
      "step": 230
    },
    {
      "epoch": 0.05143591941705958,
      "grad_norm": 20.673879623413086,
      "learning_rate": 1.993141877411059e-05,
      "loss": 0.3545,
      "step": 240
    },
    {
      "epoch": 0.053579082726103726,
      "grad_norm": 50.9938850402832,
      "learning_rate": 1.9928561223031863e-05,
      "loss": 0.5205,
      "step": 250
    },
    {
      "epoch": 0.05572224603514788,
      "grad_norm": 1.2739006280899048,
      "learning_rate": 1.9925703671953137e-05,
      "loss": 1.2346,
      "step": 260
    },
    {
      "epoch": 0.05786540934419203,
      "grad_norm": 1.5437884330749512,
      "learning_rate": 1.992284612087441e-05,
      "loss": 1.6044,
      "step": 270
    },
    {
      "epoch": 0.06000857265323618,
      "grad_norm": 74.27238464355469,
      "learning_rate": 1.991998856979569e-05,
      "loss": 0.8096,
      "step": 280
    },
    {
      "epoch": 0.062151735962280324,
      "grad_norm": 46.322113037109375,
      "learning_rate": 1.9917131018716962e-05,
      "loss": 1.0602,
      "step": 290
    },
    {
      "epoch": 0.06429489927132448,
      "grad_norm": 0.9366827607154846,
      "learning_rate": 1.9914273467638236e-05,
      "loss": 1.0112,
      "step": 300
    },
    {
      "epoch": 0.06643806258036862,
      "grad_norm": 74.50938415527344,
      "learning_rate": 1.991141591655951e-05,
      "loss": 0.8284,
      "step": 310
    },
    {
      "epoch": 0.06858122588941278,
      "grad_norm": 59.914764404296875,
      "learning_rate": 1.9908558365480784e-05,
      "loss": 0.7755,
      "step": 320
    },
    {
      "epoch": 0.07072438919845692,
      "grad_norm": 72.02323913574219,
      "learning_rate": 1.9905700814402058e-05,
      "loss": 0.9165,
      "step": 330
    },
    {
      "epoch": 0.07286755250750107,
      "grad_norm": 63.9809455871582,
      "learning_rate": 1.9902843263323332e-05,
      "loss": 0.6443,
      "step": 340
    },
    {
      "epoch": 0.07501071581654523,
      "grad_norm": 32.64987564086914,
      "learning_rate": 1.9899985712244606e-05,
      "loss": 0.4511,
      "step": 350
    },
    {
      "epoch": 0.07715387912558937,
      "grad_norm": 0.05316702276468277,
      "learning_rate": 1.9897128161165883e-05,
      "loss": 0.6074,
      "step": 360
    },
    {
      "epoch": 0.07929704243463352,
      "grad_norm": 0.06177270784974098,
      "learning_rate": 1.9894270610087157e-05,
      "loss": 0.3167,
      "step": 370
    },
    {
      "epoch": 0.08144020574367766,
      "grad_norm": 22.602258682250977,
      "learning_rate": 1.989141305900843e-05,
      "loss": 0.7506,
      "step": 380
    },
    {
      "epoch": 0.08358336905272182,
      "grad_norm": 0.06611096858978271,
      "learning_rate": 1.9888555507929705e-05,
      "loss": 0.5563,
      "step": 390
    },
    {
      "epoch": 0.08572653236176597,
      "grad_norm": 34.010650634765625,
      "learning_rate": 1.988569795685098e-05,
      "loss": 0.947,
      "step": 400
    },
    {
      "epoch": 0.08786969567081011,
      "grad_norm": 40.86321258544922,
      "learning_rate": 1.9882840405772253e-05,
      "loss": 1.0368,
      "step": 410
    },
    {
      "epoch": 0.09001285897985427,
      "grad_norm": 68.24798583984375,
      "learning_rate": 1.987998285469353e-05,
      "loss": 0.9553,
      "step": 420
    },
    {
      "epoch": 0.09215602228889841,
      "grad_norm": 63.971099853515625,
      "learning_rate": 1.9877125303614804e-05,
      "loss": 1.1222,
      "step": 430
    },
    {
      "epoch": 0.09429918559794256,
      "grad_norm": 9.150898933410645,
      "learning_rate": 1.9874267752536078e-05,
      "loss": 0.3654,
      "step": 440
    },
    {
      "epoch": 0.09644234890698672,
      "grad_norm": 0.8944530487060547,
      "learning_rate": 1.9871410201457352e-05,
      "loss": 0.849,
      "step": 450
    },
    {
      "epoch": 0.09858551221603086,
      "grad_norm": 1.231907844543457,
      "learning_rate": 1.9868552650378626e-05,
      "loss": 1.6698,
      "step": 460
    },
    {
      "epoch": 0.10072867552507501,
      "grad_norm": 39.05487060546875,
      "learning_rate": 1.9865695099299903e-05,
      "loss": 0.803,
      "step": 470
    },
    {
      "epoch": 0.10287183883411916,
      "grad_norm": 0.13896968960762024,
      "learning_rate": 1.9862837548221177e-05,
      "loss": 0.2583,
      "step": 480
    },
    {
      "epoch": 0.10501500214316331,
      "grad_norm": 0.3025451898574829,
      "learning_rate": 1.985997999714245e-05,
      "loss": 1.8952,
      "step": 490
    },
    {
      "epoch": 0.10715816545220745,
      "grad_norm": 33.57408142089844,
      "learning_rate": 1.9857122446063725e-05,
      "loss": 0.7158,
      "step": 500
    },
    {
      "epoch": 0.1093013287612516,
      "grad_norm": 38.5858268737793,
      "learning_rate": 1.9854264894985e-05,
      "loss": 0.7145,
      "step": 510
    },
    {
      "epoch": 0.11144449207029576,
      "grad_norm": 35.463951110839844,
      "learning_rate": 1.9851407343906276e-05,
      "loss": 1.0804,
      "step": 520
    },
    {
      "epoch": 0.1135876553793399,
      "grad_norm": 0.6342846155166626,
      "learning_rate": 1.984854979282755e-05,
      "loss": 0.3827,
      "step": 530
    },
    {
      "epoch": 0.11573081868838406,
      "grad_norm": 41.896339416503906,
      "learning_rate": 1.984569224174882e-05,
      "loss": 1.0676,
      "step": 540
    },
    {
      "epoch": 0.1178739819974282,
      "grad_norm": 0.9015694260597229,
      "learning_rate": 1.9842834690670095e-05,
      "loss": 0.6921,
      "step": 550
    },
    {
      "epoch": 0.12001714530647235,
      "grad_norm": 0.9915913939476013,
      "learning_rate": 1.9839977139591372e-05,
      "loss": 0.7454,
      "step": 560
    },
    {
      "epoch": 0.12216030861551651,
      "grad_norm": 0.1028805822134018,
      "learning_rate": 1.9837119588512646e-05,
      "loss": 0.585,
      "step": 570
    },
    {
      "epoch": 0.12430347192456065,
      "grad_norm": 0.16837793588638306,
      "learning_rate": 1.983426203743392e-05,
      "loss": 0.3539,
      "step": 580
    },
    {
      "epoch": 0.1264466352336048,
      "grad_norm": 0.7034919261932373,
      "learning_rate": 1.9831404486355194e-05,
      "loss": 0.924,
      "step": 590
    },
    {
      "epoch": 0.12858979854264896,
      "grad_norm": 63.68910598754883,
      "learning_rate": 1.9828546935276468e-05,
      "loss": 0.6209,
      "step": 600
    },
    {
      "epoch": 0.13073296185169309,
      "grad_norm": 43.85115432739258,
      "learning_rate": 1.9825689384197745e-05,
      "loss": 0.4887,
      "step": 610
    },
    {
      "epoch": 0.13287612516073724,
      "grad_norm": 31.58513832092285,
      "learning_rate": 1.982283183311902e-05,
      "loss": 0.7002,
      "step": 620
    },
    {
      "epoch": 0.1350192884697814,
      "grad_norm": 38.119197845458984,
      "learning_rate": 1.9819974282040293e-05,
      "loss": 0.7167,
      "step": 630
    },
    {
      "epoch": 0.13716245177882555,
      "grad_norm": 22.654050827026367,
      "learning_rate": 1.9817116730961567e-05,
      "loss": 0.5869,
      "step": 640
    },
    {
      "epoch": 0.1393056150878697,
      "grad_norm": 20.253870010375977,
      "learning_rate": 1.981425917988284e-05,
      "loss": 0.2768,
      "step": 650
    },
    {
      "epoch": 0.14144877839691383,
      "grad_norm": 83.37133026123047,
      "learning_rate": 1.9811401628804118e-05,
      "loss": 0.8233,
      "step": 660
    },
    {
      "epoch": 0.143591941705958,
      "grad_norm": 58.0783576965332,
      "learning_rate": 1.9808544077725392e-05,
      "loss": 0.4109,
      "step": 670
    },
    {
      "epoch": 0.14573510501500214,
      "grad_norm": 0.31153783202171326,
      "learning_rate": 1.9805686526646666e-05,
      "loss": 0.7109,
      "step": 680
    },
    {
      "epoch": 0.1478782683240463,
      "grad_norm": 46.928627014160156,
      "learning_rate": 1.980282897556794e-05,
      "loss": 0.9198,
      "step": 690
    },
    {
      "epoch": 0.15002143163309045,
      "grad_norm": 1.731181025505066,
      "learning_rate": 1.9799971424489214e-05,
      "loss": 0.8184,
      "step": 700
    },
    {
      "epoch": 0.15216459494213458,
      "grad_norm": 0.14690561592578888,
      "learning_rate": 1.979711387341049e-05,
      "loss": 0.0729,
      "step": 710
    },
    {
      "epoch": 0.15430775825117873,
      "grad_norm": 0.2460346668958664,
      "learning_rate": 1.9794256322331765e-05,
      "loss": 0.8391,
      "step": 720
    },
    {
      "epoch": 0.1564509215602229,
      "grad_norm": 0.15025211870670319,
      "learning_rate": 1.979139877125304e-05,
      "loss": 0.5542,
      "step": 730
    },
    {
      "epoch": 0.15859408486926704,
      "grad_norm": 60.434226989746094,
      "learning_rate": 1.9788541220174313e-05,
      "loss": 1.004,
      "step": 740
    },
    {
      "epoch": 0.1607372481783112,
      "grad_norm": 0.7944900989532471,
      "learning_rate": 1.9785683669095587e-05,
      "loss": 0.7066,
      "step": 750
    },
    {
      "epoch": 0.16288041148735533,
      "grad_norm": 44.03594970703125,
      "learning_rate": 1.978282611801686e-05,
      "loss": 0.8986,
      "step": 760
    },
    {
      "epoch": 0.16502357479639948,
      "grad_norm": 0.35280078649520874,
      "learning_rate": 1.9779968566938135e-05,
      "loss": 0.7268,
      "step": 770
    },
    {
      "epoch": 0.16716673810544364,
      "grad_norm": 1.1113711595535278,
      "learning_rate": 1.977711101585941e-05,
      "loss": 0.9044,
      "step": 780
    },
    {
      "epoch": 0.1693099014144878,
      "grad_norm": 3.8314716815948486,
      "learning_rate": 1.9774253464780683e-05,
      "loss": 0.5163,
      "step": 790
    },
    {
      "epoch": 0.17145306472353194,
      "grad_norm": 50.67228698730469,
      "learning_rate": 1.977139591370196e-05,
      "loss": 0.3826,
      "step": 800
    },
    {
      "epoch": 0.17359622803257607,
      "grad_norm": 2.1360456943511963,
      "learning_rate": 1.9768538362623234e-05,
      "loss": 0.6876,
      "step": 810
    },
    {
      "epoch": 0.17573939134162023,
      "grad_norm": 36.09822463989258,
      "learning_rate": 1.9765680811544508e-05,
      "loss": 0.6344,
      "step": 820
    },
    {
      "epoch": 0.17788255465066438,
      "grad_norm": 50.1201057434082,
      "learning_rate": 1.9762823260465782e-05,
      "loss": 1.3109,
      "step": 830
    },
    {
      "epoch": 0.18002571795970854,
      "grad_norm": 34.072166442871094,
      "learning_rate": 1.9759965709387056e-05,
      "loss": 0.3373,
      "step": 840
    },
    {
      "epoch": 0.1821688812687527,
      "grad_norm": 1.392916202545166,
      "learning_rate": 1.9757108158308333e-05,
      "loss": 0.6419,
      "step": 850
    },
    {
      "epoch": 0.18431204457779682,
      "grad_norm": 0.42243316769599915,
      "learning_rate": 1.9754250607229607e-05,
      "loss": 0.2903,
      "step": 860
    },
    {
      "epoch": 0.18645520788684097,
      "grad_norm": 42.90293502807617,
      "learning_rate": 1.975139305615088e-05,
      "loss": 0.5266,
      "step": 870
    },
    {
      "epoch": 0.18859837119588513,
      "grad_norm": 9.164815902709961,
      "learning_rate": 1.9748535505072155e-05,
      "loss": 0.3739,
      "step": 880
    },
    {
      "epoch": 0.19074153450492928,
      "grad_norm": 2.0234315395355225,
      "learning_rate": 1.974567795399343e-05,
      "loss": 1.0268,
      "step": 890
    },
    {
      "epoch": 0.19288469781397344,
      "grad_norm": 0.04290128871798515,
      "learning_rate": 1.9742820402914703e-05,
      "loss": 0.1641,
      "step": 900
    },
    {
      "epoch": 0.19502786112301757,
      "grad_norm": 0.17190808057785034,
      "learning_rate": 1.973996285183598e-05,
      "loss": 0.9445,
      "step": 910
    },
    {
      "epoch": 0.19717102443206172,
      "grad_norm": 25.716106414794922,
      "learning_rate": 1.9737105300757254e-05,
      "loss": 0.7595,
      "step": 920
    },
    {
      "epoch": 0.19931418774110587,
      "grad_norm": 1.3432997465133667,
      "learning_rate": 1.9734247749678528e-05,
      "loss": 0.4739,
      "step": 930
    },
    {
      "epoch": 0.20145735105015003,
      "grad_norm": 3.920973777770996,
      "learning_rate": 1.9731390198599802e-05,
      "loss": 0.6556,
      "step": 940
    },
    {
      "epoch": 0.20360051435919416,
      "grad_norm": 45.19245910644531,
      "learning_rate": 1.9728532647521076e-05,
      "loss": 0.8024,
      "step": 950
    },
    {
      "epoch": 0.2057436776682383,
      "grad_norm": 2.525243043899536,
      "learning_rate": 1.9725675096442353e-05,
      "loss": 0.6705,
      "step": 960
    },
    {
      "epoch": 0.20788684097728247,
      "grad_norm": 40.20686721801758,
      "learning_rate": 1.9722817545363624e-05,
      "loss": 0.3087,
      "step": 970
    },
    {
      "epoch": 0.21003000428632662,
      "grad_norm": 30.939849853515625,
      "learning_rate": 1.9719959994284897e-05,
      "loss": 0.3808,
      "step": 980
    },
    {
      "epoch": 0.21217316759537078,
      "grad_norm": 16.35280418395996,
      "learning_rate": 1.9717102443206175e-05,
      "loss": 0.9821,
      "step": 990
    },
    {
      "epoch": 0.2143163309044149,
      "grad_norm": 33.5370979309082,
      "learning_rate": 1.971424489212745e-05,
      "loss": 0.8073,
      "step": 1000
    },
    {
      "epoch": 0.21645949421345906,
      "grad_norm": 3.9347264766693115,
      "learning_rate": 1.9711387341048723e-05,
      "loss": 0.4818,
      "step": 1010
    },
    {
      "epoch": 0.2186026575225032,
      "grad_norm": 0.4345773160457611,
      "learning_rate": 1.9708529789969997e-05,
      "loss": 0.3713,
      "step": 1020
    },
    {
      "epoch": 0.22074582083154737,
      "grad_norm": 0.19182945787906647,
      "learning_rate": 1.970567223889127e-05,
      "loss": 0.4892,
      "step": 1030
    },
    {
      "epoch": 0.22288898414059152,
      "grad_norm": 0.12282036989927292,
      "learning_rate": 1.9702814687812544e-05,
      "loss": 0.3873,
      "step": 1040
    },
    {
      "epoch": 0.22503214744963565,
      "grad_norm": 3.4958066940307617,
      "learning_rate": 1.9699957136733822e-05,
      "loss": 0.4124,
      "step": 1050
    },
    {
      "epoch": 0.2271753107586798,
      "grad_norm": 24.699329376220703,
      "learning_rate": 1.9697099585655096e-05,
      "loss": 1.1141,
      "step": 1060
    },
    {
      "epoch": 0.22931847406772396,
      "grad_norm": 1.7434794902801514,
      "learning_rate": 1.969424203457637e-05,
      "loss": 0.2589,
      "step": 1070
    },
    {
      "epoch": 0.23146163737676811,
      "grad_norm": 0.4425047039985657,
      "learning_rate": 1.9691384483497643e-05,
      "loss": 0.2968,
      "step": 1080
    },
    {
      "epoch": 0.23360480068581227,
      "grad_norm": 63.82774353027344,
      "learning_rate": 1.9688526932418917e-05,
      "loss": 0.42,
      "step": 1090
    },
    {
      "epoch": 0.2357479639948564,
      "grad_norm": 52.33557891845703,
      "learning_rate": 1.9685669381340195e-05,
      "loss": 1.0177,
      "step": 1100
    },
    {
      "epoch": 0.23789112730390055,
      "grad_norm": 7.945324420928955,
      "learning_rate": 1.968281183026147e-05,
      "loss": 0.7909,
      "step": 1110
    },
    {
      "epoch": 0.2400342906129447,
      "grad_norm": 0.2009899616241455,
      "learning_rate": 1.9679954279182743e-05,
      "loss": 0.4775,
      "step": 1120
    },
    {
      "epoch": 0.24217745392198886,
      "grad_norm": 35.45773696899414,
      "learning_rate": 1.9677096728104017e-05,
      "loss": 0.8276,
      "step": 1130
    },
    {
      "epoch": 0.24432061723103302,
      "grad_norm": 37.26311111450195,
      "learning_rate": 1.967423917702529e-05,
      "loss": 0.8487,
      "step": 1140
    },
    {
      "epoch": 0.24646378054007714,
      "grad_norm": 5.237140655517578,
      "learning_rate": 1.9671381625946568e-05,
      "loss": 0.5631,
      "step": 1150
    },
    {
      "epoch": 0.2486069438491213,
      "grad_norm": 62.25538635253906,
      "learning_rate": 1.966852407486784e-05,
      "loss": 0.928,
      "step": 1160
    },
    {
      "epoch": 0.2507501071581654,
      "grad_norm": 69.99549865722656,
      "learning_rate": 1.9665666523789116e-05,
      "loss": 0.8757,
      "step": 1170
    },
    {
      "epoch": 0.2528932704672096,
      "grad_norm": 11.004998207092285,
      "learning_rate": 1.966280897271039e-05,
      "loss": 0.9432,
      "step": 1180
    },
    {
      "epoch": 0.25503643377625373,
      "grad_norm": 37.74681091308594,
      "learning_rate": 1.9659951421631663e-05,
      "loss": 0.6839,
      "step": 1190
    },
    {
      "epoch": 0.2571795970852979,
      "grad_norm": 40.92421340942383,
      "learning_rate": 1.9657093870552937e-05,
      "loss": 0.7025,
      "step": 1200
    },
    {
      "epoch": 0.25932276039434204,
      "grad_norm": 45.80708694458008,
      "learning_rate": 1.965423631947421e-05,
      "loss": 0.2463,
      "step": 1210
    },
    {
      "epoch": 0.26146592370338617,
      "grad_norm": 38.39543533325195,
      "learning_rate": 1.9651378768395485e-05,
      "loss": 0.6458,
      "step": 1220
    },
    {
      "epoch": 0.26360908701243035,
      "grad_norm": 60.14650344848633,
      "learning_rate": 1.964852121731676e-05,
      "loss": 0.6458,
      "step": 1230
    },
    {
      "epoch": 0.2657522503214745,
      "grad_norm": 1.5050488710403442,
      "learning_rate": 1.9645663666238037e-05,
      "loss": 1.3201,
      "step": 1240
    },
    {
      "epoch": 0.26789541363051866,
      "grad_norm": 41.23394775390625,
      "learning_rate": 1.964280611515931e-05,
      "loss": 0.4831,
      "step": 1250
    },
    {
      "epoch": 0.2700385769395628,
      "grad_norm": 40.65238571166992,
      "learning_rate": 1.9639948564080584e-05,
      "loss": 1.1669,
      "step": 1260
    },
    {
      "epoch": 0.2721817402486069,
      "grad_norm": 26.06684112548828,
      "learning_rate": 1.9637091013001858e-05,
      "loss": 0.2779,
      "step": 1270
    },
    {
      "epoch": 0.2743249035576511,
      "grad_norm": 0.11367509514093399,
      "learning_rate": 1.9634233461923132e-05,
      "loss": 0.223,
      "step": 1280
    },
    {
      "epoch": 0.27646806686669523,
      "grad_norm": 35.237857818603516,
      "learning_rate": 1.963137591084441e-05,
      "loss": 0.1091,
      "step": 1290
    },
    {
      "epoch": 0.2786112301757394,
      "grad_norm": 67.05636596679688,
      "learning_rate": 1.9628518359765683e-05,
      "loss": 0.6089,
      "step": 1300
    },
    {
      "epoch": 0.28075439348478354,
      "grad_norm": 31.52860450744629,
      "learning_rate": 1.9625660808686957e-05,
      "loss": 0.7762,
      "step": 1310
    },
    {
      "epoch": 0.28289755679382766,
      "grad_norm": 2.6442558765411377,
      "learning_rate": 1.962280325760823e-05,
      "loss": 0.619,
      "step": 1320
    },
    {
      "epoch": 0.28504072010287185,
      "grad_norm": 8.521754264831543,
      "learning_rate": 1.9619945706529505e-05,
      "loss": 0.7146,
      "step": 1330
    },
    {
      "epoch": 0.287183883411916,
      "grad_norm": 27.71416664123535,
      "learning_rate": 1.961708815545078e-05,
      "loss": 0.8244,
      "step": 1340
    },
    {
      "epoch": 0.28932704672096016,
      "grad_norm": 9.205469131469727,
      "learning_rate": 1.9614230604372056e-05,
      "loss": 0.3481,
      "step": 1350
    },
    {
      "epoch": 0.2914702100300043,
      "grad_norm": 31.74759292602539,
      "learning_rate": 1.961137305329333e-05,
      "loss": 0.4995,
      "step": 1360
    },
    {
      "epoch": 0.2936133733390484,
      "grad_norm": 0.13903971016407013,
      "learning_rate": 1.9608515502214604e-05,
      "loss": 0.4686,
      "step": 1370
    },
    {
      "epoch": 0.2957565366480926,
      "grad_norm": 39.906105041503906,
      "learning_rate": 1.9605657951135878e-05,
      "loss": 0.3908,
      "step": 1380
    },
    {
      "epoch": 0.2978996999571367,
      "grad_norm": 41.26169204711914,
      "learning_rate": 1.9602800400057152e-05,
      "loss": 1.1391,
      "step": 1390
    },
    {
      "epoch": 0.3000428632661809,
      "grad_norm": 0.2662945091724396,
      "learning_rate": 1.9599942848978426e-05,
      "loss": 0.6981,
      "step": 1400
    },
    {
      "epoch": 0.30218602657522503,
      "grad_norm": 5.303050518035889,
      "learning_rate": 1.95970852978997e-05,
      "loss": 0.5344,
      "step": 1410
    },
    {
      "epoch": 0.30432918988426916,
      "grad_norm": 0.7410282492637634,
      "learning_rate": 1.9594227746820974e-05,
      "loss": 0.8464,
      "step": 1420
    },
    {
      "epoch": 0.30647235319331334,
      "grad_norm": 0.1258239895105362,
      "learning_rate": 1.959137019574225e-05,
      "loss": 0.7855,
      "step": 1430
    },
    {
      "epoch": 0.30861551650235747,
      "grad_norm": 36.47433090209961,
      "learning_rate": 1.9588512644663525e-05,
      "loss": 0.7673,
      "step": 1440
    },
    {
      "epoch": 0.31075867981140165,
      "grad_norm": 7.4123334884643555,
      "learning_rate": 1.95856550935848e-05,
      "loss": 0.6822,
      "step": 1450
    },
    {
      "epoch": 0.3129018431204458,
      "grad_norm": 0.29419994354248047,
      "learning_rate": 1.9582797542506073e-05,
      "loss": 0.5978,
      "step": 1460
    },
    {
      "epoch": 0.3150450064294899,
      "grad_norm": 51.68134689331055,
      "learning_rate": 1.9579939991427347e-05,
      "loss": 1.0704,
      "step": 1470
    },
    {
      "epoch": 0.3171881697385341,
      "grad_norm": 1.4291846752166748,
      "learning_rate": 1.957708244034862e-05,
      "loss": 0.7756,
      "step": 1480
    },
    {
      "epoch": 0.3193313330475782,
      "grad_norm": 6.0241169929504395,
      "learning_rate": 1.9574224889269898e-05,
      "loss": 0.5418,
      "step": 1490
    },
    {
      "epoch": 0.3214744963566224,
      "grad_norm": 2.147730827331543,
      "learning_rate": 1.9571367338191172e-05,
      "loss": 0.4744,
      "step": 1500
    },
    {
      "epoch": 0.3236176596656665,
      "grad_norm": 0.032540708780288696,
      "learning_rate": 1.9568509787112446e-05,
      "loss": 0.5043,
      "step": 1510
    },
    {
      "epoch": 0.32576082297471065,
      "grad_norm": 0.14605559408664703,
      "learning_rate": 1.956565223603372e-05,
      "loss": 0.1955,
      "step": 1520
    },
    {
      "epoch": 0.32790398628375483,
      "grad_norm": 0.5323083400726318,
      "learning_rate": 1.9562794684954994e-05,
      "loss": 0.3927,
      "step": 1530
    },
    {
      "epoch": 0.33004714959279896,
      "grad_norm": 27.728164672851562,
      "learning_rate": 1.955993713387627e-05,
      "loss": 0.5377,
      "step": 1540
    },
    {
      "epoch": 0.33219031290184314,
      "grad_norm": 36.980403900146484,
      "learning_rate": 1.9557079582797545e-05,
      "loss": 1.0698,
      "step": 1550
    },
    {
      "epoch": 0.33433347621088727,
      "grad_norm": 27.379369735717773,
      "learning_rate": 1.955422203171882e-05,
      "loss": 0.6537,
      "step": 1560
    },
    {
      "epoch": 0.3364766395199314,
      "grad_norm": 46.811073303222656,
      "learning_rate": 1.9551364480640093e-05,
      "loss": 0.9987,
      "step": 1570
    },
    {
      "epoch": 0.3386198028289756,
      "grad_norm": 32.67144012451172,
      "learning_rate": 1.9548506929561367e-05,
      "loss": 0.533,
      "step": 1580
    },
    {
      "epoch": 0.3407629661380197,
      "grad_norm": 0.20204801857471466,
      "learning_rate": 1.9545649378482644e-05,
      "loss": 0.0704,
      "step": 1590
    },
    {
      "epoch": 0.3429061294470639,
      "grad_norm": 0.04357576742768288,
      "learning_rate": 1.9542791827403918e-05,
      "loss": 0.3015,
      "step": 1600
    },
    {
      "epoch": 0.345049292756108,
      "grad_norm": 0.039447639137506485,
      "learning_rate": 1.9539934276325192e-05,
      "loss": 0.0028,
      "step": 1610
    },
    {
      "epoch": 0.34719245606515214,
      "grad_norm": 35.886512756347656,
      "learning_rate": 1.9537076725246463e-05,
      "loss": 0.752,
      "step": 1620
    },
    {
      "epoch": 0.3493356193741963,
      "grad_norm": 0.031245151534676552,
      "learning_rate": 1.953421917416774e-05,
      "loss": 0.9298,
      "step": 1630
    },
    {
      "epoch": 0.35147878268324045,
      "grad_norm": 33.54296875,
      "learning_rate": 1.9531361623089014e-05,
      "loss": 1.3148,
      "step": 1640
    },
    {
      "epoch": 0.35362194599228464,
      "grad_norm": 53.6628303527832,
      "learning_rate": 1.9528504072010288e-05,
      "loss": 1.2169,
      "step": 1650
    },
    {
      "epoch": 0.35576510930132876,
      "grad_norm": 0.41850340366363525,
      "learning_rate": 1.9525646520931562e-05,
      "loss": 0.3347,
      "step": 1660
    },
    {
      "epoch": 0.3579082726103729,
      "grad_norm": 0.11977781355381012,
      "learning_rate": 1.9522788969852836e-05,
      "loss": 0.3559,
      "step": 1670
    },
    {
      "epoch": 0.3600514359194171,
      "grad_norm": 28.1061954498291,
      "learning_rate": 1.9519931418774113e-05,
      "loss": 1.0676,
      "step": 1680
    },
    {
      "epoch": 0.3621945992284612,
      "grad_norm": 28.77485466003418,
      "learning_rate": 1.9517073867695387e-05,
      "loss": 0.6746,
      "step": 1690
    },
    {
      "epoch": 0.3643377625375054,
      "grad_norm": 33.177608489990234,
      "learning_rate": 1.951421631661666e-05,
      "loss": 1.0902,
      "step": 1700
    },
    {
      "epoch": 0.3664809258465495,
      "grad_norm": 2.0541446208953857,
      "learning_rate": 1.9511358765537935e-05,
      "loss": 0.3702,
      "step": 1710
    },
    {
      "epoch": 0.36862408915559364,
      "grad_norm": 5.961366176605225,
      "learning_rate": 1.950850121445921e-05,
      "loss": 0.6806,
      "step": 1720
    },
    {
      "epoch": 0.3707672524646378,
      "grad_norm": 3.979654550552368,
      "learning_rate": 1.9505643663380486e-05,
      "loss": 0.7427,
      "step": 1730
    },
    {
      "epoch": 0.37291041577368195,
      "grad_norm": 17.91322898864746,
      "learning_rate": 1.950278611230176e-05,
      "loss": 0.1518,
      "step": 1740
    },
    {
      "epoch": 0.37505357908272613,
      "grad_norm": 33.698856353759766,
      "learning_rate": 1.9499928561223034e-05,
      "loss": 0.6212,
      "step": 1750
    },
    {
      "epoch": 0.37719674239177026,
      "grad_norm": 21.980300903320312,
      "learning_rate": 1.9497071010144308e-05,
      "loss": 0.6587,
      "step": 1760
    },
    {
      "epoch": 0.3793399057008144,
      "grad_norm": 0.2997153401374817,
      "learning_rate": 1.9494213459065582e-05,
      "loss": 0.7845,
      "step": 1770
    },
    {
      "epoch": 0.38148306900985857,
      "grad_norm": 37.525428771972656,
      "learning_rate": 1.949135590798686e-05,
      "loss": 0.5548,
      "step": 1780
    },
    {
      "epoch": 0.3836262323189027,
      "grad_norm": 0.1317320466041565,
      "learning_rate": 1.9488498356908133e-05,
      "loss": 0.1349,
      "step": 1790
    },
    {
      "epoch": 0.3857693956279469,
      "grad_norm": 44.67494583129883,
      "learning_rate": 1.9485640805829407e-05,
      "loss": 1.0618,
      "step": 1800
    },
    {
      "epoch": 0.387912558936991,
      "grad_norm": 0.4031739830970764,
      "learning_rate": 1.948278325475068e-05,
      "loss": 0.72,
      "step": 1810
    },
    {
      "epoch": 0.39005572224603513,
      "grad_norm": 0.6244134306907654,
      "learning_rate": 1.9479925703671955e-05,
      "loss": 0.7844,
      "step": 1820
    },
    {
      "epoch": 0.3921988855550793,
      "grad_norm": 48.03528594970703,
      "learning_rate": 1.947706815259323e-05,
      "loss": 0.6007,
      "step": 1830
    },
    {
      "epoch": 0.39434204886412344,
      "grad_norm": 0.08148891478776932,
      "learning_rate": 1.9474210601514503e-05,
      "loss": 0.3889,
      "step": 1840
    },
    {
      "epoch": 0.3964852121731676,
      "grad_norm": 0.11513315886259079,
      "learning_rate": 1.9471353050435777e-05,
      "loss": 0.1555,
      "step": 1850
    },
    {
      "epoch": 0.39862837548221175,
      "grad_norm": 2.7875795364379883,
      "learning_rate": 1.946849549935705e-05,
      "loss": 0.6133,
      "step": 1860
    },
    {
      "epoch": 0.4007715387912559,
      "grad_norm": 27.467506408691406,
      "learning_rate": 1.9465637948278328e-05,
      "loss": 0.34,
      "step": 1870
    },
    {
      "epoch": 0.40291470210030006,
      "grad_norm": 0.8915380835533142,
      "learning_rate": 1.9462780397199602e-05,
      "loss": 0.712,
      "step": 1880
    },
    {
      "epoch": 0.4050578654093442,
      "grad_norm": 0.2182988077402115,
      "learning_rate": 1.9459922846120876e-05,
      "loss": 1.221,
      "step": 1890
    },
    {
      "epoch": 0.4072010287183883,
      "grad_norm": 21.970149993896484,
      "learning_rate": 1.945706529504215e-05,
      "loss": 1.191,
      "step": 1900
    },
    {
      "epoch": 0.4093441920274325,
      "grad_norm": 1.91692316532135,
      "learning_rate": 1.9454207743963424e-05,
      "loss": 0.6012,
      "step": 1910
    },
    {
      "epoch": 0.4114873553364766,
      "grad_norm": 27.86449432373047,
      "learning_rate": 1.94513501928847e-05,
      "loss": 1.1415,
      "step": 1920
    },
    {
      "epoch": 0.4136305186455208,
      "grad_norm": 41.838844299316406,
      "learning_rate": 1.9448492641805975e-05,
      "loss": 0.7032,
      "step": 1930
    },
    {
      "epoch": 0.41577368195456493,
      "grad_norm": 13.569287300109863,
      "learning_rate": 1.944563509072725e-05,
      "loss": 0.3917,
      "step": 1940
    },
    {
      "epoch": 0.41791684526360906,
      "grad_norm": 4.8016228675842285,
      "learning_rate": 1.9442777539648523e-05,
      "loss": 0.615,
      "step": 1950
    },
    {
      "epoch": 0.42006000857265324,
      "grad_norm": 11.327485084533691,
      "learning_rate": 1.9439919988569797e-05,
      "loss": 0.6101,
      "step": 1960
    },
    {
      "epoch": 0.42220317188169737,
      "grad_norm": 0.6940925717353821,
      "learning_rate": 1.943706243749107e-05,
      "loss": 0.4009,
      "step": 1970
    },
    {
      "epoch": 0.42434633519074155,
      "grad_norm": 24.812044143676758,
      "learning_rate": 1.9434204886412348e-05,
      "loss": 0.9846,
      "step": 1980
    },
    {
      "epoch": 0.4264894984997857,
      "grad_norm": 36.34074401855469,
      "learning_rate": 1.9431347335333622e-05,
      "loss": 0.8425,
      "step": 1990
    },
    {
      "epoch": 0.4286326618088298,
      "grad_norm": 25.56438446044922,
      "learning_rate": 1.9428489784254896e-05,
      "loss": 0.4828,
      "step": 2000
    },
    {
      "epoch": 0.430775825117874,
      "grad_norm": 27.35542106628418,
      "learning_rate": 1.942563223317617e-05,
      "loss": 0.4982,
      "step": 2010
    },
    {
      "epoch": 0.4329189884269181,
      "grad_norm": 5.543044567108154,
      "learning_rate": 1.9422774682097444e-05,
      "loss": 0.3218,
      "step": 2020
    },
    {
      "epoch": 0.4350621517359623,
      "grad_norm": 11.5436429977417,
      "learning_rate": 1.941991713101872e-05,
      "loss": 1.1769,
      "step": 2030
    },
    {
      "epoch": 0.4372053150450064,
      "grad_norm": 41.4129524230957,
      "learning_rate": 1.941705957993999e-05,
      "loss": 0.1655,
      "step": 2040
    },
    {
      "epoch": 0.43934847835405055,
      "grad_norm": 0.13286584615707397,
      "learning_rate": 1.9414202028861265e-05,
      "loss": 0.6514,
      "step": 2050
    },
    {
      "epoch": 0.44149164166309474,
      "grad_norm": 25.298032760620117,
      "learning_rate": 1.9411344477782543e-05,
      "loss": 0.7787,
      "step": 2060
    },
    {
      "epoch": 0.44363480497213886,
      "grad_norm": 54.86668014526367,
      "learning_rate": 1.9408486926703817e-05,
      "loss": 1.1577,
      "step": 2070
    },
    {
      "epoch": 0.44577796828118305,
      "grad_norm": 1.2456700801849365,
      "learning_rate": 1.940562937562509e-05,
      "loss": 0.4513,
      "step": 2080
    },
    {
      "epoch": 0.4479211315902272,
      "grad_norm": 0.45792025327682495,
      "learning_rate": 1.9402771824546364e-05,
      "loss": 0.5733,
      "step": 2090
    },
    {
      "epoch": 0.4500642948992713,
      "grad_norm": 14.331550598144531,
      "learning_rate": 1.939991427346764e-05,
      "loss": 0.5692,
      "step": 2100
    },
    {
      "epoch": 0.4522074582083155,
      "grad_norm": 0.26419639587402344,
      "learning_rate": 1.9397056722388912e-05,
      "loss": 0.4627,
      "step": 2110
    },
    {
      "epoch": 0.4543506215173596,
      "grad_norm": 5.131396293640137,
      "learning_rate": 1.939419917131019e-05,
      "loss": 0.6356,
      "step": 2120
    },
    {
      "epoch": 0.4564937848264038,
      "grad_norm": 9.496095657348633,
      "learning_rate": 1.9391341620231464e-05,
      "loss": 0.2918,
      "step": 2130
    },
    {
      "epoch": 0.4586369481354479,
      "grad_norm": 0.10264983028173447,
      "learning_rate": 1.9388484069152737e-05,
      "loss": 1.2686,
      "step": 2140
    },
    {
      "epoch": 0.46078011144449205,
      "grad_norm": 0.37145501375198364,
      "learning_rate": 1.938562651807401e-05,
      "loss": 0.7003,
      "step": 2150
    },
    {
      "epoch": 0.46292327475353623,
      "grad_norm": 25.37019920349121,
      "learning_rate": 1.9382768966995285e-05,
      "loss": 0.6943,
      "step": 2160
    },
    {
      "epoch": 0.46506643806258036,
      "grad_norm": 24.13629150390625,
      "learning_rate": 1.9379911415916563e-05,
      "loss": 0.6784,
      "step": 2170
    },
    {
      "epoch": 0.46720960137162454,
      "grad_norm": 0.31709232926368713,
      "learning_rate": 1.9377053864837837e-05,
      "loss": 0.7358,
      "step": 2180
    },
    {
      "epoch": 0.46935276468066867,
      "grad_norm": 53.81786346435547,
      "learning_rate": 1.937419631375911e-05,
      "loss": 0.736,
      "step": 2190
    },
    {
      "epoch": 0.4714959279897128,
      "grad_norm": 4.061947345733643,
      "learning_rate": 1.9371338762680384e-05,
      "loss": 0.9452,
      "step": 2200
    },
    {
      "epoch": 0.473639091298757,
      "grad_norm": 0.38364744186401367,
      "learning_rate": 1.936848121160166e-05,
      "loss": 0.5001,
      "step": 2210
    },
    {
      "epoch": 0.4757822546078011,
      "grad_norm": 0.6479939818382263,
      "learning_rate": 1.9365623660522936e-05,
      "loss": 0.6589,
      "step": 2220
    },
    {
      "epoch": 0.4779254179168453,
      "grad_norm": 26.11249542236328,
      "learning_rate": 1.936276610944421e-05,
      "loss": 0.6724,
      "step": 2230
    },
    {
      "epoch": 0.4800685812258894,
      "grad_norm": 0.6579319834709167,
      "learning_rate": 1.9359908558365484e-05,
      "loss": 0.876,
      "step": 2240
    },
    {
      "epoch": 0.48221174453493354,
      "grad_norm": 1.3101942539215088,
      "learning_rate": 1.9357051007286757e-05,
      "loss": 1.0984,
      "step": 2250
    },
    {
      "epoch": 0.4843549078439777,
      "grad_norm": 23.943166732788086,
      "learning_rate": 1.935419345620803e-05,
      "loss": 0.5401,
      "step": 2260
    },
    {
      "epoch": 0.48649807115302185,
      "grad_norm": 23.968952178955078,
      "learning_rate": 1.9351335905129305e-05,
      "loss": 0.6837,
      "step": 2270
    },
    {
      "epoch": 0.48864123446206603,
      "grad_norm": 5.994570732116699,
      "learning_rate": 1.934847835405058e-05,
      "loss": 0.9235,
      "step": 2280
    },
    {
      "epoch": 0.49078439777111016,
      "grad_norm": 0.5349944829940796,
      "learning_rate": 1.9345620802971853e-05,
      "loss": 0.2513,
      "step": 2290
    },
    {
      "epoch": 0.4929275610801543,
      "grad_norm": 0.15763168036937714,
      "learning_rate": 1.9342763251893127e-05,
      "loss": 0.6755,
      "step": 2300
    },
    {
      "epoch": 0.49507072438919847,
      "grad_norm": 0.3586450219154358,
      "learning_rate": 1.9339905700814404e-05,
      "loss": 0.4382,
      "step": 2310
    },
    {
      "epoch": 0.4972138876982426,
      "grad_norm": 27.28173828125,
      "learning_rate": 1.933704814973568e-05,
      "loss": 1.5972,
      "step": 2320
    },
    {
      "epoch": 0.4993570510072868,
      "grad_norm": 3.496609687805176,
      "learning_rate": 1.9334190598656952e-05,
      "loss": 0.3264,
      "step": 2330
    },
    {
      "epoch": 0.5015002143163309,
      "grad_norm": 46.15705871582031,
      "learning_rate": 1.9331333047578226e-05,
      "loss": 0.9081,
      "step": 2340
    },
    {
      "epoch": 0.503643377625375,
      "grad_norm": 0.44779661297798157,
      "learning_rate": 1.93284754964995e-05,
      "loss": 0.1395,
      "step": 2350
    },
    {
      "epoch": 0.5057865409344192,
      "grad_norm": 0.12276600301265717,
      "learning_rate": 1.9325617945420777e-05,
      "loss": 0.3684,
      "step": 2360
    },
    {
      "epoch": 0.5079297042434634,
      "grad_norm": 0.09352849423885345,
      "learning_rate": 1.932276039434205e-05,
      "loss": 0.3946,
      "step": 2370
    },
    {
      "epoch": 0.5100728675525075,
      "grad_norm": 0.20938993990421295,
      "learning_rate": 1.9319902843263325e-05,
      "loss": 1.2592,
      "step": 2380
    },
    {
      "epoch": 0.5122160308615517,
      "grad_norm": 0.5582708120346069,
      "learning_rate": 1.93170452921846e-05,
      "loss": 0.7311,
      "step": 2390
    },
    {
      "epoch": 0.5143591941705958,
      "grad_norm": 0.7104549407958984,
      "learning_rate": 1.9314187741105873e-05,
      "loss": 0.6358,
      "step": 2400
    },
    {
      "epoch": 0.5165023574796399,
      "grad_norm": 0.4146830439567566,
      "learning_rate": 1.931133019002715e-05,
      "loss": 0.7383,
      "step": 2410
    },
    {
      "epoch": 0.5186455207886841,
      "grad_norm": 0.7475467324256897,
      "learning_rate": 1.9308472638948424e-05,
      "loss": 0.7463,
      "step": 2420
    },
    {
      "epoch": 0.5207886840977283,
      "grad_norm": 1.6179821491241455,
      "learning_rate": 1.93056150878697e-05,
      "loss": 0.1837,
      "step": 2430
    },
    {
      "epoch": 0.5229318474067723,
      "grad_norm": 19.116531372070312,
      "learning_rate": 1.9302757536790972e-05,
      "loss": 0.9056,
      "step": 2440
    },
    {
      "epoch": 0.5250750107158165,
      "grad_norm": 0.565274178981781,
      "learning_rate": 1.9299899985712246e-05,
      "loss": 0.8551,
      "step": 2450
    },
    {
      "epoch": 0.5272181740248607,
      "grad_norm": 27.395742416381836,
      "learning_rate": 1.929704243463352e-05,
      "loss": 0.6926,
      "step": 2460
    },
    {
      "epoch": 0.5293613373339049,
      "grad_norm": 5.596426963806152,
      "learning_rate": 1.9294184883554794e-05,
      "loss": 0.3873,
      "step": 2470
    },
    {
      "epoch": 0.531504500642949,
      "grad_norm": 18.47796058654785,
      "learning_rate": 1.9291327332476068e-05,
      "loss": 0.7068,
      "step": 2480
    },
    {
      "epoch": 0.5336476639519931,
      "grad_norm": 0.5949705243110657,
      "learning_rate": 1.9288469781397342e-05,
      "loss": 0.2829,
      "step": 2490
    },
    {
      "epoch": 0.5357908272610373,
      "grad_norm": 40.44016647338867,
      "learning_rate": 1.928561223031862e-05,
      "loss": 0.6582,
      "step": 2500
    },
    {
      "epoch": 0.5379339905700814,
      "grad_norm": 19.825119018554688,
      "learning_rate": 1.9282754679239893e-05,
      "loss": 0.6838,
      "step": 2510
    },
    {
      "epoch": 0.5400771538791256,
      "grad_norm": 21.304121017456055,
      "learning_rate": 1.9279897128161167e-05,
      "loss": 0.5054,
      "step": 2520
    },
    {
      "epoch": 0.5422203171881698,
      "grad_norm": 1.2788019180297852,
      "learning_rate": 1.927703957708244e-05,
      "loss": 0.548,
      "step": 2530
    },
    {
      "epoch": 0.5443634804972138,
      "grad_norm": 55.83146667480469,
      "learning_rate": 1.9274182026003715e-05,
      "loss": 0.8037,
      "step": 2540
    },
    {
      "epoch": 0.546506643806258,
      "grad_norm": 21.745412826538086,
      "learning_rate": 1.9271324474924992e-05,
      "loss": 0.8249,
      "step": 2550
    },
    {
      "epoch": 0.5486498071153022,
      "grad_norm": 0.4004412293434143,
      "learning_rate": 1.9268466923846266e-05,
      "loss": 0.7219,
      "step": 2560
    },
    {
      "epoch": 0.5507929704243464,
      "grad_norm": 2.171865224838257,
      "learning_rate": 1.926560937276754e-05,
      "loss": 0.3707,
      "step": 2570
    },
    {
      "epoch": 0.5529361337333905,
      "grad_norm": 0.536571741104126,
      "learning_rate": 1.9262751821688814e-05,
      "loss": 0.6423,
      "step": 2580
    },
    {
      "epoch": 0.5550792970424346,
      "grad_norm": 0.9973428845405579,
      "learning_rate": 1.9259894270610088e-05,
      "loss": 0.7327,
      "step": 2590
    },
    {
      "epoch": 0.5572224603514788,
      "grad_norm": 0.25072091817855835,
      "learning_rate": 1.9257036719531362e-05,
      "loss": 1.051,
      "step": 2600
    },
    {
      "epoch": 0.5593656236605229,
      "grad_norm": 26.070974349975586,
      "learning_rate": 1.925417916845264e-05,
      "loss": 1.0504,
      "step": 2610
    },
    {
      "epoch": 0.5615087869695671,
      "grad_norm": 1.105953574180603,
      "learning_rate": 1.9251321617373913e-05,
      "loss": 0.74,
      "step": 2620
    },
    {
      "epoch": 0.5636519502786113,
      "grad_norm": 1.7164106369018555,
      "learning_rate": 1.9248464066295187e-05,
      "loss": 0.6959,
      "step": 2630
    },
    {
      "epoch": 0.5657951135876553,
      "grad_norm": 19.6055850982666,
      "learning_rate": 1.924560651521646e-05,
      "loss": 0.5508,
      "step": 2640
    },
    {
      "epoch": 0.5679382768966995,
      "grad_norm": 28.798696517944336,
      "learning_rate": 1.9242748964137735e-05,
      "loss": 0.8539,
      "step": 2650
    },
    {
      "epoch": 0.5700814402057437,
      "grad_norm": 16.517560958862305,
      "learning_rate": 1.9239891413059012e-05,
      "loss": 0.6185,
      "step": 2660
    },
    {
      "epoch": 0.5722246035147879,
      "grad_norm": 15.77249526977539,
      "learning_rate": 1.9237033861980286e-05,
      "loss": 0.6445,
      "step": 2670
    },
    {
      "epoch": 0.574367766823832,
      "grad_norm": 36.042564392089844,
      "learning_rate": 1.923417631090156e-05,
      "loss": 0.5357,
      "step": 2680
    },
    {
      "epoch": 0.5765109301328761,
      "grad_norm": 0.33494654297828674,
      "learning_rate": 1.9231318759822834e-05,
      "loss": 1.0917,
      "step": 2690
    },
    {
      "epoch": 0.5786540934419203,
      "grad_norm": 22.163484573364258,
      "learning_rate": 1.9228461208744108e-05,
      "loss": 0.3337,
      "step": 2700
    },
    {
      "epoch": 0.5807972567509644,
      "grad_norm": 22.824512481689453,
      "learning_rate": 1.9225603657665382e-05,
      "loss": 0.6777,
      "step": 2710
    },
    {
      "epoch": 0.5829404200600086,
      "grad_norm": 0.39035502076148987,
      "learning_rate": 1.9222746106586656e-05,
      "loss": 0.4212,
      "step": 2720
    },
    {
      "epoch": 0.5850835833690528,
      "grad_norm": 6.468832969665527,
      "learning_rate": 1.921988855550793e-05,
      "loss": 0.9434,
      "step": 2730
    },
    {
      "epoch": 0.5872267466780968,
      "grad_norm": 1.8115698099136353,
      "learning_rate": 1.9217031004429204e-05,
      "loss": 0.3563,
      "step": 2740
    },
    {
      "epoch": 0.589369909987141,
      "grad_norm": 0.4025152623653412,
      "learning_rate": 1.921417345335048e-05,
      "loss": 0.2234,
      "step": 2750
    },
    {
      "epoch": 0.5915130732961852,
      "grad_norm": 0.28078123927116394,
      "learning_rate": 1.9211315902271755e-05,
      "loss": 0.6418,
      "step": 2760
    },
    {
      "epoch": 0.5936562366052294,
      "grad_norm": 0.28689825534820557,
      "learning_rate": 1.920845835119303e-05,
      "loss": 0.302,
      "step": 2770
    },
    {
      "epoch": 0.5957993999142734,
      "grad_norm": 26.312650680541992,
      "learning_rate": 1.9205600800114303e-05,
      "loss": 1.0855,
      "step": 2780
    },
    {
      "epoch": 0.5979425632233176,
      "grad_norm": 37.151119232177734,
      "learning_rate": 1.9202743249035577e-05,
      "loss": 0.5548,
      "step": 2790
    },
    {
      "epoch": 0.6000857265323618,
      "grad_norm": 0.32724419236183167,
      "learning_rate": 1.9199885697956854e-05,
      "loss": 0.4494,
      "step": 2800
    },
    {
      "epoch": 0.6022288898414059,
      "grad_norm": 22.872058868408203,
      "learning_rate": 1.9197028146878128e-05,
      "loss": 0.8862,
      "step": 2810
    },
    {
      "epoch": 0.6043720531504501,
      "grad_norm": 4.889121055603027,
      "learning_rate": 1.9194170595799402e-05,
      "loss": 0.5827,
      "step": 2820
    },
    {
      "epoch": 0.6065152164594942,
      "grad_norm": 20.000957489013672,
      "learning_rate": 1.9191313044720676e-05,
      "loss": 0.224,
      "step": 2830
    },
    {
      "epoch": 0.6086583797685383,
      "grad_norm": 0.07221779972314835,
      "learning_rate": 1.918845549364195e-05,
      "loss": 0.5197,
      "step": 2840
    },
    {
      "epoch": 0.6108015430775825,
      "grad_norm": 34.90927505493164,
      "learning_rate": 1.9185597942563227e-05,
      "loss": 0.5203,
      "step": 2850
    },
    {
      "epoch": 0.6129447063866267,
      "grad_norm": 0.15256327390670776,
      "learning_rate": 1.91827403914845e-05,
      "loss": 0.4855,
      "step": 2860
    },
    {
      "epoch": 0.6150878696956709,
      "grad_norm": 0.12796148657798767,
      "learning_rate": 1.9179882840405775e-05,
      "loss": 0.6806,
      "step": 2870
    },
    {
      "epoch": 0.6172310330047149,
      "grad_norm": 32.7770881652832,
      "learning_rate": 1.917702528932705e-05,
      "loss": 0.5847,
      "step": 2880
    },
    {
      "epoch": 0.6193741963137591,
      "grad_norm": 15.056477546691895,
      "learning_rate": 1.9174167738248323e-05,
      "loss": 0.2695,
      "step": 2890
    },
    {
      "epoch": 0.6215173596228033,
      "grad_norm": 42.57304763793945,
      "learning_rate": 1.9171310187169597e-05,
      "loss": 0.6699,
      "step": 2900
    },
    {
      "epoch": 0.6236605229318474,
      "grad_norm": 26.616750717163086,
      "learning_rate": 1.916845263609087e-05,
      "loss": 0.4511,
      "step": 2910
    },
    {
      "epoch": 0.6258036862408916,
      "grad_norm": 2.1685433387756348,
      "learning_rate": 1.9165595085012145e-05,
      "loss": 0.2375,
      "step": 2920
    },
    {
      "epoch": 0.6279468495499357,
      "grad_norm": 70.61978912353516,
      "learning_rate": 1.916273753393342e-05,
      "loss": 0.0371,
      "step": 2930
    },
    {
      "epoch": 0.6300900128589798,
      "grad_norm": 26.48969078063965,
      "learning_rate": 1.9159879982854696e-05,
      "loss": 0.9538,
      "step": 2940
    },
    {
      "epoch": 0.632233176168024,
      "grad_norm": 0.08981292694807053,
      "learning_rate": 1.915702243177597e-05,
      "loss": 0.6068,
      "step": 2950
    },
    {
      "epoch": 0.6343763394770682,
      "grad_norm": 26.336135864257812,
      "learning_rate": 1.9154164880697244e-05,
      "loss": 1.624,
      "step": 2960
    },
    {
      "epoch": 0.6365195027861124,
      "grad_norm": 17.77668571472168,
      "learning_rate": 1.9151307329618518e-05,
      "loss": 0.5615,
      "step": 2970
    },
    {
      "epoch": 0.6386626660951564,
      "grad_norm": 1.9251738786697388,
      "learning_rate": 1.914844977853979e-05,
      "loss": 0.7142,
      "step": 2980
    },
    {
      "epoch": 0.6408058294042006,
      "grad_norm": 22.35852813720703,
      "learning_rate": 1.914559222746107e-05,
      "loss": 0.7421,
      "step": 2990
    },
    {
      "epoch": 0.6429489927132448,
      "grad_norm": 0.25971537828445435,
      "learning_rate": 1.9142734676382343e-05,
      "loss": 0.444,
      "step": 3000
    },
    {
      "epoch": 0.6450921560222889,
      "grad_norm": 0.4543823301792145,
      "learning_rate": 1.9139877125303617e-05,
      "loss": 0.3146,
      "step": 3010
    },
    {
      "epoch": 0.647235319331333,
      "grad_norm": 0.43155038356781006,
      "learning_rate": 1.913701957422489e-05,
      "loss": 0.7377,
      "step": 3020
    },
    {
      "epoch": 0.6493784826403772,
      "grad_norm": 19.74273681640625,
      "learning_rate": 1.9134162023146165e-05,
      "loss": 0.9434,
      "step": 3030
    },
    {
      "epoch": 0.6515216459494213,
      "grad_norm": 0.2932613790035248,
      "learning_rate": 1.913130447206744e-05,
      "loss": 0.1799,
      "step": 3040
    },
    {
      "epoch": 0.6536648092584655,
      "grad_norm": 0.34691122174263,
      "learning_rate": 1.9128446920988716e-05,
      "loss": 0.045,
      "step": 3050
    },
    {
      "epoch": 0.6558079725675097,
      "grad_norm": 58.70758819580078,
      "learning_rate": 1.912558936990999e-05,
      "loss": 0.3163,
      "step": 3060
    },
    {
      "epoch": 0.6579511358765537,
      "grad_norm": 31.634618759155273,
      "learning_rate": 1.9122731818831264e-05,
      "loss": 1.1054,
      "step": 3070
    },
    {
      "epoch": 0.6600942991855979,
      "grad_norm": 10.247721672058105,
      "learning_rate": 1.9119874267752538e-05,
      "loss": 0.9745,
      "step": 3080
    },
    {
      "epoch": 0.6622374624946421,
      "grad_norm": 0.09412389248609543,
      "learning_rate": 1.911701671667381e-05,
      "loss": 0.5157,
      "step": 3090
    },
    {
      "epoch": 0.6643806258036863,
      "grad_norm": 25.523204803466797,
      "learning_rate": 1.911415916559509e-05,
      "loss": 0.5713,
      "step": 3100
    },
    {
      "epoch": 0.6665237891127304,
      "grad_norm": 14.815781593322754,
      "learning_rate": 1.9111301614516363e-05,
      "loss": 0.2164,
      "step": 3110
    },
    {
      "epoch": 0.6686669524217745,
      "grad_norm": 0.08629268407821655,
      "learning_rate": 1.9108444063437633e-05,
      "loss": 0.1257,
      "step": 3120
    },
    {
      "epoch": 0.6708101157308187,
      "grad_norm": 0.10469423979520798,
      "learning_rate": 1.910558651235891e-05,
      "loss": 1.1176,
      "step": 3130
    },
    {
      "epoch": 0.6729532790398628,
      "grad_norm": 0.26701200008392334,
      "learning_rate": 1.9102728961280185e-05,
      "loss": 0.9784,
      "step": 3140
    },
    {
      "epoch": 0.675096442348907,
      "grad_norm": 0.6393440961837769,
      "learning_rate": 1.909987141020146e-05,
      "loss": 0.3397,
      "step": 3150
    },
    {
      "epoch": 0.6772396056579512,
      "grad_norm": 0.076774001121521,
      "learning_rate": 1.9097013859122732e-05,
      "loss": 0.219,
      "step": 3160
    },
    {
      "epoch": 0.6793827689669952,
      "grad_norm": 0.27122819423675537,
      "learning_rate": 1.9094156308044006e-05,
      "loss": 0.8324,
      "step": 3170
    },
    {
      "epoch": 0.6815259322760394,
      "grad_norm": 0.5913571715354919,
      "learning_rate": 1.909129875696528e-05,
      "loss": 0.4915,
      "step": 3180
    },
    {
      "epoch": 0.6836690955850836,
      "grad_norm": 1.2952080965042114,
      "learning_rate": 1.9088441205886558e-05,
      "loss": 1.0745,
      "step": 3190
    },
    {
      "epoch": 0.6858122588941278,
      "grad_norm": 56.44414138793945,
      "learning_rate": 1.908558365480783e-05,
      "loss": 0.7781,
      "step": 3200
    },
    {
      "epoch": 0.6879554222031719,
      "grad_norm": 0.16106940805912018,
      "learning_rate": 1.9082726103729105e-05,
      "loss": 0.1401,
      "step": 3210
    },
    {
      "epoch": 0.690098585512216,
      "grad_norm": 22.900480270385742,
      "learning_rate": 1.907986855265038e-05,
      "loss": 0.5687,
      "step": 3220
    },
    {
      "epoch": 0.6922417488212602,
      "grad_norm": 26.578887939453125,
      "learning_rate": 1.9077011001571653e-05,
      "loss": 1.1899,
      "step": 3230
    },
    {
      "epoch": 0.6943849121303043,
      "grad_norm": 1.2776516675949097,
      "learning_rate": 1.907415345049293e-05,
      "loss": 0.7675,
      "step": 3240
    },
    {
      "epoch": 0.6965280754393485,
      "grad_norm": 0.5338611006736755,
      "learning_rate": 1.9071295899414205e-05,
      "loss": 0.1792,
      "step": 3250
    },
    {
      "epoch": 0.6986712387483927,
      "grad_norm": 18.63169288635254,
      "learning_rate": 1.906843834833548e-05,
      "loss": 0.7845,
      "step": 3260
    },
    {
      "epoch": 0.7008144020574367,
      "grad_norm": 25.376079559326172,
      "learning_rate": 1.9065580797256752e-05,
      "loss": 0.7265,
      "step": 3270
    },
    {
      "epoch": 0.7029575653664809,
      "grad_norm": 0.22501946985721588,
      "learning_rate": 1.9062723246178026e-05,
      "loss": 0.5539,
      "step": 3280
    },
    {
      "epoch": 0.7051007286755251,
      "grad_norm": 38.74170684814453,
      "learning_rate": 1.9059865695099304e-05,
      "loss": 0.6289,
      "step": 3290
    },
    {
      "epoch": 0.7072438919845693,
      "grad_norm": 63.464385986328125,
      "learning_rate": 1.9057008144020578e-05,
      "loss": 0.9198,
      "step": 3300
    },
    {
      "epoch": 0.7093870552936133,
      "grad_norm": 3.9720699787139893,
      "learning_rate": 1.905415059294185e-05,
      "loss": 0.0989,
      "step": 3310
    },
    {
      "epoch": 0.7115302186026575,
      "grad_norm": 0.45473387837409973,
      "learning_rate": 1.9051293041863125e-05,
      "loss": 0.5896,
      "step": 3320
    },
    {
      "epoch": 0.7136733819117017,
      "grad_norm": 1.7002294063568115,
      "learning_rate": 1.90484354907844e-05,
      "loss": 0.4614,
      "step": 3330
    },
    {
      "epoch": 0.7158165452207458,
      "grad_norm": 0.2745624780654907,
      "learning_rate": 1.9045577939705673e-05,
      "loss": 0.5705,
      "step": 3340
    },
    {
      "epoch": 0.71795970852979,
      "grad_norm": 0.0645953044295311,
      "learning_rate": 1.9042720388626947e-05,
      "loss": 0.0085,
      "step": 3350
    },
    {
      "epoch": 0.7201028718388341,
      "grad_norm": 0.050818510353565216,
      "learning_rate": 1.903986283754822e-05,
      "loss": 0.3803,
      "step": 3360
    },
    {
      "epoch": 0.7222460351478782,
      "grad_norm": 0.036797747015953064,
      "learning_rate": 1.9037005286469495e-05,
      "loss": 0.5829,
      "step": 3370
    },
    {
      "epoch": 0.7243891984569224,
      "grad_norm": 21.01807975769043,
      "learning_rate": 1.9034147735390772e-05,
      "loss": 0.227,
      "step": 3380
    },
    {
      "epoch": 0.7265323617659666,
      "grad_norm": 0.08503656834363937,
      "learning_rate": 1.9031290184312046e-05,
      "loss": 0.2345,
      "step": 3390
    },
    {
      "epoch": 0.7286755250750108,
      "grad_norm": 0.147171288728714,
      "learning_rate": 1.902843263323332e-05,
      "loss": 0.5699,
      "step": 3400
    },
    {
      "epoch": 0.7308186883840548,
      "grad_norm": 0.20532390475273132,
      "learning_rate": 1.9025575082154594e-05,
      "loss": 0.9565,
      "step": 3410
    },
    {
      "epoch": 0.732961851693099,
      "grad_norm": 32.62602996826172,
      "learning_rate": 1.9022717531075868e-05,
      "loss": 0.5266,
      "step": 3420
    },
    {
      "epoch": 0.7351050150021432,
      "grad_norm": 0.07117320597171783,
      "learning_rate": 1.9019859979997145e-05,
      "loss": 0.3003,
      "step": 3430
    },
    {
      "epoch": 0.7372481783111873,
      "grad_norm": 0.22193461656570435,
      "learning_rate": 1.901700242891842e-05,
      "loss": 0.5273,
      "step": 3440
    },
    {
      "epoch": 0.7393913416202315,
      "grad_norm": 21.720619201660156,
      "learning_rate": 1.9014144877839693e-05,
      "loss": 0.4719,
      "step": 3450
    },
    {
      "epoch": 0.7415345049292756,
      "grad_norm": 24.338451385498047,
      "learning_rate": 1.9011287326760967e-05,
      "loss": 0.9405,
      "step": 3460
    },
    {
      "epoch": 0.7436776682383197,
      "grad_norm": 0.8834787607192993,
      "learning_rate": 1.900842977568224e-05,
      "loss": 0.3836,
      "step": 3470
    },
    {
      "epoch": 0.7458208315473639,
      "grad_norm": 31.40268898010254,
      "learning_rate": 1.900557222460352e-05,
      "loss": 0.3657,
      "step": 3480
    },
    {
      "epoch": 0.7479639948564081,
      "grad_norm": 20.30143928527832,
      "learning_rate": 1.9002714673524792e-05,
      "loss": 0.8258,
      "step": 3490
    },
    {
      "epoch": 0.7501071581654523,
      "grad_norm": 8.642892837524414,
      "learning_rate": 1.8999857122446066e-05,
      "loss": 0.5916,
      "step": 3500
    },
    {
      "epoch": 0.7522503214744963,
      "grad_norm": 0.23410861194133759,
      "learning_rate": 1.899699957136734e-05,
      "loss": 0.4531,
      "step": 3510
    },
    {
      "epoch": 0.7543934847835405,
      "grad_norm": 22.73532485961914,
      "learning_rate": 1.8994142020288614e-05,
      "loss": 0.9656,
      "step": 3520
    },
    {
      "epoch": 0.7565366480925847,
      "grad_norm": 30.104496002197266,
      "learning_rate": 1.8991284469209888e-05,
      "loss": 0.5525,
      "step": 3530
    },
    {
      "epoch": 0.7586798114016288,
      "grad_norm": 25.263893127441406,
      "learning_rate": 1.8988426918131165e-05,
      "loss": 0.5599,
      "step": 3540
    },
    {
      "epoch": 0.760822974710673,
      "grad_norm": 0.47038403153419495,
      "learning_rate": 1.8985569367052436e-05,
      "loss": 0.5277,
      "step": 3550
    },
    {
      "epoch": 0.7629661380197171,
      "grad_norm": 40.23586654663086,
      "learning_rate": 1.898271181597371e-05,
      "loss": 0.1355,
      "step": 3560
    },
    {
      "epoch": 0.7651093013287612,
      "grad_norm": 31.63641929626465,
      "learning_rate": 1.8979854264894987e-05,
      "loss": 0.7806,
      "step": 3570
    },
    {
      "epoch": 0.7672524646378054,
      "grad_norm": 0.2187901884317398,
      "learning_rate": 1.897699671381626e-05,
      "loss": 0.5844,
      "step": 3580
    },
    {
      "epoch": 0.7693956279468496,
      "grad_norm": 29.974544525146484,
      "learning_rate": 1.8974139162737535e-05,
      "loss": 1.0406,
      "step": 3590
    },
    {
      "epoch": 0.7715387912558938,
      "grad_norm": 0.28445881605148315,
      "learning_rate": 1.897128161165881e-05,
      "loss": 0.1411,
      "step": 3600
    },
    {
      "epoch": 0.7736819545649378,
      "grad_norm": 0.25729528069496155,
      "learning_rate": 1.8968424060580083e-05,
      "loss": 1.0224,
      "step": 3610
    },
    {
      "epoch": 0.775825117873982,
      "grad_norm": 0.823053240776062,
      "learning_rate": 1.896556650950136e-05,
      "loss": 0.372,
      "step": 3620
    },
    {
      "epoch": 0.7779682811830262,
      "grad_norm": 43.634971618652344,
      "learning_rate": 1.8962708958422634e-05,
      "loss": 1.0833,
      "step": 3630
    },
    {
      "epoch": 0.7801114444920703,
      "grad_norm": 25.047138214111328,
      "learning_rate": 1.8959851407343908e-05,
      "loss": 0.7452,
      "step": 3640
    },
    {
      "epoch": 0.7822546078011144,
      "grad_norm": 0.4567277133464813,
      "learning_rate": 1.8956993856265182e-05,
      "loss": 0.1678,
      "step": 3650
    },
    {
      "epoch": 0.7843977711101586,
      "grad_norm": 30.98403549194336,
      "learning_rate": 1.8954136305186456e-05,
      "loss": 0.4808,
      "step": 3660
    },
    {
      "epoch": 0.7865409344192027,
      "grad_norm": 48.49364471435547,
      "learning_rate": 1.895127875410773e-05,
      "loss": 0.3363,
      "step": 3670
    },
    {
      "epoch": 0.7886840977282469,
      "grad_norm": 0.031518302857875824,
      "learning_rate": 1.8948421203029007e-05,
      "loss": 0.7117,
      "step": 3680
    },
    {
      "epoch": 0.7908272610372911,
      "grad_norm": 0.06454458832740784,
      "learning_rate": 1.894556365195028e-05,
      "loss": 0.5579,
      "step": 3690
    },
    {
      "epoch": 0.7929704243463352,
      "grad_norm": 23.820491790771484,
      "learning_rate": 1.8942706100871555e-05,
      "loss": 0.3238,
      "step": 3700
    },
    {
      "epoch": 0.7951135876553793,
      "grad_norm": 378.9187927246094,
      "learning_rate": 1.893984854979283e-05,
      "loss": 0.5036,
      "step": 3710
    },
    {
      "epoch": 0.7972567509644235,
      "grad_norm": 0.661724865436554,
      "learning_rate": 1.8936990998714103e-05,
      "loss": 1.0095,
      "step": 3720
    },
    {
      "epoch": 0.7993999142734677,
      "grad_norm": 0.8953499794006348,
      "learning_rate": 1.893413344763538e-05,
      "loss": 0.8478,
      "step": 3730
    },
    {
      "epoch": 0.8015430775825118,
      "grad_norm": 0.0658646821975708,
      "learning_rate": 1.8931275896556654e-05,
      "loss": 0.5106,
      "step": 3740
    },
    {
      "epoch": 0.8036862408915559,
      "grad_norm": 0.22989122569561005,
      "learning_rate": 1.8928418345477928e-05,
      "loss": 0.7957,
      "step": 3750
    },
    {
      "epoch": 0.8058294042006001,
      "grad_norm": 0.3053760826587677,
      "learning_rate": 1.8925560794399202e-05,
      "loss": 0.5532,
      "step": 3760
    },
    {
      "epoch": 0.8079725675096442,
      "grad_norm": 35.63039016723633,
      "learning_rate": 1.8922703243320476e-05,
      "loss": 0.453,
      "step": 3770
    },
    {
      "epoch": 0.8101157308186884,
      "grad_norm": 48.50564193725586,
      "learning_rate": 1.891984569224175e-05,
      "loss": 0.546,
      "step": 3780
    },
    {
      "epoch": 0.8122588941277326,
      "grad_norm": 1.7447307109832764,
      "learning_rate": 1.8916988141163024e-05,
      "loss": 0.4342,
      "step": 3790
    },
    {
      "epoch": 0.8144020574367766,
      "grad_norm": 37.81068801879883,
      "learning_rate": 1.8914130590084298e-05,
      "loss": 0.5552,
      "step": 3800
    },
    {
      "epoch": 0.8165452207458208,
      "grad_norm": 59.90213394165039,
      "learning_rate": 1.891127303900557e-05,
      "loss": 0.8311,
      "step": 3810
    },
    {
      "epoch": 0.818688384054865,
      "grad_norm": 27.351322174072266,
      "learning_rate": 1.890841548792685e-05,
      "loss": 0.6289,
      "step": 3820
    },
    {
      "epoch": 0.8208315473639092,
      "grad_norm": 2.1381616592407227,
      "learning_rate": 1.8905557936848123e-05,
      "loss": 1.012,
      "step": 3830
    },
    {
      "epoch": 0.8229747106729532,
      "grad_norm": 3.0208334922790527,
      "learning_rate": 1.8902700385769397e-05,
      "loss": 0.7845,
      "step": 3840
    },
    {
      "epoch": 0.8251178739819974,
      "grad_norm": 1.2776856422424316,
      "learning_rate": 1.889984283469067e-05,
      "loss": 0.4705,
      "step": 3850
    },
    {
      "epoch": 0.8272610372910416,
      "grad_norm": 0.22290067374706268,
      "learning_rate": 1.8896985283611945e-05,
      "loss": 0.3374,
      "step": 3860
    },
    {
      "epoch": 0.8294042006000857,
      "grad_norm": 0.04643288999795914,
      "learning_rate": 1.8894127732533222e-05,
      "loss": 0.908,
      "step": 3870
    },
    {
      "epoch": 0.8315473639091299,
      "grad_norm": 0.44772276282310486,
      "learning_rate": 1.8891270181454496e-05,
      "loss": 0.4728,
      "step": 3880
    },
    {
      "epoch": 0.833690527218174,
      "grad_norm": 5.282212257385254,
      "learning_rate": 1.888841263037577e-05,
      "loss": 0.8407,
      "step": 3890
    },
    {
      "epoch": 0.8358336905272181,
      "grad_norm": 20.64862060546875,
      "learning_rate": 1.8885555079297044e-05,
      "loss": 0.8969,
      "step": 3900
    },
    {
      "epoch": 0.8379768538362623,
      "grad_norm": 1.1582717895507812,
      "learning_rate": 1.8882697528218318e-05,
      "loss": 0.6296,
      "step": 3910
    },
    {
      "epoch": 0.8401200171453065,
      "grad_norm": 1.5815824270248413,
      "learning_rate": 1.8879839977139595e-05,
      "loss": 0.4492,
      "step": 3920
    },
    {
      "epoch": 0.8422631804543507,
      "grad_norm": 0.5052764415740967,
      "learning_rate": 1.887698242606087e-05,
      "loss": 0.3122,
      "step": 3930
    },
    {
      "epoch": 0.8444063437633947,
      "grad_norm": 0.19603341817855835,
      "learning_rate": 1.8874124874982143e-05,
      "loss": 0.2676,
      "step": 3940
    },
    {
      "epoch": 0.8465495070724389,
      "grad_norm": 26.63072967529297,
      "learning_rate": 1.8871267323903417e-05,
      "loss": 0.3779,
      "step": 3950
    },
    {
      "epoch": 0.8486926703814831,
      "grad_norm": 26.95232391357422,
      "learning_rate": 1.886840977282469e-05,
      "loss": 0.6462,
      "step": 3960
    },
    {
      "epoch": 0.8508358336905272,
      "grad_norm": 33.47225570678711,
      "learning_rate": 1.8865552221745968e-05,
      "loss": 1.327,
      "step": 3970
    },
    {
      "epoch": 0.8529789969995714,
      "grad_norm": 15.606114387512207,
      "learning_rate": 1.886269467066724e-05,
      "loss": 0.4772,
      "step": 3980
    },
    {
      "epoch": 0.8551221603086155,
      "grad_norm": 22.869829177856445,
      "learning_rate": 1.8859837119588512e-05,
      "loss": 0.3791,
      "step": 3990
    },
    {
      "epoch": 0.8572653236176596,
      "grad_norm": 42.018001556396484,
      "learning_rate": 1.8856979568509786e-05,
      "loss": 0.5932,
      "step": 4000
    },
    {
      "epoch": 0.8594084869267038,
      "grad_norm": 17.35334587097168,
      "learning_rate": 1.8854122017431064e-05,
      "loss": 0.8835,
      "step": 4010
    },
    {
      "epoch": 0.861551650235748,
      "grad_norm": 98.9333267211914,
      "learning_rate": 1.8851264466352338e-05,
      "loss": 0.3442,
      "step": 4020
    },
    {
      "epoch": 0.8636948135447922,
      "grad_norm": 0.33425456285476685,
      "learning_rate": 1.884840691527361e-05,
      "loss": 0.1177,
      "step": 4030
    },
    {
      "epoch": 0.8658379768538362,
      "grad_norm": 19.74440574645996,
      "learning_rate": 1.8845549364194885e-05,
      "loss": 0.7649,
      "step": 4040
    },
    {
      "epoch": 0.8679811401628804,
      "grad_norm": 0.2742801606655121,
      "learning_rate": 1.884269181311616e-05,
      "loss": 0.3753,
      "step": 4050
    },
    {
      "epoch": 0.8701243034719246,
      "grad_norm": 24.403911590576172,
      "learning_rate": 1.8839834262037437e-05,
      "loss": 0.3998,
      "step": 4060
    },
    {
      "epoch": 0.8722674667809687,
      "grad_norm": 0.7451355457305908,
      "learning_rate": 1.883697671095871e-05,
      "loss": 0.4109,
      "step": 4070
    },
    {
      "epoch": 0.8744106300900129,
      "grad_norm": 27.163755416870117,
      "learning_rate": 1.8834119159879985e-05,
      "loss": 0.7676,
      "step": 4080
    },
    {
      "epoch": 0.876553793399057,
      "grad_norm": 19.2405948638916,
      "learning_rate": 1.883126160880126e-05,
      "loss": 0.5945,
      "step": 4090
    },
    {
      "epoch": 0.8786969567081011,
      "grad_norm": 0.720952033996582,
      "learning_rate": 1.8828404057722532e-05,
      "loss": 0.4641,
      "step": 4100
    },
    {
      "epoch": 0.8808401200171453,
      "grad_norm": 27.903615951538086,
      "learning_rate": 1.882554650664381e-05,
      "loss": 0.3958,
      "step": 4110
    },
    {
      "epoch": 0.8829832833261895,
      "grad_norm": 27.51523208618164,
      "learning_rate": 1.8822688955565084e-05,
      "loss": 0.3739,
      "step": 4120
    },
    {
      "epoch": 0.8851264466352337,
      "grad_norm": 49.356048583984375,
      "learning_rate": 1.8819831404486358e-05,
      "loss": 0.9645,
      "step": 4130
    },
    {
      "epoch": 0.8872696099442777,
      "grad_norm": 0.0887574702501297,
      "learning_rate": 1.881697385340763e-05,
      "loss": 0.3302,
      "step": 4140
    },
    {
      "epoch": 0.8894127732533219,
      "grad_norm": 0.10191767662763596,
      "learning_rate": 1.8814116302328905e-05,
      "loss": 0.4528,
      "step": 4150
    },
    {
      "epoch": 0.8915559365623661,
      "grad_norm": 3.3433837890625,
      "learning_rate": 1.881125875125018e-05,
      "loss": 0.9263,
      "step": 4160
    },
    {
      "epoch": 0.8936990998714102,
      "grad_norm": 1.75273597240448,
      "learning_rate": 1.8808401200171457e-05,
      "loss": 0.4043,
      "step": 4170
    },
    {
      "epoch": 0.8958422631804543,
      "grad_norm": 21.216543197631836,
      "learning_rate": 1.880554364909273e-05,
      "loss": 0.4433,
      "step": 4180
    },
    {
      "epoch": 0.8979854264894985,
      "grad_norm": 29.595802307128906,
      "learning_rate": 1.8802686098014e-05,
      "loss": 0.3438,
      "step": 4190
    },
    {
      "epoch": 0.9001285897985426,
      "grad_norm": 0.8068084716796875,
      "learning_rate": 1.879982854693528e-05,
      "loss": 1.0653,
      "step": 4200
    },
    {
      "epoch": 0.9022717531075868,
      "grad_norm": 1.4687920808792114,
      "learning_rate": 1.8796970995856552e-05,
      "loss": 0.2576,
      "step": 4210
    },
    {
      "epoch": 0.904414916416631,
      "grad_norm": 0.6636670231819153,
      "learning_rate": 1.8794113444777826e-05,
      "loss": 0.3738,
      "step": 4220
    },
    {
      "epoch": 0.9065580797256751,
      "grad_norm": 0.0728723481297493,
      "learning_rate": 1.87912558936991e-05,
      "loss": 0.7482,
      "step": 4230
    },
    {
      "epoch": 0.9087012430347192,
      "grad_norm": 0.29985928535461426,
      "learning_rate": 1.8788398342620374e-05,
      "loss": 0.2506,
      "step": 4240
    },
    {
      "epoch": 0.9108444063437634,
      "grad_norm": 0.3604515790939331,
      "learning_rate": 1.878554079154165e-05,
      "loss": 0.5808,
      "step": 4250
    },
    {
      "epoch": 0.9129875696528076,
      "grad_norm": 0.10870642960071564,
      "learning_rate": 1.8782683240462925e-05,
      "loss": 0.5178,
      "step": 4260
    },
    {
      "epoch": 0.9151307329618517,
      "grad_norm": 1.1074007749557495,
      "learning_rate": 1.87798256893842e-05,
      "loss": 1.1903,
      "step": 4270
    },
    {
      "epoch": 0.9172738962708958,
      "grad_norm": 25.107269287109375,
      "learning_rate": 1.8776968138305473e-05,
      "loss": 0.1795,
      "step": 4280
    },
    {
      "epoch": 0.91941705957994,
      "grad_norm": 0.3322417736053467,
      "learning_rate": 1.8774110587226747e-05,
      "loss": 0.8201,
      "step": 4290
    },
    {
      "epoch": 0.9215602228889841,
      "grad_norm": 0.2898672819137573,
      "learning_rate": 1.877125303614802e-05,
      "loss": 0.7834,
      "step": 4300
    },
    {
      "epoch": 0.9237033861980283,
      "grad_norm": 22.673934936523438,
      "learning_rate": 1.87683954850693e-05,
      "loss": 0.5316,
      "step": 4310
    },
    {
      "epoch": 0.9258465495070725,
      "grad_norm": 51.998130798339844,
      "learning_rate": 1.8765537933990572e-05,
      "loss": 0.6094,
      "step": 4320
    },
    {
      "epoch": 0.9279897128161166,
      "grad_norm": 0.6944270133972168,
      "learning_rate": 1.8762680382911846e-05,
      "loss": 0.5997,
      "step": 4330
    },
    {
      "epoch": 0.9301328761251607,
      "grad_norm": 24.603721618652344,
      "learning_rate": 1.875982283183312e-05,
      "loss": 0.9957,
      "step": 4340
    },
    {
      "epoch": 0.9322760394342049,
      "grad_norm": 38.90739059448242,
      "learning_rate": 1.8756965280754394e-05,
      "loss": 0.625,
      "step": 4350
    },
    {
      "epoch": 0.9344192027432491,
      "grad_norm": 1.484161615371704,
      "learning_rate": 1.875410772967567e-05,
      "loss": 0.4963,
      "step": 4360
    },
    {
      "epoch": 0.9365623660522931,
      "grad_norm": 10.090819358825684,
      "learning_rate": 1.8751250178596945e-05,
      "loss": 0.7572,
      "step": 4370
    },
    {
      "epoch": 0.9387055293613373,
      "grad_norm": 5.004105567932129,
      "learning_rate": 1.874839262751822e-05,
      "loss": 0.2144,
      "step": 4380
    },
    {
      "epoch": 0.9408486926703815,
      "grad_norm": 28.56048011779785,
      "learning_rate": 1.8745535076439493e-05,
      "loss": 0.4416,
      "step": 4390
    },
    {
      "epoch": 0.9429918559794256,
      "grad_norm": 4.023722171783447,
      "learning_rate": 1.8742677525360767e-05,
      "loss": 0.5718,
      "step": 4400
    },
    {
      "epoch": 0.9451350192884698,
      "grad_norm": 0.29872509837150574,
      "learning_rate": 1.873981997428204e-05,
      "loss": 0.5308,
      "step": 4410
    },
    {
      "epoch": 0.947278182597514,
      "grad_norm": 0.4382062256336212,
      "learning_rate": 1.8736962423203315e-05,
      "loss": 0.7574,
      "step": 4420
    },
    {
      "epoch": 0.9494213459065581,
      "grad_norm": 33.80713653564453,
      "learning_rate": 1.873410487212459e-05,
      "loss": 0.4701,
      "step": 4430
    },
    {
      "epoch": 0.9515645092156022,
      "grad_norm": 0.39745399355888367,
      "learning_rate": 1.8731247321045863e-05,
      "loss": 0.698,
      "step": 4440
    },
    {
      "epoch": 0.9537076725246464,
      "grad_norm": 6.717837333679199,
      "learning_rate": 1.872838976996714e-05,
      "loss": 0.3655,
      "step": 4450
    },
    {
      "epoch": 0.9558508358336906,
      "grad_norm": 0.026501378044486046,
      "learning_rate": 1.8725532218888414e-05,
      "loss": 0.403,
      "step": 4460
    },
    {
      "epoch": 0.9579939991427346,
      "grad_norm": 4.526211261749268,
      "learning_rate": 1.8722674667809688e-05,
      "loss": 0.5106,
      "step": 4470
    },
    {
      "epoch": 0.9601371624517788,
      "grad_norm": 1.2705868482589722,
      "learning_rate": 1.8719817116730962e-05,
      "loss": 0.4917,
      "step": 4480
    },
    {
      "epoch": 0.962280325760823,
      "grad_norm": 0.2586347460746765,
      "learning_rate": 1.8716959565652236e-05,
      "loss": 0.3838,
      "step": 4490
    },
    {
      "epoch": 0.9644234890698671,
      "grad_norm": 0.1324198991060257,
      "learning_rate": 1.8714102014573513e-05,
      "loss": 0.3079,
      "step": 4500
    },
    {
      "epoch": 0.9665666523789113,
      "grad_norm": 0.02450805902481079,
      "learning_rate": 1.8711244463494787e-05,
      "loss": 0.5158,
      "step": 4510
    },
    {
      "epoch": 0.9687098156879554,
      "grad_norm": 0.41980069875717163,
      "learning_rate": 1.870838691241606e-05,
      "loss": 0.8521,
      "step": 4520
    },
    {
      "epoch": 0.9708529789969995,
      "grad_norm": 0.06271708011627197,
      "learning_rate": 1.8705529361337335e-05,
      "loss": 0.4812,
      "step": 4530
    },
    {
      "epoch": 0.9729961423060437,
      "grad_norm": 0.2590903341770172,
      "learning_rate": 1.870267181025861e-05,
      "loss": 0.3485,
      "step": 4540
    },
    {
      "epoch": 0.9751393056150879,
      "grad_norm": 0.16437354683876038,
      "learning_rate": 1.8699814259179886e-05,
      "loss": 0.202,
      "step": 4550
    },
    {
      "epoch": 0.9772824689241321,
      "grad_norm": 0.08591943234205246,
      "learning_rate": 1.869695670810116e-05,
      "loss": 0.5375,
      "step": 4560
    },
    {
      "epoch": 0.9794256322331761,
      "grad_norm": 21.924989700317383,
      "learning_rate": 1.8694099157022434e-05,
      "loss": 0.8732,
      "step": 4570
    },
    {
      "epoch": 0.9815687955422203,
      "grad_norm": 0.2581808865070343,
      "learning_rate": 1.8691241605943708e-05,
      "loss": 0.5289,
      "step": 4580
    },
    {
      "epoch": 0.9837119588512645,
      "grad_norm": 2.5606212615966797,
      "learning_rate": 1.8688384054864982e-05,
      "loss": 0.0979,
      "step": 4590
    },
    {
      "epoch": 0.9858551221603086,
      "grad_norm": 32.675994873046875,
      "learning_rate": 1.8685526503786256e-05,
      "loss": 0.7212,
      "step": 4600
    },
    {
      "epoch": 0.9879982854693528,
      "grad_norm": 0.05656290054321289,
      "learning_rate": 1.8682668952707533e-05,
      "loss": 0.3191,
      "step": 4610
    },
    {
      "epoch": 0.9901414487783969,
      "grad_norm": 16.730937957763672,
      "learning_rate": 1.8679811401628804e-05,
      "loss": 0.4622,
      "step": 4620
    },
    {
      "epoch": 0.992284612087441,
      "grad_norm": 0.24029187858104706,
      "learning_rate": 1.8676953850550078e-05,
      "loss": 0.3809,
      "step": 4630
    },
    {
      "epoch": 0.9944277753964852,
      "grad_norm": 28.58456802368164,
      "learning_rate": 1.8674096299471355e-05,
      "loss": 0.2437,
      "step": 4640
    },
    {
      "epoch": 0.9965709387055294,
      "grad_norm": 30.766332626342773,
      "learning_rate": 1.867123874839263e-05,
      "loss": 0.4711,
      "step": 4650
    },
    {
      "epoch": 0.9987141020145736,
      "grad_norm": 23.728267669677734,
      "learning_rate": 1.8668381197313903e-05,
      "loss": 0.9486,
      "step": 4660
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.872,
      "eval_f1": 0.5949367088607596,
      "eval_loss": 0.5344188809394836,
      "eval_precision": 0.7726027397260274,
      "eval_recall": 0.483704974271012,
      "eval_runtime": 108.8163,
      "eval_samples_per_second": 27.569,
      "eval_steps_per_second": 1.149,
      "step": 4666
    },
    {
      "epoch": 1.0008572653236176,
      "grad_norm": 0.2446308732032776,
      "learning_rate": 1.8665523646235177e-05,
      "loss": 0.4299,
      "step": 4670
    },
    {
      "epoch": 1.0030004286326617,
      "grad_norm": 31.368465423583984,
      "learning_rate": 1.866266609515645e-05,
      "loss": 0.4896,
      "step": 4680
    },
    {
      "epoch": 1.005143591941706,
      "grad_norm": 23.574234008789062,
      "learning_rate": 1.8659808544077728e-05,
      "loss": 0.448,
      "step": 4690
    },
    {
      "epoch": 1.00728675525075,
      "grad_norm": 26.259294509887695,
      "learning_rate": 1.8656950992999002e-05,
      "loss": 0.2835,
      "step": 4700
    },
    {
      "epoch": 1.0094299185597944,
      "grad_norm": 0.277037650346756,
      "learning_rate": 1.8654093441920276e-05,
      "loss": 0.4344,
      "step": 4710
    },
    {
      "epoch": 1.0115730818688384,
      "grad_norm": 40.41740798950195,
      "learning_rate": 1.865123589084155e-05,
      "loss": 1.0403,
      "step": 4720
    },
    {
      "epoch": 1.0137162451778825,
      "grad_norm": 0.16495302319526672,
      "learning_rate": 1.8648378339762824e-05,
      "loss": 0.4151,
      "step": 4730
    },
    {
      "epoch": 1.0158594084869268,
      "grad_norm": 7.152659893035889,
      "learning_rate": 1.8645520788684098e-05,
      "loss": 0.2614,
      "step": 4740
    },
    {
      "epoch": 1.0180025717959709,
      "grad_norm": 0.07239782065153122,
      "learning_rate": 1.8642663237605375e-05,
      "loss": 0.3666,
      "step": 4750
    },
    {
      "epoch": 1.020145735105015,
      "grad_norm": 0.3821852207183838,
      "learning_rate": 1.863980568652665e-05,
      "loss": 0.2872,
      "step": 4760
    },
    {
      "epoch": 1.0222888984140592,
      "grad_norm": 51.88194274902344,
      "learning_rate": 1.8636948135447923e-05,
      "loss": 0.847,
      "step": 4770
    },
    {
      "epoch": 1.0244320617231033,
      "grad_norm": 69.9463119506836,
      "learning_rate": 1.8634090584369197e-05,
      "loss": 0.1364,
      "step": 4780
    },
    {
      "epoch": 1.0265752250321474,
      "grad_norm": 0.07388581335544586,
      "learning_rate": 1.863123303329047e-05,
      "loss": 0.0999,
      "step": 4790
    },
    {
      "epoch": 1.0287183883411917,
      "grad_norm": 22.586164474487305,
      "learning_rate": 1.8628375482211748e-05,
      "loss": 1.175,
      "step": 4800
    },
    {
      "epoch": 1.0308615516502357,
      "grad_norm": 22.178449630737305,
      "learning_rate": 1.8625517931133022e-05,
      "loss": 0.3917,
      "step": 4810
    },
    {
      "epoch": 1.0330047149592798,
      "grad_norm": 43.37528991699219,
      "learning_rate": 1.8622660380054296e-05,
      "loss": 0.484,
      "step": 4820
    },
    {
      "epoch": 1.035147878268324,
      "grad_norm": 22.136722564697266,
      "learning_rate": 1.861980282897557e-05,
      "loss": 0.6961,
      "step": 4830
    },
    {
      "epoch": 1.0372910415773682,
      "grad_norm": 25.8615665435791,
      "learning_rate": 1.8616945277896844e-05,
      "loss": 0.191,
      "step": 4840
    },
    {
      "epoch": 1.0394342048864122,
      "grad_norm": 36.80144119262695,
      "learning_rate": 1.8614087726818118e-05,
      "loss": 0.77,
      "step": 4850
    },
    {
      "epoch": 1.0415773681954565,
      "grad_norm": 26.085681915283203,
      "learning_rate": 1.861123017573939e-05,
      "loss": 1.164,
      "step": 4860
    },
    {
      "epoch": 1.0437205315045006,
      "grad_norm": 11.810617446899414,
      "learning_rate": 1.8608372624660666e-05,
      "loss": 0.6314,
      "step": 4870
    },
    {
      "epoch": 1.0458636948135447,
      "grad_norm": 0.5337598919868469,
      "learning_rate": 1.860551507358194e-05,
      "loss": 0.445,
      "step": 4880
    },
    {
      "epoch": 1.048006858122589,
      "grad_norm": 24.802040100097656,
      "learning_rate": 1.8602657522503217e-05,
      "loss": 0.2868,
      "step": 4890
    },
    {
      "epoch": 1.050150021431633,
      "grad_norm": 20.425825119018555,
      "learning_rate": 1.859979997142449e-05,
      "loss": 0.6332,
      "step": 4900
    },
    {
      "epoch": 1.0522931847406773,
      "grad_norm": 0.2567313015460968,
      "learning_rate": 1.8596942420345765e-05,
      "loss": 0.2719,
      "step": 4910
    },
    {
      "epoch": 1.0544363480497214,
      "grad_norm": 3.441765546798706,
      "learning_rate": 1.859408486926704e-05,
      "loss": 0.8268,
      "step": 4920
    },
    {
      "epoch": 1.0565795113587655,
      "grad_norm": 0.18433326482772827,
      "learning_rate": 1.8591227318188313e-05,
      "loss": 0.4522,
      "step": 4930
    },
    {
      "epoch": 1.0587226746678098,
      "grad_norm": 3.394867420196533,
      "learning_rate": 1.858836976710959e-05,
      "loss": 0.3239,
      "step": 4940
    },
    {
      "epoch": 1.0608658379768539,
      "grad_norm": 0.18786625564098358,
      "learning_rate": 1.8585512216030864e-05,
      "loss": 0.0397,
      "step": 4950
    },
    {
      "epoch": 1.063009001285898,
      "grad_norm": 27.736438751220703,
      "learning_rate": 1.8582654664952138e-05,
      "loss": 1.3008,
      "step": 4960
    },
    {
      "epoch": 1.0651521645949422,
      "grad_norm": 1.6899924278259277,
      "learning_rate": 1.857979711387341e-05,
      "loss": 0.2298,
      "step": 4970
    },
    {
      "epoch": 1.0672953279039863,
      "grad_norm": 2.5406458377838135,
      "learning_rate": 1.8576939562794686e-05,
      "loss": 0.8255,
      "step": 4980
    },
    {
      "epoch": 1.0694384912130304,
      "grad_norm": 24.250581741333008,
      "learning_rate": 1.8574082011715963e-05,
      "loss": 0.1945,
      "step": 4990
    },
    {
      "epoch": 1.0715816545220747,
      "grad_norm": 0.3020286560058594,
      "learning_rate": 1.8571224460637237e-05,
      "loss": 0.3746,
      "step": 5000
    },
    {
      "epoch": 1.0737248178311187,
      "grad_norm": 27.108633041381836,
      "learning_rate": 1.856836690955851e-05,
      "loss": 0.5598,
      "step": 5010
    },
    {
      "epoch": 1.0758679811401628,
      "grad_norm": 0.04458155483007431,
      "learning_rate": 1.8565509358479785e-05,
      "loss": 0.0026,
      "step": 5020
    },
    {
      "epoch": 1.078011144449207,
      "grad_norm": 0.04290318489074707,
      "learning_rate": 1.856265180740106e-05,
      "loss": 0.4199,
      "step": 5030
    },
    {
      "epoch": 1.0801543077582512,
      "grad_norm": 0.07117071002721786,
      "learning_rate": 1.8559794256322336e-05,
      "loss": 0.6141,
      "step": 5040
    },
    {
      "epoch": 1.0822974710672952,
      "grad_norm": 0.1167953833937645,
      "learning_rate": 1.8556936705243606e-05,
      "loss": 0.409,
      "step": 5050
    },
    {
      "epoch": 1.0844406343763395,
      "grad_norm": 24.16959571838379,
      "learning_rate": 1.855407915416488e-05,
      "loss": 0.5447,
      "step": 5060
    },
    {
      "epoch": 1.0865837976853836,
      "grad_norm": 24.18718147277832,
      "learning_rate": 1.8551221603086154e-05,
      "loss": 0.6264,
      "step": 5070
    },
    {
      "epoch": 1.0887269609944277,
      "grad_norm": 0.2241789549589157,
      "learning_rate": 1.854836405200743e-05,
      "loss": 0.3008,
      "step": 5080
    },
    {
      "epoch": 1.090870124303472,
      "grad_norm": 0.08790521323680878,
      "learning_rate": 1.8545506500928706e-05,
      "loss": 0.067,
      "step": 5090
    },
    {
      "epoch": 1.093013287612516,
      "grad_norm": 28.137067794799805,
      "learning_rate": 1.854264894984998e-05,
      "loss": 0.5065,
      "step": 5100
    },
    {
      "epoch": 1.0951564509215603,
      "grad_norm": 35.82108688354492,
      "learning_rate": 1.8539791398771253e-05,
      "loss": 0.3696,
      "step": 5110
    },
    {
      "epoch": 1.0972996142306044,
      "grad_norm": 0.1916700005531311,
      "learning_rate": 1.8536933847692527e-05,
      "loss": 0.0132,
      "step": 5120
    },
    {
      "epoch": 1.0994427775396485,
      "grad_norm": 0.018329691141843796,
      "learning_rate": 1.8534076296613805e-05,
      "loss": 0.1387,
      "step": 5130
    },
    {
      "epoch": 1.1015859408486928,
      "grad_norm": 0.04491129145026207,
      "learning_rate": 1.853121874553508e-05,
      "loss": 0.2782,
      "step": 5140
    },
    {
      "epoch": 1.1037291041577368,
      "grad_norm": 0.27821603417396545,
      "learning_rate": 1.8528361194456353e-05,
      "loss": 0.6507,
      "step": 5150
    },
    {
      "epoch": 1.105872267466781,
      "grad_norm": 43.150787353515625,
      "learning_rate": 1.8525503643377626e-05,
      "loss": 0.5571,
      "step": 5160
    },
    {
      "epoch": 1.1080154307758252,
      "grad_norm": 28.995372772216797,
      "learning_rate": 1.85226460922989e-05,
      "loss": 0.5059,
      "step": 5170
    },
    {
      "epoch": 1.1101585940848693,
      "grad_norm": 0.05960650369524956,
      "learning_rate": 1.8519788541220178e-05,
      "loss": 0.2246,
      "step": 5180
    },
    {
      "epoch": 1.1123017573939133,
      "grad_norm": 0.016126278787851334,
      "learning_rate": 1.851693099014145e-05,
      "loss": 0.0736,
      "step": 5190
    },
    {
      "epoch": 1.1144449207029576,
      "grad_norm": 0.004102606326341629,
      "learning_rate": 1.8514073439062726e-05,
      "loss": 0.2393,
      "step": 5200
    },
    {
      "epoch": 1.1165880840120017,
      "grad_norm": 21.860057830810547,
      "learning_rate": 1.8511215887984e-05,
      "loss": 0.9159,
      "step": 5210
    },
    {
      "epoch": 1.1187312473210458,
      "grad_norm": 26.716405868530273,
      "learning_rate": 1.8508358336905273e-05,
      "loss": 0.6942,
      "step": 5220
    },
    {
      "epoch": 1.12087441063009,
      "grad_norm": 26.675491333007812,
      "learning_rate": 1.8505500785826547e-05,
      "loss": 0.7454,
      "step": 5230
    },
    {
      "epoch": 1.1230175739391342,
      "grad_norm": 0.6789336800575256,
      "learning_rate": 1.8502643234747825e-05,
      "loss": 0.7709,
      "step": 5240
    },
    {
      "epoch": 1.1251607372481782,
      "grad_norm": 1.1117092370986938,
      "learning_rate": 1.84997856836691e-05,
      "loss": 0.5502,
      "step": 5250
    },
    {
      "epoch": 1.1273039005572225,
      "grad_norm": 0.3656337559223175,
      "learning_rate": 1.849692813259037e-05,
      "loss": 0.4225,
      "step": 5260
    },
    {
      "epoch": 1.1294470638662666,
      "grad_norm": 28.406709671020508,
      "learning_rate": 1.8494070581511646e-05,
      "loss": 0.6012,
      "step": 5270
    },
    {
      "epoch": 1.1315902271753107,
      "grad_norm": 51.72542953491211,
      "learning_rate": 1.849121303043292e-05,
      "loss": 0.5875,
      "step": 5280
    },
    {
      "epoch": 1.133733390484355,
      "grad_norm": 21.977680206298828,
      "learning_rate": 1.8488355479354194e-05,
      "loss": 0.3854,
      "step": 5290
    },
    {
      "epoch": 1.135876553793399,
      "grad_norm": 0.27207452058792114,
      "learning_rate": 1.8485497928275468e-05,
      "loss": 0.9783,
      "step": 5300
    },
    {
      "epoch": 1.138019717102443,
      "grad_norm": 0.5910869240760803,
      "learning_rate": 1.8482640377196742e-05,
      "loss": 0.7729,
      "step": 5310
    },
    {
      "epoch": 1.1401628804114874,
      "grad_norm": 1.228525996208191,
      "learning_rate": 1.847978282611802e-05,
      "loss": 0.5427,
      "step": 5320
    },
    {
      "epoch": 1.1423060437205315,
      "grad_norm": 1.1616662740707397,
      "learning_rate": 1.8476925275039293e-05,
      "loss": 0.1964,
      "step": 5330
    },
    {
      "epoch": 1.1444492070295755,
      "grad_norm": 19.115915298461914,
      "learning_rate": 1.8474067723960567e-05,
      "loss": 0.4832,
      "step": 5340
    },
    {
      "epoch": 1.1465923703386198,
      "grad_norm": 49.71976089477539,
      "learning_rate": 1.847121017288184e-05,
      "loss": 0.5049,
      "step": 5350
    },
    {
      "epoch": 1.148735533647664,
      "grad_norm": 72.86470031738281,
      "learning_rate": 1.8468352621803115e-05,
      "loss": 0.6053,
      "step": 5360
    },
    {
      "epoch": 1.1508786969567082,
      "grad_norm": 17.649446487426758,
      "learning_rate": 1.846549507072439e-05,
      "loss": 0.4766,
      "step": 5370
    },
    {
      "epoch": 1.1530218602657523,
      "grad_norm": 0.2828604578971863,
      "learning_rate": 1.8462637519645666e-05,
      "loss": 0.3174,
      "step": 5380
    },
    {
      "epoch": 1.1551650235747963,
      "grad_norm": 0.43699827790260315,
      "learning_rate": 1.845977996856694e-05,
      "loss": 0.3832,
      "step": 5390
    },
    {
      "epoch": 1.1573081868838406,
      "grad_norm": 0.0983518585562706,
      "learning_rate": 1.8456922417488214e-05,
      "loss": 0.0808,
      "step": 5400
    },
    {
      "epoch": 1.1594513501928847,
      "grad_norm": 91.65646362304688,
      "learning_rate": 1.8454064866409488e-05,
      "loss": 0.4265,
      "step": 5410
    },
    {
      "epoch": 1.1615945135019288,
      "grad_norm": 0.03302035108208656,
      "learning_rate": 1.8451207315330762e-05,
      "loss": 0.908,
      "step": 5420
    },
    {
      "epoch": 1.163737676810973,
      "grad_norm": 0.1965148001909256,
      "learning_rate": 1.844834976425204e-05,
      "loss": 0.9408,
      "step": 5430
    },
    {
      "epoch": 1.1658808401200171,
      "grad_norm": 15.264323234558105,
      "learning_rate": 1.8445492213173313e-05,
      "loss": 0.1927,
      "step": 5440
    },
    {
      "epoch": 1.1680240034290612,
      "grad_norm": 25.541704177856445,
      "learning_rate": 1.8442634662094587e-05,
      "loss": 0.78,
      "step": 5450
    },
    {
      "epoch": 1.1701671667381055,
      "grad_norm": 36.07308578491211,
      "learning_rate": 1.843977711101586e-05,
      "loss": 0.7228,
      "step": 5460
    },
    {
      "epoch": 1.1723103300471496,
      "grad_norm": 20.9166259765625,
      "learning_rate": 1.8436919559937135e-05,
      "loss": 0.4198,
      "step": 5470
    },
    {
      "epoch": 1.1744534933561936,
      "grad_norm": 0.6408966183662415,
      "learning_rate": 1.843406200885841e-05,
      "loss": 0.5997,
      "step": 5480
    },
    {
      "epoch": 1.176596656665238,
      "grad_norm": 0.13593359291553497,
      "learning_rate": 1.8431204457779683e-05,
      "loss": 0.1507,
      "step": 5490
    },
    {
      "epoch": 1.178739819974282,
      "grad_norm": 0.028688568621873856,
      "learning_rate": 1.8428346906700957e-05,
      "loss": 0.2517,
      "step": 5500
    },
    {
      "epoch": 1.1808829832833263,
      "grad_norm": 31.366479873657227,
      "learning_rate": 1.842548935562223e-05,
      "loss": 0.4736,
      "step": 5510
    },
    {
      "epoch": 1.1830261465923704,
      "grad_norm": 0.050821758806705475,
      "learning_rate": 1.8422631804543508e-05,
      "loss": 0.4609,
      "step": 5520
    },
    {
      "epoch": 1.1851693099014144,
      "grad_norm": 18.887401580810547,
      "learning_rate": 1.8419774253464782e-05,
      "loss": 0.5594,
      "step": 5530
    },
    {
      "epoch": 1.1873124732104587,
      "grad_norm": 0.2589872181415558,
      "learning_rate": 1.8416916702386056e-05,
      "loss": 0.3975,
      "step": 5540
    },
    {
      "epoch": 1.1894556365195028,
      "grad_norm": 0.10152480006217957,
      "learning_rate": 1.841405915130733e-05,
      "loss": 0.4193,
      "step": 5550
    },
    {
      "epoch": 1.1915987998285469,
      "grad_norm": 0.10505221039056778,
      "learning_rate": 1.8411201600228604e-05,
      "loss": 0.1613,
      "step": 5560
    },
    {
      "epoch": 1.1937419631375912,
      "grad_norm": 46.58283233642578,
      "learning_rate": 1.840834404914988e-05,
      "loss": 0.7398,
      "step": 5570
    },
    {
      "epoch": 1.1958851264466352,
      "grad_norm": 30.604339599609375,
      "learning_rate": 1.8405486498071155e-05,
      "loss": 0.5717,
      "step": 5580
    },
    {
      "epoch": 1.1980282897556793,
      "grad_norm": 0.13223718106746674,
      "learning_rate": 1.840262894699243e-05,
      "loss": 0.0033,
      "step": 5590
    },
    {
      "epoch": 1.2001714530647236,
      "grad_norm": 0.0953991636633873,
      "learning_rate": 1.8399771395913703e-05,
      "loss": 0.1174,
      "step": 5600
    },
    {
      "epoch": 1.2023146163737677,
      "grad_norm": 0.04534046724438667,
      "learning_rate": 1.8396913844834977e-05,
      "loss": 0.4715,
      "step": 5610
    },
    {
      "epoch": 1.2044577796828118,
      "grad_norm": 0.015203782357275486,
      "learning_rate": 1.8394056293756254e-05,
      "loss": 0.2959,
      "step": 5620
    },
    {
      "epoch": 1.206600942991856,
      "grad_norm": 0.015057587064802647,
      "learning_rate": 1.8391198742677528e-05,
      "loss": 0.2244,
      "step": 5630
    },
    {
      "epoch": 1.2087441063009001,
      "grad_norm": 0.09972899407148361,
      "learning_rate": 1.8388341191598802e-05,
      "loss": 0.3526,
      "step": 5640
    },
    {
      "epoch": 1.2108872696099442,
      "grad_norm": 28.117551803588867,
      "learning_rate": 1.8385483640520076e-05,
      "loss": 0.6389,
      "step": 5650
    },
    {
      "epoch": 1.2130304329189885,
      "grad_norm": 30.898109436035156,
      "learning_rate": 1.838262608944135e-05,
      "loss": 0.8021,
      "step": 5660
    },
    {
      "epoch": 1.2151735962280326,
      "grad_norm": 0.6246823072433472,
      "learning_rate": 1.8379768538362627e-05,
      "loss": 0.1949,
      "step": 5670
    },
    {
      "epoch": 1.2173167595370766,
      "grad_norm": 1.574297308921814,
      "learning_rate": 1.83769109872839e-05,
      "loss": 0.6245,
      "step": 5680
    },
    {
      "epoch": 1.219459922846121,
      "grad_norm": 0.30058202147483826,
      "learning_rate": 1.8374053436205172e-05,
      "loss": 0.4372,
      "step": 5690
    },
    {
      "epoch": 1.221603086155165,
      "grad_norm": 0.016091346740722656,
      "learning_rate": 1.8371195885126446e-05,
      "loss": 0.1778,
      "step": 5700
    },
    {
      "epoch": 1.223746249464209,
      "grad_norm": 0.018053574487566948,
      "learning_rate": 1.8368338334047723e-05,
      "loss": 0.6425,
      "step": 5710
    },
    {
      "epoch": 1.2258894127732534,
      "grad_norm": 0.02849482372403145,
      "learning_rate": 1.8365480782968997e-05,
      "loss": 0.2501,
      "step": 5720
    },
    {
      "epoch": 1.2280325760822974,
      "grad_norm": 0.060546163469552994,
      "learning_rate": 1.836262323189027e-05,
      "loss": 0.4422,
      "step": 5730
    },
    {
      "epoch": 1.2301757393913415,
      "grad_norm": 0.5154125690460205,
      "learning_rate": 1.8359765680811545e-05,
      "loss": 0.5685,
      "step": 5740
    },
    {
      "epoch": 1.2323189027003858,
      "grad_norm": 0.25033894181251526,
      "learning_rate": 1.835690812973282e-05,
      "loss": 0.4007,
      "step": 5750
    },
    {
      "epoch": 1.2344620660094299,
      "grad_norm": 0.08399778604507446,
      "learning_rate": 1.8354050578654096e-05,
      "loss": 0.3627,
      "step": 5760
    },
    {
      "epoch": 1.2366052293184742,
      "grad_norm": 0.11278727650642395,
      "learning_rate": 1.835119302757537e-05,
      "loss": 0.1716,
      "step": 5770
    },
    {
      "epoch": 1.2387483926275182,
      "grad_norm": 0.37904053926467896,
      "learning_rate": 1.8348335476496644e-05,
      "loss": 0.932,
      "step": 5780
    },
    {
      "epoch": 1.2408915559365623,
      "grad_norm": 0.9615721106529236,
      "learning_rate": 1.8345477925417918e-05,
      "loss": 0.9162,
      "step": 5790
    },
    {
      "epoch": 1.2430347192456066,
      "grad_norm": 0.1572912633419037,
      "learning_rate": 1.8342620374339192e-05,
      "loss": 0.1556,
      "step": 5800
    },
    {
      "epoch": 1.2451778825546507,
      "grad_norm": 28.14308738708496,
      "learning_rate": 1.833976282326047e-05,
      "loss": 0.4395,
      "step": 5810
    },
    {
      "epoch": 1.2473210458636947,
      "grad_norm": 49.443294525146484,
      "learning_rate": 1.8336905272181743e-05,
      "loss": 0.4443,
      "step": 5820
    },
    {
      "epoch": 1.249464209172739,
      "grad_norm": 0.06363394111394882,
      "learning_rate": 1.8334047721103017e-05,
      "loss": 0.647,
      "step": 5830
    },
    {
      "epoch": 1.251607372481783,
      "grad_norm": 1.539304256439209,
      "learning_rate": 1.833119017002429e-05,
      "loss": 0.6014,
      "step": 5840
    },
    {
      "epoch": 1.2537505357908272,
      "grad_norm": 9.742762565612793,
      "learning_rate": 1.8328332618945565e-05,
      "loss": 0.0251,
      "step": 5850
    },
    {
      "epoch": 1.2558936990998715,
      "grad_norm": 0.6316414475440979,
      "learning_rate": 1.832547506786684e-05,
      "loss": 0.1378,
      "step": 5860
    },
    {
      "epoch": 1.2580368624089155,
      "grad_norm": 0.29662638902664185,
      "learning_rate": 1.8322617516788116e-05,
      "loss": 0.1954,
      "step": 5870
    },
    {
      "epoch": 1.2601800257179598,
      "grad_norm": 0.029800141230225563,
      "learning_rate": 1.831975996570939e-05,
      "loss": 0.6054,
      "step": 5880
    },
    {
      "epoch": 1.262323189027004,
      "grad_norm": 27.509063720703125,
      "learning_rate": 1.8316902414630664e-05,
      "loss": 0.5143,
      "step": 5890
    },
    {
      "epoch": 1.264466352336048,
      "grad_norm": 23.000244140625,
      "learning_rate": 1.8314044863551938e-05,
      "loss": 0.3204,
      "step": 5900
    },
    {
      "epoch": 1.2666095156450923,
      "grad_norm": 0.022037334740161896,
      "learning_rate": 1.8311187312473212e-05,
      "loss": 0.211,
      "step": 5910
    },
    {
      "epoch": 1.2687526789541363,
      "grad_norm": 0.03931534290313721,
      "learning_rate": 1.8308329761394486e-05,
      "loss": 0.382,
      "step": 5920
    },
    {
      "epoch": 1.2708958422631804,
      "grad_norm": 1.3531986474990845,
      "learning_rate": 1.830547221031576e-05,
      "loss": 0.3404,
      "step": 5930
    },
    {
      "epoch": 1.2730390055722247,
      "grad_norm": 1.8054693937301636,
      "learning_rate": 1.8302614659237034e-05,
      "loss": 0.4454,
      "step": 5940
    },
    {
      "epoch": 1.2751821688812688,
      "grad_norm": 0.03957359865307808,
      "learning_rate": 1.829975710815831e-05,
      "loss": 0.6093,
      "step": 5950
    },
    {
      "epoch": 1.2773253321903129,
      "grad_norm": 0.29364413022994995,
      "learning_rate": 1.8296899557079585e-05,
      "loss": 1.3246,
      "step": 5960
    },
    {
      "epoch": 1.2794684954993572,
      "grad_norm": 1.0328344106674194,
      "learning_rate": 1.829404200600086e-05,
      "loss": 0.4055,
      "step": 5970
    },
    {
      "epoch": 1.2816116588084012,
      "grad_norm": 0.4023391306400299,
      "learning_rate": 1.8291184454922133e-05,
      "loss": 0.2464,
      "step": 5980
    },
    {
      "epoch": 1.2837548221174453,
      "grad_norm": 0.25738146901130676,
      "learning_rate": 1.8288326903843407e-05,
      "loss": 0.5297,
      "step": 5990
    },
    {
      "epoch": 1.2858979854264896,
      "grad_norm": 0.39233583211898804,
      "learning_rate": 1.828546935276468e-05,
      "loss": 0.8604,
      "step": 6000
    },
    {
      "epoch": 1.2880411487355337,
      "grad_norm": 0.10722590982913971,
      "learning_rate": 1.8282611801685958e-05,
      "loss": 0.6273,
      "step": 6010
    },
    {
      "epoch": 1.2901843120445777,
      "grad_norm": 0.1258668452501297,
      "learning_rate": 1.8279754250607232e-05,
      "loss": 0.1635,
      "step": 6020
    },
    {
      "epoch": 1.292327475353622,
      "grad_norm": 0.15377847850322723,
      "learning_rate": 1.8276896699528506e-05,
      "loss": 0.2476,
      "step": 6030
    },
    {
      "epoch": 1.294470638662666,
      "grad_norm": 0.10156162828207016,
      "learning_rate": 1.827403914844978e-05,
      "loss": 0.31,
      "step": 6040
    },
    {
      "epoch": 1.2966138019717102,
      "grad_norm": 1.3319329023361206,
      "learning_rate": 1.8271181597371054e-05,
      "loss": 0.7145,
      "step": 6050
    },
    {
      "epoch": 1.2987569652807545,
      "grad_norm": 0.09649211168289185,
      "learning_rate": 1.826832404629233e-05,
      "loss": 0.3186,
      "step": 6060
    },
    {
      "epoch": 1.3009001285897985,
      "grad_norm": 22.862886428833008,
      "learning_rate": 1.8265466495213605e-05,
      "loss": 0.5712,
      "step": 6070
    },
    {
      "epoch": 1.3030432918988426,
      "grad_norm": 0.0900040864944458,
      "learning_rate": 1.826260894413488e-05,
      "loss": 0.4274,
      "step": 6080
    },
    {
      "epoch": 1.305186455207887,
      "grad_norm": 3.01832914352417,
      "learning_rate": 1.8259751393056153e-05,
      "loss": 0.6693,
      "step": 6090
    },
    {
      "epoch": 1.307329618516931,
      "grad_norm": 14.230270385742188,
      "learning_rate": 1.8256893841977427e-05,
      "loss": 0.4773,
      "step": 6100
    },
    {
      "epoch": 1.309472781825975,
      "grad_norm": 26.975255966186523,
      "learning_rate": 1.8254036290898704e-05,
      "loss": 0.4215,
      "step": 6110
    },
    {
      "epoch": 1.3116159451350193,
      "grad_norm": 0.18693070113658905,
      "learning_rate": 1.8251178739819974e-05,
      "loss": 0.5694,
      "step": 6120
    },
    {
      "epoch": 1.3137591084440634,
      "grad_norm": 24.909631729125977,
      "learning_rate": 1.824832118874125e-05,
      "loss": 0.3676,
      "step": 6130
    },
    {
      "epoch": 1.3159022717531075,
      "grad_norm": 0.2868970036506653,
      "learning_rate": 1.8245463637662522e-05,
      "loss": 0.3544,
      "step": 6140
    },
    {
      "epoch": 1.3180454350621518,
      "grad_norm": 0.554723858833313,
      "learning_rate": 1.82426060865838e-05,
      "loss": 0.3575,
      "step": 6150
    },
    {
      "epoch": 1.3201885983711958,
      "grad_norm": 0.1706472784280777,
      "learning_rate": 1.8239748535505073e-05,
      "loss": 0.403,
      "step": 6160
    },
    {
      "epoch": 1.32233176168024,
      "grad_norm": 0.03338543698191643,
      "learning_rate": 1.8236890984426347e-05,
      "loss": 1.164,
      "step": 6170
    },
    {
      "epoch": 1.3244749249892842,
      "grad_norm": 24.74924087524414,
      "learning_rate": 1.823403343334762e-05,
      "loss": 0.5953,
      "step": 6180
    },
    {
      "epoch": 1.3266180882983283,
      "grad_norm": 0.6818112730979919,
      "learning_rate": 1.8231175882268895e-05,
      "loss": 0.2655,
      "step": 6190
    },
    {
      "epoch": 1.3287612516073724,
      "grad_norm": 57.66432571411133,
      "learning_rate": 1.8228318331190173e-05,
      "loss": 0.6039,
      "step": 6200
    },
    {
      "epoch": 1.3309044149164166,
      "grad_norm": 0.07974690198898315,
      "learning_rate": 1.8225460780111447e-05,
      "loss": 0.5521,
      "step": 6210
    },
    {
      "epoch": 1.3330475782254607,
      "grad_norm": 0.45179200172424316,
      "learning_rate": 1.822260322903272e-05,
      "loss": 0.6569,
      "step": 6220
    },
    {
      "epoch": 1.335190741534505,
      "grad_norm": 25.026748657226562,
      "learning_rate": 1.8219745677953994e-05,
      "loss": 0.8135,
      "step": 6230
    },
    {
      "epoch": 1.337333904843549,
      "grad_norm": 0.12077141553163528,
      "learning_rate": 1.8216888126875268e-05,
      "loss": 0.1799,
      "step": 6240
    },
    {
      "epoch": 1.3394770681525932,
      "grad_norm": 0.593228280544281,
      "learning_rate": 1.8214030575796546e-05,
      "loss": 0.5064,
      "step": 6250
    },
    {
      "epoch": 1.3416202314616374,
      "grad_norm": 0.28451839089393616,
      "learning_rate": 1.821117302471782e-05,
      "loss": 0.3274,
      "step": 6260
    },
    {
      "epoch": 1.3437633947706815,
      "grad_norm": 32.02289581298828,
      "learning_rate": 1.8208315473639093e-05,
      "loss": 0.7317,
      "step": 6270
    },
    {
      "epoch": 1.3459065580797258,
      "grad_norm": 0.11305168271064758,
      "learning_rate": 1.8205457922560367e-05,
      "loss": 0.3817,
      "step": 6280
    },
    {
      "epoch": 1.3480497213887699,
      "grad_norm": 41.79202651977539,
      "learning_rate": 1.820260037148164e-05,
      "loss": 0.5633,
      "step": 6290
    },
    {
      "epoch": 1.350192884697814,
      "grad_norm": 29.140533447265625,
      "learning_rate": 1.8199742820402915e-05,
      "loss": 0.1043,
      "step": 6300
    },
    {
      "epoch": 1.3523360480068582,
      "grad_norm": 71.87467956542969,
      "learning_rate": 1.8196885269324193e-05,
      "loss": 0.4021,
      "step": 6310
    },
    {
      "epoch": 1.3544792113159023,
      "grad_norm": 23.34300422668457,
      "learning_rate": 1.8194027718245467e-05,
      "loss": 0.4156,
      "step": 6320
    },
    {
      "epoch": 1.3566223746249464,
      "grad_norm": 0.2096608430147171,
      "learning_rate": 1.819117016716674e-05,
      "loss": 0.8787,
      "step": 6330
    },
    {
      "epoch": 1.3587655379339907,
      "grad_norm": 24.302549362182617,
      "learning_rate": 1.8188312616088014e-05,
      "loss": 0.4382,
      "step": 6340
    },
    {
      "epoch": 1.3609087012430348,
      "grad_norm": 0.2894163429737091,
      "learning_rate": 1.8185455065009288e-05,
      "loss": 0.6809,
      "step": 6350
    },
    {
      "epoch": 1.3630518645520788,
      "grad_norm": 2.372140645980835,
      "learning_rate": 1.8182597513930562e-05,
      "loss": 0.4039,
      "step": 6360
    },
    {
      "epoch": 1.3651950278611231,
      "grad_norm": 9.196632385253906,
      "learning_rate": 1.8179739962851836e-05,
      "loss": 0.3775,
      "step": 6370
    },
    {
      "epoch": 1.3673381911701672,
      "grad_norm": 8.958240509033203,
      "learning_rate": 1.817688241177311e-05,
      "loss": 0.2514,
      "step": 6380
    },
    {
      "epoch": 1.3694813544792113,
      "grad_norm": 21.109106063842773,
      "learning_rate": 1.8174024860694387e-05,
      "loss": 0.1483,
      "step": 6390
    },
    {
      "epoch": 1.3716245177882556,
      "grad_norm": 0.022519439458847046,
      "learning_rate": 1.817116730961566e-05,
      "loss": 0.25,
      "step": 6400
    },
    {
      "epoch": 1.3737676810972996,
      "grad_norm": 0.07919000834226608,
      "learning_rate": 1.8168309758536935e-05,
      "loss": 0.1498,
      "step": 6410
    },
    {
      "epoch": 1.3759108444063437,
      "grad_norm": 29.58319091796875,
      "learning_rate": 1.816545220745821e-05,
      "loss": 0.8195,
      "step": 6420
    },
    {
      "epoch": 1.378054007715388,
      "grad_norm": 32.433380126953125,
      "learning_rate": 1.8162594656379483e-05,
      "loss": 0.8168,
      "step": 6430
    },
    {
      "epoch": 1.380197171024432,
      "grad_norm": 0.040918175131082535,
      "learning_rate": 1.815973710530076e-05,
      "loss": 0.5139,
      "step": 6440
    },
    {
      "epoch": 1.3823403343334761,
      "grad_norm": 5.693912982940674,
      "learning_rate": 1.8156879554222034e-05,
      "loss": 0.2775,
      "step": 6450
    },
    {
      "epoch": 1.3844834976425204,
      "grad_norm": 50.740474700927734,
      "learning_rate": 1.8154022003143308e-05,
      "loss": 0.1551,
      "step": 6460
    },
    {
      "epoch": 1.3866266609515645,
      "grad_norm": 0.023357102647423744,
      "learning_rate": 1.8151164452064582e-05,
      "loss": 0.0085,
      "step": 6470
    },
    {
      "epoch": 1.3887698242606086,
      "grad_norm": 5.051446914672852,
      "learning_rate": 1.8148306900985856e-05,
      "loss": 0.4148,
      "step": 6480
    },
    {
      "epoch": 1.3909129875696529,
      "grad_norm": 0.07541574537754059,
      "learning_rate": 1.814544934990713e-05,
      "loss": 0.7521,
      "step": 6490
    },
    {
      "epoch": 1.393056150878697,
      "grad_norm": 0.14566071331501007,
      "learning_rate": 1.8142591798828407e-05,
      "loss": 0.1113,
      "step": 6500
    },
    {
      "epoch": 1.395199314187741,
      "grad_norm": 0.15333952009677887,
      "learning_rate": 1.813973424774968e-05,
      "loss": 0.4649,
      "step": 6510
    },
    {
      "epoch": 1.3973424774967853,
      "grad_norm": 0.10380113869905472,
      "learning_rate": 1.8136876696670955e-05,
      "loss": 0.5023,
      "step": 6520
    },
    {
      "epoch": 1.3994856408058294,
      "grad_norm": 36.41020965576172,
      "learning_rate": 1.813401914559223e-05,
      "loss": 0.3936,
      "step": 6530
    },
    {
      "epoch": 1.4016288041148735,
      "grad_norm": 0.41068267822265625,
      "learning_rate": 1.8131161594513503e-05,
      "loss": 0.2259,
      "step": 6540
    },
    {
      "epoch": 1.4037719674239177,
      "grad_norm": 0.12924285233020782,
      "learning_rate": 1.8128304043434777e-05,
      "loss": 0.7056,
      "step": 6550
    },
    {
      "epoch": 1.4059151307329618,
      "grad_norm": 0.1319238543510437,
      "learning_rate": 1.812544649235605e-05,
      "loss": 0.3548,
      "step": 6560
    },
    {
      "epoch": 1.4080582940420059,
      "grad_norm": 41.595638275146484,
      "learning_rate": 1.8122588941277325e-05,
      "loss": 1.0106,
      "step": 6570
    },
    {
      "epoch": 1.4102014573510502,
      "grad_norm": 0.2678796052932739,
      "learning_rate": 1.8119731390198602e-05,
      "loss": 0.442,
      "step": 6580
    },
    {
      "epoch": 1.4123446206600943,
      "grad_norm": 0.8271540403366089,
      "learning_rate": 1.8116873839119876e-05,
      "loss": 0.4192,
      "step": 6590
    },
    {
      "epoch": 1.4144877839691383,
      "grad_norm": 0.13258406519889832,
      "learning_rate": 1.811401628804115e-05,
      "loss": 0.2672,
      "step": 6600
    },
    {
      "epoch": 1.4166309472781826,
      "grad_norm": 0.17765745520591736,
      "learning_rate": 1.8111158736962424e-05,
      "loss": 0.1597,
      "step": 6610
    },
    {
      "epoch": 1.4187741105872267,
      "grad_norm": 37.43954086303711,
      "learning_rate": 1.8108301185883698e-05,
      "loss": 0.9324,
      "step": 6620
    },
    {
      "epoch": 1.4209172738962708,
      "grad_norm": 0.04797022044658661,
      "learning_rate": 1.8105443634804972e-05,
      "loss": 0.2306,
      "step": 6630
    },
    {
      "epoch": 1.423060437205315,
      "grad_norm": 45.11161422729492,
      "learning_rate": 1.810258608372625e-05,
      "loss": 0.692,
      "step": 6640
    },
    {
      "epoch": 1.4252036005143591,
      "grad_norm": 0.16971339285373688,
      "learning_rate": 1.8099728532647523e-05,
      "loss": 0.3225,
      "step": 6650
    },
    {
      "epoch": 1.4273467638234034,
      "grad_norm": 1.47257661819458,
      "learning_rate": 1.8096870981568797e-05,
      "loss": 0.3748,
      "step": 6660
    },
    {
      "epoch": 1.4294899271324475,
      "grad_norm": 0.2616463005542755,
      "learning_rate": 1.809401343049007e-05,
      "loss": 0.2346,
      "step": 6670
    },
    {
      "epoch": 1.4316330904414916,
      "grad_norm": 3.147317886352539,
      "learning_rate": 1.8091155879411345e-05,
      "loss": 0.4324,
      "step": 6680
    },
    {
      "epoch": 1.4337762537505359,
      "grad_norm": 0.11624056845903397,
      "learning_rate": 1.8088298328332622e-05,
      "loss": 0.0024,
      "step": 6690
    },
    {
      "epoch": 1.43591941705958,
      "grad_norm": 0.1103961318731308,
      "learning_rate": 1.8085440777253896e-05,
      "loss": 0.4187,
      "step": 6700
    },
    {
      "epoch": 1.4380625803686242,
      "grad_norm": 28.758251190185547,
      "learning_rate": 1.808258322617517e-05,
      "loss": 0.0793,
      "step": 6710
    },
    {
      "epoch": 1.4402057436776683,
      "grad_norm": 0.08215761929750443,
      "learning_rate": 1.8079725675096444e-05,
      "loss": 0.6504,
      "step": 6720
    },
    {
      "epoch": 1.4423489069867124,
      "grad_norm": 0.32260939478874207,
      "learning_rate": 1.8076868124017718e-05,
      "loss": 0.0441,
      "step": 6730
    },
    {
      "epoch": 1.4444920702957567,
      "grad_norm": 4.098504066467285,
      "learning_rate": 1.8074010572938995e-05,
      "loss": 0.881,
      "step": 6740
    },
    {
      "epoch": 1.4466352336048007,
      "grad_norm": 0.5604361891746521,
      "learning_rate": 1.807115302186027e-05,
      "loss": 0.8501,
      "step": 6750
    },
    {
      "epoch": 1.4487783969138448,
      "grad_norm": 0.06340399384498596,
      "learning_rate": 1.8068295470781543e-05,
      "loss": 0.6079,
      "step": 6760
    },
    {
      "epoch": 1.450921560222889,
      "grad_norm": 0.7534204721450806,
      "learning_rate": 1.8065437919702814e-05,
      "loss": 0.3847,
      "step": 6770
    },
    {
      "epoch": 1.4530647235319332,
      "grad_norm": 0.1328205019235611,
      "learning_rate": 1.806258036862409e-05,
      "loss": 0.1211,
      "step": 6780
    },
    {
      "epoch": 1.4552078868409772,
      "grad_norm": 0.20651878416538239,
      "learning_rate": 1.8059722817545365e-05,
      "loss": 0.6351,
      "step": 6790
    },
    {
      "epoch": 1.4573510501500215,
      "grad_norm": 19.80398178100586,
      "learning_rate": 1.805686526646664e-05,
      "loss": 0.8784,
      "step": 6800
    },
    {
      "epoch": 1.4594942134590656,
      "grad_norm": 26.531482696533203,
      "learning_rate": 1.8054007715387913e-05,
      "loss": 0.8096,
      "step": 6810
    },
    {
      "epoch": 1.4616373767681097,
      "grad_norm": 0.9086167812347412,
      "learning_rate": 1.8051150164309187e-05,
      "loss": 0.5318,
      "step": 6820
    },
    {
      "epoch": 1.463780540077154,
      "grad_norm": 0.2400423139333725,
      "learning_rate": 1.8048292613230464e-05,
      "loss": 0.0859,
      "step": 6830
    },
    {
      "epoch": 1.465923703386198,
      "grad_norm": 0.06695601344108582,
      "learning_rate": 1.8045435062151738e-05,
      "loss": 0.6227,
      "step": 6840
    },
    {
      "epoch": 1.4680668666952421,
      "grad_norm": 1.4146058559417725,
      "learning_rate": 1.8042577511073012e-05,
      "loss": 0.3766,
      "step": 6850
    },
    {
      "epoch": 1.4702100300042864,
      "grad_norm": 18.76508140563965,
      "learning_rate": 1.8039719959994286e-05,
      "loss": 0.7444,
      "step": 6860
    },
    {
      "epoch": 1.4723531933133305,
      "grad_norm": 46.618045806884766,
      "learning_rate": 1.803686240891556e-05,
      "loss": 0.4511,
      "step": 6870
    },
    {
      "epoch": 1.4744963566223745,
      "grad_norm": 3.222893238067627,
      "learning_rate": 1.8034004857836837e-05,
      "loss": 0.1459,
      "step": 6880
    },
    {
      "epoch": 1.4766395199314188,
      "grad_norm": 0.11287570744752884,
      "learning_rate": 1.803114730675811e-05,
      "loss": 0.9163,
      "step": 6890
    },
    {
      "epoch": 1.478782683240463,
      "grad_norm": 0.3997633755207062,
      "learning_rate": 1.8028289755679385e-05,
      "loss": 0.4141,
      "step": 6900
    },
    {
      "epoch": 1.480925846549507,
      "grad_norm": 0.17771686613559723,
      "learning_rate": 1.802543220460066e-05,
      "loss": 0.209,
      "step": 6910
    },
    {
      "epoch": 1.4830690098585513,
      "grad_norm": 33.33601760864258,
      "learning_rate": 1.8022574653521933e-05,
      "loss": 0.448,
      "step": 6920
    },
    {
      "epoch": 1.4852121731675954,
      "grad_norm": 0.1274314820766449,
      "learning_rate": 1.8019717102443207e-05,
      "loss": 0.1742,
      "step": 6930
    },
    {
      "epoch": 1.4873553364766394,
      "grad_norm": 0.4695899784564972,
      "learning_rate": 1.8016859551364484e-05,
      "loss": 0.8958,
      "step": 6940
    },
    {
      "epoch": 1.4894984997856837,
      "grad_norm": 0.2892359495162964,
      "learning_rate": 1.8014002000285758e-05,
      "loss": 0.2771,
      "step": 6950
    },
    {
      "epoch": 1.4916416630947278,
      "grad_norm": 38.25484848022461,
      "learning_rate": 1.8011144449207032e-05,
      "loss": 0.6821,
      "step": 6960
    },
    {
      "epoch": 1.4937848264037719,
      "grad_norm": 0.423574835062027,
      "learning_rate": 1.8008286898128306e-05,
      "loss": 0.5641,
      "step": 6970
    },
    {
      "epoch": 1.4959279897128162,
      "grad_norm": 0.24166466295719147,
      "learning_rate": 1.800542934704958e-05,
      "loss": 0.1733,
      "step": 6980
    },
    {
      "epoch": 1.4980711530218602,
      "grad_norm": 0.07583559304475784,
      "learning_rate": 1.8002571795970854e-05,
      "loss": 0.669,
      "step": 6990
    },
    {
      "epoch": 1.5002143163309043,
      "grad_norm": 27.944965362548828,
      "learning_rate": 1.7999714244892128e-05,
      "loss": 0.5319,
      "step": 7000
    },
    {
      "epoch": 1.5023574796399486,
      "grad_norm": 29.72348403930664,
      "learning_rate": 1.79968566938134e-05,
      "loss": 0.8166,
      "step": 7010
    },
    {
      "epoch": 1.5045006429489927,
      "grad_norm": 1.3988089561462402,
      "learning_rate": 1.799399914273468e-05,
      "loss": 0.3968,
      "step": 7020
    },
    {
      "epoch": 1.5066438062580367,
      "grad_norm": 52.359413146972656,
      "learning_rate": 1.7991141591655953e-05,
      "loss": 0.2468,
      "step": 7030
    },
    {
      "epoch": 1.508786969567081,
      "grad_norm": 26.350393295288086,
      "learning_rate": 1.7988284040577227e-05,
      "loss": 0.5602,
      "step": 7040
    },
    {
      "epoch": 1.5109301328761253,
      "grad_norm": 0.016714228317141533,
      "learning_rate": 1.79854264894985e-05,
      "loss": 0.497,
      "step": 7050
    },
    {
      "epoch": 1.5130732961851692,
      "grad_norm": 0.0305493026971817,
      "learning_rate": 1.7982568938419774e-05,
      "loss": 0.8999,
      "step": 7060
    },
    {
      "epoch": 1.5152164594942135,
      "grad_norm": 38.40140151977539,
      "learning_rate": 1.797971138734105e-05,
      "loss": 0.1876,
      "step": 7070
    },
    {
      "epoch": 1.5173596228032578,
      "grad_norm": 30.586339950561523,
      "learning_rate": 1.7976853836262326e-05,
      "loss": 0.4569,
      "step": 7080
    },
    {
      "epoch": 1.5195027861123016,
      "grad_norm": 39.711952209472656,
      "learning_rate": 1.79739962851836e-05,
      "loss": 0.2985,
      "step": 7090
    },
    {
      "epoch": 1.521645949421346,
      "grad_norm": 3.6481127738952637,
      "learning_rate": 1.7971138734104874e-05,
      "loss": 0.4021,
      "step": 7100
    },
    {
      "epoch": 1.5237891127303902,
      "grad_norm": 0.2716776728630066,
      "learning_rate": 1.7968281183026147e-05,
      "loss": 0.1847,
      "step": 7110
    },
    {
      "epoch": 1.525932276039434,
      "grad_norm": 1.1008782386779785,
      "learning_rate": 1.796542363194742e-05,
      "loss": 0.444,
      "step": 7120
    },
    {
      "epoch": 1.5280754393484783,
      "grad_norm": 0.06771667301654816,
      "learning_rate": 1.79625660808687e-05,
      "loss": 0.3832,
      "step": 7130
    },
    {
      "epoch": 1.5302186026575226,
      "grad_norm": 1.088553786277771,
      "learning_rate": 1.7959708529789973e-05,
      "loss": 0.0166,
      "step": 7140
    },
    {
      "epoch": 1.5323617659665667,
      "grad_norm": 0.026586215943098068,
      "learning_rate": 1.7956850978711247e-05,
      "loss": 0.5611,
      "step": 7150
    },
    {
      "epoch": 1.5345049292756108,
      "grad_norm": 0.09301108121871948,
      "learning_rate": 1.795399342763252e-05,
      "loss": 0.3561,
      "step": 7160
    },
    {
      "epoch": 1.536648092584655,
      "grad_norm": 0.048213254660367966,
      "learning_rate": 1.7951135876553794e-05,
      "loss": 0.2425,
      "step": 7170
    },
    {
      "epoch": 1.5387912558936991,
      "grad_norm": 0.03390786051750183,
      "learning_rate": 1.7948278325475072e-05,
      "loss": 0.0109,
      "step": 7180
    },
    {
      "epoch": 1.5409344192027432,
      "grad_norm": 0.12659528851509094,
      "learning_rate": 1.7945420774396346e-05,
      "loss": 0.0438,
      "step": 7190
    },
    {
      "epoch": 1.5430775825117875,
      "grad_norm": 0.08093947172164917,
      "learning_rate": 1.7942563223317616e-05,
      "loss": 1.1607,
      "step": 7200
    },
    {
      "epoch": 1.5452207458208316,
      "grad_norm": 38.250308990478516,
      "learning_rate": 1.793970567223889e-05,
      "loss": 0.2782,
      "step": 7210
    },
    {
      "epoch": 1.5473639091298756,
      "grad_norm": 0.176497682929039,
      "learning_rate": 1.7936848121160167e-05,
      "loss": 0.5845,
      "step": 7220
    },
    {
      "epoch": 1.54950707243892,
      "grad_norm": 0.14087674021720886,
      "learning_rate": 1.793399057008144e-05,
      "loss": 0.3924,
      "step": 7230
    },
    {
      "epoch": 1.551650235747964,
      "grad_norm": 0.17426151037216187,
      "learning_rate": 1.7931133019002715e-05,
      "loss": 0.5492,
      "step": 7240
    },
    {
      "epoch": 1.553793399057008,
      "grad_norm": 1.9471001625061035,
      "learning_rate": 1.792827546792399e-05,
      "loss": 0.301,
      "step": 7250
    },
    {
      "epoch": 1.5559365623660524,
      "grad_norm": 0.11947306245565414,
      "learning_rate": 1.7925417916845263e-05,
      "loss": 0.1674,
      "step": 7260
    },
    {
      "epoch": 1.5580797256750964,
      "grad_norm": 28.159957885742188,
      "learning_rate": 1.792256036576654e-05,
      "loss": 0.795,
      "step": 7270
    },
    {
      "epoch": 1.5602228889841405,
      "grad_norm": 0.10305767506361008,
      "learning_rate": 1.7919702814687814e-05,
      "loss": 0.2605,
      "step": 7280
    },
    {
      "epoch": 1.5623660522931848,
      "grad_norm": 0.06615063548088074,
      "learning_rate": 1.791684526360909e-05,
      "loss": 1.1444,
      "step": 7290
    },
    {
      "epoch": 1.5645092156022289,
      "grad_norm": 0.13921353220939636,
      "learning_rate": 1.7913987712530362e-05,
      "loss": 1.0953,
      "step": 7300
    },
    {
      "epoch": 1.566652378911273,
      "grad_norm": 0.1697409301996231,
      "learning_rate": 1.7911130161451636e-05,
      "loss": 0.5895,
      "step": 7310
    },
    {
      "epoch": 1.5687955422203173,
      "grad_norm": 0.30712974071502686,
      "learning_rate": 1.7908272610372914e-05,
      "loss": 0.4256,
      "step": 7320
    },
    {
      "epoch": 1.5709387055293613,
      "grad_norm": 52.246646881103516,
      "learning_rate": 1.7905415059294187e-05,
      "loss": 0.3034,
      "step": 7330
    },
    {
      "epoch": 1.5730818688384054,
      "grad_norm": 0.14237378537654877,
      "learning_rate": 1.790255750821546e-05,
      "loss": 0.3783,
      "step": 7340
    },
    {
      "epoch": 1.5752250321474497,
      "grad_norm": 0.23196618258953094,
      "learning_rate": 1.7899699957136735e-05,
      "loss": 0.271,
      "step": 7350
    },
    {
      "epoch": 1.5773681954564938,
      "grad_norm": 0.140803724527359,
      "learning_rate": 1.789684240605801e-05,
      "loss": 0.0022,
      "step": 7360
    },
    {
      "epoch": 1.5795113587655378,
      "grad_norm": 0.0192818995565176,
      "learning_rate": 1.7893984854979287e-05,
      "loss": 0.4888,
      "step": 7370
    },
    {
      "epoch": 1.5816545220745821,
      "grad_norm": 0.029941698536276817,
      "learning_rate": 1.789112730390056e-05,
      "loss": 0.2602,
      "step": 7380
    },
    {
      "epoch": 1.5837976853836262,
      "grad_norm": 41.99081039428711,
      "learning_rate": 1.7888269752821834e-05,
      "loss": 0.2437,
      "step": 7390
    },
    {
      "epoch": 1.5859408486926703,
      "grad_norm": 0.06174188479781151,
      "learning_rate": 1.788541220174311e-05,
      "loss": 0.3347,
      "step": 7400
    },
    {
      "epoch": 1.5880840120017146,
      "grad_norm": 0.07067665457725525,
      "learning_rate": 1.7882554650664382e-05,
      "loss": 0.0927,
      "step": 7410
    },
    {
      "epoch": 1.5902271753107586,
      "grad_norm": 0.20498302578926086,
      "learning_rate": 1.7879697099585656e-05,
      "loss": 0.24,
      "step": 7420
    },
    {
      "epoch": 1.5923703386198027,
      "grad_norm": 23.36908721923828,
      "learning_rate": 1.787683954850693e-05,
      "loss": 0.4566,
      "step": 7430
    },
    {
      "epoch": 1.594513501928847,
      "grad_norm": 37.485164642333984,
      "learning_rate": 1.7873981997428204e-05,
      "loss": 0.7085,
      "step": 7440
    },
    {
      "epoch": 1.5966566652378913,
      "grad_norm": 1.5396615266799927,
      "learning_rate": 1.7871124446349478e-05,
      "loss": 0.2168,
      "step": 7450
    },
    {
      "epoch": 1.5987998285469351,
      "grad_norm": 0.6889036297798157,
      "learning_rate": 1.7868266895270755e-05,
      "loss": 0.2086,
      "step": 7460
    },
    {
      "epoch": 1.6009429918559794,
      "grad_norm": 0.06607256084680557,
      "learning_rate": 1.786540934419203e-05,
      "loss": 0.3834,
      "step": 7470
    },
    {
      "epoch": 1.6030861551650237,
      "grad_norm": 0.13353288173675537,
      "learning_rate": 1.7862551793113303e-05,
      "loss": 0.6832,
      "step": 7480
    },
    {
      "epoch": 1.6052293184740676,
      "grad_norm": 0.22596900165081024,
      "learning_rate": 1.7859694242034577e-05,
      "loss": 0.6602,
      "step": 7490
    },
    {
      "epoch": 1.6073724817831119,
      "grad_norm": 0.3713647723197937,
      "learning_rate": 1.785683669095585e-05,
      "loss": 0.3231,
      "step": 7500
    },
    {
      "epoch": 1.6095156450921562,
      "grad_norm": 0.30841514468193054,
      "learning_rate": 1.785397913987713e-05,
      "loss": 0.6192,
      "step": 7510
    },
    {
      "epoch": 1.6116588084012,
      "grad_norm": 0.10977493971586227,
      "learning_rate": 1.7851121588798402e-05,
      "loss": 0.4366,
      "step": 7520
    },
    {
      "epoch": 1.6138019717102443,
      "grad_norm": 0.6178840398788452,
      "learning_rate": 1.7848264037719676e-05,
      "loss": 0.4661,
      "step": 7530
    },
    {
      "epoch": 1.6159451350192886,
      "grad_norm": 0.2022595852613449,
      "learning_rate": 1.784540648664095e-05,
      "loss": 0.4296,
      "step": 7540
    },
    {
      "epoch": 1.6180882983283325,
      "grad_norm": 56.61478805541992,
      "learning_rate": 1.7842548935562224e-05,
      "loss": 1.0634,
      "step": 7550
    },
    {
      "epoch": 1.6202314616373767,
      "grad_norm": 0.13263513147830963,
      "learning_rate": 1.7839691384483498e-05,
      "loss": 0.4639,
      "step": 7560
    },
    {
      "epoch": 1.622374624946421,
      "grad_norm": 42.614044189453125,
      "learning_rate": 1.7836833833404775e-05,
      "loss": 0.586,
      "step": 7570
    },
    {
      "epoch": 1.6245177882554651,
      "grad_norm": 0.3304024040699005,
      "learning_rate": 1.783397628232605e-05,
      "loss": 0.3051,
      "step": 7580
    },
    {
      "epoch": 1.6266609515645092,
      "grad_norm": 38.49175262451172,
      "learning_rate": 1.7831118731247323e-05,
      "loss": 0.349,
      "step": 7590
    },
    {
      "epoch": 1.6288041148735535,
      "grad_norm": 0.20189633965492249,
      "learning_rate": 1.7828261180168597e-05,
      "loss": 0.5869,
      "step": 7600
    },
    {
      "epoch": 1.6309472781825975,
      "grad_norm": 21.79738998413086,
      "learning_rate": 1.782540362908987e-05,
      "loss": 0.3006,
      "step": 7610
    },
    {
      "epoch": 1.6330904414916416,
      "grad_norm": 0.06916265934705734,
      "learning_rate": 1.782254607801115e-05,
      "loss": 0.0284,
      "step": 7620
    },
    {
      "epoch": 1.635233604800686,
      "grad_norm": 0.015709325671195984,
      "learning_rate": 1.781968852693242e-05,
      "loss": 0.4818,
      "step": 7630
    },
    {
      "epoch": 1.63737676810973,
      "grad_norm": 22.547800064086914,
      "learning_rate": 1.7816830975853693e-05,
      "loss": 0.5253,
      "step": 7640
    },
    {
      "epoch": 1.639519931418774,
      "grad_norm": 0.2765434682369232,
      "learning_rate": 1.781397342477497e-05,
      "loss": 0.7909,
      "step": 7650
    },
    {
      "epoch": 1.6416630947278184,
      "grad_norm": 0.07377699017524719,
      "learning_rate": 1.7811115873696244e-05,
      "loss": 0.4109,
      "step": 7660
    },
    {
      "epoch": 1.6438062580368624,
      "grad_norm": 29.450252532958984,
      "learning_rate": 1.7808258322617518e-05,
      "loss": 0.1963,
      "step": 7670
    },
    {
      "epoch": 1.6459494213459065,
      "grad_norm": 0.22535057365894318,
      "learning_rate": 1.7805400771538792e-05,
      "loss": 0.4951,
      "step": 7680
    },
    {
      "epoch": 1.6480925846549508,
      "grad_norm": 4.395956516265869,
      "learning_rate": 1.7802543220460066e-05,
      "loss": 0.5225,
      "step": 7690
    },
    {
      "epoch": 1.6502357479639949,
      "grad_norm": 0.34622448682785034,
      "learning_rate": 1.779968566938134e-05,
      "loss": 0.0893,
      "step": 7700
    },
    {
      "epoch": 1.652378911273039,
      "grad_norm": 45.478668212890625,
      "learning_rate": 1.7796828118302617e-05,
      "loss": 0.3134,
      "step": 7710
    },
    {
      "epoch": 1.6545220745820832,
      "grad_norm": 0.15156430006027222,
      "learning_rate": 1.779397056722389e-05,
      "loss": 0.464,
      "step": 7720
    },
    {
      "epoch": 1.6566652378911273,
      "grad_norm": 0.01950908452272415,
      "learning_rate": 1.7791113016145165e-05,
      "loss": 0.2857,
      "step": 7730
    },
    {
      "epoch": 1.6588084012001714,
      "grad_norm": 0.03084707073867321,
      "learning_rate": 1.778825546506644e-05,
      "loss": 0.8374,
      "step": 7740
    },
    {
      "epoch": 1.6609515645092157,
      "grad_norm": 0.07173552364110947,
      "learning_rate": 1.7785397913987713e-05,
      "loss": 0.9174,
      "step": 7750
    },
    {
      "epoch": 1.6630947278182597,
      "grad_norm": 24.079782485961914,
      "learning_rate": 1.778254036290899e-05,
      "loss": 0.4833,
      "step": 7760
    },
    {
      "epoch": 1.6652378911273038,
      "grad_norm": 13.31882381439209,
      "learning_rate": 1.7779682811830264e-05,
      "loss": 0.3175,
      "step": 7770
    },
    {
      "epoch": 1.667381054436348,
      "grad_norm": 0.03460998460650444,
      "learning_rate": 1.7776825260751538e-05,
      "loss": 0.4965,
      "step": 7780
    },
    {
      "epoch": 1.6695242177453922,
      "grad_norm": 0.0739615187048912,
      "learning_rate": 1.7773967709672812e-05,
      "loss": 0.3303,
      "step": 7790
    },
    {
      "epoch": 1.6716673810544362,
      "grad_norm": 0.12692874670028687,
      "learning_rate": 1.7771110158594086e-05,
      "loss": 0.7259,
      "step": 7800
    },
    {
      "epoch": 1.6738105443634805,
      "grad_norm": 0.35041189193725586,
      "learning_rate": 1.7768252607515363e-05,
      "loss": 0.5478,
      "step": 7810
    },
    {
      "epoch": 1.6759537076725246,
      "grad_norm": 21.336259841918945,
      "learning_rate": 1.7765395056436637e-05,
      "loss": 0.6528,
      "step": 7820
    },
    {
      "epoch": 1.6780968709815687,
      "grad_norm": 0.7461324334144592,
      "learning_rate": 1.776253750535791e-05,
      "loss": 0.5233,
      "step": 7830
    },
    {
      "epoch": 1.680240034290613,
      "grad_norm": 8.842485427856445,
      "learning_rate": 1.775967995427918e-05,
      "loss": 0.5862,
      "step": 7840
    },
    {
      "epoch": 1.682383197599657,
      "grad_norm": 36.45859909057617,
      "learning_rate": 1.775682240320046e-05,
      "loss": 0.5131,
      "step": 7850
    },
    {
      "epoch": 1.6845263609087011,
      "grad_norm": 25.458023071289062,
      "learning_rate": 1.7753964852121733e-05,
      "loss": 0.708,
      "step": 7860
    },
    {
      "epoch": 1.6866695242177454,
      "grad_norm": 0.14354197680950165,
      "learning_rate": 1.7751107301043007e-05,
      "loss": 0.2841,
      "step": 7870
    },
    {
      "epoch": 1.6888126875267897,
      "grad_norm": 0.0690402165055275,
      "learning_rate": 1.774824974996428e-05,
      "loss": 0.6433,
      "step": 7880
    },
    {
      "epoch": 1.6909558508358336,
      "grad_norm": 0.21379004418849945,
      "learning_rate": 1.7745392198885555e-05,
      "loss": 0.3133,
      "step": 7890
    },
    {
      "epoch": 1.6930990141448778,
      "grad_norm": 33.51218032836914,
      "learning_rate": 1.7742534647806832e-05,
      "loss": 0.7696,
      "step": 7900
    },
    {
      "epoch": 1.6952421774539221,
      "grad_norm": 14.698649406433105,
      "learning_rate": 1.7739677096728106e-05,
      "loss": 0.4202,
      "step": 7910
    },
    {
      "epoch": 1.697385340762966,
      "grad_norm": 84.65406036376953,
      "learning_rate": 1.773681954564938e-05,
      "loss": 0.4295,
      "step": 7920
    },
    {
      "epoch": 1.6995285040720103,
      "grad_norm": 0.15621869266033173,
      "learning_rate": 1.7733961994570654e-05,
      "loss": 0.9532,
      "step": 7930
    },
    {
      "epoch": 1.7016716673810546,
      "grad_norm": 0.9782226085662842,
      "learning_rate": 1.7731104443491928e-05,
      "loss": 0.2542,
      "step": 7940
    },
    {
      "epoch": 1.7038148306900984,
      "grad_norm": 0.21626059710979462,
      "learning_rate": 1.7728246892413205e-05,
      "loss": 0.2376,
      "step": 7950
    },
    {
      "epoch": 1.7059579939991427,
      "grad_norm": 0.41768959164619446,
      "learning_rate": 1.772538934133448e-05,
      "loss": 0.3394,
      "step": 7960
    },
    {
      "epoch": 1.708101157308187,
      "grad_norm": 0.17250193655490875,
      "learning_rate": 1.7722531790255753e-05,
      "loss": 0.3611,
      "step": 7970
    },
    {
      "epoch": 1.710244320617231,
      "grad_norm": 70.86988067626953,
      "learning_rate": 1.7719674239177027e-05,
      "loss": 0.6213,
      "step": 7980
    },
    {
      "epoch": 1.7123874839262752,
      "grad_norm": 25.797971725463867,
      "learning_rate": 1.77168166880983e-05,
      "loss": 0.4587,
      "step": 7990
    },
    {
      "epoch": 1.7145306472353194,
      "grad_norm": 0.08158537745475769,
      "learning_rate": 1.7713959137019578e-05,
      "loss": 0.2651,
      "step": 8000
    },
    {
      "epoch": 1.7166738105443635,
      "grad_norm": 0.490306556224823,
      "learning_rate": 1.7711101585940852e-05,
      "loss": 0.6369,
      "step": 8010
    },
    {
      "epoch": 1.7188169738534076,
      "grad_norm": 80.28260803222656,
      "learning_rate": 1.7708244034862126e-05,
      "loss": 0.8161,
      "step": 8020
    },
    {
      "epoch": 1.7209601371624519,
      "grad_norm": 0.29314279556274414,
      "learning_rate": 1.77053864837834e-05,
      "loss": 0.2874,
      "step": 8030
    },
    {
      "epoch": 1.723103300471496,
      "grad_norm": 0.11383437365293503,
      "learning_rate": 1.7702528932704674e-05,
      "loss": 0.0497,
      "step": 8040
    },
    {
      "epoch": 1.72524646378054,
      "grad_norm": 0.11066491156816483,
      "learning_rate": 1.7699671381625948e-05,
      "loss": 0.3341,
      "step": 8050
    },
    {
      "epoch": 1.7273896270895843,
      "grad_norm": 0.3193643093109131,
      "learning_rate": 1.769681383054722e-05,
      "loss": 0.1965,
      "step": 8060
    },
    {
      "epoch": 1.7295327903986284,
      "grad_norm": 8.06412410736084,
      "learning_rate": 1.7693956279468495e-05,
      "loss": 0.5932,
      "step": 8070
    },
    {
      "epoch": 1.7316759537076725,
      "grad_norm": 21.65751075744629,
      "learning_rate": 1.769109872838977e-05,
      "loss": 0.5587,
      "step": 8080
    },
    {
      "epoch": 1.7338191170167168,
      "grad_norm": 0.08586712181568146,
      "learning_rate": 1.7688241177311047e-05,
      "loss": 0.6422,
      "step": 8090
    },
    {
      "epoch": 1.7359622803257608,
      "grad_norm": 5.554250240325928,
      "learning_rate": 1.768538362623232e-05,
      "loss": 0.3863,
      "step": 8100
    },
    {
      "epoch": 1.738105443634805,
      "grad_norm": 46.352699279785156,
      "learning_rate": 1.7682526075153595e-05,
      "loss": 0.3993,
      "step": 8110
    },
    {
      "epoch": 1.7402486069438492,
      "grad_norm": 1.3836965560913086,
      "learning_rate": 1.767966852407487e-05,
      "loss": 0.7,
      "step": 8120
    },
    {
      "epoch": 1.7423917702528933,
      "grad_norm": 0.21087250113487244,
      "learning_rate": 1.7676810972996142e-05,
      "loss": 0.8548,
      "step": 8130
    },
    {
      "epoch": 1.7445349335619373,
      "grad_norm": 0.0484311617910862,
      "learning_rate": 1.767395342191742e-05,
      "loss": 0.0624,
      "step": 8140
    },
    {
      "epoch": 1.7466780968709816,
      "grad_norm": 75.26297760009766,
      "learning_rate": 1.7671095870838694e-05,
      "loss": 0.8821,
      "step": 8150
    },
    {
      "epoch": 1.7488212601800257,
      "grad_norm": 32.090824127197266,
      "learning_rate": 1.7668238319759968e-05,
      "loss": 0.3714,
      "step": 8160
    },
    {
      "epoch": 1.7509644234890698,
      "grad_norm": 2.670236110687256,
      "learning_rate": 1.766538076868124e-05,
      "loss": 0.3904,
      "step": 8170
    },
    {
      "epoch": 1.753107586798114,
      "grad_norm": 0.03691091388463974,
      "learning_rate": 1.7662523217602515e-05,
      "loss": 0.3942,
      "step": 8180
    },
    {
      "epoch": 1.7552507501071581,
      "grad_norm": 0.12794797122478485,
      "learning_rate": 1.765966566652379e-05,
      "loss": 0.7521,
      "step": 8190
    },
    {
      "epoch": 1.7573939134162022,
      "grad_norm": 0.053309861570596695,
      "learning_rate": 1.7656808115445067e-05,
      "loss": 0.5439,
      "step": 8200
    },
    {
      "epoch": 1.7595370767252465,
      "grad_norm": 0.11205483227968216,
      "learning_rate": 1.765395056436634e-05,
      "loss": 0.1628,
      "step": 8210
    },
    {
      "epoch": 1.7616802400342906,
      "grad_norm": 0.060653917491436005,
      "learning_rate": 1.7651093013287615e-05,
      "loss": 0.0091,
      "step": 8220
    },
    {
      "epoch": 1.7638234033433347,
      "grad_norm": 128.76319885253906,
      "learning_rate": 1.764823546220889e-05,
      "loss": 0.2581,
      "step": 8230
    },
    {
      "epoch": 1.765966566652379,
      "grad_norm": 6.960423469543457,
      "learning_rate": 1.7645377911130162e-05,
      "loss": 0.7323,
      "step": 8240
    },
    {
      "epoch": 1.768109729961423,
      "grad_norm": 0.03902401030063629,
      "learning_rate": 1.764252036005144e-05,
      "loss": 0.4592,
      "step": 8250
    },
    {
      "epoch": 1.770252893270467,
      "grad_norm": 0.14031098783016205,
      "learning_rate": 1.7639662808972714e-05,
      "loss": 0.1579,
      "step": 8260
    },
    {
      "epoch": 1.7723960565795114,
      "grad_norm": 0.34060388803482056,
      "learning_rate": 1.7636805257893984e-05,
      "loss": 0.5743,
      "step": 8270
    },
    {
      "epoch": 1.7745392198885555,
      "grad_norm": 0.10723330080509186,
      "learning_rate": 1.763394770681526e-05,
      "loss": 0.0019,
      "step": 8280
    },
    {
      "epoch": 1.7766823831975995,
      "grad_norm": 0.8128768801689148,
      "learning_rate": 1.7631090155736535e-05,
      "loss": 0.2716,
      "step": 8290
    },
    {
      "epoch": 1.7788255465066438,
      "grad_norm": 8.448881149291992,
      "learning_rate": 1.762823260465781e-05,
      "loss": 0.6172,
      "step": 8300
    },
    {
      "epoch": 1.7809687098156881,
      "grad_norm": 23.650224685668945,
      "learning_rate": 1.7625375053579083e-05,
      "loss": 0.5337,
      "step": 8310
    },
    {
      "epoch": 1.783111873124732,
      "grad_norm": 137.07601928710938,
      "learning_rate": 1.7622517502500357e-05,
      "loss": 0.55,
      "step": 8320
    },
    {
      "epoch": 1.7852550364337763,
      "grad_norm": 0.2860627770423889,
      "learning_rate": 1.761965995142163e-05,
      "loss": 0.0091,
      "step": 8330
    },
    {
      "epoch": 1.7873981997428205,
      "grad_norm": 48.90216064453125,
      "learning_rate": 1.761680240034291e-05,
      "loss": 0.2783,
      "step": 8340
    },
    {
      "epoch": 1.7895413630518644,
      "grad_norm": 0.09655241668224335,
      "learning_rate": 1.7613944849264182e-05,
      "loss": 0.5532,
      "step": 8350
    },
    {
      "epoch": 1.7916845263609087,
      "grad_norm": 0.07408362627029419,
      "learning_rate": 1.7611087298185456e-05,
      "loss": 0.3919,
      "step": 8360
    },
    {
      "epoch": 1.793827689669953,
      "grad_norm": 0.08646558970212936,
      "learning_rate": 1.760822974710673e-05,
      "loss": 0.4476,
      "step": 8370
    },
    {
      "epoch": 1.7959708529789968,
      "grad_norm": 0.09903904795646667,
      "learning_rate": 1.7605372196028004e-05,
      "loss": 0.2009,
      "step": 8380
    },
    {
      "epoch": 1.7981140162880411,
      "grad_norm": 37.3646240234375,
      "learning_rate": 1.760251464494928e-05,
      "loss": 0.5212,
      "step": 8390
    },
    {
      "epoch": 1.8002571795970854,
      "grad_norm": 48.71291732788086,
      "learning_rate": 1.7599657093870555e-05,
      "loss": 0.8348,
      "step": 8400
    },
    {
      "epoch": 1.8024003429061295,
      "grad_norm": 0.18598033487796783,
      "learning_rate": 1.759679954279183e-05,
      "loss": 0.5142,
      "step": 8410
    },
    {
      "epoch": 1.8045435062151736,
      "grad_norm": 22.295074462890625,
      "learning_rate": 1.7593941991713103e-05,
      "loss": 0.4917,
      "step": 8420
    },
    {
      "epoch": 1.8066866695242179,
      "grad_norm": 0.11573155969381332,
      "learning_rate": 1.7591084440634377e-05,
      "loss": 0.3842,
      "step": 8430
    },
    {
      "epoch": 1.808829832833262,
      "grad_norm": 45.92146301269531,
      "learning_rate": 1.7588226889555654e-05,
      "loss": 0.4331,
      "step": 8440
    },
    {
      "epoch": 1.810972996142306,
      "grad_norm": 0.8581569194793701,
      "learning_rate": 1.758536933847693e-05,
      "loss": 0.1924,
      "step": 8450
    },
    {
      "epoch": 1.8131161594513503,
      "grad_norm": 2.703167200088501,
      "learning_rate": 1.7582511787398202e-05,
      "loss": 0.6336,
      "step": 8460
    },
    {
      "epoch": 1.8152593227603944,
      "grad_norm": 27.73387908935547,
      "learning_rate": 1.7579654236319476e-05,
      "loss": 0.4855,
      "step": 8470
    },
    {
      "epoch": 1.8174024860694384,
      "grad_norm": 0.25192171335220337,
      "learning_rate": 1.757679668524075e-05,
      "loss": 0.519,
      "step": 8480
    },
    {
      "epoch": 1.8195456493784827,
      "grad_norm": 54.86304473876953,
      "learning_rate": 1.7573939134162024e-05,
      "loss": 0.2082,
      "step": 8490
    },
    {
      "epoch": 1.8216888126875268,
      "grad_norm": 0.1621488332748413,
      "learning_rate": 1.7571081583083298e-05,
      "loss": 0.0437,
      "step": 8500
    },
    {
      "epoch": 1.8238319759965709,
      "grad_norm": 30.503816604614258,
      "learning_rate": 1.7568224032004572e-05,
      "loss": 0.2718,
      "step": 8510
    },
    {
      "epoch": 1.8259751393056152,
      "grad_norm": 26.140993118286133,
      "learning_rate": 1.7565366480925846e-05,
      "loss": 0.825,
      "step": 8520
    },
    {
      "epoch": 1.8281183026146592,
      "grad_norm": 0.8415318131446838,
      "learning_rate": 1.7562508929847123e-05,
      "loss": 0.4918,
      "step": 8530
    },
    {
      "epoch": 1.8302614659237033,
      "grad_norm": 26.025882720947266,
      "learning_rate": 1.7559651378768397e-05,
      "loss": 0.64,
      "step": 8540
    },
    {
      "epoch": 1.8324046292327476,
      "grad_norm": 0.4947090446949005,
      "learning_rate": 1.755679382768967e-05,
      "loss": 0.2752,
      "step": 8550
    },
    {
      "epoch": 1.8345477925417917,
      "grad_norm": 0.10871166735887527,
      "learning_rate": 1.7553936276610945e-05,
      "loss": 0.4262,
      "step": 8560
    },
    {
      "epoch": 1.8366909558508357,
      "grad_norm": 1.9277737140655518,
      "learning_rate": 1.755107872553222e-05,
      "loss": 0.1857,
      "step": 8570
    },
    {
      "epoch": 1.83883411915988,
      "grad_norm": 0.04723072052001953,
      "learning_rate": 1.7548221174453496e-05,
      "loss": 0.4783,
      "step": 8580
    },
    {
      "epoch": 1.8409772824689241,
      "grad_norm": 0.09297633171081543,
      "learning_rate": 1.754536362337477e-05,
      "loss": 0.0294,
      "step": 8590
    },
    {
      "epoch": 1.8431204457779682,
      "grad_norm": 2.9631755352020264,
      "learning_rate": 1.7542506072296044e-05,
      "loss": 0.5022,
      "step": 8600
    },
    {
      "epoch": 1.8452636090870125,
      "grad_norm": 0.05504734069108963,
      "learning_rate": 1.7539648521217318e-05,
      "loss": 0.3763,
      "step": 8610
    },
    {
      "epoch": 1.8474067723960566,
      "grad_norm": 23.448482513427734,
      "learning_rate": 1.7536790970138592e-05,
      "loss": 0.8702,
      "step": 8620
    },
    {
      "epoch": 1.8495499357051006,
      "grad_norm": 4.841933727264404,
      "learning_rate": 1.7533933419059866e-05,
      "loss": 0.5821,
      "step": 8630
    },
    {
      "epoch": 1.851693099014145,
      "grad_norm": 0.25554853677749634,
      "learning_rate": 1.7531075867981143e-05,
      "loss": 0.8624,
      "step": 8640
    },
    {
      "epoch": 1.853836262323189,
      "grad_norm": 0.2887229025363922,
      "learning_rate": 1.7528218316902417e-05,
      "loss": 0.3924,
      "step": 8650
    },
    {
      "epoch": 1.855979425632233,
      "grad_norm": 0.5158805251121521,
      "learning_rate": 1.752536076582369e-05,
      "loss": 0.3619,
      "step": 8660
    },
    {
      "epoch": 1.8581225889412774,
      "grad_norm": 0.33740103244781494,
      "learning_rate": 1.7522503214744965e-05,
      "loss": 0.1929,
      "step": 8670
    },
    {
      "epoch": 1.8602657522503214,
      "grad_norm": 92.21764373779297,
      "learning_rate": 1.751964566366624e-05,
      "loss": 0.3794,
      "step": 8680
    },
    {
      "epoch": 1.8624089155593655,
      "grad_norm": 26.988161087036133,
      "learning_rate": 1.7516788112587516e-05,
      "loss": 0.6443,
      "step": 8690
    },
    {
      "epoch": 1.8645520788684098,
      "grad_norm": 20.12244415283203,
      "learning_rate": 1.7513930561508787e-05,
      "loss": 0.9121,
      "step": 8700
    },
    {
      "epoch": 1.866695242177454,
      "grad_norm": 19.687602996826172,
      "learning_rate": 1.751107301043006e-05,
      "loss": 0.7734,
      "step": 8710
    },
    {
      "epoch": 1.868838405486498,
      "grad_norm": 79.26115417480469,
      "learning_rate": 1.7508215459351338e-05,
      "loss": 0.4113,
      "step": 8720
    },
    {
      "epoch": 1.8709815687955422,
      "grad_norm": 0.25505802035331726,
      "learning_rate": 1.7505357908272612e-05,
      "loss": 0.0511,
      "step": 8730
    },
    {
      "epoch": 1.8731247321045865,
      "grad_norm": 18.126075744628906,
      "learning_rate": 1.7502500357193886e-05,
      "loss": 0.7665,
      "step": 8740
    },
    {
      "epoch": 1.8752678954136304,
      "grad_norm": 165.93017578125,
      "learning_rate": 1.749964280611516e-05,
      "loss": 0.6706,
      "step": 8750
    },
    {
      "epoch": 1.8774110587226747,
      "grad_norm": 0.12595729529857635,
      "learning_rate": 1.7496785255036434e-05,
      "loss": 0.5708,
      "step": 8760
    },
    {
      "epoch": 1.879554222031719,
      "grad_norm": 0.24060101807117462,
      "learning_rate": 1.7493927703957708e-05,
      "loss": 0.7887,
      "step": 8770
    },
    {
      "epoch": 1.8816973853407628,
      "grad_norm": 27.33660888671875,
      "learning_rate": 1.7491070152878985e-05,
      "loss": 0.2697,
      "step": 8780
    },
    {
      "epoch": 1.883840548649807,
      "grad_norm": 65.54785919189453,
      "learning_rate": 1.748821260180026e-05,
      "loss": 0.1252,
      "step": 8790
    },
    {
      "epoch": 1.8859837119588514,
      "grad_norm": 0.25209975242614746,
      "learning_rate": 1.7485355050721533e-05,
      "loss": 0.4038,
      "step": 8800
    },
    {
      "epoch": 1.8881268752678955,
      "grad_norm": 0.17687398195266724,
      "learning_rate": 1.7482497499642807e-05,
      "loss": 0.5841,
      "step": 8810
    },
    {
      "epoch": 1.8902700385769395,
      "grad_norm": 10.090948104858398,
      "learning_rate": 1.747963994856408e-05,
      "loss": 0.5641,
      "step": 8820
    },
    {
      "epoch": 1.8924132018859838,
      "grad_norm": 0.43382441997528076,
      "learning_rate": 1.7476782397485358e-05,
      "loss": 0.5712,
      "step": 8830
    },
    {
      "epoch": 1.894556365195028,
      "grad_norm": 0.23826535046100616,
      "learning_rate": 1.7473924846406632e-05,
      "loss": 0.2198,
      "step": 8840
    },
    {
      "epoch": 1.896699528504072,
      "grad_norm": 51.11289596557617,
      "learning_rate": 1.7471067295327906e-05,
      "loss": 0.4238,
      "step": 8850
    },
    {
      "epoch": 1.8988426918131163,
      "grad_norm": 0.38819822669029236,
      "learning_rate": 1.746820974424918e-05,
      "loss": 0.1077,
      "step": 8860
    },
    {
      "epoch": 1.9009858551221603,
      "grad_norm": 0.13330741226673126,
      "learning_rate": 1.7465352193170454e-05,
      "loss": 0.3644,
      "step": 8870
    },
    {
      "epoch": 1.9031290184312044,
      "grad_norm": 0.032245997339487076,
      "learning_rate": 1.746249464209173e-05,
      "loss": 0.7338,
      "step": 8880
    },
    {
      "epoch": 1.9052721817402487,
      "grad_norm": 85.64019775390625,
      "learning_rate": 1.7459637091013005e-05,
      "loss": 1.5795,
      "step": 8890
    },
    {
      "epoch": 1.9074153450492928,
      "grad_norm": 17.885032653808594,
      "learning_rate": 1.745677953993428e-05,
      "loss": 0.4926,
      "step": 8900
    },
    {
      "epoch": 1.9095585083583368,
      "grad_norm": 0.34705492854118347,
      "learning_rate": 1.745392198885555e-05,
      "loss": 0.151,
      "step": 8910
    },
    {
      "epoch": 1.9117016716673811,
      "grad_norm": 35.61997604370117,
      "learning_rate": 1.7451064437776827e-05,
      "loss": 0.168,
      "step": 8920
    },
    {
      "epoch": 1.9138448349764252,
      "grad_norm": 0.149876669049263,
      "learning_rate": 1.74482068866981e-05,
      "loss": 0.2059,
      "step": 8930
    },
    {
      "epoch": 1.9159879982854693,
      "grad_norm": 0.18711122870445251,
      "learning_rate": 1.7445349335619375e-05,
      "loss": 0.2543,
      "step": 8940
    },
    {
      "epoch": 1.9181311615945136,
      "grad_norm": 0.06583385914564133,
      "learning_rate": 1.744249178454065e-05,
      "loss": 0.3232,
      "step": 8950
    },
    {
      "epoch": 1.9202743249035577,
      "grad_norm": 0.11307905614376068,
      "learning_rate": 1.7439634233461922e-05,
      "loss": 0.6732,
      "step": 8960
    },
    {
      "epoch": 1.9224174882126017,
      "grad_norm": 0.036431849002838135,
      "learning_rate": 1.74367766823832e-05,
      "loss": 0.2553,
      "step": 8970
    },
    {
      "epoch": 1.924560651521646,
      "grad_norm": 18.922231674194336,
      "learning_rate": 1.7433919131304474e-05,
      "loss": 0.3232,
      "step": 8980
    },
    {
      "epoch": 1.92670381483069,
      "grad_norm": 0.021177062764763832,
      "learning_rate": 1.7431061580225748e-05,
      "loss": 0.2655,
      "step": 8990
    },
    {
      "epoch": 1.9288469781397342,
      "grad_norm": 0.033094342797994614,
      "learning_rate": 1.742820402914702e-05,
      "loss": 0.3401,
      "step": 9000
    },
    {
      "epoch": 1.9309901414487785,
      "grad_norm": 0.06145954504609108,
      "learning_rate": 1.7425346478068296e-05,
      "loss": 0.003,
      "step": 9010
    },
    {
      "epoch": 1.9331333047578225,
      "grad_norm": 29.518787384033203,
      "learning_rate": 1.7422488926989573e-05,
      "loss": 0.5137,
      "step": 9020
    },
    {
      "epoch": 1.9352764680668666,
      "grad_norm": 0.1072373166680336,
      "learning_rate": 1.7419631375910847e-05,
      "loss": 0.3865,
      "step": 9030
    },
    {
      "epoch": 1.9374196313759109,
      "grad_norm": 0.37216973304748535,
      "learning_rate": 1.741677382483212e-05,
      "loss": 0.0087,
      "step": 9040
    },
    {
      "epoch": 1.939562794684955,
      "grad_norm": 0.12141704559326172,
      "learning_rate": 1.7413916273753395e-05,
      "loss": 0.7651,
      "step": 9050
    },
    {
      "epoch": 1.941705957993999,
      "grad_norm": 19.632980346679688,
      "learning_rate": 1.741105872267467e-05,
      "loss": 0.2467,
      "step": 9060
    },
    {
      "epoch": 1.9438491213030433,
      "grad_norm": 0.0643710121512413,
      "learning_rate": 1.7408201171595946e-05,
      "loss": 0.0027,
      "step": 9070
    },
    {
      "epoch": 1.9459922846120874,
      "grad_norm": 31.987884521484375,
      "learning_rate": 1.740534362051722e-05,
      "loss": 0.1714,
      "step": 9080
    },
    {
      "epoch": 1.9481354479211315,
      "grad_norm": 1.5068838596343994,
      "learning_rate": 1.7402486069438494e-05,
      "loss": 0.5805,
      "step": 9090
    },
    {
      "epoch": 1.9502786112301758,
      "grad_norm": 0.030979996547102928,
      "learning_rate": 1.7399628518359768e-05,
      "loss": 0.3896,
      "step": 9100
    },
    {
      "epoch": 1.9524217745392198,
      "grad_norm": 21.8272705078125,
      "learning_rate": 1.739677096728104e-05,
      "loss": 0.4202,
      "step": 9110
    },
    {
      "epoch": 1.954564937848264,
      "grad_norm": 0.5384546518325806,
      "learning_rate": 1.7393913416202316e-05,
      "loss": 0.2172,
      "step": 9120
    },
    {
      "epoch": 1.9567081011573082,
      "grad_norm": 0.10927122086286545,
      "learning_rate": 1.739105586512359e-05,
      "loss": 0.4152,
      "step": 9130
    },
    {
      "epoch": 1.9588512644663525,
      "grad_norm": 0.09358863532543182,
      "learning_rate": 1.7388198314044863e-05,
      "loss": 0.3805,
      "step": 9140
    },
    {
      "epoch": 1.9609944277753963,
      "grad_norm": 0.13013125956058502,
      "learning_rate": 1.7385340762966137e-05,
      "loss": 0.5554,
      "step": 9150
    },
    {
      "epoch": 1.9631375910844406,
      "grad_norm": 1.038535237312317,
      "learning_rate": 1.7382483211887415e-05,
      "loss": 0.2151,
      "step": 9160
    },
    {
      "epoch": 1.965280754393485,
      "grad_norm": 5.067136764526367,
      "learning_rate": 1.737962566080869e-05,
      "loss": 0.0111,
      "step": 9170
    },
    {
      "epoch": 1.9674239177025288,
      "grad_norm": 0.10173232108354568,
      "learning_rate": 1.7376768109729962e-05,
      "loss": 0.5762,
      "step": 9180
    },
    {
      "epoch": 1.969567081011573,
      "grad_norm": 0.3057534098625183,
      "learning_rate": 1.7373910558651236e-05,
      "loss": 0.2308,
      "step": 9190
    },
    {
      "epoch": 1.9717102443206174,
      "grad_norm": 26.59850311279297,
      "learning_rate": 1.737105300757251e-05,
      "loss": 0.5705,
      "step": 9200
    },
    {
      "epoch": 1.9738534076296612,
      "grad_norm": 0.062275566160678864,
      "learning_rate": 1.7368195456493788e-05,
      "loss": 1.2546,
      "step": 9210
    },
    {
      "epoch": 1.9759965709387055,
      "grad_norm": 0.057592228055000305,
      "learning_rate": 1.736533790541506e-05,
      "loss": 0.3556,
      "step": 9220
    },
    {
      "epoch": 1.9781397342477498,
      "grad_norm": 25.039400100708008,
      "learning_rate": 1.7362480354336335e-05,
      "loss": 0.2433,
      "step": 9230
    },
    {
      "epoch": 1.9802828975567939,
      "grad_norm": 18.854049682617188,
      "learning_rate": 1.735962280325761e-05,
      "loss": 0.6127,
      "step": 9240
    },
    {
      "epoch": 1.982426060865838,
      "grad_norm": 0.08502305299043655,
      "learning_rate": 1.7356765252178883e-05,
      "loss": 0.2225,
      "step": 9250
    },
    {
      "epoch": 1.9845692241748822,
      "grad_norm": 76.6661148071289,
      "learning_rate": 1.7353907701100157e-05,
      "loss": 0.266,
      "step": 9260
    },
    {
      "epoch": 1.9867123874839263,
      "grad_norm": 0.1746685802936554,
      "learning_rate": 1.7351050150021435e-05,
      "loss": 0.2004,
      "step": 9270
    },
    {
      "epoch": 1.9888555507929704,
      "grad_norm": 1.3687876462936401,
      "learning_rate": 1.734819259894271e-05,
      "loss": 0.4436,
      "step": 9280
    },
    {
      "epoch": 1.9909987141020147,
      "grad_norm": 0.2048070877790451,
      "learning_rate": 1.7345335047863982e-05,
      "loss": 0.4293,
      "step": 9290
    },
    {
      "epoch": 1.9931418774110587,
      "grad_norm": 46.42684555053711,
      "learning_rate": 1.7342477496785256e-05,
      "loss": 0.3172,
      "step": 9300
    },
    {
      "epoch": 1.9952850407201028,
      "grad_norm": 20.371841430664062,
      "learning_rate": 1.733961994570653e-05,
      "loss": 0.4451,
      "step": 9310
    },
    {
      "epoch": 1.9974282040291471,
      "grad_norm": 21.05464744567871,
      "learning_rate": 1.7336762394627808e-05,
      "loss": 0.7201,
      "step": 9320
    },
    {
      "epoch": 1.9995713673381912,
      "grad_norm": 23.999385833740234,
      "learning_rate": 1.733390484354908e-05,
      "loss": 0.3699,
      "step": 9330
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9063333333333333,
      "eval_f1": 0.7341532639545886,
      "eval_loss": 0.4380471110343933,
      "eval_precision": 0.8185654008438819,
      "eval_recall": 0.6655231560891939,
      "eval_runtime": 108.3534,
      "eval_samples_per_second": 27.687,
      "eval_steps_per_second": 1.154,
      "step": 9332
    },
    {
      "epoch": 2.0017145306472353,
      "grad_norm": 0.1472134292125702,
      "learning_rate": 1.7331047292470352e-05,
      "loss": 0.2279,
      "step": 9340
    },
    {
      "epoch": 2.0038576939562796,
      "grad_norm": 0.1209268718957901,
      "learning_rate": 1.732818974139163e-05,
      "loss": 0.0612,
      "step": 9350
    },
    {
      "epoch": 2.0060008572653234,
      "grad_norm": 0.04778371751308441,
      "learning_rate": 1.7325332190312903e-05,
      "loss": 0.225,
      "step": 9360
    },
    {
      "epoch": 2.0081440205743677,
      "grad_norm": 19.557228088378906,
      "learning_rate": 1.7322474639234177e-05,
      "loss": 0.6196,
      "step": 9370
    },
    {
      "epoch": 2.010287183883412,
      "grad_norm": 0.058782659471035004,
      "learning_rate": 1.731961708815545e-05,
      "loss": 0.4601,
      "step": 9380
    },
    {
      "epoch": 2.0124303471924563,
      "grad_norm": 0.08180991560220718,
      "learning_rate": 1.7316759537076725e-05,
      "loss": 0.6277,
      "step": 9390
    },
    {
      "epoch": 2.0145735105015,
      "grad_norm": 1.709399700164795,
      "learning_rate": 1.7313901985998e-05,
      "loss": 0.0081,
      "step": 9400
    },
    {
      "epoch": 2.0167166738105444,
      "grad_norm": 26.4862117767334,
      "learning_rate": 1.7311044434919276e-05,
      "loss": 0.1959,
      "step": 9410
    },
    {
      "epoch": 2.0188598371195887,
      "grad_norm": 0.2740641236305237,
      "learning_rate": 1.730818688384055e-05,
      "loss": 0.1148,
      "step": 9420
    },
    {
      "epoch": 2.0210030004286326,
      "grad_norm": 0.040415484458208084,
      "learning_rate": 1.7305329332761824e-05,
      "loss": 0.0022,
      "step": 9430
    },
    {
      "epoch": 2.023146163737677,
      "grad_norm": 0.1131952628493309,
      "learning_rate": 1.7302471781683098e-05,
      "loss": 0.001,
      "step": 9440
    },
    {
      "epoch": 2.025289327046721,
      "grad_norm": 0.05287758260965347,
      "learning_rate": 1.7299614230604372e-05,
      "loss": 0.1842,
      "step": 9450
    },
    {
      "epoch": 2.027432490355765,
      "grad_norm": 0.01599859446287155,
      "learning_rate": 1.729675667952565e-05,
      "loss": 0.1605,
      "step": 9460
    },
    {
      "epoch": 2.0295756536648093,
      "grad_norm": 0.012045406736433506,
      "learning_rate": 1.7293899128446923e-05,
      "loss": 0.5136,
      "step": 9470
    },
    {
      "epoch": 2.0317188169738536,
      "grad_norm": 0.021233879029750824,
      "learning_rate": 1.7291041577368197e-05,
      "loss": 0.351,
      "step": 9480
    },
    {
      "epoch": 2.0338619802828974,
      "grad_norm": 0.2649992108345032,
      "learning_rate": 1.728818402628947e-05,
      "loss": 0.0011,
      "step": 9490
    },
    {
      "epoch": 2.0360051435919417,
      "grad_norm": 0.028602037578821182,
      "learning_rate": 1.7285326475210745e-05,
      "loss": 0.2771,
      "step": 9500
    },
    {
      "epoch": 2.038148306900986,
      "grad_norm": 22.67832374572754,
      "learning_rate": 1.7282468924132022e-05,
      "loss": 0.1899,
      "step": 9510
    },
    {
      "epoch": 2.04029147021003,
      "grad_norm": 0.13658224046230316,
      "learning_rate": 1.7279611373053296e-05,
      "loss": 0.001,
      "step": 9520
    },
    {
      "epoch": 2.042434633519074,
      "grad_norm": 23.143552780151367,
      "learning_rate": 1.727675382197457e-05,
      "loss": 0.5497,
      "step": 9530
    },
    {
      "epoch": 2.0445777968281185,
      "grad_norm": 0.19608932733535767,
      "learning_rate": 1.7273896270895844e-05,
      "loss": 0.0086,
      "step": 9540
    },
    {
      "epoch": 2.0467209601371623,
      "grad_norm": 0.07945752888917923,
      "learning_rate": 1.7271038719817118e-05,
      "loss": 0.5413,
      "step": 9550
    },
    {
      "epoch": 2.0488641234462066,
      "grad_norm": 0.07254581898450851,
      "learning_rate": 1.7268181168738392e-05,
      "loss": 0.3779,
      "step": 9560
    },
    {
      "epoch": 2.051007286755251,
      "grad_norm": 27.197858810424805,
      "learning_rate": 1.7265323617659666e-05,
      "loss": 0.4953,
      "step": 9570
    },
    {
      "epoch": 2.0531504500642948,
      "grad_norm": 0.16633360087871552,
      "learning_rate": 1.726246606658094e-05,
      "loss": 0.0023,
      "step": 9580
    },
    {
      "epoch": 2.055293613373339,
      "grad_norm": 0.008028965443372726,
      "learning_rate": 1.7259608515502214e-05,
      "loss": 0.6454,
      "step": 9590
    },
    {
      "epoch": 2.0574367766823833,
      "grad_norm": 0.12418768554925919,
      "learning_rate": 1.725675096442349e-05,
      "loss": 0.1746,
      "step": 9600
    },
    {
      "epoch": 2.059579939991427,
      "grad_norm": 0.045878950506448746,
      "learning_rate": 1.7253893413344765e-05,
      "loss": 0.3116,
      "step": 9610
    },
    {
      "epoch": 2.0617231033004715,
      "grad_norm": 0.16158021986484528,
      "learning_rate": 1.725103586226604e-05,
      "loss": 0.1181,
      "step": 9620
    },
    {
      "epoch": 2.0638662666095158,
      "grad_norm": 0.03961974382400513,
      "learning_rate": 1.7248178311187313e-05,
      "loss": 0.1011,
      "step": 9630
    },
    {
      "epoch": 2.0660094299185596,
      "grad_norm": 0.07835254073143005,
      "learning_rate": 1.7245320760108587e-05,
      "loss": 0.0248,
      "step": 9640
    },
    {
      "epoch": 2.068152593227604,
      "grad_norm": 0.08603280037641525,
      "learning_rate": 1.7242463209029864e-05,
      "loss": 0.2422,
      "step": 9650
    },
    {
      "epoch": 2.070295756536648,
      "grad_norm": 0.2771504819393158,
      "learning_rate": 1.7239605657951138e-05,
      "loss": 0.3971,
      "step": 9660
    },
    {
      "epoch": 2.072438919845692,
      "grad_norm": 0.1999794989824295,
      "learning_rate": 1.7236748106872412e-05,
      "loss": 0.0027,
      "step": 9670
    },
    {
      "epoch": 2.0745820831547364,
      "grad_norm": 0.01992691494524479,
      "learning_rate": 1.7233890555793686e-05,
      "loss": 0.196,
      "step": 9680
    },
    {
      "epoch": 2.0767252464637806,
      "grad_norm": 0.10387694835662842,
      "learning_rate": 1.723103300471496e-05,
      "loss": 0.5795,
      "step": 9690
    },
    {
      "epoch": 2.0788684097728245,
      "grad_norm": 0.13718602061271667,
      "learning_rate": 1.7228175453636237e-05,
      "loss": 0.2181,
      "step": 9700
    },
    {
      "epoch": 2.081011573081869,
      "grad_norm": 0.008591808378696442,
      "learning_rate": 1.722531790255751e-05,
      "loss": 0.396,
      "step": 9710
    },
    {
      "epoch": 2.083154736390913,
      "grad_norm": 90.72679901123047,
      "learning_rate": 1.7222460351478785e-05,
      "loss": 0.1871,
      "step": 9720
    },
    {
      "epoch": 2.085297899699957,
      "grad_norm": 0.009208695031702518,
      "learning_rate": 1.721960280040006e-05,
      "loss": 0.001,
      "step": 9730
    },
    {
      "epoch": 2.0874410630090012,
      "grad_norm": 0.00803892221301794,
      "learning_rate": 1.7216745249321333e-05,
      "loss": 0.4167,
      "step": 9740
    },
    {
      "epoch": 2.0895842263180455,
      "grad_norm": 18.121219635009766,
      "learning_rate": 1.7213887698242607e-05,
      "loss": 0.3314,
      "step": 9750
    },
    {
      "epoch": 2.0917273896270894,
      "grad_norm": 0.14795297384262085,
      "learning_rate": 1.7211030147163884e-05,
      "loss": 0.5911,
      "step": 9760
    },
    {
      "epoch": 2.0938705529361337,
      "grad_norm": 0.15056836605072021,
      "learning_rate": 1.7208172596085155e-05,
      "loss": 0.1986,
      "step": 9770
    },
    {
      "epoch": 2.096013716245178,
      "grad_norm": 0.0660461038351059,
      "learning_rate": 1.720531504500643e-05,
      "loss": 0.0771,
      "step": 9780
    },
    {
      "epoch": 2.098156879554222,
      "grad_norm": 0.09146946668624878,
      "learning_rate": 1.7202457493927706e-05,
      "loss": 0.4682,
      "step": 9790
    },
    {
      "epoch": 2.100300042863266,
      "grad_norm": 0.1608157604932785,
      "learning_rate": 1.719959994284898e-05,
      "loss": 0.6668,
      "step": 9800
    },
    {
      "epoch": 2.1024432061723104,
      "grad_norm": 3.0548017024993896,
      "learning_rate": 1.7196742391770254e-05,
      "loss": 0.1375,
      "step": 9810
    },
    {
      "epoch": 2.1045863694813547,
      "grad_norm": 39.919639587402344,
      "learning_rate": 1.7193884840691528e-05,
      "loss": 0.8945,
      "step": 9820
    },
    {
      "epoch": 2.1067295327903985,
      "grad_norm": 15.585067749023438,
      "learning_rate": 1.71910272896128e-05,
      "loss": 0.0679,
      "step": 9830
    },
    {
      "epoch": 2.108872696099443,
      "grad_norm": 0.018750501796603203,
      "learning_rate": 1.718816973853408e-05,
      "loss": 0.3698,
      "step": 9840
    },
    {
      "epoch": 2.111015859408487,
      "grad_norm": 20.681148529052734,
      "learning_rate": 1.7185312187455353e-05,
      "loss": 0.2014,
      "step": 9850
    },
    {
      "epoch": 2.113159022717531,
      "grad_norm": 28.261751174926758,
      "learning_rate": 1.7182454636376627e-05,
      "loss": 0.4759,
      "step": 9860
    },
    {
      "epoch": 2.1153021860265753,
      "grad_norm": 0.1000775396823883,
      "learning_rate": 1.71795970852979e-05,
      "loss": 0.4031,
      "step": 9870
    },
    {
      "epoch": 2.1174453493356196,
      "grad_norm": 0.17154689133167267,
      "learning_rate": 1.7176739534219175e-05,
      "loss": 0.184,
      "step": 9880
    },
    {
      "epoch": 2.1195885126446634,
      "grad_norm": 1.2422945499420166,
      "learning_rate": 1.717388198314045e-05,
      "loss": 0.5398,
      "step": 9890
    },
    {
      "epoch": 2.1217316759537077,
      "grad_norm": 45.132999420166016,
      "learning_rate": 1.7171024432061726e-05,
      "loss": 0.3081,
      "step": 9900
    },
    {
      "epoch": 2.123874839262752,
      "grad_norm": 0.7530022859573364,
      "learning_rate": 1.7168166880983e-05,
      "loss": 0.472,
      "step": 9910
    },
    {
      "epoch": 2.126018002571796,
      "grad_norm": 0.07735489308834076,
      "learning_rate": 1.7165309329904274e-05,
      "loss": 0.0286,
      "step": 9920
    },
    {
      "epoch": 2.12816116588084,
      "grad_norm": 65.4566879272461,
      "learning_rate": 1.7162451778825548e-05,
      "loss": 0.6421,
      "step": 9930
    },
    {
      "epoch": 2.1303043291898844,
      "grad_norm": 0.9790703654289246,
      "learning_rate": 1.715959422774682e-05,
      "loss": 0.5806,
      "step": 9940
    },
    {
      "epoch": 2.1324474924989283,
      "grad_norm": 0.08470635861158371,
      "learning_rate": 1.71567366766681e-05,
      "loss": 0.23,
      "step": 9950
    },
    {
      "epoch": 2.1345906558079726,
      "grad_norm": 0.1622133105993271,
      "learning_rate": 1.7153879125589373e-05,
      "loss": 0.3009,
      "step": 9960
    },
    {
      "epoch": 2.136733819117017,
      "grad_norm": 0.07408080995082855,
      "learning_rate": 1.7151021574510647e-05,
      "loss": 0.4229,
      "step": 9970
    },
    {
      "epoch": 2.1388769824260607,
      "grad_norm": 0.06802048534154892,
      "learning_rate": 1.714816402343192e-05,
      "loss": 0.2339,
      "step": 9980
    },
    {
      "epoch": 2.141020145735105,
      "grad_norm": 0.1344069093465805,
      "learning_rate": 1.7145306472353195e-05,
      "loss": 0.1574,
      "step": 9990
    },
    {
      "epoch": 2.1431633090441493,
      "grad_norm": 0.1333044320344925,
      "learning_rate": 1.714244892127447e-05,
      "loss": 0.4547,
      "step": 10000
    },
    {
      "epoch": 2.145306472353193,
      "grad_norm": 27.792692184448242,
      "learning_rate": 1.7139591370195743e-05,
      "loss": 0.2526,
      "step": 10010
    },
    {
      "epoch": 2.1474496356622375,
      "grad_norm": 0.035048458725214005,
      "learning_rate": 1.7136733819117016e-05,
      "loss": 0.3197,
      "step": 10020
    },
    {
      "epoch": 2.1495927989712817,
      "grad_norm": 163.5021514892578,
      "learning_rate": 1.713387626803829e-05,
      "loss": 0.2873,
      "step": 10030
    },
    {
      "epoch": 2.1517359622803256,
      "grad_norm": 0.1534910351037979,
      "learning_rate": 1.7131018716959568e-05,
      "loss": 0.1616,
      "step": 10040
    },
    {
      "epoch": 2.15387912558937,
      "grad_norm": 0.6059544682502747,
      "learning_rate": 1.712816116588084e-05,
      "loss": 0.0013,
      "step": 10050
    },
    {
      "epoch": 2.156022288898414,
      "grad_norm": 130.01885986328125,
      "learning_rate": 1.7125303614802116e-05,
      "loss": 0.3295,
      "step": 10060
    },
    {
      "epoch": 2.158165452207458,
      "grad_norm": 23.382230758666992,
      "learning_rate": 1.712244606372339e-05,
      "loss": 0.1752,
      "step": 10070
    },
    {
      "epoch": 2.1603086155165023,
      "grad_norm": 0.03797184303402901,
      "learning_rate": 1.7119588512644663e-05,
      "loss": 0.0114,
      "step": 10080
    },
    {
      "epoch": 2.1624517788255466,
      "grad_norm": 74.72315979003906,
      "learning_rate": 1.711673096156594e-05,
      "loss": 0.2868,
      "step": 10090
    },
    {
      "epoch": 2.1645949421345905,
      "grad_norm": 0.01426650583744049,
      "learning_rate": 1.7113873410487215e-05,
      "loss": 0.001,
      "step": 10100
    },
    {
      "epoch": 2.1667381054436348,
      "grad_norm": 26.801532745361328,
      "learning_rate": 1.711101585940849e-05,
      "loss": 0.3824,
      "step": 10110
    },
    {
      "epoch": 2.168881268752679,
      "grad_norm": 0.03822597488760948,
      "learning_rate": 1.7108158308329763e-05,
      "loss": 0.4405,
      "step": 10120
    },
    {
      "epoch": 2.171024432061723,
      "grad_norm": 0.03712649643421173,
      "learning_rate": 1.7105300757251036e-05,
      "loss": 0.0013,
      "step": 10130
    },
    {
      "epoch": 2.173167595370767,
      "grad_norm": 20.31976318359375,
      "learning_rate": 1.7102443206172314e-05,
      "loss": 0.193,
      "step": 10140
    },
    {
      "epoch": 2.1753107586798115,
      "grad_norm": 0.01691303588449955,
      "learning_rate": 1.7099585655093588e-05,
      "loss": 0.4408,
      "step": 10150
    },
    {
      "epoch": 2.1774539219888553,
      "grad_norm": 0.04175055772066116,
      "learning_rate": 1.709672810401486e-05,
      "loss": 0.6447,
      "step": 10160
    },
    {
      "epoch": 2.1795970852978996,
      "grad_norm": 0.06549853831529617,
      "learning_rate": 1.7093870552936136e-05,
      "loss": 0.5756,
      "step": 10170
    },
    {
      "epoch": 2.181740248606944,
      "grad_norm": 0.15170830488204956,
      "learning_rate": 1.709101300185741e-05,
      "loss": 0.5401,
      "step": 10180
    },
    {
      "epoch": 2.1838834119159882,
      "grad_norm": 0.08886168897151947,
      "learning_rate": 1.7088155450778683e-05,
      "loss": 0.0139,
      "step": 10190
    },
    {
      "epoch": 2.186026575225032,
      "grad_norm": 54.84294891357422,
      "learning_rate": 1.7085297899699957e-05,
      "loss": 0.3257,
      "step": 10200
    },
    {
      "epoch": 2.1881697385340764,
      "grad_norm": 64.22209167480469,
      "learning_rate": 1.708244034862123e-05,
      "loss": 0.449,
      "step": 10210
    },
    {
      "epoch": 2.1903129018431207,
      "grad_norm": 21.493288040161133,
      "learning_rate": 1.7079582797542505e-05,
      "loss": 0.2341,
      "step": 10220
    },
    {
      "epoch": 2.1924560651521645,
      "grad_norm": 0.06714252382516861,
      "learning_rate": 1.7076725246463783e-05,
      "loss": 0.4944,
      "step": 10230
    },
    {
      "epoch": 2.194599228461209,
      "grad_norm": 64.64694213867188,
      "learning_rate": 1.7073867695385056e-05,
      "loss": 0.6348,
      "step": 10240
    },
    {
      "epoch": 2.196742391770253,
      "grad_norm": 0.06916956603527069,
      "learning_rate": 1.707101014430633e-05,
      "loss": 0.0036,
      "step": 10250
    },
    {
      "epoch": 2.198885555079297,
      "grad_norm": 0.04857748746871948,
      "learning_rate": 1.7068152593227604e-05,
      "loss": 0.0339,
      "step": 10260
    },
    {
      "epoch": 2.2010287183883412,
      "grad_norm": 0.4869992434978485,
      "learning_rate": 1.7065295042148878e-05,
      "loss": 0.2109,
      "step": 10270
    },
    {
      "epoch": 2.2031718816973855,
      "grad_norm": 0.06948366016149521,
      "learning_rate": 1.7062437491070156e-05,
      "loss": 0.2723,
      "step": 10280
    },
    {
      "epoch": 2.2053150450064294,
      "grad_norm": 0.0268719382584095,
      "learning_rate": 1.705957993999143e-05,
      "loss": 0.0019,
      "step": 10290
    },
    {
      "epoch": 2.2074582083154737,
      "grad_norm": 0.5855510234832764,
      "learning_rate": 1.7056722388912703e-05,
      "loss": 0.2211,
      "step": 10300
    },
    {
      "epoch": 2.209601371624518,
      "grad_norm": 8.739855766296387,
      "learning_rate": 1.7053864837833977e-05,
      "loss": 0.2175,
      "step": 10310
    },
    {
      "epoch": 2.211744534933562,
      "grad_norm": 0.08027032017707825,
      "learning_rate": 1.705100728675525e-05,
      "loss": 0.4361,
      "step": 10320
    },
    {
      "epoch": 2.213887698242606,
      "grad_norm": 137.50546264648438,
      "learning_rate": 1.7048149735676525e-05,
      "loss": 0.3002,
      "step": 10330
    },
    {
      "epoch": 2.2160308615516504,
      "grad_norm": 0.10245398432016373,
      "learning_rate": 1.7045292184597803e-05,
      "loss": 0.6688,
      "step": 10340
    },
    {
      "epoch": 2.2181740248606943,
      "grad_norm": 0.03961489722132683,
      "learning_rate": 1.7042434633519076e-05,
      "loss": 0.4506,
      "step": 10350
    },
    {
      "epoch": 2.2203171881697386,
      "grad_norm": 0.07388748228549957,
      "learning_rate": 1.703957708244035e-05,
      "loss": 0.4759,
      "step": 10360
    },
    {
      "epoch": 2.222460351478783,
      "grad_norm": 0.04332079738378525,
      "learning_rate": 1.7036719531361624e-05,
      "loss": 0.0038,
      "step": 10370
    },
    {
      "epoch": 2.2246035147878267,
      "grad_norm": 0.05388335883617401,
      "learning_rate": 1.7033861980282898e-05,
      "loss": 0.2072,
      "step": 10380
    },
    {
      "epoch": 2.226746678096871,
      "grad_norm": 157.2093505859375,
      "learning_rate": 1.7031004429204176e-05,
      "loss": 0.1545,
      "step": 10390
    },
    {
      "epoch": 2.2288898414059153,
      "grad_norm": 24.613040924072266,
      "learning_rate": 1.702814687812545e-05,
      "loss": 0.4608,
      "step": 10400
    },
    {
      "epoch": 2.231033004714959,
      "grad_norm": 0.09964854270219803,
      "learning_rate": 1.7025289327046723e-05,
      "loss": 0.3875,
      "step": 10410
    },
    {
      "epoch": 2.2331761680240034,
      "grad_norm": 0.11968594044446945,
      "learning_rate": 1.7022431775967997e-05,
      "loss": 0.3611,
      "step": 10420
    },
    {
      "epoch": 2.2353193313330477,
      "grad_norm": 103.85935974121094,
      "learning_rate": 1.701957422488927e-05,
      "loss": 0.4975,
      "step": 10430
    },
    {
      "epoch": 2.2374624946420916,
      "grad_norm": 0.18381546437740326,
      "learning_rate": 1.7016716673810545e-05,
      "loss": 0.5173,
      "step": 10440
    },
    {
      "epoch": 2.239605657951136,
      "grad_norm": 0.03378528356552124,
      "learning_rate": 1.701385912273182e-05,
      "loss": 0.0042,
      "step": 10450
    },
    {
      "epoch": 2.24174882126018,
      "grad_norm": 0.08441628515720367,
      "learning_rate": 1.7011001571653093e-05,
      "loss": 0.1936,
      "step": 10460
    },
    {
      "epoch": 2.243891984569224,
      "grad_norm": 0.07469504326581955,
      "learning_rate": 1.7008144020574367e-05,
      "loss": 0.5248,
      "step": 10470
    },
    {
      "epoch": 2.2460351478782683,
      "grad_norm": 17.02988052368164,
      "learning_rate": 1.7005286469495644e-05,
      "loss": 0.3741,
      "step": 10480
    },
    {
      "epoch": 2.2481783111873126,
      "grad_norm": 0.06278204917907715,
      "learning_rate": 1.7002428918416918e-05,
      "loss": 0.092,
      "step": 10490
    },
    {
      "epoch": 2.2503214744963564,
      "grad_norm": 0.023342009633779526,
      "learning_rate": 1.6999571367338192e-05,
      "loss": 0.0017,
      "step": 10500
    },
    {
      "epoch": 2.2524646378054007,
      "grad_norm": 0.06982140243053436,
      "learning_rate": 1.6996713816259466e-05,
      "loss": 0.1998,
      "step": 10510
    },
    {
      "epoch": 2.254607801114445,
      "grad_norm": 0.00979622919112444,
      "learning_rate": 1.699385626518074e-05,
      "loss": 0.0449,
      "step": 10520
    },
    {
      "epoch": 2.256750964423489,
      "grad_norm": 0.12195856869220734,
      "learning_rate": 1.6990998714102017e-05,
      "loss": 0.0009,
      "step": 10530
    },
    {
      "epoch": 2.258894127732533,
      "grad_norm": 17.251827239990234,
      "learning_rate": 1.698814116302329e-05,
      "loss": 0.3832,
      "step": 10540
    },
    {
      "epoch": 2.2610372910415775,
      "grad_norm": 0.01832231692969799,
      "learning_rate": 1.6985283611944565e-05,
      "loss": 0.1293,
      "step": 10550
    },
    {
      "epoch": 2.2631804543506213,
      "grad_norm": 0.028758883476257324,
      "learning_rate": 1.698242606086584e-05,
      "loss": 0.5568,
      "step": 10560
    },
    {
      "epoch": 2.2653236176596656,
      "grad_norm": 0.011415461078286171,
      "learning_rate": 1.6979568509787113e-05,
      "loss": 0.1139,
      "step": 10570
    },
    {
      "epoch": 2.26746678096871,
      "grad_norm": 89.86827087402344,
      "learning_rate": 1.697671095870839e-05,
      "loss": 0.0459,
      "step": 10580
    },
    {
      "epoch": 2.2696099442777538,
      "grad_norm": 0.0068289656192064285,
      "learning_rate": 1.6973853407629664e-05,
      "loss": 0.4058,
      "step": 10590
    },
    {
      "epoch": 2.271753107586798,
      "grad_norm": 0.014313575811684132,
      "learning_rate": 1.6970995856550938e-05,
      "loss": 0.4235,
      "step": 10600
    },
    {
      "epoch": 2.2738962708958423,
      "grad_norm": 49.46659469604492,
      "learning_rate": 1.6968138305472212e-05,
      "loss": 0.54,
      "step": 10610
    },
    {
      "epoch": 2.276039434204886,
      "grad_norm": 0.07992824167013168,
      "learning_rate": 1.6965280754393486e-05,
      "loss": 0.0331,
      "step": 10620
    },
    {
      "epoch": 2.2781825975139305,
      "grad_norm": 0.18302182853221893,
      "learning_rate": 1.696242320331476e-05,
      "loss": 0.252,
      "step": 10630
    },
    {
      "epoch": 2.280325760822975,
      "grad_norm": 40.2685432434082,
      "learning_rate": 1.6959565652236034e-05,
      "loss": 0.1734,
      "step": 10640
    },
    {
      "epoch": 2.2824689241320186,
      "grad_norm": 0.01900443434715271,
      "learning_rate": 1.6956708101157308e-05,
      "loss": 0.3186,
      "step": 10650
    },
    {
      "epoch": 2.284612087441063,
      "grad_norm": 0.024446049705147743,
      "learning_rate": 1.6953850550078582e-05,
      "loss": 0.2131,
      "step": 10660
    },
    {
      "epoch": 2.286755250750107,
      "grad_norm": 0.41977888345718384,
      "learning_rate": 1.695099299899986e-05,
      "loss": 0.0546,
      "step": 10670
    },
    {
      "epoch": 2.288898414059151,
      "grad_norm": 0.01907859556376934,
      "learning_rate": 1.6948135447921133e-05,
      "loss": 0.0041,
      "step": 10680
    },
    {
      "epoch": 2.2910415773681954,
      "grad_norm": 0.13967986404895782,
      "learning_rate": 1.6945277896842407e-05,
      "loss": 0.0014,
      "step": 10690
    },
    {
      "epoch": 2.2931847406772397,
      "grad_norm": 0.017278684303164482,
      "learning_rate": 1.694242034576368e-05,
      "loss": 0.1029,
      "step": 10700
    },
    {
      "epoch": 2.295327903986284,
      "grad_norm": 35.87969970703125,
      "learning_rate": 1.6939562794684955e-05,
      "loss": 0.2161,
      "step": 10710
    },
    {
      "epoch": 2.297471067295328,
      "grad_norm": 0.05808785930275917,
      "learning_rate": 1.6936705243606232e-05,
      "loss": 0.5086,
      "step": 10720
    },
    {
      "epoch": 2.299614230604372,
      "grad_norm": 0.4833357632160187,
      "learning_rate": 1.6933847692527506e-05,
      "loss": 0.1793,
      "step": 10730
    },
    {
      "epoch": 2.3017573939134164,
      "grad_norm": 14.591466903686523,
      "learning_rate": 1.693099014144878e-05,
      "loss": 0.4685,
      "step": 10740
    },
    {
      "epoch": 2.3039005572224602,
      "grad_norm": 0.23473481833934784,
      "learning_rate": 1.6928132590370054e-05,
      "loss": 0.3489,
      "step": 10750
    },
    {
      "epoch": 2.3060437205315045,
      "grad_norm": 0.29591912031173706,
      "learning_rate": 1.6925275039291328e-05,
      "loss": 0.4278,
      "step": 10760
    },
    {
      "epoch": 2.308186883840549,
      "grad_norm": 0.04979828745126724,
      "learning_rate": 1.6922417488212605e-05,
      "loss": 0.6157,
      "step": 10770
    },
    {
      "epoch": 2.3103300471495927,
      "grad_norm": 36.277950286865234,
      "learning_rate": 1.691955993713388e-05,
      "loss": 0.2626,
      "step": 10780
    },
    {
      "epoch": 2.312473210458637,
      "grad_norm": 0.09551309794187546,
      "learning_rate": 1.6916702386055153e-05,
      "loss": 0.2799,
      "step": 10790
    },
    {
      "epoch": 2.3146163737676813,
      "grad_norm": 0.21356353163719177,
      "learning_rate": 1.6913844834976427e-05,
      "loss": 0.2383,
      "step": 10800
    },
    {
      "epoch": 2.316759537076725,
      "grad_norm": 0.01735595241189003,
      "learning_rate": 1.69109872838977e-05,
      "loss": 0.1158,
      "step": 10810
    },
    {
      "epoch": 2.3189027003857694,
      "grad_norm": 99.1656723022461,
      "learning_rate": 1.6908129732818975e-05,
      "loss": 0.2989,
      "step": 10820
    },
    {
      "epoch": 2.3210458636948137,
      "grad_norm": 35.503963470458984,
      "learning_rate": 1.6905272181740252e-05,
      "loss": 0.585,
      "step": 10830
    },
    {
      "epoch": 2.3231890270038575,
      "grad_norm": 27.845260620117188,
      "learning_rate": 1.6902414630661526e-05,
      "loss": 0.2507,
      "step": 10840
    },
    {
      "epoch": 2.325332190312902,
      "grad_norm": 0.26543235778808594,
      "learning_rate": 1.6899557079582797e-05,
      "loss": 0.1985,
      "step": 10850
    },
    {
      "epoch": 2.327475353621946,
      "grad_norm": 0.01599845662713051,
      "learning_rate": 1.6896699528504074e-05,
      "loss": 0.3369,
      "step": 10860
    },
    {
      "epoch": 2.32961851693099,
      "grad_norm": 0.0056180404499173164,
      "learning_rate": 1.6893841977425348e-05,
      "loss": 0.0545,
      "step": 10870
    },
    {
      "epoch": 2.3317616802400343,
      "grad_norm": 93.41464233398438,
      "learning_rate": 1.6890984426346622e-05,
      "loss": 0.3289,
      "step": 10880
    },
    {
      "epoch": 2.3339048435490786,
      "grad_norm": 0.01900424435734749,
      "learning_rate": 1.6888126875267896e-05,
      "loss": 0.481,
      "step": 10890
    },
    {
      "epoch": 2.3360480068581224,
      "grad_norm": 0.02465706318616867,
      "learning_rate": 1.688526932418917e-05,
      "loss": 0.0052,
      "step": 10900
    },
    {
      "epoch": 2.3381911701671667,
      "grad_norm": 0.06567861884832382,
      "learning_rate": 1.6882411773110447e-05,
      "loss": 0.0028,
      "step": 10910
    },
    {
      "epoch": 2.340334333476211,
      "grad_norm": 0.00909484550356865,
      "learning_rate": 1.687955422203172e-05,
      "loss": 0.476,
      "step": 10920
    },
    {
      "epoch": 2.342477496785255,
      "grad_norm": 0.033956997096538544,
      "learning_rate": 1.6876696670952995e-05,
      "loss": 0.5425,
      "step": 10930
    },
    {
      "epoch": 2.344620660094299,
      "grad_norm": 0.04541141167283058,
      "learning_rate": 1.687383911987427e-05,
      "loss": 0.4157,
      "step": 10940
    },
    {
      "epoch": 2.3467638234033434,
      "grad_norm": 35.6058349609375,
      "learning_rate": 1.6870981568795543e-05,
      "loss": 0.1764,
      "step": 10950
    },
    {
      "epoch": 2.3489069867123873,
      "grad_norm": 0.1846158653497696,
      "learning_rate": 1.6868124017716817e-05,
      "loss": 0.332,
      "step": 10960
    },
    {
      "epoch": 2.3510501500214316,
      "grad_norm": 5.714733123779297,
      "learning_rate": 1.6865266466638094e-05,
      "loss": 0.2011,
      "step": 10970
    },
    {
      "epoch": 2.353193313330476,
      "grad_norm": 0.10631313174962997,
      "learning_rate": 1.6862408915559368e-05,
      "loss": 0.2056,
      "step": 10980
    },
    {
      "epoch": 2.35533647663952,
      "grad_norm": 23.769834518432617,
      "learning_rate": 1.6859551364480642e-05,
      "loss": 0.4967,
      "step": 10990
    },
    {
      "epoch": 2.357479639948564,
      "grad_norm": 6.613845348358154,
      "learning_rate": 1.6856693813401916e-05,
      "loss": 0.3611,
      "step": 11000
    },
    {
      "epoch": 2.3596228032576083,
      "grad_norm": 7.367878437042236,
      "learning_rate": 1.685383626232319e-05,
      "loss": 0.188,
      "step": 11010
    },
    {
      "epoch": 2.3617659665666526,
      "grad_norm": 0.05738874152302742,
      "learning_rate": 1.6850978711244467e-05,
      "loss": 0.1004,
      "step": 11020
    },
    {
      "epoch": 2.3639091298756965,
      "grad_norm": 23.964006423950195,
      "learning_rate": 1.684812116016574e-05,
      "loss": 0.6249,
      "step": 11030
    },
    {
      "epoch": 2.3660522931847408,
      "grad_norm": 0.4510788321495056,
      "learning_rate": 1.6845263609087015e-05,
      "loss": 0.0549,
      "step": 11040
    },
    {
      "epoch": 2.368195456493785,
      "grad_norm": 0.2076297402381897,
      "learning_rate": 1.684240605800829e-05,
      "loss": 0.3147,
      "step": 11050
    },
    {
      "epoch": 2.370338619802829,
      "grad_norm": 0.030539553612470627,
      "learning_rate": 1.6839548506929563e-05,
      "loss": 0.1108,
      "step": 11060
    },
    {
      "epoch": 2.372481783111873,
      "grad_norm": 0.029166026040911674,
      "learning_rate": 1.6836690955850837e-05,
      "loss": 0.2808,
      "step": 11070
    },
    {
      "epoch": 2.3746249464209175,
      "grad_norm": 46.48503494262695,
      "learning_rate": 1.683383340477211e-05,
      "loss": 0.2342,
      "step": 11080
    },
    {
      "epoch": 2.3767681097299613,
      "grad_norm": 0.18481026589870453,
      "learning_rate": 1.6830975853693384e-05,
      "loss": 0.2655,
      "step": 11090
    },
    {
      "epoch": 2.3789112730390056,
      "grad_norm": 0.8682899475097656,
      "learning_rate": 1.682811830261466e-05,
      "loss": 0.0031,
      "step": 11100
    },
    {
      "epoch": 2.38105443634805,
      "grad_norm": 0.5398343801498413,
      "learning_rate": 1.6825260751535936e-05,
      "loss": 0.2009,
      "step": 11110
    },
    {
      "epoch": 2.3831975996570938,
      "grad_norm": 0.010760949924588203,
      "learning_rate": 1.682240320045721e-05,
      "loss": 0.2335,
      "step": 11120
    },
    {
      "epoch": 2.385340762966138,
      "grad_norm": 0.06472846865653992,
      "learning_rate": 1.6819545649378484e-05,
      "loss": 0.2709,
      "step": 11130
    },
    {
      "epoch": 2.3874839262751824,
      "grad_norm": 0.020882409065961838,
      "learning_rate": 1.6816688098299757e-05,
      "loss": 0.5697,
      "step": 11140
    },
    {
      "epoch": 2.389627089584226,
      "grad_norm": 0.12958036363124847,
      "learning_rate": 1.681383054722103e-05,
      "loss": 0.2242,
      "step": 11150
    },
    {
      "epoch": 2.3917702528932705,
      "grad_norm": 0.03161253780126572,
      "learning_rate": 1.681097299614231e-05,
      "loss": 0.001,
      "step": 11160
    },
    {
      "epoch": 2.393913416202315,
      "grad_norm": 24.21997833251953,
      "learning_rate": 1.6808115445063583e-05,
      "loss": 0.4338,
      "step": 11170
    },
    {
      "epoch": 2.3960565795113586,
      "grad_norm": 0.08144771307706833,
      "learning_rate": 1.6805257893984857e-05,
      "loss": 0.1091,
      "step": 11180
    },
    {
      "epoch": 2.398199742820403,
      "grad_norm": 0.054572127759456635,
      "learning_rate": 1.680240034290613e-05,
      "loss": 0.0074,
      "step": 11190
    },
    {
      "epoch": 2.4003429061294472,
      "grad_norm": 0.06292050331830978,
      "learning_rate": 1.6799542791827404e-05,
      "loss": 0.3638,
      "step": 11200
    },
    {
      "epoch": 2.402486069438491,
      "grad_norm": 0.0647512748837471,
      "learning_rate": 1.6796685240748682e-05,
      "loss": 0.8913,
      "step": 11210
    },
    {
      "epoch": 2.4046292327475354,
      "grad_norm": 0.1779502034187317,
      "learning_rate": 1.6793827689669956e-05,
      "loss": 0.4071,
      "step": 11220
    },
    {
      "epoch": 2.4067723960565797,
      "grad_norm": 37.30427932739258,
      "learning_rate": 1.679097013859123e-05,
      "loss": 0.3018,
      "step": 11230
    },
    {
      "epoch": 2.4089155593656235,
      "grad_norm": 0.13000576198101044,
      "learning_rate": 1.6788112587512503e-05,
      "loss": 0.7719,
      "step": 11240
    },
    {
      "epoch": 2.411058722674668,
      "grad_norm": 0.3155529201030731,
      "learning_rate": 1.6785255036433777e-05,
      "loss": 0.0035,
      "step": 11250
    },
    {
      "epoch": 2.413201885983712,
      "grad_norm": 0.4765133261680603,
      "learning_rate": 1.6782397485355055e-05,
      "loss": 0.4686,
      "step": 11260
    },
    {
      "epoch": 2.415345049292756,
      "grad_norm": 22.069812774658203,
      "learning_rate": 1.677953993427633e-05,
      "loss": 0.3378,
      "step": 11270
    },
    {
      "epoch": 2.4174882126018002,
      "grad_norm": 0.23599673807621002,
      "learning_rate": 1.67766823831976e-05,
      "loss": 0.2599,
      "step": 11280
    },
    {
      "epoch": 2.4196313759108445,
      "grad_norm": 0.24776914715766907,
      "learning_rate": 1.6773824832118873e-05,
      "loss": 0.4439,
      "step": 11290
    },
    {
      "epoch": 2.4217745392198884,
      "grad_norm": 18.5379581451416,
      "learning_rate": 1.677096728104015e-05,
      "loss": 0.4186,
      "step": 11300
    },
    {
      "epoch": 2.4239177025289327,
      "grad_norm": 0.08665060997009277,
      "learning_rate": 1.6768109729961424e-05,
      "loss": 0.0021,
      "step": 11310
    },
    {
      "epoch": 2.426060865837977,
      "grad_norm": 0.049837417900562286,
      "learning_rate": 1.6765252178882698e-05,
      "loss": 0.3368,
      "step": 11320
    },
    {
      "epoch": 2.428204029147021,
      "grad_norm": 31.267234802246094,
      "learning_rate": 1.6762394627803972e-05,
      "loss": 0.4996,
      "step": 11330
    },
    {
      "epoch": 2.430347192456065,
      "grad_norm": 0.06914122402667999,
      "learning_rate": 1.6759537076725246e-05,
      "loss": 0.5495,
      "step": 11340
    },
    {
      "epoch": 2.4324903557651094,
      "grad_norm": 0.15544895827770233,
      "learning_rate": 1.6756679525646523e-05,
      "loss": 0.327,
      "step": 11350
    },
    {
      "epoch": 2.4346335190741533,
      "grad_norm": 0.04455792158842087,
      "learning_rate": 1.6753821974567797e-05,
      "loss": 0.1661,
      "step": 11360
    },
    {
      "epoch": 2.4367766823831976,
      "grad_norm": 0.06637398153543472,
      "learning_rate": 1.675096442348907e-05,
      "loss": 0.2729,
      "step": 11370
    },
    {
      "epoch": 2.438919845692242,
      "grad_norm": 0.04622325301170349,
      "learning_rate": 1.6748106872410345e-05,
      "loss": 0.4117,
      "step": 11380
    },
    {
      "epoch": 2.4410630090012857,
      "grad_norm": 0.13245545327663422,
      "learning_rate": 1.674524932133162e-05,
      "loss": 0.4951,
      "step": 11390
    },
    {
      "epoch": 2.44320617231033,
      "grad_norm": 0.10078559815883636,
      "learning_rate": 1.6742391770252897e-05,
      "loss": 0.1936,
      "step": 11400
    },
    {
      "epoch": 2.4453493356193743,
      "grad_norm": 0.05995798483490944,
      "learning_rate": 1.673953421917417e-05,
      "loss": 0.4165,
      "step": 11410
    },
    {
      "epoch": 2.447492498928418,
      "grad_norm": 0.0645148754119873,
      "learning_rate": 1.6736676668095444e-05,
      "loss": 0.4857,
      "step": 11420
    },
    {
      "epoch": 2.4496356622374624,
      "grad_norm": 0.22017917037010193,
      "learning_rate": 1.6733819117016718e-05,
      "loss": 0.1035,
      "step": 11430
    },
    {
      "epoch": 2.4517788255465067,
      "grad_norm": 0.02858579345047474,
      "learning_rate": 1.6730961565937992e-05,
      "loss": 0.4847,
      "step": 11440
    },
    {
      "epoch": 2.4539219888555506,
      "grad_norm": 0.5131778717041016,
      "learning_rate": 1.6728104014859266e-05,
      "loss": 0.2973,
      "step": 11450
    },
    {
      "epoch": 2.456065152164595,
      "grad_norm": 0.01827092096209526,
      "learning_rate": 1.6725246463780543e-05,
      "loss": 0.1237,
      "step": 11460
    },
    {
      "epoch": 2.458208315473639,
      "grad_norm": 0.02453981526196003,
      "learning_rate": 1.6722388912701817e-05,
      "loss": 0.4191,
      "step": 11470
    },
    {
      "epoch": 2.460351478782683,
      "grad_norm": 7.075181007385254,
      "learning_rate": 1.671953136162309e-05,
      "loss": 0.1277,
      "step": 11480
    },
    {
      "epoch": 2.4624946420917273,
      "grad_norm": 0.030767099931836128,
      "learning_rate": 1.6716673810544365e-05,
      "loss": 0.5368,
      "step": 11490
    },
    {
      "epoch": 2.4646378054007716,
      "grad_norm": 0.06578755378723145,
      "learning_rate": 1.671381625946564e-05,
      "loss": 0.1333,
      "step": 11500
    },
    {
      "epoch": 2.4667809687098154,
      "grad_norm": 0.07773672789335251,
      "learning_rate": 1.6710958708386913e-05,
      "loss": 0.262,
      "step": 11510
    },
    {
      "epoch": 2.4689241320188597,
      "grad_norm": 0.026036614552140236,
      "learning_rate": 1.6708101157308187e-05,
      "loss": 0.0027,
      "step": 11520
    },
    {
      "epoch": 2.471067295327904,
      "grad_norm": 0.020263830199837685,
      "learning_rate": 1.670524360622946e-05,
      "loss": 0.6773,
      "step": 11530
    },
    {
      "epoch": 2.4732104586369483,
      "grad_norm": 0.3853636085987091,
      "learning_rate": 1.6702386055150738e-05,
      "loss": 0.4223,
      "step": 11540
    },
    {
      "epoch": 2.475353621945992,
      "grad_norm": 0.24326549470424652,
      "learning_rate": 1.6699528504072012e-05,
      "loss": 0.6502,
      "step": 11550
    },
    {
      "epoch": 2.4774967852550365,
      "grad_norm": 0.6647844314575195,
      "learning_rate": 1.6696670952993286e-05,
      "loss": 0.0035,
      "step": 11560
    },
    {
      "epoch": 2.4796399485640808,
      "grad_norm": 23.377988815307617,
      "learning_rate": 1.669381340191456e-05,
      "loss": 0.6805,
      "step": 11570
    },
    {
      "epoch": 2.4817831118731246,
      "grad_norm": 0.5454700589179993,
      "learning_rate": 1.6690955850835834e-05,
      "loss": 0.6016,
      "step": 11580
    },
    {
      "epoch": 2.483926275182169,
      "grad_norm": 1.0735700130462646,
      "learning_rate": 1.6688098299757108e-05,
      "loss": 0.5561,
      "step": 11590
    },
    {
      "epoch": 2.486069438491213,
      "grad_norm": 123.36949920654297,
      "learning_rate": 1.6685240748678385e-05,
      "loss": 0.2815,
      "step": 11600
    },
    {
      "epoch": 2.488212601800257,
      "grad_norm": 77.79338073730469,
      "learning_rate": 1.668238319759966e-05,
      "loss": 0.576,
      "step": 11610
    },
    {
      "epoch": 2.4903557651093013,
      "grad_norm": 0.2975201904773712,
      "learning_rate": 1.6679525646520933e-05,
      "loss": 0.0041,
      "step": 11620
    },
    {
      "epoch": 2.4924989284183456,
      "grad_norm": 1.6073616743087769,
      "learning_rate": 1.6676668095442207e-05,
      "loss": 0.3656,
      "step": 11630
    },
    {
      "epoch": 2.4946420917273895,
      "grad_norm": 0.10042639821767807,
      "learning_rate": 1.667381054436348e-05,
      "loss": 0.003,
      "step": 11640
    },
    {
      "epoch": 2.496785255036434,
      "grad_norm": 0.0158802792429924,
      "learning_rate": 1.6670952993284758e-05,
      "loss": 0.3936,
      "step": 11650
    },
    {
      "epoch": 2.498928418345478,
      "grad_norm": 0.08287828415632248,
      "learning_rate": 1.6668095442206032e-05,
      "loss": 0.2997,
      "step": 11660
    },
    {
      "epoch": 2.501071581654522,
      "grad_norm": 44.07909393310547,
      "learning_rate": 1.6665237891127306e-05,
      "loss": 0.0279,
      "step": 11670
    },
    {
      "epoch": 2.503214744963566,
      "grad_norm": 0.016447249799966812,
      "learning_rate": 1.666238034004858e-05,
      "loss": 0.4048,
      "step": 11680
    },
    {
      "epoch": 2.5053579082726105,
      "grad_norm": 0.06974679231643677,
      "learning_rate": 1.6659522788969854e-05,
      "loss": 0.2496,
      "step": 11690
    },
    {
      "epoch": 2.5075010715816544,
      "grad_norm": 0.03137408196926117,
      "learning_rate": 1.665666523789113e-05,
      "loss": 0.4663,
      "step": 11700
    },
    {
      "epoch": 2.5096442348906987,
      "grad_norm": 0.030557449907064438,
      "learning_rate": 1.6653807686812402e-05,
      "loss": 0.1428,
      "step": 11710
    },
    {
      "epoch": 2.511787398199743,
      "grad_norm": 25.2139835357666,
      "learning_rate": 1.6650950135733676e-05,
      "loss": 0.2658,
      "step": 11720
    },
    {
      "epoch": 2.5139305615087872,
      "grad_norm": 0.025526612997055054,
      "learning_rate": 1.664809258465495e-05,
      "loss": 0.1395,
      "step": 11730
    },
    {
      "epoch": 2.516073724817831,
      "grad_norm": 12.841437339782715,
      "learning_rate": 1.6645235033576227e-05,
      "loss": 0.0114,
      "step": 11740
    },
    {
      "epoch": 2.5182168881268754,
      "grad_norm": 0.04089746251702309,
      "learning_rate": 1.66423774824975e-05,
      "loss": 0.4346,
      "step": 11750
    },
    {
      "epoch": 2.5203600514359197,
      "grad_norm": 0.12572619318962097,
      "learning_rate": 1.6639519931418775e-05,
      "loss": 0.4904,
      "step": 11760
    },
    {
      "epoch": 2.5225032147449635,
      "grad_norm": 19.21799087524414,
      "learning_rate": 1.663666238034005e-05,
      "loss": 0.5762,
      "step": 11770
    },
    {
      "epoch": 2.524646378054008,
      "grad_norm": 0.10487924516201019,
      "learning_rate": 1.6633804829261323e-05,
      "loss": 0.1694,
      "step": 11780
    },
    {
      "epoch": 2.526789541363052,
      "grad_norm": 0.2559908628463745,
      "learning_rate": 1.66309472781826e-05,
      "loss": 0.343,
      "step": 11790
    },
    {
      "epoch": 2.528932704672096,
      "grad_norm": 0.1305934190750122,
      "learning_rate": 1.6628089727103874e-05,
      "loss": 0.267,
      "step": 11800
    },
    {
      "epoch": 2.5310758679811403,
      "grad_norm": 71.16045379638672,
      "learning_rate": 1.6625232176025148e-05,
      "loss": 0.2424,
      "step": 11810
    },
    {
      "epoch": 2.5332190312901846,
      "grad_norm": 0.1317012757062912,
      "learning_rate": 1.6622374624946422e-05,
      "loss": 0.0018,
      "step": 11820
    },
    {
      "epoch": 2.5353621945992284,
      "grad_norm": 1.186767578125,
      "learning_rate": 1.6619517073867696e-05,
      "loss": 0.2547,
      "step": 11830
    },
    {
      "epoch": 2.5375053579082727,
      "grad_norm": 0.021520959213376045,
      "learning_rate": 1.6616659522788973e-05,
      "loss": 0.44,
      "step": 11840
    },
    {
      "epoch": 2.539648521217317,
      "grad_norm": 0.0066298567689955235,
      "learning_rate": 1.6613801971710247e-05,
      "loss": 0.6285,
      "step": 11850
    },
    {
      "epoch": 2.541791684526361,
      "grad_norm": 0.018536854535341263,
      "learning_rate": 1.661094442063152e-05,
      "loss": 0.2128,
      "step": 11860
    },
    {
      "epoch": 2.543934847835405,
      "grad_norm": 34.644351959228516,
      "learning_rate": 1.6608086869552795e-05,
      "loss": 1.1977,
      "step": 11870
    },
    {
      "epoch": 2.5460780111444494,
      "grad_norm": 0.058641381561756134,
      "learning_rate": 1.660522931847407e-05,
      "loss": 0.205,
      "step": 11880
    },
    {
      "epoch": 2.5482211744534933,
      "grad_norm": 0.07894665002822876,
      "learning_rate": 1.6602371767395343e-05,
      "loss": 0.0829,
      "step": 11890
    },
    {
      "epoch": 2.5503643377625376,
      "grad_norm": 37.12331008911133,
      "learning_rate": 1.659951421631662e-05,
      "loss": 0.7561,
      "step": 11900
    },
    {
      "epoch": 2.552507501071582,
      "grad_norm": 14.574629783630371,
      "learning_rate": 1.6596656665237894e-05,
      "loss": 0.3002,
      "step": 11910
    },
    {
      "epoch": 2.5546506643806257,
      "grad_norm": 33.180572509765625,
      "learning_rate": 1.6593799114159164e-05,
      "loss": 0.3464,
      "step": 11920
    },
    {
      "epoch": 2.55679382768967,
      "grad_norm": 0.1151566207408905,
      "learning_rate": 1.6590941563080442e-05,
      "loss": 0.331,
      "step": 11930
    },
    {
      "epoch": 2.5589369909987143,
      "grad_norm": 56.44569396972656,
      "learning_rate": 1.6588084012001716e-05,
      "loss": 0.1055,
      "step": 11940
    },
    {
      "epoch": 2.561080154307758,
      "grad_norm": 17.9686279296875,
      "learning_rate": 1.658522646092299e-05,
      "loss": 0.6702,
      "step": 11950
    },
    {
      "epoch": 2.5632233176168024,
      "grad_norm": 0.11957251280546188,
      "learning_rate": 1.6582368909844264e-05,
      "loss": 0.0069,
      "step": 11960
    },
    {
      "epoch": 2.5653664809258467,
      "grad_norm": 0.09454411268234253,
      "learning_rate": 1.6579511358765538e-05,
      "loss": 0.416,
      "step": 11970
    },
    {
      "epoch": 2.5675096442348906,
      "grad_norm": 0.036005549132823944,
      "learning_rate": 1.6576653807686815e-05,
      "loss": 0.1589,
      "step": 11980
    },
    {
      "epoch": 2.569652807543935,
      "grad_norm": 0.23855875432491302,
      "learning_rate": 1.657379625660809e-05,
      "loss": 0.0113,
      "step": 11990
    },
    {
      "epoch": 2.571795970852979,
      "grad_norm": 0.0748424381017685,
      "learning_rate": 1.6570938705529363e-05,
      "loss": 0.3778,
      "step": 12000
    },
    {
      "epoch": 2.573939134162023,
      "grad_norm": 0.136992946267128,
      "learning_rate": 1.6568081154450637e-05,
      "loss": 0.1446,
      "step": 12010
    },
    {
      "epoch": 2.5760822974710673,
      "grad_norm": 0.27893030643463135,
      "learning_rate": 1.656522360337191e-05,
      "loss": 0.6571,
      "step": 12020
    },
    {
      "epoch": 2.5782254607801116,
      "grad_norm": 0.014597431756556034,
      "learning_rate": 1.6562366052293184e-05,
      "loss": 0.2449,
      "step": 12030
    },
    {
      "epoch": 2.5803686240891555,
      "grad_norm": 77.43806457519531,
      "learning_rate": 1.6559508501214462e-05,
      "loss": 0.6034,
      "step": 12040
    },
    {
      "epoch": 2.5825117873981998,
      "grad_norm": 0.015277083963155746,
      "learning_rate": 1.6556650950135736e-05,
      "loss": 0.2549,
      "step": 12050
    },
    {
      "epoch": 2.584654950707244,
      "grad_norm": 3.0322139263153076,
      "learning_rate": 1.655379339905701e-05,
      "loss": 0.4755,
      "step": 12060
    },
    {
      "epoch": 2.586798114016288,
      "grad_norm": 0.02522883750498295,
      "learning_rate": 1.6550935847978284e-05,
      "loss": 0.2113,
      "step": 12070
    },
    {
      "epoch": 2.588941277325332,
      "grad_norm": 0.031406331807374954,
      "learning_rate": 1.6548078296899558e-05,
      "loss": 0.1015,
      "step": 12080
    },
    {
      "epoch": 2.5910844406343765,
      "grad_norm": 0.016018306836485863,
      "learning_rate": 1.6545220745820835e-05,
      "loss": 0.2397,
      "step": 12090
    },
    {
      "epoch": 2.5932276039434203,
      "grad_norm": 0.031208228319883347,
      "learning_rate": 1.654236319474211e-05,
      "loss": 0.0558,
      "step": 12100
    },
    {
      "epoch": 2.5953707672524646,
      "grad_norm": 0.015608897432684898,
      "learning_rate": 1.6539505643663383e-05,
      "loss": 0.1528,
      "step": 12110
    },
    {
      "epoch": 2.597513930561509,
      "grad_norm": 0.05883025750517845,
      "learning_rate": 1.6536648092584657e-05,
      "loss": 0.4056,
      "step": 12120
    },
    {
      "epoch": 2.5996570938705528,
      "grad_norm": 0.058898407965898514,
      "learning_rate": 1.653379054150593e-05,
      "loss": 0.0193,
      "step": 12130
    },
    {
      "epoch": 2.601800257179597,
      "grad_norm": 0.015620231628417969,
      "learning_rate": 1.6530932990427204e-05,
      "loss": 0.2466,
      "step": 12140
    },
    {
      "epoch": 2.6039434204886414,
      "grad_norm": 0.019647905603051186,
      "learning_rate": 1.652807543934848e-05,
      "loss": 0.513,
      "step": 12150
    },
    {
      "epoch": 2.606086583797685,
      "grad_norm": 0.025752898305654526,
      "learning_rate": 1.6525217888269752e-05,
      "loss": 0.2322,
      "step": 12160
    },
    {
      "epoch": 2.6082297471067295,
      "grad_norm": 0.018605446442961693,
      "learning_rate": 1.6522360337191026e-05,
      "loss": 0.0041,
      "step": 12170
    },
    {
      "epoch": 2.610372910415774,
      "grad_norm": 65.85626220703125,
      "learning_rate": 1.6519502786112304e-05,
      "loss": 0.9462,
      "step": 12180
    },
    {
      "epoch": 2.6125160737248176,
      "grad_norm": 0.05181948468089104,
      "learning_rate": 1.6516645235033577e-05,
      "loss": 0.2114,
      "step": 12190
    },
    {
      "epoch": 2.614659237033862,
      "grad_norm": 0.11075667291879654,
      "learning_rate": 1.651378768395485e-05,
      "loss": 0.3577,
      "step": 12200
    },
    {
      "epoch": 2.6168024003429062,
      "grad_norm": 0.04533093050122261,
      "learning_rate": 1.6510930132876125e-05,
      "loss": 0.2131,
      "step": 12210
    },
    {
      "epoch": 2.61894556365195,
      "grad_norm": 0.3263629078865051,
      "learning_rate": 1.65080725817974e-05,
      "loss": 0.26,
      "step": 12220
    },
    {
      "epoch": 2.6210887269609944,
      "grad_norm": 21.416566848754883,
      "learning_rate": 1.6505215030718677e-05,
      "loss": 0.7136,
      "step": 12230
    },
    {
      "epoch": 2.6232318902700387,
      "grad_norm": 0.3072162866592407,
      "learning_rate": 1.650235747963995e-05,
      "loss": 0.6238,
      "step": 12240
    },
    {
      "epoch": 2.6253750535790825,
      "grad_norm": 49.68058776855469,
      "learning_rate": 1.6499499928561224e-05,
      "loss": 0.2087,
      "step": 12250
    },
    {
      "epoch": 2.627518216888127,
      "grad_norm": 0.12460976094007492,
      "learning_rate": 1.64966423774825e-05,
      "loss": 0.0065,
      "step": 12260
    },
    {
      "epoch": 2.629661380197171,
      "grad_norm": 0.04484311118721962,
      "learning_rate": 1.6493784826403772e-05,
      "loss": 0.0021,
      "step": 12270
    },
    {
      "epoch": 2.631804543506215,
      "grad_norm": 0.03430145978927612,
      "learning_rate": 1.649092727532505e-05,
      "loss": 0.2056,
      "step": 12280
    },
    {
      "epoch": 2.6339477068152592,
      "grad_norm": 0.17437981069087982,
      "learning_rate": 1.6488069724246324e-05,
      "loss": 1.0659,
      "step": 12290
    },
    {
      "epoch": 2.6360908701243035,
      "grad_norm": 58.006744384765625,
      "learning_rate": 1.6485212173167597e-05,
      "loss": 0.8485,
      "step": 12300
    },
    {
      "epoch": 2.6382340334333474,
      "grad_norm": 51.912620544433594,
      "learning_rate": 1.648235462208887e-05,
      "loss": 0.5894,
      "step": 12310
    },
    {
      "epoch": 2.6403771967423917,
      "grad_norm": 0.04382299259305,
      "learning_rate": 1.6479497071010145e-05,
      "loss": 0.2441,
      "step": 12320
    },
    {
      "epoch": 2.642520360051436,
      "grad_norm": 0.09707587212324142,
      "learning_rate": 1.6476639519931423e-05,
      "loss": 0.5208,
      "step": 12330
    },
    {
      "epoch": 2.64466352336048,
      "grad_norm": 155.41026306152344,
      "learning_rate": 1.6473781968852697e-05,
      "loss": 0.3648,
      "step": 12340
    },
    {
      "epoch": 2.646806686669524,
      "grad_norm": 0.16447076201438904,
      "learning_rate": 1.6470924417773967e-05,
      "loss": 0.1539,
      "step": 12350
    },
    {
      "epoch": 2.6489498499785684,
      "grad_norm": 0.15818873047828674,
      "learning_rate": 1.646806686669524e-05,
      "loss": 0.0088,
      "step": 12360
    },
    {
      "epoch": 2.6510930132876123,
      "grad_norm": 0.02806420624256134,
      "learning_rate": 1.646520931561652e-05,
      "loss": 0.0218,
      "step": 12370
    },
    {
      "epoch": 2.6532361765966566,
      "grad_norm": 0.006268777884542942,
      "learning_rate": 1.6462351764537792e-05,
      "loss": 0.0161,
      "step": 12380
    },
    {
      "epoch": 2.655379339905701,
      "grad_norm": 0.013113525696098804,
      "learning_rate": 1.6459494213459066e-05,
      "loss": 0.1926,
      "step": 12390
    },
    {
      "epoch": 2.6575225032147447,
      "grad_norm": 0.004403586499392986,
      "learning_rate": 1.645663666238034e-05,
      "loss": 0.0009,
      "step": 12400
    },
    {
      "epoch": 2.659665666523789,
      "grad_norm": 36.18167495727539,
      "learning_rate": 1.6453779111301614e-05,
      "loss": 0.6933,
      "step": 12410
    },
    {
      "epoch": 2.6618088298328333,
      "grad_norm": 0.020498031750321388,
      "learning_rate": 1.645092156022289e-05,
      "loss": 0.0057,
      "step": 12420
    },
    {
      "epoch": 2.663951993141877,
      "grad_norm": 0.013306117616593838,
      "learning_rate": 1.6448064009144165e-05,
      "loss": 0.0309,
      "step": 12430
    },
    {
      "epoch": 2.6660951564509214,
      "grad_norm": 9.147738456726074,
      "learning_rate": 1.644520645806544e-05,
      "loss": 0.0095,
      "step": 12440
    },
    {
      "epoch": 2.6682383197599657,
      "grad_norm": 0.019724104553461075,
      "learning_rate": 1.6442348906986713e-05,
      "loss": 0.0008,
      "step": 12450
    },
    {
      "epoch": 2.67038148306901,
      "grad_norm": 50.80664825439453,
      "learning_rate": 1.6439491355907987e-05,
      "loss": 0.0212,
      "step": 12460
    },
    {
      "epoch": 2.672524646378054,
      "grad_norm": 28.131093978881836,
      "learning_rate": 1.6436633804829264e-05,
      "loss": 0.4621,
      "step": 12470
    },
    {
      "epoch": 2.674667809687098,
      "grad_norm": 0.0033719660714268684,
      "learning_rate": 1.643377625375054e-05,
      "loss": 0.5722,
      "step": 12480
    },
    {
      "epoch": 2.6768109729961425,
      "grad_norm": 0.024342939257621765,
      "learning_rate": 1.6430918702671812e-05,
      "loss": 0.3507,
      "step": 12490
    },
    {
      "epoch": 2.6789541363051863,
      "grad_norm": 0.008500246331095695,
      "learning_rate": 1.6428061151593086e-05,
      "loss": 0.1155,
      "step": 12500
    },
    {
      "epoch": 2.6810972996142306,
      "grad_norm": 0.014420263469219208,
      "learning_rate": 1.642520360051436e-05,
      "loss": 0.0133,
      "step": 12510
    },
    {
      "epoch": 2.683240462923275,
      "grad_norm": 0.006102058570832014,
      "learning_rate": 1.6422346049435634e-05,
      "loss": 0.1427,
      "step": 12520
    },
    {
      "epoch": 2.6853836262323187,
      "grad_norm": 0.022301599383354187,
      "learning_rate": 1.641948849835691e-05,
      "loss": 0.2235,
      "step": 12530
    },
    {
      "epoch": 2.687526789541363,
      "grad_norm": 0.007238276302814484,
      "learning_rate": 1.6416630947278185e-05,
      "loss": 0.0978,
      "step": 12540
    },
    {
      "epoch": 2.6896699528504073,
      "grad_norm": 0.0454179085791111,
      "learning_rate": 1.641377339619946e-05,
      "loss": 0.0103,
      "step": 12550
    },
    {
      "epoch": 2.6918131161594516,
      "grad_norm": 0.010382795706391335,
      "learning_rate": 1.6410915845120733e-05,
      "loss": 0.3939,
      "step": 12560
    },
    {
      "epoch": 2.6939562794684955,
      "grad_norm": 0.05109254643321037,
      "learning_rate": 1.6408058294042007e-05,
      "loss": 0.0375,
      "step": 12570
    },
    {
      "epoch": 2.6960994427775398,
      "grad_norm": 0.014477408491075039,
      "learning_rate": 1.640520074296328e-05,
      "loss": 0.1896,
      "step": 12580
    },
    {
      "epoch": 2.698242606086584,
      "grad_norm": 0.00724835554137826,
      "learning_rate": 1.6402343191884555e-05,
      "loss": 0.0003,
      "step": 12590
    },
    {
      "epoch": 2.700385769395628,
      "grad_norm": 0.02966274321079254,
      "learning_rate": 1.639948564080583e-05,
      "loss": 0.1792,
      "step": 12600
    },
    {
      "epoch": 2.702528932704672,
      "grad_norm": 169.4987335205078,
      "learning_rate": 1.6396628089727106e-05,
      "loss": 0.1074,
      "step": 12610
    },
    {
      "epoch": 2.7046720960137165,
      "grad_norm": 0.007962988689541817,
      "learning_rate": 1.639377053864838e-05,
      "loss": 0.0005,
      "step": 12620
    },
    {
      "epoch": 2.7068152593227603,
      "grad_norm": 0.04161424562335014,
      "learning_rate": 1.6390912987569654e-05,
      "loss": 0.0005,
      "step": 12630
    },
    {
      "epoch": 2.7089584226318046,
      "grad_norm": 6.500361442565918,
      "learning_rate": 1.6388055436490928e-05,
      "loss": 0.0204,
      "step": 12640
    },
    {
      "epoch": 2.711101585940849,
      "grad_norm": 18.961532592773438,
      "learning_rate": 1.6385197885412202e-05,
      "loss": 0.5134,
      "step": 12650
    },
    {
      "epoch": 2.713244749249893,
      "grad_norm": 53.71925354003906,
      "learning_rate": 1.6382340334333476e-05,
      "loss": 0.1399,
      "step": 12660
    },
    {
      "epoch": 2.715387912558937,
      "grad_norm": 43.515384674072266,
      "learning_rate": 1.6379482783254753e-05,
      "loss": 0.5285,
      "step": 12670
    },
    {
      "epoch": 2.7175310758679814,
      "grad_norm": 0.0396738275885582,
      "learning_rate": 1.6376625232176027e-05,
      "loss": 0.6945,
      "step": 12680
    },
    {
      "epoch": 2.719674239177025,
      "grad_norm": 0.008983617648482323,
      "learning_rate": 1.63737676810973e-05,
      "loss": 0.4481,
      "step": 12690
    },
    {
      "epoch": 2.7218174024860695,
      "grad_norm": 0.01853697933256626,
      "learning_rate": 1.6370910130018575e-05,
      "loss": 0.2482,
      "step": 12700
    },
    {
      "epoch": 2.723960565795114,
      "grad_norm": 0.07218621671199799,
      "learning_rate": 1.636805257893985e-05,
      "loss": 0.3506,
      "step": 12710
    },
    {
      "epoch": 2.7261037291041577,
      "grad_norm": 0.02031662128865719,
      "learning_rate": 1.6365195027861126e-05,
      "loss": 0.4638,
      "step": 12720
    },
    {
      "epoch": 2.728246892413202,
      "grad_norm": 36.112754821777344,
      "learning_rate": 1.63623374767824e-05,
      "loss": 0.1596,
      "step": 12730
    },
    {
      "epoch": 2.7303900557222462,
      "grad_norm": 0.022367823868989944,
      "learning_rate": 1.6359479925703674e-05,
      "loss": 0.1008,
      "step": 12740
    },
    {
      "epoch": 2.73253321903129,
      "grad_norm": 0.10314483940601349,
      "learning_rate": 1.6356622374624948e-05,
      "loss": 0.004,
      "step": 12750
    },
    {
      "epoch": 2.7346763823403344,
      "grad_norm": 20.13285255432129,
      "learning_rate": 1.6353764823546222e-05,
      "loss": 0.6212,
      "step": 12760
    },
    {
      "epoch": 2.7368195456493787,
      "grad_norm": 24.48450469970703,
      "learning_rate": 1.63509072724675e-05,
      "loss": 0.1122,
      "step": 12770
    },
    {
      "epoch": 2.7389627089584225,
      "grad_norm": 0.07529637962579727,
      "learning_rate": 1.634804972138877e-05,
      "loss": 0.0477,
      "step": 12780
    },
    {
      "epoch": 2.741105872267467,
      "grad_norm": 0.024991322308778763,
      "learning_rate": 1.6345192170310044e-05,
      "loss": 0.0571,
      "step": 12790
    },
    {
      "epoch": 2.743249035576511,
      "grad_norm": 0.03529489412903786,
      "learning_rate": 1.6342334619231318e-05,
      "loss": 0.0144,
      "step": 12800
    },
    {
      "epoch": 2.745392198885555,
      "grad_norm": 0.33214956521987915,
      "learning_rate": 1.6339477068152595e-05,
      "loss": 0.0014,
      "step": 12810
    },
    {
      "epoch": 2.7475353621945993,
      "grad_norm": 33.9122200012207,
      "learning_rate": 1.633661951707387e-05,
      "loss": 0.2803,
      "step": 12820
    },
    {
      "epoch": 2.7496785255036436,
      "grad_norm": 76.2068099975586,
      "learning_rate": 1.6333761965995143e-05,
      "loss": 0.5116,
      "step": 12830
    },
    {
      "epoch": 2.7518216888126874,
      "grad_norm": 0.033221933990716934,
      "learning_rate": 1.6330904414916417e-05,
      "loss": 0.2559,
      "step": 12840
    },
    {
      "epoch": 2.7539648521217317,
      "grad_norm": 22.484182357788086,
      "learning_rate": 1.632804686383769e-05,
      "loss": 0.4247,
      "step": 12850
    },
    {
      "epoch": 2.756108015430776,
      "grad_norm": 23.960195541381836,
      "learning_rate": 1.6325189312758968e-05,
      "loss": 0.9475,
      "step": 12860
    },
    {
      "epoch": 2.75825117873982,
      "grad_norm": 2.0340089797973633,
      "learning_rate": 1.6322331761680242e-05,
      "loss": 0.2655,
      "step": 12870
    },
    {
      "epoch": 2.760394342048864,
      "grad_norm": 0.05344812199473381,
      "learning_rate": 1.6319474210601516e-05,
      "loss": 0.4862,
      "step": 12880
    },
    {
      "epoch": 2.7625375053579084,
      "grad_norm": 32.06997299194336,
      "learning_rate": 1.631661665952279e-05,
      "loss": 0.816,
      "step": 12890
    },
    {
      "epoch": 2.7646806686669523,
      "grad_norm": 131.36029052734375,
      "learning_rate": 1.6313759108444064e-05,
      "loss": 0.4026,
      "step": 12900
    },
    {
      "epoch": 2.7668238319759966,
      "grad_norm": 0.3471885621547699,
      "learning_rate": 1.631090155736534e-05,
      "loss": 0.0977,
      "step": 12910
    },
    {
      "epoch": 2.768966995285041,
      "grad_norm": 103.97832489013672,
      "learning_rate": 1.6308044006286615e-05,
      "loss": 0.5445,
      "step": 12920
    },
    {
      "epoch": 2.7711101585940847,
      "grad_norm": 0.47172874212265015,
      "learning_rate": 1.630518645520789e-05,
      "loss": 0.579,
      "step": 12930
    },
    {
      "epoch": 2.773253321903129,
      "grad_norm": 0.5512500405311584,
      "learning_rate": 1.6302328904129163e-05,
      "loss": 0.5477,
      "step": 12940
    },
    {
      "epoch": 2.7753964852121733,
      "grad_norm": 40.800113677978516,
      "learning_rate": 1.6299471353050437e-05,
      "loss": 0.0807,
      "step": 12950
    },
    {
      "epoch": 2.777539648521217,
      "grad_norm": 47.329315185546875,
      "learning_rate": 1.6296613801971714e-05,
      "loss": 0.4368,
      "step": 12960
    },
    {
      "epoch": 2.7796828118302614,
      "grad_norm": 18.369064331054688,
      "learning_rate": 1.6293756250892988e-05,
      "loss": 0.2735,
      "step": 12970
    },
    {
      "epoch": 2.7818259751393057,
      "grad_norm": 0.023517942056059837,
      "learning_rate": 1.6290898699814262e-05,
      "loss": 0.0007,
      "step": 12980
    },
    {
      "epoch": 2.7839691384483496,
      "grad_norm": 0.010355884209275246,
      "learning_rate": 1.6288041148735532e-05,
      "loss": 0.1643,
      "step": 12990
    },
    {
      "epoch": 2.786112301757394,
      "grad_norm": 0.026456844061613083,
      "learning_rate": 1.628518359765681e-05,
      "loss": 0.3956,
      "step": 13000
    },
    {
      "epoch": 2.788255465066438,
      "grad_norm": 0.9403515458106995,
      "learning_rate": 1.6282326046578084e-05,
      "loss": 0.0025,
      "step": 13010
    },
    {
      "epoch": 2.790398628375482,
      "grad_norm": 28.73417091369629,
      "learning_rate": 1.6279468495499358e-05,
      "loss": 0.6413,
      "step": 13020
    },
    {
      "epoch": 2.7925417916845263,
      "grad_norm": 0.005473487079143524,
      "learning_rate": 1.627661094442063e-05,
      "loss": 0.5864,
      "step": 13030
    },
    {
      "epoch": 2.7946849549935706,
      "grad_norm": 20.26515769958496,
      "learning_rate": 1.6273753393341905e-05,
      "loss": 0.4663,
      "step": 13040
    },
    {
      "epoch": 2.7968281183026145,
      "grad_norm": 40.725589752197266,
      "learning_rate": 1.6270895842263183e-05,
      "loss": 0.3867,
      "step": 13050
    },
    {
      "epoch": 2.7989712816116588,
      "grad_norm": 1.9415360689163208,
      "learning_rate": 1.6268038291184457e-05,
      "loss": 0.1707,
      "step": 13060
    },
    {
      "epoch": 2.801114444920703,
      "grad_norm": 0.0034885320346802473,
      "learning_rate": 1.626518074010573e-05,
      "loss": 0.2582,
      "step": 13070
    },
    {
      "epoch": 2.803257608229747,
      "grad_norm": 0.013576596975326538,
      "learning_rate": 1.6262323189027005e-05,
      "loss": 0.0008,
      "step": 13080
    },
    {
      "epoch": 2.805400771538791,
      "grad_norm": 93.08403778076172,
      "learning_rate": 1.625946563794828e-05,
      "loss": 0.6698,
      "step": 13090
    },
    {
      "epoch": 2.8075439348478355,
      "grad_norm": 0.23475632071495056,
      "learning_rate": 1.6256608086869556e-05,
      "loss": 0.3089,
      "step": 13100
    },
    {
      "epoch": 2.8096870981568793,
      "grad_norm": 0.4513928294181824,
      "learning_rate": 1.625375053579083e-05,
      "loss": 0.0037,
      "step": 13110
    },
    {
      "epoch": 2.8118302614659236,
      "grad_norm": 24.31024932861328,
      "learning_rate": 1.6250892984712104e-05,
      "loss": 0.205,
      "step": 13120
    },
    {
      "epoch": 2.813973424774968,
      "grad_norm": 0.015276171267032623,
      "learning_rate": 1.6248035433633378e-05,
      "loss": 0.0795,
      "step": 13130
    },
    {
      "epoch": 2.8161165880840118,
      "grad_norm": 0.01832355558872223,
      "learning_rate": 1.624517788255465e-05,
      "loss": 0.372,
      "step": 13140
    },
    {
      "epoch": 2.818259751393056,
      "grad_norm": 0.8480194807052612,
      "learning_rate": 1.6242320331475925e-05,
      "loss": 0.2304,
      "step": 13150
    },
    {
      "epoch": 2.8204029147021004,
      "grad_norm": 0.03313737362623215,
      "learning_rate": 1.6239462780397203e-05,
      "loss": 0.5426,
      "step": 13160
    },
    {
      "epoch": 2.822546078011144,
      "grad_norm": 0.21727660298347473,
      "learning_rate": 1.6236605229318477e-05,
      "loss": 0.1303,
      "step": 13170
    },
    {
      "epoch": 2.8246892413201885,
      "grad_norm": 0.011880294419825077,
      "learning_rate": 1.623374767823975e-05,
      "loss": 0.11,
      "step": 13180
    },
    {
      "epoch": 2.826832404629233,
      "grad_norm": 0.017209745943546295,
      "learning_rate": 1.6230890127161025e-05,
      "loss": 0.1043,
      "step": 13190
    },
    {
      "epoch": 2.8289755679382766,
      "grad_norm": 0.007235867902636528,
      "learning_rate": 1.62280325760823e-05,
      "loss": 0.0548,
      "step": 13200
    },
    {
      "epoch": 2.831118731247321,
      "grad_norm": 0.01244175061583519,
      "learning_rate": 1.6225175025003572e-05,
      "loss": 0.2118,
      "step": 13210
    },
    {
      "epoch": 2.8332618945563652,
      "grad_norm": 0.009630214422941208,
      "learning_rate": 1.6222317473924846e-05,
      "loss": 0.3527,
      "step": 13220
    },
    {
      "epoch": 2.835405057865409,
      "grad_norm": 0.054894138127565384,
      "learning_rate": 1.621945992284612e-05,
      "loss": 0.4784,
      "step": 13230
    },
    {
      "epoch": 2.8375482211744534,
      "grad_norm": 23.127656936645508,
      "learning_rate": 1.6216602371767398e-05,
      "loss": 0.5601,
      "step": 13240
    },
    {
      "epoch": 2.8396913844834977,
      "grad_norm": 47.51652145385742,
      "learning_rate": 1.621374482068867e-05,
      "loss": 0.4121,
      "step": 13250
    },
    {
      "epoch": 2.8418345477925415,
      "grad_norm": 0.08298423886299133,
      "learning_rate": 1.6210887269609945e-05,
      "loss": 0.4832,
      "step": 13260
    },
    {
      "epoch": 2.843977711101586,
      "grad_norm": 0.40420594811439514,
      "learning_rate": 1.620802971853122e-05,
      "loss": 0.4249,
      "step": 13270
    },
    {
      "epoch": 2.84612087441063,
      "grad_norm": 0.14231017231941223,
      "learning_rate": 1.6205172167452493e-05,
      "loss": 0.3179,
      "step": 13280
    },
    {
      "epoch": 2.8482640377196744,
      "grad_norm": 0.0274003054946661,
      "learning_rate": 1.6202314616373767e-05,
      "loss": 0.1787,
      "step": 13290
    },
    {
      "epoch": 2.8504072010287183,
      "grad_norm": 0.04567080736160278,
      "learning_rate": 1.6199457065295045e-05,
      "loss": 0.049,
      "step": 13300
    },
    {
      "epoch": 2.8525503643377625,
      "grad_norm": 0.013493424281477928,
      "learning_rate": 1.619659951421632e-05,
      "loss": 0.5321,
      "step": 13310
    },
    {
      "epoch": 2.854693527646807,
      "grad_norm": 0.08524756133556366,
      "learning_rate": 1.6193741963137592e-05,
      "loss": 0.4903,
      "step": 13320
    },
    {
      "epoch": 2.8568366909558507,
      "grad_norm": 0.12495064735412598,
      "learning_rate": 1.6190884412058866e-05,
      "loss": 0.1949,
      "step": 13330
    },
    {
      "epoch": 2.858979854264895,
      "grad_norm": 0.04692520573735237,
      "learning_rate": 1.618802686098014e-05,
      "loss": 0.4198,
      "step": 13340
    },
    {
      "epoch": 2.8611230175739393,
      "grad_norm": 0.7884172201156616,
      "learning_rate": 1.6185169309901418e-05,
      "loss": 0.0449,
      "step": 13350
    },
    {
      "epoch": 2.863266180882983,
      "grad_norm": 0.11048173904418945,
      "learning_rate": 1.618231175882269e-05,
      "loss": 0.4325,
      "step": 13360
    },
    {
      "epoch": 2.8654093441920274,
      "grad_norm": 0.07120281457901001,
      "learning_rate": 1.6179454207743965e-05,
      "loss": 0.149,
      "step": 13370
    },
    {
      "epoch": 2.8675525075010717,
      "grad_norm": 51.82738494873047,
      "learning_rate": 1.617659665666524e-05,
      "loss": 0.6408,
      "step": 13380
    },
    {
      "epoch": 2.869695670810116,
      "grad_norm": 0.08064204454421997,
      "learning_rate": 1.6173739105586513e-05,
      "loss": 0.2886,
      "step": 13390
    },
    {
      "epoch": 2.87183883411916,
      "grad_norm": 0.04095131903886795,
      "learning_rate": 1.617088155450779e-05,
      "loss": 0.2928,
      "step": 13400
    },
    {
      "epoch": 2.873981997428204,
      "grad_norm": 137.2950897216797,
      "learning_rate": 1.6168024003429065e-05,
      "loss": 0.3424,
      "step": 13410
    },
    {
      "epoch": 2.8761251607372484,
      "grad_norm": 81.08641815185547,
      "learning_rate": 1.6165166452350335e-05,
      "loss": 0.1642,
      "step": 13420
    },
    {
      "epoch": 2.8782683240462923,
      "grad_norm": 49.94733428955078,
      "learning_rate": 1.616230890127161e-05,
      "loss": 0.1844,
      "step": 13430
    },
    {
      "epoch": 2.8804114873553366,
      "grad_norm": 0.11524675041437149,
      "learning_rate": 1.6159451350192886e-05,
      "loss": 0.2915,
      "step": 13440
    },
    {
      "epoch": 2.882554650664381,
      "grad_norm": 0.011335436254739761,
      "learning_rate": 1.615659379911416e-05,
      "loss": 0.0055,
      "step": 13450
    },
    {
      "epoch": 2.8846978139734247,
      "grad_norm": 77.6673355102539,
      "learning_rate": 1.6153736248035434e-05,
      "loss": 0.0503,
      "step": 13460
    },
    {
      "epoch": 2.886840977282469,
      "grad_norm": 37.194217681884766,
      "learning_rate": 1.6150878696956708e-05,
      "loss": 0.1685,
      "step": 13470
    },
    {
      "epoch": 2.8889841405915133,
      "grad_norm": 0.003842491889372468,
      "learning_rate": 1.6148021145877982e-05,
      "loss": 0.0036,
      "step": 13480
    },
    {
      "epoch": 2.891127303900557,
      "grad_norm": 0.0018622869392856956,
      "learning_rate": 1.614516359479926e-05,
      "loss": 0.6038,
      "step": 13490
    },
    {
      "epoch": 2.8932704672096015,
      "grad_norm": 0.3652655780315399,
      "learning_rate": 1.6142306043720533e-05,
      "loss": 0.0005,
      "step": 13500
    },
    {
      "epoch": 2.8954136305186458,
      "grad_norm": 20.001298904418945,
      "learning_rate": 1.6139448492641807e-05,
      "loss": 0.7231,
      "step": 13510
    },
    {
      "epoch": 2.8975567938276896,
      "grad_norm": 0.014475406147539616,
      "learning_rate": 1.613659094156308e-05,
      "loss": 0.172,
      "step": 13520
    },
    {
      "epoch": 2.899699957136734,
      "grad_norm": 64.65166473388672,
      "learning_rate": 1.6133733390484355e-05,
      "loss": 0.6245,
      "step": 13530
    },
    {
      "epoch": 2.901843120445778,
      "grad_norm": 0.21875862777233124,
      "learning_rate": 1.6130875839405632e-05,
      "loss": 0.2642,
      "step": 13540
    },
    {
      "epoch": 2.903986283754822,
      "grad_norm": 16.962656021118164,
      "learning_rate": 1.6128018288326906e-05,
      "loss": 0.44,
      "step": 13550
    },
    {
      "epoch": 2.9061294470638663,
      "grad_norm": 0.06209162250161171,
      "learning_rate": 1.612516073724818e-05,
      "loss": 0.0374,
      "step": 13560
    },
    {
      "epoch": 2.9082726103729106,
      "grad_norm": 341.9466857910156,
      "learning_rate": 1.6122303186169454e-05,
      "loss": 0.4465,
      "step": 13570
    },
    {
      "epoch": 2.9104157736819545,
      "grad_norm": 0.0859416127204895,
      "learning_rate": 1.6119445635090728e-05,
      "loss": 0.5611,
      "step": 13580
    },
    {
      "epoch": 2.9125589369909988,
      "grad_norm": 0.07247290760278702,
      "learning_rate": 1.6116588084012005e-05,
      "loss": 0.6381,
      "step": 13590
    },
    {
      "epoch": 2.914702100300043,
      "grad_norm": 0.21675904095172882,
      "learning_rate": 1.611373053293328e-05,
      "loss": 0.2835,
      "step": 13600
    },
    {
      "epoch": 2.916845263609087,
      "grad_norm": 51.32160186767578,
      "learning_rate": 1.6110872981854553e-05,
      "loss": 0.2244,
      "step": 13610
    },
    {
      "epoch": 2.918988426918131,
      "grad_norm": 46.698726654052734,
      "learning_rate": 1.6108015430775827e-05,
      "loss": 0.3432,
      "step": 13620
    },
    {
      "epoch": 2.9211315902271755,
      "grad_norm": 0.10000087320804596,
      "learning_rate": 1.61051578796971e-05,
      "loss": 0.2961,
      "step": 13630
    },
    {
      "epoch": 2.9232747535362194,
      "grad_norm": 0.2011716216802597,
      "learning_rate": 1.6102300328618375e-05,
      "loss": 0.4822,
      "step": 13640
    },
    {
      "epoch": 2.9254179168452636,
      "grad_norm": 0.03381431847810745,
      "learning_rate": 1.609944277753965e-05,
      "loss": 0.0562,
      "step": 13650
    },
    {
      "epoch": 2.927561080154308,
      "grad_norm": 0.04755399003624916,
      "learning_rate": 1.6096585226460923e-05,
      "loss": 0.2323,
      "step": 13660
    },
    {
      "epoch": 2.929704243463352,
      "grad_norm": 0.07637139409780502,
      "learning_rate": 1.6093727675382197e-05,
      "loss": 0.4028,
      "step": 13670
    },
    {
      "epoch": 2.931847406772396,
      "grad_norm": 0.30907878279685974,
      "learning_rate": 1.6090870124303474e-05,
      "loss": 0.0375,
      "step": 13680
    },
    {
      "epoch": 2.9339905700814404,
      "grad_norm": 18.67106056213379,
      "learning_rate": 1.6088012573224748e-05,
      "loss": 0.4101,
      "step": 13690
    },
    {
      "epoch": 2.9361337333904842,
      "grad_norm": 24.012632369995117,
      "learning_rate": 1.6085155022146022e-05,
      "loss": 0.3979,
      "step": 13700
    },
    {
      "epoch": 2.9382768966995285,
      "grad_norm": 40.37678909301758,
      "learning_rate": 1.6082297471067296e-05,
      "loss": 0.0892,
      "step": 13710
    },
    {
      "epoch": 2.940420060008573,
      "grad_norm": 0.23597371578216553,
      "learning_rate": 1.607943991998857e-05,
      "loss": 0.4234,
      "step": 13720
    },
    {
      "epoch": 2.9425632233176167,
      "grad_norm": 0.26074910163879395,
      "learning_rate": 1.6076582368909847e-05,
      "loss": 0.1281,
      "step": 13730
    },
    {
      "epoch": 2.944706386626661,
      "grad_norm": 31.62938690185547,
      "learning_rate": 1.607372481783112e-05,
      "loss": 0.083,
      "step": 13740
    },
    {
      "epoch": 2.9468495499357052,
      "grad_norm": 0.0137260090559721,
      "learning_rate": 1.6070867266752395e-05,
      "loss": 0.3765,
      "step": 13750
    },
    {
      "epoch": 2.948992713244749,
      "grad_norm": 21.214887619018555,
      "learning_rate": 1.606800971567367e-05,
      "loss": 0.2552,
      "step": 13760
    },
    {
      "epoch": 2.9511358765537934,
      "grad_norm": 0.02579052746295929,
      "learning_rate": 1.6065152164594943e-05,
      "loss": 0.493,
      "step": 13770
    },
    {
      "epoch": 2.9532790398628377,
      "grad_norm": 0.04847394675016403,
      "learning_rate": 1.6062294613516217e-05,
      "loss": 0.2045,
      "step": 13780
    },
    {
      "epoch": 2.9554222031718815,
      "grad_norm": 0.11643745750188828,
      "learning_rate": 1.6059437062437494e-05,
      "loss": 0.1489,
      "step": 13790
    },
    {
      "epoch": 2.957565366480926,
      "grad_norm": 30.40369415283203,
      "learning_rate": 1.6056579511358768e-05,
      "loss": 0.3814,
      "step": 13800
    },
    {
      "epoch": 2.95970852978997,
      "grad_norm": 100.17825317382812,
      "learning_rate": 1.6053721960280042e-05,
      "loss": 0.5219,
      "step": 13810
    },
    {
      "epoch": 2.961851693099014,
      "grad_norm": 28.094736099243164,
      "learning_rate": 1.6050864409201316e-05,
      "loss": 0.4234,
      "step": 13820
    },
    {
      "epoch": 2.9639948564080583,
      "grad_norm": 0.07104174047708511,
      "learning_rate": 1.604800685812259e-05,
      "loss": 0.3471,
      "step": 13830
    },
    {
      "epoch": 2.9661380197171026,
      "grad_norm": 0.027509164065122604,
      "learning_rate": 1.6045149307043867e-05,
      "loss": 0.0217,
      "step": 13840
    },
    {
      "epoch": 2.9682811830261464,
      "grad_norm": 0.03315271809697151,
      "learning_rate": 1.6042291755965138e-05,
      "loss": 0.28,
      "step": 13850
    },
    {
      "epoch": 2.9704243463351907,
      "grad_norm": 0.04558537155389786,
      "learning_rate": 1.603943420488641e-05,
      "loss": 0.0886,
      "step": 13860
    },
    {
      "epoch": 2.972567509644235,
      "grad_norm": 0.12649311125278473,
      "learning_rate": 1.603657665380769e-05,
      "loss": 0.1051,
      "step": 13870
    },
    {
      "epoch": 2.974710672953279,
      "grad_norm": 55.638832092285156,
      "learning_rate": 1.6033719102728963e-05,
      "loss": 0.7684,
      "step": 13880
    },
    {
      "epoch": 2.976853836262323,
      "grad_norm": 0.06467853486537933,
      "learning_rate": 1.6030861551650237e-05,
      "loss": 0.3494,
      "step": 13890
    },
    {
      "epoch": 2.9789969995713674,
      "grad_norm": 0.3235243260860443,
      "learning_rate": 1.602800400057151e-05,
      "loss": 0.8573,
      "step": 13900
    },
    {
      "epoch": 2.9811401628804113,
      "grad_norm": 3.453512668609619,
      "learning_rate": 1.6025146449492785e-05,
      "loss": 0.1285,
      "step": 13910
    },
    {
      "epoch": 2.9832833261894556,
      "grad_norm": 32.50737380981445,
      "learning_rate": 1.602228889841406e-05,
      "loss": 0.1322,
      "step": 13920
    },
    {
      "epoch": 2.9854264894985,
      "grad_norm": 19.704858779907227,
      "learning_rate": 1.6019431347335336e-05,
      "loss": 0.1634,
      "step": 13930
    },
    {
      "epoch": 2.9875696528075437,
      "grad_norm": 0.056579265743494034,
      "learning_rate": 1.601657379625661e-05,
      "loss": 0.5024,
      "step": 13940
    },
    {
      "epoch": 2.989712816116588,
      "grad_norm": 0.1564478576183319,
      "learning_rate": 1.6013716245177884e-05,
      "loss": 0.0026,
      "step": 13950
    },
    {
      "epoch": 2.9918559794256323,
      "grad_norm": 0.07260195910930634,
      "learning_rate": 1.6010858694099158e-05,
      "loss": 0.0011,
      "step": 13960
    },
    {
      "epoch": 2.993999142734676,
      "grad_norm": 47.94192123413086,
      "learning_rate": 1.600800114302043e-05,
      "loss": 0.3244,
      "step": 13970
    },
    {
      "epoch": 2.9961423060437204,
      "grad_norm": 0.031476981937885284,
      "learning_rate": 1.600514359194171e-05,
      "loss": 0.6222,
      "step": 13980
    },
    {
      "epoch": 2.9982854693527647,
      "grad_norm": 0.048651646822690964,
      "learning_rate": 1.6002286040862983e-05,
      "loss": 0.1973,
      "step": 13990
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9123333333333333,
      "eval_f1": 0.7584940312213039,
      "eval_loss": 0.4355905055999756,
      "eval_precision": 0.8162055335968379,
      "eval_recall": 0.7084048027444254,
      "eval_runtime": 108.5851,
      "eval_samples_per_second": 27.628,
      "eval_steps_per_second": 1.151,
      "step": 13998
    },
    {
      "epoch": 3.000428632661809,
      "grad_norm": 0.04132017493247986,
      "learning_rate": 1.5999428489784257e-05,
      "loss": 0.5077,
      "step": 14000
    },
    {
      "epoch": 3.002571795970853,
      "grad_norm": 54.62633514404297,
      "learning_rate": 1.599657093870553e-05,
      "loss": 0.0295,
      "step": 14010
    },
    {
      "epoch": 3.004714959279897,
      "grad_norm": 0.05877673625946045,
      "learning_rate": 1.5993713387626805e-05,
      "loss": 0.2298,
      "step": 14020
    },
    {
      "epoch": 3.0068581225889415,
      "grad_norm": 0.023031296208500862,
      "learning_rate": 1.5990855836548082e-05,
      "loss": 0.006,
      "step": 14030
    },
    {
      "epoch": 3.0090012858979853,
      "grad_norm": 0.3117547333240509,
      "learning_rate": 1.5987998285469356e-05,
      "loss": 0.0008,
      "step": 14040
    },
    {
      "epoch": 3.0111444492070296,
      "grad_norm": 0.0288087110966444,
      "learning_rate": 1.598514073439063e-05,
      "loss": 0.4841,
      "step": 14050
    },
    {
      "epoch": 3.013287612516074,
      "grad_norm": 0.01284163910895586,
      "learning_rate": 1.5982283183311904e-05,
      "loss": 0.0185,
      "step": 14060
    },
    {
      "epoch": 3.0154307758251178,
      "grad_norm": 0.09339720010757446,
      "learning_rate": 1.5979425632233178e-05,
      "loss": 0.1651,
      "step": 14070
    },
    {
      "epoch": 3.017573939134162,
      "grad_norm": 0.0045778509229421616,
      "learning_rate": 1.597656808115445e-05,
      "loss": 0.2423,
      "step": 14080
    },
    {
      "epoch": 3.0197171024432063,
      "grad_norm": 16.408660888671875,
      "learning_rate": 1.5973710530075726e-05,
      "loss": 0.0036,
      "step": 14090
    },
    {
      "epoch": 3.02186026575225,
      "grad_norm": 0.043627675622701645,
      "learning_rate": 1.5970852978997e-05,
      "loss": 0.2047,
      "step": 14100
    },
    {
      "epoch": 3.0240034290612945,
      "grad_norm": 0.07058285176753998,
      "learning_rate": 1.5967995427918273e-05,
      "loss": 0.213,
      "step": 14110
    },
    {
      "epoch": 3.026146592370339,
      "grad_norm": 0.008386591449379921,
      "learning_rate": 1.596513787683955e-05,
      "loss": 0.2986,
      "step": 14120
    },
    {
      "epoch": 3.0282897556793826,
      "grad_norm": 0.009016837924718857,
      "learning_rate": 1.5962280325760825e-05,
      "loss": 0.2938,
      "step": 14130
    },
    {
      "epoch": 3.030432918988427,
      "grad_norm": 0.05801479145884514,
      "learning_rate": 1.59594227746821e-05,
      "loss": 0.0012,
      "step": 14140
    },
    {
      "epoch": 3.032576082297471,
      "grad_norm": 0.02251931093633175,
      "learning_rate": 1.5956565223603372e-05,
      "loss": 0.0091,
      "step": 14150
    },
    {
      "epoch": 3.034719245606515,
      "grad_norm": 0.017102710902690887,
      "learning_rate": 1.5953707672524646e-05,
      "loss": 0.2196,
      "step": 14160
    },
    {
      "epoch": 3.0368624089155594,
      "grad_norm": 0.027007518336176872,
      "learning_rate": 1.5950850121445924e-05,
      "loss": 0.1608,
      "step": 14170
    },
    {
      "epoch": 3.0390055722246037,
      "grad_norm": 0.01596773788332939,
      "learning_rate": 1.5947992570367198e-05,
      "loss": 0.0254,
      "step": 14180
    },
    {
      "epoch": 3.0411487355336475,
      "grad_norm": 0.0024859695695340633,
      "learning_rate": 1.594513501928847e-05,
      "loss": 0.1664,
      "step": 14190
    },
    {
      "epoch": 3.043291898842692,
      "grad_norm": 0.137342169880867,
      "learning_rate": 1.5942277468209746e-05,
      "loss": 0.4355,
      "step": 14200
    },
    {
      "epoch": 3.045435062151736,
      "grad_norm": 0.10500093549489975,
      "learning_rate": 1.593941991713102e-05,
      "loss": 0.4475,
      "step": 14210
    },
    {
      "epoch": 3.04757822546078,
      "grad_norm": 0.12057764083147049,
      "learning_rate": 1.5936562366052293e-05,
      "loss": 0.0776,
      "step": 14220
    },
    {
      "epoch": 3.0497213887698242,
      "grad_norm": 0.30715644359588623,
      "learning_rate": 1.593370481497357e-05,
      "loss": 0.1123,
      "step": 14230
    },
    {
      "epoch": 3.0518645520788685,
      "grad_norm": 0.013999455608427525,
      "learning_rate": 1.5930847263894845e-05,
      "loss": 0.1322,
      "step": 14240
    },
    {
      "epoch": 3.0540077153879124,
      "grad_norm": 50.224674224853516,
      "learning_rate": 1.592798971281612e-05,
      "loss": 0.286,
      "step": 14250
    },
    {
      "epoch": 3.0561508786969567,
      "grad_norm": 24.098207473754883,
      "learning_rate": 1.5925132161737392e-05,
      "loss": 0.1444,
      "step": 14260
    },
    {
      "epoch": 3.058294042006001,
      "grad_norm": 0.007766602095216513,
      "learning_rate": 1.5922274610658666e-05,
      "loss": 0.0017,
      "step": 14270
    },
    {
      "epoch": 3.060437205315045,
      "grad_norm": 0.04659043997526169,
      "learning_rate": 1.591941705957994e-05,
      "loss": 0.6716,
      "step": 14280
    },
    {
      "epoch": 3.062580368624089,
      "grad_norm": 0.009980723261833191,
      "learning_rate": 1.5916559508501214e-05,
      "loss": 0.002,
      "step": 14290
    },
    {
      "epoch": 3.0647235319331334,
      "grad_norm": 0.061761219054460526,
      "learning_rate": 1.5913701957422488e-05,
      "loss": 0.117,
      "step": 14300
    },
    {
      "epoch": 3.0668666952421773,
      "grad_norm": 0.007478972896933556,
      "learning_rate": 1.5910844406343765e-05,
      "loss": 0.0317,
      "step": 14310
    },
    {
      "epoch": 3.0690098585512215,
      "grad_norm": 0.006437927950173616,
      "learning_rate": 1.590798685526504e-05,
      "loss": 0.0002,
      "step": 14320
    },
    {
      "epoch": 3.071153021860266,
      "grad_norm": 0.01638420671224594,
      "learning_rate": 1.5905129304186313e-05,
      "loss": 0.0909,
      "step": 14330
    },
    {
      "epoch": 3.0732961851693097,
      "grad_norm": 0.0014959432883188128,
      "learning_rate": 1.5902271753107587e-05,
      "loss": 0.0091,
      "step": 14340
    },
    {
      "epoch": 3.075439348478354,
      "grad_norm": 0.010524292476475239,
      "learning_rate": 1.589941420202886e-05,
      "loss": 0.2376,
      "step": 14350
    },
    {
      "epoch": 3.0775825117873983,
      "grad_norm": 0.036045141518116,
      "learning_rate": 1.5896556650950135e-05,
      "loss": 0.6262,
      "step": 14360
    },
    {
      "epoch": 3.0797256750964426,
      "grad_norm": 0.04320107027888298,
      "learning_rate": 1.5893699099871412e-05,
      "loss": 0.2325,
      "step": 14370
    },
    {
      "epoch": 3.0818688384054864,
      "grad_norm": 0.004857226274907589,
      "learning_rate": 1.5890841548792686e-05,
      "loss": 0.0076,
      "step": 14380
    },
    {
      "epoch": 3.0840120017145307,
      "grad_norm": 0.08455211669206619,
      "learning_rate": 1.588798399771396e-05,
      "loss": 0.251,
      "step": 14390
    },
    {
      "epoch": 3.086155165023575,
      "grad_norm": 57.1640739440918,
      "learning_rate": 1.5885126446635234e-05,
      "loss": 0.5759,
      "step": 14400
    },
    {
      "epoch": 3.088298328332619,
      "grad_norm": 0.11937449127435684,
      "learning_rate": 1.5882268895556508e-05,
      "loss": 0.0115,
      "step": 14410
    },
    {
      "epoch": 3.090441491641663,
      "grad_norm": 390.24444580078125,
      "learning_rate": 1.5879411344477785e-05,
      "loss": 0.4713,
      "step": 14420
    },
    {
      "epoch": 3.0925846549507074,
      "grad_norm": 0.08897577971220016,
      "learning_rate": 1.587655379339906e-05,
      "loss": 0.1889,
      "step": 14430
    },
    {
      "epoch": 3.0947278182597513,
      "grad_norm": 0.291519433259964,
      "learning_rate": 1.5873696242320333e-05,
      "loss": 0.3407,
      "step": 14440
    },
    {
      "epoch": 3.0968709815687956,
      "grad_norm": 59.51048278808594,
      "learning_rate": 1.5870838691241607e-05,
      "loss": 0.0291,
      "step": 14450
    },
    {
      "epoch": 3.09901414487784,
      "grad_norm": 0.02601267211139202,
      "learning_rate": 1.586798114016288e-05,
      "loss": 0.0009,
      "step": 14460
    },
    {
      "epoch": 3.1011573081868837,
      "grad_norm": 18.158851623535156,
      "learning_rate": 1.586512358908416e-05,
      "loss": 0.4393,
      "step": 14470
    },
    {
      "epoch": 3.103300471495928,
      "grad_norm": 0.07147042453289032,
      "learning_rate": 1.5862266038005432e-05,
      "loss": 0.0006,
      "step": 14480
    },
    {
      "epoch": 3.1054436348049723,
      "grad_norm": 0.04621477797627449,
      "learning_rate": 1.5859408486926706e-05,
      "loss": 0.1876,
      "step": 14490
    },
    {
      "epoch": 3.107586798114016,
      "grad_norm": 0.06718923151493073,
      "learning_rate": 1.5856550935847977e-05,
      "loss": 0.0101,
      "step": 14500
    },
    {
      "epoch": 3.1097299614230605,
      "grad_norm": 0.014954346232116222,
      "learning_rate": 1.5853693384769254e-05,
      "loss": 0.0007,
      "step": 14510
    },
    {
      "epoch": 3.1118731247321048,
      "grad_norm": 0.03891698271036148,
      "learning_rate": 1.5850835833690528e-05,
      "loss": 0.2705,
      "step": 14520
    },
    {
      "epoch": 3.1140162880411486,
      "grad_norm": 0.05566900968551636,
      "learning_rate": 1.5847978282611802e-05,
      "loss": 0.002,
      "step": 14530
    },
    {
      "epoch": 3.116159451350193,
      "grad_norm": 0.015723327174782753,
      "learning_rate": 1.5845120731533076e-05,
      "loss": 0.0145,
      "step": 14540
    },
    {
      "epoch": 3.118302614659237,
      "grad_norm": 0.04459502920508385,
      "learning_rate": 1.584226318045435e-05,
      "loss": 0.1922,
      "step": 14550
    },
    {
      "epoch": 3.120445777968281,
      "grad_norm": 0.02366483211517334,
      "learning_rate": 1.5839405629375627e-05,
      "loss": 0.1574,
      "step": 14560
    },
    {
      "epoch": 3.1225889412773253,
      "grad_norm": 0.10640078037977219,
      "learning_rate": 1.58365480782969e-05,
      "loss": 0.0009,
      "step": 14570
    },
    {
      "epoch": 3.1247321045863696,
      "grad_norm": 0.008158707991242409,
      "learning_rate": 1.5833690527218175e-05,
      "loss": 0.2179,
      "step": 14580
    },
    {
      "epoch": 3.1268752678954135,
      "grad_norm": 0.0016717821126803756,
      "learning_rate": 1.583083297613945e-05,
      "loss": 0.0002,
      "step": 14590
    },
    {
      "epoch": 3.1290184312044578,
      "grad_norm": 0.026456119492650032,
      "learning_rate": 1.5827975425060723e-05,
      "loss": 0.4723,
      "step": 14600
    },
    {
      "epoch": 3.131161594513502,
      "grad_norm": 0.002379250479862094,
      "learning_rate": 1.5825117873982e-05,
      "loss": 0.1445,
      "step": 14610
    },
    {
      "epoch": 3.133304757822546,
      "grad_norm": 0.004559820052236319,
      "learning_rate": 1.5822260322903274e-05,
      "loss": 0.0164,
      "step": 14620
    },
    {
      "epoch": 3.13544792113159,
      "grad_norm": 0.016408156603574753,
      "learning_rate": 1.5819402771824548e-05,
      "loss": 0.0002,
      "step": 14630
    },
    {
      "epoch": 3.1375910844406345,
      "grad_norm": 0.020558301359415054,
      "learning_rate": 1.5816545220745822e-05,
      "loss": 0.0105,
      "step": 14640
    },
    {
      "epoch": 3.1397342477496784,
      "grad_norm": 0.0028832738753408194,
      "learning_rate": 1.5813687669667096e-05,
      "loss": 0.5647,
      "step": 14650
    },
    {
      "epoch": 3.1418774110587226,
      "grad_norm": 0.011217322200536728,
      "learning_rate": 1.5810830118588373e-05,
      "loss": 0.3578,
      "step": 14660
    },
    {
      "epoch": 3.144020574367767,
      "grad_norm": 0.023808257654309273,
      "learning_rate": 1.5807972567509647e-05,
      "loss": 0.4928,
      "step": 14670
    },
    {
      "epoch": 3.146163737676811,
      "grad_norm": 0.06689611077308655,
      "learning_rate": 1.580511501643092e-05,
      "loss": 0.0015,
      "step": 14680
    },
    {
      "epoch": 3.148306900985855,
      "grad_norm": 0.0581851452589035,
      "learning_rate": 1.5802257465352195e-05,
      "loss": 0.0011,
      "step": 14690
    },
    {
      "epoch": 3.1504500642948994,
      "grad_norm": 0.003793352982029319,
      "learning_rate": 1.579939991427347e-05,
      "loss": 0.0007,
      "step": 14700
    },
    {
      "epoch": 3.1525932276039432,
      "grad_norm": 0.0014651177916675806,
      "learning_rate": 1.5796542363194743e-05,
      "loss": 0.1894,
      "step": 14710
    },
    {
      "epoch": 3.1547363909129875,
      "grad_norm": 0.10254064947366714,
      "learning_rate": 1.5793684812116017e-05,
      "loss": 0.3144,
      "step": 14720
    },
    {
      "epoch": 3.156879554222032,
      "grad_norm": 0.03729915991425514,
      "learning_rate": 1.579082726103729e-05,
      "loss": 0.0005,
      "step": 14730
    },
    {
      "epoch": 3.1590227175310757,
      "grad_norm": 0.000916028511710465,
      "learning_rate": 1.5787969709958565e-05,
      "loss": 0.0806,
      "step": 14740
    },
    {
      "epoch": 3.16116588084012,
      "grad_norm": 0.004339509177953005,
      "learning_rate": 1.5785112158879842e-05,
      "loss": 0.1347,
      "step": 14750
    },
    {
      "epoch": 3.1633090441491643,
      "grad_norm": 0.0017180998111143708,
      "learning_rate": 1.5782254607801116e-05,
      "loss": 0.2591,
      "step": 14760
    },
    {
      "epoch": 3.165452207458208,
      "grad_norm": 0.0049932110123336315,
      "learning_rate": 1.577939705672239e-05,
      "loss": 0.4616,
      "step": 14770
    },
    {
      "epoch": 3.1675953707672524,
      "grad_norm": 0.057021528482437134,
      "learning_rate": 1.5776539505643664e-05,
      "loss": 0.0932,
      "step": 14780
    },
    {
      "epoch": 3.1697385340762967,
      "grad_norm": 0.04800848290324211,
      "learning_rate": 1.5773681954564938e-05,
      "loss": 0.3507,
      "step": 14790
    },
    {
      "epoch": 3.1718816973853405,
      "grad_norm": 0.018918709829449654,
      "learning_rate": 1.5770824403486215e-05,
      "loss": 0.2162,
      "step": 14800
    },
    {
      "epoch": 3.174024860694385,
      "grad_norm": 0.08354691416025162,
      "learning_rate": 1.576796685240749e-05,
      "loss": 0.1871,
      "step": 14810
    },
    {
      "epoch": 3.176168024003429,
      "grad_norm": 0.06122244894504547,
      "learning_rate": 1.5765109301328763e-05,
      "loss": 0.1963,
      "step": 14820
    },
    {
      "epoch": 3.1783111873124734,
      "grad_norm": 0.05057104304432869,
      "learning_rate": 1.5762251750250037e-05,
      "loss": 0.2586,
      "step": 14830
    },
    {
      "epoch": 3.1804543506215173,
      "grad_norm": 0.15833772718906403,
      "learning_rate": 1.575939419917131e-05,
      "loss": 0.3904,
      "step": 14840
    },
    {
      "epoch": 3.1825975139305616,
      "grad_norm": 0.04855423793196678,
      "learning_rate": 1.5756536648092585e-05,
      "loss": 0.0733,
      "step": 14850
    },
    {
      "epoch": 3.184740677239606,
      "grad_norm": 95.17194366455078,
      "learning_rate": 1.5753679097013862e-05,
      "loss": 0.2575,
      "step": 14860
    },
    {
      "epoch": 3.1868838405486497,
      "grad_norm": 0.020673800259828568,
      "learning_rate": 1.5750821545935136e-05,
      "loss": 0.2029,
      "step": 14870
    },
    {
      "epoch": 3.189027003857694,
      "grad_norm": 0.055088285356760025,
      "learning_rate": 1.574796399485641e-05,
      "loss": 0.1936,
      "step": 14880
    },
    {
      "epoch": 3.1911701671667383,
      "grad_norm": 91.61756896972656,
      "learning_rate": 1.5745106443777684e-05,
      "loss": 0.4376,
      "step": 14890
    },
    {
      "epoch": 3.193313330475782,
      "grad_norm": 0.012143716216087341,
      "learning_rate": 1.5742248892698958e-05,
      "loss": 0.1243,
      "step": 14900
    },
    {
      "epoch": 3.1954564937848264,
      "grad_norm": 2.6990432739257812,
      "learning_rate": 1.5739391341620235e-05,
      "loss": 0.2239,
      "step": 14910
    },
    {
      "epoch": 3.1975996570938707,
      "grad_norm": 25.640119552612305,
      "learning_rate": 1.573653379054151e-05,
      "loss": 0.0317,
      "step": 14920
    },
    {
      "epoch": 3.1997428204029146,
      "grad_norm": 0.13254235684871674,
      "learning_rate": 1.573367623946278e-05,
      "loss": 0.004,
      "step": 14930
    },
    {
      "epoch": 3.201885983711959,
      "grad_norm": 0.0628039538860321,
      "learning_rate": 1.5730818688384057e-05,
      "loss": 0.2428,
      "step": 14940
    },
    {
      "epoch": 3.204029147021003,
      "grad_norm": 0.0038063335232436657,
      "learning_rate": 1.572796113730533e-05,
      "loss": 0.3679,
      "step": 14950
    },
    {
      "epoch": 3.206172310330047,
      "grad_norm": 0.01956792362034321,
      "learning_rate": 1.5725103586226605e-05,
      "loss": 0.0005,
      "step": 14960
    },
    {
      "epoch": 3.2083154736390913,
      "grad_norm": 46.8354606628418,
      "learning_rate": 1.572224603514788e-05,
      "loss": 0.2324,
      "step": 14970
    },
    {
      "epoch": 3.2104586369481356,
      "grad_norm": 0.02262246608734131,
      "learning_rate": 1.5719388484069153e-05,
      "loss": 0.3138,
      "step": 14980
    },
    {
      "epoch": 3.2126018002571795,
      "grad_norm": 0.10862871259450912,
      "learning_rate": 1.5716530932990426e-05,
      "loss": 0.2901,
      "step": 14990
    },
    {
      "epoch": 3.2147449635662237,
      "grad_norm": 0.026857784017920494,
      "learning_rate": 1.5713673381911704e-05,
      "loss": 0.3256,
      "step": 15000
    },
    {
      "epoch": 3.216888126875268,
      "grad_norm": 0.023075303062796593,
      "learning_rate": 1.5710815830832978e-05,
      "loss": 0.0019,
      "step": 15010
    },
    {
      "epoch": 3.219031290184312,
      "grad_norm": 84.67975616455078,
      "learning_rate": 1.570795827975425e-05,
      "loss": 0.3237,
      "step": 15020
    },
    {
      "epoch": 3.221174453493356,
      "grad_norm": 0.5548136830329895,
      "learning_rate": 1.5705100728675526e-05,
      "loss": 0.1914,
      "step": 15030
    },
    {
      "epoch": 3.2233176168024005,
      "grad_norm": 23.154653549194336,
      "learning_rate": 1.57022431775968e-05,
      "loss": 0.5012,
      "step": 15040
    },
    {
      "epoch": 3.2254607801114443,
      "grad_norm": 0.06695126742124557,
      "learning_rate": 1.5699385626518077e-05,
      "loss": 0.0008,
      "step": 15050
    },
    {
      "epoch": 3.2276039434204886,
      "grad_norm": 0.03670088201761246,
      "learning_rate": 1.569652807543935e-05,
      "loss": 0.0008,
      "step": 15060
    },
    {
      "epoch": 3.229747106729533,
      "grad_norm": 143.2795867919922,
      "learning_rate": 1.5693670524360625e-05,
      "loss": 0.5096,
      "step": 15070
    },
    {
      "epoch": 3.2318902700385768,
      "grad_norm": 0.021372469142079353,
      "learning_rate": 1.56908129732819e-05,
      "loss": 0.0588,
      "step": 15080
    },
    {
      "epoch": 3.234033433347621,
      "grad_norm": 0.059852950274944305,
      "learning_rate": 1.5687955422203173e-05,
      "loss": 0.0028,
      "step": 15090
    },
    {
      "epoch": 3.2361765966566653,
      "grad_norm": 16.62447738647461,
      "learning_rate": 1.568509787112445e-05,
      "loss": 0.4092,
      "step": 15100
    },
    {
      "epoch": 3.238319759965709,
      "grad_norm": 0.011994498781859875,
      "learning_rate": 1.5682240320045724e-05,
      "loss": 0.0005,
      "step": 15110
    },
    {
      "epoch": 3.2404629232747535,
      "grad_norm": 0.010539950802922249,
      "learning_rate": 1.5679382768966998e-05,
      "loss": 0.1326,
      "step": 15120
    },
    {
      "epoch": 3.242606086583798,
      "grad_norm": 0.007223133929073811,
      "learning_rate": 1.567652521788827e-05,
      "loss": 0.2379,
      "step": 15130
    },
    {
      "epoch": 3.2447492498928416,
      "grad_norm": 30.03463363647461,
      "learning_rate": 1.5673667666809546e-05,
      "loss": 0.138,
      "step": 15140
    },
    {
      "epoch": 3.246892413201886,
      "grad_norm": 0.035678621381521225,
      "learning_rate": 1.567081011573082e-05,
      "loss": 0.303,
      "step": 15150
    },
    {
      "epoch": 3.2490355765109302,
      "grad_norm": 0.007401604205369949,
      "learning_rate": 1.5667952564652093e-05,
      "loss": 0.0775,
      "step": 15160
    },
    {
      "epoch": 3.2511787398199745,
      "grad_norm": 0.008206572383642197,
      "learning_rate": 1.5665095013573367e-05,
      "loss": 0.0024,
      "step": 15170
    },
    {
      "epoch": 3.2533219031290184,
      "grad_norm": 0.03548944368958473,
      "learning_rate": 1.566223746249464e-05,
      "loss": 0.1423,
      "step": 15180
    },
    {
      "epoch": 3.2554650664380627,
      "grad_norm": 84.21208190917969,
      "learning_rate": 1.565937991141592e-05,
      "loss": 0.2997,
      "step": 15190
    },
    {
      "epoch": 3.257608229747107,
      "grad_norm": 0.007707062177360058,
      "learning_rate": 1.5656522360337193e-05,
      "loss": 0.2258,
      "step": 15200
    },
    {
      "epoch": 3.259751393056151,
      "grad_norm": 29.39351463317871,
      "learning_rate": 1.5653664809258466e-05,
      "loss": 0.1652,
      "step": 15210
    },
    {
      "epoch": 3.261894556365195,
      "grad_norm": 0.09457090497016907,
      "learning_rate": 1.565080725817974e-05,
      "loss": 0.3454,
      "step": 15220
    },
    {
      "epoch": 3.2640377196742394,
      "grad_norm": 0.01065361499786377,
      "learning_rate": 1.5647949707101014e-05,
      "loss": 0.1586,
      "step": 15230
    },
    {
      "epoch": 3.2661808829832832,
      "grad_norm": 0.01875886879861355,
      "learning_rate": 1.564509215602229e-05,
      "loss": 0.0017,
      "step": 15240
    },
    {
      "epoch": 3.2683240462923275,
      "grad_norm": 0.20401650667190552,
      "learning_rate": 1.5642234604943566e-05,
      "loss": 0.4656,
      "step": 15250
    },
    {
      "epoch": 3.270467209601372,
      "grad_norm": 0.006465076934546232,
      "learning_rate": 1.563937705386484e-05,
      "loss": 0.0006,
      "step": 15260
    },
    {
      "epoch": 3.2726103729104157,
      "grad_norm": 1.037856936454773,
      "learning_rate": 1.5636519502786113e-05,
      "loss": 0.001,
      "step": 15270
    },
    {
      "epoch": 3.27475353621946,
      "grad_norm": 0.06665538251399994,
      "learning_rate": 1.5633661951707387e-05,
      "loss": 0.1755,
      "step": 15280
    },
    {
      "epoch": 3.2768966995285043,
      "grad_norm": 0.032269857823848724,
      "learning_rate": 1.5630804400628665e-05,
      "loss": 0.0015,
      "step": 15290
    },
    {
      "epoch": 3.279039862837548,
      "grad_norm": 0.017677104100584984,
      "learning_rate": 1.562794684954994e-05,
      "loss": 0.0042,
      "step": 15300
    },
    {
      "epoch": 3.2811830261465924,
      "grad_norm": 0.0061521087773144245,
      "learning_rate": 1.5625089298471213e-05,
      "loss": 0.2653,
      "step": 15310
    },
    {
      "epoch": 3.2833261894556367,
      "grad_norm": 0.00793038122355938,
      "learning_rate": 1.5622231747392486e-05,
      "loss": 0.0018,
      "step": 15320
    },
    {
      "epoch": 3.2854693527646806,
      "grad_norm": 0.007158834487199783,
      "learning_rate": 1.561937419631376e-05,
      "loss": 0.2573,
      "step": 15330
    },
    {
      "epoch": 3.287612516073725,
      "grad_norm": 0.018280208110809326,
      "learning_rate": 1.5616516645235034e-05,
      "loss": 0.2019,
      "step": 15340
    },
    {
      "epoch": 3.289755679382769,
      "grad_norm": 32.36411666870117,
      "learning_rate": 1.561365909415631e-05,
      "loss": 0.5486,
      "step": 15350
    },
    {
      "epoch": 3.291898842691813,
      "grad_norm": 38.42123031616211,
      "learning_rate": 1.5610801543077582e-05,
      "loss": 0.1822,
      "step": 15360
    },
    {
      "epoch": 3.2940420060008573,
      "grad_norm": 0.16267983615398407,
      "learning_rate": 1.5607943991998856e-05,
      "loss": 0.1224,
      "step": 15370
    },
    {
      "epoch": 3.2961851693099016,
      "grad_norm": 0.013296816498041153,
      "learning_rate": 1.5605086440920133e-05,
      "loss": 0.1937,
      "step": 15380
    },
    {
      "epoch": 3.2983283326189454,
      "grad_norm": 0.024312306195497513,
      "learning_rate": 1.5602228889841407e-05,
      "loss": 0.0007,
      "step": 15390
    },
    {
      "epoch": 3.3004714959279897,
      "grad_norm": 0.011066569946706295,
      "learning_rate": 1.559937133876268e-05,
      "loss": 0.2149,
      "step": 15400
    },
    {
      "epoch": 3.302614659237034,
      "grad_norm": 0.031770773231983185,
      "learning_rate": 1.5596513787683955e-05,
      "loss": 0.3792,
      "step": 15410
    },
    {
      "epoch": 3.304757822546078,
      "grad_norm": 0.019002145156264305,
      "learning_rate": 1.559365623660523e-05,
      "loss": 0.0009,
      "step": 15420
    },
    {
      "epoch": 3.306900985855122,
      "grad_norm": 0.022191058844327927,
      "learning_rate": 1.5590798685526506e-05,
      "loss": 0.0043,
      "step": 15430
    },
    {
      "epoch": 3.3090441491641664,
      "grad_norm": 0.006629146635532379,
      "learning_rate": 1.558794113444778e-05,
      "loss": 0.4828,
      "step": 15440
    },
    {
      "epoch": 3.3111873124732103,
      "grad_norm": 0.01421236339956522,
      "learning_rate": 1.5585083583369054e-05,
      "loss": 0.0002,
      "step": 15450
    },
    {
      "epoch": 3.3133304757822546,
      "grad_norm": 0.007685512769967318,
      "learning_rate": 1.5582226032290328e-05,
      "loss": 0.0006,
      "step": 15460
    },
    {
      "epoch": 3.315473639091299,
      "grad_norm": 0.009231001138687134,
      "learning_rate": 1.5579368481211602e-05,
      "loss": 0.4223,
      "step": 15470
    },
    {
      "epoch": 3.3176168024003427,
      "grad_norm": 0.01925591379404068,
      "learning_rate": 1.5576510930132876e-05,
      "loss": 0.2514,
      "step": 15480
    },
    {
      "epoch": 3.319759965709387,
      "grad_norm": 0.004546415060758591,
      "learning_rate": 1.5573653379054153e-05,
      "loss": 0.0016,
      "step": 15490
    },
    {
      "epoch": 3.3219031290184313,
      "grad_norm": 0.7070993185043335,
      "learning_rate": 1.5570795827975427e-05,
      "loss": 0.2223,
      "step": 15500
    },
    {
      "epoch": 3.324046292327475,
      "grad_norm": 35.7337532043457,
      "learning_rate": 1.55679382768967e-05,
      "loss": 0.3093,
      "step": 15510
    },
    {
      "epoch": 3.3261894556365195,
      "grad_norm": 0.01100990455597639,
      "learning_rate": 1.5565080725817975e-05,
      "loss": 0.234,
      "step": 15520
    },
    {
      "epoch": 3.3283326189455638,
      "grad_norm": 0.03141509369015694,
      "learning_rate": 1.556222317473925e-05,
      "loss": 0.2245,
      "step": 15530
    },
    {
      "epoch": 3.3304757822546076,
      "grad_norm": 0.004864171147346497,
      "learning_rate": 1.5559365623660526e-05,
      "loss": 0.0027,
      "step": 15540
    },
    {
      "epoch": 3.332618945563652,
      "grad_norm": 0.03196060284972191,
      "learning_rate": 1.55565080725818e-05,
      "loss": 0.1937,
      "step": 15550
    },
    {
      "epoch": 3.334762108872696,
      "grad_norm": 0.04874846339225769,
      "learning_rate": 1.5553650521503074e-05,
      "loss": 0.23,
      "step": 15560
    },
    {
      "epoch": 3.33690527218174,
      "grad_norm": 0.04806158319115639,
      "learning_rate": 1.5550792970424348e-05,
      "loss": 0.3653,
      "step": 15570
    },
    {
      "epoch": 3.3390484354907843,
      "grad_norm": 23.00959587097168,
      "learning_rate": 1.5547935419345622e-05,
      "loss": 0.2479,
      "step": 15580
    },
    {
      "epoch": 3.3411915987998286,
      "grad_norm": 0.06745249778032303,
      "learning_rate": 1.5545077868266896e-05,
      "loss": 0.306,
      "step": 15590
    },
    {
      "epoch": 3.3433347621088725,
      "grad_norm": 0.6833707094192505,
      "learning_rate": 1.554222031718817e-05,
      "loss": 0.3238,
      "step": 15600
    },
    {
      "epoch": 3.3454779254179168,
      "grad_norm": 0.01277448795735836,
      "learning_rate": 1.5539362766109444e-05,
      "loss": 0.3112,
      "step": 15610
    },
    {
      "epoch": 3.347621088726961,
      "grad_norm": 0.06687791645526886,
      "learning_rate": 1.5536505215030718e-05,
      "loss": 0.2692,
      "step": 15620
    },
    {
      "epoch": 3.349764252036005,
      "grad_norm": 0.1151338741183281,
      "learning_rate": 1.5533647663951995e-05,
      "loss": 0.0029,
      "step": 15630
    },
    {
      "epoch": 3.351907415345049,
      "grad_norm": 0.023453328758478165,
      "learning_rate": 1.553079011287327e-05,
      "loss": 0.2227,
      "step": 15640
    },
    {
      "epoch": 3.3540505786540935,
      "grad_norm": 0.022350899875164032,
      "learning_rate": 1.5527932561794543e-05,
      "loss": 0.0021,
      "step": 15650
    },
    {
      "epoch": 3.3561937419631374,
      "grad_norm": 0.03976623713970184,
      "learning_rate": 1.5525075010715817e-05,
      "loss": 0.0006,
      "step": 15660
    },
    {
      "epoch": 3.3583369052721816,
      "grad_norm": 0.010126151144504547,
      "learning_rate": 1.552221745963709e-05,
      "loss": 0.7267,
      "step": 15670
    },
    {
      "epoch": 3.360480068581226,
      "grad_norm": 0.2138393372297287,
      "learning_rate": 1.5519359908558368e-05,
      "loss": 0.0009,
      "step": 15680
    },
    {
      "epoch": 3.36262323189027,
      "grad_norm": 0.09399837255477905,
      "learning_rate": 1.5516502357479642e-05,
      "loss": 0.1499,
      "step": 15690
    },
    {
      "epoch": 3.364766395199314,
      "grad_norm": 0.12977439165115356,
      "learning_rate": 1.5513644806400916e-05,
      "loss": 0.2565,
      "step": 15700
    },
    {
      "epoch": 3.3669095585083584,
      "grad_norm": 0.29984790086746216,
      "learning_rate": 1.551078725532219e-05,
      "loss": 0.0007,
      "step": 15710
    },
    {
      "epoch": 3.3690527218174027,
      "grad_norm": 0.23700807988643646,
      "learning_rate": 1.5507929704243464e-05,
      "loss": 0.4033,
      "step": 15720
    },
    {
      "epoch": 3.3711958851264465,
      "grad_norm": 25.707914352416992,
      "learning_rate": 1.550507215316474e-05,
      "loss": 0.7429,
      "step": 15730
    },
    {
      "epoch": 3.373339048435491,
      "grad_norm": 0.01806049793958664,
      "learning_rate": 1.5502214602086015e-05,
      "loss": 0.0018,
      "step": 15740
    },
    {
      "epoch": 3.375482211744535,
      "grad_norm": 0.05731138959527016,
      "learning_rate": 1.549935705100729e-05,
      "loss": 0.1931,
      "step": 15750
    },
    {
      "epoch": 3.377625375053579,
      "grad_norm": 215.72264099121094,
      "learning_rate": 1.5496499499928563e-05,
      "loss": 0.1909,
      "step": 15760
    },
    {
      "epoch": 3.3797685383626233,
      "grad_norm": 0.16968700289726257,
      "learning_rate": 1.5493641948849837e-05,
      "loss": 0.072,
      "step": 15770
    },
    {
      "epoch": 3.3819117016716675,
      "grad_norm": 0.09649474173784256,
      "learning_rate": 1.549078439777111e-05,
      "loss": 0.1511,
      "step": 15780
    },
    {
      "epoch": 3.3840548649807114,
      "grad_norm": 0.08792705088853836,
      "learning_rate": 1.5487926846692385e-05,
      "loss": 0.4332,
      "step": 15790
    },
    {
      "epoch": 3.3861980282897557,
      "grad_norm": 0.01585676148533821,
      "learning_rate": 1.548506929561366e-05,
      "loss": 0.3868,
      "step": 15800
    },
    {
      "epoch": 3.3883411915988,
      "grad_norm": 0.02063743770122528,
      "learning_rate": 1.5482211744534933e-05,
      "loss": 0.1446,
      "step": 15810
    },
    {
      "epoch": 3.390484354907844,
      "grad_norm": 66.8594741821289,
      "learning_rate": 1.547935419345621e-05,
      "loss": 0.0417,
      "step": 15820
    },
    {
      "epoch": 3.392627518216888,
      "grad_norm": 50.61132049560547,
      "learning_rate": 1.5476496642377484e-05,
      "loss": 0.5168,
      "step": 15830
    },
    {
      "epoch": 3.3947706815259324,
      "grad_norm": 2.2256112098693848,
      "learning_rate": 1.5473639091298758e-05,
      "loss": 0.0429,
      "step": 15840
    },
    {
      "epoch": 3.3969138448349763,
      "grad_norm": 0.044012974947690964,
      "learning_rate": 1.5470781540220032e-05,
      "loss": 0.0083,
      "step": 15850
    },
    {
      "epoch": 3.3990570081440206,
      "grad_norm": 0.028849728405475616,
      "learning_rate": 1.5467923989141306e-05,
      "loss": 0.1752,
      "step": 15860
    },
    {
      "epoch": 3.401200171453065,
      "grad_norm": 0.020454982295632362,
      "learning_rate": 1.5465066438062583e-05,
      "loss": 0.3293,
      "step": 15870
    },
    {
      "epoch": 3.4033433347621087,
      "grad_norm": 0.16247691214084625,
      "learning_rate": 1.5462208886983857e-05,
      "loss": 0.0011,
      "step": 15880
    },
    {
      "epoch": 3.405486498071153,
      "grad_norm": 0.11281882971525192,
      "learning_rate": 1.545935133590513e-05,
      "loss": 0.5176,
      "step": 15890
    },
    {
      "epoch": 3.4076296613801973,
      "grad_norm": 1.0553711652755737,
      "learning_rate": 1.5456493784826405e-05,
      "loss": 0.2436,
      "step": 15900
    },
    {
      "epoch": 3.409772824689241,
      "grad_norm": 0.034360650926828384,
      "learning_rate": 1.545363623374768e-05,
      "loss": 0.3365,
      "step": 15910
    },
    {
      "epoch": 3.4119159879982854,
      "grad_norm": 0.036185018718242645,
      "learning_rate": 1.5450778682668953e-05,
      "loss": 0.0019,
      "step": 15920
    },
    {
      "epoch": 3.4140591513073297,
      "grad_norm": 0.06264129281044006,
      "learning_rate": 1.544792113159023e-05,
      "loss": 0.1402,
      "step": 15930
    },
    {
      "epoch": 3.4162023146163736,
      "grad_norm": 0.0025955999735742807,
      "learning_rate": 1.5445063580511504e-05,
      "loss": 0.1474,
      "step": 15940
    },
    {
      "epoch": 3.418345477925418,
      "grad_norm": 0.07771162688732147,
      "learning_rate": 1.5442206029432778e-05,
      "loss": 0.0009,
      "step": 15950
    },
    {
      "epoch": 3.420488641234462,
      "grad_norm": 0.0036162210162729025,
      "learning_rate": 1.5439348478354052e-05,
      "loss": 0.0033,
      "step": 15960
    },
    {
      "epoch": 3.4226318045435065,
      "grad_norm": 0.017039021477103233,
      "learning_rate": 1.5436490927275326e-05,
      "loss": 0.2097,
      "step": 15970
    },
    {
      "epoch": 3.4247749678525503,
      "grad_norm": 0.0013767435448244214,
      "learning_rate": 1.5433633376196603e-05,
      "loss": 0.0002,
      "step": 15980
    },
    {
      "epoch": 3.4269181311615946,
      "grad_norm": 0.005112932529300451,
      "learning_rate": 1.5430775825117877e-05,
      "loss": 0.5329,
      "step": 15990
    },
    {
      "epoch": 3.429061294470639,
      "grad_norm": 78.15650939941406,
      "learning_rate": 1.5427918274039147e-05,
      "loss": 0.39,
      "step": 16000
    },
    {
      "epoch": 3.4312044577796827,
      "grad_norm": 0.014611300081014633,
      "learning_rate": 1.5425060722960425e-05,
      "loss": 0.2272,
      "step": 16010
    },
    {
      "epoch": 3.433347621088727,
      "grad_norm": 0.02268930710852146,
      "learning_rate": 1.54222031718817e-05,
      "loss": 0.0008,
      "step": 16020
    },
    {
      "epoch": 3.4354907843977713,
      "grad_norm": 0.06936557590961456,
      "learning_rate": 1.5419345620802973e-05,
      "loss": 0.1448,
      "step": 16030
    },
    {
      "epoch": 3.437633947706815,
      "grad_norm": 0.4295896291732788,
      "learning_rate": 1.5416488069724247e-05,
      "loss": 0.0018,
      "step": 16040
    },
    {
      "epoch": 3.4397771110158595,
      "grad_norm": 0.002622453961521387,
      "learning_rate": 1.541363051864552e-05,
      "loss": 0.0005,
      "step": 16050
    },
    {
      "epoch": 3.4419202743249038,
      "grad_norm": 0.24027250707149506,
      "learning_rate": 1.5410772967566794e-05,
      "loss": 0.3781,
      "step": 16060
    },
    {
      "epoch": 3.4440634376339476,
      "grad_norm": 0.030344270169734955,
      "learning_rate": 1.5407915416488072e-05,
      "loss": 0.1603,
      "step": 16070
    },
    {
      "epoch": 3.446206600942992,
      "grad_norm": 0.004340831656008959,
      "learning_rate": 1.5405057865409346e-05,
      "loss": 0.1567,
      "step": 16080
    },
    {
      "epoch": 3.448349764252036,
      "grad_norm": 0.00292397104203701,
      "learning_rate": 1.540220031433062e-05,
      "loss": 0.2043,
      "step": 16090
    },
    {
      "epoch": 3.45049292756108,
      "grad_norm": 0.0037769873160868883,
      "learning_rate": 1.5399342763251894e-05,
      "loss": 0.1118,
      "step": 16100
    },
    {
      "epoch": 3.4526360908701244,
      "grad_norm": 0.4851618707180023,
      "learning_rate": 1.5396485212173167e-05,
      "loss": 0.0703,
      "step": 16110
    },
    {
      "epoch": 3.4547792541791686,
      "grad_norm": 0.0009991765255108476,
      "learning_rate": 1.5393627661094445e-05,
      "loss": 0.5792,
      "step": 16120
    },
    {
      "epoch": 3.4569224174882125,
      "grad_norm": 0.0019947278779000044,
      "learning_rate": 1.539077011001572e-05,
      "loss": 0.0001,
      "step": 16130
    },
    {
      "epoch": 3.459065580797257,
      "grad_norm": 0.0051782941445708275,
      "learning_rate": 1.5387912558936993e-05,
      "loss": 0.0002,
      "step": 16140
    },
    {
      "epoch": 3.461208744106301,
      "grad_norm": 0.005321807693690062,
      "learning_rate": 1.5385055007858267e-05,
      "loss": 0.0021,
      "step": 16150
    },
    {
      "epoch": 3.463351907415345,
      "grad_norm": 0.015501807443797588,
      "learning_rate": 1.538219745677954e-05,
      "loss": 0.5773,
      "step": 16160
    },
    {
      "epoch": 3.4654950707243892,
      "grad_norm": 0.022496048361063004,
      "learning_rate": 1.5379339905700818e-05,
      "loss": 0.1335,
      "step": 16170
    },
    {
      "epoch": 3.4676382340334335,
      "grad_norm": 0.03810618072748184,
      "learning_rate": 1.5376482354622092e-05,
      "loss": 0.1677,
      "step": 16180
    },
    {
      "epoch": 3.4697813973424774,
      "grad_norm": 1.2325249910354614,
      "learning_rate": 1.5373624803543366e-05,
      "loss": 0.2496,
      "step": 16190
    },
    {
      "epoch": 3.4719245606515217,
      "grad_norm": 0.036383725702762604,
      "learning_rate": 1.537076725246464e-05,
      "loss": 0.0661,
      "step": 16200
    },
    {
      "epoch": 3.474067723960566,
      "grad_norm": 0.08613243699073792,
      "learning_rate": 1.5367909701385914e-05,
      "loss": 0.0033,
      "step": 16210
    },
    {
      "epoch": 3.47621088726961,
      "grad_norm": 0.03140478953719139,
      "learning_rate": 1.5365052150307187e-05,
      "loss": 0.443,
      "step": 16220
    },
    {
      "epoch": 3.478354050578654,
      "grad_norm": 23.73222541809082,
      "learning_rate": 1.536219459922846e-05,
      "loss": 0.1745,
      "step": 16230
    },
    {
      "epoch": 3.4804972138876984,
      "grad_norm": 0.03194904699921608,
      "learning_rate": 1.5359337048149735e-05,
      "loss": 0.226,
      "step": 16240
    },
    {
      "epoch": 3.4826403771967422,
      "grad_norm": 0.042528655380010605,
      "learning_rate": 1.535647949707101e-05,
      "loss": 0.3375,
      "step": 16250
    },
    {
      "epoch": 3.4847835405057865,
      "grad_norm": 41.95491027832031,
      "learning_rate": 1.5353621945992287e-05,
      "loss": 0.1049,
      "step": 16260
    },
    {
      "epoch": 3.486926703814831,
      "grad_norm": 0.03720497339963913,
      "learning_rate": 1.535076439491356e-05,
      "loss": 0.0009,
      "step": 16270
    },
    {
      "epoch": 3.4890698671238747,
      "grad_norm": 0.052895791828632355,
      "learning_rate": 1.5347906843834834e-05,
      "loss": 0.268,
      "step": 16280
    },
    {
      "epoch": 3.491213030432919,
      "grad_norm": 0.3487025499343872,
      "learning_rate": 1.534504929275611e-05,
      "loss": 0.0049,
      "step": 16290
    },
    {
      "epoch": 3.4933561937419633,
      "grad_norm": 0.046371180564165115,
      "learning_rate": 1.5342191741677382e-05,
      "loss": 0.0006,
      "step": 16300
    },
    {
      "epoch": 3.495499357051007,
      "grad_norm": 0.005080091767013073,
      "learning_rate": 1.533933419059866e-05,
      "loss": 0.0004,
      "step": 16310
    },
    {
      "epoch": 3.4976425203600514,
      "grad_norm": 0.898871123790741,
      "learning_rate": 1.5336476639519933e-05,
      "loss": 0.1316,
      "step": 16320
    },
    {
      "epoch": 3.4997856836690957,
      "grad_norm": 0.023982694372534752,
      "learning_rate": 1.5333619088441207e-05,
      "loss": 0.4459,
      "step": 16330
    },
    {
      "epoch": 3.5019288469781396,
      "grad_norm": 41.886436462402344,
      "learning_rate": 1.533076153736248e-05,
      "loss": 0.2941,
      "step": 16340
    },
    {
      "epoch": 3.504072010287184,
      "grad_norm": 0.034124813973903656,
      "learning_rate": 1.5327903986283755e-05,
      "loss": 0.0005,
      "step": 16350
    },
    {
      "epoch": 3.506215173596228,
      "grad_norm": 0.05246790125966072,
      "learning_rate": 1.5325046435205033e-05,
      "loss": 0.6184,
      "step": 16360
    },
    {
      "epoch": 3.508358336905272,
      "grad_norm": 0.1370241343975067,
      "learning_rate": 1.5322188884126307e-05,
      "loss": 0.0112,
      "step": 16370
    },
    {
      "epoch": 3.5105015002143163,
      "grad_norm": 0.034363821148872375,
      "learning_rate": 1.531933133304758e-05,
      "loss": 0.0014,
      "step": 16380
    },
    {
      "epoch": 3.5126446635233606,
      "grad_norm": 0.008017200976610184,
      "learning_rate": 1.5316473781968854e-05,
      "loss": 0.0022,
      "step": 16390
    },
    {
      "epoch": 3.5147878268324044,
      "grad_norm": 0.1159205436706543,
      "learning_rate": 1.531361623089013e-05,
      "loss": 0.3569,
      "step": 16400
    },
    {
      "epoch": 3.5169309901414487,
      "grad_norm": 0.003033787477761507,
      "learning_rate": 1.5310758679811402e-05,
      "loss": 0.1145,
      "step": 16410
    },
    {
      "epoch": 3.519074153450493,
      "grad_norm": 25.813199996948242,
      "learning_rate": 1.530790112873268e-05,
      "loss": 0.2424,
      "step": 16420
    },
    {
      "epoch": 3.521217316759537,
      "grad_norm": 0.16626892983913422,
      "learning_rate": 1.530504357765395e-05,
      "loss": 0.3829,
      "step": 16430
    },
    {
      "epoch": 3.523360480068581,
      "grad_norm": 0.012385105714201927,
      "learning_rate": 1.5302186026575224e-05,
      "loss": 0.6069,
      "step": 16440
    },
    {
      "epoch": 3.5255036433776255,
      "grad_norm": 0.039005622267723083,
      "learning_rate": 1.52993284754965e-05,
      "loss": 0.2653,
      "step": 16450
    },
    {
      "epoch": 3.5276468066866693,
      "grad_norm": 0.2092769891023636,
      "learning_rate": 1.5296470924417775e-05,
      "loss": 0.2652,
      "step": 16460
    },
    {
      "epoch": 3.5297899699957136,
      "grad_norm": 0.16599041223526,
      "learning_rate": 1.529361337333905e-05,
      "loss": 0.4267,
      "step": 16470
    },
    {
      "epoch": 3.531933133304758,
      "grad_norm": 0.052818845957517624,
      "learning_rate": 1.5290755822260323e-05,
      "loss": 0.0026,
      "step": 16480
    },
    {
      "epoch": 3.5340762966138017,
      "grad_norm": 0.10610173642635345,
      "learning_rate": 1.5287898271181597e-05,
      "loss": 0.4886,
      "step": 16490
    },
    {
      "epoch": 3.536219459922846,
      "grad_norm": 22.711339950561523,
      "learning_rate": 1.5285040720102874e-05,
      "loss": 0.1507,
      "step": 16500
    },
    {
      "epoch": 3.5383626232318903,
      "grad_norm": 28.738821029663086,
      "learning_rate": 1.5282183169024148e-05,
      "loss": 0.4962,
      "step": 16510
    },
    {
      "epoch": 3.540505786540934,
      "grad_norm": 0.022441349923610687,
      "learning_rate": 1.5279325617945422e-05,
      "loss": 0.3068,
      "step": 16520
    },
    {
      "epoch": 3.5426489498499785,
      "grad_norm": 96.54376220703125,
      "learning_rate": 1.5276468066866696e-05,
      "loss": 0.0221,
      "step": 16530
    },
    {
      "epoch": 3.5447921131590228,
      "grad_norm": 0.047878559678792953,
      "learning_rate": 1.527361051578797e-05,
      "loss": 0.1147,
      "step": 16540
    },
    {
      "epoch": 3.5469352764680666,
      "grad_norm": 0.018949022516608238,
      "learning_rate": 1.5270752964709244e-05,
      "loss": 0.2983,
      "step": 16550
    },
    {
      "epoch": 3.549078439777111,
      "grad_norm": 0.017315518110990524,
      "learning_rate": 1.526789541363052e-05,
      "loss": 0.2065,
      "step": 16560
    },
    {
      "epoch": 3.551221603086155,
      "grad_norm": 0.03568534180521965,
      "learning_rate": 1.5265037862551795e-05,
      "loss": 0.0011,
      "step": 16570
    },
    {
      "epoch": 3.553364766395199,
      "grad_norm": 0.04339540749788284,
      "learning_rate": 1.526218031147307e-05,
      "loss": 0.6022,
      "step": 16580
    },
    {
      "epoch": 3.5555079297042433,
      "grad_norm": 0.06440740823745728,
      "learning_rate": 1.5259322760394343e-05,
      "loss": 0.1682,
      "step": 16590
    },
    {
      "epoch": 3.5576510930132876,
      "grad_norm": 169.9928436279297,
      "learning_rate": 1.5256465209315619e-05,
      "loss": 0.2583,
      "step": 16600
    },
    {
      "epoch": 3.5597942563223315,
      "grad_norm": 24.77052116394043,
      "learning_rate": 1.5253607658236893e-05,
      "loss": 0.4719,
      "step": 16610
    },
    {
      "epoch": 3.561937419631376,
      "grad_norm": 0.10185185819864273,
      "learning_rate": 1.5250750107158168e-05,
      "loss": 0.2444,
      "step": 16620
    },
    {
      "epoch": 3.56408058294042,
      "grad_norm": 0.016735224053263664,
      "learning_rate": 1.5247892556079442e-05,
      "loss": 0.0079,
      "step": 16630
    },
    {
      "epoch": 3.5662237462494644,
      "grad_norm": 0.11822210997343063,
      "learning_rate": 1.5245035005000714e-05,
      "loss": 0.1687,
      "step": 16640
    },
    {
      "epoch": 3.568366909558508,
      "grad_norm": 0.020140092819929123,
      "learning_rate": 1.5242177453921988e-05,
      "loss": 0.0036,
      "step": 16650
    },
    {
      "epoch": 3.5705100728675525,
      "grad_norm": 20.877506256103516,
      "learning_rate": 1.5239319902843264e-05,
      "loss": 0.2505,
      "step": 16660
    },
    {
      "epoch": 3.572653236176597,
      "grad_norm": 0.08029250800609589,
      "learning_rate": 1.5236462351764538e-05,
      "loss": 0.7097,
      "step": 16670
    },
    {
      "epoch": 3.5747963994856407,
      "grad_norm": 0.04084015637636185,
      "learning_rate": 1.5233604800685814e-05,
      "loss": 0.3386,
      "step": 16680
    },
    {
      "epoch": 3.576939562794685,
      "grad_norm": 25.635452270507812,
      "learning_rate": 1.5230747249607087e-05,
      "loss": 0.3234,
      "step": 16690
    },
    {
      "epoch": 3.5790827261037292,
      "grad_norm": 0.04019846022129059,
      "learning_rate": 1.5227889698528361e-05,
      "loss": 0.0013,
      "step": 16700
    },
    {
      "epoch": 3.581225889412773,
      "grad_norm": 0.11023807525634766,
      "learning_rate": 1.5225032147449637e-05,
      "loss": 0.0009,
      "step": 16710
    },
    {
      "epoch": 3.5833690527218174,
      "grad_norm": 0.08151694387197495,
      "learning_rate": 1.5222174596370911e-05,
      "loss": 0.0462,
      "step": 16720
    },
    {
      "epoch": 3.5855122160308617,
      "grad_norm": 0.02445787377655506,
      "learning_rate": 1.5219317045292185e-05,
      "loss": 0.0184,
      "step": 16730
    },
    {
      "epoch": 3.587655379339906,
      "grad_norm": 0.08029212802648544,
      "learning_rate": 1.521645949421346e-05,
      "loss": 0.0012,
      "step": 16740
    },
    {
      "epoch": 3.58979854264895,
      "grad_norm": 0.012444783933460712,
      "learning_rate": 1.5213601943134734e-05,
      "loss": 0.0022,
      "step": 16750
    },
    {
      "epoch": 3.591941705957994,
      "grad_norm": 0.07815847545862198,
      "learning_rate": 1.521074439205601e-05,
      "loss": 0.1092,
      "step": 16760
    },
    {
      "epoch": 3.5940848692670384,
      "grad_norm": 0.005806769244372845,
      "learning_rate": 1.5207886840977284e-05,
      "loss": 0.2113,
      "step": 16770
    },
    {
      "epoch": 3.5962280325760823,
      "grad_norm": 0.019014662131667137,
      "learning_rate": 1.5205029289898558e-05,
      "loss": 0.2226,
      "step": 16780
    },
    {
      "epoch": 3.5983711958851265,
      "grad_norm": 0.03991726413369179,
      "learning_rate": 1.5202171738819834e-05,
      "loss": 0.0826,
      "step": 16790
    },
    {
      "epoch": 3.600514359194171,
      "grad_norm": 0.020687421783804893,
      "learning_rate": 1.5199314187741107e-05,
      "loss": 0.0006,
      "step": 16800
    },
    {
      "epoch": 3.6026575225032147,
      "grad_norm": 0.009011256508529186,
      "learning_rate": 1.5196456636662383e-05,
      "loss": 0.0005,
      "step": 16810
    },
    {
      "epoch": 3.604800685812259,
      "grad_norm": 80.36995697021484,
      "learning_rate": 1.5193599085583657e-05,
      "loss": 0.4462,
      "step": 16820
    },
    {
      "epoch": 3.6069438491213033,
      "grad_norm": 0.019407490268349648,
      "learning_rate": 1.5190741534504931e-05,
      "loss": 0.4099,
      "step": 16830
    },
    {
      "epoch": 3.609087012430347,
      "grad_norm": 0.026706673204898834,
      "learning_rate": 1.5187883983426207e-05,
      "loss": 0.3021,
      "step": 16840
    },
    {
      "epoch": 3.6112301757393914,
      "grad_norm": 0.038460563868284225,
      "learning_rate": 1.518502643234748e-05,
      "loss": 0.1044,
      "step": 16850
    },
    {
      "epoch": 3.6133733390484357,
      "grad_norm": 78.8111343383789,
      "learning_rate": 1.5182168881268753e-05,
      "loss": 0.3798,
      "step": 16860
    },
    {
      "epoch": 3.6155165023574796,
      "grad_norm": 0.007088380865752697,
      "learning_rate": 1.5179311330190027e-05,
      "loss": 0.0006,
      "step": 16870
    },
    {
      "epoch": 3.617659665666524,
      "grad_norm": 0.011068952269852161,
      "learning_rate": 1.5176453779111302e-05,
      "loss": 0.4226,
      "step": 16880
    },
    {
      "epoch": 3.619802828975568,
      "grad_norm": 0.03714015334844589,
      "learning_rate": 1.5173596228032576e-05,
      "loss": 0.0004,
      "step": 16890
    },
    {
      "epoch": 3.621945992284612,
      "grad_norm": 24.186904907226562,
      "learning_rate": 1.5170738676953852e-05,
      "loss": 0.4255,
      "step": 16900
    },
    {
      "epoch": 3.6240891555936563,
      "grad_norm": 0.022208428010344505,
      "learning_rate": 1.5167881125875126e-05,
      "loss": 0.3345,
      "step": 16910
    },
    {
      "epoch": 3.6262323189027006,
      "grad_norm": 0.2720484435558319,
      "learning_rate": 1.51650235747964e-05,
      "loss": 0.2552,
      "step": 16920
    },
    {
      "epoch": 3.6283754822117444,
      "grad_norm": 0.080071359872818,
      "learning_rate": 1.5162166023717675e-05,
      "loss": 0.0912,
      "step": 16930
    },
    {
      "epoch": 3.6305186455207887,
      "grad_norm": 0.021167490631341934,
      "learning_rate": 1.515930847263895e-05,
      "loss": 0.1115,
      "step": 16940
    },
    {
      "epoch": 3.632661808829833,
      "grad_norm": 0.06493325531482697,
      "learning_rate": 1.5156450921560225e-05,
      "loss": 0.266,
      "step": 16950
    },
    {
      "epoch": 3.634804972138877,
      "grad_norm": 0.25159916281700134,
      "learning_rate": 1.5153593370481499e-05,
      "loss": 0.0027,
      "step": 16960
    },
    {
      "epoch": 3.636948135447921,
      "grad_norm": 30.333887100219727,
      "learning_rate": 1.5150735819402773e-05,
      "loss": 0.4544,
      "step": 16970
    },
    {
      "epoch": 3.6390912987569655,
      "grad_norm": 0.026588650420308113,
      "learning_rate": 1.5147878268324048e-05,
      "loss": 0.1771,
      "step": 16980
    },
    {
      "epoch": 3.6412344620660093,
      "grad_norm": 0.14618174731731415,
      "learning_rate": 1.5145020717245322e-05,
      "loss": 0.3174,
      "step": 16990
    },
    {
      "epoch": 3.6433776253750536,
      "grad_norm": 0.02697322703897953,
      "learning_rate": 1.5142163166166596e-05,
      "loss": 0.0019,
      "step": 17000
    },
    {
      "epoch": 3.645520788684098,
      "grad_norm": 1.7210712432861328,
      "learning_rate": 1.5139305615087872e-05,
      "loss": 0.5066,
      "step": 17010
    },
    {
      "epoch": 3.6476639519931418,
      "grad_norm": 0.02624179609119892,
      "learning_rate": 1.5136448064009146e-05,
      "loss": 0.0147,
      "step": 17020
    },
    {
      "epoch": 3.649807115302186,
      "grad_norm": 0.017683357000350952,
      "learning_rate": 1.5133590512930421e-05,
      "loss": 0.3997,
      "step": 17030
    },
    {
      "epoch": 3.6519502786112303,
      "grad_norm": 0.014296643435955048,
      "learning_rate": 1.5130732961851695e-05,
      "loss": 0.1763,
      "step": 17040
    },
    {
      "epoch": 3.654093441920274,
      "grad_norm": 0.016836538910865784,
      "learning_rate": 1.512787541077297e-05,
      "loss": 0.4805,
      "step": 17050
    },
    {
      "epoch": 3.6562366052293185,
      "grad_norm": 0.05745099112391472,
      "learning_rate": 1.5125017859694245e-05,
      "loss": 0.2294,
      "step": 17060
    },
    {
      "epoch": 3.6583797685383628,
      "grad_norm": 0.11635541915893555,
      "learning_rate": 1.5122160308615517e-05,
      "loss": 0.2221,
      "step": 17070
    },
    {
      "epoch": 3.6605229318474066,
      "grad_norm": 0.034210771322250366,
      "learning_rate": 1.5119302757536791e-05,
      "loss": 0.0581,
      "step": 17080
    },
    {
      "epoch": 3.662666095156451,
      "grad_norm": 0.02663712203502655,
      "learning_rate": 1.5116445206458067e-05,
      "loss": 0.1866,
      "step": 17090
    },
    {
      "epoch": 3.664809258465495,
      "grad_norm": 0.042536720633506775,
      "learning_rate": 1.511358765537934e-05,
      "loss": 0.1633,
      "step": 17100
    },
    {
      "epoch": 3.666952421774539,
      "grad_norm": 0.00993147399276495,
      "learning_rate": 1.5110730104300614e-05,
      "loss": 0.1608,
      "step": 17110
    },
    {
      "epoch": 3.6690955850835834,
      "grad_norm": 0.033146463334560394,
      "learning_rate": 1.510787255322189e-05,
      "loss": 0.4753,
      "step": 17120
    },
    {
      "epoch": 3.6712387483926276,
      "grad_norm": 0.0373498871922493,
      "learning_rate": 1.5105015002143164e-05,
      "loss": 0.1809,
      "step": 17130
    },
    {
      "epoch": 3.6733819117016715,
      "grad_norm": 0.38106995820999146,
      "learning_rate": 1.5102157451064438e-05,
      "loss": 0.1532,
      "step": 17140
    },
    {
      "epoch": 3.675525075010716,
      "grad_norm": 0.014603549614548683,
      "learning_rate": 1.5099299899985714e-05,
      "loss": 0.0017,
      "step": 17150
    },
    {
      "epoch": 3.67766823831976,
      "grad_norm": 141.0654296875,
      "learning_rate": 1.5096442348906988e-05,
      "loss": 0.1537,
      "step": 17160
    },
    {
      "epoch": 3.679811401628804,
      "grad_norm": 0.0718546137213707,
      "learning_rate": 1.5093584797828263e-05,
      "loss": 0.2587,
      "step": 17170
    },
    {
      "epoch": 3.6819545649378482,
      "grad_norm": 0.013800025917589664,
      "learning_rate": 1.5090727246749537e-05,
      "loss": 0.291,
      "step": 17180
    },
    {
      "epoch": 3.6840977282468925,
      "grad_norm": 21.65682601928711,
      "learning_rate": 1.5087869695670811e-05,
      "loss": 0.4482,
      "step": 17190
    },
    {
      "epoch": 3.6862408915559364,
      "grad_norm": 0.06500124931335449,
      "learning_rate": 1.5085012144592087e-05,
      "loss": 0.0015,
      "step": 17200
    },
    {
      "epoch": 3.6883840548649807,
      "grad_norm": 0.02860306203365326,
      "learning_rate": 1.508215459351336e-05,
      "loss": 0.5396,
      "step": 17210
    },
    {
      "epoch": 3.690527218174025,
      "grad_norm": 0.018106596544384956,
      "learning_rate": 1.5079297042434634e-05,
      "loss": 0.1237,
      "step": 17220
    },
    {
      "epoch": 3.692670381483069,
      "grad_norm": 144.7631378173828,
      "learning_rate": 1.507643949135591e-05,
      "loss": 0.2907,
      "step": 17230
    },
    {
      "epoch": 3.694813544792113,
      "grad_norm": 0.16045144200325012,
      "learning_rate": 1.5073581940277184e-05,
      "loss": 0.1219,
      "step": 17240
    },
    {
      "epoch": 3.6969567081011574,
      "grad_norm": 0.03999507799744606,
      "learning_rate": 1.507072438919846e-05,
      "loss": 0.1633,
      "step": 17250
    },
    {
      "epoch": 3.6990998714102012,
      "grad_norm": 0.011303767561912537,
      "learning_rate": 1.5067866838119734e-05,
      "loss": 0.0015,
      "step": 17260
    },
    {
      "epoch": 3.7012430347192455,
      "grad_norm": 0.0030154844280332327,
      "learning_rate": 1.5065009287041008e-05,
      "loss": 0.0008,
      "step": 17270
    },
    {
      "epoch": 3.70338619802829,
      "grad_norm": 0.09067413210868835,
      "learning_rate": 1.5062151735962283e-05,
      "loss": 0.4014,
      "step": 17280
    },
    {
      "epoch": 3.7055293613373337,
      "grad_norm": 0.05721944198012352,
      "learning_rate": 1.5059294184883555e-05,
      "loss": 0.1528,
      "step": 17290
    },
    {
      "epoch": 3.707672524646378,
      "grad_norm": 4.812074184417725,
      "learning_rate": 1.505643663380483e-05,
      "loss": 0.1394,
      "step": 17300
    },
    {
      "epoch": 3.7098156879554223,
      "grad_norm": 0.02515990473330021,
      "learning_rate": 1.5053579082726105e-05,
      "loss": 0.0011,
      "step": 17310
    },
    {
      "epoch": 3.711958851264466,
      "grad_norm": 0.157090961933136,
      "learning_rate": 1.5050721531647379e-05,
      "loss": 0.0031,
      "step": 17320
    },
    {
      "epoch": 3.7141020145735104,
      "grad_norm": 0.018015369772911072,
      "learning_rate": 1.5047863980568653e-05,
      "loss": 0.2462,
      "step": 17330
    },
    {
      "epoch": 3.7162451778825547,
      "grad_norm": 7.17178201675415,
      "learning_rate": 1.5045006429489928e-05,
      "loss": 0.18,
      "step": 17340
    },
    {
      "epoch": 3.7183883411915986,
      "grad_norm": 0.018673928454518318,
      "learning_rate": 1.5042148878411202e-05,
      "loss": 0.0028,
      "step": 17350
    },
    {
      "epoch": 3.720531504500643,
      "grad_norm": 139.11839294433594,
      "learning_rate": 1.5039291327332476e-05,
      "loss": 0.3055,
      "step": 17360
    },
    {
      "epoch": 3.722674667809687,
      "grad_norm": 0.022961944341659546,
      "learning_rate": 1.5036433776253752e-05,
      "loss": 1.0247,
      "step": 17370
    },
    {
      "epoch": 3.724817831118731,
      "grad_norm": 0.021792970597743988,
      "learning_rate": 1.5033576225175026e-05,
      "loss": 0.273,
      "step": 17380
    },
    {
      "epoch": 3.7269609944277753,
      "grad_norm": 0.33673518896102905,
      "learning_rate": 1.5030718674096301e-05,
      "loss": 0.3238,
      "step": 17390
    },
    {
      "epoch": 3.7291041577368196,
      "grad_norm": 0.03567482903599739,
      "learning_rate": 1.5027861123017575e-05,
      "loss": 0.0024,
      "step": 17400
    },
    {
      "epoch": 3.7312473210458634,
      "grad_norm": 0.02447609417140484,
      "learning_rate": 1.502500357193885e-05,
      "loss": 0.2481,
      "step": 17410
    },
    {
      "epoch": 3.7333904843549077,
      "grad_norm": 0.05791996419429779,
      "learning_rate": 1.5022146020860125e-05,
      "loss": 0.0012,
      "step": 17420
    },
    {
      "epoch": 3.735533647663952,
      "grad_norm": 0.041069675236940384,
      "learning_rate": 1.5019288469781399e-05,
      "loss": 0.2244,
      "step": 17430
    },
    {
      "epoch": 3.737676810972996,
      "grad_norm": 0.06271328032016754,
      "learning_rate": 1.5016430918702673e-05,
      "loss": 0.3351,
      "step": 17440
    },
    {
      "epoch": 3.73981997428204,
      "grad_norm": 0.08810104429721832,
      "learning_rate": 1.5013573367623948e-05,
      "loss": 0.0016,
      "step": 17450
    },
    {
      "epoch": 3.7419631375910845,
      "grad_norm": 0.041749630123376846,
      "learning_rate": 1.5010715816545222e-05,
      "loss": 0.6051,
      "step": 17460
    },
    {
      "epoch": 3.7441063009001287,
      "grad_norm": 0.028247475624084473,
      "learning_rate": 1.5007858265466498e-05,
      "loss": 0.5138,
      "step": 17470
    },
    {
      "epoch": 3.7462494642091726,
      "grad_norm": 17.250465393066406,
      "learning_rate": 1.5005000714387772e-05,
      "loss": 0.3984,
      "step": 17480
    },
    {
      "epoch": 3.748392627518217,
      "grad_norm": 40.69963455200195,
      "learning_rate": 1.5002143163309046e-05,
      "loss": 0.3721,
      "step": 17490
    },
    {
      "epoch": 3.750535790827261,
      "grad_norm": 0.05271760746836662,
      "learning_rate": 1.4999285612230318e-05,
      "loss": 0.1662,
      "step": 17500
    },
    {
      "epoch": 3.752678954136305,
      "grad_norm": 0.04189300909638405,
      "learning_rate": 1.4996428061151594e-05,
      "loss": 0.1316,
      "step": 17510
    },
    {
      "epoch": 3.7548221174453493,
      "grad_norm": 1.108919382095337,
      "learning_rate": 1.4993570510072868e-05,
      "loss": 0.158,
      "step": 17520
    },
    {
      "epoch": 3.7569652807543936,
      "grad_norm": 0.026895714923739433,
      "learning_rate": 1.4990712958994143e-05,
      "loss": 0.2962,
      "step": 17530
    },
    {
      "epoch": 3.7591084440634375,
      "grad_norm": 0.0073114982806146145,
      "learning_rate": 1.4987855407915417e-05,
      "loss": 0.0218,
      "step": 17540
    },
    {
      "epoch": 3.7612516073724818,
      "grad_norm": 0.04800759255886078,
      "learning_rate": 1.4984997856836691e-05,
      "loss": 0.4058,
      "step": 17550
    },
    {
      "epoch": 3.763394770681526,
      "grad_norm": 0.02610655687749386,
      "learning_rate": 1.4982140305757967e-05,
      "loss": 0.0045,
      "step": 17560
    },
    {
      "epoch": 3.7655379339905704,
      "grad_norm": 0.019655412063002586,
      "learning_rate": 1.497928275467924e-05,
      "loss": 0.0541,
      "step": 17570
    },
    {
      "epoch": 3.767681097299614,
      "grad_norm": 0.011312107555568218,
      "learning_rate": 1.4976425203600515e-05,
      "loss": 0.0272,
      "step": 17580
    },
    {
      "epoch": 3.7698242606086585,
      "grad_norm": 0.007020062301307917,
      "learning_rate": 1.497356765252179e-05,
      "loss": 0.0004,
      "step": 17590
    },
    {
      "epoch": 3.771967423917703,
      "grad_norm": 0.02597484178841114,
      "learning_rate": 1.4970710101443064e-05,
      "loss": 0.4938,
      "step": 17600
    },
    {
      "epoch": 3.7741105872267466,
      "grad_norm": 0.022904179990291595,
      "learning_rate": 1.496785255036434e-05,
      "loss": 0.4022,
      "step": 17610
    },
    {
      "epoch": 3.776253750535791,
      "grad_norm": 0.01835828274488449,
      "learning_rate": 1.4964994999285614e-05,
      "loss": 0.2066,
      "step": 17620
    },
    {
      "epoch": 3.7783969138448352,
      "grad_norm": 0.44985270500183105,
      "learning_rate": 1.4962137448206888e-05,
      "loss": 0.3705,
      "step": 17630
    },
    {
      "epoch": 3.780540077153879,
      "grad_norm": 0.029700513929128647,
      "learning_rate": 1.4959279897128163e-05,
      "loss": 0.0012,
      "step": 17640
    },
    {
      "epoch": 3.7826832404629234,
      "grad_norm": 0.036126554012298584,
      "learning_rate": 1.4956422346049437e-05,
      "loss": 0.2383,
      "step": 17650
    },
    {
      "epoch": 3.7848264037719677,
      "grad_norm": 0.09234564751386642,
      "learning_rate": 1.4953564794970713e-05,
      "loss": 0.3761,
      "step": 17660
    },
    {
      "epoch": 3.7869695670810115,
      "grad_norm": 0.06250880658626556,
      "learning_rate": 1.4950707243891987e-05,
      "loss": 0.1552,
      "step": 17670
    },
    {
      "epoch": 3.789112730390056,
      "grad_norm": 0.07913719117641449,
      "learning_rate": 1.494784969281326e-05,
      "loss": 0.2874,
      "step": 17680
    },
    {
      "epoch": 3.7912558936991,
      "grad_norm": 0.08215248584747314,
      "learning_rate": 1.4944992141734536e-05,
      "loss": 0.0009,
      "step": 17690
    },
    {
      "epoch": 3.793399057008144,
      "grad_norm": 27.225666046142578,
      "learning_rate": 1.494213459065581e-05,
      "loss": 0.4138,
      "step": 17700
    },
    {
      "epoch": 3.7955422203171882,
      "grad_norm": 25.244630813598633,
      "learning_rate": 1.4939277039577084e-05,
      "loss": 0.7093,
      "step": 17710
    },
    {
      "epoch": 3.7976853836262325,
      "grad_norm": 0.01235528290271759,
      "learning_rate": 1.4936419488498356e-05,
      "loss": 0.0012,
      "step": 17720
    },
    {
      "epoch": 3.7998285469352764,
      "grad_norm": 19.426490783691406,
      "learning_rate": 1.4933561937419632e-05,
      "loss": 0.5181,
      "step": 17730
    },
    {
      "epoch": 3.8019717102443207,
      "grad_norm": 0.04124126955866814,
      "learning_rate": 1.4930704386340906e-05,
      "loss": 0.0016,
      "step": 17740
    },
    {
      "epoch": 3.804114873553365,
      "grad_norm": 0.06731028109788895,
      "learning_rate": 1.4927846835262181e-05,
      "loss": 0.0505,
      "step": 17750
    },
    {
      "epoch": 3.806258036862409,
      "grad_norm": 0.02603355050086975,
      "learning_rate": 1.4924989284183455e-05,
      "loss": 0.0933,
      "step": 17760
    },
    {
      "epoch": 3.808401200171453,
      "grad_norm": 0.025457289069890976,
      "learning_rate": 1.492213173310473e-05,
      "loss": 0.3884,
      "step": 17770
    },
    {
      "epoch": 3.8105443634804974,
      "grad_norm": 0.2060776948928833,
      "learning_rate": 1.4919274182026005e-05,
      "loss": 0.0826,
      "step": 17780
    },
    {
      "epoch": 3.8126875267895413,
      "grad_norm": 0.020792845636606216,
      "learning_rate": 1.4916416630947279e-05,
      "loss": 0.1941,
      "step": 17790
    },
    {
      "epoch": 3.8148306900985856,
      "grad_norm": 26.75535774230957,
      "learning_rate": 1.4913559079868554e-05,
      "loss": 0.819,
      "step": 17800
    },
    {
      "epoch": 3.81697385340763,
      "grad_norm": 0.05822116509079933,
      "learning_rate": 1.4910701528789828e-05,
      "loss": 0.0036,
      "step": 17810
    },
    {
      "epoch": 3.8191170167166737,
      "grad_norm": 0.0496310256421566,
      "learning_rate": 1.4907843977711102e-05,
      "loss": 0.6236,
      "step": 17820
    },
    {
      "epoch": 3.821260180025718,
      "grad_norm": 0.07328730076551437,
      "learning_rate": 1.4904986426632378e-05,
      "loss": 0.003,
      "step": 17830
    },
    {
      "epoch": 3.8234033433347623,
      "grad_norm": 0.05258612334728241,
      "learning_rate": 1.4902128875553652e-05,
      "loss": 0.4261,
      "step": 17840
    },
    {
      "epoch": 3.825546506643806,
      "grad_norm": 0.021192025393247604,
      "learning_rate": 1.4899271324474926e-05,
      "loss": 0.0009,
      "step": 17850
    },
    {
      "epoch": 3.8276896699528504,
      "grad_norm": 0.015299931168556213,
      "learning_rate": 1.4896413773396201e-05,
      "loss": 0.1833,
      "step": 17860
    },
    {
      "epoch": 3.8298328332618947,
      "grad_norm": 0.014443592168390751,
      "learning_rate": 1.4893556222317475e-05,
      "loss": 0.2155,
      "step": 17870
    },
    {
      "epoch": 3.8319759965709386,
      "grad_norm": 0.04693393036723137,
      "learning_rate": 1.4890698671238751e-05,
      "loss": 0.0016,
      "step": 17880
    },
    {
      "epoch": 3.834119159879983,
      "grad_norm": 0.09796732664108276,
      "learning_rate": 1.4887841120160025e-05,
      "loss": 0.0021,
      "step": 17890
    },
    {
      "epoch": 3.836262323189027,
      "grad_norm": 0.03916211426258087,
      "learning_rate": 1.4884983569081299e-05,
      "loss": 0.2544,
      "step": 17900
    },
    {
      "epoch": 3.838405486498071,
      "grad_norm": 0.042984649538993835,
      "learning_rate": 1.4882126018002574e-05,
      "loss": 0.0007,
      "step": 17910
    },
    {
      "epoch": 3.8405486498071153,
      "grad_norm": 0.043163567781448364,
      "learning_rate": 1.4879268466923848e-05,
      "loss": 0.1877,
      "step": 17920
    },
    {
      "epoch": 3.8426918131161596,
      "grad_norm": 0.09029877185821533,
      "learning_rate": 1.487641091584512e-05,
      "loss": 0.0309,
      "step": 17930
    },
    {
      "epoch": 3.8448349764252034,
      "grad_norm": 0.03042561560869217,
      "learning_rate": 1.4873553364766396e-05,
      "loss": 0.1596,
      "step": 17940
    },
    {
      "epoch": 3.8469781397342477,
      "grad_norm": 0.019657956436276436,
      "learning_rate": 1.487069581368767e-05,
      "loss": 0.08,
      "step": 17950
    },
    {
      "epoch": 3.849121303043292,
      "grad_norm": 0.016698738560080528,
      "learning_rate": 1.4867838262608944e-05,
      "loss": 0.376,
      "step": 17960
    },
    {
      "epoch": 3.851264466352336,
      "grad_norm": 0.009714565239846706,
      "learning_rate": 1.486498071153022e-05,
      "loss": 0.2559,
      "step": 17970
    },
    {
      "epoch": 3.85340762966138,
      "grad_norm": 0.011087348684668541,
      "learning_rate": 1.4862123160451494e-05,
      "loss": 0.2373,
      "step": 17980
    },
    {
      "epoch": 3.8555507929704245,
      "grad_norm": 27.820329666137695,
      "learning_rate": 1.4859265609372768e-05,
      "loss": 0.0873,
      "step": 17990
    },
    {
      "epoch": 3.8576939562794683,
      "grad_norm": 0.02415122091770172,
      "learning_rate": 1.4856408058294043e-05,
      "loss": 0.0015,
      "step": 18000
    },
    {
      "epoch": 3.8598371195885126,
      "grad_norm": 0.00551599869504571,
      "learning_rate": 1.4853550507215317e-05,
      "loss": 0.0008,
      "step": 18010
    },
    {
      "epoch": 3.861980282897557,
      "grad_norm": 0.02505977265536785,
      "learning_rate": 1.4850692956136593e-05,
      "loss": 0.1806,
      "step": 18020
    },
    {
      "epoch": 3.8641234462066008,
      "grad_norm": 19.29808807373047,
      "learning_rate": 1.4847835405057867e-05,
      "loss": 0.2324,
      "step": 18030
    },
    {
      "epoch": 3.866266609515645,
      "grad_norm": 0.14106908440589905,
      "learning_rate": 1.484497785397914e-05,
      "loss": 0.1862,
      "step": 18040
    },
    {
      "epoch": 3.8684097728246893,
      "grad_norm": 0.05232185497879982,
      "learning_rate": 1.4842120302900416e-05,
      "loss": 0.0006,
      "step": 18050
    },
    {
      "epoch": 3.870552936133733,
      "grad_norm": 403.2710266113281,
      "learning_rate": 1.483926275182169e-05,
      "loss": 0.1174,
      "step": 18060
    },
    {
      "epoch": 3.8726960994427775,
      "grad_norm": 0.35905611515045166,
      "learning_rate": 1.4836405200742964e-05,
      "loss": 0.1892,
      "step": 18070
    },
    {
      "epoch": 3.8748392627518218,
      "grad_norm": 0.09685391932725906,
      "learning_rate": 1.483354764966424e-05,
      "loss": 0.4057,
      "step": 18080
    },
    {
      "epoch": 3.8769824260608656,
      "grad_norm": 0.03705540671944618,
      "learning_rate": 1.4830690098585514e-05,
      "loss": 0.6073,
      "step": 18090
    },
    {
      "epoch": 3.87912558936991,
      "grad_norm": 38.807472229003906,
      "learning_rate": 1.482783254750679e-05,
      "loss": 0.0418,
      "step": 18100
    },
    {
      "epoch": 3.881268752678954,
      "grad_norm": 0.039315804839134216,
      "learning_rate": 1.4824974996428063e-05,
      "loss": 0.0568,
      "step": 18110
    },
    {
      "epoch": 3.883411915987998,
      "grad_norm": 0.061042167246341705,
      "learning_rate": 1.4822117445349337e-05,
      "loss": 0.1852,
      "step": 18120
    },
    {
      "epoch": 3.8855550792970424,
      "grad_norm": 0.010626586154103279,
      "learning_rate": 1.4819259894270613e-05,
      "loss": 0.1792,
      "step": 18130
    },
    {
      "epoch": 3.8876982426060867,
      "grad_norm": 0.06363942474126816,
      "learning_rate": 1.4816402343191887e-05,
      "loss": 0.2632,
      "step": 18140
    },
    {
      "epoch": 3.8898414059151305,
      "grad_norm": 0.6710067391395569,
      "learning_rate": 1.4813544792113159e-05,
      "loss": 0.2046,
      "step": 18150
    },
    {
      "epoch": 3.891984569224175,
      "grad_norm": 0.18114173412322998,
      "learning_rate": 1.4810687241034435e-05,
      "loss": 0.0009,
      "step": 18160
    },
    {
      "epoch": 3.894127732533219,
      "grad_norm": 0.5206170082092285,
      "learning_rate": 1.4807829689955708e-05,
      "loss": 0.2837,
      "step": 18170
    },
    {
      "epoch": 3.896270895842263,
      "grad_norm": 20.064428329467773,
      "learning_rate": 1.4804972138876982e-05,
      "loss": 0.1635,
      "step": 18180
    },
    {
      "epoch": 3.8984140591513072,
      "grad_norm": 0.02551873028278351,
      "learning_rate": 1.4802114587798258e-05,
      "loss": 0.1517,
      "step": 18190
    },
    {
      "epoch": 3.9005572224603515,
      "grad_norm": 0.011571449227631092,
      "learning_rate": 1.4799257036719532e-05,
      "loss": 0.1185,
      "step": 18200
    },
    {
      "epoch": 3.9027003857693954,
      "grad_norm": 0.09897119551897049,
      "learning_rate": 1.4796399485640806e-05,
      "loss": 0.3131,
      "step": 18210
    },
    {
      "epoch": 3.9048435490784397,
      "grad_norm": 0.04572656750679016,
      "learning_rate": 1.4793541934562082e-05,
      "loss": 0.0015,
      "step": 18220
    },
    {
      "epoch": 3.906986712387484,
      "grad_norm": 54.6573371887207,
      "learning_rate": 1.4790684383483355e-05,
      "loss": 0.2831,
      "step": 18230
    },
    {
      "epoch": 3.909129875696528,
      "grad_norm": 0.015421195887029171,
      "learning_rate": 1.4787826832404631e-05,
      "loss": 0.0003,
      "step": 18240
    },
    {
      "epoch": 3.911273039005572,
      "grad_norm": 0.022810420021414757,
      "learning_rate": 1.4784969281325905e-05,
      "loss": 0.2717,
      "step": 18250
    },
    {
      "epoch": 3.9134162023146164,
      "grad_norm": 0.00580318970605731,
      "learning_rate": 1.4782111730247179e-05,
      "loss": 0.0996,
      "step": 18260
    },
    {
      "epoch": 3.9155593656236602,
      "grad_norm": 0.010746888816356659,
      "learning_rate": 1.4779254179168455e-05,
      "loss": 0.245,
      "step": 18270
    },
    {
      "epoch": 3.9177025289327045,
      "grad_norm": 0.012248626910150051,
      "learning_rate": 1.4776396628089728e-05,
      "loss": 0.3942,
      "step": 18280
    },
    {
      "epoch": 3.919845692241749,
      "grad_norm": 22.11210060119629,
      "learning_rate": 1.4773539077011002e-05,
      "loss": 0.2201,
      "step": 18290
    },
    {
      "epoch": 3.921988855550793,
      "grad_norm": 0.0707370936870575,
      "learning_rate": 1.4770681525932278e-05,
      "loss": 0.2161,
      "step": 18300
    },
    {
      "epoch": 3.924132018859837,
      "grad_norm": 0.05315636098384857,
      "learning_rate": 1.4767823974853552e-05,
      "loss": 0.0036,
      "step": 18310
    },
    {
      "epoch": 3.9262751821688813,
      "grad_norm": 0.07930240035057068,
      "learning_rate": 1.4764966423774828e-05,
      "loss": 0.0025,
      "step": 18320
    },
    {
      "epoch": 3.9284183454779256,
      "grad_norm": 176.643310546875,
      "learning_rate": 1.4762108872696101e-05,
      "loss": 0.2093,
      "step": 18330
    },
    {
      "epoch": 3.9305615087869694,
      "grad_norm": 0.004998704884201288,
      "learning_rate": 1.4759251321617375e-05,
      "loss": 0.0072,
      "step": 18340
    },
    {
      "epoch": 3.9327046720960137,
      "grad_norm": 0.01386247854679823,
      "learning_rate": 1.4756393770538651e-05,
      "loss": 0.4157,
      "step": 18350
    },
    {
      "epoch": 3.934847835405058,
      "grad_norm": 0.13234016299247742,
      "learning_rate": 1.4753536219459923e-05,
      "loss": 0.233,
      "step": 18360
    },
    {
      "epoch": 3.936990998714102,
      "grad_norm": 0.05482221022248268,
      "learning_rate": 1.4750678668381197e-05,
      "loss": 0.2144,
      "step": 18370
    },
    {
      "epoch": 3.939134162023146,
      "grad_norm": 0.017635241150856018,
      "learning_rate": 1.4747821117302473e-05,
      "loss": 0.1217,
      "step": 18380
    },
    {
      "epoch": 3.9412773253321904,
      "grad_norm": 0.05256745219230652,
      "learning_rate": 1.4744963566223747e-05,
      "loss": 0.0076,
      "step": 18390
    },
    {
      "epoch": 3.9434204886412347,
      "grad_norm": 0.029905593022704124,
      "learning_rate": 1.474210601514502e-05,
      "loss": 0.0557,
      "step": 18400
    },
    {
      "epoch": 3.9455636519502786,
      "grad_norm": 0.021637797355651855,
      "learning_rate": 1.4739248464066296e-05,
      "loss": 0.0011,
      "step": 18410
    },
    {
      "epoch": 3.947706815259323,
      "grad_norm": 27.91819190979004,
      "learning_rate": 1.473639091298757e-05,
      "loss": 0.2232,
      "step": 18420
    },
    {
      "epoch": 3.949849978568367,
      "grad_norm": 0.004343862179666758,
      "learning_rate": 1.4733533361908844e-05,
      "loss": 0.0004,
      "step": 18430
    },
    {
      "epoch": 3.951993141877411,
      "grad_norm": 0.012870311737060547,
      "learning_rate": 1.473067581083012e-05,
      "loss": 0.0039,
      "step": 18440
    },
    {
      "epoch": 3.9541363051864553,
      "grad_norm": 0.028568528592586517,
      "learning_rate": 1.4727818259751394e-05,
      "loss": 0.0036,
      "step": 18450
    },
    {
      "epoch": 3.9562794684954996,
      "grad_norm": 0.012804575264453888,
      "learning_rate": 1.472496070867267e-05,
      "loss": 0.1417,
      "step": 18460
    },
    {
      "epoch": 3.9584226318045435,
      "grad_norm": 29.991418838500977,
      "learning_rate": 1.4722103157593943e-05,
      "loss": 0.3597,
      "step": 18470
    },
    {
      "epoch": 3.9605657951135878,
      "grad_norm": 21.77703285217285,
      "learning_rate": 1.4719245606515217e-05,
      "loss": 0.2622,
      "step": 18480
    },
    {
      "epoch": 3.962708958422632,
      "grad_norm": 0.051136743277311325,
      "learning_rate": 1.4716388055436493e-05,
      "loss": 0.0005,
      "step": 18490
    },
    {
      "epoch": 3.964852121731676,
      "grad_norm": 0.022553248330950737,
      "learning_rate": 1.4713530504357767e-05,
      "loss": 0.3579,
      "step": 18500
    },
    {
      "epoch": 3.96699528504072,
      "grad_norm": 32.3161506652832,
      "learning_rate": 1.4710672953279042e-05,
      "loss": 0.7316,
      "step": 18510
    },
    {
      "epoch": 3.9691384483497645,
      "grad_norm": 0.06234278157353401,
      "learning_rate": 1.4707815402200316e-05,
      "loss": 0.4761,
      "step": 18520
    },
    {
      "epoch": 3.9712816116588083,
      "grad_norm": 0.25482505559921265,
      "learning_rate": 1.470495785112159e-05,
      "loss": 0.001,
      "step": 18530
    },
    {
      "epoch": 3.9734247749678526,
      "grad_norm": 174.56190490722656,
      "learning_rate": 1.4702100300042866e-05,
      "loss": 0.1087,
      "step": 18540
    },
    {
      "epoch": 3.975567938276897,
      "grad_norm": 0.05244076997041702,
      "learning_rate": 1.469924274896414e-05,
      "loss": 0.0041,
      "step": 18550
    },
    {
      "epoch": 3.9777111015859408,
      "grad_norm": 202.18650817871094,
      "learning_rate": 1.4696385197885414e-05,
      "loss": 0.2117,
      "step": 18560
    },
    {
      "epoch": 3.979854264894985,
      "grad_norm": 0.004997536074370146,
      "learning_rate": 1.469352764680669e-05,
      "loss": 0.006,
      "step": 18570
    },
    {
      "epoch": 3.9819974282040294,
      "grad_norm": 0.22298367321491241,
      "learning_rate": 1.4690670095727962e-05,
      "loss": 0.2012,
      "step": 18580
    },
    {
      "epoch": 3.984140591513073,
      "grad_norm": 0.009750545024871826,
      "learning_rate": 1.4687812544649235e-05,
      "loss": 0.6777,
      "step": 18590
    },
    {
      "epoch": 3.9862837548221175,
      "grad_norm": 0.030048349872231483,
      "learning_rate": 1.4684954993570511e-05,
      "loss": 0.2361,
      "step": 18600
    },
    {
      "epoch": 3.988426918131162,
      "grad_norm": 22.828033447265625,
      "learning_rate": 1.4682097442491785e-05,
      "loss": 0.1836,
      "step": 18610
    },
    {
      "epoch": 3.9905700814402056,
      "grad_norm": 0.004101353697478771,
      "learning_rate": 1.4679239891413059e-05,
      "loss": 0.5696,
      "step": 18620
    },
    {
      "epoch": 3.99271324474925,
      "grad_norm": 0.045050207525491714,
      "learning_rate": 1.4676382340334335e-05,
      "loss": 0.2352,
      "step": 18630
    },
    {
      "epoch": 3.9948564080582942,
      "grad_norm": 0.06194803863763809,
      "learning_rate": 1.4673524789255609e-05,
      "loss": 0.1814,
      "step": 18640
    },
    {
      "epoch": 3.996999571367338,
      "grad_norm": 0.023616675287485123,
      "learning_rate": 1.4670667238176884e-05,
      "loss": 0.0012,
      "step": 18650
    },
    {
      "epoch": 3.9991427346763824,
      "grad_norm": 0.00566928181797266,
      "learning_rate": 1.4667809687098158e-05,
      "loss": 0.1751,
      "step": 18660
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9203333333333333,
      "eval_f1": 0.7695274831243972,
      "eval_loss": 0.458161324262619,
      "eval_precision": 0.8788546255506607,
      "eval_recall": 0.6843910806174958,
      "eval_runtime": 108.1333,
      "eval_samples_per_second": 27.744,
      "eval_steps_per_second": 1.156,
      "step": 18664
    },
    {
      "epoch": 4.001285897985427,
      "grad_norm": 0.008492359891533852,
      "learning_rate": 1.4664952136019432e-05,
      "loss": 0.0015,
      "step": 18670
    },
    {
      "epoch": 4.0034290612944705,
      "grad_norm": 0.06434610486030579,
      "learning_rate": 1.4662094584940708e-05,
      "loss": 0.2718,
      "step": 18680
    },
    {
      "epoch": 4.005572224603514,
      "grad_norm": 3.0649147033691406,
      "learning_rate": 1.4659237033861982e-05,
      "loss": 0.2046,
      "step": 18690
    },
    {
      "epoch": 4.007715387912559,
      "grad_norm": 0.06400682032108307,
      "learning_rate": 1.4656379482783255e-05,
      "loss": 0.1169,
      "step": 18700
    },
    {
      "epoch": 4.009858551221603,
      "grad_norm": 0.07302901893854141,
      "learning_rate": 1.4653521931704531e-05,
      "loss": 0.4441,
      "step": 18710
    },
    {
      "epoch": 4.012001714530647,
      "grad_norm": 0.028284527361392975,
      "learning_rate": 1.4650664380625805e-05,
      "loss": 0.0012,
      "step": 18720
    },
    {
      "epoch": 4.0141448778396915,
      "grad_norm": 0.04459552839398384,
      "learning_rate": 1.464780682954708e-05,
      "loss": 0.0046,
      "step": 18730
    },
    {
      "epoch": 4.016288041148735,
      "grad_norm": 0.012157426215708256,
      "learning_rate": 1.4644949278468355e-05,
      "loss": 0.1508,
      "step": 18740
    },
    {
      "epoch": 4.01843120445778,
      "grad_norm": 0.05056358501315117,
      "learning_rate": 1.4642091727389629e-05,
      "loss": 0.1291,
      "step": 18750
    },
    {
      "epoch": 4.020574367766824,
      "grad_norm": 0.17948564887046814,
      "learning_rate": 1.4639234176310904e-05,
      "loss": 0.1068,
      "step": 18760
    },
    {
      "epoch": 4.022717531075868,
      "grad_norm": 0.00818707887083292,
      "learning_rate": 1.4636376625232178e-05,
      "loss": 0.0004,
      "step": 18770
    },
    {
      "epoch": 4.024860694384913,
      "grad_norm": 0.07776521146297455,
      "learning_rate": 1.4633519074153452e-05,
      "loss": 0.0163,
      "step": 18780
    },
    {
      "epoch": 4.027003857693956,
      "grad_norm": 0.07729403674602509,
      "learning_rate": 1.4630661523074726e-05,
      "loss": 0.0005,
      "step": 18790
    },
    {
      "epoch": 4.029147021003,
      "grad_norm": 0.005971183069050312,
      "learning_rate": 1.4627803971996e-05,
      "loss": 0.0003,
      "step": 18800
    },
    {
      "epoch": 4.031290184312045,
      "grad_norm": 0.010207915678620338,
      "learning_rate": 1.4624946420917274e-05,
      "loss": 0.3081,
      "step": 18810
    },
    {
      "epoch": 4.033433347621089,
      "grad_norm": 130.8386993408203,
      "learning_rate": 1.462208886983855e-05,
      "loss": 0.2086,
      "step": 18820
    },
    {
      "epoch": 4.035576510930133,
      "grad_norm": 0.023007946088910103,
      "learning_rate": 1.4619231318759823e-05,
      "loss": 0.0011,
      "step": 18830
    },
    {
      "epoch": 4.037719674239177,
      "grad_norm": 0.013502086512744427,
      "learning_rate": 1.4616373767681097e-05,
      "loss": 0.1059,
      "step": 18840
    },
    {
      "epoch": 4.039862837548221,
      "grad_norm": 0.03279082849621773,
      "learning_rate": 1.4613516216602373e-05,
      "loss": 0.0005,
      "step": 18850
    },
    {
      "epoch": 4.042006000857265,
      "grad_norm": 0.020295167341828346,
      "learning_rate": 1.4610658665523647e-05,
      "loss": 0.0004,
      "step": 18860
    },
    {
      "epoch": 4.04414916416631,
      "grad_norm": 42.001182556152344,
      "learning_rate": 1.4607801114444922e-05,
      "loss": 0.6883,
      "step": 18870
    },
    {
      "epoch": 4.046292327475354,
      "grad_norm": 0.18035820126533508,
      "learning_rate": 1.4604943563366196e-05,
      "loss": 0.2777,
      "step": 18880
    },
    {
      "epoch": 4.048435490784398,
      "grad_norm": 0.3152739405632019,
      "learning_rate": 1.460208601228747e-05,
      "loss": 0.1609,
      "step": 18890
    },
    {
      "epoch": 4.050578654093442,
      "grad_norm": 78.03850555419922,
      "learning_rate": 1.4599228461208746e-05,
      "loss": 0.0529,
      "step": 18900
    },
    {
      "epoch": 4.052721817402486,
      "grad_norm": 0.012740250676870346,
      "learning_rate": 1.459637091013002e-05,
      "loss": 0.0008,
      "step": 18910
    },
    {
      "epoch": 4.05486498071153,
      "grad_norm": 0.0060323080979287624,
      "learning_rate": 1.4593513359051294e-05,
      "loss": 0.1472,
      "step": 18920
    },
    {
      "epoch": 4.057008144020575,
      "grad_norm": 0.004922897554934025,
      "learning_rate": 1.459065580797257e-05,
      "loss": 0.0015,
      "step": 18930
    },
    {
      "epoch": 4.059151307329619,
      "grad_norm": 0.011140881106257439,
      "learning_rate": 1.4587798256893843e-05,
      "loss": 0.0003,
      "step": 18940
    },
    {
      "epoch": 4.0612944706386624,
      "grad_norm": 0.008850011974573135,
      "learning_rate": 1.4584940705815119e-05,
      "loss": 0.0317,
      "step": 18950
    },
    {
      "epoch": 4.063437633947707,
      "grad_norm": 0.025157349184155464,
      "learning_rate": 1.4582083154736393e-05,
      "loss": 0.0002,
      "step": 18960
    },
    {
      "epoch": 4.065580797256751,
      "grad_norm": 0.010335797443985939,
      "learning_rate": 1.4579225603657667e-05,
      "loss": 0.1103,
      "step": 18970
    },
    {
      "epoch": 4.067723960565795,
      "grad_norm": 0.011126943863928318,
      "learning_rate": 1.4576368052578942e-05,
      "loss": 0.0002,
      "step": 18980
    },
    {
      "epoch": 4.06986712387484,
      "grad_norm": 0.008282010443508625,
      "learning_rate": 1.4573510501500216e-05,
      "loss": 0.0171,
      "step": 18990
    },
    {
      "epoch": 4.0720102871838835,
      "grad_norm": 0.012446437031030655,
      "learning_rate": 1.457065295042149e-05,
      "loss": 0.0006,
      "step": 19000
    },
    {
      "epoch": 4.074153450492927,
      "grad_norm": 0.005379476584494114,
      "learning_rate": 1.4567795399342764e-05,
      "loss": 0.3798,
      "step": 19010
    },
    {
      "epoch": 4.076296613801972,
      "grad_norm": 29.136587142944336,
      "learning_rate": 1.4564937848264038e-05,
      "loss": 0.1699,
      "step": 19020
    },
    {
      "epoch": 4.078439777111016,
      "grad_norm": 0.05510462075471878,
      "learning_rate": 1.4562080297185312e-05,
      "loss": 0.2412,
      "step": 19030
    },
    {
      "epoch": 4.08058294042006,
      "grad_norm": 0.004658158868551254,
      "learning_rate": 1.4559222746106588e-05,
      "loss": 0.0008,
      "step": 19040
    },
    {
      "epoch": 4.0827261037291045,
      "grad_norm": 0.006727499887347221,
      "learning_rate": 1.4556365195027862e-05,
      "loss": 0.2348,
      "step": 19050
    },
    {
      "epoch": 4.084869267038148,
      "grad_norm": 0.005235744174569845,
      "learning_rate": 1.4553507643949136e-05,
      "loss": 0.0002,
      "step": 19060
    },
    {
      "epoch": 4.087012430347192,
      "grad_norm": 0.012336969375610352,
      "learning_rate": 1.4550650092870411e-05,
      "loss": 0.0005,
      "step": 19070
    },
    {
      "epoch": 4.089155593656237,
      "grad_norm": 0.05713297054171562,
      "learning_rate": 1.4547792541791685e-05,
      "loss": 0.1955,
      "step": 19080
    },
    {
      "epoch": 4.091298756965281,
      "grad_norm": 0.16483382880687714,
      "learning_rate": 1.454493499071296e-05,
      "loss": 0.0002,
      "step": 19090
    },
    {
      "epoch": 4.093441920274325,
      "grad_norm": 0.0019412297988310456,
      "learning_rate": 1.4542077439634235e-05,
      "loss": 0.0004,
      "step": 19100
    },
    {
      "epoch": 4.095585083583369,
      "grad_norm": 0.06500530242919922,
      "learning_rate": 1.4539219888555509e-05,
      "loss": 0.0447,
      "step": 19110
    },
    {
      "epoch": 4.097728246892413,
      "grad_norm": 0.0024847383610904217,
      "learning_rate": 1.4536362337476784e-05,
      "loss": 0.0005,
      "step": 19120
    },
    {
      "epoch": 4.099871410201457,
      "grad_norm": 0.002014660742133856,
      "learning_rate": 1.4533504786398058e-05,
      "loss": 0.0001,
      "step": 19130
    },
    {
      "epoch": 4.102014573510502,
      "grad_norm": 241.27914428710938,
      "learning_rate": 1.4530647235319332e-05,
      "loss": 0.7808,
      "step": 19140
    },
    {
      "epoch": 4.104157736819546,
      "grad_norm": 0.009303759783506393,
      "learning_rate": 1.4527789684240608e-05,
      "loss": 0.2866,
      "step": 19150
    },
    {
      "epoch": 4.1063009001285895,
      "grad_norm": 0.03685956820845604,
      "learning_rate": 1.4524932133161882e-05,
      "loss": 0.1092,
      "step": 19160
    },
    {
      "epoch": 4.108444063437634,
      "grad_norm": 0.026203244924545288,
      "learning_rate": 1.4522074582083157e-05,
      "loss": 0.1786,
      "step": 19170
    },
    {
      "epoch": 4.110587226746678,
      "grad_norm": 0.024750931188464165,
      "learning_rate": 1.4519217031004431e-05,
      "loss": 0.1635,
      "step": 19180
    },
    {
      "epoch": 4.112730390055722,
      "grad_norm": 0.013806172646582127,
      "learning_rate": 1.4516359479925705e-05,
      "loss": 0.3267,
      "step": 19190
    },
    {
      "epoch": 4.114873553364767,
      "grad_norm": 0.027718523517251015,
      "learning_rate": 1.451350192884698e-05,
      "loss": 0.3387,
      "step": 19200
    },
    {
      "epoch": 4.1170167166738105,
      "grad_norm": 6.214656829833984,
      "learning_rate": 1.4510644377768255e-05,
      "loss": 0.0028,
      "step": 19210
    },
    {
      "epoch": 4.119159879982854,
      "grad_norm": 0.007138335146009922,
      "learning_rate": 1.4507786826689527e-05,
      "loss": 0.0006,
      "step": 19220
    },
    {
      "epoch": 4.121303043291899,
      "grad_norm": 0.006057242397218943,
      "learning_rate": 1.4504929275610802e-05,
      "loss": 0.2411,
      "step": 19230
    },
    {
      "epoch": 4.123446206600943,
      "grad_norm": 0.01726992055773735,
      "learning_rate": 1.4502071724532076e-05,
      "loss": 0.1545,
      "step": 19240
    },
    {
      "epoch": 4.125589369909987,
      "grad_norm": 0.10882474482059479,
      "learning_rate": 1.449921417345335e-05,
      "loss": 0.0024,
      "step": 19250
    },
    {
      "epoch": 4.1277325332190316,
      "grad_norm": 0.007631661370396614,
      "learning_rate": 1.4496356622374626e-05,
      "loss": 0.122,
      "step": 19260
    },
    {
      "epoch": 4.129875696528075,
      "grad_norm": 0.05514584481716156,
      "learning_rate": 1.44934990712959e-05,
      "loss": 0.0007,
      "step": 19270
    },
    {
      "epoch": 4.132018859837119,
      "grad_norm": 0.28410589694976807,
      "learning_rate": 1.4490641520217174e-05,
      "loss": 0.2524,
      "step": 19280
    },
    {
      "epoch": 4.134162023146164,
      "grad_norm": 0.02371952496469021,
      "learning_rate": 1.448778396913845e-05,
      "loss": 0.0006,
      "step": 19290
    },
    {
      "epoch": 4.136305186455208,
      "grad_norm": 0.039757419377565384,
      "learning_rate": 1.4484926418059723e-05,
      "loss": 0.2426,
      "step": 19300
    },
    {
      "epoch": 4.138448349764252,
      "grad_norm": 0.007491990923881531,
      "learning_rate": 1.4482068866980999e-05,
      "loss": 0.0054,
      "step": 19310
    },
    {
      "epoch": 4.140591513073296,
      "grad_norm": 0.004916987847536802,
      "learning_rate": 1.4479211315902273e-05,
      "loss": 0.0371,
      "step": 19320
    },
    {
      "epoch": 4.14273467638234,
      "grad_norm": 0.004980091471225023,
      "learning_rate": 1.4476353764823547e-05,
      "loss": 0.2006,
      "step": 19330
    },
    {
      "epoch": 4.144877839691384,
      "grad_norm": 0.9002359509468079,
      "learning_rate": 1.4473496213744822e-05,
      "loss": 0.3392,
      "step": 19340
    },
    {
      "epoch": 4.147021003000429,
      "grad_norm": 0.005744982045143843,
      "learning_rate": 1.4470638662666096e-05,
      "loss": 0.0474,
      "step": 19350
    },
    {
      "epoch": 4.149164166309473,
      "grad_norm": 0.08114419132471085,
      "learning_rate": 1.4467781111587372e-05,
      "loss": 0.2658,
      "step": 19360
    },
    {
      "epoch": 4.151307329618517,
      "grad_norm": 0.007588285021483898,
      "learning_rate": 1.4464923560508646e-05,
      "loss": 0.0939,
      "step": 19370
    },
    {
      "epoch": 4.153450492927561,
      "grad_norm": 0.07690411806106567,
      "learning_rate": 1.446206600942992e-05,
      "loss": 0.0343,
      "step": 19380
    },
    {
      "epoch": 4.155593656236605,
      "grad_norm": 0.05823885276913643,
      "learning_rate": 1.4459208458351195e-05,
      "loss": 0.4086,
      "step": 19390
    },
    {
      "epoch": 4.157736819545649,
      "grad_norm": 0.009457865729928017,
      "learning_rate": 1.445635090727247e-05,
      "loss": 0.0597,
      "step": 19400
    },
    {
      "epoch": 4.159879982854694,
      "grad_norm": 0.005761940497905016,
      "learning_rate": 1.4453493356193743e-05,
      "loss": 0.2067,
      "step": 19410
    },
    {
      "epoch": 4.162023146163738,
      "grad_norm": 0.045591846108436584,
      "learning_rate": 1.4450635805115019e-05,
      "loss": 0.0003,
      "step": 19420
    },
    {
      "epoch": 4.164166309472781,
      "grad_norm": 0.05599309876561165,
      "learning_rate": 1.4447778254036291e-05,
      "loss": 0.0004,
      "step": 19430
    },
    {
      "epoch": 4.166309472781826,
      "grad_norm": 0.001140271546319127,
      "learning_rate": 1.4444920702957565e-05,
      "loss": 0.3522,
      "step": 19440
    },
    {
      "epoch": 4.16845263609087,
      "grad_norm": 0.011691845022141933,
      "learning_rate": 1.444206315187884e-05,
      "loss": 0.1577,
      "step": 19450
    },
    {
      "epoch": 4.170595799399914,
      "grad_norm": 0.254672646522522,
      "learning_rate": 1.4439205600800115e-05,
      "loss": 0.0018,
      "step": 19460
    },
    {
      "epoch": 4.172738962708959,
      "grad_norm": 0.034640464931726456,
      "learning_rate": 1.4436348049721389e-05,
      "loss": 0.0007,
      "step": 19470
    },
    {
      "epoch": 4.1748821260180025,
      "grad_norm": 0.00525164557620883,
      "learning_rate": 1.4433490498642664e-05,
      "loss": 0.0516,
      "step": 19480
    },
    {
      "epoch": 4.177025289327046,
      "grad_norm": 0.0003757891245186329,
      "learning_rate": 1.4430632947563938e-05,
      "loss": 0.0003,
      "step": 19490
    },
    {
      "epoch": 4.179168452636091,
      "grad_norm": 0.021882351487874985,
      "learning_rate": 1.4427775396485214e-05,
      "loss": 0.0002,
      "step": 19500
    },
    {
      "epoch": 4.181311615945135,
      "grad_norm": 0.001242549275048077,
      "learning_rate": 1.4424917845406488e-05,
      "loss": 0.478,
      "step": 19510
    },
    {
      "epoch": 4.183454779254179,
      "grad_norm": 0.2850358486175537,
      "learning_rate": 1.4422060294327762e-05,
      "loss": 0.0003,
      "step": 19520
    },
    {
      "epoch": 4.1855979425632235,
      "grad_norm": 0.000544360198546201,
      "learning_rate": 1.4419202743249037e-05,
      "loss": 0.0002,
      "step": 19530
    },
    {
      "epoch": 4.187741105872267,
      "grad_norm": 0.02315794862806797,
      "learning_rate": 1.4416345192170311e-05,
      "loss": 0.0016,
      "step": 19540
    },
    {
      "epoch": 4.189884269181311,
      "grad_norm": 0.010012933053076267,
      "learning_rate": 1.4413487641091585e-05,
      "loss": 0.001,
      "step": 19550
    },
    {
      "epoch": 4.192027432490356,
      "grad_norm": 0.01725955866277218,
      "learning_rate": 1.441063009001286e-05,
      "loss": 0.0001,
      "step": 19560
    },
    {
      "epoch": 4.1941705957994,
      "grad_norm": 0.0002873517223633826,
      "learning_rate": 1.4407772538934135e-05,
      "loss": 0.0375,
      "step": 19570
    },
    {
      "epoch": 4.196313759108444,
      "grad_norm": 0.0028691363986581564,
      "learning_rate": 1.440491498785541e-05,
      "loss": 0.2641,
      "step": 19580
    },
    {
      "epoch": 4.198456922417488,
      "grad_norm": 3.097238063812256,
      "learning_rate": 1.4402057436776684e-05,
      "loss": 0.1632,
      "step": 19590
    },
    {
      "epoch": 4.200600085726532,
      "grad_norm": 0.0017103692516684532,
      "learning_rate": 1.4399199885697958e-05,
      "loss": 0.0097,
      "step": 19600
    },
    {
      "epoch": 4.202743249035576,
      "grad_norm": 0.03859981894493103,
      "learning_rate": 1.4396342334619234e-05,
      "loss": 0.0002,
      "step": 19610
    },
    {
      "epoch": 4.204886412344621,
      "grad_norm": 0.01964503712952137,
      "learning_rate": 1.4393484783540508e-05,
      "loss": 0.7605,
      "step": 19620
    },
    {
      "epoch": 4.207029575653665,
      "grad_norm": 0.043332237750291824,
      "learning_rate": 1.4390627232461782e-05,
      "loss": 0.0002,
      "step": 19630
    },
    {
      "epoch": 4.209172738962709,
      "grad_norm": 0.004786305129528046,
      "learning_rate": 1.4387769681383057e-05,
      "loss": 0.1374,
      "step": 19640
    },
    {
      "epoch": 4.211315902271753,
      "grad_norm": 0.06437669694423676,
      "learning_rate": 1.438491213030433e-05,
      "loss": 0.0005,
      "step": 19650
    },
    {
      "epoch": 4.213459065580797,
      "grad_norm": 0.009192265570163727,
      "learning_rate": 1.4382054579225603e-05,
      "loss": 0.0018,
      "step": 19660
    },
    {
      "epoch": 4.215602228889842,
      "grad_norm": 0.010142394341528416,
      "learning_rate": 1.4379197028146879e-05,
      "loss": 0.0624,
      "step": 19670
    },
    {
      "epoch": 4.217745392198886,
      "grad_norm": 0.0283511932939291,
      "learning_rate": 1.4376339477068153e-05,
      "loss": 0.2417,
      "step": 19680
    },
    {
      "epoch": 4.2198885555079295,
      "grad_norm": 0.012475958094000816,
      "learning_rate": 1.4373481925989427e-05,
      "loss": 0.1845,
      "step": 19690
    },
    {
      "epoch": 4.222031718816974,
      "grad_norm": 0.005033038090914488,
      "learning_rate": 1.4370624374910703e-05,
      "loss": 0.0002,
      "step": 19700
    },
    {
      "epoch": 4.224174882126018,
      "grad_norm": 0.00773463724181056,
      "learning_rate": 1.4367766823831976e-05,
      "loss": 0.143,
      "step": 19710
    },
    {
      "epoch": 4.226318045435062,
      "grad_norm": 0.012687316164374352,
      "learning_rate": 1.4364909272753252e-05,
      "loss": 0.0006,
      "step": 19720
    },
    {
      "epoch": 4.228461208744107,
      "grad_norm": 0.3264135420322418,
      "learning_rate": 1.4362051721674526e-05,
      "loss": 0.0011,
      "step": 19730
    },
    {
      "epoch": 4.2306043720531505,
      "grad_norm": 0.014396028593182564,
      "learning_rate": 1.43591941705958e-05,
      "loss": 0.2545,
      "step": 19740
    },
    {
      "epoch": 4.232747535362194,
      "grad_norm": 0.002280472544953227,
      "learning_rate": 1.4356336619517076e-05,
      "loss": 0.2269,
      "step": 19750
    },
    {
      "epoch": 4.234890698671239,
      "grad_norm": 0.08136074990034103,
      "learning_rate": 1.435347906843835e-05,
      "loss": 0.1606,
      "step": 19760
    },
    {
      "epoch": 4.237033861980283,
      "grad_norm": 0.07784614711999893,
      "learning_rate": 1.4350621517359623e-05,
      "loss": 0.1989,
      "step": 19770
    },
    {
      "epoch": 4.239177025289327,
      "grad_norm": 0.04994822293519974,
      "learning_rate": 1.4347763966280899e-05,
      "loss": 0.1905,
      "step": 19780
    },
    {
      "epoch": 4.241320188598372,
      "grad_norm": 0.09325356781482697,
      "learning_rate": 1.4344906415202173e-05,
      "loss": 0.3857,
      "step": 19790
    },
    {
      "epoch": 4.243463351907415,
      "grad_norm": 0.021607812494039536,
      "learning_rate": 1.4342048864123449e-05,
      "loss": 0.1005,
      "step": 19800
    },
    {
      "epoch": 4.245606515216459,
      "grad_norm": 0.043134838342666626,
      "learning_rate": 1.4339191313044723e-05,
      "loss": 0.2351,
      "step": 19810
    },
    {
      "epoch": 4.247749678525504,
      "grad_norm": 0.017254343256354332,
      "learning_rate": 1.4336333761965996e-05,
      "loss": 0.1474,
      "step": 19820
    },
    {
      "epoch": 4.249892841834548,
      "grad_norm": 0.006682063918560743,
      "learning_rate": 1.4333476210887272e-05,
      "loss": 0.0014,
      "step": 19830
    },
    {
      "epoch": 4.252036005143592,
      "grad_norm": 0.014264535158872604,
      "learning_rate": 1.4330618659808546e-05,
      "loss": 0.0004,
      "step": 19840
    },
    {
      "epoch": 4.254179168452636,
      "grad_norm": 0.11344467103481293,
      "learning_rate": 1.432776110872982e-05,
      "loss": 0.149,
      "step": 19850
    },
    {
      "epoch": 4.25632233176168,
      "grad_norm": 0.0066347564570605755,
      "learning_rate": 1.4324903557651094e-05,
      "loss": 0.0456,
      "step": 19860
    },
    {
      "epoch": 4.258465495070724,
      "grad_norm": 0.026357799768447876,
      "learning_rate": 1.4322046006572368e-05,
      "loss": 0.0001,
      "step": 19870
    },
    {
      "epoch": 4.260608658379769,
      "grad_norm": 0.0020707163494080305,
      "learning_rate": 1.4319188455493642e-05,
      "loss": 0.0499,
      "step": 19880
    },
    {
      "epoch": 4.262751821688813,
      "grad_norm": 0.0012693859171122313,
      "learning_rate": 1.4316330904414917e-05,
      "loss": 0.0011,
      "step": 19890
    },
    {
      "epoch": 4.264894984997857,
      "grad_norm": 31.776338577270508,
      "learning_rate": 1.4313473353336191e-05,
      "loss": 0.182,
      "step": 19900
    },
    {
      "epoch": 4.267038148306901,
      "grad_norm": 0.008909827098250389,
      "learning_rate": 1.4310615802257465e-05,
      "loss": 0.2784,
      "step": 19910
    },
    {
      "epoch": 4.269181311615945,
      "grad_norm": 0.6293180584907532,
      "learning_rate": 1.430775825117874e-05,
      "loss": 0.1944,
      "step": 19920
    },
    {
      "epoch": 4.271324474924989,
      "grad_norm": 0.11714344471693039,
      "learning_rate": 1.4304900700100015e-05,
      "loss": 0.0002,
      "step": 19930
    },
    {
      "epoch": 4.273467638234034,
      "grad_norm": 46.943992614746094,
      "learning_rate": 1.430204314902129e-05,
      "loss": 0.3466,
      "step": 19940
    },
    {
      "epoch": 4.275610801543078,
      "grad_norm": 0.0547269806265831,
      "learning_rate": 1.4299185597942564e-05,
      "loss": 0.003,
      "step": 19950
    },
    {
      "epoch": 4.2777539648521214,
      "grad_norm": 0.017208876088261604,
      "learning_rate": 1.4296328046863838e-05,
      "loss": 0.1484,
      "step": 19960
    },
    {
      "epoch": 4.279897128161166,
      "grad_norm": 0.025599302724003792,
      "learning_rate": 1.4293470495785114e-05,
      "loss": 0.3549,
      "step": 19970
    },
    {
      "epoch": 4.28204029147021,
      "grad_norm": 0.0061566876247525215,
      "learning_rate": 1.4290612944706388e-05,
      "loss": 0.0003,
      "step": 19980
    },
    {
      "epoch": 4.284183454779254,
      "grad_norm": 0.02082165703177452,
      "learning_rate": 1.4287755393627662e-05,
      "loss": 0.0003,
      "step": 19990
    },
    {
      "epoch": 4.286326618088299,
      "grad_norm": 40.01511001586914,
      "learning_rate": 1.4284897842548937e-05,
      "loss": 0.1348,
      "step": 20000
    },
    {
      "epoch": 4.2884697813973425,
      "grad_norm": 0.05925402790307999,
      "learning_rate": 1.4282040291470211e-05,
      "loss": 0.0712,
      "step": 20010
    },
    {
      "epoch": 4.290612944706386,
      "grad_norm": 0.0011600804282352328,
      "learning_rate": 1.4279182740391487e-05,
      "loss": 0.0573,
      "step": 20020
    },
    {
      "epoch": 4.292756108015431,
      "grad_norm": 0.008854500949382782,
      "learning_rate": 1.427632518931276e-05,
      "loss": 0.0001,
      "step": 20030
    },
    {
      "epoch": 4.294899271324475,
      "grad_norm": 0.08237659931182861,
      "learning_rate": 1.4273467638234035e-05,
      "loss": 0.0002,
      "step": 20040
    },
    {
      "epoch": 4.297042434633519,
      "grad_norm": 0.0006466734339483082,
      "learning_rate": 1.427061008715531e-05,
      "loss": 0.0519,
      "step": 20050
    },
    {
      "epoch": 4.2991855979425635,
      "grad_norm": 0.0006021848530508578,
      "learning_rate": 1.4267752536076584e-05,
      "loss": 0.0027,
      "step": 20060
    },
    {
      "epoch": 4.301328761251607,
      "grad_norm": 29.449039459228516,
      "learning_rate": 1.426489498499786e-05,
      "loss": 0.1736,
      "step": 20070
    },
    {
      "epoch": 4.303471924560651,
      "grad_norm": 0.0005699486937373877,
      "learning_rate": 1.4262037433919132e-05,
      "loss": 0.0004,
      "step": 20080
    },
    {
      "epoch": 4.305615087869696,
      "grad_norm": 0.0005194194382056594,
      "learning_rate": 1.4259179882840406e-05,
      "loss": 0.0001,
      "step": 20090
    },
    {
      "epoch": 4.30775825117874,
      "grad_norm": 0.015912538394331932,
      "learning_rate": 1.425632233176168e-05,
      "loss": 0.0001,
      "step": 20100
    },
    {
      "epoch": 4.309901414487784,
      "grad_norm": 0.017108552157878876,
      "learning_rate": 1.4253464780682956e-05,
      "loss": 0.0175,
      "step": 20110
    },
    {
      "epoch": 4.312044577796828,
      "grad_norm": 0.0004138186923228204,
      "learning_rate": 1.425060722960423e-05,
      "loss": 0.0013,
      "step": 20120
    },
    {
      "epoch": 4.314187741105872,
      "grad_norm": 0.030568644404411316,
      "learning_rate": 1.4247749678525503e-05,
      "loss": 0.435,
      "step": 20130
    },
    {
      "epoch": 4.316330904414916,
      "grad_norm": 0.08152211457490921,
      "learning_rate": 1.4244892127446779e-05,
      "loss": 0.0003,
      "step": 20140
    },
    {
      "epoch": 4.318474067723961,
      "grad_norm": 354.00396728515625,
      "learning_rate": 1.4242034576368053e-05,
      "loss": 0.7747,
      "step": 20150
    },
    {
      "epoch": 4.320617231033005,
      "grad_norm": 0.009335845708847046,
      "learning_rate": 1.4239177025289329e-05,
      "loss": 0.1723,
      "step": 20160
    },
    {
      "epoch": 4.3227603943420485,
      "grad_norm": 40.512657165527344,
      "learning_rate": 1.4236319474210603e-05,
      "loss": 0.6372,
      "step": 20170
    },
    {
      "epoch": 4.324903557651093,
      "grad_norm": 0.06539665162563324,
      "learning_rate": 1.4233461923131876e-05,
      "loss": 0.257,
      "step": 20180
    },
    {
      "epoch": 4.327046720960137,
      "grad_norm": 0.01939340867102146,
      "learning_rate": 1.4230604372053152e-05,
      "loss": 0.0954,
      "step": 20190
    },
    {
      "epoch": 4.329189884269181,
      "grad_norm": 0.036881450563669205,
      "learning_rate": 1.4227746820974426e-05,
      "loss": 0.0062,
      "step": 20200
    },
    {
      "epoch": 4.331333047578226,
      "grad_norm": 0.14993822574615479,
      "learning_rate": 1.4224889269895702e-05,
      "loss": 0.0133,
      "step": 20210
    },
    {
      "epoch": 4.3334762108872695,
      "grad_norm": 0.023459823802113533,
      "learning_rate": 1.4222031718816976e-05,
      "loss": 0.1495,
      "step": 20220
    },
    {
      "epoch": 4.335619374196313,
      "grad_norm": 0.03713483735918999,
      "learning_rate": 1.421917416773825e-05,
      "loss": 0.2642,
      "step": 20230
    },
    {
      "epoch": 4.337762537505358,
      "grad_norm": 0.013005836866796017,
      "learning_rate": 1.4216316616659525e-05,
      "loss": 0.0002,
      "step": 20240
    },
    {
      "epoch": 4.339905700814402,
      "grad_norm": 0.01479637436568737,
      "learning_rate": 1.4213459065580799e-05,
      "loss": 0.2631,
      "step": 20250
    },
    {
      "epoch": 4.342048864123446,
      "grad_norm": 0.013244886882603168,
      "learning_rate": 1.4210601514502073e-05,
      "loss": 0.0002,
      "step": 20260
    },
    {
      "epoch": 4.3441920274324906,
      "grad_norm": 0.02316834032535553,
      "learning_rate": 1.4207743963423349e-05,
      "loss": 0.0514,
      "step": 20270
    },
    {
      "epoch": 4.346335190741534,
      "grad_norm": 78.2486801147461,
      "learning_rate": 1.4204886412344623e-05,
      "loss": 0.2525,
      "step": 20280
    },
    {
      "epoch": 4.348478354050578,
      "grad_norm": 0.0020700604654848576,
      "learning_rate": 1.4202028861265895e-05,
      "loss": 0.0002,
      "step": 20290
    },
    {
      "epoch": 4.350621517359623,
      "grad_norm": 34.55514907836914,
      "learning_rate": 1.419917131018717e-05,
      "loss": 0.2242,
      "step": 20300
    },
    {
      "epoch": 4.352764680668667,
      "grad_norm": 0.0025635145138949156,
      "learning_rate": 1.4196313759108444e-05,
      "loss": 0.0002,
      "step": 20310
    },
    {
      "epoch": 4.354907843977711,
      "grad_norm": 37.950645446777344,
      "learning_rate": 1.4193456208029718e-05,
      "loss": 0.2294,
      "step": 20320
    },
    {
      "epoch": 4.357051007286755,
      "grad_norm": 0.006384206470102072,
      "learning_rate": 1.4190598656950994e-05,
      "loss": 0.2645,
      "step": 20330
    },
    {
      "epoch": 4.359194170595799,
      "grad_norm": 0.06447313725948334,
      "learning_rate": 1.4187741105872268e-05,
      "loss": 0.3938,
      "step": 20340
    },
    {
      "epoch": 4.361337333904844,
      "grad_norm": 31.107797622680664,
      "learning_rate": 1.4184883554793543e-05,
      "loss": 0.3071,
      "step": 20350
    },
    {
      "epoch": 4.363480497213888,
      "grad_norm": 0.228423610329628,
      "learning_rate": 1.4182026003714817e-05,
      "loss": 0.2343,
      "step": 20360
    },
    {
      "epoch": 4.365623660522932,
      "grad_norm": 119.72127532958984,
      "learning_rate": 1.4179168452636091e-05,
      "loss": 0.1225,
      "step": 20370
    },
    {
      "epoch": 4.3677668238319765,
      "grad_norm": 5.948450565338135,
      "learning_rate": 1.4176310901557367e-05,
      "loss": 0.3013,
      "step": 20380
    },
    {
      "epoch": 4.36990998714102,
      "grad_norm": 0.011827596463263035,
      "learning_rate": 1.417345335047864e-05,
      "loss": 0.0015,
      "step": 20390
    },
    {
      "epoch": 4.372053150450064,
      "grad_norm": 0.006302001886069775,
      "learning_rate": 1.4170595799399915e-05,
      "loss": 0.003,
      "step": 20400
    },
    {
      "epoch": 4.374196313759109,
      "grad_norm": 0.011002510786056519,
      "learning_rate": 1.416773824832119e-05,
      "loss": 0.0036,
      "step": 20410
    },
    {
      "epoch": 4.376339477068153,
      "grad_norm": 0.025497393682599068,
      "learning_rate": 1.4164880697242464e-05,
      "loss": 0.2132,
      "step": 20420
    },
    {
      "epoch": 4.378482640377197,
      "grad_norm": 0.06858950108289719,
      "learning_rate": 1.416202314616374e-05,
      "loss": 0.0005,
      "step": 20430
    },
    {
      "epoch": 4.380625803686241,
      "grad_norm": 0.008822638541460037,
      "learning_rate": 1.4159165595085014e-05,
      "loss": 0.0061,
      "step": 20440
    },
    {
      "epoch": 4.382768966995285,
      "grad_norm": 1.186291217803955,
      "learning_rate": 1.4156308044006288e-05,
      "loss": 0.2565,
      "step": 20450
    },
    {
      "epoch": 4.384912130304329,
      "grad_norm": 0.2010166049003601,
      "learning_rate": 1.4153450492927563e-05,
      "loss": 0.4891,
      "step": 20460
    },
    {
      "epoch": 4.387055293613374,
      "grad_norm": 0.0029331836849451065,
      "learning_rate": 1.4150592941848837e-05,
      "loss": 0.3954,
      "step": 20470
    },
    {
      "epoch": 4.389198456922418,
      "grad_norm": 0.05853905528783798,
      "learning_rate": 1.4147735390770111e-05,
      "loss": 0.0007,
      "step": 20480
    },
    {
      "epoch": 4.3913416202314615,
      "grad_norm": 0.0022315196692943573,
      "learning_rate": 1.4144877839691387e-05,
      "loss": 0.0731,
      "step": 20490
    },
    {
      "epoch": 4.393484783540506,
      "grad_norm": 0.9428224563598633,
      "learning_rate": 1.414202028861266e-05,
      "loss": 0.0042,
      "step": 20500
    },
    {
      "epoch": 4.39562794684955,
      "grad_norm": 0.03817438334226608,
      "learning_rate": 1.4139162737533933e-05,
      "loss": 0.0043,
      "step": 20510
    },
    {
      "epoch": 4.397771110158594,
      "grad_norm": 0.04670818895101547,
      "learning_rate": 1.4136305186455209e-05,
      "loss": 0.0006,
      "step": 20520
    },
    {
      "epoch": 4.399914273467639,
      "grad_norm": 0.0017869367729872465,
      "learning_rate": 1.4133447635376483e-05,
      "loss": 0.2967,
      "step": 20530
    },
    {
      "epoch": 4.4020574367766825,
      "grad_norm": 0.18128640949726105,
      "learning_rate": 1.4130590084297757e-05,
      "loss": 0.2812,
      "step": 20540
    },
    {
      "epoch": 4.404200600085726,
      "grad_norm": 0.0193728506565094,
      "learning_rate": 1.4127732533219032e-05,
      "loss": 0.0007,
      "step": 20550
    },
    {
      "epoch": 4.406343763394771,
      "grad_norm": 0.004450561944395304,
      "learning_rate": 1.4124874982140306e-05,
      "loss": 0.2377,
      "step": 20560
    },
    {
      "epoch": 4.408486926703815,
      "grad_norm": 0.029582450166344643,
      "learning_rate": 1.4122017431061582e-05,
      "loss": 0.001,
      "step": 20570
    },
    {
      "epoch": 4.410630090012859,
      "grad_norm": 0.007391638122498989,
      "learning_rate": 1.4119159879982856e-05,
      "loss": 0.2462,
      "step": 20580
    },
    {
      "epoch": 4.4127732533219035,
      "grad_norm": 0.008626624010503292,
      "learning_rate": 1.411630232890413e-05,
      "loss": 0.0002,
      "step": 20590
    },
    {
      "epoch": 4.414916416630947,
      "grad_norm": 0.005147107411175966,
      "learning_rate": 1.4113444777825405e-05,
      "loss": 0.0002,
      "step": 20600
    },
    {
      "epoch": 4.417059579939991,
      "grad_norm": 0.007250347174704075,
      "learning_rate": 1.4110587226746679e-05,
      "loss": 0.2445,
      "step": 20610
    },
    {
      "epoch": 4.419202743249036,
      "grad_norm": 22.117467880249023,
      "learning_rate": 1.4107729675667953e-05,
      "loss": 0.9106,
      "step": 20620
    },
    {
      "epoch": 4.42134590655808,
      "grad_norm": 0.28791555762290955,
      "learning_rate": 1.4104872124589229e-05,
      "loss": 0.0366,
      "step": 20630
    },
    {
      "epoch": 4.423489069867124,
      "grad_norm": 0.3867863416671753,
      "learning_rate": 1.4102014573510503e-05,
      "loss": 0.0051,
      "step": 20640
    },
    {
      "epoch": 4.425632233176168,
      "grad_norm": 0.0314967967569828,
      "learning_rate": 1.4099157022431778e-05,
      "loss": 0.3271,
      "step": 20650
    },
    {
      "epoch": 4.427775396485212,
      "grad_norm": 0.06755837798118591,
      "learning_rate": 1.4096299471353052e-05,
      "loss": 0.0011,
      "step": 20660
    },
    {
      "epoch": 4.429918559794256,
      "grad_norm": 0.013480828143656254,
      "learning_rate": 1.4093441920274326e-05,
      "loss": 0.0167,
      "step": 20670
    },
    {
      "epoch": 4.432061723103301,
      "grad_norm": 20.967390060424805,
      "learning_rate": 1.4090584369195602e-05,
      "loss": 0.4075,
      "step": 20680
    },
    {
      "epoch": 4.434204886412345,
      "grad_norm": 0.009921104647219181,
      "learning_rate": 1.4087726818116876e-05,
      "loss": 0.0134,
      "step": 20690
    },
    {
      "epoch": 4.4363480497213885,
      "grad_norm": 0.0035616515669971704,
      "learning_rate": 1.408486926703815e-05,
      "loss": 0.2671,
      "step": 20700
    },
    {
      "epoch": 4.438491213030433,
      "grad_norm": 0.004227159079164267,
      "learning_rate": 1.4082011715959425e-05,
      "loss": 0.0016,
      "step": 20710
    },
    {
      "epoch": 4.440634376339477,
      "grad_norm": 0.0055895233526825905,
      "learning_rate": 1.4079154164880697e-05,
      "loss": 0.0825,
      "step": 20720
    },
    {
      "epoch": 4.442777539648521,
      "grad_norm": 0.45719993114471436,
      "learning_rate": 1.4076296613801971e-05,
      "loss": 0.0008,
      "step": 20730
    },
    {
      "epoch": 4.444920702957566,
      "grad_norm": 27.085378646850586,
      "learning_rate": 1.4073439062723247e-05,
      "loss": 0.4265,
      "step": 20740
    },
    {
      "epoch": 4.4470638662666095,
      "grad_norm": 0.004438362549990416,
      "learning_rate": 1.4070581511644521e-05,
      "loss": 0.0004,
      "step": 20750
    },
    {
      "epoch": 4.449207029575653,
      "grad_norm": 0.00789742823690176,
      "learning_rate": 1.4067723960565795e-05,
      "loss": 0.0017,
      "step": 20760
    },
    {
      "epoch": 4.451350192884698,
      "grad_norm": 0.002586479764431715,
      "learning_rate": 1.406486640948707e-05,
      "loss": 0.0011,
      "step": 20770
    },
    {
      "epoch": 4.453493356193742,
      "grad_norm": 0.0029236695263534784,
      "learning_rate": 1.4062008858408344e-05,
      "loss": 0.2001,
      "step": 20780
    },
    {
      "epoch": 4.455636519502786,
      "grad_norm": 0.027038341388106346,
      "learning_rate": 1.405915130732962e-05,
      "loss": 0.0012,
      "step": 20790
    },
    {
      "epoch": 4.457779682811831,
      "grad_norm": 0.013708559796214104,
      "learning_rate": 1.4056293756250894e-05,
      "loss": 0.3379,
      "step": 20800
    },
    {
      "epoch": 4.459922846120874,
      "grad_norm": 0.01488230936229229,
      "learning_rate": 1.4053436205172168e-05,
      "loss": 0.6677,
      "step": 20810
    },
    {
      "epoch": 4.462066009429918,
      "grad_norm": 0.017180131748318672,
      "learning_rate": 1.4050578654093443e-05,
      "loss": 0.0156,
      "step": 20820
    },
    {
      "epoch": 4.464209172738963,
      "grad_norm": 0.02440003864467144,
      "learning_rate": 1.4047721103014717e-05,
      "loss": 0.1326,
      "step": 20830
    },
    {
      "epoch": 4.466352336048007,
      "grad_norm": 0.026853153482079506,
      "learning_rate": 1.4044863551935991e-05,
      "loss": 0.001,
      "step": 20840
    },
    {
      "epoch": 4.468495499357051,
      "grad_norm": 0.015107044018805027,
      "learning_rate": 1.4042006000857267e-05,
      "loss": 0.2765,
      "step": 20850
    },
    {
      "epoch": 4.470638662666095,
      "grad_norm": 0.028840359300374985,
      "learning_rate": 1.4039148449778541e-05,
      "loss": 0.1909,
      "step": 20860
    },
    {
      "epoch": 4.472781825975139,
      "grad_norm": 0.005710125435143709,
      "learning_rate": 1.4036290898699816e-05,
      "loss": 0.0004,
      "step": 20870
    },
    {
      "epoch": 4.474924989284183,
      "grad_norm": 0.008789332583546638,
      "learning_rate": 1.403343334762109e-05,
      "loss": 0.2643,
      "step": 20880
    },
    {
      "epoch": 4.477068152593228,
      "grad_norm": 0.008296966552734375,
      "learning_rate": 1.4030575796542364e-05,
      "loss": 0.0094,
      "step": 20890
    },
    {
      "epoch": 4.479211315902272,
      "grad_norm": 0.023811448365449905,
      "learning_rate": 1.402771824546364e-05,
      "loss": 0.346,
      "step": 20900
    },
    {
      "epoch": 4.481354479211316,
      "grad_norm": 0.017783034592866898,
      "learning_rate": 1.4024860694384914e-05,
      "loss": 0.2656,
      "step": 20910
    },
    {
      "epoch": 4.48349764252036,
      "grad_norm": 0.020891863852739334,
      "learning_rate": 1.402200314330619e-05,
      "loss": 0.1941,
      "step": 20920
    },
    {
      "epoch": 4.485640805829404,
      "grad_norm": 0.5042696595191956,
      "learning_rate": 1.4019145592227463e-05,
      "loss": 0.0013,
      "step": 20930
    },
    {
      "epoch": 4.487783969138448,
      "grad_norm": 2.867114543914795,
      "learning_rate": 1.4016288041148736e-05,
      "loss": 0.0012,
      "step": 20940
    },
    {
      "epoch": 4.489927132447493,
      "grad_norm": 0.033246781677007675,
      "learning_rate": 1.401343049007001e-05,
      "loss": 0.249,
      "step": 20950
    },
    {
      "epoch": 4.492070295756537,
      "grad_norm": 1.6494739055633545,
      "learning_rate": 1.4010572938991285e-05,
      "loss": 0.0022,
      "step": 20960
    },
    {
      "epoch": 4.4942134590655805,
      "grad_norm": 84.74633026123047,
      "learning_rate": 1.400771538791256e-05,
      "loss": 0.1307,
      "step": 20970
    },
    {
      "epoch": 4.496356622374625,
      "grad_norm": 0.006115253083407879,
      "learning_rate": 1.4004857836833833e-05,
      "loss": 0.1305,
      "step": 20980
    },
    {
      "epoch": 4.498499785683669,
      "grad_norm": 0.006171364802867174,
      "learning_rate": 1.4002000285755109e-05,
      "loss": 0.0005,
      "step": 20990
    },
    {
      "epoch": 4.500642948992713,
      "grad_norm": 0.016152875497937202,
      "learning_rate": 1.3999142734676383e-05,
      "loss": 0.0003,
      "step": 21000
    },
    {
      "epoch": 4.502786112301758,
      "grad_norm": 0.016058338806033134,
      "learning_rate": 1.3996285183597658e-05,
      "loss": 0.0012,
      "step": 21010
    },
    {
      "epoch": 4.5049292756108015,
      "grad_norm": 0.003521488280966878,
      "learning_rate": 1.3993427632518932e-05,
      "loss": 0.0002,
      "step": 21020
    },
    {
      "epoch": 4.507072438919845,
      "grad_norm": 0.008114554919302464,
      "learning_rate": 1.3990570081440206e-05,
      "loss": 0.1882,
      "step": 21030
    },
    {
      "epoch": 4.50921560222889,
      "grad_norm": 53.80076217651367,
      "learning_rate": 1.3987712530361482e-05,
      "loss": 0.0172,
      "step": 21040
    },
    {
      "epoch": 4.511358765537934,
      "grad_norm": 0.013971813023090363,
      "learning_rate": 1.3984854979282756e-05,
      "loss": 0.3593,
      "step": 21050
    },
    {
      "epoch": 4.513501928846978,
      "grad_norm": 0.006477334536612034,
      "learning_rate": 1.3981997428204031e-05,
      "loss": 0.1825,
      "step": 21060
    },
    {
      "epoch": 4.5156450921560225,
      "grad_norm": 0.10977280884981155,
      "learning_rate": 1.3979139877125305e-05,
      "loss": 0.1184,
      "step": 21070
    },
    {
      "epoch": 4.517788255465066,
      "grad_norm": 0.009727178141474724,
      "learning_rate": 1.397628232604658e-05,
      "loss": 0.0003,
      "step": 21080
    },
    {
      "epoch": 4.51993141877411,
      "grad_norm": 20.50482940673828,
      "learning_rate": 1.3973424774967855e-05,
      "loss": 0.2801,
      "step": 21090
    },
    {
      "epoch": 4.522074582083155,
      "grad_norm": 0.0186106376349926,
      "learning_rate": 1.3970567223889129e-05,
      "loss": 0.1753,
      "step": 21100
    },
    {
      "epoch": 4.524217745392199,
      "grad_norm": 0.019217172637581825,
      "learning_rate": 1.3967709672810403e-05,
      "loss": 0.0004,
      "step": 21110
    },
    {
      "epoch": 4.526360908701243,
      "grad_norm": 0.013849273324012756,
      "learning_rate": 1.3964852121731678e-05,
      "loss": 0.0007,
      "step": 21120
    },
    {
      "epoch": 4.528504072010287,
      "grad_norm": 0.2224792242050171,
      "learning_rate": 1.3961994570652952e-05,
      "loss": 0.0006,
      "step": 21130
    },
    {
      "epoch": 4.530647235319331,
      "grad_norm": 0.013066982850432396,
      "learning_rate": 1.3959137019574228e-05,
      "loss": 0.0002,
      "step": 21140
    },
    {
      "epoch": 4.532790398628375,
      "grad_norm": 0.02336888574063778,
      "learning_rate": 1.39562794684955e-05,
      "loss": 0.0014,
      "step": 21150
    },
    {
      "epoch": 4.53493356193742,
      "grad_norm": 0.006556268315762281,
      "learning_rate": 1.3953421917416774e-05,
      "loss": 0.0016,
      "step": 21160
    },
    {
      "epoch": 4.537076725246464,
      "grad_norm": 0.6549292206764221,
      "learning_rate": 1.3950564366338048e-05,
      "loss": 0.2815,
      "step": 21170
    },
    {
      "epoch": 4.5392198885555075,
      "grad_norm": 0.022141657769680023,
      "learning_rate": 1.3947706815259324e-05,
      "loss": 0.2484,
      "step": 21180
    },
    {
      "epoch": 4.541363051864552,
      "grad_norm": 0.013486926443874836,
      "learning_rate": 1.3944849264180597e-05,
      "loss": 0.0003,
      "step": 21190
    },
    {
      "epoch": 4.543506215173596,
      "grad_norm": 37.283912658691406,
      "learning_rate": 1.3941991713101873e-05,
      "loss": 0.4725,
      "step": 21200
    },
    {
      "epoch": 4.54564937848264,
      "grad_norm": 0.019348561763763428,
      "learning_rate": 1.3939134162023147e-05,
      "loss": 0.2244,
      "step": 21210
    },
    {
      "epoch": 4.547792541791685,
      "grad_norm": 0.04762785881757736,
      "learning_rate": 1.3936276610944421e-05,
      "loss": 0.0005,
      "step": 21220
    },
    {
      "epoch": 4.5499357051007285,
      "grad_norm": 0.01299115177243948,
      "learning_rate": 1.3933419059865697e-05,
      "loss": 0.0007,
      "step": 21230
    },
    {
      "epoch": 4.552078868409772,
      "grad_norm": 0.019440794363617897,
      "learning_rate": 1.393056150878697e-05,
      "loss": 0.0287,
      "step": 21240
    },
    {
      "epoch": 4.554222031718817,
      "grad_norm": 0.02234634943306446,
      "learning_rate": 1.3927703957708244e-05,
      "loss": 0.1575,
      "step": 21250
    },
    {
      "epoch": 4.556365195027861,
      "grad_norm": 0.007863752543926239,
      "learning_rate": 1.392484640662952e-05,
      "loss": 0.183,
      "step": 21260
    },
    {
      "epoch": 4.558508358336905,
      "grad_norm": 0.762710452079773,
      "learning_rate": 1.3921988855550794e-05,
      "loss": 0.2269,
      "step": 21270
    },
    {
      "epoch": 4.56065152164595,
      "grad_norm": 0.01510690338909626,
      "learning_rate": 1.391913130447207e-05,
      "loss": 0.1707,
      "step": 21280
    },
    {
      "epoch": 4.562794684954993,
      "grad_norm": 0.008304648101329803,
      "learning_rate": 1.3916273753393344e-05,
      "loss": 0.0002,
      "step": 21290
    },
    {
      "epoch": 4.564937848264037,
      "grad_norm": 0.0080900052562356,
      "learning_rate": 1.3913416202314617e-05,
      "loss": 0.4207,
      "step": 21300
    },
    {
      "epoch": 4.567081011573082,
      "grad_norm": 0.013986749574542046,
      "learning_rate": 1.3910558651235893e-05,
      "loss": 0.2205,
      "step": 21310
    },
    {
      "epoch": 4.569224174882126,
      "grad_norm": 0.016277849674224854,
      "learning_rate": 1.3907701100157167e-05,
      "loss": 0.0003,
      "step": 21320
    },
    {
      "epoch": 4.57136733819117,
      "grad_norm": 0.014173071831464767,
      "learning_rate": 1.3904843549078441e-05,
      "loss": 0.1381,
      "step": 21330
    },
    {
      "epoch": 4.573510501500214,
      "grad_norm": 0.20644813776016235,
      "learning_rate": 1.3901985997999717e-05,
      "loss": 0.2077,
      "step": 21340
    },
    {
      "epoch": 4.575653664809258,
      "grad_norm": 0.016887754201889038,
      "learning_rate": 1.389912844692099e-05,
      "loss": 0.1943,
      "step": 21350
    },
    {
      "epoch": 4.577796828118302,
      "grad_norm": 0.014802070334553719,
      "learning_rate": 1.3896270895842266e-05,
      "loss": 0.0003,
      "step": 21360
    },
    {
      "epoch": 4.579939991427347,
      "grad_norm": 0.004857540130615234,
      "learning_rate": 1.3893413344763538e-05,
      "loss": 0.0269,
      "step": 21370
    },
    {
      "epoch": 4.582083154736391,
      "grad_norm": 0.008690022863447666,
      "learning_rate": 1.3890555793684812e-05,
      "loss": 0.1798,
      "step": 21380
    },
    {
      "epoch": 4.584226318045435,
      "grad_norm": 0.020496025681495667,
      "learning_rate": 1.3887698242606086e-05,
      "loss": 0.0309,
      "step": 21390
    },
    {
      "epoch": 4.586369481354479,
      "grad_norm": 0.006939415354281664,
      "learning_rate": 1.3884840691527362e-05,
      "loss": 0.3283,
      "step": 21400
    },
    {
      "epoch": 4.588512644663523,
      "grad_norm": 33.721435546875,
      "learning_rate": 1.3881983140448636e-05,
      "loss": 0.2163,
      "step": 21410
    },
    {
      "epoch": 4.590655807972568,
      "grad_norm": 0.03237855061888695,
      "learning_rate": 1.3879125589369911e-05,
      "loss": 0.2414,
      "step": 21420
    },
    {
      "epoch": 4.592798971281612,
      "grad_norm": 0.02160649187862873,
      "learning_rate": 1.3876268038291185e-05,
      "loss": 0.0679,
      "step": 21430
    },
    {
      "epoch": 4.594942134590656,
      "grad_norm": 0.41624724864959717,
      "learning_rate": 1.387341048721246e-05,
      "loss": 0.0007,
      "step": 21440
    },
    {
      "epoch": 4.5970852978997,
      "grad_norm": 17.99600601196289,
      "learning_rate": 1.3870552936133735e-05,
      "loss": 0.0044,
      "step": 21450
    },
    {
      "epoch": 4.599228461208744,
      "grad_norm": 0.011532165110111237,
      "learning_rate": 1.3867695385055009e-05,
      "loss": 0.2199,
      "step": 21460
    },
    {
      "epoch": 4.601371624517788,
      "grad_norm": 0.004733527544885874,
      "learning_rate": 1.3864837833976283e-05,
      "loss": 0.2972,
      "step": 21470
    },
    {
      "epoch": 4.603514787826833,
      "grad_norm": 0.04593592509627342,
      "learning_rate": 1.3861980282897558e-05,
      "loss": 0.3204,
      "step": 21480
    },
    {
      "epoch": 4.605657951135877,
      "grad_norm": 0.10259431600570679,
      "learning_rate": 1.3859122731818832e-05,
      "loss": 0.1599,
      "step": 21490
    },
    {
      "epoch": 4.6078011144449205,
      "grad_norm": 51.91734313964844,
      "learning_rate": 1.3856265180740108e-05,
      "loss": 0.6224,
      "step": 21500
    },
    {
      "epoch": 4.609944277753965,
      "grad_norm": 0.01233853679150343,
      "learning_rate": 1.3853407629661382e-05,
      "loss": 0.085,
      "step": 21510
    },
    {
      "epoch": 4.612087441063009,
      "grad_norm": 0.7816318273544312,
      "learning_rate": 1.3850550078582656e-05,
      "loss": 0.406,
      "step": 21520
    },
    {
      "epoch": 4.614230604372053,
      "grad_norm": 0.02053377963602543,
      "learning_rate": 1.3847692527503931e-05,
      "loss": 0.0005,
      "step": 21530
    },
    {
      "epoch": 4.616373767681098,
      "grad_norm": 0.0072518931701779366,
      "learning_rate": 1.3844834976425205e-05,
      "loss": 0.0142,
      "step": 21540
    },
    {
      "epoch": 4.6185169309901415,
      "grad_norm": 2.5426840782165527,
      "learning_rate": 1.384197742534648e-05,
      "loss": 0.0112,
      "step": 21550
    },
    {
      "epoch": 4.620660094299185,
      "grad_norm": 51.91813278198242,
      "learning_rate": 1.3839119874267755e-05,
      "loss": 0.242,
      "step": 21560
    },
    {
      "epoch": 4.62280325760823,
      "grad_norm": 0.48584792017936707,
      "learning_rate": 1.3836262323189029e-05,
      "loss": 0.6836,
      "step": 21570
    },
    {
      "epoch": 4.624946420917274,
      "grad_norm": 0.0911463052034378,
      "learning_rate": 1.3833404772110301e-05,
      "loss": 0.3351,
      "step": 21580
    },
    {
      "epoch": 4.627089584226318,
      "grad_norm": 0.042262252420186996,
      "learning_rate": 1.3830547221031577e-05,
      "loss": 0.3875,
      "step": 21590
    },
    {
      "epoch": 4.6292327475353625,
      "grad_norm": 0.004110865294933319,
      "learning_rate": 1.382768966995285e-05,
      "loss": 0.1225,
      "step": 21600
    },
    {
      "epoch": 4.631375910844406,
      "grad_norm": 0.06818892806768417,
      "learning_rate": 1.3824832118874124e-05,
      "loss": 0.1826,
      "step": 21610
    },
    {
      "epoch": 4.63351907415345,
      "grad_norm": 0.09464284032583237,
      "learning_rate": 1.38219745677954e-05,
      "loss": 0.2597,
      "step": 21620
    },
    {
      "epoch": 4.635662237462495,
      "grad_norm": 0.005862398073077202,
      "learning_rate": 1.3819117016716674e-05,
      "loss": 0.2115,
      "step": 21630
    },
    {
      "epoch": 4.637805400771539,
      "grad_norm": 0.004526306409388781,
      "learning_rate": 1.381625946563795e-05,
      "loss": 0.1453,
      "step": 21640
    },
    {
      "epoch": 4.639948564080583,
      "grad_norm": 2.0398707389831543,
      "learning_rate": 1.3813401914559224e-05,
      "loss": 0.0967,
      "step": 21650
    },
    {
      "epoch": 4.642091727389627,
      "grad_norm": 0.0014269361272454262,
      "learning_rate": 1.3810544363480497e-05,
      "loss": 0.0577,
      "step": 21660
    },
    {
      "epoch": 4.644234890698671,
      "grad_norm": 0.0030585818458348513,
      "learning_rate": 1.3807686812401773e-05,
      "loss": 0.0012,
      "step": 21670
    },
    {
      "epoch": 4.646378054007715,
      "grad_norm": 0.0013973795576021075,
      "learning_rate": 1.3804829261323047e-05,
      "loss": 0.3575,
      "step": 21680
    },
    {
      "epoch": 4.64852121731676,
      "grad_norm": 0.005285368766635656,
      "learning_rate": 1.3801971710244321e-05,
      "loss": 0.0005,
      "step": 21690
    },
    {
      "epoch": 4.650664380625804,
      "grad_norm": 0.002701729768887162,
      "learning_rate": 1.3799114159165597e-05,
      "loss": 0.0004,
      "step": 21700
    },
    {
      "epoch": 4.6528075439348475,
      "grad_norm": 0.055083032697439194,
      "learning_rate": 1.379625660808687e-05,
      "loss": 0.3714,
      "step": 21710
    },
    {
      "epoch": 4.654950707243892,
      "grad_norm": 0.0035411755088716745,
      "learning_rate": 1.3793399057008146e-05,
      "loss": 0.012,
      "step": 21720
    },
    {
      "epoch": 4.657093870552936,
      "grad_norm": 0.0032016802579164505,
      "learning_rate": 1.379054150592942e-05,
      "loss": 0.0027,
      "step": 21730
    },
    {
      "epoch": 4.65923703386198,
      "grad_norm": 54.478694915771484,
      "learning_rate": 1.3787683954850694e-05,
      "loss": 0.3246,
      "step": 21740
    },
    {
      "epoch": 4.661380197171025,
      "grad_norm": 0.00385109381750226,
      "learning_rate": 1.378482640377197e-05,
      "loss": 0.0049,
      "step": 21750
    },
    {
      "epoch": 4.6635233604800685,
      "grad_norm": 6.097686767578125,
      "learning_rate": 1.3781968852693244e-05,
      "loss": 0.2188,
      "step": 21760
    },
    {
      "epoch": 4.665666523789112,
      "grad_norm": 0.011442048475146294,
      "learning_rate": 1.377911130161452e-05,
      "loss": 0.0002,
      "step": 21770
    },
    {
      "epoch": 4.667809687098157,
      "grad_norm": 0.004506910685449839,
      "learning_rate": 1.3776253750535793e-05,
      "loss": 0.4328,
      "step": 21780
    },
    {
      "epoch": 4.669952850407201,
      "grad_norm": 0.0030220486223697662,
      "learning_rate": 1.3773396199457067e-05,
      "loss": 0.0013,
      "step": 21790
    },
    {
      "epoch": 4.672096013716245,
      "grad_norm": 0.003105573356151581,
      "learning_rate": 1.377053864837834e-05,
      "loss": 0.0003,
      "step": 21800
    },
    {
      "epoch": 4.67423917702529,
      "grad_norm": 0.009755759499967098,
      "learning_rate": 1.3767681097299615e-05,
      "loss": 0.5846,
      "step": 21810
    },
    {
      "epoch": 4.676382340334333,
      "grad_norm": 0.016723621636629105,
      "learning_rate": 1.3764823546220889e-05,
      "loss": 0.2494,
      "step": 21820
    },
    {
      "epoch": 4.678525503643377,
      "grad_norm": 0.046932559460401535,
      "learning_rate": 1.3761965995142163e-05,
      "loss": 0.1912,
      "step": 21830
    },
    {
      "epoch": 4.680668666952422,
      "grad_norm": 0.08187064528465271,
      "learning_rate": 1.3759108444063438e-05,
      "loss": 0.0293,
      "step": 21840
    },
    {
      "epoch": 4.682811830261466,
      "grad_norm": 0.007062348071485758,
      "learning_rate": 1.3756250892984712e-05,
      "loss": 0.0007,
      "step": 21850
    },
    {
      "epoch": 4.68495499357051,
      "grad_norm": 0.026282813400030136,
      "learning_rate": 1.3753393341905988e-05,
      "loss": 0.187,
      "step": 21860
    },
    {
      "epoch": 4.6870981568795544,
      "grad_norm": 0.10276193171739578,
      "learning_rate": 1.3750535790827262e-05,
      "loss": 0.0004,
      "step": 21870
    },
    {
      "epoch": 4.689241320188598,
      "grad_norm": 0.013231993652880192,
      "learning_rate": 1.3747678239748536e-05,
      "loss": 0.3785,
      "step": 21880
    },
    {
      "epoch": 4.691384483497642,
      "grad_norm": 31.348461151123047,
      "learning_rate": 1.3744820688669811e-05,
      "loss": 0.1855,
      "step": 21890
    },
    {
      "epoch": 4.693527646806687,
      "grad_norm": 0.3698248267173767,
      "learning_rate": 1.3741963137591085e-05,
      "loss": 0.129,
      "step": 21900
    },
    {
      "epoch": 4.695670810115731,
      "grad_norm": 0.0032915333285927773,
      "learning_rate": 1.3739105586512361e-05,
      "loss": 0.0008,
      "step": 21910
    },
    {
      "epoch": 4.697813973424775,
      "grad_norm": 0.011552223935723305,
      "learning_rate": 1.3736248035433635e-05,
      "loss": 0.0543,
      "step": 21920
    },
    {
      "epoch": 4.699957136733819,
      "grad_norm": 0.33643633127212524,
      "learning_rate": 1.3733390484354909e-05,
      "loss": 0.2694,
      "step": 21930
    },
    {
      "epoch": 4.702100300042863,
      "grad_norm": 0.01564554125070572,
      "learning_rate": 1.3730532933276184e-05,
      "loss": 0.0004,
      "step": 21940
    },
    {
      "epoch": 4.704243463351908,
      "grad_norm": 0.04368351027369499,
      "learning_rate": 1.3727675382197458e-05,
      "loss": 0.2054,
      "step": 21950
    },
    {
      "epoch": 4.706386626660952,
      "grad_norm": 33.25979995727539,
      "learning_rate": 1.3724817831118732e-05,
      "loss": 0.7054,
      "step": 21960
    },
    {
      "epoch": 4.708529789969996,
      "grad_norm": 0.11916732788085938,
      "learning_rate": 1.3721960280040008e-05,
      "loss": 0.1296,
      "step": 21970
    },
    {
      "epoch": 4.71067295327904,
      "grad_norm": 0.33123716711997986,
      "learning_rate": 1.3719102728961282e-05,
      "loss": 0.002,
      "step": 21980
    },
    {
      "epoch": 4.712816116588084,
      "grad_norm": 0.03513406962156296,
      "learning_rate": 1.3716245177882557e-05,
      "loss": 0.0255,
      "step": 21990
    },
    {
      "epoch": 4.714959279897128,
      "grad_norm": 0.4069547951221466,
      "learning_rate": 1.3713387626803831e-05,
      "loss": 0.4165,
      "step": 22000
    },
    {
      "epoch": 4.717102443206173,
      "grad_norm": 21.72517967224121,
      "learning_rate": 1.3710530075725104e-05,
      "loss": 0.112,
      "step": 22010
    },
    {
      "epoch": 4.719245606515217,
      "grad_norm": 0.013246145099401474,
      "learning_rate": 1.3707672524646378e-05,
      "loss": 0.1881,
      "step": 22020
    },
    {
      "epoch": 4.7213887698242605,
      "grad_norm": 0.01921595074236393,
      "learning_rate": 1.3704814973567653e-05,
      "loss": 0.0013,
      "step": 22030
    },
    {
      "epoch": 4.723531933133305,
      "grad_norm": 0.013702168129384518,
      "learning_rate": 1.3701957422488927e-05,
      "loss": 0.1537,
      "step": 22040
    },
    {
      "epoch": 4.725675096442349,
      "grad_norm": 0.006173799280077219,
      "learning_rate": 1.3699099871410203e-05,
      "loss": 0.4067,
      "step": 22050
    },
    {
      "epoch": 4.727818259751393,
      "grad_norm": 0.009938940405845642,
      "learning_rate": 1.3696242320331477e-05,
      "loss": 0.1605,
      "step": 22060
    },
    {
      "epoch": 4.729961423060438,
      "grad_norm": 1.4809566736221313,
      "learning_rate": 1.369338476925275e-05,
      "loss": 0.3408,
      "step": 22070
    },
    {
      "epoch": 4.7321045863694815,
      "grad_norm": 0.7466285228729248,
      "learning_rate": 1.3690527218174026e-05,
      "loss": 0.0055,
      "step": 22080
    },
    {
      "epoch": 4.734247749678525,
      "grad_norm": 0.0075770178809762,
      "learning_rate": 1.36876696670953e-05,
      "loss": 0.2884,
      "step": 22090
    },
    {
      "epoch": 4.73639091298757,
      "grad_norm": 0.07186424732208252,
      "learning_rate": 1.3684812116016574e-05,
      "loss": 0.0004,
      "step": 22100
    },
    {
      "epoch": 4.738534076296614,
      "grad_norm": 0.039113808423280716,
      "learning_rate": 1.368195456493785e-05,
      "loss": 0.1952,
      "step": 22110
    },
    {
      "epoch": 4.740677239605658,
      "grad_norm": 0.02925632707774639,
      "learning_rate": 1.3679097013859124e-05,
      "loss": 0.0992,
      "step": 22120
    },
    {
      "epoch": 4.7428204029147025,
      "grad_norm": 0.005647237878292799,
      "learning_rate": 1.36762394627804e-05,
      "loss": 0.2231,
      "step": 22130
    },
    {
      "epoch": 4.744963566223746,
      "grad_norm": 0.052160684019327164,
      "learning_rate": 1.3673381911701673e-05,
      "loss": 0.0004,
      "step": 22140
    },
    {
      "epoch": 4.74710672953279,
      "grad_norm": 0.009015770629048347,
      "learning_rate": 1.3670524360622947e-05,
      "loss": 0.2568,
      "step": 22150
    },
    {
      "epoch": 4.749249892841835,
      "grad_norm": 0.035721555352211,
      "learning_rate": 1.3667666809544223e-05,
      "loss": 0.0003,
      "step": 22160
    },
    {
      "epoch": 4.751393056150879,
      "grad_norm": 0.03271602839231491,
      "learning_rate": 1.3664809258465497e-05,
      "loss": 0.2762,
      "step": 22170
    },
    {
      "epoch": 4.753536219459923,
      "grad_norm": 0.013456250540912151,
      "learning_rate": 1.366195170738677e-05,
      "loss": 0.0006,
      "step": 22180
    },
    {
      "epoch": 4.755679382768967,
      "grad_norm": 0.009016209281980991,
      "learning_rate": 1.3659094156308046e-05,
      "loss": 0.0015,
      "step": 22190
    },
    {
      "epoch": 4.757822546078011,
      "grad_norm": 0.21893101930618286,
      "learning_rate": 1.365623660522932e-05,
      "loss": 0.2846,
      "step": 22200
    },
    {
      "epoch": 4.759965709387055,
      "grad_norm": 0.06653938442468643,
      "learning_rate": 1.3653379054150596e-05,
      "loss": 0.0015,
      "step": 22210
    },
    {
      "epoch": 4.7621088726961,
      "grad_norm": 378.40155029296875,
      "learning_rate": 1.365052150307187e-05,
      "loss": 0.27,
      "step": 22220
    },
    {
      "epoch": 4.764252036005144,
      "grad_norm": 0.04221773520112038,
      "learning_rate": 1.3647663951993142e-05,
      "loss": 0.2652,
      "step": 22230
    },
    {
      "epoch": 4.7663951993141875,
      "grad_norm": 0.07125818729400635,
      "learning_rate": 1.3644806400914416e-05,
      "loss": 0.4073,
      "step": 22240
    },
    {
      "epoch": 4.768538362623232,
      "grad_norm": 0.03345669060945511,
      "learning_rate": 1.3641948849835691e-05,
      "loss": 0.0012,
      "step": 22250
    },
    {
      "epoch": 4.770681525932276,
      "grad_norm": 0.02339843101799488,
      "learning_rate": 1.3639091298756965e-05,
      "loss": 0.2703,
      "step": 22260
    },
    {
      "epoch": 4.77282468924132,
      "grad_norm": 0.014817215502262115,
      "learning_rate": 1.3636233747678241e-05,
      "loss": 0.1896,
      "step": 22270
    },
    {
      "epoch": 4.774967852550365,
      "grad_norm": 0.01096010860055685,
      "learning_rate": 1.3633376196599515e-05,
      "loss": 0.1072,
      "step": 22280
    },
    {
      "epoch": 4.777111015859409,
      "grad_norm": 27.371057510375977,
      "learning_rate": 1.3630518645520789e-05,
      "loss": 0.6532,
      "step": 22290
    },
    {
      "epoch": 4.779254179168452,
      "grad_norm": 0.011846044100821018,
      "learning_rate": 1.3627661094442064e-05,
      "loss": 0.0006,
      "step": 22300
    },
    {
      "epoch": 4.781397342477497,
      "grad_norm": 0.03553590923547745,
      "learning_rate": 1.3624803543363338e-05,
      "loss": 0.1632,
      "step": 22310
    },
    {
      "epoch": 4.783540505786541,
      "grad_norm": 0.045372188091278076,
      "learning_rate": 1.3621945992284612e-05,
      "loss": 0.2162,
      "step": 22320
    },
    {
      "epoch": 4.785683669095585,
      "grad_norm": 0.06985340267419815,
      "learning_rate": 1.3619088441205888e-05,
      "loss": 0.6436,
      "step": 22330
    },
    {
      "epoch": 4.78782683240463,
      "grad_norm": 0.053770437836647034,
      "learning_rate": 1.3616230890127162e-05,
      "loss": 0.1798,
      "step": 22340
    },
    {
      "epoch": 4.789969995713673,
      "grad_norm": 18.960674285888672,
      "learning_rate": 1.3613373339048438e-05,
      "loss": 0.1763,
      "step": 22350
    },
    {
      "epoch": 4.792113159022717,
      "grad_norm": 0.04823244735598564,
      "learning_rate": 1.3610515787969711e-05,
      "loss": 0.1203,
      "step": 22360
    },
    {
      "epoch": 4.794256322331762,
      "grad_norm": 0.08693830668926239,
      "learning_rate": 1.3607658236890985e-05,
      "loss": 0.212,
      "step": 22370
    },
    {
      "epoch": 4.796399485640806,
      "grad_norm": 0.01703125424683094,
      "learning_rate": 1.3604800685812261e-05,
      "loss": 0.001,
      "step": 22380
    },
    {
      "epoch": 4.79854264894985,
      "grad_norm": 0.002754108514636755,
      "learning_rate": 1.3601943134733535e-05,
      "loss": 0.0008,
      "step": 22390
    },
    {
      "epoch": 4.8006858122588945,
      "grad_norm": 0.5242016315460205,
      "learning_rate": 1.359908558365481e-05,
      "loss": 0.0006,
      "step": 22400
    },
    {
      "epoch": 4.802828975567938,
      "grad_norm": 0.011750927194952965,
      "learning_rate": 1.3596228032576084e-05,
      "loss": 0.28,
      "step": 22410
    },
    {
      "epoch": 4.804972138876982,
      "grad_norm": 0.024581391364336014,
      "learning_rate": 1.3593370481497358e-05,
      "loss": 0.2239,
      "step": 22420
    },
    {
      "epoch": 4.807115302186027,
      "grad_norm": 0.013332204893231392,
      "learning_rate": 1.3590512930418634e-05,
      "loss": 0.2233,
      "step": 22430
    },
    {
      "epoch": 4.809258465495071,
      "grad_norm": 0.026641104370355606,
      "learning_rate": 1.3587655379339906e-05,
      "loss": 0.0019,
      "step": 22440
    },
    {
      "epoch": 4.811401628804115,
      "grad_norm": 0.03712955862283707,
      "learning_rate": 1.358479782826118e-05,
      "loss": 0.0009,
      "step": 22450
    },
    {
      "epoch": 4.813544792113159,
      "grad_norm": 0.045139312744140625,
      "learning_rate": 1.3581940277182454e-05,
      "loss": 0.0008,
      "step": 22460
    },
    {
      "epoch": 4.815687955422203,
      "grad_norm": 0.019224774092435837,
      "learning_rate": 1.357908272610373e-05,
      "loss": 0.2117,
      "step": 22470
    },
    {
      "epoch": 4.817831118731247,
      "grad_norm": 0.08110949397087097,
      "learning_rate": 1.3576225175025004e-05,
      "loss": 0.0006,
      "step": 22480
    },
    {
      "epoch": 4.819974282040292,
      "grad_norm": 0.029775984585285187,
      "learning_rate": 1.357336762394628e-05,
      "loss": 0.0099,
      "step": 22490
    },
    {
      "epoch": 4.822117445349336,
      "grad_norm": 0.0032282869797199965,
      "learning_rate": 1.3570510072867553e-05,
      "loss": 0.0005,
      "step": 22500
    },
    {
      "epoch": 4.8242606086583795,
      "grad_norm": 0.008081831969320774,
      "learning_rate": 1.3567652521788827e-05,
      "loss": 0.1899,
      "step": 22510
    },
    {
      "epoch": 4.826403771967424,
      "grad_norm": 0.00747563224285841,
      "learning_rate": 1.3564794970710103e-05,
      "loss": 0.1193,
      "step": 22520
    },
    {
      "epoch": 4.828546935276468,
      "grad_norm": 0.02074039727449417,
      "learning_rate": 1.3561937419631377e-05,
      "loss": 0.5402,
      "step": 22530
    },
    {
      "epoch": 4.830690098585512,
      "grad_norm": 25.447311401367188,
      "learning_rate": 1.3559079868552652e-05,
      "loss": 0.6319,
      "step": 22540
    },
    {
      "epoch": 4.832833261894557,
      "grad_norm": 0.08942200988531113,
      "learning_rate": 1.3556222317473926e-05,
      "loss": 0.0011,
      "step": 22550
    },
    {
      "epoch": 4.8349764252036005,
      "grad_norm": 0.17306837439537048,
      "learning_rate": 1.35533647663952e-05,
      "loss": 0.098,
      "step": 22560
    },
    {
      "epoch": 4.837119588512644,
      "grad_norm": 0.031088586896657944,
      "learning_rate": 1.3550507215316476e-05,
      "loss": 0.0013,
      "step": 22570
    },
    {
      "epoch": 4.839262751821689,
      "grad_norm": 0.33579501509666443,
      "learning_rate": 1.354764966423775e-05,
      "loss": 0.8719,
      "step": 22580
    },
    {
      "epoch": 4.841405915130733,
      "grad_norm": 0.11327845603227615,
      "learning_rate": 1.3544792113159024e-05,
      "loss": 0.0029,
      "step": 22590
    },
    {
      "epoch": 4.843549078439777,
      "grad_norm": 0.07471603155136108,
      "learning_rate": 1.35419345620803e-05,
      "loss": 0.0006,
      "step": 22600
    },
    {
      "epoch": 4.8456922417488215,
      "grad_norm": 0.009847728535532951,
      "learning_rate": 1.3539077011001573e-05,
      "loss": 0.148,
      "step": 22610
    },
    {
      "epoch": 4.847835405057865,
      "grad_norm": 0.007702451199293137,
      "learning_rate": 1.3536219459922849e-05,
      "loss": 0.209,
      "step": 22620
    },
    {
      "epoch": 4.849978568366909,
      "grad_norm": 0.0065750922076404095,
      "learning_rate": 1.3533361908844123e-05,
      "loss": 0.4755,
      "step": 22630
    },
    {
      "epoch": 4.852121731675954,
      "grad_norm": 0.5345932245254517,
      "learning_rate": 1.3530504357765397e-05,
      "loss": 0.0275,
      "step": 22640
    },
    {
      "epoch": 4.854264894984998,
      "grad_norm": 0.014199275523424149,
      "learning_rate": 1.3527646806686672e-05,
      "loss": 0.0007,
      "step": 22650
    },
    {
      "epoch": 4.856408058294042,
      "grad_norm": 284.71063232421875,
      "learning_rate": 1.3524789255607945e-05,
      "loss": 0.612,
      "step": 22660
    },
    {
      "epoch": 4.858551221603086,
      "grad_norm": 0.06599036604166031,
      "learning_rate": 1.3521931704529218e-05,
      "loss": 0.0118,
      "step": 22670
    },
    {
      "epoch": 4.86069438491213,
      "grad_norm": 0.022725025191903114,
      "learning_rate": 1.3519074153450494e-05,
      "loss": 0.2083,
      "step": 22680
    },
    {
      "epoch": 4.862837548221174,
      "grad_norm": 1.580672025680542,
      "learning_rate": 1.3516216602371768e-05,
      "loss": 0.0019,
      "step": 22690
    },
    {
      "epoch": 4.864980711530219,
      "grad_norm": 0.034806765615940094,
      "learning_rate": 1.3513359051293042e-05,
      "loss": 0.0008,
      "step": 22700
    },
    {
      "epoch": 4.867123874839263,
      "grad_norm": 0.029542485252022743,
      "learning_rate": 1.3510501500214318e-05,
      "loss": 0.0006,
      "step": 22710
    },
    {
      "epoch": 4.8692670381483065,
      "grad_norm": 0.03345722705125809,
      "learning_rate": 1.3507643949135591e-05,
      "loss": 0.0037,
      "step": 22720
    },
    {
      "epoch": 4.871410201457351,
      "grad_norm": 0.021258343011140823,
      "learning_rate": 1.3504786398056865e-05,
      "loss": 0.256,
      "step": 22730
    },
    {
      "epoch": 4.873553364766395,
      "grad_norm": 0.018190423026680946,
      "learning_rate": 1.3501928846978141e-05,
      "loss": 0.2095,
      "step": 22740
    },
    {
      "epoch": 4.875696528075439,
      "grad_norm": 37.54806137084961,
      "learning_rate": 1.3499071295899415e-05,
      "loss": 0.3948,
      "step": 22750
    },
    {
      "epoch": 4.877839691384484,
      "grad_norm": 0.030993472784757614,
      "learning_rate": 1.349621374482069e-05,
      "loss": 0.1815,
      "step": 22760
    },
    {
      "epoch": 4.8799828546935275,
      "grad_norm": 0.0642269104719162,
      "learning_rate": 1.3493356193741965e-05,
      "loss": 0.001,
      "step": 22770
    },
    {
      "epoch": 4.882126018002571,
      "grad_norm": 0.05895831063389778,
      "learning_rate": 1.3490498642663238e-05,
      "loss": 0.0012,
      "step": 22780
    },
    {
      "epoch": 4.884269181311616,
      "grad_norm": 40.4259033203125,
      "learning_rate": 1.3487641091584514e-05,
      "loss": 0.1012,
      "step": 22790
    },
    {
      "epoch": 4.88641234462066,
      "grad_norm": 0.017086215317249298,
      "learning_rate": 1.3484783540505788e-05,
      "loss": 0.0003,
      "step": 22800
    },
    {
      "epoch": 4.888555507929704,
      "grad_norm": 0.2047235667705536,
      "learning_rate": 1.3481925989427062e-05,
      "loss": 0.0012,
      "step": 22810
    },
    {
      "epoch": 4.890698671238749,
      "grad_norm": 3.2159831523895264,
      "learning_rate": 1.3479068438348338e-05,
      "loss": 0.4588,
      "step": 22820
    },
    {
      "epoch": 4.892841834547792,
      "grad_norm": 0.01093429233878851,
      "learning_rate": 1.3476210887269611e-05,
      "loss": 0.2084,
      "step": 22830
    },
    {
      "epoch": 4.894984997856836,
      "grad_norm": 0.03439948707818985,
      "learning_rate": 1.3473353336190887e-05,
      "loss": 0.0007,
      "step": 22840
    },
    {
      "epoch": 4.897128161165881,
      "grad_norm": 0.02351480722427368,
      "learning_rate": 1.3470495785112161e-05,
      "loss": 0.2866,
      "step": 22850
    },
    {
      "epoch": 4.899271324474925,
      "grad_norm": 0.031868819147348404,
      "learning_rate": 1.3467638234033435e-05,
      "loss": 0.0009,
      "step": 22860
    },
    {
      "epoch": 4.901414487783969,
      "grad_norm": 0.12127532064914703,
      "learning_rate": 1.3464780682954707e-05,
      "loss": 0.0004,
      "step": 22870
    },
    {
      "epoch": 4.9035576510930134,
      "grad_norm": 0.004062329884618521,
      "learning_rate": 1.3461923131875983e-05,
      "loss": 0.0003,
      "step": 22880
    },
    {
      "epoch": 4.905700814402057,
      "grad_norm": 0.0134853171184659,
      "learning_rate": 1.3459065580797257e-05,
      "loss": 0.0002,
      "step": 22890
    },
    {
      "epoch": 4.907843977711101,
      "grad_norm": 0.008913467638194561,
      "learning_rate": 1.3456208029718532e-05,
      "loss": 0.2221,
      "step": 22900
    },
    {
      "epoch": 4.909987141020146,
      "grad_norm": 0.016198687255382538,
      "learning_rate": 1.3453350478639806e-05,
      "loss": 0.0004,
      "step": 22910
    },
    {
      "epoch": 4.91213030432919,
      "grad_norm": 0.1277088075876236,
      "learning_rate": 1.345049292756108e-05,
      "loss": 0.0005,
      "step": 22920
    },
    {
      "epoch": 4.914273467638234,
      "grad_norm": 95.46922302246094,
      "learning_rate": 1.3447635376482356e-05,
      "loss": 0.1177,
      "step": 22930
    },
    {
      "epoch": 4.916416630947278,
      "grad_norm": 0.012080342508852482,
      "learning_rate": 1.344477782540363e-05,
      "loss": 0.1156,
      "step": 22940
    },
    {
      "epoch": 4.918559794256322,
      "grad_norm": 0.0152710797265172,
      "learning_rate": 1.3441920274324904e-05,
      "loss": 0.0014,
      "step": 22950
    },
    {
      "epoch": 4.920702957565366,
      "grad_norm": 0.01912877708673477,
      "learning_rate": 1.343906272324618e-05,
      "loss": 0.0005,
      "step": 22960
    },
    {
      "epoch": 4.922846120874411,
      "grad_norm": 0.026405317708849907,
      "learning_rate": 1.3436205172167453e-05,
      "loss": 0.0002,
      "step": 22970
    },
    {
      "epoch": 4.924989284183455,
      "grad_norm": 0.11490077525377274,
      "learning_rate": 1.3433347621088729e-05,
      "loss": 0.2477,
      "step": 22980
    },
    {
      "epoch": 4.9271324474924985,
      "grad_norm": 0.0014299985487014055,
      "learning_rate": 1.3430490070010003e-05,
      "loss": 0.037,
      "step": 22990
    },
    {
      "epoch": 4.929275610801543,
      "grad_norm": 0.011191162280738354,
      "learning_rate": 1.3427632518931277e-05,
      "loss": 0.1909,
      "step": 23000
    },
    {
      "epoch": 4.931418774110587,
      "grad_norm": 0.1248767077922821,
      "learning_rate": 1.3424774967852552e-05,
      "loss": 0.3925,
      "step": 23010
    },
    {
      "epoch": 4.933561937419631,
      "grad_norm": 0.010029914788901806,
      "learning_rate": 1.3421917416773826e-05,
      "loss": 0.3862,
      "step": 23020
    },
    {
      "epoch": 4.935705100728676,
      "grad_norm": 0.02200256660580635,
      "learning_rate": 1.34190598656951e-05,
      "loss": 0.0005,
      "step": 23030
    },
    {
      "epoch": 4.9378482640377195,
      "grad_norm": 0.00957864336669445,
      "learning_rate": 1.3416202314616376e-05,
      "loss": 0.1928,
      "step": 23040
    },
    {
      "epoch": 4.939991427346763,
      "grad_norm": 0.018614765256643295,
      "learning_rate": 1.341334476353765e-05,
      "loss": 0.2502,
      "step": 23050
    },
    {
      "epoch": 4.942134590655808,
      "grad_norm": 0.01387597806751728,
      "learning_rate": 1.3410487212458925e-05,
      "loss": 0.118,
      "step": 23060
    },
    {
      "epoch": 4.944277753964852,
      "grad_norm": 0.022236201912164688,
      "learning_rate": 1.34076296613802e-05,
      "loss": 0.0005,
      "step": 23070
    },
    {
      "epoch": 4.946420917273897,
      "grad_norm": 0.017573410645127296,
      "learning_rate": 1.3404772110301472e-05,
      "loss": 0.0005,
      "step": 23080
    },
    {
      "epoch": 4.9485640805829405,
      "grad_norm": 0.008430199697613716,
      "learning_rate": 1.3401914559222745e-05,
      "loss": 0.1404,
      "step": 23090
    },
    {
      "epoch": 4.950707243891984,
      "grad_norm": 28.00119972229004,
      "learning_rate": 1.3399057008144021e-05,
      "loss": 0.4743,
      "step": 23100
    },
    {
      "epoch": 4.952850407201029,
      "grad_norm": 0.00407493207603693,
      "learning_rate": 1.3396199457065295e-05,
      "loss": 0.0006,
      "step": 23110
    },
    {
      "epoch": 4.954993570510073,
      "grad_norm": 1.3106708526611328,
      "learning_rate": 1.339334190598657e-05,
      "loss": 0.0017,
      "step": 23120
    },
    {
      "epoch": 4.957136733819117,
      "grad_norm": 0.007470495067536831,
      "learning_rate": 1.3390484354907845e-05,
      "loss": 0.1242,
      "step": 23130
    },
    {
      "epoch": 4.9592798971281615,
      "grad_norm": 0.00557783804833889,
      "learning_rate": 1.3387626803829118e-05,
      "loss": 0.3887,
      "step": 23140
    },
    {
      "epoch": 4.961423060437205,
      "grad_norm": 0.018316106870770454,
      "learning_rate": 1.3384769252750394e-05,
      "loss": 0.2129,
      "step": 23150
    },
    {
      "epoch": 4.963566223746249,
      "grad_norm": 0.008308660238981247,
      "learning_rate": 1.3381911701671668e-05,
      "loss": 0.1134,
      "step": 23160
    },
    {
      "epoch": 4.965709387055294,
      "grad_norm": 0.005267918575555086,
      "learning_rate": 1.3379054150592942e-05,
      "loss": 0.315,
      "step": 23170
    },
    {
      "epoch": 4.967852550364338,
      "grad_norm": 0.016592463478446007,
      "learning_rate": 1.3376196599514218e-05,
      "loss": 0.0009,
      "step": 23180
    },
    {
      "epoch": 4.969995713673382,
      "grad_norm": 0.007448370568454266,
      "learning_rate": 1.3373339048435492e-05,
      "loss": 0.1431,
      "step": 23190
    },
    {
      "epoch": 4.972138876982426,
      "grad_norm": 0.009360700845718384,
      "learning_rate": 1.3370481497356767e-05,
      "loss": 0.2117,
      "step": 23200
    },
    {
      "epoch": 4.97428204029147,
      "grad_norm": 0.017041828483343124,
      "learning_rate": 1.3367623946278041e-05,
      "loss": 0.0007,
      "step": 23210
    },
    {
      "epoch": 4.976425203600514,
      "grad_norm": 0.3573017716407776,
      "learning_rate": 1.3364766395199315e-05,
      "loss": 0.256,
      "step": 23220
    },
    {
      "epoch": 4.978568366909559,
      "grad_norm": 0.006235847249627113,
      "learning_rate": 1.336190884412059e-05,
      "loss": 0.3284,
      "step": 23230
    },
    {
      "epoch": 4.980711530218603,
      "grad_norm": 0.03893663361668587,
      "learning_rate": 1.3359051293041865e-05,
      "loss": 0.2373,
      "step": 23240
    },
    {
      "epoch": 4.9828546935276465,
      "grad_norm": 0.021564815193414688,
      "learning_rate": 1.335619374196314e-05,
      "loss": 0.2049,
      "step": 23250
    },
    {
      "epoch": 4.984997856836691,
      "grad_norm": 0.20720306038856506,
      "learning_rate": 1.3353336190884414e-05,
      "loss": 0.0006,
      "step": 23260
    },
    {
      "epoch": 4.987141020145735,
      "grad_norm": 0.004786322358995676,
      "learning_rate": 1.3350478639805688e-05,
      "loss": 0.1412,
      "step": 23270
    },
    {
      "epoch": 4.989284183454779,
      "grad_norm": 0.030901499092578888,
      "learning_rate": 1.3347621088726964e-05,
      "loss": 0.6701,
      "step": 23280
    },
    {
      "epoch": 4.991427346763824,
      "grad_norm": 0.022682473063468933,
      "learning_rate": 1.3344763537648238e-05,
      "loss": 0.0004,
      "step": 23290
    },
    {
      "epoch": 4.993570510072868,
      "grad_norm": 0.06107735633850098,
      "learning_rate": 1.334190598656951e-05,
      "loss": 0.2099,
      "step": 23300
    },
    {
      "epoch": 4.995713673381911,
      "grad_norm": 0.013487379066646099,
      "learning_rate": 1.3339048435490784e-05,
      "loss": 0.0008,
      "step": 23310
    },
    {
      "epoch": 4.997856836690956,
      "grad_norm": 0.03985847905278206,
      "learning_rate": 1.333619088441206e-05,
      "loss": 0.0129,
      "step": 23320
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9882267713546753,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.002,
      "step": 23330
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9173333333333333,
      "eval_f1": 0.7990275526742302,
      "eval_loss": 0.503389298915863,
      "eval_precision": 0.7572964669738863,
      "eval_recall": 0.8456260720411664,
      "eval_runtime": 107.8708,
      "eval_samples_per_second": 27.811,
      "eval_steps_per_second": 1.159,
      "step": 23330
    },
    {
      "epoch": 5.002143163309044,
      "grad_norm": 0.02754180133342743,
      "learning_rate": 1.3330475782254609e-05,
      "loss": 0.0004,
      "step": 23340
    },
    {
      "epoch": 5.004286326618089,
      "grad_norm": 0.04252059757709503,
      "learning_rate": 1.3327618231175883e-05,
      "loss": 0.0003,
      "step": 23350
    },
    {
      "epoch": 5.006429489927132,
      "grad_norm": 0.009871382266283035,
      "learning_rate": 1.3324760680097157e-05,
      "loss": 0.0005,
      "step": 23360
    },
    {
      "epoch": 5.008572653236176,
      "grad_norm": 0.0015535904094576836,
      "learning_rate": 1.3321903129018432e-05,
      "loss": 0.0001,
      "step": 23370
    },
    {
      "epoch": 5.010715816545221,
      "grad_norm": 0.0030127328354865313,
      "learning_rate": 1.3319045577939706e-05,
      "loss": 0.0002,
      "step": 23380
    },
    {
      "epoch": 5.012858979854265,
      "grad_norm": 0.004417285788804293,
      "learning_rate": 1.3316188026860982e-05,
      "loss": 0.0001,
      "step": 23390
    },
    {
      "epoch": 5.015002143163309,
      "grad_norm": 60.16318893432617,
      "learning_rate": 1.3313330475782256e-05,
      "loss": 0.2051,
      "step": 23400
    },
    {
      "epoch": 5.0171453064723535,
      "grad_norm": 0.016516001895070076,
      "learning_rate": 1.331047292470353e-05,
      "loss": 0.0003,
      "step": 23410
    },
    {
      "epoch": 5.019288469781397,
      "grad_norm": 0.003699954366311431,
      "learning_rate": 1.3307615373624805e-05,
      "loss": 0.0001,
      "step": 23420
    },
    {
      "epoch": 5.021431633090441,
      "grad_norm": 0.0020707673393189907,
      "learning_rate": 1.330475782254608e-05,
      "loss": 0.1796,
      "step": 23430
    },
    {
      "epoch": 5.023574796399486,
      "grad_norm": 0.001485068234615028,
      "learning_rate": 1.3301900271467353e-05,
      "loss": 0.1833,
      "step": 23440
    },
    {
      "epoch": 5.02571795970853,
      "grad_norm": 0.006049376912415028,
      "learning_rate": 1.3299042720388629e-05,
      "loss": 0.3117,
      "step": 23450
    },
    {
      "epoch": 5.027861123017574,
      "grad_norm": 0.007075388915836811,
      "learning_rate": 1.3296185169309903e-05,
      "loss": 0.0316,
      "step": 23460
    },
    {
      "epoch": 5.030004286326618,
      "grad_norm": 0.007094530388712883,
      "learning_rate": 1.3293327618231178e-05,
      "loss": 0.0018,
      "step": 23470
    },
    {
      "epoch": 5.032147449635662,
      "grad_norm": 0.052037693560123444,
      "learning_rate": 1.3290470067152452e-05,
      "loss": 0.0002,
      "step": 23480
    },
    {
      "epoch": 5.034290612944706,
      "grad_norm": 0.009299216791987419,
      "learning_rate": 1.3287612516073726e-05,
      "loss": 0.0001,
      "step": 23490
    },
    {
      "epoch": 5.036433776253751,
      "grad_norm": 0.008878042921423912,
      "learning_rate": 1.3284754964995002e-05,
      "loss": 0.0002,
      "step": 23500
    },
    {
      "epoch": 5.038576939562795,
      "grad_norm": 0.006281921174377203,
      "learning_rate": 1.3281897413916274e-05,
      "loss": 0.0693,
      "step": 23510
    },
    {
      "epoch": 5.0407201028718385,
      "grad_norm": 0.038053959608078,
      "learning_rate": 1.3279039862837548e-05,
      "loss": 0.0002,
      "step": 23520
    },
    {
      "epoch": 5.042863266180883,
      "grad_norm": 0.0023683030158281326,
      "learning_rate": 1.3276182311758824e-05,
      "loss": 0.2292,
      "step": 23530
    },
    {
      "epoch": 5.045006429489927,
      "grad_norm": 0.08439852297306061,
      "learning_rate": 1.3273324760680098e-05,
      "loss": 0.1253,
      "step": 23540
    },
    {
      "epoch": 5.047149592798971,
      "grad_norm": 0.004364460706710815,
      "learning_rate": 1.3270467209601372e-05,
      "loss": 0.0002,
      "step": 23550
    },
    {
      "epoch": 5.049292756108016,
      "grad_norm": 0.02823554538190365,
      "learning_rate": 1.3267609658522647e-05,
      "loss": 0.0002,
      "step": 23560
    },
    {
      "epoch": 5.0514359194170595,
      "grad_norm": 0.3716634213924408,
      "learning_rate": 1.3264752107443921e-05,
      "loss": 0.0004,
      "step": 23570
    },
    {
      "epoch": 5.053579082726103,
      "grad_norm": 0.002997338306158781,
      "learning_rate": 1.3261894556365195e-05,
      "loss": 0.0009,
      "step": 23580
    },
    {
      "epoch": 5.055722246035148,
      "grad_norm": 0.00433275057002902,
      "learning_rate": 1.325903700528647e-05,
      "loss": 0.0004,
      "step": 23590
    },
    {
      "epoch": 5.057865409344192,
      "grad_norm": 0.04994016885757446,
      "learning_rate": 1.3256179454207745e-05,
      "loss": 0.0099,
      "step": 23600
    },
    {
      "epoch": 5.060008572653236,
      "grad_norm": 0.0025023857597261667,
      "learning_rate": 1.325332190312902e-05,
      "loss": 0.0001,
      "step": 23610
    },
    {
      "epoch": 5.0621517359622805,
      "grad_norm": 0.002576523693278432,
      "learning_rate": 1.3250464352050294e-05,
      "loss": 0.0901,
      "step": 23620
    },
    {
      "epoch": 5.064294899271324,
      "grad_norm": 0.002149449661374092,
      "learning_rate": 1.3247606800971568e-05,
      "loss": 0.1177,
      "step": 23630
    },
    {
      "epoch": 5.066438062580368,
      "grad_norm": 0.0021710069850087166,
      "learning_rate": 1.3244749249892844e-05,
      "loss": 0.0001,
      "step": 23640
    },
    {
      "epoch": 5.068581225889413,
      "grad_norm": 0.005199194420129061,
      "learning_rate": 1.3241891698814118e-05,
      "loss": 0.1131,
      "step": 23650
    },
    {
      "epoch": 5.070724389198457,
      "grad_norm": 0.0062547666020691395,
      "learning_rate": 1.3239034147735392e-05,
      "loss": 0.2168,
      "step": 23660
    },
    {
      "epoch": 5.072867552507501,
      "grad_norm": 0.030823614448308945,
      "learning_rate": 1.3236176596656667e-05,
      "loss": 0.1942,
      "step": 23670
    },
    {
      "epoch": 5.075010715816545,
      "grad_norm": 0.003747684182599187,
      "learning_rate": 1.3233319045577941e-05,
      "loss": 0.0025,
      "step": 23680
    },
    {
      "epoch": 5.077153879125589,
      "grad_norm": 0.0040417443960905075,
      "learning_rate": 1.3230461494499217e-05,
      "loss": 0.0003,
      "step": 23690
    },
    {
      "epoch": 5.079297042434633,
      "grad_norm": 0.004358507692813873,
      "learning_rate": 1.322760394342049e-05,
      "loss": 0.0001,
      "step": 23700
    },
    {
      "epoch": 5.081440205743678,
      "grad_norm": 0.008256316184997559,
      "learning_rate": 1.3224746392341765e-05,
      "loss": 0.0009,
      "step": 23710
    },
    {
      "epoch": 5.083583369052722,
      "grad_norm": 0.006893526762723923,
      "learning_rate": 1.322188884126304e-05,
      "loss": 0.7973,
      "step": 23720
    },
    {
      "epoch": 5.085726532361766,
      "grad_norm": 0.005119386129081249,
      "learning_rate": 1.3219031290184312e-05,
      "loss": 0.0001,
      "step": 23730
    },
    {
      "epoch": 5.08786969567081,
      "grad_norm": 0.0386740006506443,
      "learning_rate": 1.3216173739105586e-05,
      "loss": 0.0001,
      "step": 23740
    },
    {
      "epoch": 5.090012858979854,
      "grad_norm": 0.023099688813090324,
      "learning_rate": 1.3213316188026862e-05,
      "loss": 0.1554,
      "step": 23750
    },
    {
      "epoch": 5.092156022288899,
      "grad_norm": 0.034428343176841736,
      "learning_rate": 1.3210458636948136e-05,
      "loss": 0.0005,
      "step": 23760
    },
    {
      "epoch": 5.094299185597943,
      "grad_norm": 0.007496738340705633,
      "learning_rate": 1.320760108586941e-05,
      "loss": 0.0002,
      "step": 23770
    },
    {
      "epoch": 5.0964423489069866,
      "grad_norm": 0.41384047269821167,
      "learning_rate": 1.3204743534790685e-05,
      "loss": 0.0008,
      "step": 23780
    },
    {
      "epoch": 5.098585512216031,
      "grad_norm": 0.00950966589152813,
      "learning_rate": 1.320188598371196e-05,
      "loss": 0.0005,
      "step": 23790
    },
    {
      "epoch": 5.100728675525075,
      "grad_norm": 0.01762949861586094,
      "learning_rate": 1.3199028432633233e-05,
      "loss": 0.2209,
      "step": 23800
    },
    {
      "epoch": 5.102871838834119,
      "grad_norm": 0.29356056451797485,
      "learning_rate": 1.3196170881554509e-05,
      "loss": 0.0005,
      "step": 23810
    },
    {
      "epoch": 5.105015002143164,
      "grad_norm": 0.01798512414097786,
      "learning_rate": 1.3193313330475783e-05,
      "loss": 0.2869,
      "step": 23820
    },
    {
      "epoch": 5.107158165452208,
      "grad_norm": 0.0209068451076746,
      "learning_rate": 1.3190455779397059e-05,
      "loss": 0.0002,
      "step": 23830
    },
    {
      "epoch": 5.109301328761251,
      "grad_norm": 0.0011765608796849847,
      "learning_rate": 1.3187598228318332e-05,
      "loss": 0.2025,
      "step": 23840
    },
    {
      "epoch": 5.111444492070296,
      "grad_norm": 0.05376356840133667,
      "learning_rate": 1.3184740677239606e-05,
      "loss": 0.0003,
      "step": 23850
    },
    {
      "epoch": 5.11358765537934,
      "grad_norm": 0.030123351141810417,
      "learning_rate": 1.3181883126160882e-05,
      "loss": 0.0002,
      "step": 23860
    },
    {
      "epoch": 5.115730818688384,
      "grad_norm": 0.0021835772786289454,
      "learning_rate": 1.3179025575082156e-05,
      "loss": 0.0002,
      "step": 23870
    },
    {
      "epoch": 5.117873981997429,
      "grad_norm": 0.0009019315475597978,
      "learning_rate": 1.317616802400343e-05,
      "loss": 0.2356,
      "step": 23880
    },
    {
      "epoch": 5.1200171453064725,
      "grad_norm": 0.054069191217422485,
      "learning_rate": 1.3173310472924705e-05,
      "loss": 0.0004,
      "step": 23890
    },
    {
      "epoch": 5.122160308615516,
      "grad_norm": 0.05659148469567299,
      "learning_rate": 1.317045292184598e-05,
      "loss": 0.0013,
      "step": 23900
    },
    {
      "epoch": 5.124303471924561,
      "grad_norm": 0.01060481183230877,
      "learning_rate": 1.3167595370767255e-05,
      "loss": 0.0001,
      "step": 23910
    },
    {
      "epoch": 5.126446635233605,
      "grad_norm": 0.0018483049934729934,
      "learning_rate": 1.3164737819688529e-05,
      "loss": 0.0001,
      "step": 23920
    },
    {
      "epoch": 5.128589798542649,
      "grad_norm": 0.17408862709999084,
      "learning_rate": 1.3161880268609803e-05,
      "loss": 0.004,
      "step": 23930
    },
    {
      "epoch": 5.1307329618516935,
      "grad_norm": 0.003214352997019887,
      "learning_rate": 1.3159022717531075e-05,
      "loss": 0.0001,
      "step": 23940
    },
    {
      "epoch": 5.132876125160737,
      "grad_norm": 0.0026845638640224934,
      "learning_rate": 1.315616516645235e-05,
      "loss": 0.0002,
      "step": 23950
    },
    {
      "epoch": 5.135019288469781,
      "grad_norm": 0.0006918036960996687,
      "learning_rate": 1.3153307615373625e-05,
      "loss": 0.1154,
      "step": 23960
    },
    {
      "epoch": 5.137162451778826,
      "grad_norm": 0.03437052667140961,
      "learning_rate": 1.31504500642949e-05,
      "loss": 0.0002,
      "step": 23970
    },
    {
      "epoch": 5.13930561508787,
      "grad_norm": 0.2351849377155304,
      "learning_rate": 1.3147592513216174e-05,
      "loss": 0.2766,
      "step": 23980
    },
    {
      "epoch": 5.141448778396914,
      "grad_norm": 0.004955824930220842,
      "learning_rate": 1.3144734962137448e-05,
      "loss": 0.0013,
      "step": 23990
    },
    {
      "epoch": 5.143591941705958,
      "grad_norm": 0.007699200883507729,
      "learning_rate": 1.3141877411058724e-05,
      "loss": 0.0002,
      "step": 24000
    },
    {
      "epoch": 5.145735105015002,
      "grad_norm": 0.002902835374698043,
      "learning_rate": 1.3139019859979998e-05,
      "loss": 0.0697,
      "step": 24010
    },
    {
      "epoch": 5.147878268324046,
      "grad_norm": 0.0016877149464562535,
      "learning_rate": 1.3136162308901272e-05,
      "loss": 0.0001,
      "step": 24020
    },
    {
      "epoch": 5.150021431633091,
      "grad_norm": 0.004067461006343365,
      "learning_rate": 1.3133304757822547e-05,
      "loss": 0.0837,
      "step": 24030
    },
    {
      "epoch": 5.152164594942135,
      "grad_norm": 0.010072212666273117,
      "learning_rate": 1.3130447206743821e-05,
      "loss": 0.0001,
      "step": 24040
    },
    {
      "epoch": 5.1543077582511785,
      "grad_norm": 0.09977972507476807,
      "learning_rate": 1.3127589655665097e-05,
      "loss": 0.2223,
      "step": 24050
    },
    {
      "epoch": 5.156450921560223,
      "grad_norm": 0.0023532842751592398,
      "learning_rate": 1.312473210458637e-05,
      "loss": 0.0249,
      "step": 24060
    },
    {
      "epoch": 5.158594084869267,
      "grad_norm": 0.03669146075844765,
      "learning_rate": 1.3121874553507645e-05,
      "loss": 0.2029,
      "step": 24070
    },
    {
      "epoch": 5.160737248178311,
      "grad_norm": 0.0019870081450790167,
      "learning_rate": 1.311901700242892e-05,
      "loss": 0.0004,
      "step": 24080
    },
    {
      "epoch": 5.162880411487356,
      "grad_norm": 0.004986295942217112,
      "learning_rate": 1.3116159451350194e-05,
      "loss": 0.2657,
      "step": 24090
    },
    {
      "epoch": 5.1650235747963995,
      "grad_norm": 0.013593491166830063,
      "learning_rate": 1.311330190027147e-05,
      "loss": 0.2408,
      "step": 24100
    },
    {
      "epoch": 5.167166738105443,
      "grad_norm": 0.02711568959057331,
      "learning_rate": 1.3110444349192744e-05,
      "loss": 0.1889,
      "step": 24110
    },
    {
      "epoch": 5.169309901414488,
      "grad_norm": 0.012584581971168518,
      "learning_rate": 1.3107586798114018e-05,
      "loss": 0.1307,
      "step": 24120
    },
    {
      "epoch": 5.171453064723532,
      "grad_norm": 0.03736191987991333,
      "learning_rate": 1.3104729247035293e-05,
      "loss": 0.0005,
      "step": 24130
    },
    {
      "epoch": 5.173596228032576,
      "grad_norm": 0.01124711986631155,
      "learning_rate": 1.3101871695956567e-05,
      "loss": 0.3414,
      "step": 24140
    },
    {
      "epoch": 5.1757393913416205,
      "grad_norm": 17.769691467285156,
      "learning_rate": 1.3099014144877841e-05,
      "loss": 0.1991,
      "step": 24150
    },
    {
      "epoch": 5.177882554650664,
      "grad_norm": 96.37114715576172,
      "learning_rate": 1.3096156593799113e-05,
      "loss": 0.0765,
      "step": 24160
    },
    {
      "epoch": 5.180025717959708,
      "grad_norm": 0.0023238302674144506,
      "learning_rate": 1.3093299042720389e-05,
      "loss": 0.0007,
      "step": 24170
    },
    {
      "epoch": 5.182168881268753,
      "grad_norm": 0.02247968688607216,
      "learning_rate": 1.3090441491641663e-05,
      "loss": 0.0006,
      "step": 24180
    },
    {
      "epoch": 5.184312044577797,
      "grad_norm": 0.1882287710905075,
      "learning_rate": 1.3087583940562939e-05,
      "loss": 0.1915,
      "step": 24190
    },
    {
      "epoch": 5.186455207886841,
      "grad_norm": 0.03660288453102112,
      "learning_rate": 1.3084726389484212e-05,
      "loss": 0.0005,
      "step": 24200
    },
    {
      "epoch": 5.188598371195885,
      "grad_norm": 0.307271808385849,
      "learning_rate": 1.3081868838405486e-05,
      "loss": 0.0004,
      "step": 24210
    },
    {
      "epoch": 5.190741534504929,
      "grad_norm": 0.0014347410760819912,
      "learning_rate": 1.3079011287326762e-05,
      "loss": 0.0054,
      "step": 24220
    },
    {
      "epoch": 5.192884697813973,
      "grad_norm": 0.0015893442323431373,
      "learning_rate": 1.3076153736248036e-05,
      "loss": 0.1584,
      "step": 24230
    },
    {
      "epoch": 5.195027861123018,
      "grad_norm": 0.11536425352096558,
      "learning_rate": 1.3073296185169312e-05,
      "loss": 0.006,
      "step": 24240
    },
    {
      "epoch": 5.197171024432062,
      "grad_norm": 61.89737319946289,
      "learning_rate": 1.3070438634090586e-05,
      "loss": 0.1626,
      "step": 24250
    },
    {
      "epoch": 5.1993141877411055,
      "grad_norm": 0.0043260264210402966,
      "learning_rate": 1.306758108301186e-05,
      "loss": 0.0018,
      "step": 24260
    },
    {
      "epoch": 5.20145735105015,
      "grad_norm": 0.05476759001612663,
      "learning_rate": 1.3064723531933135e-05,
      "loss": 0.0007,
      "step": 24270
    },
    {
      "epoch": 5.203600514359194,
      "grad_norm": 0.0030822092667222023,
      "learning_rate": 1.3061865980854409e-05,
      "loss": 0.0095,
      "step": 24280
    },
    {
      "epoch": 5.205743677668238,
      "grad_norm": 0.009248180314898491,
      "learning_rate": 1.3059008429775683e-05,
      "loss": 0.0001,
      "step": 24290
    },
    {
      "epoch": 5.207886840977283,
      "grad_norm": 0.11603289842605591,
      "learning_rate": 1.3056150878696959e-05,
      "loss": 0.0003,
      "step": 24300
    },
    {
      "epoch": 5.210030004286327,
      "grad_norm": 11.174947738647461,
      "learning_rate": 1.3053293327618232e-05,
      "loss": 0.009,
      "step": 24310
    },
    {
      "epoch": 5.21217316759537,
      "grad_norm": 0.001728386851027608,
      "learning_rate": 1.3050435776539508e-05,
      "loss": 0.0001,
      "step": 24320
    },
    {
      "epoch": 5.214316330904415,
      "grad_norm": 0.002265379996970296,
      "learning_rate": 1.3047578225460782e-05,
      "loss": 0.1373,
      "step": 24330
    },
    {
      "epoch": 5.216459494213459,
      "grad_norm": 0.0029789183754473925,
      "learning_rate": 1.3044720674382056e-05,
      "loss": 0.0002,
      "step": 24340
    },
    {
      "epoch": 5.218602657522503,
      "grad_norm": 0.002627612091600895,
      "learning_rate": 1.3041863123303332e-05,
      "loss": 0.0002,
      "step": 24350
    },
    {
      "epoch": 5.220745820831548,
      "grad_norm": 0.001511236885562539,
      "learning_rate": 1.3039005572224606e-05,
      "loss": 0.0003,
      "step": 24360
    },
    {
      "epoch": 5.222888984140591,
      "grad_norm": 0.029750026762485504,
      "learning_rate": 1.3036148021145878e-05,
      "loss": 0.6205,
      "step": 24370
    },
    {
      "epoch": 5.225032147449635,
      "grad_norm": 0.00130671844817698,
      "learning_rate": 1.3033290470067153e-05,
      "loss": 0.2335,
      "step": 24380
    },
    {
      "epoch": 5.22717531075868,
      "grad_norm": 0.00911051407456398,
      "learning_rate": 1.3030432918988427e-05,
      "loss": 0.0003,
      "step": 24390
    },
    {
      "epoch": 5.229318474067724,
      "grad_norm": 0.004203731659799814,
      "learning_rate": 1.3027575367909701e-05,
      "loss": 0.0614,
      "step": 24400
    },
    {
      "epoch": 5.231461637376768,
      "grad_norm": 0.00658093485981226,
      "learning_rate": 1.3024717816830977e-05,
      "loss": 0.1918,
      "step": 24410
    },
    {
      "epoch": 5.2336048006858125,
      "grad_norm": 93.8205337524414,
      "learning_rate": 1.302186026575225e-05,
      "loss": 0.4013,
      "step": 24420
    },
    {
      "epoch": 5.235747963994856,
      "grad_norm": 27.335344314575195,
      "learning_rate": 1.3019002714673525e-05,
      "loss": 0.35,
      "step": 24430
    },
    {
      "epoch": 5.2378911273039,
      "grad_norm": 0.16569110751152039,
      "learning_rate": 1.30161451635948e-05,
      "loss": 0.0058,
      "step": 24440
    },
    {
      "epoch": 5.240034290612945,
      "grad_norm": 0.20429573953151703,
      "learning_rate": 1.3013287612516074e-05,
      "loss": 0.1896,
      "step": 24450
    },
    {
      "epoch": 5.242177453921989,
      "grad_norm": 0.36155205965042114,
      "learning_rate": 1.301043006143735e-05,
      "loss": 0.0019,
      "step": 24460
    },
    {
      "epoch": 5.244320617231033,
      "grad_norm": 0.0018323176773265004,
      "learning_rate": 1.3007572510358624e-05,
      "loss": 0.1758,
      "step": 24470
    },
    {
      "epoch": 5.246463780540077,
      "grad_norm": 0.002277896273881197,
      "learning_rate": 1.3004714959279898e-05,
      "loss": 0.3154,
      "step": 24480
    },
    {
      "epoch": 5.248606943849121,
      "grad_norm": 0.04800187423825264,
      "learning_rate": 1.3001857408201173e-05,
      "loss": 0.0017,
      "step": 24490
    },
    {
      "epoch": 5.250750107158165,
      "grad_norm": 0.0016946688992902637,
      "learning_rate": 1.2998999857122447e-05,
      "loss": 0.0004,
      "step": 24500
    },
    {
      "epoch": 5.25289327046721,
      "grad_norm": 0.061429426074028015,
      "learning_rate": 1.2996142306043721e-05,
      "loss": 0.0005,
      "step": 24510
    },
    {
      "epoch": 5.255036433776254,
      "grad_norm": 0.05456003546714783,
      "learning_rate": 1.2993284754964997e-05,
      "loss": 0.1974,
      "step": 24520
    },
    {
      "epoch": 5.2571795970852975,
      "grad_norm": 0.004593532532453537,
      "learning_rate": 1.299042720388627e-05,
      "loss": 0.0334,
      "step": 24530
    },
    {
      "epoch": 5.259322760394342,
      "grad_norm": 0.0019097438780590892,
      "learning_rate": 1.2987569652807546e-05,
      "loss": 0.0001,
      "step": 24540
    },
    {
      "epoch": 5.261465923703386,
      "grad_norm": 0.008077671751379967,
      "learning_rate": 1.298471210172882e-05,
      "loss": 0.0001,
      "step": 24550
    },
    {
      "epoch": 5.26360908701243,
      "grad_norm": 0.0018573150737211108,
      "learning_rate": 1.2981854550650094e-05,
      "loss": 0.0004,
      "step": 24560
    },
    {
      "epoch": 5.265752250321475,
      "grad_norm": 17.574817657470703,
      "learning_rate": 1.297899699957137e-05,
      "loss": 0.1969,
      "step": 24570
    },
    {
      "epoch": 5.2678954136305185,
      "grad_norm": 0.0007989474106580019,
      "learning_rate": 1.2976139448492644e-05,
      "loss": 0.0,
      "step": 24580
    },
    {
      "epoch": 5.270038576939562,
      "grad_norm": 222.59144592285156,
      "learning_rate": 1.2973281897413916e-05,
      "loss": 0.0615,
      "step": 24590
    },
    {
      "epoch": 5.272181740248607,
      "grad_norm": 2.6126813888549805,
      "learning_rate": 1.2970424346335192e-05,
      "loss": 0.0899,
      "step": 24600
    },
    {
      "epoch": 5.274324903557651,
      "grad_norm": 0.0028147017583251,
      "learning_rate": 1.2967566795256466e-05,
      "loss": 0.0001,
      "step": 24610
    },
    {
      "epoch": 5.276468066866695,
      "grad_norm": 0.0015226444229483604,
      "learning_rate": 1.296470924417774e-05,
      "loss": 0.0003,
      "step": 24620
    },
    {
      "epoch": 5.2786112301757395,
      "grad_norm": 0.05385742709040642,
      "learning_rate": 1.2961851693099015e-05,
      "loss": 0.2812,
      "step": 24630
    },
    {
      "epoch": 5.280754393484783,
      "grad_norm": 0.5905919671058655,
      "learning_rate": 1.2958994142020289e-05,
      "loss": 0.0008,
      "step": 24640
    },
    {
      "epoch": 5.282897556793827,
      "grad_norm": 0.003492874326184392,
      "learning_rate": 1.2956136590941563e-05,
      "loss": 0.2801,
      "step": 24650
    },
    {
      "epoch": 5.285040720102872,
      "grad_norm": 0.6683353185653687,
      "learning_rate": 1.2953279039862839e-05,
      "loss": 0.1881,
      "step": 24660
    },
    {
      "epoch": 5.287183883411916,
      "grad_norm": 40.705570220947266,
      "learning_rate": 1.2950421488784113e-05,
      "loss": 0.2732,
      "step": 24670
    },
    {
      "epoch": 5.2893270467209605,
      "grad_norm": 0.015211977995932102,
      "learning_rate": 1.2947563937705388e-05,
      "loss": 0.0004,
      "step": 24680
    },
    {
      "epoch": 5.291470210030004,
      "grad_norm": 0.01206512376666069,
      "learning_rate": 1.2944706386626662e-05,
      "loss": 0.0019,
      "step": 24690
    },
    {
      "epoch": 5.293613373339048,
      "grad_norm": 0.0008012722828425467,
      "learning_rate": 1.2941848835547936e-05,
      "loss": 0.0002,
      "step": 24700
    },
    {
      "epoch": 5.295756536648093,
      "grad_norm": 0.0009704077383503318,
      "learning_rate": 1.2938991284469212e-05,
      "loss": 0.003,
      "step": 24710
    },
    {
      "epoch": 5.297899699957137,
      "grad_norm": 0.0028621957171708345,
      "learning_rate": 1.2936133733390486e-05,
      "loss": 0.0001,
      "step": 24720
    },
    {
      "epoch": 5.300042863266181,
      "grad_norm": 0.001571033732034266,
      "learning_rate": 1.293327618231176e-05,
      "loss": 0.0001,
      "step": 24730
    },
    {
      "epoch": 5.302186026575225,
      "grad_norm": 0.1910715252161026,
      "learning_rate": 1.2930418631233035e-05,
      "loss": 0.0002,
      "step": 24740
    },
    {
      "epoch": 5.304329189884269,
      "grad_norm": 0.00595497339963913,
      "learning_rate": 1.2927561080154309e-05,
      "loss": 0.1553,
      "step": 24750
    },
    {
      "epoch": 5.306472353193313,
      "grad_norm": 0.002969943918287754,
      "learning_rate": 1.2924703529075585e-05,
      "loss": 0.0001,
      "step": 24760
    },
    {
      "epoch": 5.308615516502358,
      "grad_norm": 0.0016040154732763767,
      "learning_rate": 1.2921845977996859e-05,
      "loss": 0.1203,
      "step": 24770
    },
    {
      "epoch": 5.310758679811402,
      "grad_norm": 0.0036896790843456984,
      "learning_rate": 1.2918988426918133e-05,
      "loss": 0.0001,
      "step": 24780
    },
    {
      "epoch": 5.3129018431204456,
      "grad_norm": 0.0009981569601222873,
      "learning_rate": 1.2916130875839408e-05,
      "loss": 0.0002,
      "step": 24790
    },
    {
      "epoch": 5.31504500642949,
      "grad_norm": 0.0028539591003209352,
      "learning_rate": 1.291327332476068e-05,
      "loss": 0.2035,
      "step": 24800
    },
    {
      "epoch": 5.317188169738534,
      "grad_norm": 0.1537187397480011,
      "learning_rate": 1.2910415773681954e-05,
      "loss": 0.0014,
      "step": 24810
    },
    {
      "epoch": 5.319331333047578,
      "grad_norm": 0.004153918009251356,
      "learning_rate": 1.290755822260323e-05,
      "loss": 0.0003,
      "step": 24820
    },
    {
      "epoch": 5.321474496356623,
      "grad_norm": 0.0012748483568429947,
      "learning_rate": 1.2904700671524504e-05,
      "loss": 0.0002,
      "step": 24830
    },
    {
      "epoch": 5.323617659665667,
      "grad_norm": 0.0007172890473157167,
      "learning_rate": 1.2901843120445778e-05,
      "loss": 0.0058,
      "step": 24840
    },
    {
      "epoch": 5.32576082297471,
      "grad_norm": 0.0015340694226324558,
      "learning_rate": 1.2898985569367053e-05,
      "loss": 0.2228,
      "step": 24850
    },
    {
      "epoch": 5.327903986283755,
      "grad_norm": 0.008527858182787895,
      "learning_rate": 1.2896128018288327e-05,
      "loss": 0.2153,
      "step": 24860
    },
    {
      "epoch": 5.330047149592799,
      "grad_norm": 0.0014284261269494891,
      "learning_rate": 1.2893270467209601e-05,
      "loss": 0.0001,
      "step": 24870
    },
    {
      "epoch": 5.332190312901843,
      "grad_norm": 0.0003995882871095091,
      "learning_rate": 1.2890412916130877e-05,
      "loss": 0.2262,
      "step": 24880
    },
    {
      "epoch": 5.334333476210888,
      "grad_norm": 0.0007476080791093409,
      "learning_rate": 1.288755536505215e-05,
      "loss": 0.2221,
      "step": 24890
    },
    {
      "epoch": 5.3364766395199315,
      "grad_norm": 0.00449245935305953,
      "learning_rate": 1.2884697813973426e-05,
      "loss": 0.1378,
      "step": 24900
    },
    {
      "epoch": 5.338619802828975,
      "grad_norm": 0.0333060622215271,
      "learning_rate": 1.28818402628947e-05,
      "loss": 0.0004,
      "step": 24910
    },
    {
      "epoch": 5.34076296613802,
      "grad_norm": 0.022853130474686623,
      "learning_rate": 1.2878982711815974e-05,
      "loss": 0.1919,
      "step": 24920
    },
    {
      "epoch": 5.342906129447064,
      "grad_norm": 0.00993242859840393,
      "learning_rate": 1.287612516073725e-05,
      "loss": 0.0003,
      "step": 24930
    },
    {
      "epoch": 5.345049292756108,
      "grad_norm": 0.0007296542753465474,
      "learning_rate": 1.2873267609658524e-05,
      "loss": 0.0,
      "step": 24940
    },
    {
      "epoch": 5.3471924560651525,
      "grad_norm": 0.10736347734928131,
      "learning_rate": 1.28704100585798e-05,
      "loss": 0.0002,
      "step": 24950
    },
    {
      "epoch": 5.349335619374196,
      "grad_norm": 0.03444761782884598,
      "learning_rate": 1.2867552507501073e-05,
      "loss": 0.0217,
      "step": 24960
    },
    {
      "epoch": 5.35147878268324,
      "grad_norm": 0.020634621381759644,
      "learning_rate": 1.2864694956422347e-05,
      "loss": 0.1214,
      "step": 24970
    },
    {
      "epoch": 5.353621945992285,
      "grad_norm": 0.007469549775123596,
      "learning_rate": 1.2861837405343623e-05,
      "loss": 0.197,
      "step": 24980
    },
    {
      "epoch": 5.355765109301329,
      "grad_norm": 0.0018846970051527023,
      "learning_rate": 1.2858979854264897e-05,
      "loss": 0.0,
      "step": 24990
    },
    {
      "epoch": 5.357908272610373,
      "grad_norm": 0.0006169040570966899,
      "learning_rate": 1.285612230318617e-05,
      "loss": 0.2838,
      "step": 25000
    },
    {
      "epoch": 5.360051435919417,
      "grad_norm": 0.018956400454044342,
      "learning_rate": 1.2853264752107446e-05,
      "loss": 0.0003,
      "step": 25010
    },
    {
      "epoch": 5.362194599228461,
      "grad_norm": 0.0004395203141029924,
      "learning_rate": 1.2850407201028719e-05,
      "loss": 0.0,
      "step": 25020
    },
    {
      "epoch": 5.364337762537505,
      "grad_norm": 0.0006163795478641987,
      "learning_rate": 1.2847549649949993e-05,
      "loss": 0.0001,
      "step": 25030
    },
    {
      "epoch": 5.36648092584655,
      "grad_norm": 0.003948170691728592,
      "learning_rate": 1.2844692098871268e-05,
      "loss": 0.2179,
      "step": 25040
    },
    {
      "epoch": 5.368624089155594,
      "grad_norm": 0.3410506546497345,
      "learning_rate": 1.2841834547792542e-05,
      "loss": 0.0003,
      "step": 25050
    },
    {
      "epoch": 5.3707672524646375,
      "grad_norm": 0.0017340080812573433,
      "learning_rate": 1.2838976996713816e-05,
      "loss": 0.3819,
      "step": 25060
    },
    {
      "epoch": 5.372910415773682,
      "grad_norm": 0.04022238031029701,
      "learning_rate": 1.2836119445635092e-05,
      "loss": 0.0002,
      "step": 25070
    },
    {
      "epoch": 5.375053579082726,
      "grad_norm": 0.028573207557201385,
      "learning_rate": 1.2833261894556366e-05,
      "loss": 0.0002,
      "step": 25080
    },
    {
      "epoch": 5.37719674239177,
      "grad_norm": 0.005653983447700739,
      "learning_rate": 1.2830404343477641e-05,
      "loss": 0.2554,
      "step": 25090
    },
    {
      "epoch": 5.379339905700815,
      "grad_norm": 0.012555910274386406,
      "learning_rate": 1.2827546792398915e-05,
      "loss": 0.033,
      "step": 25100
    },
    {
      "epoch": 5.3814830690098585,
      "grad_norm": 0.01631932333111763,
      "learning_rate": 1.2824689241320189e-05,
      "loss": 0.0015,
      "step": 25110
    },
    {
      "epoch": 5.383626232318902,
      "grad_norm": 0.00819532759487629,
      "learning_rate": 1.2821831690241465e-05,
      "loss": 0.0003,
      "step": 25120
    },
    {
      "epoch": 5.385769395627947,
      "grad_norm": 0.007839862257242203,
      "learning_rate": 1.2818974139162739e-05,
      "loss": 0.226,
      "step": 25130
    },
    {
      "epoch": 5.387912558936991,
      "grad_norm": 0.0009285623673349619,
      "learning_rate": 1.2816116588084013e-05,
      "loss": 0.0001,
      "step": 25140
    },
    {
      "epoch": 5.390055722246035,
      "grad_norm": 0.00029113286291249096,
      "learning_rate": 1.2813259037005288e-05,
      "loss": 0.0004,
      "step": 25150
    },
    {
      "epoch": 5.3921988855550795,
      "grad_norm": 0.004696964286267757,
      "learning_rate": 1.2810401485926562e-05,
      "loss": 0.0002,
      "step": 25160
    },
    {
      "epoch": 5.394342048864123,
      "grad_norm": 0.01222937647253275,
      "learning_rate": 1.2807543934847838e-05,
      "loss": 0.0005,
      "step": 25170
    },
    {
      "epoch": 5.396485212173167,
      "grad_norm": 0.0003041476593352854,
      "learning_rate": 1.2804686383769112e-05,
      "loss": 0.1691,
      "step": 25180
    },
    {
      "epoch": 5.398628375482212,
      "grad_norm": 0.031208379194140434,
      "learning_rate": 1.2801828832690386e-05,
      "loss": 0.582,
      "step": 25190
    },
    {
      "epoch": 5.400771538791256,
      "grad_norm": 0.03025924041867256,
      "learning_rate": 1.2798971281611661e-05,
      "loss": 0.0003,
      "step": 25200
    },
    {
      "epoch": 5.4029147021003,
      "grad_norm": 0.003992490936070681,
      "learning_rate": 1.2796113730532935e-05,
      "loss": 0.0011,
      "step": 25210
    },
    {
      "epoch": 5.405057865409344,
      "grad_norm": 0.023354222998023033,
      "learning_rate": 1.2793256179454209e-05,
      "loss": 0.0612,
      "step": 25220
    },
    {
      "epoch": 5.407201028718388,
      "grad_norm": 0.18356953561306,
      "learning_rate": 1.2790398628375483e-05,
      "loss": 0.0009,
      "step": 25230
    },
    {
      "epoch": 5.409344192027432,
      "grad_norm": 0.017275068908929825,
      "learning_rate": 1.2787541077296757e-05,
      "loss": 0.0001,
      "step": 25240
    },
    {
      "epoch": 5.411487355336477,
      "grad_norm": 0.007429472170770168,
      "learning_rate": 1.2784683526218031e-05,
      "loss": 0.0003,
      "step": 25250
    },
    {
      "epoch": 5.413630518645521,
      "grad_norm": 25.793630599975586,
      "learning_rate": 1.2781825975139306e-05,
      "loss": 0.5487,
      "step": 25260
    },
    {
      "epoch": 5.4157736819545645,
      "grad_norm": 0.05205104127526283,
      "learning_rate": 1.277896842406058e-05,
      "loss": 0.0008,
      "step": 25270
    },
    {
      "epoch": 5.417916845263609,
      "grad_norm": 29.480785369873047,
      "learning_rate": 1.2776110872981854e-05,
      "loss": 0.4531,
      "step": 25280
    },
    {
      "epoch": 5.420060008572653,
      "grad_norm": 0.03965051472187042,
      "learning_rate": 1.277325332190313e-05,
      "loss": 0.0013,
      "step": 25290
    },
    {
      "epoch": 5.422203171881697,
      "grad_norm": 0.020057085901498795,
      "learning_rate": 1.2770395770824404e-05,
      "loss": 0.0008,
      "step": 25300
    },
    {
      "epoch": 5.424346335190742,
      "grad_norm": 0.01837376318871975,
      "learning_rate": 1.276753821974568e-05,
      "loss": 0.0005,
      "step": 25310
    },
    {
      "epoch": 5.426489498499786,
      "grad_norm": 0.011397423222661018,
      "learning_rate": 1.2764680668666953e-05,
      "loss": 0.0006,
      "step": 25320
    },
    {
      "epoch": 5.428632661808829,
      "grad_norm": 0.07555337995290756,
      "learning_rate": 1.2761823117588227e-05,
      "loss": 0.0275,
      "step": 25330
    },
    {
      "epoch": 5.430775825117874,
      "grad_norm": 0.04975050315260887,
      "learning_rate": 1.2758965566509503e-05,
      "loss": 0.0292,
      "step": 25340
    },
    {
      "epoch": 5.432918988426918,
      "grad_norm": 0.09785306453704834,
      "learning_rate": 1.2756108015430777e-05,
      "loss": 0.0524,
      "step": 25350
    },
    {
      "epoch": 5.435062151735963,
      "grad_norm": 0.016497641801834106,
      "learning_rate": 1.2753250464352051e-05,
      "loss": 0.2578,
      "step": 25360
    },
    {
      "epoch": 5.437205315045007,
      "grad_norm": 35.01171112060547,
      "learning_rate": 1.2750392913273326e-05,
      "loss": 0.1406,
      "step": 25370
    },
    {
      "epoch": 5.43934847835405,
      "grad_norm": 0.005391067359596491,
      "learning_rate": 1.27475353621946e-05,
      "loss": 0.0002,
      "step": 25380
    },
    {
      "epoch": 5.441491641663095,
      "grad_norm": 100.9098129272461,
      "learning_rate": 1.2744677811115876e-05,
      "loss": 0.6593,
      "step": 25390
    },
    {
      "epoch": 5.443634804972139,
      "grad_norm": 0.03295902535319328,
      "learning_rate": 1.274182026003715e-05,
      "loss": 0.001,
      "step": 25400
    },
    {
      "epoch": 5.445777968281183,
      "grad_norm": 0.007914967834949493,
      "learning_rate": 1.2738962708958424e-05,
      "loss": 0.0002,
      "step": 25410
    },
    {
      "epoch": 5.447921131590228,
      "grad_norm": 0.0022523480001837015,
      "learning_rate": 1.27361051578797e-05,
      "loss": 0.1697,
      "step": 25420
    },
    {
      "epoch": 5.4500642948992715,
      "grad_norm": 0.010730561800301075,
      "learning_rate": 1.2733247606800973e-05,
      "loss": 0.0002,
      "step": 25430
    },
    {
      "epoch": 5.452207458208315,
      "grad_norm": 0.002752550644800067,
      "learning_rate": 1.2730390055722247e-05,
      "loss": 0.0012,
      "step": 25440
    },
    {
      "epoch": 5.45435062151736,
      "grad_norm": 0.003596665570512414,
      "learning_rate": 1.2727532504643521e-05,
      "loss": 0.0003,
      "step": 25450
    },
    {
      "epoch": 5.456493784826404,
      "grad_norm": 0.0012819507392123342,
      "learning_rate": 1.2724674953564795e-05,
      "loss": 0.0002,
      "step": 25460
    },
    {
      "epoch": 5.458636948135448,
      "grad_norm": 0.007287131622433662,
      "learning_rate": 1.2721817402486069e-05,
      "loss": 0.0002,
      "step": 25470
    },
    {
      "epoch": 5.4607801114444925,
      "grad_norm": 0.05438341945409775,
      "learning_rate": 1.2718959851407345e-05,
      "loss": 0.1196,
      "step": 25480
    },
    {
      "epoch": 5.462923274753536,
      "grad_norm": 0.000491046579554677,
      "learning_rate": 1.2716102300328619e-05,
      "loss": 0.0001,
      "step": 25490
    },
    {
      "epoch": 5.46506643806258,
      "grad_norm": 0.05953451991081238,
      "learning_rate": 1.2713244749249893e-05,
      "loss": 0.0022,
      "step": 25500
    },
    {
      "epoch": 5.467209601371625,
      "grad_norm": 0.0012187910033389926,
      "learning_rate": 1.2710387198171168e-05,
      "loss": 0.0001,
      "step": 25510
    },
    {
      "epoch": 5.469352764680669,
      "grad_norm": 0.0017336703604087234,
      "learning_rate": 1.2707529647092442e-05,
      "loss": 0.162,
      "step": 25520
    },
    {
      "epoch": 5.471495927989713,
      "grad_norm": 61.10894012451172,
      "learning_rate": 1.2704672096013718e-05,
      "loss": 0.1329,
      "step": 25530
    },
    {
      "epoch": 5.473639091298757,
      "grad_norm": 0.0008004643605090678,
      "learning_rate": 1.2701814544934992e-05,
      "loss": 0.0007,
      "step": 25540
    },
    {
      "epoch": 5.475782254607801,
      "grad_norm": 0.0015449979109689593,
      "learning_rate": 1.2698956993856266e-05,
      "loss": 0.0001,
      "step": 25550
    },
    {
      "epoch": 5.477925417916845,
      "grad_norm": 0.0017876637866720557,
      "learning_rate": 1.2696099442777541e-05,
      "loss": 0.3874,
      "step": 25560
    },
    {
      "epoch": 5.48006858122589,
      "grad_norm": 0.0029114969074726105,
      "learning_rate": 1.2693241891698815e-05,
      "loss": 0.0004,
      "step": 25570
    },
    {
      "epoch": 5.482211744534934,
      "grad_norm": 0.012583233416080475,
      "learning_rate": 1.2690384340620089e-05,
      "loss": 0.2951,
      "step": 25580
    },
    {
      "epoch": 5.4843549078439775,
      "grad_norm": 0.0023487145081162453,
      "learning_rate": 1.2687526789541365e-05,
      "loss": 0.2125,
      "step": 25590
    },
    {
      "epoch": 5.486498071153022,
      "grad_norm": 0.014050336554646492,
      "learning_rate": 1.2684669238462639e-05,
      "loss": 0.0002,
      "step": 25600
    },
    {
      "epoch": 5.488641234462066,
      "grad_norm": 0.0023961758706718683,
      "learning_rate": 1.2681811687383914e-05,
      "loss": 0.0004,
      "step": 25610
    },
    {
      "epoch": 5.49078439777111,
      "grad_norm": 0.011384465731680393,
      "learning_rate": 1.2678954136305188e-05,
      "loss": 0.1571,
      "step": 25620
    },
    {
      "epoch": 5.492927561080155,
      "grad_norm": 0.024171993136405945,
      "learning_rate": 1.2676096585226462e-05,
      "loss": 0.0003,
      "step": 25630
    },
    {
      "epoch": 5.4950707243891985,
      "grad_norm": 0.0024869979824870825,
      "learning_rate": 1.2673239034147738e-05,
      "loss": 0.0001,
      "step": 25640
    },
    {
      "epoch": 5.497213887698242,
      "grad_norm": 0.0009653614251874387,
      "learning_rate": 1.2670381483069012e-05,
      "loss": 0.0001,
      "step": 25650
    },
    {
      "epoch": 5.499357051007287,
      "grad_norm": 0.009546058252453804,
      "learning_rate": 1.2667523931990284e-05,
      "loss": 0.0001,
      "step": 25660
    },
    {
      "epoch": 5.501500214316331,
      "grad_norm": 0.015384609811007977,
      "learning_rate": 1.266466638091156e-05,
      "loss": 0.007,
      "step": 25670
    },
    {
      "epoch": 5.503643377625375,
      "grad_norm": 0.0011521700071170926,
      "learning_rate": 1.2661808829832833e-05,
      "loss": 0.0001,
      "step": 25680
    },
    {
      "epoch": 5.5057865409344195,
      "grad_norm": 24.977684020996094,
      "learning_rate": 1.2658951278754107e-05,
      "loss": 0.5141,
      "step": 25690
    },
    {
      "epoch": 5.507929704243463,
      "grad_norm": 0.0020491466857492924,
      "learning_rate": 1.2656093727675383e-05,
      "loss": 0.2699,
      "step": 25700
    },
    {
      "epoch": 5.510072867552507,
      "grad_norm": 1.3887712955474854,
      "learning_rate": 1.2653236176596657e-05,
      "loss": 0.0006,
      "step": 25710
    },
    {
      "epoch": 5.512216030861552,
      "grad_norm": 0.005792933516204357,
      "learning_rate": 1.2650378625517931e-05,
      "loss": 0.2047,
      "step": 25720
    },
    {
      "epoch": 5.514359194170596,
      "grad_norm": 0.0008272751001641154,
      "learning_rate": 1.2647521074439207e-05,
      "loss": 0.0004,
      "step": 25730
    },
    {
      "epoch": 5.51650235747964,
      "grad_norm": 0.022655479609966278,
      "learning_rate": 1.264466352336048e-05,
      "loss": 0.0687,
      "step": 25740
    },
    {
      "epoch": 5.518645520788684,
      "grad_norm": 42.9174919128418,
      "learning_rate": 1.2641805972281756e-05,
      "loss": 0.283,
      "step": 25750
    },
    {
      "epoch": 5.520788684097728,
      "grad_norm": 0.0031182507518678904,
      "learning_rate": 1.263894842120303e-05,
      "loss": 0.0001,
      "step": 25760
    },
    {
      "epoch": 5.522931847406772,
      "grad_norm": 0.003340617287904024,
      "learning_rate": 1.2636090870124304e-05,
      "loss": 0.0001,
      "step": 25770
    },
    {
      "epoch": 5.525075010715817,
      "grad_norm": 0.0026590777561068535,
      "learning_rate": 1.263323331904558e-05,
      "loss": 0.1331,
      "step": 25780
    },
    {
      "epoch": 5.527218174024861,
      "grad_norm": 0.0025711553171277046,
      "learning_rate": 1.2630375767966853e-05,
      "loss": 0.0003,
      "step": 25790
    },
    {
      "epoch": 5.529361337333905,
      "grad_norm": 0.004193794913589954,
      "learning_rate": 1.2627518216888129e-05,
      "loss": 0.1966,
      "step": 25800
    },
    {
      "epoch": 5.531504500642949,
      "grad_norm": 0.002798269269987941,
      "learning_rate": 1.2624660665809403e-05,
      "loss": 0.3261,
      "step": 25810
    },
    {
      "epoch": 5.533647663951993,
      "grad_norm": 0.0639951154589653,
      "learning_rate": 1.2621803114730677e-05,
      "loss": 0.0007,
      "step": 25820
    },
    {
      "epoch": 5.535790827261037,
      "grad_norm": 0.008414382115006447,
      "learning_rate": 1.2618945563651953e-05,
      "loss": 0.017,
      "step": 25830
    },
    {
      "epoch": 5.537933990570082,
      "grad_norm": 64.35260009765625,
      "learning_rate": 1.2616088012573227e-05,
      "loss": 0.2096,
      "step": 25840
    },
    {
      "epoch": 5.540077153879126,
      "grad_norm": 0.0028410223312675953,
      "learning_rate": 1.26132304614945e-05,
      "loss": 0.0002,
      "step": 25850
    },
    {
      "epoch": 5.542220317188169,
      "grad_norm": 0.017317187041044235,
      "learning_rate": 1.2610372910415776e-05,
      "loss": 0.0002,
      "step": 25860
    },
    {
      "epoch": 5.544363480497214,
      "grad_norm": 29.468732833862305,
      "learning_rate": 1.260751535933705e-05,
      "loss": 0.1835,
      "step": 25870
    },
    {
      "epoch": 5.546506643806258,
      "grad_norm": 0.0033205440267920494,
      "learning_rate": 1.2604657808258322e-05,
      "loss": 0.1788,
      "step": 25880
    },
    {
      "epoch": 5.548649807115302,
      "grad_norm": 0.007733987644314766,
      "learning_rate": 1.2601800257179598e-05,
      "loss": 0.2629,
      "step": 25890
    },
    {
      "epoch": 5.550792970424347,
      "grad_norm": 0.01154736615717411,
      "learning_rate": 1.2598942706100872e-05,
      "loss": 0.0009,
      "step": 25900
    },
    {
      "epoch": 5.5529361337333905,
      "grad_norm": 0.03644350916147232,
      "learning_rate": 1.2596085155022146e-05,
      "loss": 0.0002,
      "step": 25910
    },
    {
      "epoch": 5.555079297042434,
      "grad_norm": 0.0033491221256554127,
      "learning_rate": 1.2593227603943421e-05,
      "loss": 0.0003,
      "step": 25920
    },
    {
      "epoch": 5.557222460351479,
      "grad_norm": 19.794614791870117,
      "learning_rate": 1.2590370052864695e-05,
      "loss": 0.4807,
      "step": 25930
    },
    {
      "epoch": 5.559365623660523,
      "grad_norm": 62.9623908996582,
      "learning_rate": 1.2587512501785971e-05,
      "loss": 0.0658,
      "step": 25940
    },
    {
      "epoch": 5.561508786969567,
      "grad_norm": 0.015220865607261658,
      "learning_rate": 1.2584654950707245e-05,
      "loss": 0.0021,
      "step": 25950
    },
    {
      "epoch": 5.5636519502786115,
      "grad_norm": 0.008219476789236069,
      "learning_rate": 1.2581797399628519e-05,
      "loss": 0.1383,
      "step": 25960
    },
    {
      "epoch": 5.565795113587655,
      "grad_norm": 73.15348052978516,
      "learning_rate": 1.2578939848549794e-05,
      "loss": 0.114,
      "step": 25970
    },
    {
      "epoch": 5.567938276896699,
      "grad_norm": 0.0040534683503210545,
      "learning_rate": 1.2576082297471068e-05,
      "loss": 0.0058,
      "step": 25980
    },
    {
      "epoch": 5.570081440205744,
      "grad_norm": 0.0028270771726965904,
      "learning_rate": 1.2573224746392342e-05,
      "loss": 0.0003,
      "step": 25990
    },
    {
      "epoch": 5.572224603514788,
      "grad_norm": 0.01182718575000763,
      "learning_rate": 1.2570367195313618e-05,
      "loss": 0.0003,
      "step": 26000
    },
    {
      "epoch": 5.574367766823832,
      "grad_norm": 0.0020692150574177504,
      "learning_rate": 1.2567509644234892e-05,
      "loss": 0.3538,
      "step": 26010
    },
    {
      "epoch": 5.576510930132876,
      "grad_norm": 0.03169480711221695,
      "learning_rate": 1.2564652093156167e-05,
      "loss": 0.0008,
      "step": 26020
    },
    {
      "epoch": 5.57865409344192,
      "grad_norm": 0.005732012912631035,
      "learning_rate": 1.2561794542077441e-05,
      "loss": 0.0007,
      "step": 26030
    },
    {
      "epoch": 5.580797256750964,
      "grad_norm": 0.029654929414391518,
      "learning_rate": 1.2558936990998715e-05,
      "loss": 0.162,
      "step": 26040
    },
    {
      "epoch": 5.582940420060009,
      "grad_norm": 0.007084426935762167,
      "learning_rate": 1.2556079439919991e-05,
      "loss": 0.0002,
      "step": 26050
    },
    {
      "epoch": 5.585083583369053,
      "grad_norm": 0.0021328895818442106,
      "learning_rate": 1.2553221888841265e-05,
      "loss": 0.1224,
      "step": 26060
    },
    {
      "epoch": 5.5872267466780965,
      "grad_norm": 0.001761193503625691,
      "learning_rate": 1.2550364337762539e-05,
      "loss": 0.2035,
      "step": 26070
    },
    {
      "epoch": 5.589369909987141,
      "grad_norm": 0.0007470021373592317,
      "learning_rate": 1.2547506786683814e-05,
      "loss": 0.0001,
      "step": 26080
    },
    {
      "epoch": 5.591513073296185,
      "grad_norm": 0.0011619027936831117,
      "learning_rate": 1.2544649235605087e-05,
      "loss": 0.0002,
      "step": 26090
    },
    {
      "epoch": 5.593656236605229,
      "grad_norm": 0.004234871827065945,
      "learning_rate": 1.254179168452636e-05,
      "loss": 0.0004,
      "step": 26100
    },
    {
      "epoch": 5.595799399914274,
      "grad_norm": 0.014844012446701527,
      "learning_rate": 1.2538934133447636e-05,
      "loss": 0.0001,
      "step": 26110
    },
    {
      "epoch": 5.5979425632233175,
      "grad_norm": 0.0012184481602162123,
      "learning_rate": 1.253607658236891e-05,
      "loss": 0.2844,
      "step": 26120
    },
    {
      "epoch": 5.600085726532361,
      "grad_norm": 0.0339462049305439,
      "learning_rate": 1.2533219031290184e-05,
      "loss": 0.0002,
      "step": 26130
    },
    {
      "epoch": 5.602228889841406,
      "grad_norm": 0.07038024812936783,
      "learning_rate": 1.253036148021146e-05,
      "loss": 0.0002,
      "step": 26140
    },
    {
      "epoch": 5.60437205315045,
      "grad_norm": 0.0007987425778992474,
      "learning_rate": 1.2527503929132734e-05,
      "loss": 0.1211,
      "step": 26150
    },
    {
      "epoch": 5.606515216459494,
      "grad_norm": 100.58776092529297,
      "learning_rate": 1.252464637805401e-05,
      "loss": 0.3169,
      "step": 26160
    },
    {
      "epoch": 5.6086583797685385,
      "grad_norm": 0.001392642967402935,
      "learning_rate": 1.2521788826975283e-05,
      "loss": 0.0003,
      "step": 26170
    },
    {
      "epoch": 5.610801543077582,
      "grad_norm": 0.007738796062767506,
      "learning_rate": 1.2518931275896557e-05,
      "loss": 0.0004,
      "step": 26180
    },
    {
      "epoch": 5.612944706386626,
      "grad_norm": 0.0006080142920836806,
      "learning_rate": 1.2516073724817833e-05,
      "loss": 0.0022,
      "step": 26190
    },
    {
      "epoch": 5.615087869695671,
      "grad_norm": 0.0008277264423668385,
      "learning_rate": 1.2513216173739107e-05,
      "loss": 0.0746,
      "step": 26200
    },
    {
      "epoch": 5.617231033004715,
      "grad_norm": 26.793411254882812,
      "learning_rate": 1.251035862266038e-05,
      "loss": 0.4651,
      "step": 26210
    },
    {
      "epoch": 5.619374196313759,
      "grad_norm": 0.0035172500647604465,
      "learning_rate": 1.2507501071581656e-05,
      "loss": 0.5603,
      "step": 26220
    },
    {
      "epoch": 5.621517359622803,
      "grad_norm": 0.028243666514754295,
      "learning_rate": 1.250464352050293e-05,
      "loss": 0.0322,
      "step": 26230
    },
    {
      "epoch": 5.623660522931847,
      "grad_norm": 0.017648549750447273,
      "learning_rate": 1.2501785969424206e-05,
      "loss": 0.1875,
      "step": 26240
    },
    {
      "epoch": 5.625803686240891,
      "grad_norm": 0.05711401626467705,
      "learning_rate": 1.249892841834548e-05,
      "loss": 0.0048,
      "step": 26250
    },
    {
      "epoch": 5.627946849549936,
      "grad_norm": 0.18802809715270996,
      "learning_rate": 1.2496070867266754e-05,
      "loss": 0.0278,
      "step": 26260
    },
    {
      "epoch": 5.63009001285898,
      "grad_norm": 2.1134605407714844,
      "learning_rate": 1.2493213316188029e-05,
      "loss": 0.0027,
      "step": 26270
    },
    {
      "epoch": 5.6322331761680235,
      "grad_norm": 0.010104158893227577,
      "learning_rate": 1.2490355765109303e-05,
      "loss": 0.0001,
      "step": 26280
    },
    {
      "epoch": 5.634376339477068,
      "grad_norm": 0.0006361356936395168,
      "learning_rate": 1.2487498214030577e-05,
      "loss": 0.0063,
      "step": 26290
    },
    {
      "epoch": 5.636519502786112,
      "grad_norm": 0.0005381707451306283,
      "learning_rate": 1.2484640662951851e-05,
      "loss": 0.1635,
      "step": 26300
    },
    {
      "epoch": 5.638662666095156,
      "grad_norm": 0.03398125246167183,
      "learning_rate": 1.2481783111873125e-05,
      "loss": 0.2789,
      "step": 26310
    },
    {
      "epoch": 5.640805829404201,
      "grad_norm": 0.009337231516838074,
      "learning_rate": 1.2478925560794399e-05,
      "loss": 0.0013,
      "step": 26320
    },
    {
      "epoch": 5.642948992713245,
      "grad_norm": 0.0016317786648869514,
      "learning_rate": 1.2476068009715674e-05,
      "loss": 0.4258,
      "step": 26330
    },
    {
      "epoch": 5.645092156022288,
      "grad_norm": 0.008820631541311741,
      "learning_rate": 1.2473210458636948e-05,
      "loss": 0.0005,
      "step": 26340
    },
    {
      "epoch": 5.647235319331333,
      "grad_norm": 0.018114911392331123,
      "learning_rate": 1.2470352907558222e-05,
      "loss": 0.0017,
      "step": 26350
    },
    {
      "epoch": 5.649378482640377,
      "grad_norm": 0.004115236923098564,
      "learning_rate": 1.2467495356479498e-05,
      "loss": 0.0007,
      "step": 26360
    },
    {
      "epoch": 5.651521645949421,
      "grad_norm": 0.0012057310668751597,
      "learning_rate": 1.2464637805400772e-05,
      "loss": 0.0003,
      "step": 26370
    },
    {
      "epoch": 5.653664809258466,
      "grad_norm": 108.3783187866211,
      "learning_rate": 1.2461780254322047e-05,
      "loss": 0.3424,
      "step": 26380
    },
    {
      "epoch": 5.6558079725675094,
      "grad_norm": 0.08963921666145325,
      "learning_rate": 1.2458922703243321e-05,
      "loss": 0.0006,
      "step": 26390
    },
    {
      "epoch": 5.657951135876553,
      "grad_norm": 0.02902146801352501,
      "learning_rate": 1.2456065152164595e-05,
      "loss": 0.0003,
      "step": 26400
    },
    {
      "epoch": 5.660094299185598,
      "grad_norm": 0.03511708974838257,
      "learning_rate": 1.2453207601085871e-05,
      "loss": 0.3478,
      "step": 26410
    },
    {
      "epoch": 5.662237462494642,
      "grad_norm": 0.0011404886608943343,
      "learning_rate": 1.2450350050007145e-05,
      "loss": 0.001,
      "step": 26420
    },
    {
      "epoch": 5.664380625803687,
      "grad_norm": 0.000894507800694555,
      "learning_rate": 1.2447492498928419e-05,
      "loss": 0.0003,
      "step": 26430
    },
    {
      "epoch": 5.6665237891127305,
      "grad_norm": 0.0014510818291455507,
      "learning_rate": 1.2444634947849694e-05,
      "loss": 0.1082,
      "step": 26440
    },
    {
      "epoch": 5.668666952421774,
      "grad_norm": 0.002056027762591839,
      "learning_rate": 1.2441777396770968e-05,
      "loss": 0.0032,
      "step": 26450
    },
    {
      "epoch": 5.670810115730819,
      "grad_norm": 0.002714745933189988,
      "learning_rate": 1.2438919845692244e-05,
      "loss": 0.1605,
      "step": 26460
    },
    {
      "epoch": 5.672953279039863,
      "grad_norm": 0.0032765213400125504,
      "learning_rate": 1.2436062294613518e-05,
      "loss": 0.0236,
      "step": 26470
    },
    {
      "epoch": 5.675096442348907,
      "grad_norm": 0.004237297456711531,
      "learning_rate": 1.2433204743534792e-05,
      "loss": 0.0005,
      "step": 26480
    },
    {
      "epoch": 5.6772396056579515,
      "grad_norm": 0.005020046606659889,
      "learning_rate": 1.2430347192456067e-05,
      "loss": 0.0001,
      "step": 26490
    },
    {
      "epoch": 5.679382768966995,
      "grad_norm": 0.1562536060810089,
      "learning_rate": 1.2427489641377341e-05,
      "loss": 0.2614,
      "step": 26500
    },
    {
      "epoch": 5.681525932276039,
      "grad_norm": 34.85904312133789,
      "learning_rate": 1.2424632090298617e-05,
      "loss": 0.1175,
      "step": 26510
    },
    {
      "epoch": 5.683669095585084,
      "grad_norm": 0.00308254174888134,
      "learning_rate": 1.242177453921989e-05,
      "loss": 0.0001,
      "step": 26520
    },
    {
      "epoch": 5.685812258894128,
      "grad_norm": 0.00185609410982579,
      "learning_rate": 1.2418916988141163e-05,
      "loss": 0.588,
      "step": 26530
    },
    {
      "epoch": 5.687955422203172,
      "grad_norm": 0.0026925031561404467,
      "learning_rate": 1.2416059437062437e-05,
      "loss": 0.1932,
      "step": 26540
    },
    {
      "epoch": 5.690098585512216,
      "grad_norm": 0.05892761051654816,
      "learning_rate": 1.2413201885983713e-05,
      "loss": 0.0006,
      "step": 26550
    },
    {
      "epoch": 5.69224174882126,
      "grad_norm": 0.0021426957100629807,
      "learning_rate": 1.2410344334904987e-05,
      "loss": 0.0002,
      "step": 26560
    },
    {
      "epoch": 5.694384912130304,
      "grad_norm": 0.001746507827192545,
      "learning_rate": 1.240748678382626e-05,
      "loss": 0.0636,
      "step": 26570
    },
    {
      "epoch": 5.696528075439349,
      "grad_norm": 0.41689398884773254,
      "learning_rate": 1.2404629232747536e-05,
      "loss": 0.2916,
      "step": 26580
    },
    {
      "epoch": 5.698671238748393,
      "grad_norm": 12.145173072814941,
      "learning_rate": 1.240177168166881e-05,
      "loss": 0.0078,
      "step": 26590
    },
    {
      "epoch": 5.7008144020574365,
      "grad_norm": 0.004792422521859407,
      "learning_rate": 1.2398914130590086e-05,
      "loss": 0.0005,
      "step": 26600
    },
    {
      "epoch": 5.702957565366481,
      "grad_norm": 78.1493911743164,
      "learning_rate": 1.239605657951136e-05,
      "loss": 0.2695,
      "step": 26610
    },
    {
      "epoch": 5.705100728675525,
      "grad_norm": 19.233640670776367,
      "learning_rate": 1.2393199028432634e-05,
      "loss": 0.2482,
      "step": 26620
    },
    {
      "epoch": 5.707243891984569,
      "grad_norm": 0.011068465188145638,
      "learning_rate": 1.239034147735391e-05,
      "loss": 0.1487,
      "step": 26630
    },
    {
      "epoch": 5.709387055293614,
      "grad_norm": 113.24918365478516,
      "learning_rate": 1.2387483926275183e-05,
      "loss": 0.0196,
      "step": 26640
    },
    {
      "epoch": 5.7115302186026575,
      "grad_norm": 0.0637778490781784,
      "learning_rate": 1.2384626375196459e-05,
      "loss": 0.187,
      "step": 26650
    },
    {
      "epoch": 5.713673381911701,
      "grad_norm": 0.008050077594816685,
      "learning_rate": 1.2381768824117733e-05,
      "loss": 0.0005,
      "step": 26660
    },
    {
      "epoch": 5.715816545220746,
      "grad_norm": 0.022446664050221443,
      "learning_rate": 1.2378911273039007e-05,
      "loss": 0.2507,
      "step": 26670
    },
    {
      "epoch": 5.71795970852979,
      "grad_norm": 0.005072639323771,
      "learning_rate": 1.2376053721960282e-05,
      "loss": 0.0003,
      "step": 26680
    },
    {
      "epoch": 5.720102871838834,
      "grad_norm": 0.03501404821872711,
      "learning_rate": 1.2373196170881556e-05,
      "loss": 0.0003,
      "step": 26690
    },
    {
      "epoch": 5.7222460351478786,
      "grad_norm": 0.013881982304155827,
      "learning_rate": 1.237033861980283e-05,
      "loss": 0.0005,
      "step": 26700
    },
    {
      "epoch": 5.724389198456922,
      "grad_norm": 0.050332605838775635,
      "learning_rate": 1.2367481068724106e-05,
      "loss": 0.3984,
      "step": 26710
    },
    {
      "epoch": 5.726532361765966,
      "grad_norm": 0.0028344213496893644,
      "learning_rate": 1.236462351764538e-05,
      "loss": 0.0037,
      "step": 26720
    },
    {
      "epoch": 5.728675525075011,
      "grad_norm": 0.004035251680761576,
      "learning_rate": 1.2361765966566652e-05,
      "loss": 0.0008,
      "step": 26730
    },
    {
      "epoch": 5.730818688384055,
      "grad_norm": 0.020583923906087875,
      "learning_rate": 1.2358908415487927e-05,
      "loss": 0.0136,
      "step": 26740
    },
    {
      "epoch": 5.732961851693099,
      "grad_norm": 77.05896759033203,
      "learning_rate": 1.2356050864409201e-05,
      "loss": 0.171,
      "step": 26750
    },
    {
      "epoch": 5.735105015002143,
      "grad_norm": 0.08373697102069855,
      "learning_rate": 1.2353193313330475e-05,
      "loss": 0.2347,
      "step": 26760
    },
    {
      "epoch": 5.737248178311187,
      "grad_norm": 0.007698272820562124,
      "learning_rate": 1.2350335762251751e-05,
      "loss": 0.0003,
      "step": 26770
    },
    {
      "epoch": 5.739391341620231,
      "grad_norm": 0.017194440588355064,
      "learning_rate": 1.2347478211173025e-05,
      "loss": 0.3506,
      "step": 26780
    },
    {
      "epoch": 5.741534504929276,
      "grad_norm": 0.026080913841724396,
      "learning_rate": 1.23446206600943e-05,
      "loss": 0.0015,
      "step": 26790
    },
    {
      "epoch": 5.74367766823832,
      "grad_norm": 0.003505327273160219,
      "learning_rate": 1.2341763109015574e-05,
      "loss": 0.0006,
      "step": 26800
    },
    {
      "epoch": 5.745820831547364,
      "grad_norm": 0.004969695582985878,
      "learning_rate": 1.2338905557936848e-05,
      "loss": 0.0004,
      "step": 26810
    },
    {
      "epoch": 5.747963994856408,
      "grad_norm": 0.0029232001397758722,
      "learning_rate": 1.2336048006858124e-05,
      "loss": 0.2744,
      "step": 26820
    },
    {
      "epoch": 5.750107158165452,
      "grad_norm": 0.046163883060216904,
      "learning_rate": 1.2333190455779398e-05,
      "loss": 0.2291,
      "step": 26830
    },
    {
      "epoch": 5.752250321474496,
      "grad_norm": 0.0012763512786477804,
      "learning_rate": 1.2330332904700672e-05,
      "loss": 0.1679,
      "step": 26840
    },
    {
      "epoch": 5.754393484783541,
      "grad_norm": 0.005058641079813242,
      "learning_rate": 1.2327475353621947e-05,
      "loss": 0.0003,
      "step": 26850
    },
    {
      "epoch": 5.756536648092585,
      "grad_norm": 0.0529547855257988,
      "learning_rate": 1.2324617802543221e-05,
      "loss": 0.2222,
      "step": 26860
    },
    {
      "epoch": 5.758679811401628,
      "grad_norm": 0.008267616853117943,
      "learning_rate": 1.2321760251464497e-05,
      "loss": 0.0004,
      "step": 26870
    },
    {
      "epoch": 5.760822974710673,
      "grad_norm": 0.002507004654034972,
      "learning_rate": 1.2318902700385771e-05,
      "loss": 0.0005,
      "step": 26880
    },
    {
      "epoch": 5.762966138019717,
      "grad_norm": 0.0827987864613533,
      "learning_rate": 1.2316045149307045e-05,
      "loss": 0.2978,
      "step": 26890
    },
    {
      "epoch": 5.765109301328761,
      "grad_norm": 0.1743374615907669,
      "learning_rate": 1.231318759822832e-05,
      "loss": 0.0007,
      "step": 26900
    },
    {
      "epoch": 5.767252464637806,
      "grad_norm": 0.0017428089631721377,
      "learning_rate": 1.2310330047149594e-05,
      "loss": 0.0014,
      "step": 26910
    },
    {
      "epoch": 5.7693956279468495,
      "grad_norm": 0.004163853358477354,
      "learning_rate": 1.2307472496070868e-05,
      "loss": 0.3045,
      "step": 26920
    },
    {
      "epoch": 5.771538791255894,
      "grad_norm": 0.001496295677497983,
      "learning_rate": 1.2304614944992144e-05,
      "loss": 0.1588,
      "step": 26930
    },
    {
      "epoch": 5.773681954564938,
      "grad_norm": 0.012828628532588482,
      "learning_rate": 1.2301757393913418e-05,
      "loss": 0.0004,
      "step": 26940
    },
    {
      "epoch": 5.775825117873982,
      "grad_norm": 0.016934512183070183,
      "learning_rate": 1.229889984283469e-05,
      "loss": 0.0042,
      "step": 26950
    },
    {
      "epoch": 5.777968281183027,
      "grad_norm": 0.0009722996619530022,
      "learning_rate": 1.2296042291755966e-05,
      "loss": 0.0001,
      "step": 26960
    },
    {
      "epoch": 5.7801114444920705,
      "grad_norm": 0.15786851942539215,
      "learning_rate": 1.229318474067724e-05,
      "loss": 0.0842,
      "step": 26970
    },
    {
      "epoch": 5.782254607801114,
      "grad_norm": 0.001905120094306767,
      "learning_rate": 1.2290327189598514e-05,
      "loss": 0.0002,
      "step": 26980
    },
    {
      "epoch": 5.784397771110159,
      "grad_norm": 0.0004988279542885721,
      "learning_rate": 1.228746963851979e-05,
      "loss": 0.0831,
      "step": 26990
    },
    {
      "epoch": 5.786540934419203,
      "grad_norm": 0.0009416328393854201,
      "learning_rate": 1.2284612087441063e-05,
      "loss": 0.315,
      "step": 27000
    },
    {
      "epoch": 5.788684097728247,
      "grad_norm": 18.238605499267578,
      "learning_rate": 1.2281754536362339e-05,
      "loss": 0.3254,
      "step": 27010
    },
    {
      "epoch": 5.7908272610372915,
      "grad_norm": 0.004933598916977644,
      "learning_rate": 1.2278896985283613e-05,
      "loss": 0.0137,
      "step": 27020
    },
    {
      "epoch": 5.792970424346335,
      "grad_norm": 0.0074151186272501945,
      "learning_rate": 1.2276039434204887e-05,
      "loss": 0.02,
      "step": 27030
    },
    {
      "epoch": 5.795113587655379,
      "grad_norm": 0.02424040623009205,
      "learning_rate": 1.2273181883126162e-05,
      "loss": 0.0003,
      "step": 27040
    },
    {
      "epoch": 5.797256750964424,
      "grad_norm": 0.00977583508938551,
      "learning_rate": 1.2270324332047436e-05,
      "loss": 0.2721,
      "step": 27050
    },
    {
      "epoch": 5.799399914273468,
      "grad_norm": 46.40251541137695,
      "learning_rate": 1.226746678096871e-05,
      "loss": 0.0889,
      "step": 27060
    },
    {
      "epoch": 5.801543077582512,
      "grad_norm": 0.07230480760335922,
      "learning_rate": 1.2264609229889986e-05,
      "loss": 0.2842,
      "step": 27070
    },
    {
      "epoch": 5.803686240891556,
      "grad_norm": 0.008232763968408108,
      "learning_rate": 1.226175167881126e-05,
      "loss": 0.001,
      "step": 27080
    },
    {
      "epoch": 5.8058294042006,
      "grad_norm": 0.02642030268907547,
      "learning_rate": 1.2258894127732535e-05,
      "loss": 0.0005,
      "step": 27090
    },
    {
      "epoch": 5.807972567509644,
      "grad_norm": 0.005937953479588032,
      "learning_rate": 1.225603657665381e-05,
      "loss": 0.5407,
      "step": 27100
    },
    {
      "epoch": 5.810115730818689,
      "grad_norm": 0.04018767178058624,
      "learning_rate": 1.2253179025575083e-05,
      "loss": 0.0022,
      "step": 27110
    },
    {
      "epoch": 5.812258894127733,
      "grad_norm": 0.03153042122721672,
      "learning_rate": 1.2250321474496359e-05,
      "loss": 0.0004,
      "step": 27120
    },
    {
      "epoch": 5.8144020574367765,
      "grad_norm": 0.00920579582452774,
      "learning_rate": 1.2247463923417633e-05,
      "loss": 0.1912,
      "step": 27130
    },
    {
      "epoch": 5.816545220745821,
      "grad_norm": 0.17225168645381927,
      "learning_rate": 1.2244606372338907e-05,
      "loss": 0.2056,
      "step": 27140
    },
    {
      "epoch": 5.818688384054865,
      "grad_norm": 0.0063834888860583305,
      "learning_rate": 1.2241748821260182e-05,
      "loss": 0.0251,
      "step": 27150
    },
    {
      "epoch": 5.820831547363909,
      "grad_norm": 0.00973378773778677,
      "learning_rate": 1.2238891270181454e-05,
      "loss": 0.2947,
      "step": 27160
    },
    {
      "epoch": 5.822974710672954,
      "grad_norm": 30.248950958251953,
      "learning_rate": 1.2236033719102728e-05,
      "loss": 0.2847,
      "step": 27170
    },
    {
      "epoch": 5.8251178739819975,
      "grad_norm": 0.007968492805957794,
      "learning_rate": 1.2233176168024004e-05,
      "loss": 0.0005,
      "step": 27180
    },
    {
      "epoch": 5.827261037291041,
      "grad_norm": 0.009337132796645164,
      "learning_rate": 1.2230318616945278e-05,
      "loss": 0.0005,
      "step": 27190
    },
    {
      "epoch": 5.829404200600086,
      "grad_norm": 0.006150239147245884,
      "learning_rate": 1.2227461065866552e-05,
      "loss": 0.0004,
      "step": 27200
    },
    {
      "epoch": 5.83154736390913,
      "grad_norm": 0.005406598094850779,
      "learning_rate": 1.2224603514787828e-05,
      "loss": 0.0003,
      "step": 27210
    },
    {
      "epoch": 5.833690527218174,
      "grad_norm": 0.005255424417555332,
      "learning_rate": 1.2221745963709101e-05,
      "loss": 0.0001,
      "step": 27220
    },
    {
      "epoch": 5.835833690527219,
      "grad_norm": 0.004822966642677784,
      "learning_rate": 1.2218888412630377e-05,
      "loss": 0.0946,
      "step": 27230
    },
    {
      "epoch": 5.837976853836262,
      "grad_norm": 0.004102632403373718,
      "learning_rate": 1.2216030861551651e-05,
      "loss": 0.2808,
      "step": 27240
    },
    {
      "epoch": 5.840120017145306,
      "grad_norm": 0.0061089652590453625,
      "learning_rate": 1.2213173310472925e-05,
      "loss": 0.1829,
      "step": 27250
    },
    {
      "epoch": 5.842263180454351,
      "grad_norm": 0.003991208970546722,
      "learning_rate": 1.22103157593942e-05,
      "loss": 0.0006,
      "step": 27260
    },
    {
      "epoch": 5.844406343763395,
      "grad_norm": 0.0021410665940493345,
      "learning_rate": 1.2207458208315474e-05,
      "loss": 0.2552,
      "step": 27270
    },
    {
      "epoch": 5.846549507072439,
      "grad_norm": 0.0035232093650847673,
      "learning_rate": 1.2204600657236748e-05,
      "loss": 0.0533,
      "step": 27280
    },
    {
      "epoch": 5.848692670381483,
      "grad_norm": 0.0021312313620001078,
      "learning_rate": 1.2201743106158024e-05,
      "loss": 0.0003,
      "step": 27290
    },
    {
      "epoch": 5.850835833690527,
      "grad_norm": 0.03130823373794556,
      "learning_rate": 1.2198885555079298e-05,
      "loss": 0.2882,
      "step": 27300
    },
    {
      "epoch": 5.852978996999571,
      "grad_norm": 0.018550913780927658,
      "learning_rate": 1.2196028004000574e-05,
      "loss": 0.0003,
      "step": 27310
    },
    {
      "epoch": 5.855122160308616,
      "grad_norm": 0.02135378308594227,
      "learning_rate": 1.2193170452921848e-05,
      "loss": 0.0011,
      "step": 27320
    },
    {
      "epoch": 5.85726532361766,
      "grad_norm": 46.48017501831055,
      "learning_rate": 1.2190312901843121e-05,
      "loss": 0.1774,
      "step": 27330
    },
    {
      "epoch": 5.859408486926704,
      "grad_norm": 0.003643566044047475,
      "learning_rate": 1.2187455350764397e-05,
      "loss": 0.3087,
      "step": 27340
    },
    {
      "epoch": 5.861551650235748,
      "grad_norm": 0.07678841799497604,
      "learning_rate": 1.2184597799685671e-05,
      "loss": 0.1408,
      "step": 27350
    },
    {
      "epoch": 5.863694813544792,
      "grad_norm": 0.0029474394395947456,
      "learning_rate": 1.2181740248606947e-05,
      "loss": 0.0025,
      "step": 27360
    },
    {
      "epoch": 5.865837976853836,
      "grad_norm": 0.06288862973451614,
      "learning_rate": 1.217888269752822e-05,
      "loss": 0.003,
      "step": 27370
    },
    {
      "epoch": 5.867981140162881,
      "grad_norm": 0.011080656200647354,
      "learning_rate": 1.2176025146449493e-05,
      "loss": 0.1559,
      "step": 27380
    },
    {
      "epoch": 5.870124303471925,
      "grad_norm": 0.013526943512260914,
      "learning_rate": 1.2173167595370767e-05,
      "loss": 0.2706,
      "step": 27390
    },
    {
      "epoch": 5.8722674667809684,
      "grad_norm": 0.010418808087706566,
      "learning_rate": 1.2170310044292042e-05,
      "loss": 0.2089,
      "step": 27400
    },
    {
      "epoch": 5.874410630090013,
      "grad_norm": 0.06231603026390076,
      "learning_rate": 1.2167452493213316e-05,
      "loss": 0.1461,
      "step": 27410
    },
    {
      "epoch": 5.876553793399057,
      "grad_norm": 0.004293940961360931,
      "learning_rate": 1.216459494213459e-05,
      "loss": 0.0018,
      "step": 27420
    },
    {
      "epoch": 5.878696956708101,
      "grad_norm": 0.005634661298245192,
      "learning_rate": 1.2161737391055866e-05,
      "loss": 0.0052,
      "step": 27430
    },
    {
      "epoch": 5.880840120017146,
      "grad_norm": 0.009546314366161823,
      "learning_rate": 1.215887983997714e-05,
      "loss": 0.1724,
      "step": 27440
    },
    {
      "epoch": 5.8829832833261895,
      "grad_norm": 0.026747792959213257,
      "learning_rate": 1.2156022288898415e-05,
      "loss": 0.0002,
      "step": 27450
    },
    {
      "epoch": 5.885126446635233,
      "grad_norm": 0.010287731885910034,
      "learning_rate": 1.215316473781969e-05,
      "loss": 0.0002,
      "step": 27460
    },
    {
      "epoch": 5.887269609944278,
      "grad_norm": 0.0020999321714043617,
      "learning_rate": 1.2150307186740963e-05,
      "loss": 0.0897,
      "step": 27470
    },
    {
      "epoch": 5.889412773253322,
      "grad_norm": 0.03810015693306923,
      "learning_rate": 1.2147449635662239e-05,
      "loss": 0.2722,
      "step": 27480
    },
    {
      "epoch": 5.891555936562366,
      "grad_norm": 0.003434262005612254,
      "learning_rate": 1.2144592084583513e-05,
      "loss": 0.0018,
      "step": 27490
    },
    {
      "epoch": 5.8936990998714105,
      "grad_norm": 0.003265582025051117,
      "learning_rate": 1.2141734533504788e-05,
      "loss": 0.0002,
      "step": 27500
    },
    {
      "epoch": 5.895842263180454,
      "grad_norm": 0.024615038186311722,
      "learning_rate": 1.2138876982426062e-05,
      "loss": 0.0004,
      "step": 27510
    },
    {
      "epoch": 5.897985426489498,
      "grad_norm": 0.012329744175076485,
      "learning_rate": 1.2136019431347336e-05,
      "loss": 0.0003,
      "step": 27520
    },
    {
      "epoch": 5.900128589798543,
      "grad_norm": 0.003260483732447028,
      "learning_rate": 1.2133161880268612e-05,
      "loss": 0.4653,
      "step": 27530
    },
    {
      "epoch": 5.902271753107587,
      "grad_norm": 0.023269815370440483,
      "learning_rate": 1.2130304329189886e-05,
      "loss": 0.0006,
      "step": 27540
    },
    {
      "epoch": 5.904414916416631,
      "grad_norm": 0.05490932986140251,
      "learning_rate": 1.212744677811116e-05,
      "loss": 0.1637,
      "step": 27550
    },
    {
      "epoch": 5.906558079725675,
      "grad_norm": 2.6870675086975098,
      "learning_rate": 1.2124589227032435e-05,
      "loss": 0.001,
      "step": 27560
    },
    {
      "epoch": 5.908701243034719,
      "grad_norm": 0.013014904223382473,
      "learning_rate": 1.212173167595371e-05,
      "loss": 0.0003,
      "step": 27570
    },
    {
      "epoch": 5.910844406343763,
      "grad_norm": 0.007732721045613289,
      "learning_rate": 1.2118874124874985e-05,
      "loss": 0.1943,
      "step": 27580
    },
    {
      "epoch": 5.912987569652808,
      "grad_norm": 0.007493534125387669,
      "learning_rate": 1.2116016573796257e-05,
      "loss": 0.0001,
      "step": 27590
    },
    {
      "epoch": 5.915130732961852,
      "grad_norm": 0.00800089631229639,
      "learning_rate": 1.2113159022717531e-05,
      "loss": 0.3021,
      "step": 27600
    },
    {
      "epoch": 5.9172738962708955,
      "grad_norm": 0.005314083304256201,
      "learning_rate": 1.2110301471638805e-05,
      "loss": 0.0013,
      "step": 27610
    },
    {
      "epoch": 5.91941705957994,
      "grad_norm": 0.022743413224816322,
      "learning_rate": 1.210744392056008e-05,
      "loss": 0.0423,
      "step": 27620
    },
    {
      "epoch": 5.921560222888984,
      "grad_norm": 0.006077451631426811,
      "learning_rate": 1.2104586369481355e-05,
      "loss": 0.0004,
      "step": 27630
    },
    {
      "epoch": 5.923703386198028,
      "grad_norm": 0.006964072585105896,
      "learning_rate": 1.210172881840263e-05,
      "loss": 0.2617,
      "step": 27640
    },
    {
      "epoch": 5.925846549507073,
      "grad_norm": 0.026590770110487938,
      "learning_rate": 1.2098871267323904e-05,
      "loss": 0.0836,
      "step": 27650
    },
    {
      "epoch": 5.9279897128161165,
      "grad_norm": 0.009464823640882969,
      "learning_rate": 1.2096013716245178e-05,
      "loss": 0.0004,
      "step": 27660
    },
    {
      "epoch": 5.93013287612516,
      "grad_norm": 0.017535746097564697,
      "learning_rate": 1.2093156165166454e-05,
      "loss": 0.0004,
      "step": 27670
    },
    {
      "epoch": 5.932276039434205,
      "grad_norm": 0.01720595173537731,
      "learning_rate": 1.2090298614087728e-05,
      "loss": 0.0004,
      "step": 27680
    },
    {
      "epoch": 5.934419202743249,
      "grad_norm": 0.00461126072332263,
      "learning_rate": 1.2087441063009001e-05,
      "loss": 0.0009,
      "step": 27690
    },
    {
      "epoch": 5.936562366052293,
      "grad_norm": 0.03879998251795769,
      "learning_rate": 1.2084583511930277e-05,
      "loss": 0.0003,
      "step": 27700
    },
    {
      "epoch": 5.9387055293613376,
      "grad_norm": 0.005170451011508703,
      "learning_rate": 1.2081725960851551e-05,
      "loss": 0.0005,
      "step": 27710
    },
    {
      "epoch": 5.940848692670381,
      "grad_norm": 0.007894406095147133,
      "learning_rate": 1.2078868409772827e-05,
      "loss": 0.5425,
      "step": 27720
    },
    {
      "epoch": 5.942991855979425,
      "grad_norm": 0.031773343682289124,
      "learning_rate": 1.20760108586941e-05,
      "loss": 0.2609,
      "step": 27730
    },
    {
      "epoch": 5.94513501928847,
      "grad_norm": 0.014428519643843174,
      "learning_rate": 1.2073153307615375e-05,
      "loss": 0.2123,
      "step": 27740
    },
    {
      "epoch": 5.947278182597514,
      "grad_norm": 0.047532226890325546,
      "learning_rate": 1.207029575653665e-05,
      "loss": 0.0005,
      "step": 27750
    },
    {
      "epoch": 5.949421345906558,
      "grad_norm": 0.02258879318833351,
      "learning_rate": 1.2067438205457924e-05,
      "loss": 0.254,
      "step": 27760
    },
    {
      "epoch": 5.951564509215602,
      "grad_norm": 1.1793473958969116,
      "learning_rate": 1.2064580654379198e-05,
      "loss": 0.2498,
      "step": 27770
    },
    {
      "epoch": 5.953707672524646,
      "grad_norm": 0.021538671106100082,
      "learning_rate": 1.2061723103300474e-05,
      "loss": 0.1042,
      "step": 27780
    },
    {
      "epoch": 5.95585083583369,
      "grad_norm": 0.011111597530543804,
      "learning_rate": 1.2058865552221748e-05,
      "loss": 0.0005,
      "step": 27790
    },
    {
      "epoch": 5.957993999142735,
      "grad_norm": 0.024088572710752487,
      "learning_rate": 1.2056008001143023e-05,
      "loss": 0.201,
      "step": 27800
    },
    {
      "epoch": 5.960137162451779,
      "grad_norm": 0.024306833744049072,
      "learning_rate": 1.2053150450064295e-05,
      "loss": 0.0008,
      "step": 27810
    },
    {
      "epoch": 5.962280325760823,
      "grad_norm": 0.014267231337726116,
      "learning_rate": 1.205029289898557e-05,
      "loss": 0.0007,
      "step": 27820
    },
    {
      "epoch": 5.964423489069867,
      "grad_norm": 0.015351216308772564,
      "learning_rate": 1.2047435347906843e-05,
      "loss": 0.0005,
      "step": 27830
    },
    {
      "epoch": 5.966566652378911,
      "grad_norm": 0.014016220346093178,
      "learning_rate": 1.2044577796828119e-05,
      "loss": 0.0003,
      "step": 27840
    },
    {
      "epoch": 5.968709815687955,
      "grad_norm": 0.011664868332445621,
      "learning_rate": 1.2041720245749393e-05,
      "loss": 0.0021,
      "step": 27850
    },
    {
      "epoch": 5.970852978997,
      "grad_norm": 0.01650608330965042,
      "learning_rate": 1.2038862694670668e-05,
      "loss": 0.0004,
      "step": 27860
    },
    {
      "epoch": 5.972996142306044,
      "grad_norm": 0.011063999496400356,
      "learning_rate": 1.2036005143591942e-05,
      "loss": 0.0953,
      "step": 27870
    },
    {
      "epoch": 5.975139305615087,
      "grad_norm": 0.1809999942779541,
      "learning_rate": 1.2033147592513216e-05,
      "loss": 0.0002,
      "step": 27880
    },
    {
      "epoch": 5.977282468924132,
      "grad_norm": 136.19500732421875,
      "learning_rate": 1.2030290041434492e-05,
      "loss": 0.6903,
      "step": 27890
    },
    {
      "epoch": 5.979425632233176,
      "grad_norm": 0.01847173273563385,
      "learning_rate": 1.2027432490355766e-05,
      "loss": 0.3874,
      "step": 27900
    },
    {
      "epoch": 5.98156879554222,
      "grad_norm": 0.005733105354011059,
      "learning_rate": 1.202457493927704e-05,
      "loss": 0.2423,
      "step": 27910
    },
    {
      "epoch": 5.983711958851265,
      "grad_norm": 0.04914059862494469,
      "learning_rate": 1.2021717388198315e-05,
      "loss": 0.0013,
      "step": 27920
    },
    {
      "epoch": 5.9858551221603085,
      "grad_norm": 0.012055078521370888,
      "learning_rate": 1.201885983711959e-05,
      "loss": 0.2273,
      "step": 27930
    },
    {
      "epoch": 5.987998285469352,
      "grad_norm": 0.04205695912241936,
      "learning_rate": 1.2016002286040865e-05,
      "loss": 0.2076,
      "step": 27940
    },
    {
      "epoch": 5.990141448778397,
      "grad_norm": 0.016855167225003242,
      "learning_rate": 1.2013144734962139e-05,
      "loss": 0.0004,
      "step": 27950
    },
    {
      "epoch": 5.992284612087441,
      "grad_norm": 0.07390734553337097,
      "learning_rate": 1.2010287183883413e-05,
      "loss": 0.0004,
      "step": 27960
    },
    {
      "epoch": 5.994427775396485,
      "grad_norm": 0.06681131571531296,
      "learning_rate": 1.2007429632804688e-05,
      "loss": 0.0007,
      "step": 27970
    },
    {
      "epoch": 5.9965709387055295,
      "grad_norm": 0.009940934367477894,
      "learning_rate": 1.2004572081725962e-05,
      "loss": 0.1561,
      "step": 27980
    },
    {
      "epoch": 5.998714102014573,
      "grad_norm": 443.16571044921875,
      "learning_rate": 1.2001714530647236e-05,
      "loss": 0.0931,
      "step": 27990
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9186666666666666,
      "eval_f1": 0.7973421926910299,
      "eval_loss": 0.5516773462295532,
      "eval_precision": 0.7729468599033816,
      "eval_recall": 0.823327615780446,
      "eval_runtime": 108.309,
      "eval_samples_per_second": 27.699,
      "eval_steps_per_second": 1.154,
      "step": 27996
    },
    {
      "epoch": 6.000857265323618,
      "grad_norm": 0.015086128376424313,
      "learning_rate": 1.1998856979568512e-05,
      "loss": 0.0006,
      "step": 28000
    },
    {
      "epoch": 6.003000428632662,
      "grad_norm": 0.1379459798336029,
      "learning_rate": 1.1995999428489786e-05,
      "loss": 0.0004,
      "step": 28010
    },
    {
      "epoch": 6.005143591941706,
      "grad_norm": 0.006258026231080294,
      "learning_rate": 1.1993141877411058e-05,
      "loss": 0.0002,
      "step": 28020
    },
    {
      "epoch": 6.0072867552507505,
      "grad_norm": 0.014819856733083725,
      "learning_rate": 1.1990284326332334e-05,
      "loss": 0.0002,
      "step": 28030
    },
    {
      "epoch": 6.009429918559794,
      "grad_norm": 0.009065688587725163,
      "learning_rate": 1.1987426775253608e-05,
      "loss": 0.0002,
      "step": 28040
    },
    {
      "epoch": 6.011573081868838,
      "grad_norm": 0.003391634440049529,
      "learning_rate": 1.1984569224174882e-05,
      "loss": 0.0002,
      "step": 28050
    },
    {
      "epoch": 6.013716245177883,
      "grad_norm": 0.006173237692564726,
      "learning_rate": 1.1981711673096157e-05,
      "loss": 0.289,
      "step": 28060
    },
    {
      "epoch": 6.015859408486927,
      "grad_norm": 0.0026008826680481434,
      "learning_rate": 1.1978854122017431e-05,
      "loss": 0.0001,
      "step": 28070
    },
    {
      "epoch": 6.018002571795971,
      "grad_norm": 0.001975375460460782,
      "learning_rate": 1.1975996570938707e-05,
      "loss": 0.0001,
      "step": 28080
    },
    {
      "epoch": 6.020145735105015,
      "grad_norm": 0.002848272444680333,
      "learning_rate": 1.197313901985998e-05,
      "loss": 0.0001,
      "step": 28090
    },
    {
      "epoch": 6.022288898414059,
      "grad_norm": 0.013798650354146957,
      "learning_rate": 1.1970281468781255e-05,
      "loss": 0.0002,
      "step": 28100
    },
    {
      "epoch": 6.024432061723103,
      "grad_norm": 0.0012053619138896465,
      "learning_rate": 1.196742391770253e-05,
      "loss": 0.0001,
      "step": 28110
    },
    {
      "epoch": 6.026575225032148,
      "grad_norm": 0.036583565175533295,
      "learning_rate": 1.1964566366623804e-05,
      "loss": 0.2091,
      "step": 28120
    },
    {
      "epoch": 6.028718388341192,
      "grad_norm": 0.006476222537457943,
      "learning_rate": 1.1961708815545078e-05,
      "loss": 0.1839,
      "step": 28130
    },
    {
      "epoch": 6.0308615516502355,
      "grad_norm": 0.0019667053129523993,
      "learning_rate": 1.1958851264466354e-05,
      "loss": 0.2167,
      "step": 28140
    },
    {
      "epoch": 6.03300471495928,
      "grad_norm": 0.07445264607667923,
      "learning_rate": 1.1955993713387628e-05,
      "loss": 0.0006,
      "step": 28150
    },
    {
      "epoch": 6.035147878268324,
      "grad_norm": 0.004856971092522144,
      "learning_rate": 1.1953136162308903e-05,
      "loss": 0.0001,
      "step": 28160
    },
    {
      "epoch": 6.037291041577368,
      "grad_norm": 0.022138062864542007,
      "learning_rate": 1.1950278611230177e-05,
      "loss": 0.0002,
      "step": 28170
    },
    {
      "epoch": 6.039434204886413,
      "grad_norm": 0.029399428516626358,
      "learning_rate": 1.1947421060151451e-05,
      "loss": 0.0003,
      "step": 28180
    },
    {
      "epoch": 6.0415773681954565,
      "grad_norm": 0.0015768776647746563,
      "learning_rate": 1.1944563509072727e-05,
      "loss": 0.0001,
      "step": 28190
    },
    {
      "epoch": 6.0437205315045,
      "grad_norm": 0.010345096699893475,
      "learning_rate": 1.1941705957994e-05,
      "loss": 0.0001,
      "step": 28200
    },
    {
      "epoch": 6.045863694813545,
      "grad_norm": 0.0007107070996426046,
      "learning_rate": 1.1938848406915276e-05,
      "loss": 0.2137,
      "step": 28210
    },
    {
      "epoch": 6.048006858122589,
      "grad_norm": 0.002034261589869857,
      "learning_rate": 1.193599085583655e-05,
      "loss": 0.0001,
      "step": 28220
    },
    {
      "epoch": 6.050150021431633,
      "grad_norm": 0.003486714093014598,
      "learning_rate": 1.1933133304757824e-05,
      "loss": 0.3213,
      "step": 28230
    },
    {
      "epoch": 6.052293184740678,
      "grad_norm": 0.0370686799287796,
      "learning_rate": 1.1930275753679096e-05,
      "loss": 0.0004,
      "step": 28240
    },
    {
      "epoch": 6.054436348049721,
      "grad_norm": 0.024843713268637657,
      "learning_rate": 1.1927418202600372e-05,
      "loss": 0.0006,
      "step": 28250
    },
    {
      "epoch": 6.056579511358765,
      "grad_norm": 0.0019360254518687725,
      "learning_rate": 1.1924560651521646e-05,
      "loss": 0.0005,
      "step": 28260
    },
    {
      "epoch": 6.05872267466781,
      "grad_norm": 0.04149773716926575,
      "learning_rate": 1.192170310044292e-05,
      "loss": 0.1786,
      "step": 28270
    },
    {
      "epoch": 6.060865837976854,
      "grad_norm": 0.017374912276864052,
      "learning_rate": 1.1918845549364195e-05,
      "loss": 0.0004,
      "step": 28280
    },
    {
      "epoch": 6.063009001285898,
      "grad_norm": 0.0022084868978708982,
      "learning_rate": 1.191598799828547e-05,
      "loss": 0.1498,
      "step": 28290
    },
    {
      "epoch": 6.065152164594942,
      "grad_norm": 0.03059469163417816,
      "learning_rate": 1.1913130447206745e-05,
      "loss": 0.0188,
      "step": 28300
    },
    {
      "epoch": 6.067295327903986,
      "grad_norm": 0.001159785082563758,
      "learning_rate": 1.1910272896128019e-05,
      "loss": 0.0006,
      "step": 28310
    },
    {
      "epoch": 6.06943849121303,
      "grad_norm": 0.0026738650631159544,
      "learning_rate": 1.1907415345049293e-05,
      "loss": 0.0003,
      "step": 28320
    },
    {
      "epoch": 6.071581654522075,
      "grad_norm": 0.0021338893566280603,
      "learning_rate": 1.1904557793970568e-05,
      "loss": 0.0002,
      "step": 28330
    },
    {
      "epoch": 6.073724817831119,
      "grad_norm": 75.91804504394531,
      "learning_rate": 1.1901700242891842e-05,
      "loss": 0.084,
      "step": 28340
    },
    {
      "epoch": 6.075867981140163,
      "grad_norm": 0.002192522631958127,
      "learning_rate": 1.1898842691813118e-05,
      "loss": 0.21,
      "step": 28350
    },
    {
      "epoch": 6.078011144449207,
      "grad_norm": 17.569963455200195,
      "learning_rate": 1.1895985140734392e-05,
      "loss": 0.1723,
      "step": 28360
    },
    {
      "epoch": 6.080154307758251,
      "grad_norm": 0.0022701129782944918,
      "learning_rate": 1.1893127589655666e-05,
      "loss": 0.0007,
      "step": 28370
    },
    {
      "epoch": 6.082297471067295,
      "grad_norm": 0.009343123994767666,
      "learning_rate": 1.1890270038576942e-05,
      "loss": 0.0002,
      "step": 28380
    },
    {
      "epoch": 6.08444063437634,
      "grad_norm": 0.01201250497251749,
      "learning_rate": 1.1887412487498215e-05,
      "loss": 0.0001,
      "step": 28390
    },
    {
      "epoch": 6.086583797685384,
      "grad_norm": 0.05995848774909973,
      "learning_rate": 1.188455493641949e-05,
      "loss": 0.0004,
      "step": 28400
    },
    {
      "epoch": 6.0887269609944275,
      "grad_norm": 0.006954556796699762,
      "learning_rate": 1.1881697385340765e-05,
      "loss": 0.3776,
      "step": 28410
    },
    {
      "epoch": 6.090870124303472,
      "grad_norm": 0.015373513102531433,
      "learning_rate": 1.1878839834262039e-05,
      "loss": 0.0009,
      "step": 28420
    },
    {
      "epoch": 6.093013287612516,
      "grad_norm": 0.18742498755455017,
      "learning_rate": 1.1875982283183315e-05,
      "loss": 0.0005,
      "step": 28430
    },
    {
      "epoch": 6.09515645092156,
      "grad_norm": 0.005489158444106579,
      "learning_rate": 1.1873124732104588e-05,
      "loss": 0.0001,
      "step": 28440
    },
    {
      "epoch": 6.097299614230605,
      "grad_norm": 0.043301280587911606,
      "learning_rate": 1.187026718102586e-05,
      "loss": 0.0001,
      "step": 28450
    },
    {
      "epoch": 6.0994427775396485,
      "grad_norm": 0.003986712545156479,
      "learning_rate": 1.1867409629947135e-05,
      "loss": 0.1591,
      "step": 28460
    },
    {
      "epoch": 6.101585940848692,
      "grad_norm": 0.014967063441872597,
      "learning_rate": 1.186455207886841e-05,
      "loss": 0.0001,
      "step": 28470
    },
    {
      "epoch": 6.103729104157737,
      "grad_norm": 0.007838050834834576,
      "learning_rate": 1.1861694527789684e-05,
      "loss": 0.2028,
      "step": 28480
    },
    {
      "epoch": 6.105872267466781,
      "grad_norm": 0.002768756588920951,
      "learning_rate": 1.185883697671096e-05,
      "loss": 0.0,
      "step": 28490
    },
    {
      "epoch": 6.108015430775825,
      "grad_norm": 27.524927139282227,
      "learning_rate": 1.1855979425632234e-05,
      "loss": 0.2539,
      "step": 28500
    },
    {
      "epoch": 6.1101585940848695,
      "grad_norm": 0.007052134722471237,
      "learning_rate": 1.1853121874553508e-05,
      "loss": 0.0007,
      "step": 28510
    },
    {
      "epoch": 6.112301757393913,
      "grad_norm": 0.03384095057845116,
      "learning_rate": 1.1850264323474783e-05,
      "loss": 0.0008,
      "step": 28520
    },
    {
      "epoch": 6.114444920702957,
      "grad_norm": 12.32438850402832,
      "learning_rate": 1.1847406772396057e-05,
      "loss": 0.0017,
      "step": 28530
    },
    {
      "epoch": 6.116588084012002,
      "grad_norm": 0.012814678251743317,
      "learning_rate": 1.1844549221317331e-05,
      "loss": 0.0001,
      "step": 28540
    },
    {
      "epoch": 6.118731247321046,
      "grad_norm": 44.86330795288086,
      "learning_rate": 1.1841691670238607e-05,
      "loss": 0.3895,
      "step": 28550
    },
    {
      "epoch": 6.12087441063009,
      "grad_norm": 0.005670050624758005,
      "learning_rate": 1.183883411915988e-05,
      "loss": 0.0003,
      "step": 28560
    },
    {
      "epoch": 6.123017573939134,
      "grad_norm": 0.001048609963618219,
      "learning_rate": 1.1835976568081156e-05,
      "loss": 0.1103,
      "step": 28570
    },
    {
      "epoch": 6.125160737248178,
      "grad_norm": 0.000598009442910552,
      "learning_rate": 1.183311901700243e-05,
      "loss": 0.292,
      "step": 28580
    },
    {
      "epoch": 6.127303900557222,
      "grad_norm": 22.658681869506836,
      "learning_rate": 1.1830261465923704e-05,
      "loss": 0.3958,
      "step": 28590
    },
    {
      "epoch": 6.129447063866267,
      "grad_norm": 0.07468298822641373,
      "learning_rate": 1.182740391484498e-05,
      "loss": 0.6292,
      "step": 28600
    },
    {
      "epoch": 6.131590227175311,
      "grad_norm": 0.0614827536046505,
      "learning_rate": 1.1824546363766254e-05,
      "loss": 0.0015,
      "step": 28610
    },
    {
      "epoch": 6.1337333904843545,
      "grad_norm": 0.022174565121531487,
      "learning_rate": 1.1821688812687528e-05,
      "loss": 0.1764,
      "step": 28620
    },
    {
      "epoch": 6.135876553793399,
      "grad_norm": 0.7477917075157166,
      "learning_rate": 1.1818831261608803e-05,
      "loss": 0.1386,
      "step": 28630
    },
    {
      "epoch": 6.138019717102443,
      "grad_norm": 0.10070972889661789,
      "learning_rate": 1.1815973710530077e-05,
      "loss": 0.1136,
      "step": 28640
    },
    {
      "epoch": 6.140162880411487,
      "grad_norm": 0.004053821787238121,
      "learning_rate": 1.1813116159451353e-05,
      "loss": 0.0036,
      "step": 28650
    },
    {
      "epoch": 6.142306043720532,
      "grad_norm": 20.701282501220703,
      "learning_rate": 1.1810258608372627e-05,
      "loss": 0.0197,
      "step": 28660
    },
    {
      "epoch": 6.1444492070295755,
      "grad_norm": 0.02835129015147686,
      "learning_rate": 1.1807401057293899e-05,
      "loss": 0.0005,
      "step": 28670
    },
    {
      "epoch": 6.146592370338619,
      "grad_norm": 0.12427297979593277,
      "learning_rate": 1.1804543506215173e-05,
      "loss": 0.0308,
      "step": 28680
    },
    {
      "epoch": 6.148735533647664,
      "grad_norm": 0.01538200955837965,
      "learning_rate": 1.1801685955136449e-05,
      "loss": 0.0002,
      "step": 28690
    },
    {
      "epoch": 6.150878696956708,
      "grad_norm": 0.0030720571521669626,
      "learning_rate": 1.1798828404057722e-05,
      "loss": 0.0794,
      "step": 28700
    },
    {
      "epoch": 6.153021860265753,
      "grad_norm": 0.006327644921839237,
      "learning_rate": 1.1795970852978998e-05,
      "loss": 0.0012,
      "step": 28710
    },
    {
      "epoch": 6.155165023574797,
      "grad_norm": 0.00989364180713892,
      "learning_rate": 1.1793113301900272e-05,
      "loss": 0.0003,
      "step": 28720
    },
    {
      "epoch": 6.15730818688384,
      "grad_norm": 0.002929504495114088,
      "learning_rate": 1.1790255750821546e-05,
      "loss": 0.0002,
      "step": 28730
    },
    {
      "epoch": 6.159451350192885,
      "grad_norm": 0.00498207425698638,
      "learning_rate": 1.1787398199742822e-05,
      "loss": 0.0001,
      "step": 28740
    },
    {
      "epoch": 6.161594513501929,
      "grad_norm": 0.016344912350177765,
      "learning_rate": 1.1784540648664095e-05,
      "loss": 0.0002,
      "step": 28750
    },
    {
      "epoch": 6.163737676810973,
      "grad_norm": 0.002614798489958048,
      "learning_rate": 1.178168309758537e-05,
      "loss": 0.0001,
      "step": 28760
    },
    {
      "epoch": 6.165880840120018,
      "grad_norm": 0.0018567231018096209,
      "learning_rate": 1.1778825546506645e-05,
      "loss": 0.0004,
      "step": 28770
    },
    {
      "epoch": 6.168024003429061,
      "grad_norm": 0.0018960920860990882,
      "learning_rate": 1.1775967995427919e-05,
      "loss": 0.0001,
      "step": 28780
    },
    {
      "epoch": 6.170167166738105,
      "grad_norm": 0.0033684573136270046,
      "learning_rate": 1.1773110444349195e-05,
      "loss": 0.2791,
      "step": 28790
    },
    {
      "epoch": 6.17231033004715,
      "grad_norm": 0.04372153431177139,
      "learning_rate": 1.1770252893270469e-05,
      "loss": 0.0004,
      "step": 28800
    },
    {
      "epoch": 6.174453493356194,
      "grad_norm": 0.0009604406077414751,
      "learning_rate": 1.1767395342191742e-05,
      "loss": 0.0453,
      "step": 28810
    },
    {
      "epoch": 6.176596656665238,
      "grad_norm": 0.017908988520503044,
      "learning_rate": 1.1764537791113018e-05,
      "loss": 0.0002,
      "step": 28820
    },
    {
      "epoch": 6.1787398199742825,
      "grad_norm": 0.0007371571846306324,
      "learning_rate": 1.1761680240034292e-05,
      "loss": 0.0001,
      "step": 28830
    },
    {
      "epoch": 6.180882983283326,
      "grad_norm": 0.006542419549077749,
      "learning_rate": 1.1758822688955568e-05,
      "loss": 0.0001,
      "step": 28840
    },
    {
      "epoch": 6.18302614659237,
      "grad_norm": 0.05298435688018799,
      "learning_rate": 1.1755965137876842e-05,
      "loss": 0.0001,
      "step": 28850
    },
    {
      "epoch": 6.185169309901415,
      "grad_norm": 0.000585163536015898,
      "learning_rate": 1.1753107586798115e-05,
      "loss": 0.2197,
      "step": 28860
    },
    {
      "epoch": 6.187312473210459,
      "grad_norm": 57.72228240966797,
      "learning_rate": 1.1750250035719391e-05,
      "loss": 0.0484,
      "step": 28870
    },
    {
      "epoch": 6.189455636519503,
      "grad_norm": 0.09287139028310776,
      "learning_rate": 1.1747392484640663e-05,
      "loss": 0.2249,
      "step": 28880
    },
    {
      "epoch": 6.191598799828547,
      "grad_norm": 0.010364086367189884,
      "learning_rate": 1.1744534933561937e-05,
      "loss": 0.2517,
      "step": 28890
    },
    {
      "epoch": 6.193741963137591,
      "grad_norm": 0.0008255240391008556,
      "learning_rate": 1.1741677382483211e-05,
      "loss": 0.0,
      "step": 28900
    },
    {
      "epoch": 6.195885126446635,
      "grad_norm": 0.0010034206788986921,
      "learning_rate": 1.1738819831404487e-05,
      "loss": 0.0002,
      "step": 28910
    },
    {
      "epoch": 6.19802828975568,
      "grad_norm": 0.004784591030329466,
      "learning_rate": 1.173596228032576e-05,
      "loss": 0.0002,
      "step": 28920
    },
    {
      "epoch": 6.200171453064724,
      "grad_norm": 0.001553015667013824,
      "learning_rate": 1.1733104729247036e-05,
      "loss": 0.0032,
      "step": 28930
    },
    {
      "epoch": 6.2023146163737675,
      "grad_norm": 0.04623112455010414,
      "learning_rate": 1.173024717816831e-05,
      "loss": 0.0001,
      "step": 28940
    },
    {
      "epoch": 6.204457779682812,
      "grad_norm": 0.07273954153060913,
      "learning_rate": 1.1727389627089584e-05,
      "loss": 0.0003,
      "step": 28950
    },
    {
      "epoch": 6.206600942991856,
      "grad_norm": 0.018456095829606056,
      "learning_rate": 1.172453207601086e-05,
      "loss": 0.0007,
      "step": 28960
    },
    {
      "epoch": 6.2087441063009,
      "grad_norm": 0.0023310170508921146,
      "learning_rate": 1.1721674524932134e-05,
      "loss": 0.1791,
      "step": 28970
    },
    {
      "epoch": 6.210887269609945,
      "grad_norm": 0.009737013839185238,
      "learning_rate": 1.171881697385341e-05,
      "loss": 0.0005,
      "step": 28980
    },
    {
      "epoch": 6.2130304329189885,
      "grad_norm": 0.2041408121585846,
      "learning_rate": 1.1715959422774683e-05,
      "loss": 0.0007,
      "step": 28990
    },
    {
      "epoch": 6.215173596228032,
      "grad_norm": 0.0027341742534190416,
      "learning_rate": 1.1713101871695957e-05,
      "loss": 0.0001,
      "step": 29000
    },
    {
      "epoch": 6.217316759537077,
      "grad_norm": 0.010359052568674088,
      "learning_rate": 1.1710244320617233e-05,
      "loss": 0.0001,
      "step": 29010
    },
    {
      "epoch": 6.219459922846121,
      "grad_norm": 0.0004829690733458847,
      "learning_rate": 1.1707386769538507e-05,
      "loss": 0.0,
      "step": 29020
    },
    {
      "epoch": 6.221603086155165,
      "grad_norm": 0.26987630128860474,
      "learning_rate": 1.170452921845978e-05,
      "loss": 0.0003,
      "step": 29030
    },
    {
      "epoch": 6.2237462494642095,
      "grad_norm": 0.0008112438954412937,
      "learning_rate": 1.1701671667381056e-05,
      "loss": 0.0001,
      "step": 29040
    },
    {
      "epoch": 6.225889412773253,
      "grad_norm": 0.0014015656197443604,
      "learning_rate": 1.169881411630233e-05,
      "loss": 0.0001,
      "step": 29050
    },
    {
      "epoch": 6.228032576082297,
      "grad_norm": 0.0004211411578580737,
      "learning_rate": 1.1695956565223606e-05,
      "loss": 0.0,
      "step": 29060
    },
    {
      "epoch": 6.230175739391342,
      "grad_norm": 0.006145650055259466,
      "learning_rate": 1.169309901414488e-05,
      "loss": 0.1448,
      "step": 29070
    },
    {
      "epoch": 6.232318902700386,
      "grad_norm": 0.0006808821344748139,
      "learning_rate": 1.1690241463066154e-05,
      "loss": 0.0002,
      "step": 29080
    },
    {
      "epoch": 6.23446206600943,
      "grad_norm": 0.0017308704555034637,
      "learning_rate": 1.168738391198743e-05,
      "loss": 0.0,
      "step": 29090
    },
    {
      "epoch": 6.236605229318474,
      "grad_norm": 0.0006597694009542465,
      "learning_rate": 1.1684526360908702e-05,
      "loss": 0.0088,
      "step": 29100
    },
    {
      "epoch": 6.238748392627518,
      "grad_norm": 0.00036462792195379734,
      "learning_rate": 1.1681668809829976e-05,
      "loss": 0.2476,
      "step": 29110
    },
    {
      "epoch": 6.240891555936562,
      "grad_norm": 0.052630383521318436,
      "learning_rate": 1.1678811258751251e-05,
      "loss": 0.0001,
      "step": 29120
    },
    {
      "epoch": 6.243034719245607,
      "grad_norm": 0.1071561649441719,
      "learning_rate": 1.1675953707672525e-05,
      "loss": 0.1692,
      "step": 29130
    },
    {
      "epoch": 6.245177882554651,
      "grad_norm": 0.01503525860607624,
      "learning_rate": 1.1673096156593799e-05,
      "loss": 0.2503,
      "step": 29140
    },
    {
      "epoch": 6.2473210458636945,
      "grad_norm": 0.025216467678546906,
      "learning_rate": 1.1670238605515075e-05,
      "loss": 0.0002,
      "step": 29150
    },
    {
      "epoch": 6.249464209172739,
      "grad_norm": 17.19487762451172,
      "learning_rate": 1.1667381054436349e-05,
      "loss": 0.1506,
      "step": 29160
    },
    {
      "epoch": 6.251607372481783,
      "grad_norm": 0.08899366110563278,
      "learning_rate": 1.1664523503357623e-05,
      "loss": 0.0006,
      "step": 29170
    },
    {
      "epoch": 6.253750535790827,
      "grad_norm": 0.0012058222200721502,
      "learning_rate": 1.1661665952278898e-05,
      "loss": 0.2835,
      "step": 29180
    },
    {
      "epoch": 6.255893699099872,
      "grad_norm": 0.013959060423076153,
      "learning_rate": 1.1658808401200172e-05,
      "loss": 0.0024,
      "step": 29190
    },
    {
      "epoch": 6.2580368624089155,
      "grad_norm": 0.0018533377442508936,
      "learning_rate": 1.1655950850121448e-05,
      "loss": 0.0,
      "step": 29200
    },
    {
      "epoch": 6.260180025717959,
      "grad_norm": 0.0048362682573497295,
      "learning_rate": 1.1653093299042722e-05,
      "loss": 0.0002,
      "step": 29210
    },
    {
      "epoch": 6.262323189027004,
      "grad_norm": 0.008119536563754082,
      "learning_rate": 1.1650235747963996e-05,
      "loss": 0.0043,
      "step": 29220
    },
    {
      "epoch": 6.264466352336048,
      "grad_norm": 22.27219009399414,
      "learning_rate": 1.1647378196885271e-05,
      "loss": 0.6771,
      "step": 29230
    },
    {
      "epoch": 6.266609515645092,
      "grad_norm": 0.002660898258909583,
      "learning_rate": 1.1644520645806545e-05,
      "loss": 0.0103,
      "step": 29240
    },
    {
      "epoch": 6.268752678954137,
      "grad_norm": 0.05515579506754875,
      "learning_rate": 1.1641663094727819e-05,
      "loss": 0.0002,
      "step": 29250
    },
    {
      "epoch": 6.27089584226318,
      "grad_norm": 0.002561882371082902,
      "learning_rate": 1.1638805543649095e-05,
      "loss": 0.0001,
      "step": 29260
    },
    {
      "epoch": 6.273039005572224,
      "grad_norm": 0.0020361244678497314,
      "learning_rate": 1.1635947992570369e-05,
      "loss": 0.1843,
      "step": 29270
    },
    {
      "epoch": 6.275182168881269,
      "grad_norm": 0.0014636998530477285,
      "learning_rate": 1.1633090441491644e-05,
      "loss": 0.0002,
      "step": 29280
    },
    {
      "epoch": 6.277325332190313,
      "grad_norm": 0.00133613427169621,
      "learning_rate": 1.1630232890412918e-05,
      "loss": 0.2403,
      "step": 29290
    },
    {
      "epoch": 6.279468495499357,
      "grad_norm": 0.0009095068089663982,
      "learning_rate": 1.1627375339334192e-05,
      "loss": 0.1975,
      "step": 29300
    },
    {
      "epoch": 6.281611658808401,
      "grad_norm": 0.009822518564760685,
      "learning_rate": 1.1624517788255464e-05,
      "loss": 0.2366,
      "step": 29310
    },
    {
      "epoch": 6.283754822117445,
      "grad_norm": 0.08467476069927216,
      "learning_rate": 1.162166023717674e-05,
      "loss": 0.3487,
      "step": 29320
    },
    {
      "epoch": 6.285897985426489,
      "grad_norm": 0.005291968118399382,
      "learning_rate": 1.1618802686098014e-05,
      "loss": 0.0263,
      "step": 29330
    },
    {
      "epoch": 6.288041148735534,
      "grad_norm": 0.004571255296468735,
      "learning_rate": 1.161594513501929e-05,
      "loss": 0.0009,
      "step": 29340
    },
    {
      "epoch": 6.290184312044578,
      "grad_norm": 0.002624999266117811,
      "learning_rate": 1.1613087583940563e-05,
      "loss": 0.0002,
      "step": 29350
    },
    {
      "epoch": 6.292327475353622,
      "grad_norm": 0.03117150068283081,
      "learning_rate": 1.1610230032861837e-05,
      "loss": 0.0003,
      "step": 29360
    },
    {
      "epoch": 6.294470638662666,
      "grad_norm": 0.0025353487581014633,
      "learning_rate": 1.1607372481783113e-05,
      "loss": 0.0001,
      "step": 29370
    },
    {
      "epoch": 6.29661380197171,
      "grad_norm": 0.0015765699790790677,
      "learning_rate": 1.1604514930704387e-05,
      "loss": 0.0253,
      "step": 29380
    },
    {
      "epoch": 6.298756965280754,
      "grad_norm": 0.0019551459699869156,
      "learning_rate": 1.160165737962566e-05,
      "loss": 0.1352,
      "step": 29390
    },
    {
      "epoch": 6.300900128589799,
      "grad_norm": 0.0008231140091083944,
      "learning_rate": 1.1598799828546936e-05,
      "loss": 0.0025,
      "step": 29400
    },
    {
      "epoch": 6.303043291898843,
      "grad_norm": 0.003940204158425331,
      "learning_rate": 1.159594227746821e-05,
      "loss": 0.0005,
      "step": 29410
    },
    {
      "epoch": 6.3051864552078865,
      "grad_norm": 0.009611779823899269,
      "learning_rate": 1.1593084726389486e-05,
      "loss": 0.1605,
      "step": 29420
    },
    {
      "epoch": 6.307329618516931,
      "grad_norm": 0.0016462927451357245,
      "learning_rate": 1.159022717531076e-05,
      "loss": 0.0001,
      "step": 29430
    },
    {
      "epoch": 6.309472781825975,
      "grad_norm": 0.0014860312221571803,
      "learning_rate": 1.1587369624232034e-05,
      "loss": 0.1199,
      "step": 29440
    },
    {
      "epoch": 6.311615945135019,
      "grad_norm": 0.013399665243923664,
      "learning_rate": 1.158451207315331e-05,
      "loss": 0.0001,
      "step": 29450
    },
    {
      "epoch": 6.313759108444064,
      "grad_norm": 0.08678079396486282,
      "learning_rate": 1.1581654522074583e-05,
      "loss": 0.0003,
      "step": 29460
    },
    {
      "epoch": 6.3159022717531075,
      "grad_norm": 0.005102173890918493,
      "learning_rate": 1.1578796970995857e-05,
      "loss": 0.2701,
      "step": 29470
    },
    {
      "epoch": 6.318045435062151,
      "grad_norm": 0.0068539767526090145,
      "learning_rate": 1.1575939419917133e-05,
      "loss": 0.0002,
      "step": 29480
    },
    {
      "epoch": 6.320188598371196,
      "grad_norm": 101.38121032714844,
      "learning_rate": 1.1573081868838407e-05,
      "loss": 0.4802,
      "step": 29490
    },
    {
      "epoch": 6.32233176168024,
      "grad_norm": 0.009053217247128487,
      "learning_rate": 1.1570224317759682e-05,
      "loss": 0.0007,
      "step": 29500
    },
    {
      "epoch": 6.324474924989284,
      "grad_norm": 216.5557098388672,
      "learning_rate": 1.1567366766680956e-05,
      "loss": 0.2012,
      "step": 29510
    },
    {
      "epoch": 6.3266180882983285,
      "grad_norm": 0.00445258803665638,
      "learning_rate": 1.156450921560223e-05,
      "loss": 0.0001,
      "step": 29520
    },
    {
      "epoch": 6.328761251607372,
      "grad_norm": 0.00309191457927227,
      "learning_rate": 1.1561651664523503e-05,
      "loss": 0.0003,
      "step": 29530
    },
    {
      "epoch": 6.330904414916416,
      "grad_norm": 0.0012937878491356969,
      "learning_rate": 1.1558794113444778e-05,
      "loss": 0.0001,
      "step": 29540
    },
    {
      "epoch": 6.333047578225461,
      "grad_norm": 0.01615472137928009,
      "learning_rate": 1.1555936562366052e-05,
      "loss": 0.1188,
      "step": 29550
    },
    {
      "epoch": 6.335190741534505,
      "grad_norm": 0.003858214244246483,
      "learning_rate": 1.1553079011287328e-05,
      "loss": 0.0003,
      "step": 29560
    },
    {
      "epoch": 6.337333904843549,
      "grad_norm": 0.002109211403876543,
      "learning_rate": 1.1550221460208602e-05,
      "loss": 0.0001,
      "step": 29570
    },
    {
      "epoch": 6.339477068152593,
      "grad_norm": 0.006948958151042461,
      "learning_rate": 1.1547363909129876e-05,
      "loss": 0.161,
      "step": 29580
    },
    {
      "epoch": 6.341620231461637,
      "grad_norm": 0.0022500096820294857,
      "learning_rate": 1.1544506358051151e-05,
      "loss": 0.0002,
      "step": 29590
    },
    {
      "epoch": 6.343763394770681,
      "grad_norm": 0.0035131105687469244,
      "learning_rate": 1.1541648806972425e-05,
      "loss": 0.4744,
      "step": 29600
    },
    {
      "epoch": 6.345906558079726,
      "grad_norm": 0.016564108431339264,
      "learning_rate": 1.1538791255893699e-05,
      "loss": 0.0007,
      "step": 29610
    },
    {
      "epoch": 6.34804972138877,
      "grad_norm": 0.008250778540968895,
      "learning_rate": 1.1535933704814975e-05,
      "loss": 0.0004,
      "step": 29620
    },
    {
      "epoch": 6.3501928846978135,
      "grad_norm": 0.006872060243040323,
      "learning_rate": 1.1533076153736249e-05,
      "loss": 0.0089,
      "step": 29630
    },
    {
      "epoch": 6.352336048006858,
      "grad_norm": 0.0041238488629460335,
      "learning_rate": 1.1530218602657524e-05,
      "loss": 0.0006,
      "step": 29640
    },
    {
      "epoch": 6.354479211315902,
      "grad_norm": 0.002342826686799526,
      "learning_rate": 1.1527361051578798e-05,
      "loss": 0.0004,
      "step": 29650
    },
    {
      "epoch": 6.356622374624947,
      "grad_norm": 0.005140370223671198,
      "learning_rate": 1.1524503500500072e-05,
      "loss": 0.0004,
      "step": 29660
    },
    {
      "epoch": 6.358765537933991,
      "grad_norm": 0.05343230068683624,
      "learning_rate": 1.1521645949421348e-05,
      "loss": 0.0002,
      "step": 29670
    },
    {
      "epoch": 6.3609087012430345,
      "grad_norm": 0.002298880834132433,
      "learning_rate": 1.1518788398342622e-05,
      "loss": 0.0,
      "step": 29680
    },
    {
      "epoch": 6.363051864552079,
      "grad_norm": 0.0009805056033656001,
      "learning_rate": 1.1515930847263897e-05,
      "loss": 0.0,
      "step": 29690
    },
    {
      "epoch": 6.365195027861123,
      "grad_norm": 0.002015859354287386,
      "learning_rate": 1.1513073296185171e-05,
      "loss": 0.0886,
      "step": 29700
    },
    {
      "epoch": 6.367338191170167,
      "grad_norm": 0.0013400823809206486,
      "learning_rate": 1.1510215745106445e-05,
      "loss": 0.0003,
      "step": 29710
    },
    {
      "epoch": 6.369481354479212,
      "grad_norm": 0.004813473671674728,
      "learning_rate": 1.150735819402772e-05,
      "loss": 0.3124,
      "step": 29720
    },
    {
      "epoch": 6.371624517788256,
      "grad_norm": 0.0067041474394500256,
      "learning_rate": 1.1504500642948995e-05,
      "loss": 0.0002,
      "step": 29730
    },
    {
      "epoch": 6.373767681097299,
      "grad_norm": 0.03650052845478058,
      "learning_rate": 1.1501643091870267e-05,
      "loss": 0.1901,
      "step": 29740
    },
    {
      "epoch": 6.375910844406344,
      "grad_norm": 0.012068438343703747,
      "learning_rate": 1.149878554079154e-05,
      "loss": 0.0004,
      "step": 29750
    },
    {
      "epoch": 6.378054007715388,
      "grad_norm": 0.00539016630500555,
      "learning_rate": 1.1495927989712816e-05,
      "loss": 0.0002,
      "step": 29760
    },
    {
      "epoch": 6.380197171024432,
      "grad_norm": 0.014953105710446835,
      "learning_rate": 1.149307043863409e-05,
      "loss": 0.2518,
      "step": 29770
    },
    {
      "epoch": 6.382340334333477,
      "grad_norm": 0.009926197119057178,
      "learning_rate": 1.1490212887555366e-05,
      "loss": 0.0023,
      "step": 29780
    },
    {
      "epoch": 6.38448349764252,
      "grad_norm": 0.013233950361609459,
      "learning_rate": 1.148735533647664e-05,
      "loss": 0.0954,
      "step": 29790
    },
    {
      "epoch": 6.386626660951564,
      "grad_norm": 0.06621792912483215,
      "learning_rate": 1.1484497785397914e-05,
      "loss": 0.1976,
      "step": 29800
    },
    {
      "epoch": 6.388769824260609,
      "grad_norm": 0.023662105202674866,
      "learning_rate": 1.148164023431919e-05,
      "loss": 0.0002,
      "step": 29810
    },
    {
      "epoch": 6.390912987569653,
      "grad_norm": 0.0021418894175440073,
      "learning_rate": 1.1478782683240463e-05,
      "loss": 0.0005,
      "step": 29820
    },
    {
      "epoch": 6.393056150878697,
      "grad_norm": 0.011130512692034245,
      "learning_rate": 1.1475925132161739e-05,
      "loss": 0.0002,
      "step": 29830
    },
    {
      "epoch": 6.3951993141877415,
      "grad_norm": 0.768704891204834,
      "learning_rate": 1.1473067581083013e-05,
      "loss": 0.0007,
      "step": 29840
    },
    {
      "epoch": 6.397342477496785,
      "grad_norm": 0.0014694518176838756,
      "learning_rate": 1.1470210030004287e-05,
      "loss": 0.0344,
      "step": 29850
    },
    {
      "epoch": 6.399485640805829,
      "grad_norm": 0.003582671284675598,
      "learning_rate": 1.1467352478925563e-05,
      "loss": 0.0342,
      "step": 29860
    },
    {
      "epoch": 6.401628804114874,
      "grad_norm": 0.0018503169994801283,
      "learning_rate": 1.1464494927846836e-05,
      "loss": 0.0004,
      "step": 29870
    },
    {
      "epoch": 6.403771967423918,
      "grad_norm": 0.0007936274050734937,
      "learning_rate": 1.146163737676811e-05,
      "loss": 0.0002,
      "step": 29880
    },
    {
      "epoch": 6.405915130732962,
      "grad_norm": 0.008848462253808975,
      "learning_rate": 1.1458779825689386e-05,
      "loss": 0.0015,
      "step": 29890
    },
    {
      "epoch": 6.408058294042006,
      "grad_norm": 0.003940421622246504,
      "learning_rate": 1.145592227461066e-05,
      "loss": 0.0093,
      "step": 29900
    },
    {
      "epoch": 6.41020145735105,
      "grad_norm": 0.0009337934316135943,
      "learning_rate": 1.1453064723531936e-05,
      "loss": 0.0001,
      "step": 29910
    },
    {
      "epoch": 6.412344620660094,
      "grad_norm": 0.000477699504699558,
      "learning_rate": 1.145020717245321e-05,
      "loss": 0.0,
      "step": 29920
    },
    {
      "epoch": 6.414487783969139,
      "grad_norm": 0.0005641144816763699,
      "learning_rate": 1.1447349621374483e-05,
      "loss": 0.0001,
      "step": 29930
    },
    {
      "epoch": 6.416630947278183,
      "grad_norm": 0.0025984514504671097,
      "learning_rate": 1.1444492070295759e-05,
      "loss": 0.2111,
      "step": 29940
    },
    {
      "epoch": 6.4187741105872265,
      "grad_norm": 0.024351021274924278,
      "learning_rate": 1.1441634519217031e-05,
      "loss": 0.0007,
      "step": 29950
    },
    {
      "epoch": 6.420917273896271,
      "grad_norm": 0.0045165568590164185,
      "learning_rate": 1.1438776968138305e-05,
      "loss": 0.0001,
      "step": 29960
    },
    {
      "epoch": 6.423060437205315,
      "grad_norm": 0.0012366120936349034,
      "learning_rate": 1.143591941705958e-05,
      "loss": 0.0,
      "step": 29970
    },
    {
      "epoch": 6.425203600514359,
      "grad_norm": 0.0017237347783520818,
      "learning_rate": 1.1433061865980855e-05,
      "loss": 0.2216,
      "step": 29980
    },
    {
      "epoch": 6.427346763823404,
      "grad_norm": 0.002744192723184824,
      "learning_rate": 1.1430204314902129e-05,
      "loss": 0.0002,
      "step": 29990
    },
    {
      "epoch": 6.4294899271324475,
      "grad_norm": 24.439390182495117,
      "learning_rate": 1.1427346763823404e-05,
      "loss": 0.3905,
      "step": 30000
    },
    {
      "epoch": 6.431633090441491,
      "grad_norm": 0.033727969974279404,
      "learning_rate": 1.1424489212744678e-05,
      "loss": 0.0004,
      "step": 30010
    },
    {
      "epoch": 6.433776253750536,
      "grad_norm": 0.004004996735602617,
      "learning_rate": 1.1421631661665952e-05,
      "loss": 0.0005,
      "step": 30020
    },
    {
      "epoch": 6.43591941705958,
      "grad_norm": 0.002337399637326598,
      "learning_rate": 1.1418774110587228e-05,
      "loss": 0.0002,
      "step": 30030
    },
    {
      "epoch": 6.438062580368624,
      "grad_norm": 0.01535271666944027,
      "learning_rate": 1.1415916559508502e-05,
      "loss": 0.0003,
      "step": 30040
    },
    {
      "epoch": 6.4402057436776685,
      "grad_norm": 0.00047379417810589075,
      "learning_rate": 1.1413059008429777e-05,
      "loss": 0.0002,
      "step": 30050
    },
    {
      "epoch": 6.442348906986712,
      "grad_norm": 0.00048206260544247925,
      "learning_rate": 1.1410201457351051e-05,
      "loss": 0.0029,
      "step": 30060
    },
    {
      "epoch": 6.444492070295756,
      "grad_norm": 0.0010089839342981577,
      "learning_rate": 1.1407343906272325e-05,
      "loss": 0.0,
      "step": 30070
    },
    {
      "epoch": 6.446635233604801,
      "grad_norm": 0.0006103115156292915,
      "learning_rate": 1.14044863551936e-05,
      "loss": 0.0001,
      "step": 30080
    },
    {
      "epoch": 6.448778396913845,
      "grad_norm": 0.0004684787127189338,
      "learning_rate": 1.1401628804114875e-05,
      "loss": 0.0002,
      "step": 30090
    },
    {
      "epoch": 6.450921560222889,
      "grad_norm": 0.0070399753749370575,
      "learning_rate": 1.1398771253036149e-05,
      "loss": 0.3534,
      "step": 30100
    },
    {
      "epoch": 6.453064723531933,
      "grad_norm": 0.0069890390150249004,
      "learning_rate": 1.1395913701957424e-05,
      "loss": 0.0291,
      "step": 30110
    },
    {
      "epoch": 6.455207886840977,
      "grad_norm": 0.00031201442470774055,
      "learning_rate": 1.1393056150878698e-05,
      "loss": 0.0,
      "step": 30120
    },
    {
      "epoch": 6.457351050150021,
      "grad_norm": 39.20939254760742,
      "learning_rate": 1.1390198599799974e-05,
      "loss": 0.6883,
      "step": 30130
    },
    {
      "epoch": 6.459494213459066,
      "grad_norm": 0.0008041077526286244,
      "learning_rate": 1.1387341048721248e-05,
      "loss": 0.2316,
      "step": 30140
    },
    {
      "epoch": 6.46163737676811,
      "grad_norm": 0.0006513021653518081,
      "learning_rate": 1.1384483497642522e-05,
      "loss": 0.0434,
      "step": 30150
    },
    {
      "epoch": 6.4637805400771535,
      "grad_norm": 0.19072265923023224,
      "learning_rate": 1.1381625946563797e-05,
      "loss": 0.222,
      "step": 30160
    },
    {
      "epoch": 6.465923703386198,
      "grad_norm": 0.02001638151705265,
      "learning_rate": 1.137876839548507e-05,
      "loss": 0.1785,
      "step": 30170
    },
    {
      "epoch": 6.468066866695242,
      "grad_norm": 0.005065080244094133,
      "learning_rate": 1.1375910844406343e-05,
      "loss": 0.237,
      "step": 30180
    },
    {
      "epoch": 6.470210030004286,
      "grad_norm": 0.01299747359007597,
      "learning_rate": 1.1373053293327619e-05,
      "loss": 0.0077,
      "step": 30190
    },
    {
      "epoch": 6.472353193313331,
      "grad_norm": 0.07108120620250702,
      "learning_rate": 1.1370195742248893e-05,
      "loss": 0.001,
      "step": 30200
    },
    {
      "epoch": 6.4744963566223745,
      "grad_norm": 0.008551634848117828,
      "learning_rate": 1.1367338191170167e-05,
      "loss": 0.0013,
      "step": 30210
    },
    {
      "epoch": 6.476639519931418,
      "grad_norm": 0.0025661978870630264,
      "learning_rate": 1.1364480640091443e-05,
      "loss": 0.0002,
      "step": 30220
    },
    {
      "epoch": 6.478782683240463,
      "grad_norm": 0.0005673730629496276,
      "learning_rate": 1.1361623089012716e-05,
      "loss": 0.0001,
      "step": 30230
    },
    {
      "epoch": 6.480925846549507,
      "grad_norm": 0.0068958830088377,
      "learning_rate": 1.135876553793399e-05,
      "loss": 0.2835,
      "step": 30240
    },
    {
      "epoch": 6.483069009858551,
      "grad_norm": 0.031644027680158615,
      "learning_rate": 1.1355907986855266e-05,
      "loss": 0.0002,
      "step": 30250
    },
    {
      "epoch": 6.485212173167596,
      "grad_norm": 0.0005047242157161236,
      "learning_rate": 1.135305043577654e-05,
      "loss": 0.0002,
      "step": 30260
    },
    {
      "epoch": 6.487355336476639,
      "grad_norm": 0.0008974748197942972,
      "learning_rate": 1.1350192884697816e-05,
      "loss": 0.2607,
      "step": 30270
    },
    {
      "epoch": 6.489498499785683,
      "grad_norm": 0.0009030920919030905,
      "learning_rate": 1.134733533361909e-05,
      "loss": 0.0006,
      "step": 30280
    },
    {
      "epoch": 6.491641663094728,
      "grad_norm": 0.004092753399163485,
      "learning_rate": 1.1344477782540363e-05,
      "loss": 0.1573,
      "step": 30290
    },
    {
      "epoch": 6.493784826403772,
      "grad_norm": 0.17871199548244476,
      "learning_rate": 1.1341620231461639e-05,
      "loss": 0.0002,
      "step": 30300
    },
    {
      "epoch": 6.495927989712816,
      "grad_norm": 0.01772431842982769,
      "learning_rate": 1.1338762680382913e-05,
      "loss": 0.2687,
      "step": 30310
    },
    {
      "epoch": 6.4980711530218604,
      "grad_norm": 0.008007258176803589,
      "learning_rate": 1.1335905129304187e-05,
      "loss": 0.0025,
      "step": 30320
    },
    {
      "epoch": 6.500214316330904,
      "grad_norm": 0.05323486030101776,
      "learning_rate": 1.1333047578225463e-05,
      "loss": 0.0006,
      "step": 30330
    },
    {
      "epoch": 6.502357479639949,
      "grad_norm": 0.012372611090540886,
      "learning_rate": 1.1330190027146736e-05,
      "loss": 0.0839,
      "step": 30340
    },
    {
      "epoch": 6.504500642948993,
      "grad_norm": 18.737913131713867,
      "learning_rate": 1.1327332476068012e-05,
      "loss": 0.3337,
      "step": 30350
    },
    {
      "epoch": 6.506643806258037,
      "grad_norm": 0.013569355942308903,
      "learning_rate": 1.1324474924989286e-05,
      "loss": 0.2511,
      "step": 30360
    },
    {
      "epoch": 6.5087869695670815,
      "grad_norm": 0.014028038829565048,
      "learning_rate": 1.132161737391056e-05,
      "loss": 0.0004,
      "step": 30370
    },
    {
      "epoch": 6.510930132876125,
      "grad_norm": 0.005523297470062971,
      "learning_rate": 1.1318759822831832e-05,
      "loss": 0.1365,
      "step": 30380
    },
    {
      "epoch": 6.513073296185169,
      "grad_norm": 0.12642090022563934,
      "learning_rate": 1.1315902271753108e-05,
      "loss": 0.0116,
      "step": 30390
    },
    {
      "epoch": 6.515216459494214,
      "grad_norm": 0.0030040752608329058,
      "learning_rate": 1.1313044720674382e-05,
      "loss": 0.0003,
      "step": 30400
    },
    {
      "epoch": 6.517359622803258,
      "grad_norm": 0.005989867262542248,
      "learning_rate": 1.1310187169595657e-05,
      "loss": 0.0007,
      "step": 30410
    },
    {
      "epoch": 6.519502786112302,
      "grad_norm": 0.013723354786634445,
      "learning_rate": 1.1307329618516931e-05,
      "loss": 0.0003,
      "step": 30420
    },
    {
      "epoch": 6.521645949421346,
      "grad_norm": 0.1612597554922104,
      "learning_rate": 1.1304472067438205e-05,
      "loss": 0.2597,
      "step": 30430
    },
    {
      "epoch": 6.52378911273039,
      "grad_norm": 0.012485220097005367,
      "learning_rate": 1.1301614516359481e-05,
      "loss": 0.0003,
      "step": 30440
    },
    {
      "epoch": 6.525932276039434,
      "grad_norm": 0.010281884111464024,
      "learning_rate": 1.1298756965280755e-05,
      "loss": 0.137,
      "step": 30450
    },
    {
      "epoch": 6.528075439348479,
      "grad_norm": 0.001125340349972248,
      "learning_rate": 1.1295899414202029e-05,
      "loss": 0.2277,
      "step": 30460
    },
    {
      "epoch": 6.530218602657523,
      "grad_norm": 0.000726225902326405,
      "learning_rate": 1.1293041863123304e-05,
      "loss": 0.0017,
      "step": 30470
    },
    {
      "epoch": 6.5323617659665665,
      "grad_norm": 0.010894411243498325,
      "learning_rate": 1.1290184312044578e-05,
      "loss": 0.0002,
      "step": 30480
    },
    {
      "epoch": 6.534504929275611,
      "grad_norm": 0.013456239365041256,
      "learning_rate": 1.1287326760965854e-05,
      "loss": 0.0001,
      "step": 30490
    },
    {
      "epoch": 6.536648092584655,
      "grad_norm": 0.001383485272526741,
      "learning_rate": 1.1284469209887128e-05,
      "loss": 0.0396,
      "step": 30500
    },
    {
      "epoch": 6.538791255893699,
      "grad_norm": 0.0008851991151459515,
      "learning_rate": 1.1281611658808402e-05,
      "loss": 0.2568,
      "step": 30510
    },
    {
      "epoch": 6.540934419202744,
      "grad_norm": 0.02189660258591175,
      "learning_rate": 1.1278754107729677e-05,
      "loss": 0.0002,
      "step": 30520
    },
    {
      "epoch": 6.5430775825117875,
      "grad_norm": 233.99951171875,
      "learning_rate": 1.1275896556650951e-05,
      "loss": 0.3619,
      "step": 30530
    },
    {
      "epoch": 6.545220745820831,
      "grad_norm": 0.05422054976224899,
      "learning_rate": 1.1273039005572227e-05,
      "loss": 0.0727,
      "step": 30540
    },
    {
      "epoch": 6.547363909129876,
      "grad_norm": 171.11245727539062,
      "learning_rate": 1.12701814544935e-05,
      "loss": 0.4842,
      "step": 30550
    },
    {
      "epoch": 6.54950707243892,
      "grad_norm": 0.006568446289747953,
      "learning_rate": 1.1267323903414775e-05,
      "loss": 0.0004,
      "step": 30560
    },
    {
      "epoch": 6.551650235747964,
      "grad_norm": 0.010081564076244831,
      "learning_rate": 1.126446635233605e-05,
      "loss": 0.0293,
      "step": 30570
    },
    {
      "epoch": 6.5537933990570085,
      "grad_norm": 0.0008113273652270436,
      "learning_rate": 1.1261608801257324e-05,
      "loss": 0.0005,
      "step": 30580
    },
    {
      "epoch": 6.555936562366052,
      "grad_norm": 0.003573741763830185,
      "learning_rate": 1.1258751250178598e-05,
      "loss": 0.1437,
      "step": 30590
    },
    {
      "epoch": 6.558079725675096,
      "grad_norm": 0.41873160004615784,
      "learning_rate": 1.125589369909987e-05,
      "loss": 0.0014,
      "step": 30600
    },
    {
      "epoch": 6.560222888984141,
      "grad_norm": 0.010037270374596119,
      "learning_rate": 1.1253036148021146e-05,
      "loss": 0.0003,
      "step": 30610
    },
    {
      "epoch": 6.562366052293185,
      "grad_norm": 0.0002887139853555709,
      "learning_rate": 1.125017859694242e-05,
      "loss": 0.0059,
      "step": 30620
    },
    {
      "epoch": 6.564509215602229,
      "grad_norm": 0.9837342500686646,
      "learning_rate": 1.1247321045863696e-05,
      "loss": 0.0005,
      "step": 30630
    },
    {
      "epoch": 6.566652378911273,
      "grad_norm": 0.0002039355895249173,
      "learning_rate": 1.124446349478497e-05,
      "loss": 0.0262,
      "step": 30640
    },
    {
      "epoch": 6.568795542220317,
      "grad_norm": 0.003280260832980275,
      "learning_rate": 1.1241605943706244e-05,
      "loss": 0.0002,
      "step": 30650
    },
    {
      "epoch": 6.570938705529361,
      "grad_norm": 0.002346242079511285,
      "learning_rate": 1.1238748392627519e-05,
      "loss": 0.0001,
      "step": 30660
    },
    {
      "epoch": 6.573081868838406,
      "grad_norm": 0.06681551784276962,
      "learning_rate": 1.1235890841548793e-05,
      "loss": 0.2363,
      "step": 30670
    },
    {
      "epoch": 6.57522503214745,
      "grad_norm": 0.006653324235230684,
      "learning_rate": 1.1233033290470069e-05,
      "loss": 0.0001,
      "step": 30680
    },
    {
      "epoch": 6.5773681954564935,
      "grad_norm": 6.216999530792236,
      "learning_rate": 1.1230175739391343e-05,
      "loss": 0.0075,
      "step": 30690
    },
    {
      "epoch": 6.579511358765538,
      "grad_norm": 0.006972515489906073,
      "learning_rate": 1.1227318188312617e-05,
      "loss": 0.2483,
      "step": 30700
    },
    {
      "epoch": 6.581654522074582,
      "grad_norm": 0.004349544178694487,
      "learning_rate": 1.1224460637233892e-05,
      "loss": 0.0002,
      "step": 30710
    },
    {
      "epoch": 6.583797685383626,
      "grad_norm": 0.0004398475866764784,
      "learning_rate": 1.1221603086155166e-05,
      "loss": 0.0,
      "step": 30720
    },
    {
      "epoch": 6.585940848692671,
      "grad_norm": 0.0002245421492261812,
      "learning_rate": 1.121874553507644e-05,
      "loss": 0.0001,
      "step": 30730
    },
    {
      "epoch": 6.588084012001715,
      "grad_norm": 0.00025894519058056176,
      "learning_rate": 1.1215887983997716e-05,
      "loss": 0.0003,
      "step": 30740
    },
    {
      "epoch": 6.590227175310758,
      "grad_norm": 0.014703170396387577,
      "learning_rate": 1.121303043291899e-05,
      "loss": 0.1234,
      "step": 30750
    },
    {
      "epoch": 6.592370338619803,
      "grad_norm": 0.027643952518701553,
      "learning_rate": 1.1210172881840265e-05,
      "loss": 0.0001,
      "step": 30760
    },
    {
      "epoch": 6.594513501928847,
      "grad_norm": 0.0573241263628006,
      "learning_rate": 1.1207315330761539e-05,
      "loss": 0.0007,
      "step": 30770
    },
    {
      "epoch": 6.596656665237891,
      "grad_norm": 0.033675726503133774,
      "learning_rate": 1.1204457779682813e-05,
      "loss": 0.0002,
      "step": 30780
    },
    {
      "epoch": 6.598799828546936,
      "grad_norm": 0.00035891003790311515,
      "learning_rate": 1.1201600228604089e-05,
      "loss": 0.0,
      "step": 30790
    },
    {
      "epoch": 6.600942991855979,
      "grad_norm": 0.0017049608286470175,
      "learning_rate": 1.1198742677525363e-05,
      "loss": 0.0002,
      "step": 30800
    },
    {
      "epoch": 6.603086155165023,
      "grad_norm": 0.0008400427177548409,
      "learning_rate": 1.1195885126446635e-05,
      "loss": 0.4569,
      "step": 30810
    },
    {
      "epoch": 6.605229318474068,
      "grad_norm": 0.016200721263885498,
      "learning_rate": 1.119302757536791e-05,
      "loss": 0.0013,
      "step": 30820
    },
    {
      "epoch": 6.607372481783112,
      "grad_norm": 0.004065748304128647,
      "learning_rate": 1.1190170024289184e-05,
      "loss": 0.0003,
      "step": 30830
    },
    {
      "epoch": 6.609515645092156,
      "grad_norm": 0.022140245884656906,
      "learning_rate": 1.1187312473210458e-05,
      "loss": 0.2801,
      "step": 30840
    },
    {
      "epoch": 6.6116588084012005,
      "grad_norm": 0.0019815301056951284,
      "learning_rate": 1.1184454922131734e-05,
      "loss": 0.0006,
      "step": 30850
    },
    {
      "epoch": 6.613801971710244,
      "grad_norm": 0.0004917261539958417,
      "learning_rate": 1.1181597371053008e-05,
      "loss": 0.4363,
      "step": 30860
    },
    {
      "epoch": 6.615945135019288,
      "grad_norm": 0.00029245702899061143,
      "learning_rate": 1.1178739819974282e-05,
      "loss": 0.0003,
      "step": 30870
    },
    {
      "epoch": 6.618088298328333,
      "grad_norm": 0.12534116208553314,
      "learning_rate": 1.1175882268895557e-05,
      "loss": 0.0003,
      "step": 30880
    },
    {
      "epoch": 6.620231461637377,
      "grad_norm": 0.0004282388254068792,
      "learning_rate": 1.1173024717816831e-05,
      "loss": 0.0009,
      "step": 30890
    },
    {
      "epoch": 6.622374624946421,
      "grad_norm": 102.98339080810547,
      "learning_rate": 1.1170167166738107e-05,
      "loss": 0.036,
      "step": 30900
    },
    {
      "epoch": 6.624517788255465,
      "grad_norm": 0.0006641190848313272,
      "learning_rate": 1.1167309615659381e-05,
      "loss": 0.2895,
      "step": 30910
    },
    {
      "epoch": 6.626660951564509,
      "grad_norm": 0.005226801615208387,
      "learning_rate": 1.1164452064580655e-05,
      "loss": 0.0001,
      "step": 30920
    },
    {
      "epoch": 6.628804114873553,
      "grad_norm": 0.0052451323717832565,
      "learning_rate": 1.116159451350193e-05,
      "loss": 0.1657,
      "step": 30930
    },
    {
      "epoch": 6.630947278182598,
      "grad_norm": 0.0014870143495500088,
      "learning_rate": 1.1158736962423204e-05,
      "loss": 0.0003,
      "step": 30940
    },
    {
      "epoch": 6.633090441491642,
      "grad_norm": 0.003385962452739477,
      "learning_rate": 1.1155879411344478e-05,
      "loss": 0.1364,
      "step": 30950
    },
    {
      "epoch": 6.6352336048006855,
      "grad_norm": 0.0005762988585047424,
      "learning_rate": 1.1153021860265754e-05,
      "loss": 0.0005,
      "step": 30960
    },
    {
      "epoch": 6.63737676810973,
      "grad_norm": 0.2049327939748764,
      "learning_rate": 1.1150164309187028e-05,
      "loss": 0.0035,
      "step": 30970
    },
    {
      "epoch": 6.639519931418774,
      "grad_norm": 0.02389192208647728,
      "learning_rate": 1.1147306758108303e-05,
      "loss": 0.1915,
      "step": 30980
    },
    {
      "epoch": 6.641663094727818,
      "grad_norm": 91.53285217285156,
      "learning_rate": 1.1144449207029577e-05,
      "loss": 0.3653,
      "step": 30990
    },
    {
      "epoch": 6.643806258036863,
      "grad_norm": 30.849781036376953,
      "learning_rate": 1.1141591655950851e-05,
      "loss": 0.3281,
      "step": 31000
    },
    {
      "epoch": 6.6459494213459065,
      "grad_norm": 0.0010587073629722,
      "learning_rate": 1.1138734104872127e-05,
      "loss": 0.0001,
      "step": 31010
    },
    {
      "epoch": 6.64809258465495,
      "grad_norm": 0.041877977550029755,
      "learning_rate": 1.1135876553793401e-05,
      "loss": 0.2141,
      "step": 31020
    },
    {
      "epoch": 6.650235747963995,
      "grad_norm": 0.03378229960799217,
      "learning_rate": 1.1133019002714673e-05,
      "loss": 0.0002,
      "step": 31030
    },
    {
      "epoch": 6.652378911273039,
      "grad_norm": 0.007882371544837952,
      "learning_rate": 1.1130161451635949e-05,
      "loss": 0.0004,
      "step": 31040
    },
    {
      "epoch": 6.654522074582083,
      "grad_norm": 188.66680908203125,
      "learning_rate": 1.1127303900557223e-05,
      "loss": 0.1994,
      "step": 31050
    },
    {
      "epoch": 6.6566652378911275,
      "grad_norm": 0.2678929269313812,
      "learning_rate": 1.1124446349478497e-05,
      "loss": 0.0002,
      "step": 31060
    },
    {
      "epoch": 6.658808401200171,
      "grad_norm": 0.008136104792356491,
      "learning_rate": 1.1121588798399772e-05,
      "loss": 0.2687,
      "step": 31070
    },
    {
      "epoch": 6.660951564509215,
      "grad_norm": 0.0001407328963978216,
      "learning_rate": 1.1118731247321046e-05,
      "loss": 0.1524,
      "step": 31080
    },
    {
      "epoch": 6.66309472781826,
      "grad_norm": 0.00019024462380912155,
      "learning_rate": 1.111587369624232e-05,
      "loss": 0.0001,
      "step": 31090
    },
    {
      "epoch": 6.665237891127304,
      "grad_norm": 0.0002577106934040785,
      "learning_rate": 1.1113016145163596e-05,
      "loss": 0.0001,
      "step": 31100
    },
    {
      "epoch": 6.667381054436348,
      "grad_norm": 0.00020085019059479237,
      "learning_rate": 1.111015859408487e-05,
      "loss": 0.0007,
      "step": 31110
    },
    {
      "epoch": 6.669524217745392,
      "grad_norm": 0.000624414999037981,
      "learning_rate": 1.1107301043006145e-05,
      "loss": 0.0035,
      "step": 31120
    },
    {
      "epoch": 6.671667381054436,
      "grad_norm": 0.005253498908132315,
      "learning_rate": 1.110444349192742e-05,
      "loss": 0.0,
      "step": 31130
    },
    {
      "epoch": 6.67381054436348,
      "grad_norm": 0.0015330052701756358,
      "learning_rate": 1.1101585940848693e-05,
      "loss": 0.0002,
      "step": 31140
    },
    {
      "epoch": 6.675953707672525,
      "grad_norm": 22.66910171508789,
      "learning_rate": 1.1098728389769969e-05,
      "loss": 0.3842,
      "step": 31150
    },
    {
      "epoch": 6.678096870981569,
      "grad_norm": 68.39690399169922,
      "learning_rate": 1.1095870838691243e-05,
      "loss": 0.1279,
      "step": 31160
    },
    {
      "epoch": 6.6802400342906125,
      "grad_norm": 0.05664286017417908,
      "learning_rate": 1.1093013287612517e-05,
      "loss": 0.0002,
      "step": 31170
    },
    {
      "epoch": 6.682383197599657,
      "grad_norm": 0.03583481162786484,
      "learning_rate": 1.1090155736533792e-05,
      "loss": 0.0311,
      "step": 31180
    },
    {
      "epoch": 6.684526360908701,
      "grad_norm": 0.16128578782081604,
      "learning_rate": 1.1087298185455066e-05,
      "loss": 0.0003,
      "step": 31190
    },
    {
      "epoch": 6.686669524217745,
      "grad_norm": 0.00012729076843243092,
      "learning_rate": 1.1084440634376342e-05,
      "loss": 0.1543,
      "step": 31200
    },
    {
      "epoch": 6.68881268752679,
      "grad_norm": 0.08173146098852158,
      "learning_rate": 1.1081583083297616e-05,
      "loss": 0.3801,
      "step": 31210
    },
    {
      "epoch": 6.6909558508358336,
      "grad_norm": 0.0036799011286348104,
      "learning_rate": 1.107872553221889e-05,
      "loss": 0.0014,
      "step": 31220
    },
    {
      "epoch": 6.693099014144877,
      "grad_norm": 0.07043704390525818,
      "learning_rate": 1.1075867981140165e-05,
      "loss": 0.0046,
      "step": 31230
    },
    {
      "epoch": 6.695242177453922,
      "grad_norm": 175.52432250976562,
      "learning_rate": 1.1073010430061437e-05,
      "loss": 0.1227,
      "step": 31240
    },
    {
      "epoch": 6.697385340762966,
      "grad_norm": 0.02486776001751423,
      "learning_rate": 1.1070152878982711e-05,
      "loss": 0.2074,
      "step": 31250
    },
    {
      "epoch": 6.69952850407201,
      "grad_norm": 0.18128064274787903,
      "learning_rate": 1.1067295327903987e-05,
      "loss": 0.1062,
      "step": 31260
    },
    {
      "epoch": 6.701671667381055,
      "grad_norm": 0.0006600252236239612,
      "learning_rate": 1.1064437776825261e-05,
      "loss": 0.0001,
      "step": 31270
    },
    {
      "epoch": 6.703814830690098,
      "grad_norm": 0.0011236611753702164,
      "learning_rate": 1.1061580225746535e-05,
      "loss": 0.24,
      "step": 31280
    },
    {
      "epoch": 6.705957993999142,
      "grad_norm": 0.0034609807189553976,
      "learning_rate": 1.105872267466781e-05,
      "loss": 0.0007,
      "step": 31290
    },
    {
      "epoch": 6.708101157308187,
      "grad_norm": 0.5753983855247498,
      "learning_rate": 1.1055865123589084e-05,
      "loss": 0.0006,
      "step": 31300
    },
    {
      "epoch": 6.710244320617231,
      "grad_norm": 0.010625635273754597,
      "learning_rate": 1.1053007572510358e-05,
      "loss": 0.0004,
      "step": 31310
    },
    {
      "epoch": 6.712387483926275,
      "grad_norm": 0.0014234096743166447,
      "learning_rate": 1.1050150021431634e-05,
      "loss": 0.001,
      "step": 31320
    },
    {
      "epoch": 6.7145306472353194,
      "grad_norm": 0.002543010748922825,
      "learning_rate": 1.1047292470352908e-05,
      "loss": 0.1626,
      "step": 31330
    },
    {
      "epoch": 6.716673810544363,
      "grad_norm": 0.0025076805613934994,
      "learning_rate": 1.1044434919274184e-05,
      "loss": 0.0008,
      "step": 31340
    },
    {
      "epoch": 6.718816973853407,
      "grad_norm": 0.019780870527029037,
      "learning_rate": 1.1041577368195457e-05,
      "loss": 0.0005,
      "step": 31350
    },
    {
      "epoch": 6.720960137162452,
      "grad_norm": 0.0007036594906821847,
      "learning_rate": 1.1038719817116731e-05,
      "loss": 0.4447,
      "step": 31360
    },
    {
      "epoch": 6.723103300471496,
      "grad_norm": 0.3092799186706543,
      "learning_rate": 1.1035862266038007e-05,
      "loss": 0.0004,
      "step": 31370
    },
    {
      "epoch": 6.72524646378054,
      "grad_norm": 0.0005519523983821273,
      "learning_rate": 1.1033004714959281e-05,
      "loss": 0.0003,
      "step": 31380
    },
    {
      "epoch": 6.727389627089584,
      "grad_norm": 0.0019766720943152905,
      "learning_rate": 1.1030147163880557e-05,
      "loss": 0.0002,
      "step": 31390
    },
    {
      "epoch": 6.729532790398628,
      "grad_norm": 0.007264334242790937,
      "learning_rate": 1.102728961280183e-05,
      "loss": 0.1517,
      "step": 31400
    },
    {
      "epoch": 6.731675953707673,
      "grad_norm": 0.028148410841822624,
      "learning_rate": 1.1024432061723104e-05,
      "loss": 0.0001,
      "step": 31410
    },
    {
      "epoch": 6.733819117016717,
      "grad_norm": 0.03974809870123863,
      "learning_rate": 1.102157451064438e-05,
      "loss": 0.0001,
      "step": 31420
    },
    {
      "epoch": 6.735962280325761,
      "grad_norm": 0.02816874161362648,
      "learning_rate": 1.1018716959565654e-05,
      "loss": 0.0001,
      "step": 31430
    },
    {
      "epoch": 6.738105443634805,
      "grad_norm": 0.04989544302225113,
      "learning_rate": 1.1015859408486928e-05,
      "loss": 0.1712,
      "step": 31440
    },
    {
      "epoch": 6.740248606943849,
      "grad_norm": 0.005339142866432667,
      "learning_rate": 1.1013001857408204e-05,
      "loss": 0.2486,
      "step": 31450
    },
    {
      "epoch": 6.742391770252893,
      "grad_norm": 0.0005455281352624297,
      "learning_rate": 1.1010144306329476e-05,
      "loss": 0.0003,
      "step": 31460
    },
    {
      "epoch": 6.744534933561938,
      "grad_norm": 0.007157099898904562,
      "learning_rate": 1.100728675525075e-05,
      "loss": 0.0003,
      "step": 31470
    },
    {
      "epoch": 6.746678096870982,
      "grad_norm": 0.0012977924197912216,
      "learning_rate": 1.1004429204172025e-05,
      "loss": 0.0001,
      "step": 31480
    },
    {
      "epoch": 6.7488212601800255,
      "grad_norm": 0.008141865953803062,
      "learning_rate": 1.10015716530933e-05,
      "loss": 0.0001,
      "step": 31490
    },
    {
      "epoch": 6.75096442348907,
      "grad_norm": 0.006199794355779886,
      "learning_rate": 1.0998714102014573e-05,
      "loss": 0.0001,
      "step": 31500
    },
    {
      "epoch": 6.753107586798114,
      "grad_norm": 0.006566847208887339,
      "learning_rate": 1.0995856550935849e-05,
      "loss": 0.1395,
      "step": 31510
    },
    {
      "epoch": 6.755250750107158,
      "grad_norm": 0.0072854007594287395,
      "learning_rate": 1.0992998999857123e-05,
      "loss": 0.0002,
      "step": 31520
    },
    {
      "epoch": 6.757393913416203,
      "grad_norm": 0.07082556933164597,
      "learning_rate": 1.0990141448778398e-05,
      "loss": 0.5726,
      "step": 31530
    },
    {
      "epoch": 6.7595370767252465,
      "grad_norm": 0.007496669888496399,
      "learning_rate": 1.0987283897699672e-05,
      "loss": 0.1319,
      "step": 31540
    },
    {
      "epoch": 6.76168024003429,
      "grad_norm": 0.007938518188893795,
      "learning_rate": 1.0984426346620946e-05,
      "loss": 0.0001,
      "step": 31550
    },
    {
      "epoch": 6.763823403343335,
      "grad_norm": 0.016248559579253197,
      "learning_rate": 1.0981568795542222e-05,
      "loss": 0.225,
      "step": 31560
    },
    {
      "epoch": 6.765966566652379,
      "grad_norm": 0.05029416084289551,
      "learning_rate": 1.0978711244463496e-05,
      "loss": 0.0992,
      "step": 31570
    },
    {
      "epoch": 6.768109729961423,
      "grad_norm": 0.004765479825437069,
      "learning_rate": 1.097585369338477e-05,
      "loss": 0.0221,
      "step": 31580
    },
    {
      "epoch": 6.7702528932704675,
      "grad_norm": 0.009977057576179504,
      "learning_rate": 1.0972996142306045e-05,
      "loss": 0.1577,
      "step": 31590
    },
    {
      "epoch": 6.772396056579511,
      "grad_norm": 0.0006142749334685504,
      "learning_rate": 1.097013859122732e-05,
      "loss": 0.0003,
      "step": 31600
    },
    {
      "epoch": 6.774539219888555,
      "grad_norm": 0.008286179974675179,
      "learning_rate": 1.0967281040148595e-05,
      "loss": 0.1381,
      "step": 31610
    },
    {
      "epoch": 6.7766823831976,
      "grad_norm": 22.756019592285156,
      "learning_rate": 1.0964423489069869e-05,
      "loss": 0.1618,
      "step": 31620
    },
    {
      "epoch": 6.778825546506644,
      "grad_norm": 0.018874574452638626,
      "learning_rate": 1.0961565937991143e-05,
      "loss": 0.0575,
      "step": 31630
    },
    {
      "epoch": 6.780968709815688,
      "grad_norm": 0.006990371737629175,
      "learning_rate": 1.0958708386912418e-05,
      "loss": 0.0007,
      "step": 31640
    },
    {
      "epoch": 6.783111873124732,
      "grad_norm": 0.0003371525090187788,
      "learning_rate": 1.0955850835833692e-05,
      "loss": 0.0008,
      "step": 31650
    },
    {
      "epoch": 6.785255036433776,
      "grad_norm": 0.018261298537254333,
      "learning_rate": 1.0952993284754966e-05,
      "loss": 0.0008,
      "step": 31660
    },
    {
      "epoch": 6.78739819974282,
      "grad_norm": 0.0013376014539971948,
      "learning_rate": 1.095013573367624e-05,
      "loss": 0.0009,
      "step": 31670
    },
    {
      "epoch": 6.789541363051865,
      "grad_norm": 0.03840698301792145,
      "learning_rate": 1.0947278182597514e-05,
      "loss": 0.0003,
      "step": 31680
    },
    {
      "epoch": 6.791684526360909,
      "grad_norm": 0.00016674288781359792,
      "learning_rate": 1.0944420631518788e-05,
      "loss": 0.0013,
      "step": 31690
    },
    {
      "epoch": 6.7938276896699525,
      "grad_norm": 0.0003398412954993546,
      "learning_rate": 1.0941563080440064e-05,
      "loss": 0.0017,
      "step": 31700
    },
    {
      "epoch": 6.795970852978997,
      "grad_norm": 0.00023294505081139505,
      "learning_rate": 1.0938705529361338e-05,
      "loss": 0.0523,
      "step": 31710
    },
    {
      "epoch": 6.798114016288041,
      "grad_norm": 23.238468170166016,
      "learning_rate": 1.0935847978282611e-05,
      "loss": 0.3266,
      "step": 31720
    },
    {
      "epoch": 6.800257179597085,
      "grad_norm": 0.00018382775306236,
      "learning_rate": 1.0932990427203887e-05,
      "loss": 0.0003,
      "step": 31730
    },
    {
      "epoch": 6.80240034290613,
      "grad_norm": 0.002194693312048912,
      "learning_rate": 1.0930132876125161e-05,
      "loss": 0.1719,
      "step": 31740
    },
    {
      "epoch": 6.804543506215174,
      "grad_norm": 0.0034354759845882654,
      "learning_rate": 1.0927275325046437e-05,
      "loss": 0.226,
      "step": 31750
    },
    {
      "epoch": 6.806686669524217,
      "grad_norm": 0.01623045839369297,
      "learning_rate": 1.092441777396771e-05,
      "loss": 0.0001,
      "step": 31760
    },
    {
      "epoch": 6.808829832833262,
      "grad_norm": 0.0034815091639757156,
      "learning_rate": 1.0921560222888984e-05,
      "loss": 0.2826,
      "step": 31770
    },
    {
      "epoch": 6.810972996142306,
      "grad_norm": 0.0002164680336136371,
      "learning_rate": 1.091870267181026e-05,
      "loss": 0.0003,
      "step": 31780
    },
    {
      "epoch": 6.81311615945135,
      "grad_norm": 0.001607441925443709,
      "learning_rate": 1.0915845120731534e-05,
      "loss": 0.0972,
      "step": 31790
    },
    {
      "epoch": 6.815259322760395,
      "grad_norm": 0.1598019152879715,
      "learning_rate": 1.0912987569652808e-05,
      "loss": 0.1833,
      "step": 31800
    },
    {
      "epoch": 6.817402486069438,
      "grad_norm": 0.0002987101615872234,
      "learning_rate": 1.0910130018574084e-05,
      "loss": 0.1348,
      "step": 31810
    },
    {
      "epoch": 6.819545649378482,
      "grad_norm": 0.0001547759457025677,
      "learning_rate": 1.0907272467495357e-05,
      "loss": 0.0014,
      "step": 31820
    },
    {
      "epoch": 6.821688812687527,
      "grad_norm": 0.00017567641043569893,
      "learning_rate": 1.0904414916416633e-05,
      "loss": 0.356,
      "step": 31830
    },
    {
      "epoch": 6.823831975996571,
      "grad_norm": 19.80035400390625,
      "learning_rate": 1.0901557365337907e-05,
      "loss": 0.4176,
      "step": 31840
    },
    {
      "epoch": 6.825975139305615,
      "grad_norm": 0.00483446940779686,
      "learning_rate": 1.0898699814259181e-05,
      "loss": 0.2095,
      "step": 31850
    },
    {
      "epoch": 6.8281183026146595,
      "grad_norm": 0.2154650241136551,
      "learning_rate": 1.0895842263180457e-05,
      "loss": 0.1539,
      "step": 31860
    },
    {
      "epoch": 6.830261465923703,
      "grad_norm": 0.013715755194425583,
      "learning_rate": 1.089298471210173e-05,
      "loss": 0.0011,
      "step": 31870
    },
    {
      "epoch": 6.832404629232747,
      "grad_norm": 0.00047105117118917406,
      "learning_rate": 1.0890127161023004e-05,
      "loss": 0.262,
      "step": 31880
    },
    {
      "epoch": 6.834547792541792,
      "grad_norm": 0.03904108330607414,
      "learning_rate": 1.0887269609944278e-05,
      "loss": 0.0006,
      "step": 31890
    },
    {
      "epoch": 6.836690955850836,
      "grad_norm": 0.01248086430132389,
      "learning_rate": 1.0884412058865552e-05,
      "loss": 0.0002,
      "step": 31900
    },
    {
      "epoch": 6.83883411915988,
      "grad_norm": 0.18460030853748322,
      "learning_rate": 1.0881554507786826e-05,
      "loss": 0.0165,
      "step": 31910
    },
    {
      "epoch": 6.840977282468924,
      "grad_norm": 0.05719699338078499,
      "learning_rate": 1.0878696956708102e-05,
      "loss": 0.0011,
      "step": 31920
    },
    {
      "epoch": 6.843120445777968,
      "grad_norm": 0.0001504525716882199,
      "learning_rate": 1.0875839405629376e-05,
      "loss": 0.0003,
      "step": 31930
    },
    {
      "epoch": 6.845263609087013,
      "grad_norm": 31.801958084106445,
      "learning_rate": 1.087298185455065e-05,
      "loss": 0.2393,
      "step": 31940
    },
    {
      "epoch": 6.847406772396057,
      "grad_norm": 0.1795429140329361,
      "learning_rate": 1.0870124303471925e-05,
      "loss": 0.2189,
      "step": 31950
    },
    {
      "epoch": 6.849549935705101,
      "grad_norm": 0.007144310511648655,
      "learning_rate": 1.08672667523932e-05,
      "loss": 0.1114,
      "step": 31960
    },
    {
      "epoch": 6.851693099014145,
      "grad_norm": 0.00011627251660684124,
      "learning_rate": 1.0864409201314475e-05,
      "loss": 0.0007,
      "step": 31970
    },
    {
      "epoch": 6.853836262323189,
      "grad_norm": 0.04243112727999687,
      "learning_rate": 1.0861551650235749e-05,
      "loss": 0.1174,
      "step": 31980
    },
    {
      "epoch": 6.855979425632233,
      "grad_norm": 0.049805544316768646,
      "learning_rate": 1.0858694099157023e-05,
      "loss": 0.2115,
      "step": 31990
    },
    {
      "epoch": 6.858122588941278,
      "grad_norm": 0.00033161367173306644,
      "learning_rate": 1.0855836548078298e-05,
      "loss": 0.0005,
      "step": 32000
    },
    {
      "epoch": 6.860265752250322,
      "grad_norm": 0.005368143320083618,
      "learning_rate": 1.0852978996999572e-05,
      "loss": 0.0002,
      "step": 32010
    },
    {
      "epoch": 6.8624089155593655,
      "grad_norm": 0.02081250213086605,
      "learning_rate": 1.0850121445920846e-05,
      "loss": 0.0011,
      "step": 32020
    },
    {
      "epoch": 6.86455207886841,
      "grad_norm": 0.01969320699572563,
      "learning_rate": 1.0847263894842122e-05,
      "loss": 0.0078,
      "step": 32030
    },
    {
      "epoch": 6.866695242177454,
      "grad_norm": 0.0002635966520756483,
      "learning_rate": 1.0844406343763396e-05,
      "loss": 0.0083,
      "step": 32040
    },
    {
      "epoch": 6.868838405486498,
      "grad_norm": 0.0010071221040561795,
      "learning_rate": 1.0841548792684671e-05,
      "loss": 0.0002,
      "step": 32050
    },
    {
      "epoch": 6.870981568795543,
      "grad_norm": 0.0013733076630160213,
      "learning_rate": 1.0838691241605945e-05,
      "loss": 0.0001,
      "step": 32060
    },
    {
      "epoch": 6.8731247321045865,
      "grad_norm": 0.0297065619379282,
      "learning_rate": 1.083583369052722e-05,
      "loss": 0.0001,
      "step": 32070
    },
    {
      "epoch": 6.87526789541363,
      "grad_norm": 0.08791328966617584,
      "learning_rate": 1.0832976139448495e-05,
      "loss": 0.0003,
      "step": 32080
    },
    {
      "epoch": 6.877411058722675,
      "grad_norm": 0.0018179757753387094,
      "learning_rate": 1.0830118588369769e-05,
      "loss": 0.0004,
      "step": 32090
    },
    {
      "epoch": 6.879554222031719,
      "grad_norm": 8.650514064356685e-05,
      "learning_rate": 1.0827261037291041e-05,
      "loss": 0.0002,
      "step": 32100
    },
    {
      "epoch": 6.881697385340763,
      "grad_norm": 0.11932236701250076,
      "learning_rate": 1.0824403486212317e-05,
      "loss": 0.0007,
      "step": 32110
    },
    {
      "epoch": 6.8838405486498075,
      "grad_norm": 0.15340904891490936,
      "learning_rate": 1.082154593513359e-05,
      "loss": 0.1444,
      "step": 32120
    },
    {
      "epoch": 6.885983711958851,
      "grad_norm": 0.00016649565077386796,
      "learning_rate": 1.0818688384054865e-05,
      "loss": 0.2969,
      "step": 32130
    },
    {
      "epoch": 6.888126875267895,
      "grad_norm": 0.00010693466174416244,
      "learning_rate": 1.081583083297614e-05,
      "loss": 0.0001,
      "step": 32140
    },
    {
      "epoch": 6.89027003857694,
      "grad_norm": 0.00010033162834588438,
      "learning_rate": 1.0812973281897414e-05,
      "loss": 0.0001,
      "step": 32150
    },
    {
      "epoch": 6.892413201885984,
      "grad_norm": 0.022220320999622345,
      "learning_rate": 1.0810115730818688e-05,
      "loss": 0.0002,
      "step": 32160
    },
    {
      "epoch": 6.894556365195028,
      "grad_norm": 6.0968202888034284e-05,
      "learning_rate": 1.0807258179739964e-05,
      "loss": 0.0022,
      "step": 32170
    },
    {
      "epoch": 6.896699528504072,
      "grad_norm": 0.05689253658056259,
      "learning_rate": 1.0804400628661238e-05,
      "loss": 0.0003,
      "step": 32180
    },
    {
      "epoch": 6.898842691813116,
      "grad_norm": 7.703886512899771e-05,
      "learning_rate": 1.0801543077582513e-05,
      "loss": 0.0001,
      "step": 32190
    },
    {
      "epoch": 6.90098585512216,
      "grad_norm": 6.385338201653212e-05,
      "learning_rate": 1.0798685526503787e-05,
      "loss": 0.0001,
      "step": 32200
    },
    {
      "epoch": 6.903129018431205,
      "grad_norm": 9.922108438331634e-05,
      "learning_rate": 1.0795827975425061e-05,
      "loss": 0.0,
      "step": 32210
    },
    {
      "epoch": 6.905272181740249,
      "grad_norm": 0.0020265262573957443,
      "learning_rate": 1.0792970424346337e-05,
      "loss": 0.0211,
      "step": 32220
    },
    {
      "epoch": 6.9074153450492926,
      "grad_norm": 0.006479884032160044,
      "learning_rate": 1.079011287326761e-05,
      "loss": 0.1176,
      "step": 32230
    },
    {
      "epoch": 6.909558508358337,
      "grad_norm": 0.0008213966502808034,
      "learning_rate": 1.0787255322188886e-05,
      "loss": 0.0002,
      "step": 32240
    },
    {
      "epoch": 6.911701671667381,
      "grad_norm": 6.793403008487076e-05,
      "learning_rate": 1.078439777111016e-05,
      "loss": 0.0001,
      "step": 32250
    },
    {
      "epoch": 6.913844834976425,
      "grad_norm": 0.002544543007388711,
      "learning_rate": 1.0781540220031434e-05,
      "loss": 0.3379,
      "step": 32260
    },
    {
      "epoch": 6.91598799828547,
      "grad_norm": 0.008157619275152683,
      "learning_rate": 1.077868266895271e-05,
      "loss": 0.0005,
      "step": 32270
    },
    {
      "epoch": 6.918131161594514,
      "grad_norm": 6.249490979826078e-05,
      "learning_rate": 1.0775825117873984e-05,
      "loss": 0.0001,
      "step": 32280
    },
    {
      "epoch": 6.920274324903557,
      "grad_norm": 0.02444009855389595,
      "learning_rate": 1.0772967566795258e-05,
      "loss": 0.0,
      "step": 32290
    },
    {
      "epoch": 6.922417488212602,
      "grad_norm": 0.03622175380587578,
      "learning_rate": 1.0770110015716533e-05,
      "loss": 0.1283,
      "step": 32300
    },
    {
      "epoch": 6.924560651521646,
      "grad_norm": 0.00011349876876920462,
      "learning_rate": 1.0767252464637807e-05,
      "loss": 0.0002,
      "step": 32310
    },
    {
      "epoch": 6.92670381483069,
      "grad_norm": 9.532989497529343e-05,
      "learning_rate": 1.076439491355908e-05,
      "loss": 0.0001,
      "step": 32320
    },
    {
      "epoch": 6.928846978139735,
      "grad_norm": 2.29311203956604,
      "learning_rate": 1.0761537362480355e-05,
      "loss": 0.0004,
      "step": 32330
    },
    {
      "epoch": 6.9309901414487785,
      "grad_norm": 0.00014507693413179368,
      "learning_rate": 1.0758679811401629e-05,
      "loss": 0.0,
      "step": 32340
    },
    {
      "epoch": 6.933133304757822,
      "grad_norm": 0.03855494409799576,
      "learning_rate": 1.0755822260322903e-05,
      "loss": 0.0001,
      "step": 32350
    },
    {
      "epoch": 6.935276468066867,
      "grad_norm": 0.0001320641749771312,
      "learning_rate": 1.0752964709244178e-05,
      "loss": 0.2075,
      "step": 32360
    },
    {
      "epoch": 6.937419631375911,
      "grad_norm": 0.002499527530744672,
      "learning_rate": 1.0750107158165452e-05,
      "loss": 0.1642,
      "step": 32370
    },
    {
      "epoch": 6.939562794684955,
      "grad_norm": 0.0041667926125228405,
      "learning_rate": 1.0747249607086728e-05,
      "loss": 0.0001,
      "step": 32380
    },
    {
      "epoch": 6.9417059579939995,
      "grad_norm": 9.667431731941178e-05,
      "learning_rate": 1.0744392056008002e-05,
      "loss": 0.0,
      "step": 32390
    },
    {
      "epoch": 6.943849121303043,
      "grad_norm": 6.586667586816475e-05,
      "learning_rate": 1.0741534504929276e-05,
      "loss": 0.0003,
      "step": 32400
    },
    {
      "epoch": 6.945992284612087,
      "grad_norm": 0.0018048033816739917,
      "learning_rate": 1.0738676953850551e-05,
      "loss": 0.0001,
      "step": 32410
    },
    {
      "epoch": 6.948135447921132,
      "grad_norm": 0.00012613424041774124,
      "learning_rate": 1.0735819402771825e-05,
      "loss": 0.0027,
      "step": 32420
    },
    {
      "epoch": 6.950278611230176,
      "grad_norm": 0.0016949892742559314,
      "learning_rate": 1.07329618516931e-05,
      "loss": 0.3535,
      "step": 32430
    },
    {
      "epoch": 6.95242177453922,
      "grad_norm": 0.004033219534903765,
      "learning_rate": 1.0730104300614375e-05,
      "loss": 0.0003,
      "step": 32440
    },
    {
      "epoch": 6.954564937848264,
      "grad_norm": 0.002070149639621377,
      "learning_rate": 1.0727246749535649e-05,
      "loss": 0.0,
      "step": 32450
    },
    {
      "epoch": 6.956708101157308,
      "grad_norm": 0.00247082207351923,
      "learning_rate": 1.0724389198456924e-05,
      "loss": 0.0003,
      "step": 32460
    },
    {
      "epoch": 6.958851264466352,
      "grad_norm": 0.001130343764089048,
      "learning_rate": 1.0721531647378198e-05,
      "loss": 0.0009,
      "step": 32470
    },
    {
      "epoch": 6.960994427775397,
      "grad_norm": 8.574929961469024e-05,
      "learning_rate": 1.0718674096299472e-05,
      "loss": 0.364,
      "step": 32480
    },
    {
      "epoch": 6.963137591084441,
      "grad_norm": 0.00021566091163549572,
      "learning_rate": 1.0715816545220748e-05,
      "loss": 0.0,
      "step": 32490
    },
    {
      "epoch": 6.9652807543934845,
      "grad_norm": 0.0003261420060880482,
      "learning_rate": 1.0712958994142022e-05,
      "loss": 0.0,
      "step": 32500
    },
    {
      "epoch": 6.967423917702529,
      "grad_norm": 0.0034930782858282328,
      "learning_rate": 1.0710101443063296e-05,
      "loss": 0.0001,
      "step": 32510
    },
    {
      "epoch": 6.969567081011573,
      "grad_norm": 0.002918589860200882,
      "learning_rate": 1.0707243891984571e-05,
      "loss": 0.2169,
      "step": 32520
    },
    {
      "epoch": 6.971710244320617,
      "grad_norm": 0.0002669903915375471,
      "learning_rate": 1.0704386340905844e-05,
      "loss": 0.1957,
      "step": 32530
    },
    {
      "epoch": 6.973853407629662,
      "grad_norm": 0.00040189860737882555,
      "learning_rate": 1.0701528789827118e-05,
      "loss": 0.001,
      "step": 32540
    },
    {
      "epoch": 6.9759965709387055,
      "grad_norm": 0.0016159986844286323,
      "learning_rate": 1.0698671238748393e-05,
      "loss": 0.0001,
      "step": 32550
    },
    {
      "epoch": 6.978139734247749,
      "grad_norm": 0.0019123466918244958,
      "learning_rate": 1.0695813687669667e-05,
      "loss": 0.0002,
      "step": 32560
    },
    {
      "epoch": 6.980282897556794,
      "grad_norm": 0.010977276600897312,
      "learning_rate": 1.0692956136590941e-05,
      "loss": 0.0001,
      "step": 32570
    },
    {
      "epoch": 6.982426060865838,
      "grad_norm": 0.010533947497606277,
      "learning_rate": 1.0690098585512217e-05,
      "loss": 0.0,
      "step": 32580
    },
    {
      "epoch": 6.984569224174882,
      "grad_norm": 0.003916822373867035,
      "learning_rate": 1.068724103443349e-05,
      "loss": 0.0003,
      "step": 32590
    },
    {
      "epoch": 6.9867123874839265,
      "grad_norm": 0.0057101077400147915,
      "learning_rate": 1.0684383483354766e-05,
      "loss": 0.0002,
      "step": 32600
    },
    {
      "epoch": 6.98885555079297,
      "grad_norm": 0.00033509501372464,
      "learning_rate": 1.068152593227604e-05,
      "loss": 0.0,
      "step": 32610
    },
    {
      "epoch": 6.990998714102014,
      "grad_norm": 0.00010967208800138906,
      "learning_rate": 1.0678668381197314e-05,
      "loss": 0.1138,
      "step": 32620
    },
    {
      "epoch": 6.993141877411059,
      "grad_norm": 0.000142736331326887,
      "learning_rate": 1.067581083011859e-05,
      "loss": 0.0,
      "step": 32630
    },
    {
      "epoch": 6.995285040720103,
      "grad_norm": 0.0046661230735480785,
      "learning_rate": 1.0672953279039864e-05,
      "loss": 0.0001,
      "step": 32640
    },
    {
      "epoch": 6.997428204029147,
      "grad_norm": 0.00018134248966816813,
      "learning_rate": 1.0670095727961138e-05,
      "loss": 0.003,
      "step": 32650
    },
    {
      "epoch": 6.999571367338191,
      "grad_norm": 0.006869361735880375,
      "learning_rate": 1.0667238176882413e-05,
      "loss": 0.8084,
      "step": 32660
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9223333333333333,
      "eval_f1": 0.7961504811898513,
      "eval_loss": 0.5829705595970154,
      "eval_precision": 0.8125,
      "eval_recall": 0.7804459691252144,
      "eval_runtime": 107.609,
      "eval_samples_per_second": 27.879,
      "eval_steps_per_second": 1.162,
      "step": 32662
    },
    {
      "epoch": 7.001714530647235,
      "grad_norm": 0.002328493632376194,
      "learning_rate": 1.0664380625803687e-05,
      "loss": 0.0002,
      "step": 32670
    },
    {
      "epoch": 7.003857693956279,
      "grad_norm": 0.01408045832067728,
      "learning_rate": 1.0661523074724963e-05,
      "loss": 0.0002,
      "step": 32680
    },
    {
      "epoch": 7.006000857265324,
      "grad_norm": 0.0023089649621397257,
      "learning_rate": 1.0658665523646237e-05,
      "loss": 0.0059,
      "step": 32690
    },
    {
      "epoch": 7.008144020574368,
      "grad_norm": 0.0012697913916781545,
      "learning_rate": 1.065580797256751e-05,
      "loss": 0.0002,
      "step": 32700
    },
    {
      "epoch": 7.0102871838834115,
      "grad_norm": 0.0047467858530581,
      "learning_rate": 1.0652950421488786e-05,
      "loss": 0.0001,
      "step": 32710
    },
    {
      "epoch": 7.012430347192456,
      "grad_norm": 0.012832473032176495,
      "learning_rate": 1.065009287041006e-05,
      "loss": 0.0006,
      "step": 32720
    },
    {
      "epoch": 7.0145735105015,
      "grad_norm": 0.0013933589216321707,
      "learning_rate": 1.0647235319331334e-05,
      "loss": 0.0001,
      "step": 32730
    },
    {
      "epoch": 7.016716673810544,
      "grad_norm": 0.008913692086935043,
      "learning_rate": 1.064437776825261e-05,
      "loss": 0.0003,
      "step": 32740
    },
    {
      "epoch": 7.018859837119589,
      "grad_norm": 0.001301213982515037,
      "learning_rate": 1.0641520217173882e-05,
      "loss": 0.0001,
      "step": 32750
    },
    {
      "epoch": 7.021003000428633,
      "grad_norm": 0.016845811158418655,
      "learning_rate": 1.0638662666095156e-05,
      "loss": 0.0001,
      "step": 32760
    },
    {
      "epoch": 7.023146163737676,
      "grad_norm": 0.0018520576413720846,
      "learning_rate": 1.0635805115016431e-05,
      "loss": 0.1955,
      "step": 32770
    },
    {
      "epoch": 7.025289327046721,
      "grad_norm": 0.0057426621206104755,
      "learning_rate": 1.0632947563937705e-05,
      "loss": 0.3965,
      "step": 32780
    },
    {
      "epoch": 7.027432490355765,
      "grad_norm": 0.05375797674059868,
      "learning_rate": 1.063009001285898e-05,
      "loss": 0.0006,
      "step": 32790
    },
    {
      "epoch": 7.029575653664809,
      "grad_norm": 0.01702657900750637,
      "learning_rate": 1.0627232461780255e-05,
      "loss": 0.0004,
      "step": 32800
    },
    {
      "epoch": 7.031718816973854,
      "grad_norm": 0.0022702831774950027,
      "learning_rate": 1.0624374910701529e-05,
      "loss": 0.0004,
      "step": 32810
    },
    {
      "epoch": 7.033861980282897,
      "grad_norm": 0.020168354734778404,
      "learning_rate": 1.0621517359622805e-05,
      "loss": 0.0001,
      "step": 32820
    },
    {
      "epoch": 7.036005143591941,
      "grad_norm": 0.04334403574466705,
      "learning_rate": 1.0618659808544078e-05,
      "loss": 0.0003,
      "step": 32830
    },
    {
      "epoch": 7.038148306900986,
      "grad_norm": 0.0022460659965872765,
      "learning_rate": 1.0615802257465352e-05,
      "loss": 0.0012,
      "step": 32840
    },
    {
      "epoch": 7.04029147021003,
      "grad_norm": 0.0008565408643335104,
      "learning_rate": 1.0612944706386628e-05,
      "loss": 0.2094,
      "step": 32850
    },
    {
      "epoch": 7.042434633519074,
      "grad_norm": 0.0006264952826313674,
      "learning_rate": 1.0610087155307902e-05,
      "loss": 0.0001,
      "step": 32860
    },
    {
      "epoch": 7.0445777968281185,
      "grad_norm": 0.0006703484687022865,
      "learning_rate": 1.0607229604229176e-05,
      "loss": 0.0001,
      "step": 32870
    },
    {
      "epoch": 7.046720960137162,
      "grad_norm": 0.008424567990005016,
      "learning_rate": 1.0604372053150451e-05,
      "loss": 0.0003,
      "step": 32880
    },
    {
      "epoch": 7.048864123446206,
      "grad_norm": 0.010801367461681366,
      "learning_rate": 1.0601514502071725e-05,
      "loss": 0.0001,
      "step": 32890
    },
    {
      "epoch": 7.051007286755251,
      "grad_norm": 0.004767576698213816,
      "learning_rate": 1.0598656950993001e-05,
      "loss": 0.0001,
      "step": 32900
    },
    {
      "epoch": 7.053150450064295,
      "grad_norm": 0.0005617520655505359,
      "learning_rate": 1.0595799399914275e-05,
      "loss": 0.0001,
      "step": 32910
    },
    {
      "epoch": 7.055293613373339,
      "grad_norm": 0.0068119121715426445,
      "learning_rate": 1.0592941848835549e-05,
      "loss": 0.0001,
      "step": 32920
    },
    {
      "epoch": 7.057436776682383,
      "grad_norm": 0.03926488757133484,
      "learning_rate": 1.0590084297756825e-05,
      "loss": 0.0001,
      "step": 32930
    },
    {
      "epoch": 7.059579939991427,
      "grad_norm": 0.007751269731670618,
      "learning_rate": 1.0587226746678098e-05,
      "loss": 0.0001,
      "step": 32940
    },
    {
      "epoch": 7.061723103300472,
      "grad_norm": 0.0012224941747263074,
      "learning_rate": 1.0584369195599374e-05,
      "loss": 0.0001,
      "step": 32950
    },
    {
      "epoch": 7.063866266609516,
      "grad_norm": 0.010423975996673107,
      "learning_rate": 1.0581511644520646e-05,
      "loss": 0.0,
      "step": 32960
    },
    {
      "epoch": 7.06600942991856,
      "grad_norm": 0.00045799376675859094,
      "learning_rate": 1.057865409344192e-05,
      "loss": 0.0001,
      "step": 32970
    },
    {
      "epoch": 7.068152593227604,
      "grad_norm": 0.0007760953740216792,
      "learning_rate": 1.0575796542363194e-05,
      "loss": 0.2285,
      "step": 32980
    },
    {
      "epoch": 7.070295756536648,
      "grad_norm": 0.004966330714523792,
      "learning_rate": 1.057293899128447e-05,
      "loss": 0.0001,
      "step": 32990
    },
    {
      "epoch": 7.072438919845692,
      "grad_norm": 0.00924465712159872,
      "learning_rate": 1.0570081440205744e-05,
      "loss": 0.0001,
      "step": 33000
    },
    {
      "epoch": 7.074582083154737,
      "grad_norm": 0.00658821314573288,
      "learning_rate": 1.0567223889127018e-05,
      "loss": 0.2557,
      "step": 33010
    },
    {
      "epoch": 7.076725246463781,
      "grad_norm": 0.02083260379731655,
      "learning_rate": 1.0564366338048293e-05,
      "loss": 0.1257,
      "step": 33020
    },
    {
      "epoch": 7.0788684097728245,
      "grad_norm": 0.029578223824501038,
      "learning_rate": 1.0561508786969567e-05,
      "loss": 0.1481,
      "step": 33030
    },
    {
      "epoch": 7.081011573081869,
      "grad_norm": 35.06450653076172,
      "learning_rate": 1.0558651235890843e-05,
      "loss": 0.0576,
      "step": 33040
    },
    {
      "epoch": 7.083154736390913,
      "grad_norm": 0.00050185970030725,
      "learning_rate": 1.0555793684812117e-05,
      "loss": 0.0331,
      "step": 33050
    },
    {
      "epoch": 7.085297899699957,
      "grad_norm": 0.00244720745831728,
      "learning_rate": 1.055293613373339e-05,
      "loss": 0.0008,
      "step": 33060
    },
    {
      "epoch": 7.087441063009002,
      "grad_norm": 0.0074491421692073345,
      "learning_rate": 1.0550078582654666e-05,
      "loss": 0.0003,
      "step": 33070
    },
    {
      "epoch": 7.0895842263180455,
      "grad_norm": 0.161451056599617,
      "learning_rate": 1.054722103157594e-05,
      "loss": 0.0003,
      "step": 33080
    },
    {
      "epoch": 7.091727389627089,
      "grad_norm": 0.004800212103873491,
      "learning_rate": 1.0544363480497216e-05,
      "loss": 0.0407,
      "step": 33090
    },
    {
      "epoch": 7.093870552936134,
      "grad_norm": 0.0020955915097147226,
      "learning_rate": 1.054150592941849e-05,
      "loss": 0.0,
      "step": 33100
    },
    {
      "epoch": 7.096013716245178,
      "grad_norm": 0.0021320621017366648,
      "learning_rate": 1.0538648378339764e-05,
      "loss": 0.0001,
      "step": 33110
    },
    {
      "epoch": 7.098156879554222,
      "grad_norm": 0.00043964062933810055,
      "learning_rate": 1.053579082726104e-05,
      "loss": 0.1741,
      "step": 33120
    },
    {
      "epoch": 7.1003000428632665,
      "grad_norm": 0.01802956871688366,
      "learning_rate": 1.0532933276182313e-05,
      "loss": 0.0001,
      "step": 33130
    },
    {
      "epoch": 7.10244320617231,
      "grad_norm": 0.2905179262161255,
      "learning_rate": 1.0530075725103587e-05,
      "loss": 0.1528,
      "step": 33140
    },
    {
      "epoch": 7.104586369481354,
      "grad_norm": 0.0006396243697963655,
      "learning_rate": 1.0527218174024863e-05,
      "loss": 0.1404,
      "step": 33150
    },
    {
      "epoch": 7.106729532790399,
      "grad_norm": 0.0036898397374898195,
      "learning_rate": 1.0524360622946137e-05,
      "loss": 0.0001,
      "step": 33160
    },
    {
      "epoch": 7.108872696099443,
      "grad_norm": 0.0013212274061515927,
      "learning_rate": 1.0521503071867412e-05,
      "loss": 0.0027,
      "step": 33170
    },
    {
      "epoch": 7.111015859408487,
      "grad_norm": 0.0049924165941774845,
      "learning_rate": 1.0518645520788685e-05,
      "loss": 0.0,
      "step": 33180
    },
    {
      "epoch": 7.113159022717531,
      "grad_norm": 0.0009436876280233264,
      "learning_rate": 1.0515787969709959e-05,
      "loss": 0.0001,
      "step": 33190
    },
    {
      "epoch": 7.115302186026575,
      "grad_norm": 0.000547296367585659,
      "learning_rate": 1.0512930418631232e-05,
      "loss": 0.0003,
      "step": 33200
    },
    {
      "epoch": 7.117445349335619,
      "grad_norm": 0.0018560645403340459,
      "learning_rate": 1.0510072867552508e-05,
      "loss": 0.1176,
      "step": 33210
    },
    {
      "epoch": 7.119588512644664,
      "grad_norm": 0.0007605153368785977,
      "learning_rate": 1.0507215316473782e-05,
      "loss": 0.0,
      "step": 33220
    },
    {
      "epoch": 7.121731675953708,
      "grad_norm": 0.0004065491957589984,
      "learning_rate": 1.0504357765395058e-05,
      "loss": 0.0003,
      "step": 33230
    },
    {
      "epoch": 7.123874839262752,
      "grad_norm": 0.006261922884732485,
      "learning_rate": 1.0501500214316332e-05,
      "loss": 0.3164,
      "step": 33240
    },
    {
      "epoch": 7.126018002571796,
      "grad_norm": 0.0004806028737220913,
      "learning_rate": 1.0498642663237605e-05,
      "loss": 0.0001,
      "step": 33250
    },
    {
      "epoch": 7.12816116588084,
      "grad_norm": 0.0027292894665151834,
      "learning_rate": 1.0495785112158881e-05,
      "loss": 0.0,
      "step": 33260
    },
    {
      "epoch": 7.130304329189884,
      "grad_norm": 0.00022867041116114706,
      "learning_rate": 1.0492927561080155e-05,
      "loss": 0.007,
      "step": 33270
    },
    {
      "epoch": 7.132447492498929,
      "grad_norm": 0.00032557983649894595,
      "learning_rate": 1.0490070010001429e-05,
      "loss": 0.0001,
      "step": 33280
    },
    {
      "epoch": 7.134590655807973,
      "grad_norm": 0.002791821025311947,
      "learning_rate": 1.0487212458922705e-05,
      "loss": 0.0,
      "step": 33290
    },
    {
      "epoch": 7.136733819117016,
      "grad_norm": 0.00022691427147947252,
      "learning_rate": 1.0484354907843978e-05,
      "loss": 0.0012,
      "step": 33300
    },
    {
      "epoch": 7.138876982426061,
      "grad_norm": 1.9866087436676025,
      "learning_rate": 1.0481497356765254e-05,
      "loss": 0.0005,
      "step": 33310
    },
    {
      "epoch": 7.141020145735105,
      "grad_norm": 0.0002693287387955934,
      "learning_rate": 1.0478639805686528e-05,
      "loss": 0.0004,
      "step": 33320
    },
    {
      "epoch": 7.143163309044149,
      "grad_norm": 0.00046073723933659494,
      "learning_rate": 1.0475782254607802e-05,
      "loss": 0.0001,
      "step": 33330
    },
    {
      "epoch": 7.145306472353194,
      "grad_norm": 0.0021353941410779953,
      "learning_rate": 1.0472924703529078e-05,
      "loss": 0.0002,
      "step": 33340
    },
    {
      "epoch": 7.1474496356622375,
      "grad_norm": 0.00046374229714274406,
      "learning_rate": 1.0470067152450352e-05,
      "loss": 0.0,
      "step": 33350
    },
    {
      "epoch": 7.149592798971281,
      "grad_norm": 0.0036593854892998934,
      "learning_rate": 1.0467209601371625e-05,
      "loss": 0.0,
      "step": 33360
    },
    {
      "epoch": 7.151735962280326,
      "grad_norm": 0.0006535896100103855,
      "learning_rate": 1.0464352050292901e-05,
      "loss": 0.2088,
      "step": 33370
    },
    {
      "epoch": 7.15387912558937,
      "grad_norm": 0.001051082625053823,
      "learning_rate": 1.0461494499214175e-05,
      "loss": 0.4675,
      "step": 33380
    },
    {
      "epoch": 7.156022288898414,
      "grad_norm": 0.005059927701950073,
      "learning_rate": 1.0458636948135447e-05,
      "loss": 0.0001,
      "step": 33390
    },
    {
      "epoch": 7.1581654522074585,
      "grad_norm": 0.0004735026159323752,
      "learning_rate": 1.0455779397056723e-05,
      "loss": 0.0003,
      "step": 33400
    },
    {
      "epoch": 7.160308615516502,
      "grad_norm": 0.012036139145493507,
      "learning_rate": 1.0452921845977997e-05,
      "loss": 0.028,
      "step": 33410
    },
    {
      "epoch": 7.162451778825546,
      "grad_norm": 0.012030517682433128,
      "learning_rate": 1.045006429489927e-05,
      "loss": 0.0003,
      "step": 33420
    },
    {
      "epoch": 7.164594942134591,
      "grad_norm": 0.00048317958135157824,
      "learning_rate": 1.0447206743820546e-05,
      "loss": 0.0,
      "step": 33430
    },
    {
      "epoch": 7.166738105443635,
      "grad_norm": 0.000716611510142684,
      "learning_rate": 1.044434919274182e-05,
      "loss": 0.0004,
      "step": 33440
    },
    {
      "epoch": 7.168881268752679,
      "grad_norm": 0.003942796029150486,
      "learning_rate": 1.0441491641663096e-05,
      "loss": 0.0788,
      "step": 33450
    },
    {
      "epoch": 7.171024432061723,
      "grad_norm": 0.0006187730468809605,
      "learning_rate": 1.043863409058437e-05,
      "loss": 0.0067,
      "step": 33460
    },
    {
      "epoch": 7.173167595370767,
      "grad_norm": 0.00037158146733418107,
      "learning_rate": 1.0435776539505644e-05,
      "loss": 0.0006,
      "step": 33470
    },
    {
      "epoch": 7.175310758679811,
      "grad_norm": 40.43635940551758,
      "learning_rate": 1.043291898842692e-05,
      "loss": 0.5582,
      "step": 33480
    },
    {
      "epoch": 7.177453921988856,
      "grad_norm": 0.0005091573693789542,
      "learning_rate": 1.0430061437348193e-05,
      "loss": 0.1312,
      "step": 33490
    },
    {
      "epoch": 7.1795970852979,
      "grad_norm": 0.0028926485683768988,
      "learning_rate": 1.0427203886269467e-05,
      "loss": 0.0002,
      "step": 33500
    },
    {
      "epoch": 7.1817402486069435,
      "grad_norm": 0.011221647262573242,
      "learning_rate": 1.0424346335190743e-05,
      "loss": 0.0001,
      "step": 33510
    },
    {
      "epoch": 7.183883411915988,
      "grad_norm": 0.0005142570589669049,
      "learning_rate": 1.0421488784112017e-05,
      "loss": 0.0001,
      "step": 33520
    },
    {
      "epoch": 7.186026575225032,
      "grad_norm": 0.0005054957582615316,
      "learning_rate": 1.0418631233033292e-05,
      "loss": 0.0001,
      "step": 33530
    },
    {
      "epoch": 7.188169738534076,
      "grad_norm": 0.041206371039152145,
      "learning_rate": 1.0415773681954566e-05,
      "loss": 0.0001,
      "step": 33540
    },
    {
      "epoch": 7.190312901843121,
      "grad_norm": 0.00046461232705041766,
      "learning_rate": 1.041291613087584e-05,
      "loss": 0.1302,
      "step": 33550
    },
    {
      "epoch": 7.1924560651521645,
      "grad_norm": 0.003866772633045912,
      "learning_rate": 1.0410058579797116e-05,
      "loss": 0.0254,
      "step": 33560
    },
    {
      "epoch": 7.194599228461208,
      "grad_norm": 0.0015803433489054441,
      "learning_rate": 1.040720102871839e-05,
      "loss": 0.0,
      "step": 33570
    },
    {
      "epoch": 7.196742391770253,
      "grad_norm": 0.03164568170905113,
      "learning_rate": 1.0404343477639664e-05,
      "loss": 0.0559,
      "step": 33580
    },
    {
      "epoch": 7.198885555079297,
      "grad_norm": 0.008348080329596996,
      "learning_rate": 1.040148592656094e-05,
      "loss": 0.0,
      "step": 33590
    },
    {
      "epoch": 7.201028718388341,
      "grad_norm": 0.0040608979761600494,
      "learning_rate": 1.0398628375482212e-05,
      "loss": 0.1707,
      "step": 33600
    },
    {
      "epoch": 7.2031718816973855,
      "grad_norm": 0.0002497530949767679,
      "learning_rate": 1.0395770824403486e-05,
      "loss": 0.1779,
      "step": 33610
    },
    {
      "epoch": 7.205315045006429,
      "grad_norm": 0.0003481988387648016,
      "learning_rate": 1.0392913273324761e-05,
      "loss": 0.0,
      "step": 33620
    },
    {
      "epoch": 7.207458208315473,
      "grad_norm": 0.21607668697834015,
      "learning_rate": 1.0390055722246035e-05,
      "loss": 0.2406,
      "step": 33630
    },
    {
      "epoch": 7.209601371624518,
      "grad_norm": 0.00030507828341796994,
      "learning_rate": 1.0387198171167309e-05,
      "loss": 0.0004,
      "step": 33640
    },
    {
      "epoch": 7.211744534933562,
      "grad_norm": 0.0002501713752280921,
      "learning_rate": 1.0384340620088585e-05,
      "loss": 0.3627,
      "step": 33650
    },
    {
      "epoch": 7.213887698242606,
      "grad_norm": 0.0073417117819190025,
      "learning_rate": 1.0381483069009859e-05,
      "loss": 0.0003,
      "step": 33660
    },
    {
      "epoch": 7.21603086155165,
      "grad_norm": 0.8145888447761536,
      "learning_rate": 1.0378625517931134e-05,
      "loss": 0.3595,
      "step": 33670
    },
    {
      "epoch": 7.218174024860694,
      "grad_norm": 0.03969152271747589,
      "learning_rate": 1.0375767966852408e-05,
      "loss": 0.0004,
      "step": 33680
    },
    {
      "epoch": 7.220317188169738,
      "grad_norm": 0.009387494996190071,
      "learning_rate": 1.0372910415773682e-05,
      "loss": 0.0114,
      "step": 33690
    },
    {
      "epoch": 7.222460351478783,
      "grad_norm": 0.0057139089331030846,
      "learning_rate": 1.0370052864694958e-05,
      "loss": 0.0004,
      "step": 33700
    },
    {
      "epoch": 7.224603514787827,
      "grad_norm": 0.054044246673583984,
      "learning_rate": 1.0367195313616232e-05,
      "loss": 0.0008,
      "step": 33710
    },
    {
      "epoch": 7.226746678096871,
      "grad_norm": 0.0022175104822963476,
      "learning_rate": 1.0364337762537506e-05,
      "loss": 0.0003,
      "step": 33720
    },
    {
      "epoch": 7.228889841405915,
      "grad_norm": 0.005731422454118729,
      "learning_rate": 1.0361480211458781e-05,
      "loss": 0.0001,
      "step": 33730
    },
    {
      "epoch": 7.231033004714959,
      "grad_norm": 0.0022892719134688377,
      "learning_rate": 1.0358622660380055e-05,
      "loss": 0.0001,
      "step": 33740
    },
    {
      "epoch": 7.233176168024004,
      "grad_norm": 0.04937543347477913,
      "learning_rate": 1.035576510930133e-05,
      "loss": 0.0001,
      "step": 33750
    },
    {
      "epoch": 7.235319331333048,
      "grad_norm": 0.002285387134179473,
      "learning_rate": 1.0352907558222605e-05,
      "loss": 0.0004,
      "step": 33760
    },
    {
      "epoch": 7.237462494642092,
      "grad_norm": 0.017758861184120178,
      "learning_rate": 1.0350050007143879e-05,
      "loss": 0.0008,
      "step": 33770
    },
    {
      "epoch": 7.239605657951136,
      "grad_norm": 0.002533070044592023,
      "learning_rate": 1.0347192456065154e-05,
      "loss": 0.0001,
      "step": 33780
    },
    {
      "epoch": 7.24174882126018,
      "grad_norm": 0.0013361192541196942,
      "learning_rate": 1.0344334904986428e-05,
      "loss": 0.0001,
      "step": 33790
    },
    {
      "epoch": 7.243891984569224,
      "grad_norm": 0.010596797801554203,
      "learning_rate": 1.0341477353907704e-05,
      "loss": 0.0004,
      "step": 33800
    },
    {
      "epoch": 7.246035147878269,
      "grad_norm": 0.0024534522090107203,
      "learning_rate": 1.0338619802828978e-05,
      "loss": 0.1663,
      "step": 33810
    },
    {
      "epoch": 7.248178311187313,
      "grad_norm": 0.0023181666620075703,
      "learning_rate": 1.033576225175025e-05,
      "loss": 0.0001,
      "step": 33820
    },
    {
      "epoch": 7.2503214744963564,
      "grad_norm": 0.003977350890636444,
      "learning_rate": 1.0332904700671524e-05,
      "loss": 0.0,
      "step": 33830
    },
    {
      "epoch": 7.252464637805401,
      "grad_norm": 30.16342544555664,
      "learning_rate": 1.03300471495928e-05,
      "loss": 0.0025,
      "step": 33840
    },
    {
      "epoch": 7.254607801114445,
      "grad_norm": 0.0018840485718101263,
      "learning_rate": 1.0327189598514073e-05,
      "loss": 0.0001,
      "step": 33850
    },
    {
      "epoch": 7.256750964423489,
      "grad_norm": 0.0008577218977734447,
      "learning_rate": 1.0324332047435347e-05,
      "loss": 0.0001,
      "step": 33860
    },
    {
      "epoch": 7.258894127732534,
      "grad_norm": 0.007714000530540943,
      "learning_rate": 1.0321474496356623e-05,
      "loss": 0.0001,
      "step": 33870
    },
    {
      "epoch": 7.2610372910415775,
      "grad_norm": 0.001266614650376141,
      "learning_rate": 1.0318616945277897e-05,
      "loss": 0.0001,
      "step": 33880
    },
    {
      "epoch": 7.263180454350621,
      "grad_norm": 0.002447044011205435,
      "learning_rate": 1.0315759394199172e-05,
      "loss": 0.1873,
      "step": 33890
    },
    {
      "epoch": 7.265323617659666,
      "grad_norm": 0.0010802088072523475,
      "learning_rate": 1.0312901843120446e-05,
      "loss": 0.0001,
      "step": 33900
    },
    {
      "epoch": 7.26746678096871,
      "grad_norm": 0.0007656894740648568,
      "learning_rate": 1.031004429204172e-05,
      "loss": 0.0001,
      "step": 33910
    },
    {
      "epoch": 7.269609944277754,
      "grad_norm": 0.0015634620795026422,
      "learning_rate": 1.0307186740962996e-05,
      "loss": 0.2697,
      "step": 33920
    },
    {
      "epoch": 7.2717531075867985,
      "grad_norm": 0.0038973891641944647,
      "learning_rate": 1.030432918988427e-05,
      "loss": 0.0002,
      "step": 33930
    },
    {
      "epoch": 7.273896270895842,
      "grad_norm": 0.003828511107712984,
      "learning_rate": 1.0301471638805545e-05,
      "loss": 0.0001,
      "step": 33940
    },
    {
      "epoch": 7.276039434204886,
      "grad_norm": 0.0036969268694519997,
      "learning_rate": 1.029861408772682e-05,
      "loss": 0.1507,
      "step": 33950
    },
    {
      "epoch": 7.278182597513931,
      "grad_norm": 0.0031431145034730434,
      "learning_rate": 1.0295756536648093e-05,
      "loss": 0.0008,
      "step": 33960
    },
    {
      "epoch": 7.280325760822975,
      "grad_norm": 0.013379798270761967,
      "learning_rate": 1.0292898985569369e-05,
      "loss": 0.0001,
      "step": 33970
    },
    {
      "epoch": 7.282468924132019,
      "grad_norm": 0.001117431209422648,
      "learning_rate": 1.0290041434490643e-05,
      "loss": 0.0015,
      "step": 33980
    },
    {
      "epoch": 7.284612087441063,
      "grad_norm": 0.0008970066555775702,
      "learning_rate": 1.0287183883411917e-05,
      "loss": 0.0001,
      "step": 33990
    },
    {
      "epoch": 7.286755250750107,
      "grad_norm": 0.002348753623664379,
      "learning_rate": 1.0284326332333192e-05,
      "loss": 0.0,
      "step": 34000
    },
    {
      "epoch": 7.288898414059151,
      "grad_norm": 0.015003225766122341,
      "learning_rate": 1.0281468781254466e-05,
      "loss": 0.2541,
      "step": 34010
    },
    {
      "epoch": 7.291041577368196,
      "grad_norm": 0.04519418254494667,
      "learning_rate": 1.0278611230175742e-05,
      "loss": 0.0012,
      "step": 34020
    },
    {
      "epoch": 7.29318474067724,
      "grad_norm": 0.768852710723877,
      "learning_rate": 1.0275753679097014e-05,
      "loss": 0.0005,
      "step": 34030
    },
    {
      "epoch": 7.2953279039862835,
      "grad_norm": 0.003467854345217347,
      "learning_rate": 1.0272896128018288e-05,
      "loss": 0.0003,
      "step": 34040
    },
    {
      "epoch": 7.297471067295328,
      "grad_norm": 0.0009891573572531343,
      "learning_rate": 1.0270038576939562e-05,
      "loss": 0.0003,
      "step": 34050
    },
    {
      "epoch": 7.299614230604372,
      "grad_norm": 0.0009403880685567856,
      "learning_rate": 1.0267181025860838e-05,
      "loss": 0.0001,
      "step": 34060
    },
    {
      "epoch": 7.301757393913416,
      "grad_norm": 0.0010647180024534464,
      "learning_rate": 1.0264323474782112e-05,
      "loss": 0.2971,
      "step": 34070
    },
    {
      "epoch": 7.303900557222461,
      "grad_norm": 0.0006766794249415398,
      "learning_rate": 1.0261465923703387e-05,
      "loss": 0.1193,
      "step": 34080
    },
    {
      "epoch": 7.3060437205315045,
      "grad_norm": 0.011918839067220688,
      "learning_rate": 1.0258608372624661e-05,
      "loss": 0.0002,
      "step": 34090
    },
    {
      "epoch": 7.308186883840548,
      "grad_norm": 0.0016241399571299553,
      "learning_rate": 1.0255750821545935e-05,
      "loss": 0.1101,
      "step": 34100
    },
    {
      "epoch": 7.310330047149593,
      "grad_norm": 0.0028325736057013273,
      "learning_rate": 1.025289327046721e-05,
      "loss": 0.0157,
      "step": 34110
    },
    {
      "epoch": 7.312473210458637,
      "grad_norm": 0.0024248536210507154,
      "learning_rate": 1.0250035719388485e-05,
      "loss": 0.4518,
      "step": 34120
    },
    {
      "epoch": 7.314616373767681,
      "grad_norm": 0.0005690167308785021,
      "learning_rate": 1.0247178168309759e-05,
      "loss": 0.158,
      "step": 34130
    },
    {
      "epoch": 7.3167595370767256,
      "grad_norm": 0.0007093248423188925,
      "learning_rate": 1.0244320617231034e-05,
      "loss": 0.0001,
      "step": 34140
    },
    {
      "epoch": 7.318902700385769,
      "grad_norm": 0.0005063476273790002,
      "learning_rate": 1.0241463066152308e-05,
      "loss": 0.0002,
      "step": 34150
    },
    {
      "epoch": 7.321045863694813,
      "grad_norm": 0.0011524921283125877,
      "learning_rate": 1.0238605515073584e-05,
      "loss": 0.0005,
      "step": 34160
    },
    {
      "epoch": 7.323189027003858,
      "grad_norm": 0.00230240635573864,
      "learning_rate": 1.0235747963994858e-05,
      "loss": 0.2059,
      "step": 34170
    },
    {
      "epoch": 7.325332190312902,
      "grad_norm": 0.0025039049796760082,
      "learning_rate": 1.0232890412916132e-05,
      "loss": 0.0001,
      "step": 34180
    },
    {
      "epoch": 7.327475353621946,
      "grad_norm": 0.0005478966049849987,
      "learning_rate": 1.0230032861837407e-05,
      "loss": 0.0002,
      "step": 34190
    },
    {
      "epoch": 7.32961851693099,
      "grad_norm": 0.08798721432685852,
      "learning_rate": 1.0227175310758681e-05,
      "loss": 0.0026,
      "step": 34200
    },
    {
      "epoch": 7.331761680240034,
      "grad_norm": 0.0006159296026453376,
      "learning_rate": 1.0224317759679955e-05,
      "loss": 0.1447,
      "step": 34210
    },
    {
      "epoch": 7.333904843549078,
      "grad_norm": 0.0007391694816760719,
      "learning_rate": 1.022146020860123e-05,
      "loss": 0.0004,
      "step": 34220
    },
    {
      "epoch": 7.336048006858123,
      "grad_norm": 0.00029731058748438954,
      "learning_rate": 1.0218602657522505e-05,
      "loss": 0.0002,
      "step": 34230
    },
    {
      "epoch": 7.338191170167167,
      "grad_norm": 0.0044092824682593346,
      "learning_rate": 1.021574510644378e-05,
      "loss": 0.2135,
      "step": 34240
    },
    {
      "epoch": 7.340334333476211,
      "grad_norm": 0.0022030107211321592,
      "learning_rate": 1.0212887555365053e-05,
      "loss": 0.0009,
      "step": 34250
    },
    {
      "epoch": 7.342477496785255,
      "grad_norm": 0.0017501999391242862,
      "learning_rate": 1.0210030004286326e-05,
      "loss": 0.0001,
      "step": 34260
    },
    {
      "epoch": 7.344620660094299,
      "grad_norm": 0.007608558516949415,
      "learning_rate": 1.02071724532076e-05,
      "loss": 0.0003,
      "step": 34270
    },
    {
      "epoch": 7.346763823403343,
      "grad_norm": 0.0004027190734632313,
      "learning_rate": 1.0204314902128876e-05,
      "loss": 0.0001,
      "step": 34280
    },
    {
      "epoch": 7.348906986712388,
      "grad_norm": 0.00036414439091458917,
      "learning_rate": 1.020145735105015e-05,
      "loss": 0.0386,
      "step": 34290
    },
    {
      "epoch": 7.351050150021432,
      "grad_norm": 0.000286640104604885,
      "learning_rate": 1.0198599799971426e-05,
      "loss": 0.1784,
      "step": 34300
    },
    {
      "epoch": 7.353193313330475,
      "grad_norm": 0.006977705750614405,
      "learning_rate": 1.01957422488927e-05,
      "loss": 0.0001,
      "step": 34310
    },
    {
      "epoch": 7.35533647663952,
      "grad_norm": 0.00025440080207772553,
      "learning_rate": 1.0192884697813973e-05,
      "loss": 0.0004,
      "step": 34320
    },
    {
      "epoch": 7.357479639948564,
      "grad_norm": 0.0003505687927827239,
      "learning_rate": 1.0190027146735249e-05,
      "loss": 0.0,
      "step": 34330
    },
    {
      "epoch": 7.359622803257608,
      "grad_norm": 0.0003130151308141649,
      "learning_rate": 1.0187169595656523e-05,
      "loss": 0.0001,
      "step": 34340
    },
    {
      "epoch": 7.361765966566653,
      "grad_norm": 0.000250871671596542,
      "learning_rate": 1.0184312044577797e-05,
      "loss": 0.132,
      "step": 34350
    },
    {
      "epoch": 7.3639091298756965,
      "grad_norm": 0.00032766969525255263,
      "learning_rate": 1.0181454493499072e-05,
      "loss": 0.0001,
      "step": 34360
    },
    {
      "epoch": 7.36605229318474,
      "grad_norm": 0.0003155636368319392,
      "learning_rate": 1.0178596942420346e-05,
      "loss": 0.0033,
      "step": 34370
    },
    {
      "epoch": 7.368195456493785,
      "grad_norm": 0.0008286961237899959,
      "learning_rate": 1.0175739391341622e-05,
      "loss": 0.0001,
      "step": 34380
    },
    {
      "epoch": 7.370338619802829,
      "grad_norm": 0.00041370344115421176,
      "learning_rate": 1.0172881840262896e-05,
      "loss": 0.0001,
      "step": 34390
    },
    {
      "epoch": 7.372481783111873,
      "grad_norm": 0.00038636871613562107,
      "learning_rate": 1.017002428918417e-05,
      "loss": 0.1663,
      "step": 34400
    },
    {
      "epoch": 7.3746249464209175,
      "grad_norm": 0.0038014936726540327,
      "learning_rate": 1.0167166738105446e-05,
      "loss": 0.0,
      "step": 34410
    },
    {
      "epoch": 7.376768109729961,
      "grad_norm": 0.0005723881185986102,
      "learning_rate": 1.016430918702672e-05,
      "loss": 0.0,
      "step": 34420
    },
    {
      "epoch": 7.378911273039005,
      "grad_norm": 0.0014912126353010535,
      "learning_rate": 1.0161451635947993e-05,
      "loss": 0.0,
      "step": 34430
    },
    {
      "epoch": 7.38105443634805,
      "grad_norm": 0.003267513820901513,
      "learning_rate": 1.0158594084869269e-05,
      "loss": 0.0,
      "step": 34440
    },
    {
      "epoch": 7.383197599657094,
      "grad_norm": 113.48955535888672,
      "learning_rate": 1.0155736533790543e-05,
      "loss": 0.2959,
      "step": 34450
    },
    {
      "epoch": 7.385340762966138,
      "grad_norm": 0.0002476372756063938,
      "learning_rate": 1.0152878982711815e-05,
      "loss": 0.0,
      "step": 34460
    },
    {
      "epoch": 7.387483926275182,
      "grad_norm": 0.20726333558559418,
      "learning_rate": 1.015002143163309e-05,
      "loss": 0.2422,
      "step": 34470
    },
    {
      "epoch": 7.389627089584226,
      "grad_norm": 0.006713658105581999,
      "learning_rate": 1.0147163880554365e-05,
      "loss": 0.1337,
      "step": 34480
    },
    {
      "epoch": 7.39177025289327,
      "grad_norm": 0.0003671355952974409,
      "learning_rate": 1.0144306329475639e-05,
      "loss": 0.0,
      "step": 34490
    },
    {
      "epoch": 7.393913416202315,
      "grad_norm": 0.00042554314131848514,
      "learning_rate": 1.0141448778396914e-05,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 7.396056579511359,
      "grad_norm": 34.8253288269043,
      "learning_rate": 1.0138591227318188e-05,
      "loss": 0.2774,
      "step": 34510
    },
    {
      "epoch": 7.3981997428204025,
      "grad_norm": 0.0005153438542038202,
      "learning_rate": 1.0135733676239464e-05,
      "loss": 0.0,
      "step": 34520
    },
    {
      "epoch": 7.400342906129447,
      "grad_norm": 0.0005786703550256789,
      "learning_rate": 1.0132876125160738e-05,
      "loss": 0.0001,
      "step": 34530
    },
    {
      "epoch": 7.402486069438491,
      "grad_norm": 0.016190312802791595,
      "learning_rate": 1.0130018574082012e-05,
      "loss": 0.0003,
      "step": 34540
    },
    {
      "epoch": 7.404629232747535,
      "grad_norm": 0.0010777735151350498,
      "learning_rate": 1.0127161023003287e-05,
      "loss": 0.0001,
      "step": 34550
    },
    {
      "epoch": 7.40677239605658,
      "grad_norm": 0.0009584680665284395,
      "learning_rate": 1.0124303471924561e-05,
      "loss": 0.0006,
      "step": 34560
    },
    {
      "epoch": 7.4089155593656235,
      "grad_norm": 0.0011769977863878012,
      "learning_rate": 1.0121445920845835e-05,
      "loss": 0.0,
      "step": 34570
    },
    {
      "epoch": 7.411058722674667,
      "grad_norm": 0.0016416007420048118,
      "learning_rate": 1.011858836976711e-05,
      "loss": 0.0001,
      "step": 34580
    },
    {
      "epoch": 7.413201885983712,
      "grad_norm": 0.0007256086682900786,
      "learning_rate": 1.0115730818688385e-05,
      "loss": 0.0001,
      "step": 34590
    },
    {
      "epoch": 7.415345049292756,
      "grad_norm": 0.0014738833997398615,
      "learning_rate": 1.011287326760966e-05,
      "loss": 0.1408,
      "step": 34600
    },
    {
      "epoch": 7.4174882126018,
      "grad_norm": 0.0019974405877292156,
      "learning_rate": 1.0110015716530934e-05,
      "loss": 0.0004,
      "step": 34610
    },
    {
      "epoch": 7.4196313759108445,
      "grad_norm": 0.0027988471556454897,
      "learning_rate": 1.0107158165452208e-05,
      "loss": 0.0033,
      "step": 34620
    },
    {
      "epoch": 7.421774539219888,
      "grad_norm": 0.002035232726484537,
      "learning_rate": 1.0104300614373484e-05,
      "loss": 0.1406,
      "step": 34630
    },
    {
      "epoch": 7.423917702528932,
      "grad_norm": 0.0011271836701780558,
      "learning_rate": 1.0101443063294758e-05,
      "loss": 0.237,
      "step": 34640
    },
    {
      "epoch": 7.426060865837977,
      "grad_norm": 0.000341112696332857,
      "learning_rate": 1.0098585512216033e-05,
      "loss": 0.0003,
      "step": 34650
    },
    {
      "epoch": 7.428204029147021,
      "grad_norm": 0.0017780893249437213,
      "learning_rate": 1.0095727961137307e-05,
      "loss": 0.1489,
      "step": 34660
    },
    {
      "epoch": 7.430347192456066,
      "grad_norm": 0.00040997337782755494,
      "learning_rate": 1.0092870410058581e-05,
      "loss": 0.0,
      "step": 34670
    },
    {
      "epoch": 7.432490355765109,
      "grad_norm": 0.0003822589642368257,
      "learning_rate": 1.0090012858979853e-05,
      "loss": 0.1276,
      "step": 34680
    },
    {
      "epoch": 7.434633519074153,
      "grad_norm": 0.004738711751997471,
      "learning_rate": 1.0087155307901129e-05,
      "loss": 0.0003,
      "step": 34690
    },
    {
      "epoch": 7.436776682383198,
      "grad_norm": 0.01313400361686945,
      "learning_rate": 1.0084297756822403e-05,
      "loss": 0.3659,
      "step": 34700
    },
    {
      "epoch": 7.438919845692242,
      "grad_norm": 0.0034088497050106525,
      "learning_rate": 1.0081440205743677e-05,
      "loss": 0.0002,
      "step": 34710
    },
    {
      "epoch": 7.441063009001286,
      "grad_norm": 0.01121764536947012,
      "learning_rate": 1.0078582654664953e-05,
      "loss": 0.0002,
      "step": 34720
    },
    {
      "epoch": 7.44320617231033,
      "grad_norm": 0.014719752594828606,
      "learning_rate": 1.0075725103586226e-05,
      "loss": 0.0002,
      "step": 34730
    },
    {
      "epoch": 7.445349335619374,
      "grad_norm": 0.006215329747647047,
      "learning_rate": 1.0072867552507502e-05,
      "loss": 0.0002,
      "step": 34740
    },
    {
      "epoch": 7.447492498928418,
      "grad_norm": 0.26953861117362976,
      "learning_rate": 1.0070010001428776e-05,
      "loss": 0.0004,
      "step": 34750
    },
    {
      "epoch": 7.449635662237463,
      "grad_norm": 0.005774669349193573,
      "learning_rate": 1.006715245035005e-05,
      "loss": 0.0001,
      "step": 34760
    },
    {
      "epoch": 7.451778825546507,
      "grad_norm": 0.008007104508578777,
      "learning_rate": 1.0064294899271326e-05,
      "loss": 0.0002,
      "step": 34770
    },
    {
      "epoch": 7.453921988855551,
      "grad_norm": 0.0012758646626025438,
      "learning_rate": 1.00614373481926e-05,
      "loss": 0.0007,
      "step": 34780
    },
    {
      "epoch": 7.456065152164595,
      "grad_norm": 0.0011716008884832263,
      "learning_rate": 1.0058579797113875e-05,
      "loss": 0.0003,
      "step": 34790
    },
    {
      "epoch": 7.458208315473639,
      "grad_norm": 0.004671760369092226,
      "learning_rate": 1.0055722246035149e-05,
      "loss": 0.1265,
      "step": 34800
    },
    {
      "epoch": 7.460351478782683,
      "grad_norm": 0.0016686376184225082,
      "learning_rate": 1.0052864694956423e-05,
      "loss": 0.0,
      "step": 34810
    },
    {
      "epoch": 7.462494642091728,
      "grad_norm": 0.024418849498033524,
      "learning_rate": 1.0050007143877699e-05,
      "loss": 0.0004,
      "step": 34820
    },
    {
      "epoch": 7.464637805400772,
      "grad_norm": 0.0012764465063810349,
      "learning_rate": 1.0047149592798973e-05,
      "loss": 0.0002,
      "step": 34830
    },
    {
      "epoch": 7.4667809687098154,
      "grad_norm": 0.002019515261054039,
      "learning_rate": 1.0044292041720246e-05,
      "loss": 0.0001,
      "step": 34840
    },
    {
      "epoch": 7.46892413201886,
      "grad_norm": 0.024092145264148712,
      "learning_rate": 1.0041434490641522e-05,
      "loss": 0.0002,
      "step": 34850
    },
    {
      "epoch": 7.471067295327904,
      "grad_norm": 0.01106063649058342,
      "learning_rate": 1.0038576939562796e-05,
      "loss": 0.0041,
      "step": 34860
    },
    {
      "epoch": 7.473210458636948,
      "grad_norm": 0.008004352450370789,
      "learning_rate": 1.0035719388484072e-05,
      "loss": 0.5805,
      "step": 34870
    },
    {
      "epoch": 7.475353621945993,
      "grad_norm": 0.0011724154464900494,
      "learning_rate": 1.0032861837405346e-05,
      "loss": 0.0057,
      "step": 34880
    },
    {
      "epoch": 7.4774967852550365,
      "grad_norm": 0.0030629471875727177,
      "learning_rate": 1.0030004286326618e-05,
      "loss": 0.0003,
      "step": 34890
    },
    {
      "epoch": 7.47963994856408,
      "grad_norm": 0.0022251044865697622,
      "learning_rate": 1.0027146735247892e-05,
      "loss": 0.0001,
      "step": 34900
    },
    {
      "epoch": 7.481783111873125,
      "grad_norm": 0.0016882548807188869,
      "learning_rate": 1.0024289184169167e-05,
      "loss": 0.0001,
      "step": 34910
    },
    {
      "epoch": 7.483926275182169,
      "grad_norm": 0.00153874303214252,
      "learning_rate": 1.0021431633090441e-05,
      "loss": 0.0,
      "step": 34920
    },
    {
      "epoch": 7.486069438491213,
      "grad_norm": 0.03569332882761955,
      "learning_rate": 1.0018574082011717e-05,
      "loss": 0.0001,
      "step": 34930
    },
    {
      "epoch": 7.4882126018002575,
      "grad_norm": 0.0008207475766539574,
      "learning_rate": 1.001571653093299e-05,
      "loss": 0.0,
      "step": 34940
    },
    {
      "epoch": 7.490355765109301,
      "grad_norm": 0.024142881855368614,
      "learning_rate": 1.0012858979854265e-05,
      "loss": 0.0001,
      "step": 34950
    },
    {
      "epoch": 7.492498928418345,
      "grad_norm": 0.0011770881246775389,
      "learning_rate": 1.001000142877554e-05,
      "loss": 0.0012,
      "step": 34960
    },
    {
      "epoch": 7.49464209172739,
      "grad_norm": 0.0012732668546959758,
      "learning_rate": 1.0007143877696814e-05,
      "loss": 0.0,
      "step": 34970
    },
    {
      "epoch": 7.496785255036434,
      "grad_norm": 0.0023887711577117443,
      "learning_rate": 1.0004286326618088e-05,
      "loss": 0.0005,
      "step": 34980
    },
    {
      "epoch": 7.498928418345478,
      "grad_norm": 0.004960122983902693,
      "learning_rate": 1.0001428775539364e-05,
      "loss": 0.0001,
      "step": 34990
    },
    {
      "epoch": 7.501071581654522,
      "grad_norm": 0.013112839311361313,
      "learning_rate": 9.998571224460638e-06,
      "loss": 0.002,
      "step": 35000
    },
    {
      "epoch": 7.503214744963566,
      "grad_norm": 0.0015967708313837647,
      "learning_rate": 9.995713673381913e-06,
      "loss": 0.0,
      "step": 35010
    },
    {
      "epoch": 7.50535790827261,
      "grad_norm": 0.0005570233915932477,
      "learning_rate": 9.992856122303187e-06,
      "loss": 0.0001,
      "step": 35020
    },
    {
      "epoch": 7.507501071581655,
      "grad_norm": 0.0008225567871704698,
      "learning_rate": 9.989998571224461e-06,
      "loss": 0.236,
      "step": 35030
    },
    {
      "epoch": 7.509644234890699,
      "grad_norm": 0.0033447474706918,
      "learning_rate": 9.987141020145737e-06,
      "loss": 0.0002,
      "step": 35040
    },
    {
      "epoch": 7.5117873981997425,
      "grad_norm": 0.014702319167554379,
      "learning_rate": 9.984283469067009e-06,
      "loss": 0.0106,
      "step": 35050
    },
    {
      "epoch": 7.513930561508787,
      "grad_norm": 1944.1131591796875,
      "learning_rate": 9.981425917988285e-06,
      "loss": 0.055,
      "step": 35060
    },
    {
      "epoch": 7.516073724817831,
      "grad_norm": 0.0008048081654123962,
      "learning_rate": 9.978568366909559e-06,
      "loss": 0.0001,
      "step": 35070
    },
    {
      "epoch": 7.518216888126875,
      "grad_norm": 73.3006820678711,
      "learning_rate": 9.975710815830834e-06,
      "loss": 0.3806,
      "step": 35080
    },
    {
      "epoch": 7.52036005143592,
      "grad_norm": 0.0008569313213229179,
      "learning_rate": 9.972853264752108e-06,
      "loss": 0.0133,
      "step": 35090
    },
    {
      "epoch": 7.5225032147449635,
      "grad_norm": 23.747352600097656,
      "learning_rate": 9.969995713673382e-06,
      "loss": 0.4817,
      "step": 35100
    },
    {
      "epoch": 7.524646378054007,
      "grad_norm": 0.0022977220360189676,
      "learning_rate": 9.967138162594658e-06,
      "loss": 0.0,
      "step": 35110
    },
    {
      "epoch": 7.526789541363052,
      "grad_norm": 0.0015527112409472466,
      "learning_rate": 9.964280611515932e-06,
      "loss": 0.2259,
      "step": 35120
    },
    {
      "epoch": 7.528932704672096,
      "grad_norm": 0.006973941810429096,
      "learning_rate": 9.961423060437206e-06,
      "loss": 0.2689,
      "step": 35130
    },
    {
      "epoch": 7.53107586798114,
      "grad_norm": 0.0040577915497124195,
      "learning_rate": 9.958565509358481e-06,
      "loss": 0.2407,
      "step": 35140
    },
    {
      "epoch": 7.5332190312901846,
      "grad_norm": 0.010996912606060505,
      "learning_rate": 9.955707958279755e-06,
      "loss": 0.0006,
      "step": 35150
    },
    {
      "epoch": 7.535362194599228,
      "grad_norm": 0.001690288307145238,
      "learning_rate": 9.952850407201029e-06,
      "loss": 0.0002,
      "step": 35160
    },
    {
      "epoch": 7.537505357908272,
      "grad_norm": 0.0030050005298107862,
      "learning_rate": 9.949992856122303e-06,
      "loss": 0.25,
      "step": 35170
    },
    {
      "epoch": 7.539648521217317,
      "grad_norm": 0.003176476340740919,
      "learning_rate": 9.947135305043579e-06,
      "loss": 0.0001,
      "step": 35180
    },
    {
      "epoch": 7.541791684526361,
      "grad_norm": 0.001110915094614029,
      "learning_rate": 9.944277753964853e-06,
      "loss": 0.0002,
      "step": 35190
    },
    {
      "epoch": 7.543934847835405,
      "grad_norm": 0.0012543873162940145,
      "learning_rate": 9.941420202886127e-06,
      "loss": 0.0016,
      "step": 35200
    },
    {
      "epoch": 7.546078011144449,
      "grad_norm": 0.0019012422999367118,
      "learning_rate": 9.938562651807402e-06,
      "loss": 0.0002,
      "step": 35210
    },
    {
      "epoch": 7.548221174453493,
      "grad_norm": 0.0021318045910447836,
      "learning_rate": 9.935705100728676e-06,
      "loss": 0.0003,
      "step": 35220
    },
    {
      "epoch": 7.550364337762537,
      "grad_norm": 0.009250344708561897,
      "learning_rate": 9.932847549649952e-06,
      "loss": 0.0001,
      "step": 35230
    },
    {
      "epoch": 7.552507501071582,
      "grad_norm": 0.0014299997128546238,
      "learning_rate": 9.929989998571226e-06,
      "loss": 0.0001,
      "step": 35240
    },
    {
      "epoch": 7.554650664380626,
      "grad_norm": 0.1958019882440567,
      "learning_rate": 9.9271324474925e-06,
      "loss": 0.0005,
      "step": 35250
    },
    {
      "epoch": 7.5567938276896705,
      "grad_norm": 0.008631560951471329,
      "learning_rate": 9.924274896413775e-06,
      "loss": 0.3412,
      "step": 35260
    },
    {
      "epoch": 7.558936990998714,
      "grad_norm": 0.007264937274158001,
      "learning_rate": 9.921417345335047e-06,
      "loss": 0.0004,
      "step": 35270
    },
    {
      "epoch": 7.561080154307758,
      "grad_norm": 0.007964755408465862,
      "learning_rate": 9.918559794256323e-06,
      "loss": 0.0003,
      "step": 35280
    },
    {
      "epoch": 7.563223317616803,
      "grad_norm": 0.0027947919443249702,
      "learning_rate": 9.915702243177597e-06,
      "loss": 0.1773,
      "step": 35290
    },
    {
      "epoch": 7.565366480925847,
      "grad_norm": 0.005234041251242161,
      "learning_rate": 9.912844692098873e-06,
      "loss": 0.0003,
      "step": 35300
    },
    {
      "epoch": 7.567509644234891,
      "grad_norm": 0.0064231320284307,
      "learning_rate": 9.909987141020146e-06,
      "loss": 0.2112,
      "step": 35310
    },
    {
      "epoch": 7.569652807543935,
      "grad_norm": 0.00782160647213459,
      "learning_rate": 9.90712958994142e-06,
      "loss": 0.1262,
      "step": 35320
    },
    {
      "epoch": 7.571795970852979,
      "grad_norm": 0.003330359235405922,
      "learning_rate": 9.904272038862696e-06,
      "loss": 0.0019,
      "step": 35330
    },
    {
      "epoch": 7.573939134162023,
      "grad_norm": 0.0026380205526947975,
      "learning_rate": 9.90141448778397e-06,
      "loss": 0.0004,
      "step": 35340
    },
    {
      "epoch": 7.576082297471068,
      "grad_norm": 0.0027584987692534924,
      "learning_rate": 9.898556936705246e-06,
      "loss": 0.0001,
      "step": 35350
    },
    {
      "epoch": 7.578225460780112,
      "grad_norm": 0.0044750915840268135,
      "learning_rate": 9.89569938562652e-06,
      "loss": 0.0002,
      "step": 35360
    },
    {
      "epoch": 7.5803686240891555,
      "grad_norm": 0.0051748305559158325,
      "learning_rate": 9.892841834547793e-06,
      "loss": 0.0001,
      "step": 35370
    },
    {
      "epoch": 7.5825117873982,
      "grad_norm": 0.011857062578201294,
      "learning_rate": 9.889984283469067e-06,
      "loss": 0.0001,
      "step": 35380
    },
    {
      "epoch": 7.584654950707244,
      "grad_norm": 0.002360772807151079,
      "learning_rate": 9.887126732390341e-06,
      "loss": 0.1575,
      "step": 35390
    },
    {
      "epoch": 7.586798114016288,
      "grad_norm": 0.004885315429419279,
      "learning_rate": 9.884269181311617e-06,
      "loss": 0.0211,
      "step": 35400
    },
    {
      "epoch": 7.588941277325333,
      "grad_norm": 0.0029323927592486143,
      "learning_rate": 9.881411630232891e-06,
      "loss": 0.1709,
      "step": 35410
    },
    {
      "epoch": 7.5910844406343765,
      "grad_norm": 0.07527729868888855,
      "learning_rate": 9.878554079154166e-06,
      "loss": 0.2462,
      "step": 35420
    },
    {
      "epoch": 7.59322760394342,
      "grad_norm": 0.003542747814208269,
      "learning_rate": 9.87569652807544e-06,
      "loss": 0.3355,
      "step": 35430
    },
    {
      "epoch": 7.595370767252465,
      "grad_norm": 0.003690986894071102,
      "learning_rate": 9.872838976996714e-06,
      "loss": 0.002,
      "step": 35440
    },
    {
      "epoch": 7.597513930561509,
      "grad_norm": 0.035626474767923355,
      "learning_rate": 9.86998142591799e-06,
      "loss": 0.0728,
      "step": 35450
    },
    {
      "epoch": 7.599657093870553,
      "grad_norm": 0.0013008919777348638,
      "learning_rate": 9.867123874839264e-06,
      "loss": 0.1085,
      "step": 35460
    },
    {
      "epoch": 7.6018002571795975,
      "grad_norm": 0.010260464623570442,
      "learning_rate": 9.864266323760538e-06,
      "loss": 0.0495,
      "step": 35470
    },
    {
      "epoch": 7.603943420488641,
      "grad_norm": 0.018022820353507996,
      "learning_rate": 9.861408772681812e-06,
      "loss": 0.0002,
      "step": 35480
    },
    {
      "epoch": 7.606086583797685,
      "grad_norm": 0.002999410731717944,
      "learning_rate": 9.858551221603087e-06,
      "loss": 0.0001,
      "step": 35490
    },
    {
      "epoch": 7.60822974710673,
      "grad_norm": 0.004316686652600765,
      "learning_rate": 9.855693670524361e-06,
      "loss": 0.0002,
      "step": 35500
    },
    {
      "epoch": 7.610372910415774,
      "grad_norm": 0.002285924507305026,
      "learning_rate": 9.852836119445635e-06,
      "loss": 0.0002,
      "step": 35510
    },
    {
      "epoch": 7.612516073724818,
      "grad_norm": 0.0020149494521319866,
      "learning_rate": 9.849978568366911e-06,
      "loss": 0.0001,
      "step": 35520
    },
    {
      "epoch": 7.614659237033862,
      "grad_norm": 0.003961320035159588,
      "learning_rate": 9.847121017288185e-06,
      "loss": 0.0001,
      "step": 35530
    },
    {
      "epoch": 7.616802400342906,
      "grad_norm": 0.009149057790637016,
      "learning_rate": 9.844263466209459e-06,
      "loss": 0.3256,
      "step": 35540
    },
    {
      "epoch": 7.61894556365195,
      "grad_norm": 0.007747224532067776,
      "learning_rate": 9.841405915130734e-06,
      "loss": 0.0055,
      "step": 35550
    },
    {
      "epoch": 7.621088726960995,
      "grad_norm": 0.00411294586956501,
      "learning_rate": 9.838548364052008e-06,
      "loss": 0.2703,
      "step": 35560
    },
    {
      "epoch": 7.623231890270039,
      "grad_norm": 0.023163646459579468,
      "learning_rate": 9.835690812973284e-06,
      "loss": 0.2915,
      "step": 35570
    },
    {
      "epoch": 7.6253750535790825,
      "grad_norm": 25.698278427124023,
      "learning_rate": 9.832833261894558e-06,
      "loss": 0.8039,
      "step": 35580
    },
    {
      "epoch": 7.627518216888127,
      "grad_norm": 0.030353069305419922,
      "learning_rate": 9.829975710815832e-06,
      "loss": 0.0008,
      "step": 35590
    },
    {
      "epoch": 7.629661380197171,
      "grad_norm": 0.043753206729888916,
      "learning_rate": 9.827118159737106e-06,
      "loss": 0.0008,
      "step": 35600
    },
    {
      "epoch": 7.631804543506215,
      "grad_norm": 0.025750907137989998,
      "learning_rate": 9.82426060865838e-06,
      "loss": 0.0012,
      "step": 35610
    },
    {
      "epoch": 7.63394770681526,
      "grad_norm": 95.82801055908203,
      "learning_rate": 9.821403057579655e-06,
      "loss": 0.1098,
      "step": 35620
    },
    {
      "epoch": 7.6360908701243035,
      "grad_norm": 0.07351180911064148,
      "learning_rate": 9.818545506500929e-06,
      "loss": 0.0004,
      "step": 35630
    },
    {
      "epoch": 7.638234033433347,
      "grad_norm": 0.021087760105729103,
      "learning_rate": 9.815687955422205e-06,
      "loss": 0.2171,
      "step": 35640
    },
    {
      "epoch": 7.640377196742392,
      "grad_norm": 0.006928499788045883,
      "learning_rate": 9.812830404343479e-06,
      "loss": 0.0004,
      "step": 35650
    },
    {
      "epoch": 7.642520360051436,
      "grad_norm": 0.0040703099220991135,
      "learning_rate": 9.809972853264753e-06,
      "loss": 0.0002,
      "step": 35660
    },
    {
      "epoch": 7.64466352336048,
      "grad_norm": 0.01694195345044136,
      "learning_rate": 9.807115302186028e-06,
      "loss": 0.1118,
      "step": 35670
    },
    {
      "epoch": 7.646806686669525,
      "grad_norm": 0.0043350206688046455,
      "learning_rate": 9.804257751107302e-06,
      "loss": 0.0004,
      "step": 35680
    },
    {
      "epoch": 7.648949849978568,
      "grad_norm": 0.004387660417705774,
      "learning_rate": 9.801400200028576e-06,
      "loss": 0.0107,
      "step": 35690
    },
    {
      "epoch": 7.651093013287612,
      "grad_norm": 0.9158481359481812,
      "learning_rate": 9.79854264894985e-06,
      "loss": 0.107,
      "step": 35700
    },
    {
      "epoch": 7.653236176596657,
      "grad_norm": 0.6676890254020691,
      "learning_rate": 9.795685097871126e-06,
      "loss": 0.1474,
      "step": 35710
    },
    {
      "epoch": 7.655379339905701,
      "grad_norm": 39.1517219543457,
      "learning_rate": 9.7928275467924e-06,
      "loss": 0.2051,
      "step": 35720
    },
    {
      "epoch": 7.657522503214745,
      "grad_norm": 0.4983203709125519,
      "learning_rate": 9.789969995713674e-06,
      "loss": 0.0003,
      "step": 35730
    },
    {
      "epoch": 7.659665666523789,
      "grad_norm": 0.0035839646589010954,
      "learning_rate": 9.787112444634949e-06,
      "loss": 0.0224,
      "step": 35740
    },
    {
      "epoch": 7.661808829832833,
      "grad_norm": 0.002881609369069338,
      "learning_rate": 9.784254893556223e-06,
      "loss": 0.2922,
      "step": 35750
    },
    {
      "epoch": 7.663951993141877,
      "grad_norm": 0.004488775040954351,
      "learning_rate": 9.781397342477497e-06,
      "loss": 0.0001,
      "step": 35760
    },
    {
      "epoch": 7.666095156450922,
      "grad_norm": 0.005935145542025566,
      "learning_rate": 9.778539791398773e-06,
      "loss": 0.0001,
      "step": 35770
    },
    {
      "epoch": 7.668238319759966,
      "grad_norm": 0.0044313035905361176,
      "learning_rate": 9.775682240320047e-06,
      "loss": 0.0002,
      "step": 35780
    },
    {
      "epoch": 7.67038148306901,
      "grad_norm": 0.010118083097040653,
      "learning_rate": 9.772824689241322e-06,
      "loss": 0.0793,
      "step": 35790
    },
    {
      "epoch": 7.672524646378054,
      "grad_norm": 0.007017975673079491,
      "learning_rate": 9.769967138162596e-06,
      "loss": 0.2189,
      "step": 35800
    },
    {
      "epoch": 7.674667809687098,
      "grad_norm": 0.00532933883368969,
      "learning_rate": 9.76710958708387e-06,
      "loss": 0.0003,
      "step": 35810
    },
    {
      "epoch": 7.676810972996142,
      "grad_norm": 0.014084389433264732,
      "learning_rate": 9.764252036005144e-06,
      "loss": 0.1855,
      "step": 35820
    },
    {
      "epoch": 7.678954136305187,
      "grad_norm": 0.06768857687711716,
      "learning_rate": 9.761394484926418e-06,
      "loss": 0.3299,
      "step": 35830
    },
    {
      "epoch": 7.681097299614231,
      "grad_norm": 0.005652259103953838,
      "learning_rate": 9.758536933847693e-06,
      "loss": 0.0488,
      "step": 35840
    },
    {
      "epoch": 7.6832404629232744,
      "grad_norm": 0.017345493659377098,
      "learning_rate": 9.755679382768967e-06,
      "loss": 0.0002,
      "step": 35850
    },
    {
      "epoch": 7.685383626232319,
      "grad_norm": 0.002427781466394663,
      "learning_rate": 9.752821831690243e-06,
      "loss": 0.0003,
      "step": 35860
    },
    {
      "epoch": 7.687526789541363,
      "grad_norm": 0.0013439368922263384,
      "learning_rate": 9.749964280611517e-06,
      "loss": 0.0001,
      "step": 35870
    },
    {
      "epoch": 7.689669952850407,
      "grad_norm": 0.0009341547265648842,
      "learning_rate": 9.747106729532791e-06,
      "loss": 0.0002,
      "step": 35880
    },
    {
      "epoch": 7.691813116159452,
      "grad_norm": 0.00825961772352457,
      "learning_rate": 9.744249178454067e-06,
      "loss": 0.0003,
      "step": 35890
    },
    {
      "epoch": 7.6939562794684955,
      "grad_norm": 19.26255989074707,
      "learning_rate": 9.74139162737534e-06,
      "loss": 0.2882,
      "step": 35900
    },
    {
      "epoch": 7.696099442777539,
      "grad_norm": 0.003048356156796217,
      "learning_rate": 9.738534076296614e-06,
      "loss": 0.0001,
      "step": 35910
    },
    {
      "epoch": 7.698242606086584,
      "grad_norm": 0.008901357650756836,
      "learning_rate": 9.735676525217888e-06,
      "loss": 0.2726,
      "step": 35920
    },
    {
      "epoch": 7.700385769395628,
      "grad_norm": 0.011431362479925156,
      "learning_rate": 9.732818974139164e-06,
      "loss": 0.0003,
      "step": 35930
    },
    {
      "epoch": 7.702528932704672,
      "grad_norm": 0.025084281340241432,
      "learning_rate": 9.729961423060438e-06,
      "loss": 0.1237,
      "step": 35940
    },
    {
      "epoch": 7.7046720960137165,
      "grad_norm": 0.008821284398436546,
      "learning_rate": 9.727103871981712e-06,
      "loss": 0.0001,
      "step": 35950
    },
    {
      "epoch": 7.70681525932276,
      "grad_norm": 0.010443841107189655,
      "learning_rate": 9.724246320902987e-06,
      "loss": 0.0008,
      "step": 35960
    },
    {
      "epoch": 7.708958422631804,
      "grad_norm": 0.2621484398841858,
      "learning_rate": 9.721388769824261e-06,
      "loss": 0.0006,
      "step": 35970
    },
    {
      "epoch": 7.711101585940849,
      "grad_norm": 0.0036104265600442886,
      "learning_rate": 9.718531218745535e-06,
      "loss": 0.0001,
      "step": 35980
    },
    {
      "epoch": 7.713244749249893,
      "grad_norm": 0.008981190621852875,
      "learning_rate": 9.715673667666811e-06,
      "loss": 0.0419,
      "step": 35990
    },
    {
      "epoch": 7.715387912558937,
      "grad_norm": 0.00631090858951211,
      "learning_rate": 9.712816116588085e-06,
      "loss": 0.0003,
      "step": 36000
    },
    {
      "epoch": 7.717531075867981,
      "grad_norm": 0.22267185151576996,
      "learning_rate": 9.70995856550936e-06,
      "loss": 0.2324,
      "step": 36010
    },
    {
      "epoch": 7.719674239177025,
      "grad_norm": 0.003849960630759597,
      "learning_rate": 9.707101014430633e-06,
      "loss": 0.0001,
      "step": 36020
    },
    {
      "epoch": 7.721817402486069,
      "grad_norm": 0.0009506916394457221,
      "learning_rate": 9.704243463351908e-06,
      "loss": 0.0001,
      "step": 36030
    },
    {
      "epoch": 7.723960565795114,
      "grad_norm": 0.0020672250539064407,
      "learning_rate": 9.701385912273182e-06,
      "loss": 0.1238,
      "step": 36040
    },
    {
      "epoch": 7.726103729104158,
      "grad_norm": 0.01947656087577343,
      "learning_rate": 9.698528361194456e-06,
      "loss": 0.0001,
      "step": 36050
    },
    {
      "epoch": 7.7282468924132015,
      "grad_norm": 0.009073893539607525,
      "learning_rate": 9.695670810115732e-06,
      "loss": 0.1079,
      "step": 36060
    },
    {
      "epoch": 7.730390055722246,
      "grad_norm": 0.009201557375490665,
      "learning_rate": 9.692813259037006e-06,
      "loss": 0.2764,
      "step": 36070
    },
    {
      "epoch": 7.73253321903129,
      "grad_norm": 0.0032051128800958395,
      "learning_rate": 9.689955707958281e-06,
      "loss": 0.0005,
      "step": 36080
    },
    {
      "epoch": 7.734676382340334,
      "grad_norm": 0.0035619621630758047,
      "learning_rate": 9.687098156879555e-06,
      "loss": 0.0001,
      "step": 36090
    },
    {
      "epoch": 7.736819545649379,
      "grad_norm": 0.0015118247829377651,
      "learning_rate": 9.68424060580083e-06,
      "loss": 0.0001,
      "step": 36100
    },
    {
      "epoch": 7.7389627089584225,
      "grad_norm": 0.0018883096054196358,
      "learning_rate": 9.681383054722105e-06,
      "loss": 0.0001,
      "step": 36110
    },
    {
      "epoch": 7.741105872267466,
      "grad_norm": 0.0027867855969816446,
      "learning_rate": 9.678525503643379e-06,
      "loss": 0.0001,
      "step": 36120
    },
    {
      "epoch": 7.743249035576511,
      "grad_norm": 0.001873545697890222,
      "learning_rate": 9.675667952564653e-06,
      "loss": 0.2338,
      "step": 36130
    },
    {
      "epoch": 7.745392198885555,
      "grad_norm": 0.0016373808030039072,
      "learning_rate": 9.672810401485927e-06,
      "loss": 0.0001,
      "step": 36140
    },
    {
      "epoch": 7.747535362194599,
      "grad_norm": 0.003376732813194394,
      "learning_rate": 9.669952850407202e-06,
      "loss": 0.0001,
      "step": 36150
    },
    {
      "epoch": 7.7496785255036436,
      "grad_norm": 0.022423865273594856,
      "learning_rate": 9.667095299328476e-06,
      "loss": 0.0001,
      "step": 36160
    },
    {
      "epoch": 7.751821688812687,
      "grad_norm": 0.0004758897703140974,
      "learning_rate": 9.66423774824975e-06,
      "loss": 0.1385,
      "step": 36170
    },
    {
      "epoch": 7.753964852121731,
      "grad_norm": 0.0007289724890142679,
      "learning_rate": 9.661380197171026e-06,
      "loss": 0.0001,
      "step": 36180
    },
    {
      "epoch": 7.756108015430776,
      "grad_norm": 0.006064470391720533,
      "learning_rate": 9.6585226460923e-06,
      "loss": 0.0,
      "step": 36190
    },
    {
      "epoch": 7.75825117873982,
      "grad_norm": 0.001636211876757443,
      "learning_rate": 9.655665095013575e-06,
      "loss": 0.0029,
      "step": 36200
    },
    {
      "epoch": 7.760394342048864,
      "grad_norm": 0.00585927302017808,
      "learning_rate": 9.65280754393485e-06,
      "loss": 0.0002,
      "step": 36210
    },
    {
      "epoch": 7.762537505357908,
      "grad_norm": 0.00042556054540909827,
      "learning_rate": 9.649949992856123e-06,
      "loss": 0.0,
      "step": 36220
    },
    {
      "epoch": 7.764680668666952,
      "grad_norm": 0.00660747429355979,
      "learning_rate": 9.647092441777397e-06,
      "loss": 0.1726,
      "step": 36230
    },
    {
      "epoch": 7.766823831975996,
      "grad_norm": 0.0017528494354337454,
      "learning_rate": 9.644234890698671e-06,
      "loss": 0.3039,
      "step": 36240
    },
    {
      "epoch": 7.768966995285041,
      "grad_norm": 0.0033967653289437294,
      "learning_rate": 9.641377339619947e-06,
      "loss": 0.0001,
      "step": 36250
    },
    {
      "epoch": 7.771110158594085,
      "grad_norm": 0.005238056182861328,
      "learning_rate": 9.63851978854122e-06,
      "loss": 0.0005,
      "step": 36260
    },
    {
      "epoch": 7.773253321903129,
      "grad_norm": 0.005261715035885572,
      "learning_rate": 9.635662237462496e-06,
      "loss": 0.0066,
      "step": 36270
    },
    {
      "epoch": 7.775396485212173,
      "grad_norm": 0.005752383731305599,
      "learning_rate": 9.63280468638377e-06,
      "loss": 0.1863,
      "step": 36280
    },
    {
      "epoch": 7.777539648521217,
      "grad_norm": 0.001203420339152217,
      "learning_rate": 9.629947135305044e-06,
      "loss": 0.0001,
      "step": 36290
    },
    {
      "epoch": 7.779682811830261,
      "grad_norm": 0.01599987968802452,
      "learning_rate": 9.62708958422632e-06,
      "loss": 0.1526,
      "step": 36300
    },
    {
      "epoch": 7.781825975139306,
      "grad_norm": 0.021476322785019875,
      "learning_rate": 9.624232033147594e-06,
      "loss": 0.0001,
      "step": 36310
    },
    {
      "epoch": 7.78396913844835,
      "grad_norm": 0.004739703144878149,
      "learning_rate": 9.621374482068867e-06,
      "loss": 0.0002,
      "step": 36320
    },
    {
      "epoch": 7.786112301757393,
      "grad_norm": 0.003115090075880289,
      "learning_rate": 9.618516930990143e-06,
      "loss": 0.0001,
      "step": 36330
    },
    {
      "epoch": 7.788255465066438,
      "grad_norm": 0.0063430848531425,
      "learning_rate": 9.615659379911417e-06,
      "loss": 0.0001,
      "step": 36340
    },
    {
      "epoch": 7.790398628375482,
      "grad_norm": 0.002006048336625099,
      "learning_rate": 9.612801828832691e-06,
      "loss": 0.1895,
      "step": 36350
    },
    {
      "epoch": 7.792541791684526,
      "grad_norm": 0.8411560654640198,
      "learning_rate": 9.609944277753965e-06,
      "loss": 0.0036,
      "step": 36360
    },
    {
      "epoch": 7.794684954993571,
      "grad_norm": 0.0006131121190264821,
      "learning_rate": 9.60708672667524e-06,
      "loss": 0.0,
      "step": 36370
    },
    {
      "epoch": 7.7968281183026145,
      "grad_norm": 0.0017425398109480739,
      "learning_rate": 9.604229175596514e-06,
      "loss": 0.1799,
      "step": 36380
    },
    {
      "epoch": 7.798971281611658,
      "grad_norm": 0.05934293195605278,
      "learning_rate": 9.601371624517788e-06,
      "loss": 0.0011,
      "step": 36390
    },
    {
      "epoch": 7.801114444920703,
      "grad_norm": 0.0006068654474802315,
      "learning_rate": 9.598514073439064e-06,
      "loss": 0.0001,
      "step": 36400
    },
    {
      "epoch": 7.803257608229747,
      "grad_norm": 0.08744972199201584,
      "learning_rate": 9.595656522360338e-06,
      "loss": 0.0001,
      "step": 36410
    },
    {
      "epoch": 7.805400771538792,
      "grad_norm": 0.00046788182226009667,
      "learning_rate": 9.592798971281614e-06,
      "loss": 0.0002,
      "step": 36420
    },
    {
      "epoch": 7.8075439348478355,
      "grad_norm": 0.016233082860708237,
      "learning_rate": 9.589941420202887e-06,
      "loss": 0.0,
      "step": 36430
    },
    {
      "epoch": 7.809687098156879,
      "grad_norm": 0.001267825486138463,
      "learning_rate": 9.587083869124161e-06,
      "loss": 0.2603,
      "step": 36440
    },
    {
      "epoch": 7.811830261465924,
      "grad_norm": 0.00043097842717543244,
      "learning_rate": 9.584226318045435e-06,
      "loss": 0.0,
      "step": 36450
    },
    {
      "epoch": 7.813973424774968,
      "grad_norm": 0.0005306738312356174,
      "learning_rate": 9.58136876696671e-06,
      "loss": 0.0001,
      "step": 36460
    },
    {
      "epoch": 7.816116588084012,
      "grad_norm": 0.0014737859601154923,
      "learning_rate": 9.578511215887985e-06,
      "loss": 0.2007,
      "step": 36470
    },
    {
      "epoch": 7.8182597513930565,
      "grad_norm": 0.0008052994962781668,
      "learning_rate": 9.575653664809259e-06,
      "loss": 0.0001,
      "step": 36480
    },
    {
      "epoch": 7.8204029147021,
      "grad_norm": 0.0007351638050749898,
      "learning_rate": 9.572796113730534e-06,
      "loss": 0.0003,
      "step": 36490
    },
    {
      "epoch": 7.822546078011144,
      "grad_norm": 0.00254091527312994,
      "learning_rate": 9.569938562651808e-06,
      "loss": 0.0001,
      "step": 36500
    },
    {
      "epoch": 7.824689241320189,
      "grad_norm": 0.0015844415174797177,
      "learning_rate": 9.567081011573082e-06,
      "loss": 0.0001,
      "step": 36510
    },
    {
      "epoch": 7.826832404629233,
      "grad_norm": 0.00188830541446805,
      "learning_rate": 9.564223460494358e-06,
      "loss": 0.0002,
      "step": 36520
    },
    {
      "epoch": 7.828975567938277,
      "grad_norm": 0.0005173101089894772,
      "learning_rate": 9.561365909415632e-06,
      "loss": 0.0001,
      "step": 36530
    },
    {
      "epoch": 7.831118731247321,
      "grad_norm": 0.0006406527245417237,
      "learning_rate": 9.558508358336906e-06,
      "loss": 0.0001,
      "step": 36540
    },
    {
      "epoch": 7.833261894556365,
      "grad_norm": 0.0008924413123168051,
      "learning_rate": 9.555650807258181e-06,
      "loss": 0.0006,
      "step": 36550
    },
    {
      "epoch": 7.835405057865409,
      "grad_norm": 0.011242781765758991,
      "learning_rate": 9.552793256179455e-06,
      "loss": 0.0001,
      "step": 36560
    },
    {
      "epoch": 7.837548221174454,
      "grad_norm": 0.00046756493975408375,
      "learning_rate": 9.54993570510073e-06,
      "loss": 0.2889,
      "step": 36570
    },
    {
      "epoch": 7.839691384483498,
      "grad_norm": 0.010288734920322895,
      "learning_rate": 9.547078154022003e-06,
      "loss": 0.0,
      "step": 36580
    },
    {
      "epoch": 7.8418345477925415,
      "grad_norm": 0.00044733728282153606,
      "learning_rate": 9.544220602943279e-06,
      "loss": 0.0,
      "step": 36590
    },
    {
      "epoch": 7.843977711101586,
      "grad_norm": 0.0008515011286363006,
      "learning_rate": 9.541363051864553e-06,
      "loss": 0.0001,
      "step": 36600
    },
    {
      "epoch": 7.84612087441063,
      "grad_norm": 0.0003071539686061442,
      "learning_rate": 9.538505500785827e-06,
      "loss": 0.0,
      "step": 36610
    },
    {
      "epoch": 7.848264037719674,
      "grad_norm": 0.00028147842385806143,
      "learning_rate": 9.535647949707102e-06,
      "loss": 0.0001,
      "step": 36620
    },
    {
      "epoch": 7.850407201028719,
      "grad_norm": 0.0004150656459387392,
      "learning_rate": 9.532790398628376e-06,
      "loss": 0.0005,
      "step": 36630
    },
    {
      "epoch": 7.8525503643377625,
      "grad_norm": 0.007045490201562643,
      "learning_rate": 9.529932847549652e-06,
      "loss": 0.1715,
      "step": 36640
    },
    {
      "epoch": 7.854693527646806,
      "grad_norm": 0.09612902253866196,
      "learning_rate": 9.527075296470926e-06,
      "loss": 0.0001,
      "step": 36650
    },
    {
      "epoch": 7.856836690955851,
      "grad_norm": 0.04456784576177597,
      "learning_rate": 9.5242177453922e-06,
      "loss": 0.3031,
      "step": 36660
    },
    {
      "epoch": 7.858979854264895,
      "grad_norm": 0.0009683467214927077,
      "learning_rate": 9.521360194313474e-06,
      "loss": 0.0006,
      "step": 36670
    },
    {
      "epoch": 7.861123017573939,
      "grad_norm": 0.0015471181832253933,
      "learning_rate": 9.518502643234748e-06,
      "loss": 0.0,
      "step": 36680
    },
    {
      "epoch": 7.863266180882984,
      "grad_norm": 0.0006249766447581351,
      "learning_rate": 9.515645092156023e-06,
      "loss": 0.0,
      "step": 36690
    },
    {
      "epoch": 7.865409344192027,
      "grad_norm": 0.0005218351725488901,
      "learning_rate": 9.512787541077297e-06,
      "loss": 0.0003,
      "step": 36700
    },
    {
      "epoch": 7.867552507501071,
      "grad_norm": 0.006167224142700434,
      "learning_rate": 9.509929989998573e-06,
      "loss": 0.0002,
      "step": 36710
    },
    {
      "epoch": 7.869695670810116,
      "grad_norm": 0.0014558947877958417,
      "learning_rate": 9.507072438919847e-06,
      "loss": 0.2905,
      "step": 36720
    },
    {
      "epoch": 7.87183883411916,
      "grad_norm": 0.20920728147029877,
      "learning_rate": 9.50421488784112e-06,
      "loss": 0.0649,
      "step": 36730
    },
    {
      "epoch": 7.873981997428204,
      "grad_norm": 0.018572267144918442,
      "learning_rate": 9.501357336762396e-06,
      "loss": 0.0001,
      "step": 36740
    },
    {
      "epoch": 7.876125160737248,
      "grad_norm": 0.005320873577147722,
      "learning_rate": 9.49849978568367e-06,
      "loss": 0.0001,
      "step": 36750
    },
    {
      "epoch": 7.878268324046292,
      "grad_norm": 0.0010925413807854056,
      "learning_rate": 9.495642234604944e-06,
      "loss": 0.0009,
      "step": 36760
    },
    {
      "epoch": 7.880411487355336,
      "grad_norm": 41.0018310546875,
      "learning_rate": 9.492784683526218e-06,
      "loss": 0.0157,
      "step": 36770
    },
    {
      "epoch": 7.882554650664381,
      "grad_norm": 0.0006107372464612126,
      "learning_rate": 9.489927132447494e-06,
      "loss": 0.0,
      "step": 36780
    },
    {
      "epoch": 7.884697813973425,
      "grad_norm": 0.000688885455019772,
      "learning_rate": 9.487069581368768e-06,
      "loss": 0.0001,
      "step": 36790
    },
    {
      "epoch": 7.886840977282469,
      "grad_norm": 0.003443398978561163,
      "learning_rate": 9.484212030290041e-06,
      "loss": 0.0006,
      "step": 36800
    },
    {
      "epoch": 7.888984140591513,
      "grad_norm": 0.00218697777017951,
      "learning_rate": 9.481354479211317e-06,
      "loss": 0.0005,
      "step": 36810
    },
    {
      "epoch": 7.891127303900557,
      "grad_norm": 0.005964846350252628,
      "learning_rate": 9.478496928132591e-06,
      "loss": 0.0014,
      "step": 36820
    },
    {
      "epoch": 7.893270467209601,
      "grad_norm": 0.0004818532324861735,
      "learning_rate": 9.475639377053865e-06,
      "loss": 0.0,
      "step": 36830
    },
    {
      "epoch": 7.895413630518646,
      "grad_norm": 0.0005813472671434283,
      "learning_rate": 9.47278182597514e-06,
      "loss": 0.0,
      "step": 36840
    },
    {
      "epoch": 7.89755679382769,
      "grad_norm": 0.006515913177281618,
      "learning_rate": 9.469924274896414e-06,
      "loss": 0.0,
      "step": 36850
    },
    {
      "epoch": 7.8996999571367335,
      "grad_norm": 0.0004308848874643445,
      "learning_rate": 9.46706672381769e-06,
      "loss": 0.2164,
      "step": 36860
    },
    {
      "epoch": 7.901843120445778,
      "grad_norm": 0.0006442427402362227,
      "learning_rate": 9.464209172738964e-06,
      "loss": 0.0,
      "step": 36870
    },
    {
      "epoch": 7.903986283754822,
      "grad_norm": 0.0006916035781614482,
      "learning_rate": 9.461351621660238e-06,
      "loss": 0.016,
      "step": 36880
    },
    {
      "epoch": 7.906129447063866,
      "grad_norm": 42.64773941040039,
      "learning_rate": 9.458494070581512e-06,
      "loss": 0.25,
      "step": 36890
    },
    {
      "epoch": 7.908272610372911,
      "grad_norm": 0.002045443980023265,
      "learning_rate": 9.455636519502786e-06,
      "loss": 0.0,
      "step": 36900
    },
    {
      "epoch": 7.9104157736819545,
      "grad_norm": 0.002633180469274521,
      "learning_rate": 9.452778968424061e-06,
      "loss": 0.1946,
      "step": 36910
    },
    {
      "epoch": 7.912558936990998,
      "grad_norm": 0.0008885595016181469,
      "learning_rate": 9.449921417345335e-06,
      "loss": 0.0,
      "step": 36920
    },
    {
      "epoch": 7.914702100300043,
      "grad_norm": 0.0030718613415956497,
      "learning_rate": 9.447063866266611e-06,
      "loss": 0.0,
      "step": 36930
    },
    {
      "epoch": 7.916845263609087,
      "grad_norm": 0.0017346967943012714,
      "learning_rate": 9.444206315187885e-06,
      "loss": 0.1065,
      "step": 36940
    },
    {
      "epoch": 7.918988426918132,
      "grad_norm": 0.0028064034413546324,
      "learning_rate": 9.441348764109159e-06,
      "loss": 0.0003,
      "step": 36950
    },
    {
      "epoch": 7.9211315902271755,
      "grad_norm": 0.3894461989402771,
      "learning_rate": 9.438491213030434e-06,
      "loss": 0.0002,
      "step": 36960
    },
    {
      "epoch": 7.923274753536219,
      "grad_norm": 0.025767428800463676,
      "learning_rate": 9.435633661951708e-06,
      "loss": 0.2244,
      "step": 36970
    },
    {
      "epoch": 7.925417916845264,
      "grad_norm": 0.004683469422161579,
      "learning_rate": 9.432776110872984e-06,
      "loss": 0.1443,
      "step": 36980
    },
    {
      "epoch": 7.927561080154308,
      "grad_norm": 0.002928041620180011,
      "learning_rate": 9.429918559794256e-06,
      "loss": 0.0791,
      "step": 36990
    },
    {
      "epoch": 7.929704243463352,
      "grad_norm": 0.001445863046683371,
      "learning_rate": 9.427061008715532e-06,
      "loss": 0.0002,
      "step": 37000
    },
    {
      "epoch": 7.9318474067723965,
      "grad_norm": 0.001431767945177853,
      "learning_rate": 9.424203457636806e-06,
      "loss": 0.0002,
      "step": 37010
    },
    {
      "epoch": 7.93399057008144,
      "grad_norm": 0.002122186589986086,
      "learning_rate": 9.42134590655808e-06,
      "loss": 0.0002,
      "step": 37020
    },
    {
      "epoch": 7.936133733390484,
      "grad_norm": 0.0007247626781463623,
      "learning_rate": 9.418488355479355e-06,
      "loss": 0.0001,
      "step": 37030
    },
    {
      "epoch": 7.938276896699529,
      "grad_norm": 0.002631733426824212,
      "learning_rate": 9.41563080440063e-06,
      "loss": 0.0024,
      "step": 37040
    },
    {
      "epoch": 7.940420060008573,
      "grad_norm": 0.011564061045646667,
      "learning_rate": 9.412773253321905e-06,
      "loss": 0.0,
      "step": 37050
    },
    {
      "epoch": 7.942563223317617,
      "grad_norm": 0.0004734678368549794,
      "learning_rate": 9.409915702243179e-06,
      "loss": 0.0002,
      "step": 37060
    },
    {
      "epoch": 7.944706386626661,
      "grad_norm": 0.0004992661997675896,
      "learning_rate": 9.407058151164453e-06,
      "loss": 0.0,
      "step": 37070
    },
    {
      "epoch": 7.946849549935705,
      "grad_norm": 0.0005795334582217038,
      "learning_rate": 9.404200600085728e-06,
      "loss": 0.0,
      "step": 37080
    },
    {
      "epoch": 7.948992713244749,
      "grad_norm": 0.0009751224424690008,
      "learning_rate": 9.401343049007e-06,
      "loss": 0.0001,
      "step": 37090
    },
    {
      "epoch": 7.951135876553794,
      "grad_norm": 0.00024689934798516333,
      "learning_rate": 9.398485497928276e-06,
      "loss": 0.1485,
      "step": 37100
    },
    {
      "epoch": 7.953279039862838,
      "grad_norm": 0.0006877875421196222,
      "learning_rate": 9.39562794684955e-06,
      "loss": 0.0003,
      "step": 37110
    },
    {
      "epoch": 7.9554222031718815,
      "grad_norm": 0.03601879999041557,
      "learning_rate": 9.392770395770826e-06,
      "loss": 0.0001,
      "step": 37120
    },
    {
      "epoch": 7.957565366480926,
      "grad_norm": 0.0003978078893851489,
      "learning_rate": 9.3899128446921e-06,
      "loss": 0.0007,
      "step": 37130
    },
    {
      "epoch": 7.95970852978997,
      "grad_norm": 158.85972595214844,
      "learning_rate": 9.387055293613374e-06,
      "loss": 0.2517,
      "step": 37140
    },
    {
      "epoch": 7.961851693099014,
      "grad_norm": 0.00031615886837244034,
      "learning_rate": 9.38419774253465e-06,
      "loss": 0.0002,
      "step": 37150
    },
    {
      "epoch": 7.963994856408059,
      "grad_norm": 0.0004161234537605196,
      "learning_rate": 9.381340191455923e-06,
      "loss": 0.0735,
      "step": 37160
    },
    {
      "epoch": 7.966138019717103,
      "grad_norm": 0.0006744666025042534,
      "learning_rate": 9.378482640377197e-06,
      "loss": 0.0,
      "step": 37170
    },
    {
      "epoch": 7.968281183026146,
      "grad_norm": 16.804668426513672,
      "learning_rate": 9.375625089298473e-06,
      "loss": 0.1612,
      "step": 37180
    },
    {
      "epoch": 7.970424346335191,
      "grad_norm": 0.000526554707903415,
      "learning_rate": 9.372767538219747e-06,
      "loss": 0.0,
      "step": 37190
    },
    {
      "epoch": 7.972567509644235,
      "grad_norm": 0.00026745363720692694,
      "learning_rate": 9.36990998714102e-06,
      "loss": 0.0149,
      "step": 37200
    },
    {
      "epoch": 7.974710672953279,
      "grad_norm": 0.32586368918418884,
      "learning_rate": 9.367052436062295e-06,
      "loss": 0.0005,
      "step": 37210
    },
    {
      "epoch": 7.976853836262324,
      "grad_norm": 0.001973873469978571,
      "learning_rate": 9.36419488498357e-06,
      "loss": 0.0,
      "step": 37220
    },
    {
      "epoch": 7.978996999571367,
      "grad_norm": 0.0003709726734086871,
      "learning_rate": 9.361337333904844e-06,
      "loss": 0.0,
      "step": 37230
    },
    {
      "epoch": 7.981140162880411,
      "grad_norm": 0.00047400969197042286,
      "learning_rate": 9.358479782826118e-06,
      "loss": 0.1104,
      "step": 37240
    },
    {
      "epoch": 7.983283326189456,
      "grad_norm": 0.0005376506596803665,
      "learning_rate": 9.355622231747394e-06,
      "loss": 0.0001,
      "step": 37250
    },
    {
      "epoch": 7.9854264894985,
      "grad_norm": 0.0006512758554890752,
      "learning_rate": 9.352764680668668e-06,
      "loss": 0.0,
      "step": 37260
    },
    {
      "epoch": 7.987569652807544,
      "grad_norm": 0.0002998415438923985,
      "learning_rate": 9.349907129589943e-06,
      "loss": 0.0001,
      "step": 37270
    },
    {
      "epoch": 7.9897128161165885,
      "grad_norm": 0.0007246196619234979,
      "learning_rate": 9.347049578511217e-06,
      "loss": 0.0,
      "step": 37280
    },
    {
      "epoch": 7.991855979425632,
      "grad_norm": 0.00020932404731865972,
      "learning_rate": 9.344192027432491e-06,
      "loss": 0.0016,
      "step": 37290
    },
    {
      "epoch": 7.993999142734676,
      "grad_norm": 0.013156618922948837,
      "learning_rate": 9.341334476353767e-06,
      "loss": 0.0,
      "step": 37300
    },
    {
      "epoch": 7.996142306043721,
      "grad_norm": 0.00016908925317693502,
      "learning_rate": 9.338476925275039e-06,
      "loss": 0.0,
      "step": 37310
    },
    {
      "epoch": 7.998285469352765,
      "grad_norm": 0.0008772968431003392,
      "learning_rate": 9.335619374196315e-06,
      "loss": 0.0,
      "step": 37320
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9233333333333333,
      "eval_f1": 0.7931654676258992,
      "eval_loss": 0.699561595916748,
      "eval_precision": 0.833648393194707,
      "eval_recall": 0.7564322469982847,
      "eval_runtime": 108.1528,
      "eval_samples_per_second": 27.739,
      "eval_steps_per_second": 1.156,
      "step": 37328
    },
    {
      "epoch": 8.000428632661809,
      "grad_norm": 0.0009944107150658965,
      "learning_rate": 9.332761823117588e-06,
      "loss": 0.0002,
      "step": 37330
    },
    {
      "epoch": 8.002571795970853,
      "grad_norm": 0.00029208906926214695,
      "learning_rate": 9.329904272038864e-06,
      "loss": 0.0001,
      "step": 37340
    },
    {
      "epoch": 8.004714959279896,
      "grad_norm": 0.006523106247186661,
      "learning_rate": 9.327046720960138e-06,
      "loss": 0.0,
      "step": 37350
    },
    {
      "epoch": 8.006858122588941,
      "grad_norm": 0.0005546251777559519,
      "learning_rate": 9.324189169881412e-06,
      "loss": 0.2601,
      "step": 37360
    },
    {
      "epoch": 8.009001285897986,
      "grad_norm": 0.0010528110433369875,
      "learning_rate": 9.321331618802688e-06,
      "loss": 0.0,
      "step": 37370
    },
    {
      "epoch": 8.011144449207029,
      "grad_norm": 0.001655136002227664,
      "learning_rate": 9.318474067723961e-06,
      "loss": 0.0001,
      "step": 37380
    },
    {
      "epoch": 8.013287612516073,
      "grad_norm": 0.046714019030332565,
      "learning_rate": 9.315616516645235e-06,
      "loss": 0.0002,
      "step": 37390
    },
    {
      "epoch": 8.015430775825118,
      "grad_norm": 0.010633541271090508,
      "learning_rate": 9.312758965566511e-06,
      "loss": 0.1205,
      "step": 37400
    },
    {
      "epoch": 8.017573939134161,
      "grad_norm": 0.0006633885204792023,
      "learning_rate": 9.309901414487785e-06,
      "loss": 0.0001,
      "step": 37410
    },
    {
      "epoch": 8.019717102443206,
      "grad_norm": 0.005282767117023468,
      "learning_rate": 9.307043863409059e-06,
      "loss": 0.0,
      "step": 37420
    },
    {
      "epoch": 8.02186026575225,
      "grad_norm": 0.007374322973191738,
      "learning_rate": 9.304186312330333e-06,
      "loss": 0.0,
      "step": 37430
    },
    {
      "epoch": 8.024003429061294,
      "grad_norm": 0.0007962022791616619,
      "learning_rate": 9.301328761251608e-06,
      "loss": 0.0,
      "step": 37440
    },
    {
      "epoch": 8.026146592370338,
      "grad_norm": 0.0012883238960057497,
      "learning_rate": 9.298471210172882e-06,
      "loss": 0.0001,
      "step": 37450
    },
    {
      "epoch": 8.028289755679383,
      "grad_norm": 0.0006942474283277988,
      "learning_rate": 9.295613659094156e-06,
      "loss": 0.0002,
      "step": 37460
    },
    {
      "epoch": 8.030432918988426,
      "grad_norm": 0.0007297506090253592,
      "learning_rate": 9.292756108015432e-06,
      "loss": 0.0,
      "step": 37470
    },
    {
      "epoch": 8.03257608229747,
      "grad_norm": 0.0007905806414783001,
      "learning_rate": 9.289898556936706e-06,
      "loss": 0.0004,
      "step": 37480
    },
    {
      "epoch": 8.034719245606516,
      "grad_norm": 0.00034650834277272224,
      "learning_rate": 9.287041005857981e-06,
      "loss": 0.0002,
      "step": 37490
    },
    {
      "epoch": 8.03686240891556,
      "grad_norm": 0.00043615387403406203,
      "learning_rate": 9.284183454779255e-06,
      "loss": 0.0,
      "step": 37500
    },
    {
      "epoch": 8.039005572224603,
      "grad_norm": 0.0002805369149427861,
      "learning_rate": 9.28132590370053e-06,
      "loss": 0.0,
      "step": 37510
    },
    {
      "epoch": 8.041148735533648,
      "grad_norm": 0.00014502319390885532,
      "learning_rate": 9.278468352621803e-06,
      "loss": 0.0,
      "step": 37520
    },
    {
      "epoch": 8.043291898842693,
      "grad_norm": 0.00018980333697982132,
      "learning_rate": 9.275610801543077e-06,
      "loss": 0.0,
      "step": 37530
    },
    {
      "epoch": 8.045435062151736,
      "grad_norm": 0.00023850798606872559,
      "learning_rate": 9.272753250464353e-06,
      "loss": 0.0,
      "step": 37540
    },
    {
      "epoch": 8.04757822546078,
      "grad_norm": 0.0002099282864946872,
      "learning_rate": 9.269895699385627e-06,
      "loss": 0.0,
      "step": 37550
    },
    {
      "epoch": 8.049721388769825,
      "grad_norm": 0.0001713394303806126,
      "learning_rate": 9.267038148306902e-06,
      "loss": 0.0015,
      "step": 37560
    },
    {
      "epoch": 8.051864552078868,
      "grad_norm": 0.044287052005529404,
      "learning_rate": 9.264180597228176e-06,
      "loss": 0.0001,
      "step": 37570
    },
    {
      "epoch": 8.054007715387913,
      "grad_norm": 0.0004530248115770519,
      "learning_rate": 9.26132304614945e-06,
      "loss": 0.2712,
      "step": 37580
    },
    {
      "epoch": 8.056150878696958,
      "grad_norm": 0.0007728371419943869,
      "learning_rate": 9.258465495070726e-06,
      "loss": 0.0001,
      "step": 37590
    },
    {
      "epoch": 8.058294042006,
      "grad_norm": 0.0038836959283798933,
      "learning_rate": 9.255607943992e-06,
      "loss": 0.0002,
      "step": 37600
    },
    {
      "epoch": 8.060437205315045,
      "grad_norm": 0.0039621139876544476,
      "learning_rate": 9.252750392913274e-06,
      "loss": 0.0017,
      "step": 37610
    },
    {
      "epoch": 8.06258036862409,
      "grad_norm": 14.09302043914795,
      "learning_rate": 9.24989284183455e-06,
      "loss": 0.0012,
      "step": 37620
    },
    {
      "epoch": 8.064723531933133,
      "grad_norm": 0.0008549555204808712,
      "learning_rate": 9.247035290755823e-06,
      "loss": 0.0,
      "step": 37630
    },
    {
      "epoch": 8.066866695242178,
      "grad_norm": 0.008560149930417538,
      "learning_rate": 9.244177739677097e-06,
      "loss": 0.0001,
      "step": 37640
    },
    {
      "epoch": 8.069009858551222,
      "grad_norm": 0.007180198561400175,
      "learning_rate": 9.241320188598371e-06,
      "loss": 0.0009,
      "step": 37650
    },
    {
      "epoch": 8.071153021860265,
      "grad_norm": 0.000565478578209877,
      "learning_rate": 9.238462637519647e-06,
      "loss": 0.0001,
      "step": 37660
    },
    {
      "epoch": 8.07329618516931,
      "grad_norm": 0.0022068237885832787,
      "learning_rate": 9.23560508644092e-06,
      "loss": 0.0002,
      "step": 37670
    },
    {
      "epoch": 8.075439348478355,
      "grad_norm": 0.004337600897997618,
      "learning_rate": 9.232747535362195e-06,
      "loss": 0.0001,
      "step": 37680
    },
    {
      "epoch": 8.077582511787398,
      "grad_norm": 0.0006041317246854305,
      "learning_rate": 9.22988998428347e-06,
      "loss": 0.0001,
      "step": 37690
    },
    {
      "epoch": 8.079725675096443,
      "grad_norm": 0.0009468632633797824,
      "learning_rate": 9.227032433204744e-06,
      "loss": 0.0022,
      "step": 37700
    },
    {
      "epoch": 8.081868838405487,
      "grad_norm": 0.0004639528051484376,
      "learning_rate": 9.22417488212602e-06,
      "loss": 0.0,
      "step": 37710
    },
    {
      "epoch": 8.08401200171453,
      "grad_norm": 0.0002600128063932061,
      "learning_rate": 9.221317331047294e-06,
      "loss": 0.0,
      "step": 37720
    },
    {
      "epoch": 8.086155165023575,
      "grad_norm": 0.01300309132784605,
      "learning_rate": 9.218459779968568e-06,
      "loss": 0.0,
      "step": 37730
    },
    {
      "epoch": 8.08829832833262,
      "grad_norm": 0.003948168829083443,
      "learning_rate": 9.215602228889842e-06,
      "loss": 0.0001,
      "step": 37740
    },
    {
      "epoch": 8.090441491641663,
      "grad_norm": 0.0013257393147796392,
      "learning_rate": 9.212744677811115e-06,
      "loss": 0.0,
      "step": 37750
    },
    {
      "epoch": 8.092584654950707,
      "grad_norm": 0.0006876706029288471,
      "learning_rate": 9.209887126732391e-06,
      "loss": 0.0,
      "step": 37760
    },
    {
      "epoch": 8.094727818259752,
      "grad_norm": 0.0004975131596438587,
      "learning_rate": 9.207029575653665e-06,
      "loss": 0.2448,
      "step": 37770
    },
    {
      "epoch": 8.096870981568795,
      "grad_norm": 0.0010253413347527385,
      "learning_rate": 9.20417202457494e-06,
      "loss": 0.0,
      "step": 37780
    },
    {
      "epoch": 8.09901414487784,
      "grad_norm": 0.000470917351776734,
      "learning_rate": 9.201314473496215e-06,
      "loss": 0.0001,
      "step": 37790
    },
    {
      "epoch": 8.101157308186885,
      "grad_norm": 0.0013724968302994967,
      "learning_rate": 9.198456922417488e-06,
      "loss": 0.0,
      "step": 37800
    },
    {
      "epoch": 8.103300471495928,
      "grad_norm": 0.003934111446142197,
      "learning_rate": 9.195599371338764e-06,
      "loss": 0.0,
      "step": 37810
    },
    {
      "epoch": 8.105443634804972,
      "grad_norm": 0.0009500465821474791,
      "learning_rate": 9.192741820260038e-06,
      "loss": 0.0,
      "step": 37820
    },
    {
      "epoch": 8.107586798114017,
      "grad_norm": 0.013076229952275753,
      "learning_rate": 9.189884269181314e-06,
      "loss": 0.0001,
      "step": 37830
    },
    {
      "epoch": 8.10972996142306,
      "grad_norm": 0.00014399408246390522,
      "learning_rate": 9.187026718102586e-06,
      "loss": 0.0,
      "step": 37840
    },
    {
      "epoch": 8.111873124732105,
      "grad_norm": 0.0002369877474848181,
      "learning_rate": 9.184169167023862e-06,
      "loss": 0.1712,
      "step": 37850
    },
    {
      "epoch": 8.11401628804115,
      "grad_norm": 0.00043745615403167903,
      "learning_rate": 9.181311615945135e-06,
      "loss": 0.0,
      "step": 37860
    },
    {
      "epoch": 8.116159451350192,
      "grad_norm": 0.0003862285811919719,
      "learning_rate": 9.17845406486641e-06,
      "loss": 0.0,
      "step": 37870
    },
    {
      "epoch": 8.118302614659237,
      "grad_norm": 0.0011671186657622457,
      "learning_rate": 9.175596513787685e-06,
      "loss": 0.0,
      "step": 37880
    },
    {
      "epoch": 8.120445777968282,
      "grad_norm": 0.003240677062422037,
      "learning_rate": 9.172738962708959e-06,
      "loss": 0.0,
      "step": 37890
    },
    {
      "epoch": 8.122588941277325,
      "grad_norm": 0.0011060640681535006,
      "learning_rate": 9.169881411630235e-06,
      "loss": 0.0,
      "step": 37900
    },
    {
      "epoch": 8.12473210458637,
      "grad_norm": 0.00299842213280499,
      "learning_rate": 9.167023860551508e-06,
      "loss": 0.0,
      "step": 37910
    },
    {
      "epoch": 8.126875267895414,
      "grad_norm": 0.0005721342749893665,
      "learning_rate": 9.164166309472782e-06,
      "loss": 0.0,
      "step": 37920
    },
    {
      "epoch": 8.129018431204457,
      "grad_norm": 0.0013682019198313355,
      "learning_rate": 9.161308758394058e-06,
      "loss": 0.0,
      "step": 37930
    },
    {
      "epoch": 8.131161594513502,
      "grad_norm": 0.016542039811611176,
      "learning_rate": 9.158451207315332e-06,
      "loss": 0.0001,
      "step": 37940
    },
    {
      "epoch": 8.133304757822547,
      "grad_norm": 0.09124694764614105,
      "learning_rate": 9.155593656236606e-06,
      "loss": 0.2458,
      "step": 37950
    },
    {
      "epoch": 8.13544792113159,
      "grad_norm": 0.00024565530475229025,
      "learning_rate": 9.15273610515788e-06,
      "loss": 0.0,
      "step": 37960
    },
    {
      "epoch": 8.137591084440635,
      "grad_norm": 0.00017296620353590697,
      "learning_rate": 9.149878554079155e-06,
      "loss": 0.0,
      "step": 37970
    },
    {
      "epoch": 8.13973424774968,
      "grad_norm": 0.00024279537319671363,
      "learning_rate": 9.14702100300043e-06,
      "loss": 0.0,
      "step": 37980
    },
    {
      "epoch": 8.141877411058722,
      "grad_norm": 0.0002428985171718523,
      "learning_rate": 9.144163451921703e-06,
      "loss": 0.0,
      "step": 37990
    },
    {
      "epoch": 8.144020574367767,
      "grad_norm": 0.0073722791858017445,
      "learning_rate": 9.141305900842979e-06,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 8.146163737676812,
      "grad_norm": 0.00018640587222762406,
      "learning_rate": 9.138448349764253e-06,
      "loss": 0.0,
      "step": 38010
    },
    {
      "epoch": 8.148306900985855,
      "grad_norm": 0.00129079376347363,
      "learning_rate": 9.135590798685527e-06,
      "loss": 0.4152,
      "step": 38020
    },
    {
      "epoch": 8.1504500642949,
      "grad_norm": 0.0014561440329998732,
      "learning_rate": 9.132733247606802e-06,
      "loss": 0.1964,
      "step": 38030
    },
    {
      "epoch": 8.152593227603944,
      "grad_norm": 0.005253348499536514,
      "learning_rate": 9.129875696528076e-06,
      "loss": 0.0036,
      "step": 38040
    },
    {
      "epoch": 8.154736390912987,
      "grad_norm": 0.008499718271195889,
      "learning_rate": 9.127018145449352e-06,
      "loss": 0.0883,
      "step": 38050
    },
    {
      "epoch": 8.156879554222032,
      "grad_norm": 0.004204256925731897,
      "learning_rate": 9.124160594370624e-06,
      "loss": 0.0001,
      "step": 38060
    },
    {
      "epoch": 8.159022717531077,
      "grad_norm": 0.0025075238663703203,
      "learning_rate": 9.1213030432919e-06,
      "loss": 0.0001,
      "step": 38070
    },
    {
      "epoch": 8.16116588084012,
      "grad_norm": 0.0036608099471777678,
      "learning_rate": 9.118445492213174e-06,
      "loss": 0.0003,
      "step": 38080
    },
    {
      "epoch": 8.163309044149164,
      "grad_norm": 0.0009378180257044733,
      "learning_rate": 9.115587941134448e-06,
      "loss": 0.0001,
      "step": 38090
    },
    {
      "epoch": 8.165452207458209,
      "grad_norm": 0.16722826659679413,
      "learning_rate": 9.112730390055723e-06,
      "loss": 0.0002,
      "step": 38100
    },
    {
      "epoch": 8.167595370767252,
      "grad_norm": 0.014254127629101276,
      "learning_rate": 9.109872838976997e-06,
      "loss": 0.0125,
      "step": 38110
    },
    {
      "epoch": 8.169738534076297,
      "grad_norm": 0.0037613401655107737,
      "learning_rate": 9.107015287898273e-06,
      "loss": 0.0,
      "step": 38120
    },
    {
      "epoch": 8.171881697385341,
      "grad_norm": 0.0066298795863986015,
      "learning_rate": 9.104157736819547e-06,
      "loss": 0.0,
      "step": 38130
    },
    {
      "epoch": 8.174024860694384,
      "grad_norm": 0.0011634115362539887,
      "learning_rate": 9.10130018574082e-06,
      "loss": 0.0,
      "step": 38140
    },
    {
      "epoch": 8.17616802400343,
      "grad_norm": 0.0017603191081434488,
      "learning_rate": 9.098442634662096e-06,
      "loss": 0.0,
      "step": 38150
    },
    {
      "epoch": 8.178311187312474,
      "grad_norm": 0.000573961588088423,
      "learning_rate": 9.09558508358337e-06,
      "loss": 0.0,
      "step": 38160
    },
    {
      "epoch": 8.180454350621517,
      "grad_norm": 0.0018723777029663324,
      "learning_rate": 9.092727532504644e-06,
      "loss": 0.0,
      "step": 38170
    },
    {
      "epoch": 8.182597513930562,
      "grad_norm": 0.0005652892286889255,
      "learning_rate": 9.089869981425918e-06,
      "loss": 0.0023,
      "step": 38180
    },
    {
      "epoch": 8.184740677239606,
      "grad_norm": 0.0003529606619849801,
      "learning_rate": 9.087012430347194e-06,
      "loss": 0.0,
      "step": 38190
    },
    {
      "epoch": 8.18688384054865,
      "grad_norm": 0.002395754912868142,
      "learning_rate": 9.084154879268468e-06,
      "loss": 0.0202,
      "step": 38200
    },
    {
      "epoch": 8.189027003857694,
      "grad_norm": 0.000821638444904238,
      "learning_rate": 9.081297328189742e-06,
      "loss": 0.2138,
      "step": 38210
    },
    {
      "epoch": 8.191170167166739,
      "grad_norm": 0.002406689105555415,
      "learning_rate": 9.078439777111017e-06,
      "loss": 0.208,
      "step": 38220
    },
    {
      "epoch": 8.193313330475782,
      "grad_norm": 0.001466588000766933,
      "learning_rate": 9.075582226032291e-06,
      "loss": 0.0,
      "step": 38230
    },
    {
      "epoch": 8.195456493784826,
      "grad_norm": 0.14130046963691711,
      "learning_rate": 9.072724674953565e-06,
      "loss": 0.0003,
      "step": 38240
    },
    {
      "epoch": 8.197599657093871,
      "grad_norm": 0.000643203326035291,
      "learning_rate": 9.06986712387484e-06,
      "loss": 0.3496,
      "step": 38250
    },
    {
      "epoch": 8.199742820402914,
      "grad_norm": 0.0025349543429911137,
      "learning_rate": 9.067009572796115e-06,
      "loss": 0.1243,
      "step": 38260
    },
    {
      "epoch": 8.201885983711959,
      "grad_norm": 0.011277417652308941,
      "learning_rate": 9.064152021717389e-06,
      "loss": 0.0024,
      "step": 38270
    },
    {
      "epoch": 8.204029147021004,
      "grad_norm": 0.15331731736660004,
      "learning_rate": 9.061294470638662e-06,
      "loss": 0.0003,
      "step": 38280
    },
    {
      "epoch": 8.206172310330047,
      "grad_norm": 0.0012965514324605465,
      "learning_rate": 9.058436919559938e-06,
      "loss": 0.0002,
      "step": 38290
    },
    {
      "epoch": 8.208315473639091,
      "grad_norm": 0.0080284234136343,
      "learning_rate": 9.055579368481212e-06,
      "loss": 0.0001,
      "step": 38300
    },
    {
      "epoch": 8.210458636948136,
      "grad_norm": 0.00045469735050573945,
      "learning_rate": 9.052721817402486e-06,
      "loss": 0.0001,
      "step": 38310
    },
    {
      "epoch": 8.212601800257179,
      "grad_norm": 0.0003556001465767622,
      "learning_rate": 9.049864266323762e-06,
      "loss": 0.0,
      "step": 38320
    },
    {
      "epoch": 8.214744963566224,
      "grad_norm": 0.012544605880975723,
      "learning_rate": 9.047006715245035e-06,
      "loss": 0.0,
      "step": 38330
    },
    {
      "epoch": 8.216888126875268,
      "grad_norm": 0.010859793052077293,
      "learning_rate": 9.044149164166311e-06,
      "loss": 0.0013,
      "step": 38340
    },
    {
      "epoch": 8.219031290184311,
      "grad_norm": 0.17288093268871307,
      "learning_rate": 9.041291613087585e-06,
      "loss": 0.0004,
      "step": 38350
    },
    {
      "epoch": 8.221174453493356,
      "grad_norm": 0.05668061226606369,
      "learning_rate": 9.038434062008859e-06,
      "loss": 0.0007,
      "step": 38360
    },
    {
      "epoch": 8.223317616802401,
      "grad_norm": 0.026464838534593582,
      "learning_rate": 9.035576510930135e-06,
      "loss": 0.0001,
      "step": 38370
    },
    {
      "epoch": 8.225460780111444,
      "grad_norm": 0.0025055843871086836,
      "learning_rate": 9.032718959851407e-06,
      "loss": 0.0001,
      "step": 38380
    },
    {
      "epoch": 8.227603943420489,
      "grad_norm": 0.001029019826091826,
      "learning_rate": 9.029861408772682e-06,
      "loss": 0.0002,
      "step": 38390
    },
    {
      "epoch": 8.229747106729533,
      "grad_norm": 0.003072321182116866,
      "learning_rate": 9.027003857693956e-06,
      "loss": 0.0006,
      "step": 38400
    },
    {
      "epoch": 8.231890270038576,
      "grad_norm": 0.00040282862028107047,
      "learning_rate": 9.024146306615232e-06,
      "loss": 0.2793,
      "step": 38410
    },
    {
      "epoch": 8.234033433347621,
      "grad_norm": 0.024213649332523346,
      "learning_rate": 9.021288755536506e-06,
      "loss": 0.0001,
      "step": 38420
    },
    {
      "epoch": 8.236176596656666,
      "grad_norm": 0.0036902360152453184,
      "learning_rate": 9.01843120445778e-06,
      "loss": 0.0001,
      "step": 38430
    },
    {
      "epoch": 8.238319759965709,
      "grad_norm": 0.00022527598775923252,
      "learning_rate": 9.015573653379055e-06,
      "loss": 0.0,
      "step": 38440
    },
    {
      "epoch": 8.240462923274753,
      "grad_norm": 0.0003042124444618821,
      "learning_rate": 9.01271610230033e-06,
      "loss": 0.0001,
      "step": 38450
    },
    {
      "epoch": 8.242606086583798,
      "grad_norm": 0.00025719651603139937,
      "learning_rate": 9.009858551221603e-06,
      "loss": 0.0236,
      "step": 38460
    },
    {
      "epoch": 8.244749249892841,
      "grad_norm": 0.001422520144842565,
      "learning_rate": 9.007001000142879e-06,
      "loss": 0.0002,
      "step": 38470
    },
    {
      "epoch": 8.246892413201886,
      "grad_norm": 0.005679289810359478,
      "learning_rate": 9.004143449064153e-06,
      "loss": 0.0002,
      "step": 38480
    },
    {
      "epoch": 8.24903557651093,
      "grad_norm": 0.004509455990046263,
      "learning_rate": 9.001285897985427e-06,
      "loss": 0.1908,
      "step": 38490
    },
    {
      "epoch": 8.251178739819974,
      "grad_norm": 0.0007677579997107387,
      "learning_rate": 8.9984283469067e-06,
      "loss": 0.4174,
      "step": 38500
    },
    {
      "epoch": 8.253321903129018,
      "grad_norm": 0.17002762854099274,
      "learning_rate": 8.995570795827976e-06,
      "loss": 0.0002,
      "step": 38510
    },
    {
      "epoch": 8.255465066438063,
      "grad_norm": 0.0034929001703858376,
      "learning_rate": 8.99271324474925e-06,
      "loss": 0.0002,
      "step": 38520
    },
    {
      "epoch": 8.257608229747106,
      "grad_norm": 0.0008022105903364718,
      "learning_rate": 8.989855693670524e-06,
      "loss": 0.0001,
      "step": 38530
    },
    {
      "epoch": 8.25975139305615,
      "grad_norm": 0.002416162984445691,
      "learning_rate": 8.9869981425918e-06,
      "loss": 0.324,
      "step": 38540
    },
    {
      "epoch": 8.261894556365196,
      "grad_norm": 0.0002999336866196245,
      "learning_rate": 8.984140591513074e-06,
      "loss": 0.0001,
      "step": 38550
    },
    {
      "epoch": 8.264037719674239,
      "grad_norm": 0.008491049520671368,
      "learning_rate": 8.98128304043435e-06,
      "loss": 0.0001,
      "step": 38560
    },
    {
      "epoch": 8.266180882983283,
      "grad_norm": 0.007674052380025387,
      "learning_rate": 8.978425489355623e-06,
      "loss": 0.0,
      "step": 38570
    },
    {
      "epoch": 8.268324046292328,
      "grad_norm": 0.00043073261622339487,
      "learning_rate": 8.975567938276897e-06,
      "loss": 0.0001,
      "step": 38580
    },
    {
      "epoch": 8.270467209601371,
      "grad_norm": 0.008522490039467812,
      "learning_rate": 8.972710387198173e-06,
      "loss": 0.0001,
      "step": 38590
    },
    {
      "epoch": 8.272610372910416,
      "grad_norm": 0.013228117488324642,
      "learning_rate": 8.969852836119445e-06,
      "loss": 0.0001,
      "step": 38600
    },
    {
      "epoch": 8.27475353621946,
      "grad_norm": 0.0002720626653172076,
      "learning_rate": 8.96699528504072e-06,
      "loss": 0.0,
      "step": 38610
    },
    {
      "epoch": 8.276896699528503,
      "grad_norm": 0.11921119689941406,
      "learning_rate": 8.964137733961995e-06,
      "loss": 0.0004,
      "step": 38620
    },
    {
      "epoch": 8.279039862837548,
      "grad_norm": 0.004176112357527018,
      "learning_rate": 8.96128018288327e-06,
      "loss": 0.0,
      "step": 38630
    },
    {
      "epoch": 8.281183026146593,
      "grad_norm": 0.000579218496568501,
      "learning_rate": 8.958422631804544e-06,
      "loss": 0.0001,
      "step": 38640
    },
    {
      "epoch": 8.283326189455636,
      "grad_norm": 0.00024003852740861475,
      "learning_rate": 8.955565080725818e-06,
      "loss": 0.0001,
      "step": 38650
    },
    {
      "epoch": 8.28546935276468,
      "grad_norm": 0.000350268732290715,
      "learning_rate": 8.952707529647094e-06,
      "loss": 0.0003,
      "step": 38660
    },
    {
      "epoch": 8.287612516073725,
      "grad_norm": 0.09293241798877716,
      "learning_rate": 8.949849978568368e-06,
      "loss": 0.0001,
      "step": 38670
    },
    {
      "epoch": 8.289755679382768,
      "grad_norm": 0.002376814605668187,
      "learning_rate": 8.946992427489643e-06,
      "loss": 0.1798,
      "step": 38680
    },
    {
      "epoch": 8.291898842691813,
      "grad_norm": 0.023877978324890137,
      "learning_rate": 8.944134876410917e-06,
      "loss": 0.0001,
      "step": 38690
    },
    {
      "epoch": 8.294042006000858,
      "grad_norm": 0.00027372242766432464,
      "learning_rate": 8.941277325332191e-06,
      "loss": 0.0003,
      "step": 38700
    },
    {
      "epoch": 8.2961851693099,
      "grad_norm": 0.029731037095189095,
      "learning_rate": 8.938419774253465e-06,
      "loss": 0.0001,
      "step": 38710
    },
    {
      "epoch": 8.298328332618945,
      "grad_norm": 0.0009667949634604156,
      "learning_rate": 8.935562223174739e-06,
      "loss": 0.0002,
      "step": 38720
    },
    {
      "epoch": 8.30047149592799,
      "grad_norm": 0.0004609988536685705,
      "learning_rate": 8.932704672096015e-06,
      "loss": 0.1617,
      "step": 38730
    },
    {
      "epoch": 8.302614659237033,
      "grad_norm": 0.0002800858928821981,
      "learning_rate": 8.929847121017289e-06,
      "loss": 0.0,
      "step": 38740
    },
    {
      "epoch": 8.304757822546078,
      "grad_norm": 0.13268937170505524,
      "learning_rate": 8.926989569938564e-06,
      "loss": 0.0001,
      "step": 38750
    },
    {
      "epoch": 8.306900985855123,
      "grad_norm": 0.025702301412820816,
      "learning_rate": 8.924132018859838e-06,
      "loss": 0.3347,
      "step": 38760
    },
    {
      "epoch": 8.309044149164166,
      "grad_norm": 0.0013119300128892064,
      "learning_rate": 8.921274467781112e-06,
      "loss": 0.1187,
      "step": 38770
    },
    {
      "epoch": 8.31118731247321,
      "grad_norm": 0.001433808938600123,
      "learning_rate": 8.918416916702388e-06,
      "loss": 0.0,
      "step": 38780
    },
    {
      "epoch": 8.313330475782255,
      "grad_norm": 0.001853593741543591,
      "learning_rate": 8.915559365623662e-06,
      "loss": 0.0005,
      "step": 38790
    },
    {
      "epoch": 8.315473639091298,
      "grad_norm": 0.0008323881775140762,
      "learning_rate": 8.912701814544936e-06,
      "loss": 0.0001,
      "step": 38800
    },
    {
      "epoch": 8.317616802400343,
      "grad_norm": 0.02534220926463604,
      "learning_rate": 8.90984426346621e-06,
      "loss": 0.0001,
      "step": 38810
    },
    {
      "epoch": 8.319759965709387,
      "grad_norm": 0.0009863938903436065,
      "learning_rate": 8.906986712387485e-06,
      "loss": 0.0001,
      "step": 38820
    },
    {
      "epoch": 8.32190312901843,
      "grad_norm": 0.000674201175570488,
      "learning_rate": 8.904129161308759e-06,
      "loss": 0.0,
      "step": 38830
    },
    {
      "epoch": 8.324046292327475,
      "grad_norm": 0.003951466642320156,
      "learning_rate": 8.901271610230033e-06,
      "loss": 0.0001,
      "step": 38840
    },
    {
      "epoch": 8.32618945563652,
      "grad_norm": 0.0012993448181077838,
      "learning_rate": 8.898414059151309e-06,
      "loss": 0.0001,
      "step": 38850
    },
    {
      "epoch": 8.328332618945563,
      "grad_norm": 0.02978469803929329,
      "learning_rate": 8.895556508072582e-06,
      "loss": 0.0,
      "step": 38860
    },
    {
      "epoch": 8.330475782254608,
      "grad_norm": 0.000809891615062952,
      "learning_rate": 8.892698956993856e-06,
      "loss": 0.0002,
      "step": 38870
    },
    {
      "epoch": 8.332618945563652,
      "grad_norm": 0.0008050723117776215,
      "learning_rate": 8.889841405915132e-06,
      "loss": 0.0004,
      "step": 38880
    },
    {
      "epoch": 8.334762108872695,
      "grad_norm": 0.0008620554581284523,
      "learning_rate": 8.886983854836406e-06,
      "loss": 0.0,
      "step": 38890
    },
    {
      "epoch": 8.33690527218174,
      "grad_norm": 0.0004314858524594456,
      "learning_rate": 8.884126303757682e-06,
      "loss": 0.0,
      "step": 38900
    },
    {
      "epoch": 8.339048435490785,
      "grad_norm": 17.50575065612793,
      "learning_rate": 8.881268752678955e-06,
      "loss": 0.141,
      "step": 38910
    },
    {
      "epoch": 8.341191598799828,
      "grad_norm": 0.34288981556892395,
      "learning_rate": 8.87841120160023e-06,
      "loss": 0.0003,
      "step": 38920
    },
    {
      "epoch": 8.343334762108872,
      "grad_norm": 0.0008980645798146725,
      "learning_rate": 8.875553650521503e-06,
      "loss": 0.0,
      "step": 38930
    },
    {
      "epoch": 8.345477925417917,
      "grad_norm": 0.0008355050231330097,
      "learning_rate": 8.872696099442777e-06,
      "loss": 0.0613,
      "step": 38940
    },
    {
      "epoch": 8.34762108872696,
      "grad_norm": 0.0005304196383804083,
      "learning_rate": 8.869838548364053e-06,
      "loss": 0.0,
      "step": 38950
    },
    {
      "epoch": 8.349764252036005,
      "grad_norm": 0.0016053058207035065,
      "learning_rate": 8.866980997285327e-06,
      "loss": 0.0005,
      "step": 38960
    },
    {
      "epoch": 8.35190741534505,
      "grad_norm": 0.00027754611801356077,
      "learning_rate": 8.864123446206602e-06,
      "loss": 0.0,
      "step": 38970
    },
    {
      "epoch": 8.354050578654093,
      "grad_norm": 0.0006909340736456215,
      "learning_rate": 8.861265895127876e-06,
      "loss": 0.0,
      "step": 38980
    },
    {
      "epoch": 8.356193741963137,
      "grad_norm": 0.0026683055330067873,
      "learning_rate": 8.85840834404915e-06,
      "loss": 0.2484,
      "step": 38990
    },
    {
      "epoch": 8.358336905272182,
      "grad_norm": 0.0005158495041541755,
      "learning_rate": 8.855550792970426e-06,
      "loss": 0.0001,
      "step": 39000
    },
    {
      "epoch": 8.360480068581225,
      "grad_norm": 0.0032217379193753004,
      "learning_rate": 8.8526932418917e-06,
      "loss": 0.0,
      "step": 39010
    },
    {
      "epoch": 8.36262323189027,
      "grad_norm": 0.0010595970088616014,
      "learning_rate": 8.849835690812974e-06,
      "loss": 0.0,
      "step": 39020
    },
    {
      "epoch": 8.364766395199315,
      "grad_norm": 0.0003877685812767595,
      "learning_rate": 8.846978139734248e-06,
      "loss": 0.0001,
      "step": 39030
    },
    {
      "epoch": 8.366909558508357,
      "grad_norm": 0.0006334882928058505,
      "learning_rate": 8.844120588655523e-06,
      "loss": 0.0199,
      "step": 39040
    },
    {
      "epoch": 8.369052721817402,
      "grad_norm": 0.018237482756376266,
      "learning_rate": 8.841263037576797e-06,
      "loss": 0.0,
      "step": 39050
    },
    {
      "epoch": 8.371195885126447,
      "grad_norm": 0.004313971381634474,
      "learning_rate": 8.838405486498071e-06,
      "loss": 0.0006,
      "step": 39060
    },
    {
      "epoch": 8.37333904843549,
      "grad_norm": 0.004084742162376642,
      "learning_rate": 8.835547935419347e-06,
      "loss": 0.0,
      "step": 39070
    },
    {
      "epoch": 8.375482211744535,
      "grad_norm": 0.00024148166994564235,
      "learning_rate": 8.83269038434062e-06,
      "loss": 0.0,
      "step": 39080
    },
    {
      "epoch": 8.37762537505358,
      "grad_norm": 0.19060198962688446,
      "learning_rate": 8.829832833261895e-06,
      "loss": 0.0003,
      "step": 39090
    },
    {
      "epoch": 8.379768538362622,
      "grad_norm": 0.0008443704573437572,
      "learning_rate": 8.82697528218317e-06,
      "loss": 0.0,
      "step": 39100
    },
    {
      "epoch": 8.381911701671667,
      "grad_norm": 0.001815139432437718,
      "learning_rate": 8.824117731104444e-06,
      "loss": 0.0,
      "step": 39110
    },
    {
      "epoch": 8.384054864980712,
      "grad_norm": 0.005209303926676512,
      "learning_rate": 8.82126018002572e-06,
      "loss": 0.09,
      "step": 39120
    },
    {
      "epoch": 8.386198028289755,
      "grad_norm": 0.0005126059986650944,
      "learning_rate": 8.818402628946992e-06,
      "loss": 0.0,
      "step": 39130
    },
    {
      "epoch": 8.3883411915988,
      "grad_norm": 0.02305043488740921,
      "learning_rate": 8.815545077868268e-06,
      "loss": 0.0,
      "step": 39140
    },
    {
      "epoch": 8.390484354907844,
      "grad_norm": 0.00032531170290894806,
      "learning_rate": 8.812687526789542e-06,
      "loss": 0.0,
      "step": 39150
    },
    {
      "epoch": 8.392627518216887,
      "grad_norm": 0.0006548513192683458,
      "learning_rate": 8.809829975710816e-06,
      "loss": 0.0,
      "step": 39160
    },
    {
      "epoch": 8.394770681525932,
      "grad_norm": 0.0004024962254334241,
      "learning_rate": 8.806972424632091e-06,
      "loss": 0.0,
      "step": 39170
    },
    {
      "epoch": 8.396913844834977,
      "grad_norm": 0.018398668617010117,
      "learning_rate": 8.804114873553365e-06,
      "loss": 0.0002,
      "step": 39180
    },
    {
      "epoch": 8.39905700814402,
      "grad_norm": 0.0002047750458586961,
      "learning_rate": 8.80125732247464e-06,
      "loss": 0.0001,
      "step": 39190
    },
    {
      "epoch": 8.401200171453064,
      "grad_norm": 0.00020254988339729607,
      "learning_rate": 8.798399771395915e-06,
      "loss": 0.0,
      "step": 39200
    },
    {
      "epoch": 8.40334333476211,
      "grad_norm": 0.0003128079988528043,
      "learning_rate": 8.795542220317189e-06,
      "loss": 0.0,
      "step": 39210
    },
    {
      "epoch": 8.405486498071152,
      "grad_norm": 0.45221757888793945,
      "learning_rate": 8.792684669238464e-06,
      "loss": 0.1608,
      "step": 39220
    },
    {
      "epoch": 8.407629661380197,
      "grad_norm": 0.0018117136787623167,
      "learning_rate": 8.789827118159738e-06,
      "loss": 0.0004,
      "step": 39230
    },
    {
      "epoch": 8.409772824689242,
      "grad_norm": 0.00016763513849582523,
      "learning_rate": 8.786969567081012e-06,
      "loss": 0.0001,
      "step": 39240
    },
    {
      "epoch": 8.411915987998286,
      "grad_norm": 0.00025472097331658006,
      "learning_rate": 8.784112016002286e-06,
      "loss": 0.0,
      "step": 39250
    },
    {
      "epoch": 8.41405915130733,
      "grad_norm": 0.004217427223920822,
      "learning_rate": 8.781254464923562e-06,
      "loss": 0.2639,
      "step": 39260
    },
    {
      "epoch": 8.416202314616374,
      "grad_norm": 0.0012688026763498783,
      "learning_rate": 8.778396913844836e-06,
      "loss": 0.0,
      "step": 39270
    },
    {
      "epoch": 8.418345477925419,
      "grad_norm": 0.0007343754987232387,
      "learning_rate": 8.77553936276611e-06,
      "loss": 0.0001,
      "step": 39280
    },
    {
      "epoch": 8.420488641234462,
      "grad_norm": 0.0006127465749159455,
      "learning_rate": 8.772681811687385e-06,
      "loss": 0.0001,
      "step": 39290
    },
    {
      "epoch": 8.422631804543506,
      "grad_norm": 0.000820973131339997,
      "learning_rate": 8.769824260608659e-06,
      "loss": 0.0,
      "step": 39300
    },
    {
      "epoch": 8.424774967852551,
      "grad_norm": 0.0008860310190357268,
      "learning_rate": 8.766966709529933e-06,
      "loss": 0.0001,
      "step": 39310
    },
    {
      "epoch": 8.426918131161594,
      "grad_norm": 0.0002491524792276323,
      "learning_rate": 8.764109158451209e-06,
      "loss": 0.0011,
      "step": 39320
    },
    {
      "epoch": 8.429061294470639,
      "grad_norm": 0.0004181605763733387,
      "learning_rate": 8.761251607372483e-06,
      "loss": 0.0,
      "step": 39330
    },
    {
      "epoch": 8.431204457779684,
      "grad_norm": 0.0003376262029632926,
      "learning_rate": 8.758394056293758e-06,
      "loss": 0.0,
      "step": 39340
    },
    {
      "epoch": 8.433347621088727,
      "grad_norm": 0.001255935407243669,
      "learning_rate": 8.75553650521503e-06,
      "loss": 0.2246,
      "step": 39350
    },
    {
      "epoch": 8.435490784397771,
      "grad_norm": 0.3814541697502136,
      "learning_rate": 8.752678954136306e-06,
      "loss": 0.2447,
      "step": 39360
    },
    {
      "epoch": 8.437633947706816,
      "grad_norm": 0.009657378308475018,
      "learning_rate": 8.74982140305758e-06,
      "loss": 0.0238,
      "step": 39370
    },
    {
      "epoch": 8.439777111015859,
      "grad_norm": 0.005336184985935688,
      "learning_rate": 8.746963851978854e-06,
      "loss": 0.0,
      "step": 39380
    },
    {
      "epoch": 8.441920274324904,
      "grad_norm": 0.001287248800508678,
      "learning_rate": 8.74410630090013e-06,
      "loss": 0.0001,
      "step": 39390
    },
    {
      "epoch": 8.444063437633949,
      "grad_norm": 0.005218862555921078,
      "learning_rate": 8.741248749821403e-06,
      "loss": 0.0,
      "step": 39400
    },
    {
      "epoch": 8.446206600942991,
      "grad_norm": 0.004461994394659996,
      "learning_rate": 8.738391198742679e-06,
      "loss": 0.0001,
      "step": 39410
    },
    {
      "epoch": 8.448349764252036,
      "grad_norm": 0.013450236059725285,
      "learning_rate": 8.735533647663953e-06,
      "loss": 0.28,
      "step": 39420
    },
    {
      "epoch": 8.450492927561081,
      "grad_norm": 0.00266385730355978,
      "learning_rate": 8.732676096585227e-06,
      "loss": 0.0001,
      "step": 39430
    },
    {
      "epoch": 8.452636090870124,
      "grad_norm": 0.0010817988077178597,
      "learning_rate": 8.729818545506502e-06,
      "loss": 0.0242,
      "step": 39440
    },
    {
      "epoch": 8.454779254179169,
      "grad_norm": 0.002188553102314472,
      "learning_rate": 8.726960994427775e-06,
      "loss": 0.3511,
      "step": 39450
    },
    {
      "epoch": 8.456922417488213,
      "grad_norm": 0.000903880107216537,
      "learning_rate": 8.72410344334905e-06,
      "loss": 0.0001,
      "step": 39460
    },
    {
      "epoch": 8.459065580797256,
      "grad_norm": 0.0007274019299075007,
      "learning_rate": 8.721245892270324e-06,
      "loss": 0.0002,
      "step": 39470
    },
    {
      "epoch": 8.461208744106301,
      "grad_norm": 0.000638201367110014,
      "learning_rate": 8.7183883411916e-06,
      "loss": 0.355,
      "step": 39480
    },
    {
      "epoch": 8.463351907415346,
      "grad_norm": 0.0036059152334928513,
      "learning_rate": 8.715530790112874e-06,
      "loss": 0.0002,
      "step": 39490
    },
    {
      "epoch": 8.465495070724389,
      "grad_norm": 0.0002848126459866762,
      "learning_rate": 8.712673239034148e-06,
      "loss": 0.0001,
      "step": 39500
    },
    {
      "epoch": 8.467638234033434,
      "grad_norm": 0.0028784244786947966,
      "learning_rate": 8.709815687955423e-06,
      "loss": 0.0006,
      "step": 39510
    },
    {
      "epoch": 8.469781397342478,
      "grad_norm": 0.00043003231985494494,
      "learning_rate": 8.706958136876697e-06,
      "loss": 0.0001,
      "step": 39520
    },
    {
      "epoch": 8.471924560651521,
      "grad_norm": 0.0004926003748551011,
      "learning_rate": 8.704100585797973e-06,
      "loss": 0.0,
      "step": 39530
    },
    {
      "epoch": 8.474067723960566,
      "grad_norm": 0.0024539711885154247,
      "learning_rate": 8.701243034719247e-06,
      "loss": 0.0005,
      "step": 39540
    },
    {
      "epoch": 8.47621088726961,
      "grad_norm": 0.009743701666593552,
      "learning_rate": 8.69838548364052e-06,
      "loss": 0.0004,
      "step": 39550
    },
    {
      "epoch": 8.478354050578654,
      "grad_norm": 0.00016936608881223947,
      "learning_rate": 8.695527932561795e-06,
      "loss": 0.0825,
      "step": 39560
    },
    {
      "epoch": 8.480497213887698,
      "grad_norm": 0.0014496444491669536,
      "learning_rate": 8.692670381483069e-06,
      "loss": 0.0001,
      "step": 39570
    },
    {
      "epoch": 8.482640377196743,
      "grad_norm": 0.00019470855477266014,
      "learning_rate": 8.689812830404344e-06,
      "loss": 0.0001,
      "step": 39580
    },
    {
      "epoch": 8.484783540505786,
      "grad_norm": 0.00014372591977007687,
      "learning_rate": 8.686955279325618e-06,
      "loss": 0.0001,
      "step": 39590
    },
    {
      "epoch": 8.48692670381483,
      "grad_norm": 0.00020217610290274024,
      "learning_rate": 8.684097728246894e-06,
      "loss": 0.0,
      "step": 39600
    },
    {
      "epoch": 8.489069867123876,
      "grad_norm": 0.00013345948536880314,
      "learning_rate": 8.681240177168168e-06,
      "loss": 0.0,
      "step": 39610
    },
    {
      "epoch": 8.491213030432919,
      "grad_norm": 0.00016373525431845337,
      "learning_rate": 8.678382626089442e-06,
      "loss": 0.0115,
      "step": 39620
    },
    {
      "epoch": 8.493356193741963,
      "grad_norm": 0.00027752178721129894,
      "learning_rate": 8.675525075010717e-06,
      "loss": 0.0,
      "step": 39630
    },
    {
      "epoch": 8.495499357051008,
      "grad_norm": 0.009517461061477661,
      "learning_rate": 8.672667523931991e-06,
      "loss": 0.001,
      "step": 39640
    },
    {
      "epoch": 8.497642520360051,
      "grad_norm": 0.0002402333775535226,
      "learning_rate": 8.669809972853265e-06,
      "loss": 0.0,
      "step": 39650
    },
    {
      "epoch": 8.499785683669096,
      "grad_norm": 0.0007669534534215927,
      "learning_rate": 8.66695242177454e-06,
      "loss": 0.0,
      "step": 39660
    },
    {
      "epoch": 8.50192884697814,
      "grad_norm": 0.00014437751087825745,
      "learning_rate": 8.664094870695815e-06,
      "loss": 0.1804,
      "step": 39670
    },
    {
      "epoch": 8.504072010287183,
      "grad_norm": 0.0007657944224774837,
      "learning_rate": 8.661237319617089e-06,
      "loss": 0.1193,
      "step": 39680
    },
    {
      "epoch": 8.506215173596228,
      "grad_norm": 0.003501118393614888,
      "learning_rate": 8.658379768538363e-06,
      "loss": 0.0282,
      "step": 39690
    },
    {
      "epoch": 8.508358336905273,
      "grad_norm": 0.001889584818854928,
      "learning_rate": 8.655522217459638e-06,
      "loss": 0.0006,
      "step": 39700
    },
    {
      "epoch": 8.510501500214316,
      "grad_norm": 0.0002353176532778889,
      "learning_rate": 8.652664666380912e-06,
      "loss": 0.0001,
      "step": 39710
    },
    {
      "epoch": 8.51264466352336,
      "grad_norm": 0.00020841488731093705,
      "learning_rate": 8.649807115302186e-06,
      "loss": 0.0,
      "step": 39720
    },
    {
      "epoch": 8.514787826832405,
      "grad_norm": 0.0008108962792903185,
      "learning_rate": 8.646949564223462e-06,
      "loss": 0.0,
      "step": 39730
    },
    {
      "epoch": 8.516930990141448,
      "grad_norm": 0.021031629294157028,
      "learning_rate": 8.644092013144736e-06,
      "loss": 0.0,
      "step": 39740
    },
    {
      "epoch": 8.519074153450493,
      "grad_norm": 0.028090594336390495,
      "learning_rate": 8.641234462066011e-06,
      "loss": 0.4606,
      "step": 39750
    },
    {
      "epoch": 8.521217316759538,
      "grad_norm": 0.008290080353617668,
      "learning_rate": 8.638376910987285e-06,
      "loss": 0.0004,
      "step": 39760
    },
    {
      "epoch": 8.52336048006858,
      "grad_norm": 0.0040443409234285355,
      "learning_rate": 8.635519359908559e-06,
      "loss": 0.0002,
      "step": 39770
    },
    {
      "epoch": 8.525503643377625,
      "grad_norm": 0.004943246487528086,
      "learning_rate": 8.632661808829833e-06,
      "loss": 0.0001,
      "step": 39780
    },
    {
      "epoch": 8.52764680668667,
      "grad_norm": 0.007109025027602911,
      "learning_rate": 8.629804257751107e-06,
      "loss": 0.0001,
      "step": 39790
    },
    {
      "epoch": 8.529789969995713,
      "grad_norm": 0.0034530451521277428,
      "learning_rate": 8.626946706672383e-06,
      "loss": 0.0004,
      "step": 39800
    },
    {
      "epoch": 8.531933133304758,
      "grad_norm": 0.010908552445471287,
      "learning_rate": 8.624089155593656e-06,
      "loss": 0.0001,
      "step": 39810
    },
    {
      "epoch": 8.534076296613803,
      "grad_norm": 0.0015175298321992159,
      "learning_rate": 8.621231604514932e-06,
      "loss": 0.0001,
      "step": 39820
    },
    {
      "epoch": 8.536219459922846,
      "grad_norm": 21.736948013305664,
      "learning_rate": 8.618374053436206e-06,
      "loss": 0.4106,
      "step": 39830
    },
    {
      "epoch": 8.53836262323189,
      "grad_norm": 0.007194541860371828,
      "learning_rate": 8.61551650235748e-06,
      "loss": 0.0001,
      "step": 39840
    },
    {
      "epoch": 8.540505786540935,
      "grad_norm": 0.002399007324129343,
      "learning_rate": 8.612658951278756e-06,
      "loss": 0.0003,
      "step": 39850
    },
    {
      "epoch": 8.542648949849978,
      "grad_norm": 0.045084983110427856,
      "learning_rate": 8.60980140020003e-06,
      "loss": 0.0002,
      "step": 39860
    },
    {
      "epoch": 8.544792113159023,
      "grad_norm": 0.0021398046519607306,
      "learning_rate": 8.606943849121303e-06,
      "loss": 0.1796,
      "step": 39870
    },
    {
      "epoch": 8.546935276468067,
      "grad_norm": 0.0025908625684678555,
      "learning_rate": 8.604086298042577e-06,
      "loss": 0.0002,
      "step": 39880
    },
    {
      "epoch": 8.54907843977711,
      "grad_norm": 0.018015960231423378,
      "learning_rate": 8.601228746963853e-06,
      "loss": 0.0006,
      "step": 39890
    },
    {
      "epoch": 8.551221603086155,
      "grad_norm": 0.002878558123484254,
      "learning_rate": 8.598371195885127e-06,
      "loss": 0.1336,
      "step": 39900
    },
    {
      "epoch": 8.5533647663952,
      "grad_norm": 19.882770538330078,
      "learning_rate": 8.5955136448064e-06,
      "loss": 0.1117,
      "step": 39910
    },
    {
      "epoch": 8.555507929704243,
      "grad_norm": 0.00162379234097898,
      "learning_rate": 8.592656093727676e-06,
      "loss": 0.2631,
      "step": 39920
    },
    {
      "epoch": 8.557651093013288,
      "grad_norm": 0.0023213205859065056,
      "learning_rate": 8.58979854264895e-06,
      "loss": 0.0002,
      "step": 39930
    },
    {
      "epoch": 8.559794256322332,
      "grad_norm": 0.01652865670621395,
      "learning_rate": 8.586940991570224e-06,
      "loss": 0.0005,
      "step": 39940
    },
    {
      "epoch": 8.561937419631375,
      "grad_norm": 0.026079008355736732,
      "learning_rate": 8.5840834404915e-06,
      "loss": 0.0003,
      "step": 39950
    },
    {
      "epoch": 8.56408058294042,
      "grad_norm": 0.0012346055591478944,
      "learning_rate": 8.581225889412774e-06,
      "loss": 0.0586,
      "step": 39960
    },
    {
      "epoch": 8.566223746249465,
      "grad_norm": 0.0042295255698263645,
      "learning_rate": 8.57836833833405e-06,
      "loss": 0.0004,
      "step": 39970
    },
    {
      "epoch": 8.568366909558508,
      "grad_norm": 0.0012159472098574042,
      "learning_rate": 8.575510787255323e-06,
      "loss": 0.0,
      "step": 39980
    },
    {
      "epoch": 8.570510072867553,
      "grad_norm": 0.0006627222173847258,
      "learning_rate": 8.572653236176597e-06,
      "loss": 0.2531,
      "step": 39990
    },
    {
      "epoch": 8.572653236176597,
      "grad_norm": 0.0006427456974051893,
      "learning_rate": 8.569795685097871e-06,
      "loss": 0.293,
      "step": 40000
    },
    {
      "epoch": 8.57479639948564,
      "grad_norm": 0.0023896275088191032,
      "learning_rate": 8.566938134019145e-06,
      "loss": 0.14,
      "step": 40010
    },
    {
      "epoch": 8.576939562794685,
      "grad_norm": 26.159860610961914,
      "learning_rate": 8.56408058294042e-06,
      "loss": 0.1943,
      "step": 40020
    },
    {
      "epoch": 8.57908272610373,
      "grad_norm": 0.0025571908336132765,
      "learning_rate": 8.561223031861695e-06,
      "loss": 0.0011,
      "step": 40030
    },
    {
      "epoch": 8.581225889412773,
      "grad_norm": 0.006209030747413635,
      "learning_rate": 8.55836548078297e-06,
      "loss": 0.0002,
      "step": 40040
    },
    {
      "epoch": 8.583369052721817,
      "grad_norm": 0.020431948825716972,
      "learning_rate": 8.555507929704244e-06,
      "loss": 0.005,
      "step": 40050
    },
    {
      "epoch": 8.585512216030862,
      "grad_norm": 0.0013973221648484468,
      "learning_rate": 8.552650378625518e-06,
      "loss": 0.0003,
      "step": 40060
    },
    {
      "epoch": 8.587655379339905,
      "grad_norm": 0.01653929054737091,
      "learning_rate": 8.549792827546794e-06,
      "loss": 0.0002,
      "step": 40070
    },
    {
      "epoch": 8.58979854264895,
      "grad_norm": 0.0008589302888140082,
      "learning_rate": 8.546935276468068e-06,
      "loss": 0.0012,
      "step": 40080
    },
    {
      "epoch": 8.591941705957995,
      "grad_norm": 0.0007677249377593398,
      "learning_rate": 8.544077725389342e-06,
      "loss": 0.0,
      "step": 40090
    },
    {
      "epoch": 8.594084869267038,
      "grad_norm": 0.0027658112812787294,
      "learning_rate": 8.541220174310616e-06,
      "loss": 0.1344,
      "step": 40100
    },
    {
      "epoch": 8.596228032576082,
      "grad_norm": 0.0009755882201716304,
      "learning_rate": 8.538362623231891e-06,
      "loss": 0.1566,
      "step": 40110
    },
    {
      "epoch": 8.598371195885127,
      "grad_norm": 0.00239790347404778,
      "learning_rate": 8.535505072153165e-06,
      "loss": 0.0002,
      "step": 40120
    },
    {
      "epoch": 8.60051435919417,
      "grad_norm": 0.005097764544188976,
      "learning_rate": 8.532647521074439e-06,
      "loss": 0.0372,
      "step": 40130
    },
    {
      "epoch": 8.602657522503215,
      "grad_norm": 0.0012607115786522627,
      "learning_rate": 8.529789969995715e-06,
      "loss": 0.0003,
      "step": 40140
    },
    {
      "epoch": 8.60480068581226,
      "grad_norm": 0.003457617713138461,
      "learning_rate": 8.526932418916989e-06,
      "loss": 0.0002,
      "step": 40150
    },
    {
      "epoch": 8.606943849121302,
      "grad_norm": 0.0010038870386779308,
      "learning_rate": 8.524074867838263e-06,
      "loss": 0.0,
      "step": 40160
    },
    {
      "epoch": 8.609087012430347,
      "grad_norm": 0.0014824550598859787,
      "learning_rate": 8.521217316759538e-06,
      "loss": 0.0,
      "step": 40170
    },
    {
      "epoch": 8.611230175739392,
      "grad_norm": 0.000476341403555125,
      "learning_rate": 8.518359765680812e-06,
      "loss": 0.0001,
      "step": 40180
    },
    {
      "epoch": 8.613373339048435,
      "grad_norm": 0.0016321628354489803,
      "learning_rate": 8.515502214602088e-06,
      "loss": 0.0,
      "step": 40190
    },
    {
      "epoch": 8.61551650235748,
      "grad_norm": 0.003190024523064494,
      "learning_rate": 8.512644663523362e-06,
      "loss": 0.1154,
      "step": 40200
    },
    {
      "epoch": 8.617659665666524,
      "grad_norm": 0.001615831977687776,
      "learning_rate": 8.509787112444636e-06,
      "loss": 0.2583,
      "step": 40210
    },
    {
      "epoch": 8.619802828975567,
      "grad_norm": 0.0013293614611029625,
      "learning_rate": 8.50692956136591e-06,
      "loss": 0.0,
      "step": 40220
    },
    {
      "epoch": 8.621945992284612,
      "grad_norm": 0.00045887005398981273,
      "learning_rate": 8.504072010287183e-06,
      "loss": 0.0007,
      "step": 40230
    },
    {
      "epoch": 8.624089155593657,
      "grad_norm": 0.00044058452476747334,
      "learning_rate": 8.501214459208459e-06,
      "loss": 0.0001,
      "step": 40240
    },
    {
      "epoch": 8.6262323189027,
      "grad_norm": 0.001025688019581139,
      "learning_rate": 8.498356908129733e-06,
      "loss": 0.0,
      "step": 40250
    },
    {
      "epoch": 8.628375482211744,
      "grad_norm": 0.0016872792039066553,
      "learning_rate": 8.495499357051009e-06,
      "loss": 0.0,
      "step": 40260
    },
    {
      "epoch": 8.63051864552079,
      "grad_norm": 0.0008704182109795511,
      "learning_rate": 8.492641805972283e-06,
      "loss": 0.0377,
      "step": 40270
    },
    {
      "epoch": 8.632661808829832,
      "grad_norm": 0.0005160138825885952,
      "learning_rate": 8.489784254893557e-06,
      "loss": 0.0001,
      "step": 40280
    },
    {
      "epoch": 8.634804972138877,
      "grad_norm": 0.0006106864893808961,
      "learning_rate": 8.486926703814832e-06,
      "loss": 0.3235,
      "step": 40290
    },
    {
      "epoch": 8.636948135447922,
      "grad_norm": 0.000826727133244276,
      "learning_rate": 8.484069152736106e-06,
      "loss": 0.0004,
      "step": 40300
    },
    {
      "epoch": 8.639091298756965,
      "grad_norm": 0.004010421689599752,
      "learning_rate": 8.48121160165738e-06,
      "loss": 0.0001,
      "step": 40310
    },
    {
      "epoch": 8.64123446206601,
      "grad_norm": 0.6701926589012146,
      "learning_rate": 8.478354050578654e-06,
      "loss": 0.0017,
      "step": 40320
    },
    {
      "epoch": 8.643377625375054,
      "grad_norm": 0.0006828918121755123,
      "learning_rate": 8.47549649949993e-06,
      "loss": 0.0002,
      "step": 40330
    },
    {
      "epoch": 8.645520788684097,
      "grad_norm": 0.0024954667314887047,
      "learning_rate": 8.472638948421203e-06,
      "loss": 0.0014,
      "step": 40340
    },
    {
      "epoch": 8.647663951993142,
      "grad_norm": 0.0010129561414942145,
      "learning_rate": 8.469781397342477e-06,
      "loss": 0.3214,
      "step": 40350
    },
    {
      "epoch": 8.649807115302186,
      "grad_norm": 0.004689747467637062,
      "learning_rate": 8.466923846263753e-06,
      "loss": 0.0,
      "step": 40360
    },
    {
      "epoch": 8.65195027861123,
      "grad_norm": 0.0006317811203189194,
      "learning_rate": 8.464066295185027e-06,
      "loss": 0.2815,
      "step": 40370
    },
    {
      "epoch": 8.654093441920274,
      "grad_norm": 0.0009280142257921398,
      "learning_rate": 8.461208744106303e-06,
      "loss": 0.0001,
      "step": 40380
    },
    {
      "epoch": 8.656236605229319,
      "grad_norm": 0.004118066746741533,
      "learning_rate": 8.458351193027577e-06,
      "loss": 0.1888,
      "step": 40390
    },
    {
      "epoch": 8.658379768538362,
      "grad_norm": 0.005229714326560497,
      "learning_rate": 8.45549364194885e-06,
      "loss": 0.0002,
      "step": 40400
    },
    {
      "epoch": 8.660522931847407,
      "grad_norm": 0.001721411244943738,
      "learning_rate": 8.452636090870126e-06,
      "loss": 0.0001,
      "step": 40410
    },
    {
      "epoch": 8.662666095156451,
      "grad_norm": 0.002672619419172406,
      "learning_rate": 8.449778539791398e-06,
      "loss": 0.1486,
      "step": 40420
    },
    {
      "epoch": 8.664809258465494,
      "grad_norm": 0.0041277287527918816,
      "learning_rate": 8.446920988712674e-06,
      "loss": 0.0002,
      "step": 40430
    },
    {
      "epoch": 8.666952421774539,
      "grad_norm": 0.0009519956656731665,
      "learning_rate": 8.444063437633948e-06,
      "loss": 0.0001,
      "step": 40440
    },
    {
      "epoch": 8.669095585083584,
      "grad_norm": 0.004505273886024952,
      "learning_rate": 8.441205886555223e-06,
      "loss": 0.0001,
      "step": 40450
    },
    {
      "epoch": 8.671238748392627,
      "grad_norm": 0.0073102787137031555,
      "learning_rate": 8.438348335476497e-06,
      "loss": 0.0,
      "step": 40460
    },
    {
      "epoch": 8.673381911701671,
      "grad_norm": 0.017933299764990807,
      "learning_rate": 8.435490784397771e-06,
      "loss": 0.0006,
      "step": 40470
    },
    {
      "epoch": 8.675525075010716,
      "grad_norm": 0.0014691760297864676,
      "learning_rate": 8.432633233319047e-06,
      "loss": 0.0,
      "step": 40480
    },
    {
      "epoch": 8.67766823831976,
      "grad_norm": 0.0012564279604703188,
      "learning_rate": 8.429775682240321e-06,
      "loss": 0.0007,
      "step": 40490
    },
    {
      "epoch": 8.679811401628804,
      "grad_norm": 0.001496723503805697,
      "learning_rate": 8.426918131161595e-06,
      "loss": 0.0001,
      "step": 40500
    },
    {
      "epoch": 8.681954564937849,
      "grad_norm": 0.0017265616916120052,
      "learning_rate": 8.42406058008287e-06,
      "loss": 0.0,
      "step": 40510
    },
    {
      "epoch": 8.684097728246892,
      "grad_norm": 0.0014793830923736095,
      "learning_rate": 8.421203029004144e-06,
      "loss": 0.0,
      "step": 40520
    },
    {
      "epoch": 8.686240891555936,
      "grad_norm": 0.00136775360442698,
      "learning_rate": 8.418345477925418e-06,
      "loss": 0.0001,
      "step": 40530
    },
    {
      "epoch": 8.688384054864981,
      "grad_norm": 0.0006610060227103531,
      "learning_rate": 8.415487926846692e-06,
      "loss": 0.0001,
      "step": 40540
    },
    {
      "epoch": 8.690527218174024,
      "grad_norm": 0.000964917941018939,
      "learning_rate": 8.412630375767968e-06,
      "loss": 0.0001,
      "step": 40550
    },
    {
      "epoch": 8.692670381483069,
      "grad_norm": 0.0007582284742966294,
      "learning_rate": 8.409772824689242e-06,
      "loss": 0.0,
      "step": 40560
    },
    {
      "epoch": 8.694813544792114,
      "grad_norm": 0.6862549185752869,
      "learning_rate": 8.406915273610516e-06,
      "loss": 0.0001,
      "step": 40570
    },
    {
      "epoch": 8.696956708101157,
      "grad_norm": 0.002714044414460659,
      "learning_rate": 8.404057722531791e-06,
      "loss": 0.0005,
      "step": 40580
    },
    {
      "epoch": 8.699099871410201,
      "grad_norm": 0.0006056685233488679,
      "learning_rate": 8.401200171453065e-06,
      "loss": 0.0,
      "step": 40590
    },
    {
      "epoch": 8.701243034719246,
      "grad_norm": 0.0017114608781412244,
      "learning_rate": 8.398342620374341e-06,
      "loss": 0.0001,
      "step": 40600
    },
    {
      "epoch": 8.703386198028289,
      "grad_norm": 0.000531362893525511,
      "learning_rate": 8.395485069295615e-06,
      "loss": 0.0001,
      "step": 40610
    },
    {
      "epoch": 8.705529361337334,
      "grad_norm": 0.0018130631651729345,
      "learning_rate": 8.392627518216889e-06,
      "loss": 0.0015,
      "step": 40620
    },
    {
      "epoch": 8.707672524646378,
      "grad_norm": 0.00048392670578323305,
      "learning_rate": 8.389769967138164e-06,
      "loss": 0.0865,
      "step": 40630
    },
    {
      "epoch": 8.709815687955421,
      "grad_norm": 0.0014252476394176483,
      "learning_rate": 8.386912416059437e-06,
      "loss": 0.0005,
      "step": 40640
    },
    {
      "epoch": 8.711958851264466,
      "grad_norm": 0.002986264182254672,
      "learning_rate": 8.384054864980712e-06,
      "loss": 0.0,
      "step": 40650
    },
    {
      "epoch": 8.71410201457351,
      "grad_norm": 0.0003129246470052749,
      "learning_rate": 8.381197313901986e-06,
      "loss": 0.0002,
      "step": 40660
    },
    {
      "epoch": 8.716245177882554,
      "grad_norm": 0.00045859316014684737,
      "learning_rate": 8.378339762823262e-06,
      "loss": 0.0,
      "step": 40670
    },
    {
      "epoch": 8.718388341191599,
      "grad_norm": 0.0006007323390804231,
      "learning_rate": 8.375482211744536e-06,
      "loss": 0.0,
      "step": 40680
    },
    {
      "epoch": 8.720531504500643,
      "grad_norm": 0.0003788256726693362,
      "learning_rate": 8.37262466066581e-06,
      "loss": 0.0,
      "step": 40690
    },
    {
      "epoch": 8.722674667809688,
      "grad_norm": 0.0006208695704117417,
      "learning_rate": 8.369767109587085e-06,
      "loss": 0.2575,
      "step": 40700
    },
    {
      "epoch": 8.724817831118731,
      "grad_norm": 0.0004864174989052117,
      "learning_rate": 8.366909558508359e-06,
      "loss": 0.0005,
      "step": 40710
    },
    {
      "epoch": 8.726960994427776,
      "grad_norm": 0.0003568828396964818,
      "learning_rate": 8.364052007429633e-06,
      "loss": 0.0,
      "step": 40720
    },
    {
      "epoch": 8.72910415773682,
      "grad_norm": 0.00045874345232732594,
      "learning_rate": 8.361194456350909e-06,
      "loss": 0.1814,
      "step": 40730
    },
    {
      "epoch": 8.731247321045863,
      "grad_norm": 0.00025699130492284894,
      "learning_rate": 8.358336905272183e-06,
      "loss": 0.0,
      "step": 40740
    },
    {
      "epoch": 8.733390484354908,
      "grad_norm": 0.00045505849993787706,
      "learning_rate": 8.355479354193457e-06,
      "loss": 0.0,
      "step": 40750
    },
    {
      "epoch": 8.735533647663953,
      "grad_norm": 0.00489606149494648,
      "learning_rate": 8.35262180311473e-06,
      "loss": 0.0,
      "step": 40760
    },
    {
      "epoch": 8.737676810972996,
      "grad_norm": 0.00024139185552485287,
      "learning_rate": 8.349764252036006e-06,
      "loss": 0.0011,
      "step": 40770
    },
    {
      "epoch": 8.73981997428204,
      "grad_norm": 0.0013880501501262188,
      "learning_rate": 8.34690670095728e-06,
      "loss": 0.1076,
      "step": 40780
    },
    {
      "epoch": 8.741963137591085,
      "grad_norm": 0.00044816237641498446,
      "learning_rate": 8.344049149878554e-06,
      "loss": 0.0001,
      "step": 40790
    },
    {
      "epoch": 8.744106300900128,
      "grad_norm": 50.33571243286133,
      "learning_rate": 8.34119159879983e-06,
      "loss": 0.0181,
      "step": 40800
    },
    {
      "epoch": 8.746249464209173,
      "grad_norm": 0.0010846254881471395,
      "learning_rate": 8.338334047721104e-06,
      "loss": 0.2179,
      "step": 40810
    },
    {
      "epoch": 8.748392627518218,
      "grad_norm": 0.0003549902467057109,
      "learning_rate": 8.335476496642379e-06,
      "loss": 0.0,
      "step": 40820
    },
    {
      "epoch": 8.75053579082726,
      "grad_norm": 0.00043949278187938035,
      "learning_rate": 8.332618945563653e-06,
      "loss": 0.0001,
      "step": 40830
    },
    {
      "epoch": 8.752678954136305,
      "grad_norm": 0.00032246156479232013,
      "learning_rate": 8.329761394484927e-06,
      "loss": 0.1181,
      "step": 40840
    },
    {
      "epoch": 8.75482211744535,
      "grad_norm": 0.0006269218283705413,
      "learning_rate": 8.326903843406201e-06,
      "loss": 0.0002,
      "step": 40850
    },
    {
      "epoch": 8.756965280754393,
      "grad_norm": 0.0003279233060311526,
      "learning_rate": 8.324046292327475e-06,
      "loss": 0.0001,
      "step": 40860
    },
    {
      "epoch": 8.759108444063438,
      "grad_norm": 0.00394672155380249,
      "learning_rate": 8.32118874124875e-06,
      "loss": 0.1853,
      "step": 40870
    },
    {
      "epoch": 8.761251607372483,
      "grad_norm": 0.04073622077703476,
      "learning_rate": 8.318331190170024e-06,
      "loss": 0.0003,
      "step": 40880
    },
    {
      "epoch": 8.763394770681526,
      "grad_norm": 0.000869995856191963,
      "learning_rate": 8.3154736390913e-06,
      "loss": 0.0001,
      "step": 40890
    },
    {
      "epoch": 8.76553793399057,
      "grad_norm": 0.003591236425563693,
      "learning_rate": 8.312616088012574e-06,
      "loss": 0.0002,
      "step": 40900
    },
    {
      "epoch": 8.767681097299615,
      "grad_norm": 0.0013967001577839255,
      "learning_rate": 8.309758536933848e-06,
      "loss": 0.2634,
      "step": 40910
    },
    {
      "epoch": 8.769824260608658,
      "grad_norm": 0.011772160418331623,
      "learning_rate": 8.306900985855123e-06,
      "loss": 0.0,
      "step": 40920
    },
    {
      "epoch": 8.771967423917703,
      "grad_norm": 0.00920149590820074,
      "learning_rate": 8.304043434776397e-06,
      "loss": 0.0,
      "step": 40930
    },
    {
      "epoch": 8.774110587226748,
      "grad_norm": 0.0006342629203572869,
      "learning_rate": 8.301185883697671e-06,
      "loss": 0.0001,
      "step": 40940
    },
    {
      "epoch": 8.77625375053579,
      "grad_norm": 0.0007772092940285802,
      "learning_rate": 8.298328332618947e-06,
      "loss": 0.0,
      "step": 40950
    },
    {
      "epoch": 8.778396913844835,
      "grad_norm": 0.0005381659721024334,
      "learning_rate": 8.295470781540221e-06,
      "loss": 0.0006,
      "step": 40960
    },
    {
      "epoch": 8.78054007715388,
      "grad_norm": 0.0009375201188959181,
      "learning_rate": 8.292613230461495e-06,
      "loss": 0.0,
      "step": 40970
    },
    {
      "epoch": 8.782683240462923,
      "grad_norm": 0.0007666515884920955,
      "learning_rate": 8.289755679382769e-06,
      "loss": 0.0,
      "step": 40980
    },
    {
      "epoch": 8.784826403771968,
      "grad_norm": 0.000890629889909178,
      "learning_rate": 8.286898128304044e-06,
      "loss": 0.0,
      "step": 40990
    },
    {
      "epoch": 8.786969567081012,
      "grad_norm": 0.0005758201004937291,
      "learning_rate": 8.284040577225318e-06,
      "loss": 0.0001,
      "step": 41000
    },
    {
      "epoch": 8.789112730390055,
      "grad_norm": 0.0004941495135426521,
      "learning_rate": 8.281183026146592e-06,
      "loss": 0.0,
      "step": 41010
    },
    {
      "epoch": 8.7912558936991,
      "grad_norm": 0.00038442781078629196,
      "learning_rate": 8.278325475067868e-06,
      "loss": 0.0,
      "step": 41020
    },
    {
      "epoch": 8.793399057008145,
      "grad_norm": 0.0005165436887182295,
      "learning_rate": 8.275467923989142e-06,
      "loss": 0.0,
      "step": 41030
    },
    {
      "epoch": 8.795542220317188,
      "grad_norm": 0.0005830755108036101,
      "learning_rate": 8.272610372910417e-06,
      "loss": 0.0001,
      "step": 41040
    },
    {
      "epoch": 8.797685383626233,
      "grad_norm": 0.00043780732084997,
      "learning_rate": 8.269752821831691e-06,
      "loss": 0.3522,
      "step": 41050
    },
    {
      "epoch": 8.799828546935277,
      "grad_norm": 0.0004951389855705202,
      "learning_rate": 8.266895270752965e-06,
      "loss": 0.0004,
      "step": 41060
    },
    {
      "epoch": 8.80197171024432,
      "grad_norm": 34.86497116088867,
      "learning_rate": 8.26403771967424e-06,
      "loss": 0.2456,
      "step": 41070
    },
    {
      "epoch": 8.804114873553365,
      "grad_norm": 0.002094733528792858,
      "learning_rate": 8.261180168595513e-06,
      "loss": 0.0003,
      "step": 41080
    },
    {
      "epoch": 8.80625803686241,
      "grad_norm": 0.000510525715071708,
      "learning_rate": 8.258322617516789e-06,
      "loss": 0.2559,
      "step": 41090
    },
    {
      "epoch": 8.808401200171453,
      "grad_norm": 0.004923718050122261,
      "learning_rate": 8.255465066438063e-06,
      "loss": 0.0001,
      "step": 41100
    },
    {
      "epoch": 8.810544363480497,
      "grad_norm": 0.020108981058001518,
      "learning_rate": 8.252607515359338e-06,
      "loss": 0.1446,
      "step": 41110
    },
    {
      "epoch": 8.812687526789542,
      "grad_norm": 0.00301837595179677,
      "learning_rate": 8.249749964280612e-06,
      "loss": 0.0006,
      "step": 41120
    },
    {
      "epoch": 8.814830690098585,
      "grad_norm": 0.007066770922392607,
      "learning_rate": 8.246892413201886e-06,
      "loss": 0.0007,
      "step": 41130
    },
    {
      "epoch": 8.81697385340763,
      "grad_norm": 0.002535108244046569,
      "learning_rate": 8.244034862123162e-06,
      "loss": 0.1932,
      "step": 41140
    },
    {
      "epoch": 8.819117016716675,
      "grad_norm": 0.0017502137925475836,
      "learning_rate": 8.241177311044436e-06,
      "loss": 0.0004,
      "step": 41150
    },
    {
      "epoch": 8.821260180025718,
      "grad_norm": 0.07995029538869858,
      "learning_rate": 8.238319759965711e-06,
      "loss": 0.0009,
      "step": 41160
    },
    {
      "epoch": 8.823403343334762,
      "grad_norm": 0.001105761039070785,
      "learning_rate": 8.235462208886984e-06,
      "loss": 0.0001,
      "step": 41170
    },
    {
      "epoch": 8.825546506643807,
      "grad_norm": 0.0003661436785478145,
      "learning_rate": 8.23260465780826e-06,
      "loss": 0.0003,
      "step": 41180
    },
    {
      "epoch": 8.82768966995285,
      "grad_norm": 0.0012557615991681814,
      "learning_rate": 8.229747106729533e-06,
      "loss": 0.0001,
      "step": 41190
    },
    {
      "epoch": 8.829832833261895,
      "grad_norm": 0.0011891647009178996,
      "learning_rate": 8.226889555650807e-06,
      "loss": 0.0001,
      "step": 41200
    },
    {
      "epoch": 8.83197599657094,
      "grad_norm": 0.0012780106626451015,
      "learning_rate": 8.224032004572083e-06,
      "loss": 0.0001,
      "step": 41210
    },
    {
      "epoch": 8.834119159879982,
      "grad_norm": 0.0005165754118934274,
      "learning_rate": 8.221174453493357e-06,
      "loss": 0.0041,
      "step": 41220
    },
    {
      "epoch": 8.836262323189027,
      "grad_norm": 0.000828190182801336,
      "learning_rate": 8.218316902414632e-06,
      "loss": 0.0001,
      "step": 41230
    },
    {
      "epoch": 8.838405486498072,
      "grad_norm": 0.0016072893049567938,
      "learning_rate": 8.215459351335906e-06,
      "loss": 0.0001,
      "step": 41240
    },
    {
      "epoch": 8.840548649807115,
      "grad_norm": 0.00048356890329159796,
      "learning_rate": 8.21260180025718e-06,
      "loss": 0.1037,
      "step": 41250
    },
    {
      "epoch": 8.84269181311616,
      "grad_norm": 0.0004787234356626868,
      "learning_rate": 8.209744249178456e-06,
      "loss": 0.001,
      "step": 41260
    },
    {
      "epoch": 8.844834976425204,
      "grad_norm": 0.0012524280464276671,
      "learning_rate": 8.20688669809973e-06,
      "loss": 0.0005,
      "step": 41270
    },
    {
      "epoch": 8.846978139734247,
      "grad_norm": 0.010136469267308712,
      "learning_rate": 8.204029147021004e-06,
      "loss": 0.0003,
      "step": 41280
    },
    {
      "epoch": 8.849121303043292,
      "grad_norm": 0.0001688701449893415,
      "learning_rate": 8.201171595942277e-06,
      "loss": 0.0,
      "step": 41290
    },
    {
      "epoch": 8.851264466352337,
      "grad_norm": 0.0005201182793825865,
      "learning_rate": 8.198314044863553e-06,
      "loss": 0.0,
      "step": 41300
    },
    {
      "epoch": 8.85340762966138,
      "grad_norm": 0.0002303518122062087,
      "learning_rate": 8.195456493784827e-06,
      "loss": 0.0,
      "step": 41310
    },
    {
      "epoch": 8.855550792970424,
      "grad_norm": 0.00021756165369879454,
      "learning_rate": 8.192598942706101e-06,
      "loss": 0.0001,
      "step": 41320
    },
    {
      "epoch": 8.85769395627947,
      "grad_norm": 0.0003875010006595403,
      "learning_rate": 8.189741391627377e-06,
      "loss": 0.0,
      "step": 41330
    },
    {
      "epoch": 8.859837119588512,
      "grad_norm": 0.0009435949614271522,
      "learning_rate": 8.18688384054865e-06,
      "loss": 0.0,
      "step": 41340
    },
    {
      "epoch": 8.861980282897557,
      "grad_norm": 0.01219795923680067,
      "learning_rate": 8.184026289469924e-06,
      "loss": 0.0,
      "step": 41350
    },
    {
      "epoch": 8.864123446206602,
      "grad_norm": 36.532623291015625,
      "learning_rate": 8.1811687383912e-06,
      "loss": 0.0795,
      "step": 41360
    },
    {
      "epoch": 8.866266609515645,
      "grad_norm": 0.0013282641302794218,
      "learning_rate": 8.178311187312474e-06,
      "loss": 0.0,
      "step": 41370
    },
    {
      "epoch": 8.86840977282469,
      "grad_norm": 0.00031169416615739465,
      "learning_rate": 8.17545363623375e-06,
      "loss": 0.0,
      "step": 41380
    },
    {
      "epoch": 8.870552936133734,
      "grad_norm": 0.00018913688836619258,
      "learning_rate": 8.172596085155022e-06,
      "loss": 0.0,
      "step": 41390
    },
    {
      "epoch": 8.872696099442777,
      "grad_norm": 0.0010631181066855788,
      "learning_rate": 8.169738534076297e-06,
      "loss": 0.0,
      "step": 41400
    },
    {
      "epoch": 8.874839262751822,
      "grad_norm": 0.001557951676659286,
      "learning_rate": 8.166880982997571e-06,
      "loss": 0.0,
      "step": 41410
    },
    {
      "epoch": 8.876982426060867,
      "grad_norm": 0.00037493949639610946,
      "learning_rate": 8.164023431918845e-06,
      "loss": 0.0,
      "step": 41420
    },
    {
      "epoch": 8.87912558936991,
      "grad_norm": 0.010504881851375103,
      "learning_rate": 8.161165880840121e-06,
      "loss": 0.0,
      "step": 41430
    },
    {
      "epoch": 8.881268752678954,
      "grad_norm": 0.001087105949409306,
      "learning_rate": 8.158308329761395e-06,
      "loss": 0.2435,
      "step": 41440
    },
    {
      "epoch": 8.883411915987999,
      "grad_norm": 0.000582306704018265,
      "learning_rate": 8.15545077868267e-06,
      "loss": 0.0893,
      "step": 41450
    },
    {
      "epoch": 8.885555079297042,
      "grad_norm": 0.022730955854058266,
      "learning_rate": 8.152593227603944e-06,
      "loss": 0.0003,
      "step": 41460
    },
    {
      "epoch": 8.887698242606087,
      "grad_norm": 0.00023245108604896814,
      "learning_rate": 8.149735676525218e-06,
      "loss": 0.1259,
      "step": 41470
    },
    {
      "epoch": 8.889841405915131,
      "grad_norm": 0.0005246340297162533,
      "learning_rate": 8.146878125446494e-06,
      "loss": 0.0,
      "step": 41480
    },
    {
      "epoch": 8.891984569224174,
      "grad_norm": 0.00045530468923971057,
      "learning_rate": 8.144020574367766e-06,
      "loss": 0.0007,
      "step": 41490
    },
    {
      "epoch": 8.894127732533219,
      "grad_norm": 0.0002766010584309697,
      "learning_rate": 8.141163023289042e-06,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 8.896270895842264,
      "grad_norm": 0.0007607156876474619,
      "learning_rate": 8.138305472210316e-06,
      "loss": 0.708,
      "step": 41510
    },
    {
      "epoch": 8.898414059151307,
      "grad_norm": 0.00180906243622303,
      "learning_rate": 8.135447921131591e-06,
      "loss": 0.0001,
      "step": 41520
    },
    {
      "epoch": 8.900557222460352,
      "grad_norm": 0.0036190899554640055,
      "learning_rate": 8.132590370052865e-06,
      "loss": 0.0001,
      "step": 41530
    },
    {
      "epoch": 8.902700385769396,
      "grad_norm": 0.013885377906262875,
      "learning_rate": 8.12973281897414e-06,
      "loss": 0.0003,
      "step": 41540
    },
    {
      "epoch": 8.90484354907844,
      "grad_norm": 0.0018761774990707636,
      "learning_rate": 8.126875267895415e-06,
      "loss": 0.1674,
      "step": 41550
    },
    {
      "epoch": 8.906986712387484,
      "grad_norm": 0.009456820785999298,
      "learning_rate": 8.124017716816689e-06,
      "loss": 0.0002,
      "step": 41560
    },
    {
      "epoch": 8.909129875696529,
      "grad_norm": 0.003432095516473055,
      "learning_rate": 8.121160165737963e-06,
      "loss": 0.0001,
      "step": 41570
    },
    {
      "epoch": 8.911273039005572,
      "grad_norm": 0.004947172477841377,
      "learning_rate": 8.118302614659238e-06,
      "loss": 0.0001,
      "step": 41580
    },
    {
      "epoch": 8.913416202314616,
      "grad_norm": 0.0031361698638647795,
      "learning_rate": 8.115445063580512e-06,
      "loss": 0.0001,
      "step": 41590
    },
    {
      "epoch": 8.915559365623661,
      "grad_norm": 0.0011322777718305588,
      "learning_rate": 8.112587512501786e-06,
      "loss": 0.2119,
      "step": 41600
    },
    {
      "epoch": 8.917702528932704,
      "grad_norm": 0.005458913277834654,
      "learning_rate": 8.10972996142306e-06,
      "loss": 0.2844,
      "step": 41610
    },
    {
      "epoch": 8.919845692241749,
      "grad_norm": 0.001640600268729031,
      "learning_rate": 8.106872410344336e-06,
      "loss": 0.0001,
      "step": 41620
    },
    {
      "epoch": 8.921988855550794,
      "grad_norm": 0.0017956607043743134,
      "learning_rate": 8.10401485926561e-06,
      "loss": 0.0001,
      "step": 41630
    },
    {
      "epoch": 8.924132018859837,
      "grad_norm": 0.0008141990401782095,
      "learning_rate": 8.101157308186884e-06,
      "loss": 0.0001,
      "step": 41640
    },
    {
      "epoch": 8.926275182168881,
      "grad_norm": 0.0012536569265648723,
      "learning_rate": 8.09829975710816e-06,
      "loss": 0.0002,
      "step": 41650
    },
    {
      "epoch": 8.928418345477926,
      "grad_norm": 0.004458385519683361,
      "learning_rate": 8.095442206029433e-06,
      "loss": 0.0,
      "step": 41660
    },
    {
      "epoch": 8.930561508786969,
      "grad_norm": 0.0008225238416343927,
      "learning_rate": 8.092584654950709e-06,
      "loss": 0.0001,
      "step": 41670
    },
    {
      "epoch": 8.932704672096014,
      "grad_norm": 0.003458956955000758,
      "learning_rate": 8.089727103871983e-06,
      "loss": 0.0001,
      "step": 41680
    },
    {
      "epoch": 8.934847835405058,
      "grad_norm": 0.006513217464089394,
      "learning_rate": 8.086869552793257e-06,
      "loss": 0.3864,
      "step": 41690
    },
    {
      "epoch": 8.936990998714101,
      "grad_norm": 0.4280956983566284,
      "learning_rate": 8.084012001714532e-06,
      "loss": 0.0034,
      "step": 41700
    },
    {
      "epoch": 8.939134162023146,
      "grad_norm": 0.000424575264332816,
      "learning_rate": 8.081154450635804e-06,
      "loss": 0.0009,
      "step": 41710
    },
    {
      "epoch": 8.94127732533219,
      "grad_norm": 0.0012803912395611405,
      "learning_rate": 8.07829689955708e-06,
      "loss": 0.1886,
      "step": 41720
    },
    {
      "epoch": 8.943420488641234,
      "grad_norm": 0.003035519504919648,
      "learning_rate": 8.075439348478354e-06,
      "loss": 0.0006,
      "step": 41730
    },
    {
      "epoch": 8.945563651950279,
      "grad_norm": 0.0018442325526848435,
      "learning_rate": 8.07258179739963e-06,
      "loss": 0.0002,
      "step": 41740
    },
    {
      "epoch": 8.947706815259323,
      "grad_norm": 0.003104401985183358,
      "learning_rate": 8.069724246320904e-06,
      "loss": 0.0001,
      "step": 41750
    },
    {
      "epoch": 8.949849978568366,
      "grad_norm": 0.0003894198453053832,
      "learning_rate": 8.066866695242178e-06,
      "loss": 0.0002,
      "step": 41760
    },
    {
      "epoch": 8.951993141877411,
      "grad_norm": 0.0005821851082146168,
      "learning_rate": 8.064009144163453e-06,
      "loss": 0.0001,
      "step": 41770
    },
    {
      "epoch": 8.954136305186456,
      "grad_norm": 0.007195895072072744,
      "learning_rate": 8.061151593084727e-06,
      "loss": 0.0,
      "step": 41780
    },
    {
      "epoch": 8.956279468495499,
      "grad_norm": 0.008922024630010128,
      "learning_rate": 8.058294042006003e-06,
      "loss": 0.0001,
      "step": 41790
    },
    {
      "epoch": 8.958422631804543,
      "grad_norm": 0.002126776147633791,
      "learning_rate": 8.055436490927277e-06,
      "loss": 0.0001,
      "step": 41800
    },
    {
      "epoch": 8.960565795113588,
      "grad_norm": 0.00032179986010305583,
      "learning_rate": 8.05257893984855e-06,
      "loss": 0.0001,
      "step": 41810
    },
    {
      "epoch": 8.962708958422631,
      "grad_norm": 0.0007867290987633169,
      "learning_rate": 8.049721388769824e-06,
      "loss": 0.0047,
      "step": 41820
    },
    {
      "epoch": 8.964852121731676,
      "grad_norm": 0.0364668071269989,
      "learning_rate": 8.046863837691098e-06,
      "loss": 0.0002,
      "step": 41830
    },
    {
      "epoch": 8.96699528504072,
      "grad_norm": 0.010603806003928185,
      "learning_rate": 8.044006286612374e-06,
      "loss": 0.0001,
      "step": 41840
    },
    {
      "epoch": 8.969138448349764,
      "grad_norm": 0.0154005391523242,
      "learning_rate": 8.041148735533648e-06,
      "loss": 0.0002,
      "step": 41850
    },
    {
      "epoch": 8.971281611658808,
      "grad_norm": 0.0011556302197277546,
      "learning_rate": 8.038291184454924e-06,
      "loss": 0.0,
      "step": 41860
    },
    {
      "epoch": 8.973424774967853,
      "grad_norm": 0.001164535991847515,
      "learning_rate": 8.035433633376198e-06,
      "loss": 0.0001,
      "step": 41870
    },
    {
      "epoch": 8.975567938276896,
      "grad_norm": 0.005543338600546122,
      "learning_rate": 8.032576082297471e-06,
      "loss": 0.0,
      "step": 41880
    },
    {
      "epoch": 8.97771110158594,
      "grad_norm": 0.004000475630164146,
      "learning_rate": 8.029718531218747e-06,
      "loss": 0.009,
      "step": 41890
    },
    {
      "epoch": 8.979854264894986,
      "grad_norm": 0.0008882921538315713,
      "learning_rate": 8.026860980140021e-06,
      "loss": 0.0,
      "step": 41900
    },
    {
      "epoch": 8.981997428204028,
      "grad_norm": 0.00031714499345980585,
      "learning_rate": 8.024003429061295e-06,
      "loss": 0.0001,
      "step": 41910
    },
    {
      "epoch": 8.984140591513073,
      "grad_norm": 0.00027696919278241694,
      "learning_rate": 8.021145877982569e-06,
      "loss": 0.0,
      "step": 41920
    },
    {
      "epoch": 8.986283754822118,
      "grad_norm": 0.0003074727428611368,
      "learning_rate": 8.018288326903844e-06,
      "loss": 0.0,
      "step": 41930
    },
    {
      "epoch": 8.988426918131161,
      "grad_norm": 0.0010734924580901861,
      "learning_rate": 8.015430775825118e-06,
      "loss": 0.1841,
      "step": 41940
    },
    {
      "epoch": 8.990570081440206,
      "grad_norm": 0.00031186200794763863,
      "learning_rate": 8.012573224746392e-06,
      "loss": 0.0,
      "step": 41950
    },
    {
      "epoch": 8.99271324474925,
      "grad_norm": 0.00036823697155341506,
      "learning_rate": 8.009715673667668e-06,
      "loss": 0.0001,
      "step": 41960
    },
    {
      "epoch": 8.994856408058293,
      "grad_norm": 0.0027597961015999317,
      "learning_rate": 8.006858122588942e-06,
      "loss": 0.0009,
      "step": 41970
    },
    {
      "epoch": 8.996999571367338,
      "grad_norm": 0.02358228899538517,
      "learning_rate": 8.004000571510216e-06,
      "loss": 0.0002,
      "step": 41980
    },
    {
      "epoch": 8.999142734676383,
      "grad_norm": 0.002404354512691498,
      "learning_rate": 8.001143020431491e-06,
      "loss": 0.0,
      "step": 41990
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9236666666666666,
      "eval_f1": 0.7957181088314006,
      "eval_loss": 0.6601364612579346,
      "eval_precision": 0.828996282527881,
      "eval_recall": 0.7650085763293311,
      "eval_runtime": 108.4771,
      "eval_samples_per_second": 27.656,
      "eval_steps_per_second": 1.152,
      "step": 41994
    },
    {
      "epoch": 9.001285897985426,
      "grad_norm": 0.0002930514747276902,
      "learning_rate": 7.998285469352765e-06,
      "loss": 0.1428,
      "step": 42000
    },
    {
      "epoch": 9.00342906129447,
      "grad_norm": 0.0008949298644438386,
      "learning_rate": 7.995427918274041e-06,
      "loss": 0.0,
      "step": 42010
    },
    {
      "epoch": 9.005572224603515,
      "grad_norm": 0.0002158729184884578,
      "learning_rate": 7.992570367195315e-06,
      "loss": 0.001,
      "step": 42020
    },
    {
      "epoch": 9.007715387912558,
      "grad_norm": 0.007158402353525162,
      "learning_rate": 7.989712816116589e-06,
      "loss": 0.0002,
      "step": 42030
    },
    {
      "epoch": 9.009858551221603,
      "grad_norm": 0.002394695533439517,
      "learning_rate": 7.986855265037863e-06,
      "loss": 0.0003,
      "step": 42040
    },
    {
      "epoch": 9.012001714530648,
      "grad_norm": 0.0008263691561296582,
      "learning_rate": 7.983997713959137e-06,
      "loss": 0.2573,
      "step": 42050
    },
    {
      "epoch": 9.01414487783969,
      "grad_norm": 0.0017260339809581637,
      "learning_rate": 7.981140162880412e-06,
      "loss": 0.0,
      "step": 42060
    },
    {
      "epoch": 9.016288041148735,
      "grad_norm": 0.0019083794904872775,
      "learning_rate": 7.978282611801686e-06,
      "loss": 0.0001,
      "step": 42070
    },
    {
      "epoch": 9.01843120445778,
      "grad_norm": 0.003921540454030037,
      "learning_rate": 7.975425060722962e-06,
      "loss": 0.0005,
      "step": 42080
    },
    {
      "epoch": 9.020574367766823,
      "grad_norm": 0.0055479626171290874,
      "learning_rate": 7.972567509644236e-06,
      "loss": 0.0,
      "step": 42090
    },
    {
      "epoch": 9.022717531075868,
      "grad_norm": 0.0008139479323290288,
      "learning_rate": 7.96970995856551e-06,
      "loss": 0.0003,
      "step": 42100
    },
    {
      "epoch": 9.024860694384913,
      "grad_norm": 0.005187950562685728,
      "learning_rate": 7.966852407486785e-06,
      "loss": 0.0,
      "step": 42110
    },
    {
      "epoch": 9.027003857693956,
      "grad_norm": 0.0009062152239494026,
      "learning_rate": 7.96399485640806e-06,
      "loss": 0.1202,
      "step": 42120
    },
    {
      "epoch": 9.029147021003,
      "grad_norm": 0.011417332105338573,
      "learning_rate": 7.961137305329333e-06,
      "loss": 0.0001,
      "step": 42130
    },
    {
      "epoch": 9.031290184312045,
      "grad_norm": 0.032335858792066574,
      "learning_rate": 7.958279754250607e-06,
      "loss": 0.0001,
      "step": 42140
    },
    {
      "epoch": 9.033433347621088,
      "grad_norm": 0.0004817668523173779,
      "learning_rate": 7.955422203171883e-06,
      "loss": 0.0,
      "step": 42150
    },
    {
      "epoch": 9.035576510930133,
      "grad_norm": 0.0004225118027534336,
      "learning_rate": 7.952564652093157e-06,
      "loss": 0.0,
      "step": 42160
    },
    {
      "epoch": 9.037719674239177,
      "grad_norm": 0.0008779907366260886,
      "learning_rate": 7.94970710101443e-06,
      "loss": 0.0016,
      "step": 42170
    },
    {
      "epoch": 9.03986283754822,
      "grad_norm": 0.000540506443940103,
      "learning_rate": 7.946849549935706e-06,
      "loss": 0.1138,
      "step": 42180
    },
    {
      "epoch": 9.042006000857265,
      "grad_norm": 0.0011506445007398725,
      "learning_rate": 7.94399199885698e-06,
      "loss": 0.2433,
      "step": 42190
    },
    {
      "epoch": 9.04414916416631,
      "grad_norm": 0.0002651925606187433,
      "learning_rate": 7.941134447778254e-06,
      "loss": 0.2344,
      "step": 42200
    },
    {
      "epoch": 9.046292327475353,
      "grad_norm": 0.0003346501907799393,
      "learning_rate": 7.93827689669953e-06,
      "loss": 0.0001,
      "step": 42210
    },
    {
      "epoch": 9.048435490784398,
      "grad_norm": 0.012478247284889221,
      "learning_rate": 7.935419345620804e-06,
      "loss": 0.0001,
      "step": 42220
    },
    {
      "epoch": 9.050578654093442,
      "grad_norm": 0.00039679964538663626,
      "learning_rate": 7.93256179454208e-06,
      "loss": 0.0002,
      "step": 42230
    },
    {
      "epoch": 9.052721817402485,
      "grad_norm": 0.0009995788568630815,
      "learning_rate": 7.929704243463353e-06,
      "loss": 0.0,
      "step": 42240
    },
    {
      "epoch": 9.05486498071153,
      "grad_norm": 0.032944709062576294,
      "learning_rate": 7.926846692384627e-06,
      "loss": 0.1616,
      "step": 42250
    },
    {
      "epoch": 9.057008144020575,
      "grad_norm": 78.28074645996094,
      "learning_rate": 7.923989141305901e-06,
      "loss": 0.2106,
      "step": 42260
    },
    {
      "epoch": 9.059151307329618,
      "grad_norm": 0.00487552909180522,
      "learning_rate": 7.921131590227175e-06,
      "loss": 0.0001,
      "step": 42270
    },
    {
      "epoch": 9.061294470638662,
      "grad_norm": 0.00817179400473833,
      "learning_rate": 7.91827403914845e-06,
      "loss": 0.0001,
      "step": 42280
    },
    {
      "epoch": 9.063437633947707,
      "grad_norm": 0.0006757277296856046,
      "learning_rate": 7.915416488069725e-06,
      "loss": 0.0,
      "step": 42290
    },
    {
      "epoch": 9.06558079725675,
      "grad_norm": 0.0014486433938145638,
      "learning_rate": 7.912558936991e-06,
      "loss": 0.0003,
      "step": 42300
    },
    {
      "epoch": 9.067723960565795,
      "grad_norm": 0.0014257949078455567,
      "learning_rate": 7.909701385912274e-06,
      "loss": 0.0,
      "step": 42310
    },
    {
      "epoch": 9.06986712387484,
      "grad_norm": 0.011090795509517193,
      "learning_rate": 7.906843834833548e-06,
      "loss": 0.0,
      "step": 42320
    },
    {
      "epoch": 9.072010287183883,
      "grad_norm": 0.0006594330188818276,
      "learning_rate": 7.903986283754824e-06,
      "loss": 0.0003,
      "step": 42330
    },
    {
      "epoch": 9.074153450492927,
      "grad_norm": 0.00040366017492488027,
      "learning_rate": 7.901128732676098e-06,
      "loss": 0.0,
      "step": 42340
    },
    {
      "epoch": 9.076296613801972,
      "grad_norm": 0.00018140538304578513,
      "learning_rate": 7.898271181597371e-06,
      "loss": 0.0,
      "step": 42350
    },
    {
      "epoch": 9.078439777111015,
      "grad_norm": 0.00042913859942927957,
      "learning_rate": 7.895413630518645e-06,
      "loss": 0.0,
      "step": 42360
    },
    {
      "epoch": 9.08058294042006,
      "grad_norm": 0.0010681903222575784,
      "learning_rate": 7.892556079439921e-06,
      "loss": 0.0,
      "step": 42370
    },
    {
      "epoch": 9.082726103729104,
      "grad_norm": 0.01540779322385788,
      "learning_rate": 7.889698528361195e-06,
      "loss": 0.0,
      "step": 42380
    },
    {
      "epoch": 9.084869267038147,
      "grad_norm": 0.00016295273962896317,
      "learning_rate": 7.886840977282469e-06,
      "loss": 0.0,
      "step": 42390
    },
    {
      "epoch": 9.087012430347192,
      "grad_norm": 0.0020168398041278124,
      "learning_rate": 7.883983426203745e-06,
      "loss": 0.0,
      "step": 42400
    },
    {
      "epoch": 9.089155593656237,
      "grad_norm": 0.0024889730848371983,
      "learning_rate": 7.881125875125018e-06,
      "loss": 0.0,
      "step": 42410
    },
    {
      "epoch": 9.09129875696528,
      "grad_norm": 0.003845703788101673,
      "learning_rate": 7.878268324046292e-06,
      "loss": 0.0001,
      "step": 42420
    },
    {
      "epoch": 9.093441920274325,
      "grad_norm": 0.0009112412226386368,
      "learning_rate": 7.875410772967568e-06,
      "loss": 0.0,
      "step": 42430
    },
    {
      "epoch": 9.09558508358337,
      "grad_norm": 0.0005271101836115122,
      "learning_rate": 7.872553221888842e-06,
      "loss": 0.0004,
      "step": 42440
    },
    {
      "epoch": 9.097728246892412,
      "grad_norm": 0.0003206791006959975,
      "learning_rate": 7.869695670810118e-06,
      "loss": 0.1402,
      "step": 42450
    },
    {
      "epoch": 9.099871410201457,
      "grad_norm": 0.0003180256171617657,
      "learning_rate": 7.86683811973139e-06,
      "loss": 0.3187,
      "step": 42460
    },
    {
      "epoch": 9.102014573510502,
      "grad_norm": 0.002598485443741083,
      "learning_rate": 7.863980568652665e-06,
      "loss": 0.0,
      "step": 42470
    },
    {
      "epoch": 9.104157736819545,
      "grad_norm": 0.00037019402952864766,
      "learning_rate": 7.86112301757394e-06,
      "loss": 0.0001,
      "step": 42480
    },
    {
      "epoch": 9.10630090012859,
      "grad_norm": 0.004217531997710466,
      "learning_rate": 7.858265466495213e-06,
      "loss": 0.0,
      "step": 42490
    },
    {
      "epoch": 9.108444063437634,
      "grad_norm": 0.0005766582326032221,
      "learning_rate": 7.855407915416489e-06,
      "loss": 0.0004,
      "step": 42500
    },
    {
      "epoch": 9.110587226746677,
      "grad_norm": 0.0013401850592345,
      "learning_rate": 7.852550364337763e-06,
      "loss": 0.0,
      "step": 42510
    },
    {
      "epoch": 9.112730390055722,
      "grad_norm": 0.06892471015453339,
      "learning_rate": 7.849692813259038e-06,
      "loss": 0.0003,
      "step": 42520
    },
    {
      "epoch": 9.114873553364767,
      "grad_norm": 0.0008720015175640583,
      "learning_rate": 7.846835262180312e-06,
      "loss": 0.0,
      "step": 42530
    },
    {
      "epoch": 9.117016716673811,
      "grad_norm": 0.0008308265823870897,
      "learning_rate": 7.843977711101586e-06,
      "loss": 0.0,
      "step": 42540
    },
    {
      "epoch": 9.119159879982854,
      "grad_norm": 0.00029352560522966087,
      "learning_rate": 7.841120160022862e-06,
      "loss": 0.0,
      "step": 42550
    },
    {
      "epoch": 9.1213030432919,
      "grad_norm": 0.0004479795752558857,
      "learning_rate": 7.838262608944136e-06,
      "loss": 0.0,
      "step": 42560
    },
    {
      "epoch": 9.123446206600944,
      "grad_norm": 0.0005593589157797396,
      "learning_rate": 7.83540505786541e-06,
      "loss": 0.0056,
      "step": 42570
    },
    {
      "epoch": 9.125589369909987,
      "grad_norm": 0.0003998797037638724,
      "learning_rate": 7.832547506786684e-06,
      "loss": 0.0029,
      "step": 42580
    },
    {
      "epoch": 9.127732533219032,
      "grad_norm": 0.001202798681333661,
      "learning_rate": 7.82968995570796e-06,
      "loss": 0.0001,
      "step": 42590
    },
    {
      "epoch": 9.129875696528076,
      "grad_norm": 0.003579049604013562,
      "learning_rate": 7.826832404629233e-06,
      "loss": 0.0001,
      "step": 42600
    },
    {
      "epoch": 9.13201885983712,
      "grad_norm": 0.019763967022299767,
      "learning_rate": 7.823974853550507e-06,
      "loss": 0.0,
      "step": 42610
    },
    {
      "epoch": 9.134162023146164,
      "grad_norm": 0.000886228634044528,
      "learning_rate": 7.821117302471783e-06,
      "loss": 0.0,
      "step": 42620
    },
    {
      "epoch": 9.136305186455209,
      "grad_norm": 0.00028498380561359227,
      "learning_rate": 7.818259751393057e-06,
      "loss": 0.0,
      "step": 42630
    },
    {
      "epoch": 9.138448349764252,
      "grad_norm": 0.00016465925727970898,
      "learning_rate": 7.815402200314332e-06,
      "loss": 0.0001,
      "step": 42640
    },
    {
      "epoch": 9.140591513073296,
      "grad_norm": 0.0002625756897032261,
      "learning_rate": 7.812544649235606e-06,
      "loss": 0.0,
      "step": 42650
    },
    {
      "epoch": 9.142734676382341,
      "grad_norm": 0.0002345679677091539,
      "learning_rate": 7.80968709815688e-06,
      "loss": 0.0,
      "step": 42660
    },
    {
      "epoch": 9.144877839691384,
      "grad_norm": 0.00032009664573706686,
      "learning_rate": 7.806829547078156e-06,
      "loss": 0.0001,
      "step": 42670
    },
    {
      "epoch": 9.147021003000429,
      "grad_norm": 0.00023117892851587385,
      "learning_rate": 7.803971995999428e-06,
      "loss": 0.2151,
      "step": 42680
    },
    {
      "epoch": 9.149164166309474,
      "grad_norm": 0.0009375179070048034,
      "learning_rate": 7.801114444920704e-06,
      "loss": 0.0001,
      "step": 42690
    },
    {
      "epoch": 9.151307329618517,
      "grad_norm": 0.020197389647364616,
      "learning_rate": 7.798256893841978e-06,
      "loss": 0.0003,
      "step": 42700
    },
    {
      "epoch": 9.153450492927561,
      "grad_norm": 0.0001482705119997263,
      "learning_rate": 7.795399342763253e-06,
      "loss": 0.0001,
      "step": 42710
    },
    {
      "epoch": 9.155593656236606,
      "grad_norm": 0.0011013485491275787,
      "learning_rate": 7.792541791684527e-06,
      "loss": 0.0001,
      "step": 42720
    },
    {
      "epoch": 9.157736819545649,
      "grad_norm": 0.00023055561177898198,
      "learning_rate": 7.789684240605801e-06,
      "loss": 0.0001,
      "step": 42730
    },
    {
      "epoch": 9.159879982854694,
      "grad_norm": 0.0006647172849625349,
      "learning_rate": 7.786826689527077e-06,
      "loss": 0.0003,
      "step": 42740
    },
    {
      "epoch": 9.162023146163738,
      "grad_norm": 0.0022395013365894556,
      "learning_rate": 7.78396913844835e-06,
      "loss": 0.0001,
      "step": 42750
    },
    {
      "epoch": 9.164166309472781,
      "grad_norm": 0.00016940782370511442,
      "learning_rate": 7.781111587369625e-06,
      "loss": 0.0,
      "step": 42760
    },
    {
      "epoch": 9.166309472781826,
      "grad_norm": 0.00023532379418611526,
      "learning_rate": 7.7782540362909e-06,
      "loss": 0.0,
      "step": 42770
    },
    {
      "epoch": 9.168452636090871,
      "grad_norm": 0.00017059477977454662,
      "learning_rate": 7.775396485212174e-06,
      "loss": 0.1738,
      "step": 42780
    },
    {
      "epoch": 9.170595799399914,
      "grad_norm": 0.0011973741929978132,
      "learning_rate": 7.772538934133448e-06,
      "loss": 0.0,
      "step": 42790
    },
    {
      "epoch": 9.172738962708959,
      "grad_norm": 0.0018522528698667884,
      "learning_rate": 7.769681383054722e-06,
      "loss": 0.1873,
      "step": 42800
    },
    {
      "epoch": 9.174882126018003,
      "grad_norm": 0.0005799946375191212,
      "learning_rate": 7.766823831975998e-06,
      "loss": 0.0001,
      "step": 42810
    },
    {
      "epoch": 9.177025289327046,
      "grad_norm": 0.0005950132617726922,
      "learning_rate": 7.763966280897272e-06,
      "loss": 0.1912,
      "step": 42820
    },
    {
      "epoch": 9.179168452636091,
      "grad_norm": 0.018892815336585045,
      "learning_rate": 7.761108729818545e-06,
      "loss": 0.0001,
      "step": 42830
    },
    {
      "epoch": 9.181311615945136,
      "grad_norm": 0.000956396572291851,
      "learning_rate": 7.758251178739821e-06,
      "loss": 0.0,
      "step": 42840
    },
    {
      "epoch": 9.183454779254179,
      "grad_norm": 0.003420598804950714,
      "learning_rate": 7.755393627661095e-06,
      "loss": 0.0,
      "step": 42850
    },
    {
      "epoch": 9.185597942563223,
      "grad_norm": 0.00041699467692524195,
      "learning_rate": 7.75253607658237e-06,
      "loss": 0.0,
      "step": 42860
    },
    {
      "epoch": 9.187741105872268,
      "grad_norm": 0.21641339361667633,
      "learning_rate": 7.749678525503645e-06,
      "loss": 0.0001,
      "step": 42870
    },
    {
      "epoch": 9.189884269181311,
      "grad_norm": 0.00469578942283988,
      "learning_rate": 7.746820974424918e-06,
      "loss": 0.0001,
      "step": 42880
    },
    {
      "epoch": 9.192027432490356,
      "grad_norm": 0.0009751170291565359,
      "learning_rate": 7.743963423346192e-06,
      "loss": 0.219,
      "step": 42890
    },
    {
      "epoch": 9.1941705957994,
      "grad_norm": 0.0002582765882834792,
      "learning_rate": 7.741105872267466e-06,
      "loss": 0.0,
      "step": 42900
    },
    {
      "epoch": 9.196313759108444,
      "grad_norm": 0.001382088870741427,
      "learning_rate": 7.738248321188742e-06,
      "loss": 0.0,
      "step": 42910
    },
    {
      "epoch": 9.198456922417488,
      "grad_norm": 0.0003892271197400987,
      "learning_rate": 7.735390770110016e-06,
      "loss": 0.0001,
      "step": 42920
    },
    {
      "epoch": 9.200600085726533,
      "grad_norm": 0.00173481076490134,
      "learning_rate": 7.732533219031292e-06,
      "loss": 0.0001,
      "step": 42930
    },
    {
      "epoch": 9.202743249035576,
      "grad_norm": 0.0002827597490977496,
      "learning_rate": 7.729675667952565e-06,
      "loss": 0.0,
      "step": 42940
    },
    {
      "epoch": 9.20488641234462,
      "grad_norm": 0.00035691019729711115,
      "learning_rate": 7.72681811687384e-06,
      "loss": 0.1894,
      "step": 42950
    },
    {
      "epoch": 9.207029575653666,
      "grad_norm": 0.0023650622460991144,
      "learning_rate": 7.723960565795115e-06,
      "loss": 0.0001,
      "step": 42960
    },
    {
      "epoch": 9.209172738962708,
      "grad_norm": 3.9976160526275635,
      "learning_rate": 7.721103014716389e-06,
      "loss": 0.0077,
      "step": 42970
    },
    {
      "epoch": 9.211315902271753,
      "grad_norm": 0.0004884243244305253,
      "learning_rate": 7.718245463637663e-06,
      "loss": 0.0001,
      "step": 42980
    },
    {
      "epoch": 9.213459065580798,
      "grad_norm": 0.00046166093670763075,
      "learning_rate": 7.715387912558938e-06,
      "loss": 0.1743,
      "step": 42990
    },
    {
      "epoch": 9.215602228889841,
      "grad_norm": 0.0006125971558503807,
      "learning_rate": 7.712530361480212e-06,
      "loss": 0.0,
      "step": 43000
    },
    {
      "epoch": 9.217745392198886,
      "grad_norm": 0.031902819871902466,
      "learning_rate": 7.709672810401486e-06,
      "loss": 0.0001,
      "step": 43010
    },
    {
      "epoch": 9.21988855550793,
      "grad_norm": 0.0550985224545002,
      "learning_rate": 7.70681525932276e-06,
      "loss": 0.0001,
      "step": 43020
    },
    {
      "epoch": 9.222031718816973,
      "grad_norm": 0.00029640496359206736,
      "learning_rate": 7.703957708244036e-06,
      "loss": 0.0001,
      "step": 43030
    },
    {
      "epoch": 9.224174882126018,
      "grad_norm": 0.0002979004930239171,
      "learning_rate": 7.70110015716531e-06,
      "loss": 0.0001,
      "step": 43040
    },
    {
      "epoch": 9.226318045435063,
      "grad_norm": 0.00019429971871431917,
      "learning_rate": 7.698242606086584e-06,
      "loss": 0.0,
      "step": 43050
    },
    {
      "epoch": 9.228461208744106,
      "grad_norm": 0.0010852314298972487,
      "learning_rate": 7.69538505500786e-06,
      "loss": 0.0002,
      "step": 43060
    },
    {
      "epoch": 9.23060437205315,
      "grad_norm": 0.00019847242219839245,
      "learning_rate": 7.692527503929133e-06,
      "loss": 0.0003,
      "step": 43070
    },
    {
      "epoch": 9.232747535362195,
      "grad_norm": 0.00031300136470235884,
      "learning_rate": 7.689669952850409e-06,
      "loss": 0.0,
      "step": 43080
    },
    {
      "epoch": 9.234890698671238,
      "grad_norm": 0.0005929087637923658,
      "learning_rate": 7.686812401771683e-06,
      "loss": 0.0004,
      "step": 43090
    },
    {
      "epoch": 9.237033861980283,
      "grad_norm": 0.00015203554357867688,
      "learning_rate": 7.683954850692957e-06,
      "loss": 0.0001,
      "step": 43100
    },
    {
      "epoch": 9.239177025289328,
      "grad_norm": 0.0010609438177198172,
      "learning_rate": 7.68109729961423e-06,
      "loss": 0.0001,
      "step": 43110
    },
    {
      "epoch": 9.24132018859837,
      "grad_norm": 0.00227560312487185,
      "learning_rate": 7.678239748535505e-06,
      "loss": 0.1764,
      "step": 43120
    },
    {
      "epoch": 9.243463351907415,
      "grad_norm": 0.00867491401731968,
      "learning_rate": 7.67538219745678e-06,
      "loss": 0.1543,
      "step": 43130
    },
    {
      "epoch": 9.24560651521646,
      "grad_norm": 0.00024334581394214183,
      "learning_rate": 7.672524646378054e-06,
      "loss": 0.0001,
      "step": 43140
    },
    {
      "epoch": 9.247749678525503,
      "grad_norm": 0.00021658574405591935,
      "learning_rate": 7.66966709529933e-06,
      "loss": 0.0,
      "step": 43150
    },
    {
      "epoch": 9.249892841834548,
      "grad_norm": 0.00025795353576540947,
      "learning_rate": 7.666809544220604e-06,
      "loss": 0.0001,
      "step": 43160
    },
    {
      "epoch": 9.252036005143593,
      "grad_norm": 0.00020667175704147667,
      "learning_rate": 7.663951993141878e-06,
      "loss": 0.0001,
      "step": 43170
    },
    {
      "epoch": 9.254179168452636,
      "grad_norm": 0.020374123007059097,
      "learning_rate": 7.661094442063153e-06,
      "loss": 0.0001,
      "step": 43180
    },
    {
      "epoch": 9.25632233176168,
      "grad_norm": 0.01090890634804964,
      "learning_rate": 7.658236890984427e-06,
      "loss": 0.0,
      "step": 43190
    },
    {
      "epoch": 9.258465495070725,
      "grad_norm": 0.00045215163845568895,
      "learning_rate": 7.655379339905701e-06,
      "loss": 0.0,
      "step": 43200
    },
    {
      "epoch": 9.260608658379768,
      "grad_norm": 0.00030362638062797487,
      "learning_rate": 7.652521788826975e-06,
      "loss": 0.0,
      "step": 43210
    },
    {
      "epoch": 9.262751821688813,
      "grad_norm": 0.006396278738975525,
      "learning_rate": 7.64966423774825e-06,
      "loss": 0.0,
      "step": 43220
    },
    {
      "epoch": 9.264894984997857,
      "grad_norm": 0.00017236045096069574,
      "learning_rate": 7.646806686669525e-06,
      "loss": 0.0,
      "step": 43230
    },
    {
      "epoch": 9.2670381483069,
      "grad_norm": 0.0002279411710333079,
      "learning_rate": 7.643949135590799e-06,
      "loss": 0.0002,
      "step": 43240
    },
    {
      "epoch": 9.269181311615945,
      "grad_norm": 0.00030961065203882754,
      "learning_rate": 7.641091584512074e-06,
      "loss": 0.2538,
      "step": 43250
    },
    {
      "epoch": 9.27132447492499,
      "grad_norm": 0.0008985562017187476,
      "learning_rate": 7.638234033433348e-06,
      "loss": 0.0,
      "step": 43260
    },
    {
      "epoch": 9.273467638234033,
      "grad_norm": 0.006334292236715555,
      "learning_rate": 7.635376482354622e-06,
      "loss": 0.0001,
      "step": 43270
    },
    {
      "epoch": 9.275610801543078,
      "grad_norm": 0.003974982537329197,
      "learning_rate": 7.632518931275898e-06,
      "loss": 0.0,
      "step": 43280
    },
    {
      "epoch": 9.277753964852122,
      "grad_norm": 0.00039470853516831994,
      "learning_rate": 7.629661380197172e-06,
      "loss": 0.0,
      "step": 43290
    },
    {
      "epoch": 9.279897128161165,
      "grad_norm": 0.00045459679677151144,
      "learning_rate": 7.626803829118446e-06,
      "loss": 0.0002,
      "step": 43300
    },
    {
      "epoch": 9.28204029147021,
      "grad_norm": 0.0008875141502358019,
      "learning_rate": 7.623946278039721e-06,
      "loss": 0.0006,
      "step": 43310
    },
    {
      "epoch": 9.284183454779255,
      "grad_norm": 0.0014040557434782386,
      "learning_rate": 7.621088726960994e-06,
      "loss": 0.0057,
      "step": 43320
    },
    {
      "epoch": 9.286326618088298,
      "grad_norm": 0.0022322789300233126,
      "learning_rate": 7.618231175882269e-06,
      "loss": 0.0,
      "step": 43330
    },
    {
      "epoch": 9.288469781397342,
      "grad_norm": 0.10766640305519104,
      "learning_rate": 7.615373624803544e-06,
      "loss": 0.0003,
      "step": 43340
    },
    {
      "epoch": 9.290612944706387,
      "grad_norm": 0.0001267218467546627,
      "learning_rate": 7.6125160737248185e-06,
      "loss": 0.0,
      "step": 43350
    },
    {
      "epoch": 9.29275610801543,
      "grad_norm": 0.00011082419223384932,
      "learning_rate": 7.6096585226460924e-06,
      "loss": 0.0002,
      "step": 43360
    },
    {
      "epoch": 9.294899271324475,
      "grad_norm": 0.2579921782016754,
      "learning_rate": 7.606800971567367e-06,
      "loss": 0.2523,
      "step": 43370
    },
    {
      "epoch": 9.29704243463352,
      "grad_norm": 0.0003199554339516908,
      "learning_rate": 7.603943420488642e-06,
      "loss": 0.0,
      "step": 43380
    },
    {
      "epoch": 9.299185597942563,
      "grad_norm": 0.024336909875273705,
      "learning_rate": 7.601085869409917e-06,
      "loss": 0.0002,
      "step": 43390
    },
    {
      "epoch": 9.301328761251607,
      "grad_norm": 0.000634734402410686,
      "learning_rate": 7.5982283183311915e-06,
      "loss": 0.0001,
      "step": 43400
    },
    {
      "epoch": 9.303471924560652,
      "grad_norm": 0.0003053035179618746,
      "learning_rate": 7.5953707672524655e-06,
      "loss": 0.0,
      "step": 43410
    },
    {
      "epoch": 9.305615087869695,
      "grad_norm": 0.00015282697859220207,
      "learning_rate": 7.59251321617374e-06,
      "loss": 0.0006,
      "step": 43420
    },
    {
      "epoch": 9.30775825117874,
      "grad_norm": 0.0721830204129219,
      "learning_rate": 7.589655665095013e-06,
      "loss": 0.0,
      "step": 43430
    },
    {
      "epoch": 9.309901414487785,
      "grad_norm": 0.0007576881325803697,
      "learning_rate": 7.586798114016288e-06,
      "loss": 0.0002,
      "step": 43440
    },
    {
      "epoch": 9.312044577796827,
      "grad_norm": 0.031547751277685165,
      "learning_rate": 7.583940562937563e-06,
      "loss": 0.0005,
      "step": 43450
    },
    {
      "epoch": 9.314187741105872,
      "grad_norm": 1.2425600290298462,
      "learning_rate": 7.581083011858838e-06,
      "loss": 0.1607,
      "step": 43460
    },
    {
      "epoch": 9.316330904414917,
      "grad_norm": 0.00015194568550214171,
      "learning_rate": 7.5782254607801124e-06,
      "loss": 0.0002,
      "step": 43470
    },
    {
      "epoch": 9.31847406772396,
      "grad_norm": 9.547717490931973e-05,
      "learning_rate": 7.575367909701386e-06,
      "loss": 0.2824,
      "step": 43480
    },
    {
      "epoch": 9.320617231033005,
      "grad_norm": 0.00011759265180444345,
      "learning_rate": 7.572510358622661e-06,
      "loss": 0.0,
      "step": 43490
    },
    {
      "epoch": 9.32276039434205,
      "grad_norm": 0.003965084906667471,
      "learning_rate": 7.569652807543936e-06,
      "loss": 0.0,
      "step": 43500
    },
    {
      "epoch": 9.324903557651092,
      "grad_norm": 0.00010565822594799101,
      "learning_rate": 7.566795256465211e-06,
      "loss": 0.0,
      "step": 43510
    },
    {
      "epoch": 9.327046720960137,
      "grad_norm": 0.0001858358591562137,
      "learning_rate": 7.563937705386485e-06,
      "loss": 0.0,
      "step": 43520
    },
    {
      "epoch": 9.329189884269182,
      "grad_norm": 0.0001770186936482787,
      "learning_rate": 7.5610801543077585e-06,
      "loss": 0.0,
      "step": 43530
    },
    {
      "epoch": 9.331333047578225,
      "grad_norm": 0.0004176576912868768,
      "learning_rate": 7.558222603229033e-06,
      "loss": 0.0,
      "step": 43540
    },
    {
      "epoch": 9.33347621088727,
      "grad_norm": 0.002567115006968379,
      "learning_rate": 7.555365052150307e-06,
      "loss": 0.0127,
      "step": 43550
    },
    {
      "epoch": 9.335619374196314,
      "grad_norm": 0.00019769287609960884,
      "learning_rate": 7.552507501071582e-06,
      "loss": 0.0,
      "step": 43560
    },
    {
      "epoch": 9.337762537505357,
      "grad_norm": 0.0002612338284961879,
      "learning_rate": 7.549649949992857e-06,
      "loss": 0.0,
      "step": 43570
    },
    {
      "epoch": 9.339905700814402,
      "grad_norm": 9.807440073927864e-05,
      "learning_rate": 7.5467923989141316e-06,
      "loss": 0.0,
      "step": 43580
    },
    {
      "epoch": 9.342048864123447,
      "grad_norm": 0.00012070083903381601,
      "learning_rate": 7.5439348478354055e-06,
      "loss": 0.0,
      "step": 43590
    },
    {
      "epoch": 9.34419202743249,
      "grad_norm": 0.00010251002822769806,
      "learning_rate": 7.54107729675668e-06,
      "loss": 0.0,
      "step": 43600
    },
    {
      "epoch": 9.346335190741534,
      "grad_norm": 0.00017482161638326943,
      "learning_rate": 7.538219745677955e-06,
      "loss": 0.0001,
      "step": 43610
    },
    {
      "epoch": 9.34847835405058,
      "grad_norm": 0.00014119756815489382,
      "learning_rate": 7.53536219459923e-06,
      "loss": 0.0091,
      "step": 43620
    },
    {
      "epoch": 9.350621517359622,
      "grad_norm": 0.00013368508371058851,
      "learning_rate": 7.532504643520504e-06,
      "loss": 0.0,
      "step": 43630
    },
    {
      "epoch": 9.352764680668667,
      "grad_norm": 7.068389822961763e-05,
      "learning_rate": 7.529647092441778e-06,
      "loss": 0.0,
      "step": 43640
    },
    {
      "epoch": 9.354907843977712,
      "grad_norm": 0.012277543544769287,
      "learning_rate": 7.5267895413630525e-06,
      "loss": 0.0,
      "step": 43650
    },
    {
      "epoch": 9.357051007286755,
      "grad_norm": 0.00854488555341959,
      "learning_rate": 7.523931990284326e-06,
      "loss": 0.0,
      "step": 43660
    },
    {
      "epoch": 9.3591941705958,
      "grad_norm": 0.004862257745116949,
      "learning_rate": 7.521074439205601e-06,
      "loss": 0.0,
      "step": 43670
    },
    {
      "epoch": 9.361337333904844,
      "grad_norm": 0.0015726719284430146,
      "learning_rate": 7.518216888126876e-06,
      "loss": 0.2021,
      "step": 43680
    },
    {
      "epoch": 9.363480497213887,
      "grad_norm": 0.00011327493120916188,
      "learning_rate": 7.515359337048151e-06,
      "loss": 0.0297,
      "step": 43690
    },
    {
      "epoch": 9.365623660522932,
      "grad_norm": 0.0009563345811329782,
      "learning_rate": 7.512501785969425e-06,
      "loss": 0.0009,
      "step": 43700
    },
    {
      "epoch": 9.367766823831976,
      "grad_norm": 0.0006477166898548603,
      "learning_rate": 7.509644234890699e-06,
      "loss": 0.0,
      "step": 43710
    },
    {
      "epoch": 9.36990998714102,
      "grad_norm": 0.00021174902212806046,
      "learning_rate": 7.506786683811974e-06,
      "loss": 0.0167,
      "step": 43720
    },
    {
      "epoch": 9.372053150450064,
      "grad_norm": 0.007778707891702652,
      "learning_rate": 7.503929132733249e-06,
      "loss": 0.0,
      "step": 43730
    },
    {
      "epoch": 9.374196313759109,
      "grad_norm": 0.00014640296285506338,
      "learning_rate": 7.501071581654523e-06,
      "loss": 0.0,
      "step": 43740
    },
    {
      "epoch": 9.376339477068152,
      "grad_norm": 0.00011844855907838792,
      "learning_rate": 7.498214030575797e-06,
      "loss": 0.0,
      "step": 43750
    },
    {
      "epoch": 9.378482640377197,
      "grad_norm": 8.043634443311021e-05,
      "learning_rate": 7.495356479497072e-06,
      "loss": 0.0,
      "step": 43760
    },
    {
      "epoch": 9.380625803686241,
      "grad_norm": 0.00014402574743144214,
      "learning_rate": 7.4924989284183455e-06,
      "loss": 0.0,
      "step": 43770
    },
    {
      "epoch": 9.382768966995284,
      "grad_norm": 0.00023832761507946998,
      "learning_rate": 7.48964137733962e-06,
      "loss": 0.0,
      "step": 43780
    },
    {
      "epoch": 9.384912130304329,
      "grad_norm": 0.00012606041855178773,
      "learning_rate": 7.486783826260895e-06,
      "loss": 0.0,
      "step": 43790
    },
    {
      "epoch": 9.387055293613374,
      "grad_norm": 0.00017731990374159068,
      "learning_rate": 7.48392627518217e-06,
      "loss": 0.0,
      "step": 43800
    },
    {
      "epoch": 9.389198456922417,
      "grad_norm": 0.00022844766499474645,
      "learning_rate": 7.481068724103444e-06,
      "loss": 0.0,
      "step": 43810
    },
    {
      "epoch": 9.391341620231461,
      "grad_norm": 0.00037187550333328545,
      "learning_rate": 7.4782111730247186e-06,
      "loss": 0.0,
      "step": 43820
    },
    {
      "epoch": 9.393484783540506,
      "grad_norm": 0.0003870450018439442,
      "learning_rate": 7.475353621945993e-06,
      "loss": 0.2663,
      "step": 43830
    },
    {
      "epoch": 9.39562794684955,
      "grad_norm": 0.00319233862683177,
      "learning_rate": 7.472496070867268e-06,
      "loss": 0.2109,
      "step": 43840
    },
    {
      "epoch": 9.397771110158594,
      "grad_norm": 0.028667181730270386,
      "learning_rate": 7.469638519788542e-06,
      "loss": 0.0001,
      "step": 43850
    },
    {
      "epoch": 9.399914273467639,
      "grad_norm": 0.08041804283857346,
      "learning_rate": 7.466780968709816e-06,
      "loss": 0.0002,
      "step": 43860
    },
    {
      "epoch": 9.402057436776682,
      "grad_norm": 0.004812092054635286,
      "learning_rate": 7.463923417631091e-06,
      "loss": 0.0002,
      "step": 43870
    },
    {
      "epoch": 9.404200600085726,
      "grad_norm": 0.0008324814261868596,
      "learning_rate": 7.461065866552365e-06,
      "loss": 0.0002,
      "step": 43880
    },
    {
      "epoch": 9.406343763394771,
      "grad_norm": 0.0009136777953244746,
      "learning_rate": 7.4582083154736394e-06,
      "loss": 0.0001,
      "step": 43890
    },
    {
      "epoch": 9.408486926703814,
      "grad_norm": 0.0002402986428933218,
      "learning_rate": 7.455350764394914e-06,
      "loss": 0.0001,
      "step": 43900
    },
    {
      "epoch": 9.410630090012859,
      "grad_norm": 0.00040321872802451253,
      "learning_rate": 7.452493213316189e-06,
      "loss": 0.0,
      "step": 43910
    },
    {
      "epoch": 9.412773253321904,
      "grad_norm": 0.00019012637494597584,
      "learning_rate": 7.449635662237463e-06,
      "loss": 0.2044,
      "step": 43920
    },
    {
      "epoch": 9.414916416630946,
      "grad_norm": 0.00014551942877005786,
      "learning_rate": 7.446778111158738e-06,
      "loss": 0.0,
      "step": 43930
    },
    {
      "epoch": 9.417059579939991,
      "grad_norm": 0.0025085557717829943,
      "learning_rate": 7.4439205600800125e-06,
      "loss": 0.2741,
      "step": 43940
    },
    {
      "epoch": 9.419202743249036,
      "grad_norm": 0.0040151141583919525,
      "learning_rate": 7.441063009001287e-06,
      "loss": 0.0002,
      "step": 43950
    },
    {
      "epoch": 9.421345906558079,
      "grad_norm": 0.765388011932373,
      "learning_rate": 7.43820545792256e-06,
      "loss": 0.0008,
      "step": 43960
    },
    {
      "epoch": 9.423489069867124,
      "grad_norm": 0.002034947508946061,
      "learning_rate": 7.435347906843835e-06,
      "loss": 0.0,
      "step": 43970
    },
    {
      "epoch": 9.425632233176168,
      "grad_norm": 0.048905085772275925,
      "learning_rate": 7.43249035576511e-06,
      "loss": 0.0001,
      "step": 43980
    },
    {
      "epoch": 9.427775396485211,
      "grad_norm": 0.0001865404046839103,
      "learning_rate": 7.429632804686384e-06,
      "loss": 0.0,
      "step": 43990
    },
    {
      "epoch": 9.429918559794256,
      "grad_norm": 0.00016949472774285823,
      "learning_rate": 7.426775253607659e-06,
      "loss": 0.0009,
      "step": 44000
    },
    {
      "epoch": 9.4320617231033,
      "grad_norm": 8.496062946505845e-05,
      "learning_rate": 7.423917702528933e-06,
      "loss": 0.3153,
      "step": 44010
    },
    {
      "epoch": 9.434204886412344,
      "grad_norm": 0.0001502850209362805,
      "learning_rate": 7.421060151450208e-06,
      "loss": 0.0,
      "step": 44020
    },
    {
      "epoch": 9.436348049721389,
      "grad_norm": 9.225079702446237e-05,
      "learning_rate": 7.418202600371482e-06,
      "loss": 0.0,
      "step": 44030
    },
    {
      "epoch": 9.438491213030433,
      "grad_norm": 0.00010874485451495275,
      "learning_rate": 7.415345049292757e-06,
      "loss": 0.0,
      "step": 44040
    },
    {
      "epoch": 9.440634376339476,
      "grad_norm": 0.0019429518142715096,
      "learning_rate": 7.412487498214032e-06,
      "loss": 0.0,
      "step": 44050
    },
    {
      "epoch": 9.442777539648521,
      "grad_norm": 7.897725299699232e-05,
      "learning_rate": 7.409629947135306e-06,
      "loss": 0.0,
      "step": 44060
    },
    {
      "epoch": 9.444920702957566,
      "grad_norm": 42.996028900146484,
      "learning_rate": 7.4067723960565795e-06,
      "loss": 0.2461,
      "step": 44070
    },
    {
      "epoch": 9.447063866266609,
      "grad_norm": 0.00011915146023966372,
      "learning_rate": 7.403914844977854e-06,
      "loss": 0.1277,
      "step": 44080
    },
    {
      "epoch": 9.449207029575653,
      "grad_norm": 0.00014614823157899082,
      "learning_rate": 7.401057293899129e-06,
      "loss": 0.0,
      "step": 44090
    },
    {
      "epoch": 9.451350192884698,
      "grad_norm": 0.00018627294048201293,
      "learning_rate": 7.398199742820403e-06,
      "loss": 0.1964,
      "step": 44100
    },
    {
      "epoch": 9.453493356193743,
      "grad_norm": 0.00010218838724540547,
      "learning_rate": 7.395342191741678e-06,
      "loss": 0.0,
      "step": 44110
    },
    {
      "epoch": 9.455636519502786,
      "grad_norm": 0.00011042886762879789,
      "learning_rate": 7.3924846406629525e-06,
      "loss": 0.0,
      "step": 44120
    },
    {
      "epoch": 9.45777968281183,
      "grad_norm": 0.0016294728266075253,
      "learning_rate": 7.389627089584227e-06,
      "loss": 0.0,
      "step": 44130
    },
    {
      "epoch": 9.459922846120875,
      "grad_norm": 0.015018363483250141,
      "learning_rate": 7.386769538505501e-06,
      "loss": 0.0001,
      "step": 44140
    },
    {
      "epoch": 9.462066009429918,
      "grad_norm": 0.0004485821700654924,
      "learning_rate": 7.383911987426776e-06,
      "loss": 0.0,
      "step": 44150
    },
    {
      "epoch": 9.464209172738963,
      "grad_norm": 0.00010499627387616783,
      "learning_rate": 7.381054436348051e-06,
      "loss": 0.0,
      "step": 44160
    },
    {
      "epoch": 9.466352336048008,
      "grad_norm": 0.0001771783281583339,
      "learning_rate": 7.3781968852693255e-06,
      "loss": 0.0,
      "step": 44170
    },
    {
      "epoch": 9.46849549935705,
      "grad_norm": 0.00029004731914028525,
      "learning_rate": 7.375339334190599e-06,
      "loss": 0.0,
      "step": 44180
    },
    {
      "epoch": 9.470638662666095,
      "grad_norm": 0.0013132905587553978,
      "learning_rate": 7.372481783111873e-06,
      "loss": 0.0,
      "step": 44190
    },
    {
      "epoch": 9.47278182597514,
      "grad_norm": 8.929565228754655e-05,
      "learning_rate": 7.369624232033148e-06,
      "loss": 0.0,
      "step": 44200
    },
    {
      "epoch": 9.474924989284183,
      "grad_norm": 0.00033093258389271796,
      "learning_rate": 7.366766680954422e-06,
      "loss": 0.0,
      "step": 44210
    },
    {
      "epoch": 9.477068152593228,
      "grad_norm": 0.002827912103384733,
      "learning_rate": 7.363909129875697e-06,
      "loss": 0.0,
      "step": 44220
    },
    {
      "epoch": 9.479211315902273,
      "grad_norm": 0.00024959276197478175,
      "learning_rate": 7.361051578796972e-06,
      "loss": 0.0138,
      "step": 44230
    },
    {
      "epoch": 9.481354479211316,
      "grad_norm": 8.267941302619874e-05,
      "learning_rate": 7.358194027718246e-06,
      "loss": 0.0004,
      "step": 44240
    },
    {
      "epoch": 9.48349764252036,
      "grad_norm": 7.61324554332532e-05,
      "learning_rate": 7.355336476639521e-06,
      "loss": 0.0,
      "step": 44250
    },
    {
      "epoch": 9.485640805829405,
      "grad_norm": 0.001258434378542006,
      "learning_rate": 7.352478925560795e-06,
      "loss": 0.0,
      "step": 44260
    },
    {
      "epoch": 9.487783969138448,
      "grad_norm": 0.03006320260465145,
      "learning_rate": 7.34962137448207e-06,
      "loss": 0.0,
      "step": 44270
    },
    {
      "epoch": 9.489927132447493,
      "grad_norm": 413.68304443359375,
      "learning_rate": 7.346763823403345e-06,
      "loss": 0.0256,
      "step": 44280
    },
    {
      "epoch": 9.492070295756537,
      "grad_norm": 8.430096204392612e-05,
      "learning_rate": 7.343906272324618e-06,
      "loss": 0.0004,
      "step": 44290
    },
    {
      "epoch": 9.49421345906558,
      "grad_norm": 0.0008823403040878475,
      "learning_rate": 7.3410487212458925e-06,
      "loss": 0.2406,
      "step": 44300
    },
    {
      "epoch": 9.496356622374625,
      "grad_norm": 0.00021146460494492203,
      "learning_rate": 7.338191170167167e-06,
      "loss": 0.0,
      "step": 44310
    },
    {
      "epoch": 9.49849978568367,
      "grad_norm": 0.0006769208703190088,
      "learning_rate": 7.335333619088442e-06,
      "loss": 0.0001,
      "step": 44320
    },
    {
      "epoch": 9.500642948992713,
      "grad_norm": 9.501269232714549e-05,
      "learning_rate": 7.332476068009716e-06,
      "loss": 0.0,
      "step": 44330
    },
    {
      "epoch": 9.502786112301758,
      "grad_norm": 36.86112594604492,
      "learning_rate": 7.329618516930991e-06,
      "loss": 0.4919,
      "step": 44340
    },
    {
      "epoch": 9.504929275610802,
      "grad_norm": 0.0001016040550894104,
      "learning_rate": 7.3267609658522655e-06,
      "loss": 0.0006,
      "step": 44350
    },
    {
      "epoch": 9.507072438919845,
      "grad_norm": 0.0064146192744374275,
      "learning_rate": 7.32390341477354e-06,
      "loss": 0.0,
      "step": 44360
    },
    {
      "epoch": 9.50921560222889,
      "grad_norm": 0.005893494468182325,
      "learning_rate": 7.321045863694814e-06,
      "loss": 0.1706,
      "step": 44370
    },
    {
      "epoch": 9.511358765537935,
      "grad_norm": 0.0006774929934181273,
      "learning_rate": 7.318188312616089e-06,
      "loss": 0.0002,
      "step": 44380
    },
    {
      "epoch": 9.513501928846978,
      "grad_norm": 0.004604758229106665,
      "learning_rate": 7.315330761537363e-06,
      "loss": 0.0002,
      "step": 44390
    },
    {
      "epoch": 9.515645092156022,
      "grad_norm": 9.954538836609572e-05,
      "learning_rate": 7.312473210458637e-06,
      "loss": 0.0,
      "step": 44400
    },
    {
      "epoch": 9.517788255465067,
      "grad_norm": 43.42624282836914,
      "learning_rate": 7.309615659379912e-06,
      "loss": 0.3327,
      "step": 44410
    },
    {
      "epoch": 9.51993141877411,
      "grad_norm": 708.0243530273438,
      "learning_rate": 7.3067581083011864e-06,
      "loss": 0.0539,
      "step": 44420
    },
    {
      "epoch": 9.522074582083155,
      "grad_norm": 0.00012858069385401905,
      "learning_rate": 7.303900557222461e-06,
      "loss": 0.0001,
      "step": 44430
    },
    {
      "epoch": 9.5242177453922,
      "grad_norm": 0.00015011546202003956,
      "learning_rate": 7.301043006143735e-06,
      "loss": 0.0001,
      "step": 44440
    },
    {
      "epoch": 9.526360908701243,
      "grad_norm": 0.006546338554471731,
      "learning_rate": 7.29818545506501e-06,
      "loss": 0.0,
      "step": 44450
    },
    {
      "epoch": 9.528504072010287,
      "grad_norm": 0.00010281460708938539,
      "learning_rate": 7.295327903986285e-06,
      "loss": 0.0,
      "step": 44460
    },
    {
      "epoch": 9.530647235319332,
      "grad_norm": 0.10339876264333725,
      "learning_rate": 7.2924703529075595e-06,
      "loss": 0.0001,
      "step": 44470
    },
    {
      "epoch": 9.532790398628375,
      "grad_norm": 0.0011756959138438106,
      "learning_rate": 7.289612801828833e-06,
      "loss": 0.0088,
      "step": 44480
    },
    {
      "epoch": 9.53493356193742,
      "grad_norm": 7.874222501413897e-05,
      "learning_rate": 7.286755250750108e-06,
      "loss": 0.0,
      "step": 44490
    },
    {
      "epoch": 9.537076725246465,
      "grad_norm": 0.002529338700696826,
      "learning_rate": 7.283897699671382e-06,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 9.539219888555508,
      "grad_norm": 0.00021262826339807361,
      "learning_rate": 7.281040148592656e-06,
      "loss": 0.0,
      "step": 44510
    },
    {
      "epoch": 9.541363051864552,
      "grad_norm": 0.000174190106918104,
      "learning_rate": 7.278182597513931e-06,
      "loss": 0.0001,
      "step": 44520
    },
    {
      "epoch": 9.543506215173597,
      "grad_norm": 0.00035401820787228644,
      "learning_rate": 7.2753250464352056e-06,
      "loss": 0.1067,
      "step": 44530
    },
    {
      "epoch": 9.54564937848264,
      "grad_norm": 0.0001411542616551742,
      "learning_rate": 7.27246749535648e-06,
      "loss": 0.0,
      "step": 44540
    },
    {
      "epoch": 9.547792541791685,
      "grad_norm": 0.00024030954227782786,
      "learning_rate": 7.269609944277754e-06,
      "loss": 0.0,
      "step": 44550
    },
    {
      "epoch": 9.54993570510073,
      "grad_norm": 0.00016137247439473867,
      "learning_rate": 7.266752393199029e-06,
      "loss": 0.0001,
      "step": 44560
    },
    {
      "epoch": 9.552078868409772,
      "grad_norm": 0.007178386207669973,
      "learning_rate": 7.263894842120304e-06,
      "loss": 0.0,
      "step": 44570
    },
    {
      "epoch": 9.554222031718817,
      "grad_norm": 8.045083814067766e-05,
      "learning_rate": 7.261037291041579e-06,
      "loss": 0.0,
      "step": 44580
    },
    {
      "epoch": 9.556365195027862,
      "grad_norm": 5.945071825408377e-05,
      "learning_rate": 7.2581797399628525e-06,
      "loss": 0.175,
      "step": 44590
    },
    {
      "epoch": 9.558508358336905,
      "grad_norm": 9.136673907050863e-05,
      "learning_rate": 7.255322188884127e-06,
      "loss": 0.0001,
      "step": 44600
    },
    {
      "epoch": 9.56065152164595,
      "grad_norm": 0.000498100882396102,
      "learning_rate": 7.252464637805401e-06,
      "loss": 0.0001,
      "step": 44610
    },
    {
      "epoch": 9.562794684954994,
      "grad_norm": 6.519549060612917e-05,
      "learning_rate": 7.249607086726675e-06,
      "loss": 0.0002,
      "step": 44620
    },
    {
      "epoch": 9.564937848264037,
      "grad_norm": 0.015188155695796013,
      "learning_rate": 7.24674953564795e-06,
      "loss": 0.0,
      "step": 44630
    },
    {
      "epoch": 9.567081011573082,
      "grad_norm": 0.00013862621563021094,
      "learning_rate": 7.243891984569225e-06,
      "loss": 0.1593,
      "step": 44640
    },
    {
      "epoch": 9.569224174882127,
      "grad_norm": 6.839630077593029e-05,
      "learning_rate": 7.2410344334904995e-06,
      "loss": 0.0,
      "step": 44650
    },
    {
      "epoch": 9.57136733819117,
      "grad_norm": 0.0021721310913562775,
      "learning_rate": 7.238176882411773e-06,
      "loss": 0.0,
      "step": 44660
    },
    {
      "epoch": 9.573510501500214,
      "grad_norm": 6.814011430833489e-05,
      "learning_rate": 7.235319331333048e-06,
      "loss": 0.0707,
      "step": 44670
    },
    {
      "epoch": 9.57565366480926,
      "grad_norm": 0.001729448908008635,
      "learning_rate": 7.232461780254323e-06,
      "loss": 0.0,
      "step": 44680
    },
    {
      "epoch": 9.577796828118302,
      "grad_norm": 0.00011784492380684242,
      "learning_rate": 7.229604229175598e-06,
      "loss": 0.0001,
      "step": 44690
    },
    {
      "epoch": 9.579939991427347,
      "grad_norm": 0.0004991050809621811,
      "learning_rate": 7.226746678096872e-06,
      "loss": 0.4537,
      "step": 44700
    },
    {
      "epoch": 9.582083154736392,
      "grad_norm": 0.00032486001146025956,
      "learning_rate": 7.223889127018146e-06,
      "loss": 0.0001,
      "step": 44710
    },
    {
      "epoch": 9.584226318045435,
      "grad_norm": 0.0008627979550510645,
      "learning_rate": 7.22103157593942e-06,
      "loss": 0.1777,
      "step": 44720
    },
    {
      "epoch": 9.58636948135448,
      "grad_norm": 0.3661285936832428,
      "learning_rate": 7.218174024860694e-06,
      "loss": 0.0002,
      "step": 44730
    },
    {
      "epoch": 9.588512644663524,
      "grad_norm": 0.029475649818778038,
      "learning_rate": 7.215316473781969e-06,
      "loss": 0.0002,
      "step": 44740
    },
    {
      "epoch": 9.590655807972567,
      "grad_norm": 0.0005425475537776947,
      "learning_rate": 7.212458922703244e-06,
      "loss": 0.0001,
      "step": 44750
    },
    {
      "epoch": 9.592798971281612,
      "grad_norm": 0.000861804757732898,
      "learning_rate": 7.209601371624519e-06,
      "loss": 0.0,
      "step": 44760
    },
    {
      "epoch": 9.594942134590656,
      "grad_norm": 0.00017885270062834024,
      "learning_rate": 7.2067438205457926e-06,
      "loss": 0.0001,
      "step": 44770
    },
    {
      "epoch": 9.5970852978997,
      "grad_norm": 0.00022827160137239844,
      "learning_rate": 7.203886269467067e-06,
      "loss": 0.1281,
      "step": 44780
    },
    {
      "epoch": 9.599228461208744,
      "grad_norm": 0.13523435592651367,
      "learning_rate": 7.201028718388342e-06,
      "loss": 0.0001,
      "step": 44790
    },
    {
      "epoch": 9.601371624517789,
      "grad_norm": 0.0006971222464926541,
      "learning_rate": 7.198171167309617e-06,
      "loss": 0.0,
      "step": 44800
    },
    {
      "epoch": 9.603514787826832,
      "grad_norm": 0.004035774618387222,
      "learning_rate": 7.195313616230891e-06,
      "loss": 0.0,
      "step": 44810
    },
    {
      "epoch": 9.605657951135877,
      "grad_norm": 0.00013623878476209939,
      "learning_rate": 7.192456065152165e-06,
      "loss": 0.0,
      "step": 44820
    },
    {
      "epoch": 9.607801114444921,
      "grad_norm": 0.00010742189624579623,
      "learning_rate": 7.1895985140734395e-06,
      "loss": 0.0002,
      "step": 44830
    },
    {
      "epoch": 9.609944277753964,
      "grad_norm": 0.00021254496823530644,
      "learning_rate": 7.1867409629947134e-06,
      "loss": 0.0007,
      "step": 44840
    },
    {
      "epoch": 9.612087441063009,
      "grad_norm": 0.003082860726863146,
      "learning_rate": 7.183883411915988e-06,
      "loss": 0.0,
      "step": 44850
    },
    {
      "epoch": 9.614230604372054,
      "grad_norm": 0.002518031047657132,
      "learning_rate": 7.181025860837263e-06,
      "loss": 0.1004,
      "step": 44860
    },
    {
      "epoch": 9.616373767681097,
      "grad_norm": 0.0001517169876024127,
      "learning_rate": 7.178168309758538e-06,
      "loss": 0.0001,
      "step": 44870
    },
    {
      "epoch": 9.618516930990141,
      "grad_norm": 8.19755659904331e-05,
      "learning_rate": 7.175310758679812e-06,
      "loss": 0.0,
      "step": 44880
    },
    {
      "epoch": 9.620660094299186,
      "grad_norm": 0.0005260004545561969,
      "learning_rate": 7.1724532076010865e-06,
      "loss": 0.0,
      "step": 44890
    },
    {
      "epoch": 9.62280325760823,
      "grad_norm": 0.0006475835107266903,
      "learning_rate": 7.169595656522361e-06,
      "loss": 0.0008,
      "step": 44900
    },
    {
      "epoch": 9.624946420917274,
      "grad_norm": 7.20284806448035e-05,
      "learning_rate": 7.166738105443636e-06,
      "loss": 0.0,
      "step": 44910
    },
    {
      "epoch": 9.627089584226319,
      "grad_norm": 0.00025418572477065027,
      "learning_rate": 7.16388055436491e-06,
      "loss": 0.0,
      "step": 44920
    },
    {
      "epoch": 9.629232747535362,
      "grad_norm": 7.969502621563151e-05,
      "learning_rate": 7.161023003286184e-06,
      "loss": 0.0011,
      "step": 44930
    },
    {
      "epoch": 9.631375910844406,
      "grad_norm": 5.2963412599638104e-05,
      "learning_rate": 7.158165452207459e-06,
      "loss": 0.0001,
      "step": 44940
    },
    {
      "epoch": 9.633519074153451,
      "grad_norm": 5.1326383982086554e-05,
      "learning_rate": 7.155307901128733e-06,
      "loss": 0.0,
      "step": 44950
    },
    {
      "epoch": 9.635662237462494,
      "grad_norm": 0.00015519488079007715,
      "learning_rate": 7.152450350050007e-06,
      "loss": 0.0,
      "step": 44960
    },
    {
      "epoch": 9.637805400771539,
      "grad_norm": 7.942627416923642e-05,
      "learning_rate": 7.149592798971282e-06,
      "loss": 0.0,
      "step": 44970
    },
    {
      "epoch": 9.639948564080584,
      "grad_norm": 6.316975486697629e-05,
      "learning_rate": 7.146735247892557e-06,
      "loss": 0.0,
      "step": 44980
    },
    {
      "epoch": 9.642091727389626,
      "grad_norm": 6.586426025023684e-05,
      "learning_rate": 7.143877696813831e-06,
      "loss": 0.0006,
      "step": 44990
    },
    {
      "epoch": 9.644234890698671,
      "grad_norm": 9.753357153385878e-05,
      "learning_rate": 7.141020145735106e-06,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 9.646378054007716,
      "grad_norm": 5.452019104268402e-05,
      "learning_rate": 7.13816259465638e-06,
      "loss": 0.0009,
      "step": 45010
    },
    {
      "epoch": 9.648521217316759,
      "grad_norm": 0.0001344858028460294,
      "learning_rate": 7.135305043577655e-06,
      "loss": 0.0,
      "step": 45020
    },
    {
      "epoch": 9.650664380625804,
      "grad_norm": 8.403617539443076e-05,
      "learning_rate": 7.13244749249893e-06,
      "loss": 0.1558,
      "step": 45030
    },
    {
      "epoch": 9.652807543934848,
      "grad_norm": 0.00045698267058469355,
      "learning_rate": 7.129589941420203e-06,
      "loss": 0.0,
      "step": 45040
    },
    {
      "epoch": 9.654950707243891,
      "grad_norm": 0.0005724839284084737,
      "learning_rate": 7.126732390341478e-06,
      "loss": 0.0,
      "step": 45050
    },
    {
      "epoch": 9.657093870552936,
      "grad_norm": 0.0033975259866565466,
      "learning_rate": 7.123874839262752e-06,
      "loss": 0.0,
      "step": 45060
    },
    {
      "epoch": 9.65923703386198,
      "grad_norm": 6.455562834162265e-05,
      "learning_rate": 7.1210172881840265e-06,
      "loss": 0.0004,
      "step": 45070
    },
    {
      "epoch": 9.661380197171024,
      "grad_norm": 7.177104998845607e-05,
      "learning_rate": 7.118159737105301e-06,
      "loss": 0.0,
      "step": 45080
    },
    {
      "epoch": 9.663523360480069,
      "grad_norm": 6.0760965425288305e-05,
      "learning_rate": 7.115302186026576e-06,
      "loss": 0.0129,
      "step": 45090
    },
    {
      "epoch": 9.665666523789113,
      "grad_norm": 9.951630636351183e-05,
      "learning_rate": 7.112444634947851e-06,
      "loss": 0.0,
      "step": 45100
    },
    {
      "epoch": 9.667809687098156,
      "grad_norm": 8.490565960528329e-05,
      "learning_rate": 7.109587083869125e-06,
      "loss": 0.0,
      "step": 45110
    },
    {
      "epoch": 9.669952850407201,
      "grad_norm": 6.504101475002244e-05,
      "learning_rate": 7.1067295327903995e-06,
      "loss": 0.117,
      "step": 45120
    },
    {
      "epoch": 9.672096013716246,
      "grad_norm": 34.68871307373047,
      "learning_rate": 7.103871981711674e-06,
      "loss": 0.2418,
      "step": 45130
    },
    {
      "epoch": 9.674239177025289,
      "grad_norm": 5.4341428040061146e-05,
      "learning_rate": 7.101014430632947e-06,
      "loss": 0.0,
      "step": 45140
    },
    {
      "epoch": 9.676382340334333,
      "grad_norm": 8.037604857236147e-05,
      "learning_rate": 7.098156879554222e-06,
      "loss": 0.0614,
      "step": 45150
    },
    {
      "epoch": 9.678525503643378,
      "grad_norm": 26.3110408782959,
      "learning_rate": 7.095299328475497e-06,
      "loss": 0.2335,
      "step": 45160
    },
    {
      "epoch": 9.680668666952421,
      "grad_norm": 0.00011562285362742841,
      "learning_rate": 7.092441777396772e-06,
      "loss": 0.0,
      "step": 45170
    },
    {
      "epoch": 9.682811830261466,
      "grad_norm": 9.497614519204944e-05,
      "learning_rate": 7.089584226318046e-06,
      "loss": 0.0,
      "step": 45180
    },
    {
      "epoch": 9.68495499357051,
      "grad_norm": 0.0001145634232671,
      "learning_rate": 7.08672667523932e-06,
      "loss": 0.0001,
      "step": 45190
    },
    {
      "epoch": 9.687098156879554,
      "grad_norm": 7.632311462657526e-05,
      "learning_rate": 7.083869124160595e-06,
      "loss": 0.0,
      "step": 45200
    },
    {
      "epoch": 9.689241320188598,
      "grad_norm": 0.000361135316779837,
      "learning_rate": 7.08101157308187e-06,
      "loss": 0.0,
      "step": 45210
    },
    {
      "epoch": 9.691384483497643,
      "grad_norm": 0.0005838992656208575,
      "learning_rate": 7.078154022003144e-06,
      "loss": 0.0,
      "step": 45220
    },
    {
      "epoch": 9.693527646806686,
      "grad_norm": 8.391049777856097e-05,
      "learning_rate": 7.075296470924419e-06,
      "loss": 0.0,
      "step": 45230
    },
    {
      "epoch": 9.69567081011573,
      "grad_norm": 0.0008103233994916081,
      "learning_rate": 7.0724389198456934e-06,
      "loss": 0.0,
      "step": 45240
    },
    {
      "epoch": 9.697813973424775,
      "grad_norm": 8.503570279572159e-05,
      "learning_rate": 7.0695813687669665e-06,
      "loss": 0.0,
      "step": 45250
    },
    {
      "epoch": 9.699957136733818,
      "grad_norm": 24.47247314453125,
      "learning_rate": 7.066723817688241e-06,
      "loss": 0.1459,
      "step": 45260
    },
    {
      "epoch": 9.702100300042863,
      "grad_norm": 0.0011518592946231365,
      "learning_rate": 7.063866266609516e-06,
      "loss": 0.008,
      "step": 45270
    },
    {
      "epoch": 9.704243463351908,
      "grad_norm": 0.00012253386375959963,
      "learning_rate": 7.061008715530791e-06,
      "loss": 0.0001,
      "step": 45280
    },
    {
      "epoch": 9.70638662666095,
      "grad_norm": 6.71297893859446e-05,
      "learning_rate": 7.058151164452065e-06,
      "loss": 0.0001,
      "step": 45290
    },
    {
      "epoch": 9.708529789969996,
      "grad_norm": 7.673505751881748e-05,
      "learning_rate": 7.0552936133733396e-06,
      "loss": 0.0004,
      "step": 45300
    },
    {
      "epoch": 9.71067295327904,
      "grad_norm": 4.9335259973304346e-05,
      "learning_rate": 7.052436062294614e-06,
      "loss": 0.6194,
      "step": 45310
    },
    {
      "epoch": 9.712816116588083,
      "grad_norm": 0.00032903149258345366,
      "learning_rate": 7.049578511215889e-06,
      "loss": 0.0,
      "step": 45320
    },
    {
      "epoch": 9.714959279897128,
      "grad_norm": 0.00024898367701098323,
      "learning_rate": 7.046720960137163e-06,
      "loss": 0.1739,
      "step": 45330
    },
    {
      "epoch": 9.717102443206173,
      "grad_norm": 0.0013736680848523974,
      "learning_rate": 7.043863409058438e-06,
      "loss": 0.0,
      "step": 45340
    },
    {
      "epoch": 9.719245606515216,
      "grad_norm": 0.0004829521058127284,
      "learning_rate": 7.041005857979713e-06,
      "loss": 0.0002,
      "step": 45350
    },
    {
      "epoch": 9.72138876982426,
      "grad_norm": 0.001252950867637992,
      "learning_rate": 7.038148306900986e-06,
      "loss": 0.0,
      "step": 45360
    },
    {
      "epoch": 9.723531933133305,
      "grad_norm": 0.0016868170350790024,
      "learning_rate": 7.0352907558222604e-06,
      "loss": 0.0,
      "step": 45370
    },
    {
      "epoch": 9.725675096442348,
      "grad_norm": 0.00011728487879736349,
      "learning_rate": 7.032433204743535e-06,
      "loss": 0.0001,
      "step": 45380
    },
    {
      "epoch": 9.727818259751393,
      "grad_norm": 0.0061537423171103,
      "learning_rate": 7.02957565366481e-06,
      "loss": 0.0,
      "step": 45390
    },
    {
      "epoch": 9.729961423060438,
      "grad_norm": 0.01106257364153862,
      "learning_rate": 7.026718102586084e-06,
      "loss": 0.0003,
      "step": 45400
    },
    {
      "epoch": 9.73210458636948,
      "grad_norm": 0.0016852181870490313,
      "learning_rate": 7.023860551507359e-06,
      "loss": 0.0,
      "step": 45410
    },
    {
      "epoch": 9.734247749678525,
      "grad_norm": 0.0009188996627926826,
      "learning_rate": 7.0210030004286335e-06,
      "loss": 0.0,
      "step": 45420
    },
    {
      "epoch": 9.73639091298757,
      "grad_norm": 0.00027035028324462473,
      "learning_rate": 7.018145449349908e-06,
      "loss": 0.0,
      "step": 45430
    },
    {
      "epoch": 9.738534076296613,
      "grad_norm": 0.016530385240912437,
      "learning_rate": 7.015287898271182e-06,
      "loss": 0.0002,
      "step": 45440
    },
    {
      "epoch": 9.740677239605658,
      "grad_norm": 6.77948773954995e-05,
      "learning_rate": 7.012430347192457e-06,
      "loss": 0.0,
      "step": 45450
    },
    {
      "epoch": 9.742820402914703,
      "grad_norm": 0.0029297086875885725,
      "learning_rate": 7.009572796113732e-06,
      "loss": 0.0003,
      "step": 45460
    },
    {
      "epoch": 9.744963566223745,
      "grad_norm": 6.321586261037737e-05,
      "learning_rate": 7.006715245035005e-06,
      "loss": 0.0007,
      "step": 45470
    },
    {
      "epoch": 9.74710672953279,
      "grad_norm": 0.29754114151000977,
      "learning_rate": 7.00385769395628e-06,
      "loss": 0.0001,
      "step": 45480
    },
    {
      "epoch": 9.749249892841835,
      "grad_norm": 4.369368252810091e-05,
      "learning_rate": 7.001000142877554e-06,
      "loss": 0.0,
      "step": 45490
    },
    {
      "epoch": 9.751393056150878,
      "grad_norm": 0.00016323245654348284,
      "learning_rate": 6.998142591798829e-06,
      "loss": 0.0,
      "step": 45500
    },
    {
      "epoch": 9.753536219459923,
      "grad_norm": 0.004251111764460802,
      "learning_rate": 6.995285040720103e-06,
      "loss": 0.5283,
      "step": 45510
    },
    {
      "epoch": 9.755679382768967,
      "grad_norm": 4.287316187401302e-05,
      "learning_rate": 6.992427489641378e-06,
      "loss": 0.0,
      "step": 45520
    },
    {
      "epoch": 9.75782254607801,
      "grad_norm": 0.01305045373737812,
      "learning_rate": 6.989569938562653e-06,
      "loss": 0.0,
      "step": 45530
    },
    {
      "epoch": 9.759965709387055,
      "grad_norm": 0.0016430584946647286,
      "learning_rate": 6.986712387483927e-06,
      "loss": 0.1647,
      "step": 45540
    },
    {
      "epoch": 9.7621088726961,
      "grad_norm": 0.021451041102409363,
      "learning_rate": 6.983854836405201e-06,
      "loss": 0.0002,
      "step": 45550
    },
    {
      "epoch": 9.764252036005143,
      "grad_norm": 0.0005936076049692929,
      "learning_rate": 6.980997285326476e-06,
      "loss": 0.0001,
      "step": 45560
    },
    {
      "epoch": 9.766395199314188,
      "grad_norm": 4.059346974827349e-05,
      "learning_rate": 6.97813973424775e-06,
      "loss": 0.0,
      "step": 45570
    },
    {
      "epoch": 9.768538362623232,
      "grad_norm": 4.89773228764534e-05,
      "learning_rate": 6.975282183169024e-06,
      "loss": 0.0002,
      "step": 45580
    },
    {
      "epoch": 9.770681525932275,
      "grad_norm": 3.5904540709452704e-05,
      "learning_rate": 6.972424632090299e-06,
      "loss": 0.0002,
      "step": 45590
    },
    {
      "epoch": 9.77282468924132,
      "grad_norm": 0.0005797508638352156,
      "learning_rate": 6.9695670810115735e-06,
      "loss": 0.0,
      "step": 45600
    },
    {
      "epoch": 9.774967852550365,
      "grad_norm": 4.8206573410425335e-05,
      "learning_rate": 6.966709529932848e-06,
      "loss": 0.0012,
      "step": 45610
    },
    {
      "epoch": 9.777111015859408,
      "grad_norm": 0.0006199961062520742,
      "learning_rate": 6.963851978854122e-06,
      "loss": 0.0,
      "step": 45620
    },
    {
      "epoch": 9.779254179168452,
      "grad_norm": 0.045826300978660583,
      "learning_rate": 6.960994427775397e-06,
      "loss": 0.0866,
      "step": 45630
    },
    {
      "epoch": 9.781397342477497,
      "grad_norm": 0.0026420215144753456,
      "learning_rate": 6.958136876696672e-06,
      "loss": 0.0,
      "step": 45640
    },
    {
      "epoch": 9.78354050578654,
      "grad_norm": 0.00022160600929055363,
      "learning_rate": 6.9552793256179465e-06,
      "loss": 0.0,
      "step": 45650
    },
    {
      "epoch": 9.785683669095585,
      "grad_norm": 0.00014283036580309272,
      "learning_rate": 6.9524217745392205e-06,
      "loss": 0.0292,
      "step": 45660
    },
    {
      "epoch": 9.78782683240463,
      "grad_norm": 0.00044666597386822104,
      "learning_rate": 6.949564223460495e-06,
      "loss": 0.0,
      "step": 45670
    },
    {
      "epoch": 9.789969995713673,
      "grad_norm": 0.00020178711565677077,
      "learning_rate": 6.946706672381769e-06,
      "loss": 0.0,
      "step": 45680
    },
    {
      "epoch": 9.792113159022717,
      "grad_norm": 0.0012843526201322675,
      "learning_rate": 6.943849121303043e-06,
      "loss": 0.0,
      "step": 45690
    },
    {
      "epoch": 9.794256322331762,
      "grad_norm": 6.016726911184378e-05,
      "learning_rate": 6.940991570224318e-06,
      "loss": 0.0004,
      "step": 45700
    },
    {
      "epoch": 9.796399485640805,
      "grad_norm": 0.0006102451006881893,
      "learning_rate": 6.938134019145593e-06,
      "loss": 0.0,
      "step": 45710
    },
    {
      "epoch": 9.79854264894985,
      "grad_norm": 7.766929775243625e-05,
      "learning_rate": 6.935276468066867e-06,
      "loss": 0.0,
      "step": 45720
    },
    {
      "epoch": 9.800685812258894,
      "grad_norm": 0.0001945573021657765,
      "learning_rate": 6.932418916988141e-06,
      "loss": 0.0,
      "step": 45730
    },
    {
      "epoch": 9.802828975567937,
      "grad_norm": 0.0005708058597519994,
      "learning_rate": 6.929561365909416e-06,
      "loss": 0.0001,
      "step": 45740
    },
    {
      "epoch": 9.804972138876982,
      "grad_norm": 5.106856769998558e-05,
      "learning_rate": 6.926703814830691e-06,
      "loss": 0.0,
      "step": 45750
    },
    {
      "epoch": 9.807115302186027,
      "grad_norm": 8.9577108155936e-05,
      "learning_rate": 6.923846263751966e-06,
      "loss": 0.0001,
      "step": 45760
    },
    {
      "epoch": 9.80925846549507,
      "grad_norm": 6.748356827301905e-05,
      "learning_rate": 6.92098871267324e-06,
      "loss": 0.0,
      "step": 45770
    },
    {
      "epoch": 9.811401628804115,
      "grad_norm": 0.008661847561597824,
      "learning_rate": 6.918131161594514e-06,
      "loss": 0.0,
      "step": 45780
    },
    {
      "epoch": 9.81354479211316,
      "grad_norm": 0.00013255917292553931,
      "learning_rate": 6.915273610515788e-06,
      "loss": 0.0,
      "step": 45790
    },
    {
      "epoch": 9.815687955422202,
      "grad_norm": 3.413860321044922,
      "learning_rate": 6.912416059437062e-06,
      "loss": 0.0196,
      "step": 45800
    },
    {
      "epoch": 9.817831118731247,
      "grad_norm": 0.005252744071185589,
      "learning_rate": 6.909558508358337e-06,
      "loss": 0.0,
      "step": 45810
    },
    {
      "epoch": 9.819974282040292,
      "grad_norm": 4.5010023313807324e-05,
      "learning_rate": 6.906700957279612e-06,
      "loss": 0.176,
      "step": 45820
    },
    {
      "epoch": 9.822117445349335,
      "grad_norm": 5.15642313985154e-05,
      "learning_rate": 6.9038434062008866e-06,
      "loss": 0.0,
      "step": 45830
    },
    {
      "epoch": 9.82426060865838,
      "grad_norm": 0.0004001854977104813,
      "learning_rate": 6.9009858551221605e-06,
      "loss": 0.0,
      "step": 45840
    },
    {
      "epoch": 9.826403771967424,
      "grad_norm": 0.00041482836240902543,
      "learning_rate": 6.898128304043435e-06,
      "loss": 0.2781,
      "step": 45850
    },
    {
      "epoch": 9.828546935276467,
      "grad_norm": 4.8691210395190865e-05,
      "learning_rate": 6.89527075296471e-06,
      "loss": 0.0001,
      "step": 45860
    },
    {
      "epoch": 9.830690098585512,
      "grad_norm": 0.00023328102543018758,
      "learning_rate": 6.892413201885985e-06,
      "loss": 0.0001,
      "step": 45870
    },
    {
      "epoch": 9.832833261894557,
      "grad_norm": 0.004498847760260105,
      "learning_rate": 6.88955565080726e-06,
      "loss": 0.0,
      "step": 45880
    },
    {
      "epoch": 9.8349764252036,
      "grad_norm": 5.3403364290716127e-05,
      "learning_rate": 6.8866980997285335e-06,
      "loss": 0.0,
      "step": 45890
    },
    {
      "epoch": 9.837119588512644,
      "grad_norm": 0.0004767692007590085,
      "learning_rate": 6.8838405486498074e-06,
      "loss": 0.2338,
      "step": 45900
    },
    {
      "epoch": 9.839262751821689,
      "grad_norm": 4.786676436197013e-05,
      "learning_rate": 6.880982997571081e-06,
      "loss": 0.0,
      "step": 45910
    },
    {
      "epoch": 9.841405915130732,
      "grad_norm": 0.002589777112007141,
      "learning_rate": 6.878125446492356e-06,
      "loss": 0.0001,
      "step": 45920
    },
    {
      "epoch": 9.843549078439777,
      "grad_norm": 4.484318196773529e-05,
      "learning_rate": 6.875267895413631e-06,
      "loss": 0.0006,
      "step": 45930
    },
    {
      "epoch": 9.845692241748822,
      "grad_norm": 0.05722225829958916,
      "learning_rate": 6.872410344334906e-06,
      "loss": 0.0,
      "step": 45940
    },
    {
      "epoch": 9.847835405057864,
      "grad_norm": 0.001986823510378599,
      "learning_rate": 6.8695527932561805e-06,
      "loss": 0.0,
      "step": 45950
    },
    {
      "epoch": 9.84997856836691,
      "grad_norm": 0.0077292462810873985,
      "learning_rate": 6.866695242177454e-06,
      "loss": 0.0002,
      "step": 45960
    },
    {
      "epoch": 9.852121731675954,
      "grad_norm": 3.946179276681505e-05,
      "learning_rate": 6.863837691098729e-06,
      "loss": 0.0001,
      "step": 45970
    },
    {
      "epoch": 9.854264894984997,
      "grad_norm": 0.0018452240619808435,
      "learning_rate": 6.860980140020004e-06,
      "loss": 0.0,
      "step": 45980
    },
    {
      "epoch": 9.856408058294042,
      "grad_norm": 4.435031587490812e-05,
      "learning_rate": 6.858122588941279e-06,
      "loss": 0.0,
      "step": 45990
    },
    {
      "epoch": 9.858551221603086,
      "grad_norm": 4.665123560698703e-05,
      "learning_rate": 6.855265037862552e-06,
      "loss": 0.0,
      "step": 46000
    },
    {
      "epoch": 9.860694384912131,
      "grad_norm": 0.003203056054189801,
      "learning_rate": 6.852407486783827e-06,
      "loss": 0.0,
      "step": 46010
    },
    {
      "epoch": 9.862837548221174,
      "grad_norm": 0.15998250246047974,
      "learning_rate": 6.849549935705101e-06,
      "loss": 0.0001,
      "step": 46020
    },
    {
      "epoch": 9.864980711530219,
      "grad_norm": 0.003913416061550379,
      "learning_rate": 6.846692384626375e-06,
      "loss": 0.0,
      "step": 46030
    },
    {
      "epoch": 9.867123874839264,
      "grad_norm": 4.219494803692214e-05,
      "learning_rate": 6.84383483354765e-06,
      "loss": 0.0,
      "step": 46040
    },
    {
      "epoch": 9.869267038148307,
      "grad_norm": 0.0007341696764342487,
      "learning_rate": 6.840977282468925e-06,
      "loss": 0.0,
      "step": 46050
    },
    {
      "epoch": 9.871410201457351,
      "grad_norm": 4.534234540187754e-05,
      "learning_rate": 6.8381197313902e-06,
      "loss": 0.0011,
      "step": 46060
    },
    {
      "epoch": 9.873553364766396,
      "grad_norm": 9.462972957408056e-05,
      "learning_rate": 6.8352621803114735e-06,
      "loss": 0.0,
      "step": 46070
    },
    {
      "epoch": 9.875696528075439,
      "grad_norm": 7.476099563064054e-05,
      "learning_rate": 6.832404629232748e-06,
      "loss": 0.0003,
      "step": 46080
    },
    {
      "epoch": 9.877839691384484,
      "grad_norm": 0.00012369912292342633,
      "learning_rate": 6.829547078154023e-06,
      "loss": 0.0,
      "step": 46090
    },
    {
      "epoch": 9.879982854693528,
      "grad_norm": 0.001967569114640355,
      "learning_rate": 6.826689527075298e-06,
      "loss": 0.0,
      "step": 46100
    },
    {
      "epoch": 9.882126018002571,
      "grad_norm": 0.0012045440962538123,
      "learning_rate": 6.823831975996571e-06,
      "loss": 0.2769,
      "step": 46110
    },
    {
      "epoch": 9.884269181311616,
      "grad_norm": 0.0008483584970235825,
      "learning_rate": 6.820974424917846e-06,
      "loss": 0.0,
      "step": 46120
    },
    {
      "epoch": 9.88641234462066,
      "grad_norm": 0.0004044612869620323,
      "learning_rate": 6.8181168738391205e-06,
      "loss": 0.408,
      "step": 46130
    },
    {
      "epoch": 9.888555507929704,
      "grad_norm": 30.689292907714844,
      "learning_rate": 6.8152593227603944e-06,
      "loss": 0.2468,
      "step": 46140
    },
    {
      "epoch": 9.890698671238749,
      "grad_norm": 0.00016802057507447898,
      "learning_rate": 6.812401771681669e-06,
      "loss": 0.1612,
      "step": 46150
    },
    {
      "epoch": 9.892841834547793,
      "grad_norm": 0.002710978500545025,
      "learning_rate": 6.809544220602944e-06,
      "loss": 0.0003,
      "step": 46160
    },
    {
      "epoch": 9.894984997856836,
      "grad_norm": 0.0002358709170948714,
      "learning_rate": 6.806686669524219e-06,
      "loss": 0.0,
      "step": 46170
    },
    {
      "epoch": 9.897128161165881,
      "grad_norm": 0.020128905773162842,
      "learning_rate": 6.803829118445493e-06,
      "loss": 0.0001,
      "step": 46180
    },
    {
      "epoch": 9.899271324474926,
      "grad_norm": 26.230093002319336,
      "learning_rate": 6.8009715673667675e-06,
      "loss": 0.0031,
      "step": 46190
    },
    {
      "epoch": 9.901414487783969,
      "grad_norm": 0.2787552773952484,
      "learning_rate": 6.798114016288042e-06,
      "loss": 0.2546,
      "step": 46200
    },
    {
      "epoch": 9.903557651093013,
      "grad_norm": 0.0025926323141902685,
      "learning_rate": 6.795256465209317e-06,
      "loss": 0.0001,
      "step": 46210
    },
    {
      "epoch": 9.905700814402058,
      "grad_norm": 0.014393925666809082,
      "learning_rate": 6.79239891413059e-06,
      "loss": 0.052,
      "step": 46220
    },
    {
      "epoch": 9.907843977711101,
      "grad_norm": 0.05718856677412987,
      "learning_rate": 6.789541363051865e-06,
      "loss": 0.0048,
      "step": 46230
    },
    {
      "epoch": 9.909987141020146,
      "grad_norm": 0.0001324727782048285,
      "learning_rate": 6.78668381197314e-06,
      "loss": 0.0,
      "step": 46240
    },
    {
      "epoch": 9.91213030432919,
      "grad_norm": 0.0003058357979170978,
      "learning_rate": 6.7838262608944136e-06,
      "loss": 0.0001,
      "step": 46250
    },
    {
      "epoch": 9.914273467638234,
      "grad_norm": 0.0003278983640484512,
      "learning_rate": 6.780968709815688e-06,
      "loss": 0.0,
      "step": 46260
    },
    {
      "epoch": 9.916416630947278,
      "grad_norm": 0.007308756001293659,
      "learning_rate": 6.778111158736963e-06,
      "loss": 0.0001,
      "step": 46270
    },
    {
      "epoch": 9.918559794256323,
      "grad_norm": 0.00037218836951069534,
      "learning_rate": 6.775253607658238e-06,
      "loss": 0.0,
      "step": 46280
    },
    {
      "epoch": 9.920702957565366,
      "grad_norm": 0.00039160370943136513,
      "learning_rate": 6.772396056579512e-06,
      "loss": 0.0,
      "step": 46290
    },
    {
      "epoch": 9.92284612087441,
      "grad_norm": 0.0002179927541874349,
      "learning_rate": 6.769538505500787e-06,
      "loss": 0.0,
      "step": 46300
    },
    {
      "epoch": 9.924989284183455,
      "grad_norm": 0.00013891627895645797,
      "learning_rate": 6.766680954422061e-06,
      "loss": 0.0107,
      "step": 46310
    },
    {
      "epoch": 9.927132447492498,
      "grad_norm": 0.006805167533457279,
      "learning_rate": 6.763823403343336e-06,
      "loss": 0.0,
      "step": 46320
    },
    {
      "epoch": 9.929275610801543,
      "grad_norm": 0.0007499513449147344,
      "learning_rate": 6.760965852264609e-06,
      "loss": 0.0,
      "step": 46330
    },
    {
      "epoch": 9.931418774110588,
      "grad_norm": 0.00047510481090284884,
      "learning_rate": 6.758108301185884e-06,
      "loss": 0.0,
      "step": 46340
    },
    {
      "epoch": 9.933561937419631,
      "grad_norm": 0.0001788102090358734,
      "learning_rate": 6.755250750107159e-06,
      "loss": 0.0,
      "step": 46350
    },
    {
      "epoch": 9.935705100728676,
      "grad_norm": 0.00015815117512829602,
      "learning_rate": 6.752393199028433e-06,
      "loss": 0.0001,
      "step": 46360
    },
    {
      "epoch": 9.93784826403772,
      "grad_norm": 0.0003595854213926941,
      "learning_rate": 6.7495356479497075e-06,
      "loss": 0.0,
      "step": 46370
    },
    {
      "epoch": 9.939991427346763,
      "grad_norm": 0.0001338546717306599,
      "learning_rate": 6.746678096870982e-06,
      "loss": 0.0,
      "step": 46380
    },
    {
      "epoch": 9.942134590655808,
      "grad_norm": 0.00013249552284833044,
      "learning_rate": 6.743820545792257e-06,
      "loss": 0.0001,
      "step": 46390
    },
    {
      "epoch": 9.944277753964853,
      "grad_norm": 0.0006705974810756743,
      "learning_rate": 6.740962994713531e-06,
      "loss": 0.0014,
      "step": 46400
    },
    {
      "epoch": 9.946420917273896,
      "grad_norm": 0.00018017915135715157,
      "learning_rate": 6.738105443634806e-06,
      "loss": 0.0,
      "step": 46410
    },
    {
      "epoch": 9.94856408058294,
      "grad_norm": 0.00022963785158935934,
      "learning_rate": 6.7352478925560805e-06,
      "loss": 0.0,
      "step": 46420
    },
    {
      "epoch": 9.950707243891985,
      "grad_norm": 0.00030303647508844733,
      "learning_rate": 6.732390341477354e-06,
      "loss": 0.0001,
      "step": 46430
    },
    {
      "epoch": 9.952850407201028,
      "grad_norm": 0.044072944670915604,
      "learning_rate": 6.729532790398628e-06,
      "loss": 0.0003,
      "step": 46440
    },
    {
      "epoch": 9.954993570510073,
      "grad_norm": 0.00027482747100293636,
      "learning_rate": 6.726675239319903e-06,
      "loss": 0.0,
      "step": 46450
    },
    {
      "epoch": 9.957136733819118,
      "grad_norm": 0.022460661828517914,
      "learning_rate": 6.723817688241178e-06,
      "loss": 0.0,
      "step": 46460
    },
    {
      "epoch": 9.95927989712816,
      "grad_norm": 5.413885082816705e-05,
      "learning_rate": 6.720960137162452e-06,
      "loss": 0.0,
      "step": 46470
    },
    {
      "epoch": 9.961423060437205,
      "grad_norm": 8.726332453079522e-05,
      "learning_rate": 6.718102586083727e-06,
      "loss": 0.1746,
      "step": 46480
    },
    {
      "epoch": 9.96356622374625,
      "grad_norm": 8.667981455801055e-05,
      "learning_rate": 6.715245035005001e-06,
      "loss": 0.0,
      "step": 46490
    },
    {
      "epoch": 9.965709387055293,
      "grad_norm": 8.751495624892414e-05,
      "learning_rate": 6.712387483926276e-06,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 9.967852550364338,
      "grad_norm": 0.00010406052751932293,
      "learning_rate": 6.70952993284755e-06,
      "loss": 0.0,
      "step": 46510
    },
    {
      "epoch": 9.969995713673383,
      "grad_norm": 0.0001157643273472786,
      "learning_rate": 6.706672381768825e-06,
      "loss": 0.0,
      "step": 46520
    },
    {
      "epoch": 9.972138876982426,
      "grad_norm": 8.367697591893375e-05,
      "learning_rate": 6.7038148306901e-06,
      "loss": 0.005,
      "step": 46530
    },
    {
      "epoch": 9.97428204029147,
      "grad_norm": 9.360451076645404e-05,
      "learning_rate": 6.700957279611373e-06,
      "loss": 0.0001,
      "step": 46540
    },
    {
      "epoch": 9.976425203600515,
      "grad_norm": 0.0001777546276571229,
      "learning_rate": 6.6980997285326475e-06,
      "loss": 0.0,
      "step": 46550
    },
    {
      "epoch": 9.978568366909558,
      "grad_norm": 0.00012063702160958201,
      "learning_rate": 6.695242177453922e-06,
      "loss": 0.0,
      "step": 46560
    },
    {
      "epoch": 9.980711530218603,
      "grad_norm": 8.981760765891522e-05,
      "learning_rate": 6.692384626375197e-06,
      "loss": 0.0,
      "step": 46570
    },
    {
      "epoch": 9.982854693527647,
      "grad_norm": 0.00015866295143496245,
      "learning_rate": 6.689527075296471e-06,
      "loss": 0.0023,
      "step": 46580
    },
    {
      "epoch": 9.98499785683669,
      "grad_norm": 0.00015064913895912468,
      "learning_rate": 6.686669524217746e-06,
      "loss": 0.0,
      "step": 46590
    },
    {
      "epoch": 9.987141020145735,
      "grad_norm": 0.0001701525179669261,
      "learning_rate": 6.6838119731390205e-06,
      "loss": 0.0,
      "step": 46600
    },
    {
      "epoch": 9.98928418345478,
      "grad_norm": 0.0007484221714548767,
      "learning_rate": 6.680954422060295e-06,
      "loss": 0.0,
      "step": 46610
    },
    {
      "epoch": 9.991427346763823,
      "grad_norm": 0.05635528638958931,
      "learning_rate": 6.67809687098157e-06,
      "loss": 0.1186,
      "step": 46620
    },
    {
      "epoch": 9.993570510072868,
      "grad_norm": 0.8515933752059937,
      "learning_rate": 6.675239319902844e-06,
      "loss": 0.0013,
      "step": 46630
    },
    {
      "epoch": 9.995713673381912,
      "grad_norm": 8.487448940286413e-05,
      "learning_rate": 6.672381768824119e-06,
      "loss": 0.0,
      "step": 46640
    },
    {
      "epoch": 9.997856836690955,
      "grad_norm": 0.00032069161534309387,
      "learning_rate": 6.669524217745392e-06,
      "loss": 0.0,
      "step": 46650
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.00022124318638816476,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.14,
      "step": 46660
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.9246666666666666,
      "eval_f1": 0.8087986463620982,
      "eval_loss": 0.7372255921363831,
      "eval_precision": 0.7979966611018364,
      "eval_recall": 0.8198970840480274,
      "eval_runtime": 108.5547,
      "eval_samples_per_second": 27.636,
      "eval_steps_per_second": 1.151,
      "step": 46660
    },
    {
      "epoch": 10.002143163309045,
      "grad_norm": 0.00023882016830611974,
      "learning_rate": 6.663809115587941e-06,
      "loss": 0.001,
      "step": 46670
    },
    {
      "epoch": 10.004286326618088,
      "grad_norm": 0.00017360149649903178,
      "learning_rate": 6.660951564509216e-06,
      "loss": 0.0,
      "step": 46680
    },
    {
      "epoch": 10.006429489927132,
      "grad_norm": 0.00041797509766183794,
      "learning_rate": 6.658094013430491e-06,
      "loss": 0.0,
      "step": 46690
    },
    {
      "epoch": 10.008572653236177,
      "grad_norm": 0.25730592012405396,
      "learning_rate": 6.655236462351765e-06,
      "loss": 0.0004,
      "step": 46700
    },
    {
      "epoch": 10.01071581654522,
      "grad_norm": 0.00015809758042450994,
      "learning_rate": 6.65237891127304e-06,
      "loss": 0.0,
      "step": 46710
    },
    {
      "epoch": 10.012858979854265,
      "grad_norm": 7.965391705511138e-05,
      "learning_rate": 6.6495213601943145e-06,
      "loss": 0.0,
      "step": 46720
    },
    {
      "epoch": 10.01500214316331,
      "grad_norm": 38.74287033081055,
      "learning_rate": 6.646663809115589e-06,
      "loss": 0.0336,
      "step": 46730
    },
    {
      "epoch": 10.017145306472353,
      "grad_norm": 0.0005698943277820945,
      "learning_rate": 6.643806258036863e-06,
      "loss": 0.1282,
      "step": 46740
    },
    {
      "epoch": 10.019288469781397,
      "grad_norm": 0.0003468109935056418,
      "learning_rate": 6.640948706958137e-06,
      "loss": 0.0,
      "step": 46750
    },
    {
      "epoch": 10.021431633090442,
      "grad_norm": 0.0001093920145649463,
      "learning_rate": 6.638091155879412e-06,
      "loss": 0.0,
      "step": 46760
    },
    {
      "epoch": 10.023574796399485,
      "grad_norm": 0.00013356747513171285,
      "learning_rate": 6.635233604800686e-06,
      "loss": 0.0,
      "step": 46770
    },
    {
      "epoch": 10.02571795970853,
      "grad_norm": 0.00022905279183760285,
      "learning_rate": 6.6323760537219606e-06,
      "loss": 0.0,
      "step": 46780
    },
    {
      "epoch": 10.027861123017574,
      "grad_norm": 5.345228055375628e-05,
      "learning_rate": 6.629518502643235e-06,
      "loss": 0.0,
      "step": 46790
    },
    {
      "epoch": 10.030004286326617,
      "grad_norm": 4.890881245955825e-05,
      "learning_rate": 6.62666095156451e-06,
      "loss": 0.0,
      "step": 46800
    },
    {
      "epoch": 10.032147449635662,
      "grad_norm": 0.00018170282419305295,
      "learning_rate": 6.623803400485784e-06,
      "loss": 0.0,
      "step": 46810
    },
    {
      "epoch": 10.034290612944707,
      "grad_norm": 0.0001570947206346318,
      "learning_rate": 6.620945849407059e-06,
      "loss": 0.0,
      "step": 46820
    },
    {
      "epoch": 10.03643377625375,
      "grad_norm": 8.471259934594855e-05,
      "learning_rate": 6.618088298328334e-06,
      "loss": 0.0,
      "step": 46830
    },
    {
      "epoch": 10.038576939562795,
      "grad_norm": 0.02467680722475052,
      "learning_rate": 6.615230747249608e-06,
      "loss": 0.0,
      "step": 46840
    },
    {
      "epoch": 10.04072010287184,
      "grad_norm": 0.00018151123367715627,
      "learning_rate": 6.612373196170882e-06,
      "loss": 0.0,
      "step": 46850
    },
    {
      "epoch": 10.042863266180882,
      "grad_norm": 5.413322651293129e-05,
      "learning_rate": 6.609515645092156e-06,
      "loss": 0.0,
      "step": 46860
    },
    {
      "epoch": 10.045006429489927,
      "grad_norm": 5.580171637120657e-05,
      "learning_rate": 6.606658094013431e-06,
      "loss": 0.0,
      "step": 46870
    },
    {
      "epoch": 10.047149592798972,
      "grad_norm": 4.690732748713344e-05,
      "learning_rate": 6.603800542934705e-06,
      "loss": 0.0,
      "step": 46880
    },
    {
      "epoch": 10.049292756108015,
      "grad_norm": 5.171871089260094e-05,
      "learning_rate": 6.60094299185598e-06,
      "loss": 0.0,
      "step": 46890
    },
    {
      "epoch": 10.05143591941706,
      "grad_norm": 7.153176557039842e-05,
      "learning_rate": 6.5980854407772545e-06,
      "loss": 0.0,
      "step": 46900
    },
    {
      "epoch": 10.053579082726104,
      "grad_norm": 9.10008602659218e-05,
      "learning_rate": 6.595227889698529e-06,
      "loss": 0.0,
      "step": 46910
    },
    {
      "epoch": 10.055722246035147,
      "grad_norm": 0.0006397412507794797,
      "learning_rate": 6.592370338619803e-06,
      "loss": 0.0,
      "step": 46920
    },
    {
      "epoch": 10.057865409344192,
      "grad_norm": 0.00011318747419863939,
      "learning_rate": 6.589512787541078e-06,
      "loss": 0.0,
      "step": 46930
    },
    {
      "epoch": 10.060008572653237,
      "grad_norm": 8.72655218699947e-05,
      "learning_rate": 6.586655236462353e-06,
      "loss": 0.0,
      "step": 46940
    },
    {
      "epoch": 10.06215173596228,
      "grad_norm": 8.536709356121719e-05,
      "learning_rate": 6.5837976853836275e-06,
      "loss": 0.0001,
      "step": 46950
    },
    {
      "epoch": 10.064294899271324,
      "grad_norm": 6.271130405366421e-05,
      "learning_rate": 6.5809401343049014e-06,
      "loss": 0.0,
      "step": 46960
    },
    {
      "epoch": 10.066438062580369,
      "grad_norm": 4.400283796712756e-05,
      "learning_rate": 6.578082583226175e-06,
      "loss": 0.0006,
      "step": 46970
    },
    {
      "epoch": 10.068581225889412,
      "grad_norm": 8.392876043217257e-05,
      "learning_rate": 6.57522503214745e-06,
      "loss": 0.0,
      "step": 46980
    },
    {
      "epoch": 10.070724389198457,
      "grad_norm": 4.2249106627423316e-05,
      "learning_rate": 6.572367481068724e-06,
      "loss": 0.0,
      "step": 46990
    },
    {
      "epoch": 10.072867552507502,
      "grad_norm": 0.00011463221744634211,
      "learning_rate": 6.569509929989999e-06,
      "loss": 0.0001,
      "step": 47000
    },
    {
      "epoch": 10.075010715816545,
      "grad_norm": 0.00010137231583939865,
      "learning_rate": 6.566652378911274e-06,
      "loss": 0.0,
      "step": 47010
    },
    {
      "epoch": 10.07715387912559,
      "grad_norm": 0.00022754340898245573,
      "learning_rate": 6.563794827832548e-06,
      "loss": 0.0,
      "step": 47020
    },
    {
      "epoch": 10.079297042434634,
      "grad_norm": 0.22448523342609406,
      "learning_rate": 6.560937276753822e-06,
      "loss": 0.0002,
      "step": 47030
    },
    {
      "epoch": 10.081440205743677,
      "grad_norm": 0.00014917217777110636,
      "learning_rate": 6.558079725675097e-06,
      "loss": 0.0,
      "step": 47040
    },
    {
      "epoch": 10.083583369052722,
      "grad_norm": 5.7658267905935645e-05,
      "learning_rate": 6.555222174596372e-06,
      "loss": 0.0,
      "step": 47050
    },
    {
      "epoch": 10.085726532361766,
      "grad_norm": 3.702357935253531e-05,
      "learning_rate": 6.552364623517647e-06,
      "loss": 0.0,
      "step": 47060
    },
    {
      "epoch": 10.08786969567081,
      "grad_norm": 4.050064308103174e-05,
      "learning_rate": 6.5495070724389206e-06,
      "loss": 0.0,
      "step": 47070
    },
    {
      "epoch": 10.090012858979854,
      "grad_norm": 6.499376468127593e-05,
      "learning_rate": 6.5466495213601945e-06,
      "loss": 0.0,
      "step": 47080
    },
    {
      "epoch": 10.092156022288899,
      "grad_norm": 0.00019965966930612922,
      "learning_rate": 6.543791970281469e-06,
      "loss": 0.0,
      "step": 47090
    },
    {
      "epoch": 10.094299185597942,
      "grad_norm": 0.00021931491210125387,
      "learning_rate": 6.540934419202743e-06,
      "loss": 0.0,
      "step": 47100
    },
    {
      "epoch": 10.096442348906987,
      "grad_norm": 8.462934783892706e-05,
      "learning_rate": 6.538076868124018e-06,
      "loss": 0.0,
      "step": 47110
    },
    {
      "epoch": 10.098585512216031,
      "grad_norm": 4.905140303890221e-05,
      "learning_rate": 6.535219317045293e-06,
      "loss": 0.0001,
      "step": 47120
    },
    {
      "epoch": 10.100728675525074,
      "grad_norm": 3.79184348275885e-05,
      "learning_rate": 6.5323617659665675e-06,
      "loss": 0.0,
      "step": 47130
    },
    {
      "epoch": 10.102871838834119,
      "grad_norm": 6.231861334526911e-05,
      "learning_rate": 6.5295042148878415e-06,
      "loss": 0.0012,
      "step": 47140
    },
    {
      "epoch": 10.105015002143164,
      "grad_norm": 3.537482916726731e-05,
      "learning_rate": 6.526646663809116e-06,
      "loss": 0.0,
      "step": 47150
    },
    {
      "epoch": 10.107158165452207,
      "grad_norm": 3.446865230216645e-05,
      "learning_rate": 6.523789112730391e-06,
      "loss": 0.0,
      "step": 47160
    },
    {
      "epoch": 10.109301328761251,
      "grad_norm": 2.8110975108575076e-05,
      "learning_rate": 6.520931561651666e-06,
      "loss": 0.0,
      "step": 47170
    },
    {
      "epoch": 10.111444492070296,
      "grad_norm": 5.732534918934107e-05,
      "learning_rate": 6.518074010572939e-06,
      "loss": 0.1878,
      "step": 47180
    },
    {
      "epoch": 10.11358765537934,
      "grad_norm": 6.32134688203223e-05,
      "learning_rate": 6.515216459494214e-06,
      "loss": 0.0,
      "step": 47190
    },
    {
      "epoch": 10.115730818688384,
      "grad_norm": 3.540141187841073e-05,
      "learning_rate": 6.512358908415488e-06,
      "loss": 0.0,
      "step": 47200
    },
    {
      "epoch": 10.117873981997429,
      "grad_norm": 0.00024727644631639123,
      "learning_rate": 6.509501357336762e-06,
      "loss": 0.0,
      "step": 47210
    },
    {
      "epoch": 10.120017145306472,
      "grad_norm": 2.968299150466919,
      "learning_rate": 6.506643806258037e-06,
      "loss": 0.0037,
      "step": 47220
    },
    {
      "epoch": 10.122160308615516,
      "grad_norm": 0.00018579859170131385,
      "learning_rate": 6.503786255179312e-06,
      "loss": 0.1919,
      "step": 47230
    },
    {
      "epoch": 10.124303471924561,
      "grad_norm": 4.5793887693434954e-05,
      "learning_rate": 6.500928704100587e-06,
      "loss": 0.0,
      "step": 47240
    },
    {
      "epoch": 10.126446635233604,
      "grad_norm": 0.0007761160377413034,
      "learning_rate": 6.498071153021861e-06,
      "loss": 0.0,
      "step": 47250
    },
    {
      "epoch": 10.128589798542649,
      "grad_norm": 6.446511542890221e-05,
      "learning_rate": 6.495213601943135e-06,
      "loss": 0.0,
      "step": 47260
    },
    {
      "epoch": 10.130732961851693,
      "grad_norm": 3.856106195598841e-05,
      "learning_rate": 6.49235605086441e-06,
      "loss": 0.0779,
      "step": 47270
    },
    {
      "epoch": 10.132876125160736,
      "grad_norm": 2.5164863473037258e-05,
      "learning_rate": 6.489498499785685e-06,
      "loss": 0.0,
      "step": 47280
    },
    {
      "epoch": 10.135019288469781,
      "grad_norm": 3.604155426728539e-05,
      "learning_rate": 6.486640948706958e-06,
      "loss": 0.0,
      "step": 47290
    },
    {
      "epoch": 10.137162451778826,
      "grad_norm": 0.00013015202421229333,
      "learning_rate": 6.483783397628233e-06,
      "loss": 0.221,
      "step": 47300
    },
    {
      "epoch": 10.139305615087869,
      "grad_norm": 9.239001519745216e-05,
      "learning_rate": 6.4809258465495076e-06,
      "loss": 0.0,
      "step": 47310
    },
    {
      "epoch": 10.141448778396914,
      "grad_norm": 3.282671241322532e-05,
      "learning_rate": 6.4780682954707815e-06,
      "loss": 0.0,
      "step": 47320
    },
    {
      "epoch": 10.143591941705958,
      "grad_norm": 5.903485725866631e-05,
      "learning_rate": 6.475210744392056e-06,
      "loss": 0.0,
      "step": 47330
    },
    {
      "epoch": 10.145735105015001,
      "grad_norm": 2.0573912479449064e-05,
      "learning_rate": 6.472353193313331e-06,
      "loss": 0.0,
      "step": 47340
    },
    {
      "epoch": 10.147878268324046,
      "grad_norm": 7.107828423613682e-05,
      "learning_rate": 6.469495642234606e-06,
      "loss": 0.0,
      "step": 47350
    },
    {
      "epoch": 10.15002143163309,
      "grad_norm": 2.752098225755617e-05,
      "learning_rate": 6.46663809115588e-06,
      "loss": 0.3127,
      "step": 47360
    },
    {
      "epoch": 10.152164594942134,
      "grad_norm": 0.00023978781246114522,
      "learning_rate": 6.4637805400771545e-06,
      "loss": 0.0,
      "step": 47370
    },
    {
      "epoch": 10.154307758251178,
      "grad_norm": 5.524718653759919e-05,
      "learning_rate": 6.460922988998429e-06,
      "loss": 0.0,
      "step": 47380
    },
    {
      "epoch": 10.156450921560223,
      "grad_norm": 3.408156771911308e-05,
      "learning_rate": 6.458065437919704e-06,
      "loss": 0.0,
      "step": 47390
    },
    {
      "epoch": 10.158594084869266,
      "grad_norm": 3.94898779632058e-05,
      "learning_rate": 6.455207886840977e-06,
      "loss": 0.0,
      "step": 47400
    },
    {
      "epoch": 10.160737248178311,
      "grad_norm": 0.00013869107351638377,
      "learning_rate": 6.452350335762252e-06,
      "loss": 0.0,
      "step": 47410
    },
    {
      "epoch": 10.162880411487356,
      "grad_norm": 0.00015897088451310992,
      "learning_rate": 6.449492784683527e-06,
      "loss": 0.0,
      "step": 47420
    },
    {
      "epoch": 10.165023574796399,
      "grad_norm": 0.00011613265087362379,
      "learning_rate": 6.446635233604801e-06,
      "loss": 0.0,
      "step": 47430
    },
    {
      "epoch": 10.167166738105443,
      "grad_norm": 0.00014822109369561076,
      "learning_rate": 6.443777682526075e-06,
      "loss": 0.0,
      "step": 47440
    },
    {
      "epoch": 10.169309901414488,
      "grad_norm": 3.4374148526694626e-05,
      "learning_rate": 6.44092013144735e-06,
      "loss": 0.0,
      "step": 47450
    },
    {
      "epoch": 10.171453064723533,
      "grad_norm": 0.00010220454714726657,
      "learning_rate": 6.438062580368625e-06,
      "loss": 0.0,
      "step": 47460
    },
    {
      "epoch": 10.173596228032576,
      "grad_norm": 2.711785418796353e-05,
      "learning_rate": 6.4352050292899e-06,
      "loss": 0.0,
      "step": 47470
    },
    {
      "epoch": 10.17573939134162,
      "grad_norm": 0.0001044091914081946,
      "learning_rate": 6.432347478211174e-06,
      "loss": 0.0004,
      "step": 47480
    },
    {
      "epoch": 10.177882554650665,
      "grad_norm": 0.00041558867087587714,
      "learning_rate": 6.4294899271324484e-06,
      "loss": 0.2036,
      "step": 47490
    },
    {
      "epoch": 10.180025717959708,
      "grad_norm": 4.1989107558038086e-05,
      "learning_rate": 6.426632376053723e-06,
      "loss": 0.2619,
      "step": 47500
    },
    {
      "epoch": 10.182168881268753,
      "grad_norm": 0.0002079212135868147,
      "learning_rate": 6.423774824974996e-06,
      "loss": 0.0002,
      "step": 47510
    },
    {
      "epoch": 10.184312044577798,
      "grad_norm": 0.000538933090865612,
      "learning_rate": 6.420917273896271e-06,
      "loss": 0.0,
      "step": 47520
    },
    {
      "epoch": 10.18645520788684,
      "grad_norm": 2.937859608209692e-05,
      "learning_rate": 6.418059722817546e-06,
      "loss": 0.0,
      "step": 47530
    },
    {
      "epoch": 10.188598371195885,
      "grad_norm": 0.0002083537692669779,
      "learning_rate": 6.415202171738821e-06,
      "loss": 0.0,
      "step": 47540
    },
    {
      "epoch": 10.19074153450493,
      "grad_norm": 49.784061431884766,
      "learning_rate": 6.4123446206600945e-06,
      "loss": 0.3501,
      "step": 47550
    },
    {
      "epoch": 10.192884697813973,
      "grad_norm": 0.00017372930597048253,
      "learning_rate": 6.409487069581369e-06,
      "loss": 0.0015,
      "step": 47560
    },
    {
      "epoch": 10.195027861123018,
      "grad_norm": 0.00021631010167766362,
      "learning_rate": 6.406629518502644e-06,
      "loss": 0.0,
      "step": 47570
    },
    {
      "epoch": 10.197171024432063,
      "grad_norm": 0.0013232073979452252,
      "learning_rate": 6.403771967423919e-06,
      "loss": 0.0,
      "step": 47580
    },
    {
      "epoch": 10.199314187741106,
      "grad_norm": 0.00026395218446850777,
      "learning_rate": 6.400914416345193e-06,
      "loss": 0.1507,
      "step": 47590
    },
    {
      "epoch": 10.20145735105015,
      "grad_norm": 0.00038359672180376947,
      "learning_rate": 6.3980568652664676e-06,
      "loss": 0.0,
      "step": 47600
    },
    {
      "epoch": 10.203600514359195,
      "grad_norm": 0.027936598286032677,
      "learning_rate": 6.3951993141877415e-06,
      "loss": 0.0,
      "step": 47610
    },
    {
      "epoch": 10.205743677668238,
      "grad_norm": 0.0007299515418708324,
      "learning_rate": 6.3923417631090154e-06,
      "loss": 0.0008,
      "step": 47620
    },
    {
      "epoch": 10.207886840977283,
      "grad_norm": 0.00031051679980009794,
      "learning_rate": 6.38948421203029e-06,
      "loss": 0.0,
      "step": 47630
    },
    {
      "epoch": 10.210030004286327,
      "grad_norm": 0.00041605037404224277,
      "learning_rate": 6.386626660951565e-06,
      "loss": 0.0,
      "step": 47640
    },
    {
      "epoch": 10.21217316759537,
      "grad_norm": 0.00017402302182745188,
      "learning_rate": 6.38376910987284e-06,
      "loss": 0.0,
      "step": 47650
    },
    {
      "epoch": 10.214316330904415,
      "grad_norm": 0.0003161398053634912,
      "learning_rate": 6.380911558794114e-06,
      "loss": 0.0,
      "step": 47660
    },
    {
      "epoch": 10.21645949421346,
      "grad_norm": 0.00017556438979227096,
      "learning_rate": 6.3780540077153885e-06,
      "loss": 0.0,
      "step": 47670
    },
    {
      "epoch": 10.218602657522503,
      "grad_norm": 0.00015602314670104533,
      "learning_rate": 6.375196456636663e-06,
      "loss": 0.0,
      "step": 47680
    },
    {
      "epoch": 10.220745820831548,
      "grad_norm": 0.00020486096036620438,
      "learning_rate": 6.372338905557938e-06,
      "loss": 0.0012,
      "step": 47690
    },
    {
      "epoch": 10.222888984140592,
      "grad_norm": 0.003389841178432107,
      "learning_rate": 6.369481354479212e-06,
      "loss": 0.0004,
      "step": 47700
    },
    {
      "epoch": 10.225032147449635,
      "grad_norm": 0.021441511809825897,
      "learning_rate": 6.366623803400487e-06,
      "loss": 0.15,
      "step": 47710
    },
    {
      "epoch": 10.22717531075868,
      "grad_norm": 0.00014319998444989324,
      "learning_rate": 6.363766252321761e-06,
      "loss": 0.0,
      "step": 47720
    },
    {
      "epoch": 10.229318474067725,
      "grad_norm": 0.00037951988633722067,
      "learning_rate": 6.3609087012430346e-06,
      "loss": 0.146,
      "step": 47730
    },
    {
      "epoch": 10.231461637376768,
      "grad_norm": 0.004255105275660753,
      "learning_rate": 6.358051150164309e-06,
      "loss": 0.0,
      "step": 47740
    },
    {
      "epoch": 10.233604800685812,
      "grad_norm": 18.07464599609375,
      "learning_rate": 6.355193599085584e-06,
      "loss": 0.1566,
      "step": 47750
    },
    {
      "epoch": 10.235747963994857,
      "grad_norm": 0.0029858655761927366,
      "learning_rate": 6.352336048006859e-06,
      "loss": 0.0,
      "step": 47760
    },
    {
      "epoch": 10.2378911273039,
      "grad_norm": 0.0037447288632392883,
      "learning_rate": 6.349478496928133e-06,
      "loss": 0.0,
      "step": 47770
    },
    {
      "epoch": 10.240034290612945,
      "grad_norm": 0.0007388046942651272,
      "learning_rate": 6.346620945849408e-06,
      "loss": 0.0,
      "step": 47780
    },
    {
      "epoch": 10.24217745392199,
      "grad_norm": 0.00040540326153859496,
      "learning_rate": 6.343763394770682e-06,
      "loss": 0.0,
      "step": 47790
    },
    {
      "epoch": 10.244320617231033,
      "grad_norm": 0.0002516231033951044,
      "learning_rate": 6.340905843691957e-06,
      "loss": 0.0,
      "step": 47800
    },
    {
      "epoch": 10.246463780540077,
      "grad_norm": 7.754210673738271e-05,
      "learning_rate": 6.338048292613231e-06,
      "loss": 0.0,
      "step": 47810
    },
    {
      "epoch": 10.248606943849122,
      "grad_norm": 0.00018218666082248092,
      "learning_rate": 6.335190741534506e-06,
      "loss": 0.2499,
      "step": 47820
    },
    {
      "epoch": 10.250750107158165,
      "grad_norm": 0.00021352592739276588,
      "learning_rate": 6.33233319045578e-06,
      "loss": 0.0,
      "step": 47830
    },
    {
      "epoch": 10.25289327046721,
      "grad_norm": 8.562453876947984e-05,
      "learning_rate": 6.329475639377054e-06,
      "loss": 0.0,
      "step": 47840
    },
    {
      "epoch": 10.255036433776255,
      "grad_norm": 0.00017151643987745047,
      "learning_rate": 6.3266180882983285e-06,
      "loss": 0.0,
      "step": 47850
    },
    {
      "epoch": 10.257179597085297,
      "grad_norm": 0.000325166794937104,
      "learning_rate": 6.323760537219603e-06,
      "loss": 0.0957,
      "step": 47860
    },
    {
      "epoch": 10.259322760394342,
      "grad_norm": 9.124205826083198e-05,
      "learning_rate": 6.320902986140878e-06,
      "loss": 0.0,
      "step": 47870
    },
    {
      "epoch": 10.261465923703387,
      "grad_norm": 0.0028945181984454393,
      "learning_rate": 6.318045435062152e-06,
      "loss": 0.0,
      "step": 47880
    },
    {
      "epoch": 10.26360908701243,
      "grad_norm": 9.860781574388966e-05,
      "learning_rate": 6.315187883983427e-06,
      "loss": 0.0,
      "step": 47890
    },
    {
      "epoch": 10.265752250321475,
      "grad_norm": 0.0002616541169118136,
      "learning_rate": 6.3123303329047015e-06,
      "loss": 0.0,
      "step": 47900
    },
    {
      "epoch": 10.26789541363052,
      "grad_norm": 0.00022472867567557842,
      "learning_rate": 6.309472781825976e-06,
      "loss": 0.0001,
      "step": 47910
    },
    {
      "epoch": 10.270038576939562,
      "grad_norm": 0.0006656516925431788,
      "learning_rate": 6.30661523074725e-06,
      "loss": 0.0,
      "step": 47920
    },
    {
      "epoch": 10.272181740248607,
      "grad_norm": 0.000340972444973886,
      "learning_rate": 6.303757679668525e-06,
      "loss": 0.0,
      "step": 47930
    },
    {
      "epoch": 10.274324903557652,
      "grad_norm": 0.0020878231152892113,
      "learning_rate": 6.300900128589799e-06,
      "loss": 0.4326,
      "step": 47940
    },
    {
      "epoch": 10.276468066866695,
      "grad_norm": 185.0879669189453,
      "learning_rate": 6.298042577511073e-06,
      "loss": 0.1901,
      "step": 47950
    },
    {
      "epoch": 10.27861123017574,
      "grad_norm": 0.0004562762624118477,
      "learning_rate": 6.295185026432348e-06,
      "loss": 0.0,
      "step": 47960
    },
    {
      "epoch": 10.280754393484784,
      "grad_norm": 0.0007168754236772656,
      "learning_rate": 6.292327475353622e-06,
      "loss": 0.0,
      "step": 47970
    },
    {
      "epoch": 10.282897556793827,
      "grad_norm": 0.0013024439103901386,
      "learning_rate": 6.289469924274897e-06,
      "loss": 0.0075,
      "step": 47980
    },
    {
      "epoch": 10.285040720102872,
      "grad_norm": 0.000508840021211654,
      "learning_rate": 6.286612373196171e-06,
      "loss": 0.0001,
      "step": 47990
    },
    {
      "epoch": 10.287183883411917,
      "grad_norm": 0.0005562630831263959,
      "learning_rate": 6.283754822117446e-06,
      "loss": 0.0011,
      "step": 48000
    },
    {
      "epoch": 10.28932704672096,
      "grad_norm": 0.0001176868609036319,
      "learning_rate": 6.280897271038721e-06,
      "loss": 0.0001,
      "step": 48010
    },
    {
      "epoch": 10.291470210030004,
      "grad_norm": 5.2101251640124246e-05,
      "learning_rate": 6.2780397199599954e-06,
      "loss": 0.0,
      "step": 48020
    },
    {
      "epoch": 10.29361337333905,
      "grad_norm": 0.00038777737063355744,
      "learning_rate": 6.275182168881269e-06,
      "loss": 0.0001,
      "step": 48030
    },
    {
      "epoch": 10.295756536648092,
      "grad_norm": 9.389259503223002e-05,
      "learning_rate": 6.272324617802543e-06,
      "loss": 0.0,
      "step": 48040
    },
    {
      "epoch": 10.297899699957137,
      "grad_norm": 0.00027492843219079077,
      "learning_rate": 6.269467066723818e-06,
      "loss": 0.0,
      "step": 48050
    },
    {
      "epoch": 10.300042863266182,
      "grad_norm": 0.00014174228999763727,
      "learning_rate": 6.266609515645092e-06,
      "loss": 0.0002,
      "step": 48060
    },
    {
      "epoch": 10.302186026575225,
      "grad_norm": 0.0003642341762315482,
      "learning_rate": 6.263751964566367e-06,
      "loss": 0.0,
      "step": 48070
    },
    {
      "epoch": 10.30432918988427,
      "grad_norm": 0.0018921832088381052,
      "learning_rate": 6.2608944134876415e-06,
      "loss": 0.0,
      "step": 48080
    },
    {
      "epoch": 10.306472353193314,
      "grad_norm": 0.0001261732104467228,
      "learning_rate": 6.258036862408916e-06,
      "loss": 0.2118,
      "step": 48090
    },
    {
      "epoch": 10.308615516502357,
      "grad_norm": 0.00043963940697722137,
      "learning_rate": 6.25517931133019e-06,
      "loss": 0.0001,
      "step": 48100
    },
    {
      "epoch": 10.310758679811402,
      "grad_norm": 0.00013778281572740525,
      "learning_rate": 6.252321760251465e-06,
      "loss": 0.0006,
      "step": 48110
    },
    {
      "epoch": 10.312901843120446,
      "grad_norm": 6.931939424248412e-05,
      "learning_rate": 6.24946420917274e-06,
      "loss": 0.0,
      "step": 48120
    },
    {
      "epoch": 10.31504500642949,
      "grad_norm": 0.0004342758620623499,
      "learning_rate": 6.2466066580940146e-06,
      "loss": 0.0001,
      "step": 48130
    },
    {
      "epoch": 10.317188169738534,
      "grad_norm": 0.009556771256029606,
      "learning_rate": 6.2437491070152885e-06,
      "loss": 0.0,
      "step": 48140
    },
    {
      "epoch": 10.319331333047579,
      "grad_norm": 0.0004921119543723762,
      "learning_rate": 6.2408915559365624e-06,
      "loss": 0.0,
      "step": 48150
    },
    {
      "epoch": 10.321474496356622,
      "grad_norm": 8.622197492513806e-05,
      "learning_rate": 6.238034004857837e-06,
      "loss": 0.0003,
      "step": 48160
    },
    {
      "epoch": 10.323617659665667,
      "grad_norm": 0.013739495538175106,
      "learning_rate": 6.235176453779111e-06,
      "loss": 0.0,
      "step": 48170
    },
    {
      "epoch": 10.325760822974711,
      "grad_norm": 4.71066014142707e-05,
      "learning_rate": 6.232318902700386e-06,
      "loss": 0.0009,
      "step": 48180
    },
    {
      "epoch": 10.327903986283754,
      "grad_norm": 0.004127056337893009,
      "learning_rate": 6.229461351621661e-06,
      "loss": 0.0001,
      "step": 48190
    },
    {
      "epoch": 10.330047149592799,
      "grad_norm": 0.0008238398586399853,
      "learning_rate": 6.2266038005429355e-06,
      "loss": 0.0948,
      "step": 48200
    },
    {
      "epoch": 10.332190312901844,
      "grad_norm": 0.00024184418725781143,
      "learning_rate": 6.223746249464209e-06,
      "loss": 0.3022,
      "step": 48210
    },
    {
      "epoch": 10.334333476210887,
      "grad_norm": 103.9360122680664,
      "learning_rate": 6.220888698385484e-06,
      "loss": 0.2783,
      "step": 48220
    },
    {
      "epoch": 10.336476639519931,
      "grad_norm": 0.0001971268793568015,
      "learning_rate": 6.218031147306759e-06,
      "loss": 0.0,
      "step": 48230
    },
    {
      "epoch": 10.338619802828976,
      "grad_norm": 0.00023527731536887586,
      "learning_rate": 6.215173596228034e-06,
      "loss": 0.0001,
      "step": 48240
    },
    {
      "epoch": 10.34076296613802,
      "grad_norm": 6.466438935603946e-05,
      "learning_rate": 6.2123160451493085e-06,
      "loss": 0.0107,
      "step": 48250
    },
    {
      "epoch": 10.342906129447064,
      "grad_norm": 5.968381083221175e-05,
      "learning_rate": 6.2094584940705816e-06,
      "loss": 0.0,
      "step": 48260
    },
    {
      "epoch": 10.345049292756109,
      "grad_norm": 0.0009976732544600964,
      "learning_rate": 6.206600942991856e-06,
      "loss": 0.0,
      "step": 48270
    },
    {
      "epoch": 10.347192456065152,
      "grad_norm": 4.2696869059000164e-05,
      "learning_rate": 6.20374339191313e-06,
      "loss": 0.0001,
      "step": 48280
    },
    {
      "epoch": 10.349335619374196,
      "grad_norm": 40.89607620239258,
      "learning_rate": 6.200885840834405e-06,
      "loss": 0.1732,
      "step": 48290
    },
    {
      "epoch": 10.351478782683241,
      "grad_norm": 3.4766831959132105e-05,
      "learning_rate": 6.19802828975568e-06,
      "loss": 0.0,
      "step": 48300
    },
    {
      "epoch": 10.353621945992284,
      "grad_norm": 0.0003845298779197037,
      "learning_rate": 6.195170738676955e-06,
      "loss": 0.4171,
      "step": 48310
    },
    {
      "epoch": 10.355765109301329,
      "grad_norm": 0.0021780694369226694,
      "learning_rate": 6.192313187598229e-06,
      "loss": 0.0,
      "step": 48320
    },
    {
      "epoch": 10.357908272610374,
      "grad_norm": 0.007324769161641598,
      "learning_rate": 6.189455636519503e-06,
      "loss": 0.0,
      "step": 48330
    },
    {
      "epoch": 10.360051435919416,
      "grad_norm": 0.0008236823487095535,
      "learning_rate": 6.186598085440778e-06,
      "loss": 0.0,
      "step": 48340
    },
    {
      "epoch": 10.362194599228461,
      "grad_norm": 0.012163866311311722,
      "learning_rate": 6.183740534362053e-06,
      "loss": 0.2382,
      "step": 48350
    },
    {
      "epoch": 10.364337762537506,
      "grad_norm": 0.0032723559997975826,
      "learning_rate": 6.180882983283326e-06,
      "loss": 0.0,
      "step": 48360
    },
    {
      "epoch": 10.366480925846549,
      "grad_norm": 0.004489176906645298,
      "learning_rate": 6.178025432204601e-06,
      "loss": 0.0,
      "step": 48370
    },
    {
      "epoch": 10.368624089155594,
      "grad_norm": 0.004336770158261061,
      "learning_rate": 6.1751678811258755e-06,
      "loss": 0.0008,
      "step": 48380
    },
    {
      "epoch": 10.370767252464638,
      "grad_norm": 0.0013318301644176245,
      "learning_rate": 6.17231033004715e-06,
      "loss": 0.0008,
      "step": 48390
    },
    {
      "epoch": 10.372910415773681,
      "grad_norm": 0.004558299668133259,
      "learning_rate": 6.169452778968424e-06,
      "loss": 0.0,
      "step": 48400
    },
    {
      "epoch": 10.375053579082726,
      "grad_norm": 0.0006767972372472286,
      "learning_rate": 6.166595227889699e-06,
      "loss": 0.0,
      "step": 48410
    },
    {
      "epoch": 10.37719674239177,
      "grad_norm": 0.0008718600147403777,
      "learning_rate": 6.163737676810974e-06,
      "loss": 0.0002,
      "step": 48420
    },
    {
      "epoch": 10.379339905700814,
      "grad_norm": 0.0005979255656711757,
      "learning_rate": 6.1608801257322485e-06,
      "loss": 0.0,
      "step": 48430
    },
    {
      "epoch": 10.381483069009859,
      "grad_norm": 0.001193312113173306,
      "learning_rate": 6.1580225746535224e-06,
      "loss": 0.0,
      "step": 48440
    },
    {
      "epoch": 10.383626232318903,
      "grad_norm": 0.001812306116335094,
      "learning_rate": 6.155165023574797e-06,
      "loss": 0.2386,
      "step": 48450
    },
    {
      "epoch": 10.385769395627946,
      "grad_norm": 0.0010552445892244577,
      "learning_rate": 6.152307472496072e-06,
      "loss": 0.0001,
      "step": 48460
    },
    {
      "epoch": 10.387912558936991,
      "grad_norm": 0.0005335661116987467,
      "learning_rate": 6.149449921417345e-06,
      "loss": 0.0,
      "step": 48470
    },
    {
      "epoch": 10.390055722246036,
      "grad_norm": 0.0205790176987648,
      "learning_rate": 6.14659237033862e-06,
      "loss": 0.0001,
      "step": 48480
    },
    {
      "epoch": 10.392198885555079,
      "grad_norm": 0.001278443494811654,
      "learning_rate": 6.143734819259895e-06,
      "loss": 0.0,
      "step": 48490
    },
    {
      "epoch": 10.394342048864123,
      "grad_norm": 0.04744579643011093,
      "learning_rate": 6.140877268181169e-06,
      "loss": 0.0002,
      "step": 48500
    },
    {
      "epoch": 10.396485212173168,
      "grad_norm": 0.048026394098997116,
      "learning_rate": 6.138019717102443e-06,
      "loss": 0.0001,
      "step": 48510
    },
    {
      "epoch": 10.398628375482211,
      "grad_norm": 0.0030282498337328434,
      "learning_rate": 6.135162166023718e-06,
      "loss": 0.0,
      "step": 48520
    },
    {
      "epoch": 10.400771538791256,
      "grad_norm": 0.0014671118697151542,
      "learning_rate": 6.132304614944993e-06,
      "loss": 0.0,
      "step": 48530
    },
    {
      "epoch": 10.4029147021003,
      "grad_norm": 0.0013737755361944437,
      "learning_rate": 6.129447063866268e-06,
      "loss": 0.0,
      "step": 48540
    },
    {
      "epoch": 10.405057865409344,
      "grad_norm": 0.0003755392099265009,
      "learning_rate": 6.126589512787542e-06,
      "loss": 0.0,
      "step": 48550
    },
    {
      "epoch": 10.407201028718388,
      "grad_norm": 17.48276138305664,
      "learning_rate": 6.123731961708816e-06,
      "loss": 0.4121,
      "step": 48560
    },
    {
      "epoch": 10.409344192027433,
      "grad_norm": 0.10559424757957458,
      "learning_rate": 6.120874410630091e-06,
      "loss": 0.0001,
      "step": 48570
    },
    {
      "epoch": 10.411487355336476,
      "grad_norm": 0.0009513588738627732,
      "learning_rate": 6.118016859551364e-06,
      "loss": 0.0,
      "step": 48580
    },
    {
      "epoch": 10.41363051864552,
      "grad_norm": 0.0004628283786587417,
      "learning_rate": 6.115159308472639e-06,
      "loss": 0.0001,
      "step": 48590
    },
    {
      "epoch": 10.415773681954565,
      "grad_norm": 0.0006196785252541304,
      "learning_rate": 6.112301757393914e-06,
      "loss": 0.0004,
      "step": 48600
    },
    {
      "epoch": 10.417916845263608,
      "grad_norm": 0.0006308123120106757,
      "learning_rate": 6.1094442063151885e-06,
      "loss": 0.0,
      "step": 48610
    },
    {
      "epoch": 10.420060008572653,
      "grad_norm": 0.0008599408902227879,
      "learning_rate": 6.1065866552364625e-06,
      "loss": 0.0001,
      "step": 48620
    },
    {
      "epoch": 10.422203171881698,
      "grad_norm": 0.011525255627930164,
      "learning_rate": 6.103729104157737e-06,
      "loss": 0.0002,
      "step": 48630
    },
    {
      "epoch": 10.42434633519074,
      "grad_norm": 0.0005660027964040637,
      "learning_rate": 6.100871553079012e-06,
      "loss": 0.0,
      "step": 48640
    },
    {
      "epoch": 10.426489498499786,
      "grad_norm": 0.03536267951130867,
      "learning_rate": 6.098014002000287e-06,
      "loss": 0.0001,
      "step": 48650
    },
    {
      "epoch": 10.42863266180883,
      "grad_norm": 0.002512827515602112,
      "learning_rate": 6.095156450921561e-06,
      "loss": 0.0001,
      "step": 48660
    },
    {
      "epoch": 10.430775825117873,
      "grad_norm": 0.0025742945726960897,
      "learning_rate": 6.0922988998428355e-06,
      "loss": 0.0,
      "step": 48670
    },
    {
      "epoch": 10.432918988426918,
      "grad_norm": 0.0007257722318172455,
      "learning_rate": 6.08944134876411e-06,
      "loss": 0.0,
      "step": 48680
    },
    {
      "epoch": 10.435062151735963,
      "grad_norm": 0.00011916635412489995,
      "learning_rate": 6.086583797685383e-06,
      "loss": 0.0,
      "step": 48690
    },
    {
      "epoch": 10.437205315045006,
      "grad_norm": 0.00047118408838286996,
      "learning_rate": 6.083726246606658e-06,
      "loss": 0.0,
      "step": 48700
    },
    {
      "epoch": 10.43934847835405,
      "grad_norm": 0.003817550837993622,
      "learning_rate": 6.080868695527933e-06,
      "loss": 0.0001,
      "step": 48710
    },
    {
      "epoch": 10.441491641663095,
      "grad_norm": 0.000896926096174866,
      "learning_rate": 6.078011144449208e-06,
      "loss": 0.1442,
      "step": 48720
    },
    {
      "epoch": 10.443634804972138,
      "grad_norm": 0.0003787081514019519,
      "learning_rate": 6.075153593370482e-06,
      "loss": 0.0001,
      "step": 48730
    },
    {
      "epoch": 10.445777968281183,
      "grad_norm": 0.010948820039629936,
      "learning_rate": 6.072296042291756e-06,
      "loss": 0.0,
      "step": 48740
    },
    {
      "epoch": 10.447921131590228,
      "grad_norm": 0.038086023181676865,
      "learning_rate": 6.069438491213031e-06,
      "loss": 0.0001,
      "step": 48750
    },
    {
      "epoch": 10.45006429489927,
      "grad_norm": 0.00047618476673960686,
      "learning_rate": 6.066580940134306e-06,
      "loss": 0.0,
      "step": 48760
    },
    {
      "epoch": 10.452207458208315,
      "grad_norm": 0.00036265794187784195,
      "learning_rate": 6.06372338905558e-06,
      "loss": 0.1736,
      "step": 48770
    },
    {
      "epoch": 10.45435062151736,
      "grad_norm": 0.00044838935718871653,
      "learning_rate": 6.060865837976855e-06,
      "loss": 0.0961,
      "step": 48780
    },
    {
      "epoch": 10.456493784826403,
      "grad_norm": 0.0018301197560504079,
      "learning_rate": 6.0580082868981286e-06,
      "loss": 0.102,
      "step": 48790
    },
    {
      "epoch": 10.458636948135448,
      "grad_norm": 0.0005447298171930015,
      "learning_rate": 6.0551507358194025e-06,
      "loss": 0.0,
      "step": 48800
    },
    {
      "epoch": 10.460780111444492,
      "grad_norm": 0.001046565012075007,
      "learning_rate": 6.052293184740677e-06,
      "loss": 0.0003,
      "step": 48810
    },
    {
      "epoch": 10.462923274753535,
      "grad_norm": 0.0005139305721968412,
      "learning_rate": 6.049435633661952e-06,
      "loss": 0.0001,
      "step": 48820
    },
    {
      "epoch": 10.46506643806258,
      "grad_norm": 0.0004339696606621146,
      "learning_rate": 6.046578082583227e-06,
      "loss": 0.0001,
      "step": 48830
    },
    {
      "epoch": 10.467209601371625,
      "grad_norm": 0.002280081622302532,
      "learning_rate": 6.043720531504501e-06,
      "loss": 0.0002,
      "step": 48840
    },
    {
      "epoch": 10.469352764680668,
      "grad_norm": 0.0008165903273038566,
      "learning_rate": 6.0408629804257755e-06,
      "loss": 0.0001,
      "step": 48850
    },
    {
      "epoch": 10.471495927989713,
      "grad_norm": 0.0003477382124401629,
      "learning_rate": 6.03800542934705e-06,
      "loss": 0.0,
      "step": 48860
    },
    {
      "epoch": 10.473639091298757,
      "grad_norm": 0.0003831333597190678,
      "learning_rate": 6.035147878268325e-06,
      "loss": 0.0,
      "step": 48870
    },
    {
      "epoch": 10.4757822546078,
      "grad_norm": 0.0003841877623926848,
      "learning_rate": 6.032290327189599e-06,
      "loss": 0.1595,
      "step": 48880
    },
    {
      "epoch": 10.477925417916845,
      "grad_norm": 0.018413495272397995,
      "learning_rate": 6.029432776110874e-06,
      "loss": 0.0,
      "step": 48890
    },
    {
      "epoch": 10.48006858122589,
      "grad_norm": 0.0017013854812830687,
      "learning_rate": 6.026575225032148e-06,
      "loss": 0.1601,
      "step": 48900
    },
    {
      "epoch": 10.482211744534933,
      "grad_norm": 0.00015740776143502444,
      "learning_rate": 6.023717673953422e-06,
      "loss": 0.0006,
      "step": 48910
    },
    {
      "epoch": 10.484354907843978,
      "grad_norm": 0.00029758262098766863,
      "learning_rate": 6.020860122874696e-06,
      "loss": 0.1384,
      "step": 48920
    },
    {
      "epoch": 10.486498071153022,
      "grad_norm": 0.00035619508707895875,
      "learning_rate": 6.018002571795971e-06,
      "loss": 0.0,
      "step": 48930
    },
    {
      "epoch": 10.488641234462065,
      "grad_norm": 0.0006491485983133316,
      "learning_rate": 6.015145020717246e-06,
      "loss": 0.0,
      "step": 48940
    },
    {
      "epoch": 10.49078439777111,
      "grad_norm": 0.002516118809580803,
      "learning_rate": 6.01228746963852e-06,
      "loss": 0.0,
      "step": 48950
    },
    {
      "epoch": 10.492927561080155,
      "grad_norm": 0.000807283679023385,
      "learning_rate": 6.009429918559795e-06,
      "loss": 0.0004,
      "step": 48960
    },
    {
      "epoch": 10.495070724389198,
      "grad_norm": 0.000328957277815789,
      "learning_rate": 6.0065723674810694e-06,
      "loss": 0.0,
      "step": 48970
    },
    {
      "epoch": 10.497213887698242,
      "grad_norm": 0.00021665837266482413,
      "learning_rate": 6.003714816402344e-06,
      "loss": 0.1182,
      "step": 48980
    },
    {
      "epoch": 10.499357051007287,
      "grad_norm": 0.1227417141199112,
      "learning_rate": 6.000857265323618e-06,
      "loss": 0.0012,
      "step": 48990
    },
    {
      "epoch": 10.50150021431633,
      "grad_norm": 0.018996143713593483,
      "learning_rate": 5.997999714244893e-06,
      "loss": 0.0001,
      "step": 49000
    },
    {
      "epoch": 10.503643377625375,
      "grad_norm": 0.0002770271967165172,
      "learning_rate": 5.995142163166167e-06,
      "loss": 0.0,
      "step": 49010
    },
    {
      "epoch": 10.50578654093442,
      "grad_norm": 0.00010129525617230684,
      "learning_rate": 5.992284612087441e-06,
      "loss": 0.0,
      "step": 49020
    },
    {
      "epoch": 10.507929704243463,
      "grad_norm": 0.0004549509030766785,
      "learning_rate": 5.9894270610087156e-06,
      "loss": 0.0001,
      "step": 49030
    },
    {
      "epoch": 10.510072867552507,
      "grad_norm": 0.00010606342402752489,
      "learning_rate": 5.98656950992999e-06,
      "loss": 0.0,
      "step": 49040
    },
    {
      "epoch": 10.512216030861552,
      "grad_norm": 0.00023753236746415496,
      "learning_rate": 5.983711958851265e-06,
      "loss": 0.0001,
      "step": 49050
    },
    {
      "epoch": 10.514359194170595,
      "grad_norm": 0.0011101749259978533,
      "learning_rate": 5.980854407772539e-06,
      "loss": 0.0,
      "step": 49060
    },
    {
      "epoch": 10.51650235747964,
      "grad_norm": 0.0007690801867283881,
      "learning_rate": 5.977996856693814e-06,
      "loss": 0.1201,
      "step": 49070
    },
    {
      "epoch": 10.518645520788684,
      "grad_norm": 86.33417510986328,
      "learning_rate": 5.975139305615089e-06,
      "loss": 0.0047,
      "step": 49080
    },
    {
      "epoch": 10.520788684097727,
      "grad_norm": 0.0009638871997594833,
      "learning_rate": 5.972281754536363e-06,
      "loss": 0.0,
      "step": 49090
    },
    {
      "epoch": 10.522931847406772,
      "grad_norm": 0.001270041917450726,
      "learning_rate": 5.969424203457638e-06,
      "loss": 0.0111,
      "step": 49100
    },
    {
      "epoch": 10.525075010715817,
      "grad_norm": 0.0003092274419032037,
      "learning_rate": 5.966566652378912e-06,
      "loss": 0.0,
      "step": 49110
    },
    {
      "epoch": 10.52721817402486,
      "grad_norm": 0.00012039716966683045,
      "learning_rate": 5.963709101300186e-06,
      "loss": 0.0031,
      "step": 49120
    },
    {
      "epoch": 10.529361337333905,
      "grad_norm": 0.00027781579410657287,
      "learning_rate": 5.96085155022146e-06,
      "loss": 0.0002,
      "step": 49130
    },
    {
      "epoch": 10.53150450064295,
      "grad_norm": 0.00045931717613711953,
      "learning_rate": 5.957993999142735e-06,
      "loss": 0.0,
      "step": 49140
    },
    {
      "epoch": 10.533647663951992,
      "grad_norm": 0.0004045178066007793,
      "learning_rate": 5.9551364480640095e-06,
      "loss": 0.0,
      "step": 49150
    },
    {
      "epoch": 10.535790827261037,
      "grad_norm": 0.0002241955226054415,
      "learning_rate": 5.952278896985284e-06,
      "loss": 0.0122,
      "step": 49160
    },
    {
      "epoch": 10.537933990570082,
      "grad_norm": 0.000161523770657368,
      "learning_rate": 5.949421345906559e-06,
      "loss": 0.0,
      "step": 49170
    },
    {
      "epoch": 10.540077153879125,
      "grad_norm": 0.0002581342705525458,
      "learning_rate": 5.946563794827833e-06,
      "loss": 0.0,
      "step": 49180
    },
    {
      "epoch": 10.54222031718817,
      "grad_norm": 0.00015132079715840518,
      "learning_rate": 5.943706243749108e-06,
      "loss": 0.0,
      "step": 49190
    },
    {
      "epoch": 10.544363480497214,
      "grad_norm": 0.0005585930193774402,
      "learning_rate": 5.9408486926703825e-06,
      "loss": 0.0,
      "step": 49200
    },
    {
      "epoch": 10.546506643806257,
      "grad_norm": 0.0005497281672433019,
      "learning_rate": 5.937991141591657e-06,
      "loss": 0.0,
      "step": 49210
    },
    {
      "epoch": 10.548649807115302,
      "grad_norm": 0.0001990741293411702,
      "learning_rate": 5.93513359051293e-06,
      "loss": 0.0,
      "step": 49220
    },
    {
      "epoch": 10.550792970424347,
      "grad_norm": 0.0004423744685482234,
      "learning_rate": 5.932276039434205e-06,
      "loss": 0.0,
      "step": 49230
    },
    {
      "epoch": 10.55293613373339,
      "grad_norm": 0.0017687162617221475,
      "learning_rate": 5.92941848835548e-06,
      "loss": 0.0,
      "step": 49240
    },
    {
      "epoch": 10.555079297042434,
      "grad_norm": 0.00011798404739238322,
      "learning_rate": 5.926560937276754e-06,
      "loss": 0.0,
      "step": 49250
    },
    {
      "epoch": 10.557222460351479,
      "grad_norm": 0.000562369532417506,
      "learning_rate": 5.923703386198029e-06,
      "loss": 0.0,
      "step": 49260
    },
    {
      "epoch": 10.559365623660522,
      "grad_norm": 0.6395217180252075,
      "learning_rate": 5.920845835119303e-06,
      "loss": 0.0013,
      "step": 49270
    },
    {
      "epoch": 10.561508786969567,
      "grad_norm": 0.00020882594981230795,
      "learning_rate": 5.917988284040578e-06,
      "loss": 0.0,
      "step": 49280
    },
    {
      "epoch": 10.563651950278611,
      "grad_norm": 0.0004980138037353754,
      "learning_rate": 5.915130732961852e-06,
      "loss": 0.0002,
      "step": 49290
    },
    {
      "epoch": 10.565795113587654,
      "grad_norm": 0.00016755255637690425,
      "learning_rate": 5.912273181883127e-06,
      "loss": 0.0003,
      "step": 49300
    },
    {
      "epoch": 10.5679382768967,
      "grad_norm": 0.0003014644898939878,
      "learning_rate": 5.909415630804402e-06,
      "loss": 0.0,
      "step": 49310
    },
    {
      "epoch": 10.570081440205744,
      "grad_norm": 0.00017415924230590463,
      "learning_rate": 5.906558079725676e-06,
      "loss": 0.0,
      "step": 49320
    },
    {
      "epoch": 10.572224603514789,
      "grad_norm": 0.00037876551505178213,
      "learning_rate": 5.9037005286469495e-06,
      "loss": 0.0,
      "step": 49330
    },
    {
      "epoch": 10.574367766823832,
      "grad_norm": 0.00014776174793951213,
      "learning_rate": 5.900842977568224e-06,
      "loss": 0.3738,
      "step": 49340
    },
    {
      "epoch": 10.576510930132876,
      "grad_norm": 0.0004086591361556202,
      "learning_rate": 5.897985426489499e-06,
      "loss": 0.3255,
      "step": 49350
    },
    {
      "epoch": 10.578654093441921,
      "grad_norm": 0.0008554993546567857,
      "learning_rate": 5.895127875410773e-06,
      "loss": 0.0,
      "step": 49360
    },
    {
      "epoch": 10.580797256750964,
      "grad_norm": 0.019329795613884926,
      "learning_rate": 5.892270324332048e-06,
      "loss": 0.0001,
      "step": 49370
    },
    {
      "epoch": 10.582940420060009,
      "grad_norm": 0.0015454061795026064,
      "learning_rate": 5.8894127732533225e-06,
      "loss": 0.0001,
      "step": 49380
    },
    {
      "epoch": 10.585083583369054,
      "grad_norm": 0.007694473024457693,
      "learning_rate": 5.886555222174597e-06,
      "loss": 0.0,
      "step": 49390
    },
    {
      "epoch": 10.587226746678096,
      "grad_norm": 0.0008069444447755814,
      "learning_rate": 5.883697671095871e-06,
      "loss": 0.0001,
      "step": 49400
    },
    {
      "epoch": 10.589369909987141,
      "grad_norm": 0.0012629061238840222,
      "learning_rate": 5.880840120017146e-06,
      "loss": 0.0001,
      "step": 49410
    },
    {
      "epoch": 10.591513073296186,
      "grad_norm": 0.0008374509634450078,
      "learning_rate": 5.877982568938421e-06,
      "loss": 0.0007,
      "step": 49420
    },
    {
      "epoch": 10.593656236605229,
      "grad_norm": 0.0011174135142937303,
      "learning_rate": 5.8751250178596956e-06,
      "loss": 0.0,
      "step": 49430
    },
    {
      "epoch": 10.595799399914274,
      "grad_norm": 0.0015409295447170734,
      "learning_rate": 5.872267466780969e-06,
      "loss": 0.0001,
      "step": 49440
    },
    {
      "epoch": 10.597942563223318,
      "grad_norm": 0.0005635616835206747,
      "learning_rate": 5.869409915702243e-06,
      "loss": 0.0,
      "step": 49450
    },
    {
      "epoch": 10.600085726532361,
      "grad_norm": 0.0005616389098577201,
      "learning_rate": 5.866552364623518e-06,
      "loss": 0.0,
      "step": 49460
    },
    {
      "epoch": 10.602228889841406,
      "grad_norm": 0.000376352749299258,
      "learning_rate": 5.863694813544792e-06,
      "loss": 0.0,
      "step": 49470
    },
    {
      "epoch": 10.60437205315045,
      "grad_norm": 0.0009813138749450445,
      "learning_rate": 5.860837262466067e-06,
      "loss": 0.0,
      "step": 49480
    },
    {
      "epoch": 10.606515216459494,
      "grad_norm": 0.0007188996532931924,
      "learning_rate": 5.857979711387342e-06,
      "loss": 0.0,
      "step": 49490
    },
    {
      "epoch": 10.608658379768539,
      "grad_norm": 0.0017961704870685935,
      "learning_rate": 5.8551221603086164e-06,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 10.610801543077583,
      "grad_norm": 0.00220237928442657,
      "learning_rate": 5.85226460922989e-06,
      "loss": 0.0,
      "step": 49510
    },
    {
      "epoch": 10.612944706386626,
      "grad_norm": 0.0009530478273518384,
      "learning_rate": 5.849407058151165e-06,
      "loss": 0.0,
      "step": 49520
    },
    {
      "epoch": 10.615087869695671,
      "grad_norm": 0.0006987216183915734,
      "learning_rate": 5.84654950707244e-06,
      "loss": 0.0,
      "step": 49530
    },
    {
      "epoch": 10.617231033004716,
      "grad_norm": 0.0010197729570791125,
      "learning_rate": 5.843691955993715e-06,
      "loss": 0.0,
      "step": 49540
    },
    {
      "epoch": 10.619374196313759,
      "grad_norm": 0.0016553467139601707,
      "learning_rate": 5.840834404914988e-06,
      "loss": 0.0,
      "step": 49550
    },
    {
      "epoch": 10.621517359622803,
      "grad_norm": 0.001157954684458673,
      "learning_rate": 5.8379768538362625e-06,
      "loss": 0.0,
      "step": 49560
    },
    {
      "epoch": 10.623660522931848,
      "grad_norm": 0.0013214920181781054,
      "learning_rate": 5.835119302757537e-06,
      "loss": 0.0,
      "step": 49570
    },
    {
      "epoch": 10.625803686240891,
      "grad_norm": 0.0005790306022390723,
      "learning_rate": 5.832261751678811e-06,
      "loss": 0.1414,
      "step": 49580
    },
    {
      "epoch": 10.627946849549936,
      "grad_norm": 0.0065065594390034676,
      "learning_rate": 5.829404200600086e-06,
      "loss": 0.0,
      "step": 49590
    },
    {
      "epoch": 10.63009001285898,
      "grad_norm": 0.00046058211592026055,
      "learning_rate": 5.826546649521361e-06,
      "loss": 0.0,
      "step": 49600
    },
    {
      "epoch": 10.632233176168024,
      "grad_norm": 0.0014506953302770853,
      "learning_rate": 5.823689098442636e-06,
      "loss": 0.0008,
      "step": 49610
    },
    {
      "epoch": 10.634376339477068,
      "grad_norm": 0.00047902221558615565,
      "learning_rate": 5.8208315473639095e-06,
      "loss": 0.0,
      "step": 49620
    },
    {
      "epoch": 10.636519502786113,
      "grad_norm": 25.331031799316406,
      "learning_rate": 5.817973996285184e-06,
      "loss": 0.3047,
      "step": 49630
    },
    {
      "epoch": 10.638662666095156,
      "grad_norm": 0.00045104618766345084,
      "learning_rate": 5.815116445206459e-06,
      "loss": 0.0,
      "step": 49640
    },
    {
      "epoch": 10.6408058294042,
      "grad_norm": 0.0008578215492889285,
      "learning_rate": 5.812258894127732e-06,
      "loss": 0.0012,
      "step": 49650
    },
    {
      "epoch": 10.642948992713245,
      "grad_norm": 0.0006319145322777331,
      "learning_rate": 5.809401343049007e-06,
      "loss": 0.0,
      "step": 49660
    },
    {
      "epoch": 10.645092156022288,
      "grad_norm": 0.3795424997806549,
      "learning_rate": 5.806543791970282e-06,
      "loss": 0.0004,
      "step": 49670
    },
    {
      "epoch": 10.647235319331333,
      "grad_norm": 0.04707556590437889,
      "learning_rate": 5.8036862408915565e-06,
      "loss": 0.0001,
      "step": 49680
    },
    {
      "epoch": 10.649378482640378,
      "grad_norm": 0.0003653545572888106,
      "learning_rate": 5.80082868981283e-06,
      "loss": 0.0,
      "step": 49690
    },
    {
      "epoch": 10.65152164594942,
      "grad_norm": 0.0007645623991265893,
      "learning_rate": 5.797971138734105e-06,
      "loss": 0.0,
      "step": 49700
    },
    {
      "epoch": 10.653664809258466,
      "grad_norm": 0.0006140074110589921,
      "learning_rate": 5.79511358765538e-06,
      "loss": 0.0,
      "step": 49710
    },
    {
      "epoch": 10.65580797256751,
      "grad_norm": 0.0003277479554526508,
      "learning_rate": 5.792256036576655e-06,
      "loss": 0.0,
      "step": 49720
    },
    {
      "epoch": 10.657951135876553,
      "grad_norm": 0.0003633301821537316,
      "learning_rate": 5.789398485497929e-06,
      "loss": 0.0,
      "step": 49730
    },
    {
      "epoch": 10.660094299185598,
      "grad_norm": 0.000251686607953161,
      "learning_rate": 5.786540934419203e-06,
      "loss": 0.0,
      "step": 49740
    },
    {
      "epoch": 10.662237462494643,
      "grad_norm": 0.00039835029747337103,
      "learning_rate": 5.783683383340478e-06,
      "loss": 0.0,
      "step": 49750
    },
    {
      "epoch": 10.664380625803686,
      "grad_norm": 0.0006632490549236536,
      "learning_rate": 5.780825832261751e-06,
      "loss": 0.0001,
      "step": 49760
    },
    {
      "epoch": 10.66652378911273,
      "grad_norm": 0.00040865488699637353,
      "learning_rate": 5.777968281183026e-06,
      "loss": 0.0,
      "step": 49770
    },
    {
      "epoch": 10.668666952421775,
      "grad_norm": 0.0015089587541297078,
      "learning_rate": 5.775110730104301e-06,
      "loss": 0.0,
      "step": 49780
    },
    {
      "epoch": 10.670810115730818,
      "grad_norm": 0.000172574698808603,
      "learning_rate": 5.772253179025576e-06,
      "loss": 0.0,
      "step": 49790
    },
    {
      "epoch": 10.672953279039863,
      "grad_norm": 0.0025050153490155935,
      "learning_rate": 5.7693956279468495e-06,
      "loss": 0.0,
      "step": 49800
    },
    {
      "epoch": 10.675096442348908,
      "grad_norm": 0.0004073299642186612,
      "learning_rate": 5.766538076868124e-06,
      "loss": 0.0342,
      "step": 49810
    },
    {
      "epoch": 10.67723960565795,
      "grad_norm": 0.0007460424676537514,
      "learning_rate": 5.763680525789399e-06,
      "loss": 0.0,
      "step": 49820
    },
    {
      "epoch": 10.679382768966995,
      "grad_norm": 0.0004360219172667712,
      "learning_rate": 5.760822974710674e-06,
      "loss": 0.0,
      "step": 49830
    },
    {
      "epoch": 10.68152593227604,
      "grad_norm": 0.9680553078651428,
      "learning_rate": 5.757965423631949e-06,
      "loss": 0.0015,
      "step": 49840
    },
    {
      "epoch": 10.683669095585083,
      "grad_norm": 0.0007429210236296058,
      "learning_rate": 5.7551078725532226e-06,
      "loss": 0.0,
      "step": 49850
    },
    {
      "epoch": 10.685812258894128,
      "grad_norm": 0.0001599787938175723,
      "learning_rate": 5.752250321474497e-06,
      "loss": 0.0228,
      "step": 49860
    },
    {
      "epoch": 10.687955422203173,
      "grad_norm": 0.001189892995171249,
      "learning_rate": 5.74939277039577e-06,
      "loss": 0.0,
      "step": 49870
    },
    {
      "epoch": 10.690098585512215,
      "grad_norm": 0.0014036977663636208,
      "learning_rate": 5.746535219317045e-06,
      "loss": 0.0,
      "step": 49880
    },
    {
      "epoch": 10.69224174882126,
      "grad_norm": 0.000353159848600626,
      "learning_rate": 5.74367766823832e-06,
      "loss": 0.0001,
      "step": 49890
    },
    {
      "epoch": 10.694384912130305,
      "grad_norm": 0.004491047002375126,
      "learning_rate": 5.740820117159595e-06,
      "loss": 0.0,
      "step": 49900
    },
    {
      "epoch": 10.696528075439348,
      "grad_norm": 0.00018592893320601434,
      "learning_rate": 5.7379625660808695e-06,
      "loss": 0.0,
      "step": 49910
    },
    {
      "epoch": 10.698671238748393,
      "grad_norm": 0.00032952020410448313,
      "learning_rate": 5.7351050150021434e-06,
      "loss": 0.0,
      "step": 49920
    },
    {
      "epoch": 10.700814402057437,
      "grad_norm": 0.00142586138099432,
      "learning_rate": 5.732247463923418e-06,
      "loss": 0.0002,
      "step": 49930
    },
    {
      "epoch": 10.70295756536648,
      "grad_norm": 0.0003377344983164221,
      "learning_rate": 5.729389912844693e-06,
      "loss": 0.0001,
      "step": 49940
    },
    {
      "epoch": 10.705100728675525,
      "grad_norm": 0.0003544689971022308,
      "learning_rate": 5.726532361765968e-06,
      "loss": 0.1607,
      "step": 49950
    },
    {
      "epoch": 10.70724389198457,
      "grad_norm": 0.0002414719929220155,
      "learning_rate": 5.723674810687242e-06,
      "loss": 0.0,
      "step": 49960
    },
    {
      "epoch": 10.709387055293613,
      "grad_norm": 0.00013639559620060027,
      "learning_rate": 5.720817259608516e-06,
      "loss": 0.0,
      "step": 49970
    },
    {
      "epoch": 10.711530218602658,
      "grad_norm": 0.00010774274414870888,
      "learning_rate": 5.71795970852979e-06,
      "loss": 0.4914,
      "step": 49980
    },
    {
      "epoch": 10.713673381911702,
      "grad_norm": 0.00012099055311409757,
      "learning_rate": 5.715102157451064e-06,
      "loss": 0.0,
      "step": 49990
    },
    {
      "epoch": 10.715816545220745,
      "grad_norm": 0.00024096395645756274,
      "learning_rate": 5.712244606372339e-06,
      "loss": 0.0,
      "step": 50000
    },
    {
      "epoch": 10.71795970852979,
      "grad_norm": 0.0002745855017565191,
      "learning_rate": 5.709387055293614e-06,
      "loss": 0.0,
      "step": 50010
    },
    {
      "epoch": 10.720102871838835,
      "grad_norm": 0.0002494711661711335,
      "learning_rate": 5.706529504214889e-06,
      "loss": 0.0,
      "step": 50020
    },
    {
      "epoch": 10.722246035147878,
      "grad_norm": 0.00042282239883206785,
      "learning_rate": 5.703671953136163e-06,
      "loss": 0.0,
      "step": 50030
    },
    {
      "epoch": 10.724389198456922,
      "grad_norm": 0.0001703798188827932,
      "learning_rate": 5.700814402057437e-06,
      "loss": 0.0,
      "step": 50040
    },
    {
      "epoch": 10.726532361765967,
      "grad_norm": 0.000201458198716864,
      "learning_rate": 5.697956850978712e-06,
      "loss": 0.0,
      "step": 50050
    },
    {
      "epoch": 10.72867552507501,
      "grad_norm": 0.0004152558685746044,
      "learning_rate": 5.695099299899987e-06,
      "loss": 0.0,
      "step": 50060
    },
    {
      "epoch": 10.730818688384055,
      "grad_norm": 0.0003009708016179502,
      "learning_rate": 5.692241748821261e-06,
      "loss": 0.0,
      "step": 50070
    },
    {
      "epoch": 10.7329618516931,
      "grad_norm": 0.00033990785595960915,
      "learning_rate": 5.689384197742535e-06,
      "loss": 0.0,
      "step": 50080
    },
    {
      "epoch": 10.735105015002143,
      "grad_norm": 0.0012435434618964791,
      "learning_rate": 5.6865266466638095e-06,
      "loss": 0.0,
      "step": 50090
    },
    {
      "epoch": 10.737248178311187,
      "grad_norm": 0.00034013736876659095,
      "learning_rate": 5.6836690955850835e-06,
      "loss": 0.0,
      "step": 50100
    },
    {
      "epoch": 10.739391341620232,
      "grad_norm": 0.0017644279869273305,
      "learning_rate": 5.680811544506358e-06,
      "loss": 0.0,
      "step": 50110
    },
    {
      "epoch": 10.741534504929275,
      "grad_norm": 0.00027441157726570964,
      "learning_rate": 5.677953993427633e-06,
      "loss": 0.0,
      "step": 50120
    },
    {
      "epoch": 10.74367766823832,
      "grad_norm": 0.0035741475876420736,
      "learning_rate": 5.675096442348908e-06,
      "loss": 0.3105,
      "step": 50130
    },
    {
      "epoch": 10.745820831547364,
      "grad_norm": 0.0004945185501128435,
      "learning_rate": 5.672238891270182e-06,
      "loss": 0.0001,
      "step": 50140
    },
    {
      "epoch": 10.747963994856407,
      "grad_norm": 0.0010447725653648376,
      "learning_rate": 5.6693813401914565e-06,
      "loss": 0.0,
      "step": 50150
    },
    {
      "epoch": 10.750107158165452,
      "grad_norm": 0.00035423124791122973,
      "learning_rate": 5.666523789112731e-06,
      "loss": 0.0,
      "step": 50160
    },
    {
      "epoch": 10.752250321474497,
      "grad_norm": 0.0003576085437089205,
      "learning_rate": 5.663666238034006e-06,
      "loss": 0.0,
      "step": 50170
    },
    {
      "epoch": 10.75439348478354,
      "grad_norm": 0.00047733899555169046,
      "learning_rate": 5.66080868695528e-06,
      "loss": 0.0,
      "step": 50180
    },
    {
      "epoch": 10.756536648092585,
      "grad_norm": 0.00018831422494258732,
      "learning_rate": 5.657951135876554e-06,
      "loss": 0.0258,
      "step": 50190
    },
    {
      "epoch": 10.75867981140163,
      "grad_norm": 0.008634926751255989,
      "learning_rate": 5.655093584797829e-06,
      "loss": 0.0,
      "step": 50200
    },
    {
      "epoch": 10.760822974710672,
      "grad_norm": 0.002653334988281131,
      "learning_rate": 5.652236033719103e-06,
      "loss": 0.0001,
      "step": 50210
    },
    {
      "epoch": 10.762966138019717,
      "grad_norm": 0.0019881732296198606,
      "learning_rate": 5.649378482640377e-06,
      "loss": 0.0004,
      "step": 50220
    },
    {
      "epoch": 10.765109301328762,
      "grad_norm": 0.0008689590613357723,
      "learning_rate": 5.646520931561652e-06,
      "loss": 0.0,
      "step": 50230
    },
    {
      "epoch": 10.767252464637805,
      "grad_norm": 0.0015875285025686026,
      "learning_rate": 5.643663380482927e-06,
      "loss": 0.0,
      "step": 50240
    },
    {
      "epoch": 10.76939562794685,
      "grad_norm": 0.001275311573408544,
      "learning_rate": 5.640805829404201e-06,
      "loss": 0.0,
      "step": 50250
    },
    {
      "epoch": 10.771538791255894,
      "grad_norm": 0.0001626242883503437,
      "learning_rate": 5.637948278325476e-06,
      "loss": 0.0,
      "step": 50260
    },
    {
      "epoch": 10.773681954564937,
      "grad_norm": 0.0012515648268163204,
      "learning_rate": 5.63509072724675e-06,
      "loss": 0.0,
      "step": 50270
    },
    {
      "epoch": 10.775825117873982,
      "grad_norm": 0.00025505543453618884,
      "learning_rate": 5.632233176168025e-06,
      "loss": 0.0002,
      "step": 50280
    },
    {
      "epoch": 10.777968281183027,
      "grad_norm": 0.00014251518587116152,
      "learning_rate": 5.629375625089299e-06,
      "loss": 0.0001,
      "step": 50290
    },
    {
      "epoch": 10.78011144449207,
      "grad_norm": 0.007544784341007471,
      "learning_rate": 5.626518074010573e-06,
      "loss": 0.0,
      "step": 50300
    },
    {
      "epoch": 10.782254607801114,
      "grad_norm": 0.00033871049527078867,
      "learning_rate": 5.623660522931848e-06,
      "loss": 0.0,
      "step": 50310
    },
    {
      "epoch": 10.784397771110159,
      "grad_norm": 0.00019376067211851478,
      "learning_rate": 5.620802971853122e-06,
      "loss": 0.0,
      "step": 50320
    },
    {
      "epoch": 10.786540934419202,
      "grad_norm": 0.001555241527967155,
      "learning_rate": 5.6179454207743965e-06,
      "loss": 0.0,
      "step": 50330
    },
    {
      "epoch": 10.788684097728247,
      "grad_norm": 0.26676779985427856,
      "learning_rate": 5.615087869695671e-06,
      "loss": 0.0006,
      "step": 50340
    },
    {
      "epoch": 10.790827261037292,
      "grad_norm": 0.00039552917587570846,
      "learning_rate": 5.612230318616946e-06,
      "loss": 0.0056,
      "step": 50350
    },
    {
      "epoch": 10.792970424346334,
      "grad_norm": 0.00014514381473418325,
      "learning_rate": 5.60937276753822e-06,
      "loss": 0.0,
      "step": 50360
    },
    {
      "epoch": 10.79511358765538,
      "grad_norm": 7.645314326509833e-05,
      "learning_rate": 5.606515216459495e-06,
      "loss": 0.0,
      "step": 50370
    },
    {
      "epoch": 10.797256750964424,
      "grad_norm": 0.00012257613707333803,
      "learning_rate": 5.6036576653807696e-06,
      "loss": 0.0,
      "step": 50380
    },
    {
      "epoch": 10.799399914273467,
      "grad_norm": 0.0022254562936723232,
      "learning_rate": 5.600800114302044e-06,
      "loss": 0.0,
      "step": 50390
    },
    {
      "epoch": 10.801543077582512,
      "grad_norm": 9.605957166058943e-05,
      "learning_rate": 5.597942563223317e-06,
      "loss": 0.0,
      "step": 50400
    },
    {
      "epoch": 10.803686240891556,
      "grad_norm": 0.0004062341176904738,
      "learning_rate": 5.595085012144592e-06,
      "loss": 0.0,
      "step": 50410
    },
    {
      "epoch": 10.8058294042006,
      "grad_norm": 51.165008544921875,
      "learning_rate": 5.592227461065867e-06,
      "loss": 0.23,
      "step": 50420
    },
    {
      "epoch": 10.807972567509644,
      "grad_norm": 0.0013331157388165593,
      "learning_rate": 5.589369909987141e-06,
      "loss": 0.0,
      "step": 50430
    },
    {
      "epoch": 10.810115730818689,
      "grad_norm": 0.0010349804069846869,
      "learning_rate": 5.586512358908416e-06,
      "loss": 0.0,
      "step": 50440
    },
    {
      "epoch": 10.812258894127732,
      "grad_norm": 0.0017823409289121628,
      "learning_rate": 5.5836548078296904e-06,
      "loss": 0.0,
      "step": 50450
    },
    {
      "epoch": 10.814402057436777,
      "grad_norm": 0.001755705801770091,
      "learning_rate": 5.580797256750965e-06,
      "loss": 0.0,
      "step": 50460
    },
    {
      "epoch": 10.816545220745821,
      "grad_norm": 0.00029452142189256847,
      "learning_rate": 5.577939705672239e-06,
      "loss": 0.0,
      "step": 50470
    },
    {
      "epoch": 10.818688384054864,
      "grad_norm": 0.00019054308359045535,
      "learning_rate": 5.575082154593514e-06,
      "loss": 0.0,
      "step": 50480
    },
    {
      "epoch": 10.820831547363909,
      "grad_norm": 0.0247793085873127,
      "learning_rate": 5.572224603514789e-06,
      "loss": 0.0,
      "step": 50490
    },
    {
      "epoch": 10.822974710672954,
      "grad_norm": 0.0004138542280998081,
      "learning_rate": 5.5693670524360635e-06,
      "loss": 0.0,
      "step": 50500
    },
    {
      "epoch": 10.825117873981997,
      "grad_norm": 0.0002974148083012551,
      "learning_rate": 5.5665095013573366e-06,
      "loss": 0.0,
      "step": 50510
    },
    {
      "epoch": 10.827261037291041,
      "grad_norm": 0.0001606485020602122,
      "learning_rate": 5.563651950278611e-06,
      "loss": 0.0,
      "step": 50520
    },
    {
      "epoch": 10.829404200600086,
      "grad_norm": 0.0005521242856048048,
      "learning_rate": 5.560794399199886e-06,
      "loss": 0.0001,
      "step": 50530
    },
    {
      "epoch": 10.831547363909129,
      "grad_norm": 0.0001401685003656894,
      "learning_rate": 5.55793684812116e-06,
      "loss": 0.0,
      "step": 50540
    },
    {
      "epoch": 10.833690527218174,
      "grad_norm": 0.0005907342419959605,
      "learning_rate": 5.555079297042435e-06,
      "loss": 0.2432,
      "step": 50550
    },
    {
      "epoch": 10.835833690527219,
      "grad_norm": 0.00022772960073780268,
      "learning_rate": 5.55222174596371e-06,
      "loss": 0.0,
      "step": 50560
    },
    {
      "epoch": 10.837976853836262,
      "grad_norm": 0.0019319363636896014,
      "learning_rate": 5.549364194884984e-06,
      "loss": 0.0,
      "step": 50570
    },
    {
      "epoch": 10.840120017145306,
      "grad_norm": 9.32918701437302e-05,
      "learning_rate": 5.546506643806258e-06,
      "loss": 0.0,
      "step": 50580
    },
    {
      "epoch": 10.842263180454351,
      "grad_norm": 0.00011630027438513935,
      "learning_rate": 5.543649092727533e-06,
      "loss": 0.0,
      "step": 50590
    },
    {
      "epoch": 10.844406343763394,
      "grad_norm": 0.5723771452903748,
      "learning_rate": 5.540791541648808e-06,
      "loss": 0.001,
      "step": 50600
    },
    {
      "epoch": 10.846549507072439,
      "grad_norm": 0.005485058296471834,
      "learning_rate": 5.537933990570083e-06,
      "loss": 0.0,
      "step": 50610
    },
    {
      "epoch": 10.848692670381483,
      "grad_norm": 0.00032275536796078086,
      "learning_rate": 5.535076439491356e-06,
      "loss": 0.0,
      "step": 50620
    },
    {
      "epoch": 10.850835833690526,
      "grad_norm": 0.00012043517926940694,
      "learning_rate": 5.5322188884126305e-06,
      "loss": 0.0001,
      "step": 50630
    },
    {
      "epoch": 10.852978996999571,
      "grad_norm": 0.00023912730102892965,
      "learning_rate": 5.529361337333905e-06,
      "loss": 0.0,
      "step": 50640
    },
    {
      "epoch": 10.855122160308616,
      "grad_norm": 0.0015036443946883082,
      "learning_rate": 5.526503786255179e-06,
      "loss": 0.0,
      "step": 50650
    },
    {
      "epoch": 10.857265323617659,
      "grad_norm": 0.011464862152934074,
      "learning_rate": 5.523646235176454e-06,
      "loss": 0.0,
      "step": 50660
    },
    {
      "epoch": 10.859408486926704,
      "grad_norm": 0.00025530578568577766,
      "learning_rate": 5.520788684097729e-06,
      "loss": 0.0002,
      "step": 50670
    },
    {
      "epoch": 10.861551650235748,
      "grad_norm": 0.00012286963465157896,
      "learning_rate": 5.5179311330190035e-06,
      "loss": 0.0,
      "step": 50680
    },
    {
      "epoch": 10.863694813544793,
      "grad_norm": 0.00019883141794707626,
      "learning_rate": 5.515073581940278e-06,
      "loss": 0.0,
      "step": 50690
    },
    {
      "epoch": 10.865837976853836,
      "grad_norm": 0.00013141347153577954,
      "learning_rate": 5.512216030861552e-06,
      "loss": 0.0,
      "step": 50700
    },
    {
      "epoch": 10.86798114016288,
      "grad_norm": 0.0006205608369782567,
      "learning_rate": 5.509358479782827e-06,
      "loss": 0.0,
      "step": 50710
    },
    {
      "epoch": 10.870124303471925,
      "grad_norm": 0.0001727206545183435,
      "learning_rate": 5.506500928704102e-06,
      "loss": 0.0,
      "step": 50720
    },
    {
      "epoch": 10.872267466780968,
      "grad_norm": 0.0007270036730915308,
      "learning_rate": 5.503643377625375e-06,
      "loss": 0.0,
      "step": 50730
    },
    {
      "epoch": 10.874410630090013,
      "grad_norm": 0.00017427433340344578,
      "learning_rate": 5.50078582654665e-06,
      "loss": 0.0,
      "step": 50740
    },
    {
      "epoch": 10.876553793399058,
      "grad_norm": 0.00010101746738655493,
      "learning_rate": 5.497928275467924e-06,
      "loss": 0.0,
      "step": 50750
    },
    {
      "epoch": 10.8786969567081,
      "grad_norm": 0.00032647658372297883,
      "learning_rate": 5.495070724389199e-06,
      "loss": 0.0,
      "step": 50760
    },
    {
      "epoch": 10.880840120017146,
      "grad_norm": 6.140862387837842e-05,
      "learning_rate": 5.492213173310473e-06,
      "loss": 0.0,
      "step": 50770
    },
    {
      "epoch": 10.88298328332619,
      "grad_norm": 0.00013139900693204254,
      "learning_rate": 5.489355622231748e-06,
      "loss": 0.0,
      "step": 50780
    },
    {
      "epoch": 10.885126446635233,
      "grad_norm": 0.0005456272629089653,
      "learning_rate": 5.486498071153023e-06,
      "loss": 0.0,
      "step": 50790
    },
    {
      "epoch": 10.887269609944278,
      "grad_norm": 0.003039357252418995,
      "learning_rate": 5.483640520074297e-06,
      "loss": 0.0,
      "step": 50800
    },
    {
      "epoch": 10.889412773253323,
      "grad_norm": 85.96776580810547,
      "learning_rate": 5.480782968995571e-06,
      "loss": 0.2164,
      "step": 50810
    },
    {
      "epoch": 10.891555936562366,
      "grad_norm": 9.53460403252393e-05,
      "learning_rate": 5.477925417916846e-06,
      "loss": 0.0001,
      "step": 50820
    },
    {
      "epoch": 10.89369909987141,
      "grad_norm": 0.00016762017912697047,
      "learning_rate": 5.47506786683812e-06,
      "loss": 0.0,
      "step": 50830
    },
    {
      "epoch": 10.895842263180455,
      "grad_norm": 0.002368992893025279,
      "learning_rate": 5.472210315759394e-06,
      "loss": 0.0,
      "step": 50840
    },
    {
      "epoch": 10.897985426489498,
      "grad_norm": 521.9114990234375,
      "learning_rate": 5.469352764680669e-06,
      "loss": 0.027,
      "step": 50850
    },
    {
      "epoch": 10.900128589798543,
      "grad_norm": 7.325501792365685e-05,
      "learning_rate": 5.4664952136019435e-06,
      "loss": 0.0,
      "step": 50860
    },
    {
      "epoch": 10.902271753107588,
      "grad_norm": 0.001576910843141377,
      "learning_rate": 5.463637662523218e-06,
      "loss": 0.0,
      "step": 50870
    },
    {
      "epoch": 10.90441491641663,
      "grad_norm": 0.00026484718546271324,
      "learning_rate": 5.460780111444492e-06,
      "loss": 0.0,
      "step": 50880
    },
    {
      "epoch": 10.906558079725675,
      "grad_norm": 8.910791802918538e-05,
      "learning_rate": 5.457922560365767e-06,
      "loss": 0.0,
      "step": 50890
    },
    {
      "epoch": 10.90870124303472,
      "grad_norm": 0.0001106475610868074,
      "learning_rate": 5.455065009287042e-06,
      "loss": 0.0,
      "step": 50900
    },
    {
      "epoch": 10.910844406343763,
      "grad_norm": 0.00021655825548805296,
      "learning_rate": 5.4522074582083166e-06,
      "loss": 0.0,
      "step": 50910
    },
    {
      "epoch": 10.912987569652808,
      "grad_norm": 7.05638449289836e-05,
      "learning_rate": 5.4493499071295905e-06,
      "loss": 0.0,
      "step": 50920
    },
    {
      "epoch": 10.915130732961853,
      "grad_norm": 0.00014291955449152738,
      "learning_rate": 5.446492356050865e-06,
      "loss": 0.0,
      "step": 50930
    },
    {
      "epoch": 10.917273896270896,
      "grad_norm": 0.0001706023031147197,
      "learning_rate": 5.443634804972139e-06,
      "loss": 0.0,
      "step": 50940
    },
    {
      "epoch": 10.91941705957994,
      "grad_norm": 5.524093649000861e-05,
      "learning_rate": 5.440777253893413e-06,
      "loss": 0.0,
      "step": 50950
    },
    {
      "epoch": 10.921560222888985,
      "grad_norm": 0.0008085508598014712,
      "learning_rate": 5.437919702814688e-06,
      "loss": 0.0,
      "step": 50960
    },
    {
      "epoch": 10.923703386198028,
      "grad_norm": 0.0003134581493213773,
      "learning_rate": 5.435062151735963e-06,
      "loss": 0.0,
      "step": 50970
    },
    {
      "epoch": 10.925846549507073,
      "grad_norm": 0.00015926166088320315,
      "learning_rate": 5.4322046006572374e-06,
      "loss": 0.0,
      "step": 50980
    },
    {
      "epoch": 10.927989712816117,
      "grad_norm": 0.00010383543849457055,
      "learning_rate": 5.429347049578511e-06,
      "loss": 0.0,
      "step": 50990
    },
    {
      "epoch": 10.93013287612516,
      "grad_norm": 4.510642247623764e-05,
      "learning_rate": 5.426489498499786e-06,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 10.932276039434205,
      "grad_norm": 5.299647091305815e-05,
      "learning_rate": 5.423631947421061e-06,
      "loss": 0.0,
      "step": 51010
    },
    {
      "epoch": 10.93441920274325,
      "grad_norm": 0.00015211975551210344,
      "learning_rate": 5.420774396342336e-06,
      "loss": 0.0,
      "step": 51020
    },
    {
      "epoch": 10.936562366052293,
      "grad_norm": 0.00015290080045815557,
      "learning_rate": 5.41791684526361e-06,
      "loss": 0.0009,
      "step": 51030
    },
    {
      "epoch": 10.938705529361338,
      "grad_norm": 0.0007674781372770667,
      "learning_rate": 5.415059294184884e-06,
      "loss": 0.0003,
      "step": 51040
    },
    {
      "epoch": 10.940848692670382,
      "grad_norm": 5.36438928975258e-05,
      "learning_rate": 5.412201743106158e-06,
      "loss": 0.0,
      "step": 51050
    },
    {
      "epoch": 10.942991855979425,
      "grad_norm": 5.624432014883496e-05,
      "learning_rate": 5.409344192027432e-06,
      "loss": 0.0004,
      "step": 51060
    },
    {
      "epoch": 10.94513501928847,
      "grad_norm": 0.0001538074720883742,
      "learning_rate": 5.406486640948707e-06,
      "loss": 0.0,
      "step": 51070
    },
    {
      "epoch": 10.947278182597515,
      "grad_norm": 0.000722496653907001,
      "learning_rate": 5.403629089869982e-06,
      "loss": 0.0,
      "step": 51080
    },
    {
      "epoch": 10.949421345906558,
      "grad_norm": 8.354237070307136e-05,
      "learning_rate": 5.400771538791257e-06,
      "loss": 0.1604,
      "step": 51090
    },
    {
      "epoch": 10.951564509215602,
      "grad_norm": 0.00011731890845112503,
      "learning_rate": 5.3979139877125305e-06,
      "loss": 0.0,
      "step": 51100
    },
    {
      "epoch": 10.953707672524647,
      "grad_norm": 0.00010534709872445092,
      "learning_rate": 5.395056436633805e-06,
      "loss": 0.0,
      "step": 51110
    },
    {
      "epoch": 10.95585083583369,
      "grad_norm": 0.0019624666310846806,
      "learning_rate": 5.39219888555508e-06,
      "loss": 0.2677,
      "step": 51120
    },
    {
      "epoch": 10.957993999142735,
      "grad_norm": 0.0005754202138632536,
      "learning_rate": 5.389341334476355e-06,
      "loss": 0.2028,
      "step": 51130
    },
    {
      "epoch": 10.96013716245178,
      "grad_norm": 8.597659325459972e-05,
      "learning_rate": 5.386483783397629e-06,
      "loss": 0.0,
      "step": 51140
    },
    {
      "epoch": 10.962280325760823,
      "grad_norm": 0.00032687452039681375,
      "learning_rate": 5.3836262323189035e-06,
      "loss": 0.3171,
      "step": 51150
    },
    {
      "epoch": 10.964423489069867,
      "grad_norm": 0.0009276718483306468,
      "learning_rate": 5.3807686812401775e-06,
      "loss": 0.0,
      "step": 51160
    },
    {
      "epoch": 10.966566652378912,
      "grad_norm": 0.018667710945010185,
      "learning_rate": 5.377911130161451e-06,
      "loss": 0.0,
      "step": 51170
    },
    {
      "epoch": 10.968709815687955,
      "grad_norm": 0.0006189942359924316,
      "learning_rate": 5.375053579082726e-06,
      "loss": 0.0001,
      "step": 51180
    },
    {
      "epoch": 10.970852978997,
      "grad_norm": 0.0003434348327573389,
      "learning_rate": 5.372196028004001e-06,
      "loss": 0.0001,
      "step": 51190
    },
    {
      "epoch": 10.972996142306044,
      "grad_norm": 9.3194299552124e-05,
      "learning_rate": 5.369338476925276e-06,
      "loss": 0.0003,
      "step": 51200
    },
    {
      "epoch": 10.975139305615087,
      "grad_norm": 0.00040760679985396564,
      "learning_rate": 5.36648092584655e-06,
      "loss": 0.0,
      "step": 51210
    },
    {
      "epoch": 10.977282468924132,
      "grad_norm": 6.231202860362828e-05,
      "learning_rate": 5.3636233747678244e-06,
      "loss": 0.0,
      "step": 51220
    },
    {
      "epoch": 10.979425632233177,
      "grad_norm": 0.0010519868228584528,
      "learning_rate": 5.360765823689099e-06,
      "loss": 0.0007,
      "step": 51230
    },
    {
      "epoch": 10.98156879554222,
      "grad_norm": 9.383946598973125e-05,
      "learning_rate": 5.357908272610374e-06,
      "loss": 0.0,
      "step": 51240
    },
    {
      "epoch": 10.983711958851265,
      "grad_norm": 0.0002102826547343284,
      "learning_rate": 5.355050721531648e-06,
      "loss": 0.0,
      "step": 51250
    },
    {
      "epoch": 10.98585512216031,
      "grad_norm": 0.00027056544786319137,
      "learning_rate": 5.352193170452922e-06,
      "loss": 0.0,
      "step": 51260
    },
    {
      "epoch": 10.987998285469352,
      "grad_norm": 0.0004858638276346028,
      "learning_rate": 5.349335619374197e-06,
      "loss": 0.0,
      "step": 51270
    },
    {
      "epoch": 10.990141448778397,
      "grad_norm": 7.339815056184307e-05,
      "learning_rate": 5.3464780682954705e-06,
      "loss": 0.0,
      "step": 51280
    },
    {
      "epoch": 10.992284612087442,
      "grad_norm": 0.00030649444670416415,
      "learning_rate": 5.343620517216745e-06,
      "loss": 0.0,
      "step": 51290
    },
    {
      "epoch": 10.994427775396485,
      "grad_norm": 7.450299017364159e-05,
      "learning_rate": 5.34076296613802e-06,
      "loss": 0.0002,
      "step": 51300
    },
    {
      "epoch": 10.99657093870553,
      "grad_norm": 0.0032453015446662903,
      "learning_rate": 5.337905415059295e-06,
      "loss": 0.0,
      "step": 51310
    },
    {
      "epoch": 10.998714102014574,
      "grad_norm": 0.0006779953837394714,
      "learning_rate": 5.335047863980569e-06,
      "loss": 0.0001,
      "step": 51320
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.934,
      "eval_f1": 0.8253968253968254,
      "eval_loss": 0.6477859616279602,
      "eval_precision": 0.8493647912885662,
      "eval_recall": 0.8027444253859348,
      "eval_runtime": 108.6064,
      "eval_samples_per_second": 27.623,
      "eval_steps_per_second": 1.151,
      "step": 51326
    }
  ],
  "logging_steps": 10,
  "max_steps": 69990,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 15,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.692297967109714e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
